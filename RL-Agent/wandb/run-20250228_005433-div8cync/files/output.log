Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.00660
Policy Entropy: 4.12693
Value Function Loss: 0.04861

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.01208
Policy Update Magnitude: 0.25398
Value Function Update Magnitude: 0.36310

Collected Steps per Second: 6,631.75954
Overall Steps per Second: 3,263.65173

Timestep Collection Time: 7.54129
Timestep Consumption Time: 7.78265
PPO Batch Consumption Time: 3.18040
Total Iteration Time: 15.32394

Cumulative Model Updates: 113,274
Cumulative Timesteps: 944,568,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.15539
Policy Entropy: 3.98847
Value Function Loss: 0.04230

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07642
Policy Update Magnitude: 0.67500
Value Function Update Magnitude: 0.77347

Collected Steps per Second: 20,107.31890
Overall Steps per Second: 11,088.96496

Timestep Collection Time: 2.48765
Timestep Consumption Time: 2.02314
PPO Batch Consumption Time: 0.30566
Total Iteration Time: 4.51079

Cumulative Model Updates: 113,278
Cumulative Timesteps: 944,618,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 944618138...
Checkpoint 944618138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.91110
Policy Entropy: 3.90441
Value Function Loss: 0.03736

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.61795
Value Function Update Magnitude: 0.78526

Collected Steps per Second: 20,533.94921
Overall Steps per Second: 11,276.52775

Timestep Collection Time: 2.43499
Timestep Consumption Time: 1.99900
PPO Batch Consumption Time: 0.30667
Total Iteration Time: 4.43399

Cumulative Model Updates: 113,282
Cumulative Timesteps: 944,668,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.70173
Policy Entropy: 3.77519
Value Function Loss: 0.03606

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.75688
Value Function Update Magnitude: 0.90641

Collected Steps per Second: 20,174.88450
Overall Steps per Second: 9,982.58557

Timestep Collection Time: 2.47853
Timestep Consumption Time: 2.53060
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 5.00912

Cumulative Model Updates: 113,288
Cumulative Timesteps: 944,718,142

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 944718142...
Checkpoint 944718142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.65482
Policy Entropy: 3.78617
Value Function Loss: 0.03517

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.67415
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 21,212.33162
Overall Steps per Second: 10,257.90246

Timestep Collection Time: 2.35759
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.87527

Cumulative Model Updates: 113,294
Cumulative Timesteps: 944,768,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.54735
Policy Entropy: 3.77626
Value Function Loss: 0.03344

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.60397
Value Function Update Magnitude: 0.49080

Collected Steps per Second: 21,329.69092
Overall Steps per Second: 10,269.87417

Timestep Collection Time: 2.34453
Timestep Consumption Time: 2.52486
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.86939

Cumulative Model Updates: 113,300
Cumulative Timesteps: 944,818,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 944818160...
Checkpoint 944818160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.82267
Policy Entropy: 3.79685
Value Function Loss: 0.02839

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.50378

Collected Steps per Second: 21,079.55071
Overall Steps per Second: 10,328.50538

Timestep Collection Time: 2.37225
Timestep Consumption Time: 2.46930
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.84155

Cumulative Model Updates: 113,306
Cumulative Timesteps: 944,868,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.59912
Policy Entropy: 3.75640
Value Function Loss: 0.03011

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.52748

Collected Steps per Second: 20,153.13562
Overall Steps per Second: 10,220.16170

Timestep Collection Time: 2.48100
Timestep Consumption Time: 2.41129
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.89229

Cumulative Model Updates: 113,312
Cumulative Timesteps: 944,918,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 944918166...
Checkpoint 944918166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.58814
Policy Entropy: 3.78371
Value Function Loss: 0.02657

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.50660

Collected Steps per Second: 20,369.54285
Overall Steps per Second: 10,022.34918

Timestep Collection Time: 2.45514
Timestep Consumption Time: 2.53471
PPO Batch Consumption Time: 0.30306
Total Iteration Time: 4.98985

Cumulative Model Updates: 113,318
Cumulative Timesteps: 944,968,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.78272
Policy Entropy: 3.75557
Value Function Loss: 0.02548

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08546
Policy Update Magnitude: 0.62786
Value Function Update Magnitude: 0.51308

Collected Steps per Second: 15,785.80541
Overall Steps per Second: 8,910.19018

Timestep Collection Time: 3.16842
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 5.61335

Cumulative Model Updates: 113,324
Cumulative Timesteps: 945,018,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 945018192...
Checkpoint 945018192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.08926
Policy Entropy: 3.74704
Value Function Loss: 0.02233

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15559
Policy Update Magnitude: 0.60893
Value Function Update Magnitude: 0.65056

Collected Steps per Second: 14,965.92720
Overall Steps per Second: 8,329.59149

Timestep Collection Time: 3.34199
Timestep Consumption Time: 2.66262
PPO Batch Consumption Time: 0.30923
Total Iteration Time: 6.00462

Cumulative Model Updates: 113,330
Cumulative Timesteps: 945,068,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.08926
Policy Entropy: 3.70324
Value Function Loss: 0.02366

Mean KL Divergence: 0.03333
SB3 Clip Fraction: 0.32467
Policy Update Magnitude: 0.47001
Value Function Update Magnitude: 0.65107

Collected Steps per Second: 15,679.58973
Overall Steps per Second: 8,774.13215

Timestep Collection Time: 3.19039
Timestep Consumption Time: 2.51091
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 5.70130

Cumulative Model Updates: 113,336
Cumulative Timesteps: 945,118,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 945118232...
Checkpoint 945118232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,366.97401
Policy Entropy: 3.68776
Value Function Loss: 0.04115

Mean KL Divergence: 0.02876
SB3 Clip Fraction: 0.27927
Policy Update Magnitude: 0.47333
Value Function Update Magnitude: 0.59085

Collected Steps per Second: 20,846.85806
Overall Steps per Second: 10,031.33564

Timestep Collection Time: 2.39854
Timestep Consumption Time: 2.58604
PPO Batch Consumption Time: 0.30467
Total Iteration Time: 4.98458

Cumulative Model Updates: 113,342
Cumulative Timesteps: 945,168,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,761.01249
Policy Entropy: 3.72429
Value Function Loss: 0.05885

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.17693
Policy Update Magnitude: 0.59255
Value Function Update Magnitude: 0.59979

Collected Steps per Second: 20,313.11860
Overall Steps per Second: 9,799.54655

Timestep Collection Time: 2.46146
Timestep Consumption Time: 2.64081
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 5.10228

Cumulative Model Updates: 113,348
Cumulative Timesteps: 945,218,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 945218234...
Checkpoint 945218234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,971.23396
Policy Entropy: 3.79355
Value Function Loss: 0.05513

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.86820
Value Function Update Magnitude: 0.71051

Collected Steps per Second: 20,270.99054
Overall Steps per Second: 9,870.41732

Timestep Collection Time: 2.46717
Timestep Consumption Time: 2.59969
PPO Batch Consumption Time: 0.29892
Total Iteration Time: 5.06686

Cumulative Model Updates: 113,354
Cumulative Timesteps: 945,268,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.88060
Policy Entropy: 3.85031
Value Function Loss: 0.04387

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.97738
Value Function Update Magnitude: 0.68669

Collected Steps per Second: 21,075.38560
Overall Steps per Second: 10,390.52471

Timestep Collection Time: 2.37367
Timestep Consumption Time: 2.44091
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.81458

Cumulative Model Updates: 113,360
Cumulative Timesteps: 945,318,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945318272...
Checkpoint 945318272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,314.92424
Policy Entropy: 3.83148
Value Function Loss: 0.04053

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.98830
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 20,737.27572
Overall Steps per Second: 10,174.36668

Timestep Collection Time: 2.41285
Timestep Consumption Time: 2.50500
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.91785

Cumulative Model Updates: 113,366
Cumulative Timesteps: 945,368,308

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,984.38583
Policy Entropy: 3.80504
Value Function Loss: 0.03439

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.17543
Policy Update Magnitude: 0.83026
Value Function Update Magnitude: 0.61562

Collected Steps per Second: 19,635.76419
Overall Steps per Second: 9,895.71775

Timestep Collection Time: 2.54780
Timestep Consumption Time: 2.50772
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 5.05552

Cumulative Model Updates: 113,372
Cumulative Timesteps: 945,418,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 945418336...
Checkpoint 945418336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,391.58744
Policy Entropy: 3.78631
Value Function Loss: 0.03297

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.66677
Value Function Update Magnitude: 0.66387

Collected Steps per Second: 21,916.07827
Overall Steps per Second: 10,502.10865

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.76171

Cumulative Model Updates: 113,378
Cumulative Timesteps: 945,468,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.26294
Policy Entropy: 3.78939
Value Function Loss: 0.03161

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.48995

Collected Steps per Second: 21,776.86068
Overall Steps per Second: 10,433.60525

Timestep Collection Time: 2.29657
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.79336

Cumulative Model Updates: 113,384
Cumulative Timesteps: 945,518,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 945518356...
Checkpoint 945518356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,850.26294
Policy Entropy: 3.75876
Value Function Loss: 0.02806

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.17697
Policy Update Magnitude: 0.42852
Value Function Update Magnitude: 0.33179

Collected Steps per Second: 20,006.07604
Overall Steps per Second: 9,907.91372

Timestep Collection Time: 2.50064
Timestep Consumption Time: 2.54866
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 5.04930

Cumulative Model Updates: 113,390
Cumulative Timesteps: 945,568,384

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,782.12863
Policy Entropy: 3.72594
Value Function Loss: 0.02602

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.22479
Policy Update Magnitude: 0.38768
Value Function Update Magnitude: 0.46996

Collected Steps per Second: 20,831.53140
Overall Steps per Second: 10,020.02262

Timestep Collection Time: 2.40136
Timestep Consumption Time: 2.59104
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.99240

Cumulative Model Updates: 113,396
Cumulative Timesteps: 945,618,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 945618408...
Checkpoint 945618408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,066.20252
Policy Entropy: 3.69701
Value Function Loss: 0.03835

Mean KL Divergence: 0.02193
SB3 Clip Fraction: 0.25187
Policy Update Magnitude: 0.39177
Value Function Update Magnitude: 0.55099

Collected Steps per Second: 21,268.93713
Overall Steps per Second: 10,096.54389

Timestep Collection Time: 2.35113
Timestep Consumption Time: 2.60166
PPO Batch Consumption Time: 0.30363
Total Iteration Time: 4.95278

Cumulative Model Updates: 113,402
Cumulative Timesteps: 945,668,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,576.08535
Policy Entropy: 3.69243
Value Function Loss: 0.05290

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.53590
Value Function Update Magnitude: 0.54221

Collected Steps per Second: 20,566.89402
Overall Steps per Second: 9,896.72122

Timestep Collection Time: 2.43323
Timestep Consumption Time: 2.62339
PPO Batch Consumption Time: 0.30660
Total Iteration Time: 5.05662

Cumulative Model Updates: 113,408
Cumulative Timesteps: 945,718,458

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 945718458...
Checkpoint 945718458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,530.99628
Policy Entropy: 3.75382
Value Function Loss: 0.05082

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15478
Policy Update Magnitude: 0.67598
Value Function Update Magnitude: 0.47899

Collected Steps per Second: 21,081.53092
Overall Steps per Second: 10,214.73966

Timestep Collection Time: 2.37288
Timestep Consumption Time: 2.52435
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.89724

Cumulative Model Updates: 113,414
Cumulative Timesteps: 945,768,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,474.64361
Policy Entropy: 3.76302
Value Function Loss: 0.05084

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.66902
Value Function Update Magnitude: 0.53975

Collected Steps per Second: 20,621.96414
Overall Steps per Second: 10,076.32962

Timestep Collection Time: 2.42586
Timestep Consumption Time: 2.53884
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.96470

Cumulative Model Updates: 113,420
Cumulative Timesteps: 945,818,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945818508...
Checkpoint 945818508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,336.39824
Policy Entropy: 3.80319
Value Function Loss: 0.04092

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13801
Policy Update Magnitude: 0.61793
Value Function Update Magnitude: 0.49522

Collected Steps per Second: 20,498.05318
Overall Steps per Second: 9,959.33887

Timestep Collection Time: 2.44004
Timestep Consumption Time: 2.58198
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 5.02202

Cumulative Model Updates: 113,426
Cumulative Timesteps: 945,868,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,484.96470
Policy Entropy: 3.74979
Value Function Loss: 0.03940

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.48257

Collected Steps per Second: 21,153.58587
Overall Steps per Second: 10,249.47561

Timestep Collection Time: 2.36499
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.88103

Cumulative Model Updates: 113,432
Cumulative Timesteps: 945,918,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 945918552...
Checkpoint 945918552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,529.34194
Policy Entropy: 3.77543
Value Function Loss: 0.02900

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.48255
Value Function Update Magnitude: 0.47717

Collected Steps per Second: 19,736.26153
Overall Steps per Second: 9,869.62605

Timestep Collection Time: 2.53493
Timestep Consumption Time: 2.53416
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 5.06909

Cumulative Model Updates: 113,438
Cumulative Timesteps: 945,968,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,002.97566
Policy Entropy: 3.74554
Value Function Loss: 0.02745

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.40995
Value Function Update Magnitude: 0.42840

Collected Steps per Second: 21,844.66412
Overall Steps per Second: 10,208.59040

Timestep Collection Time: 2.28925
Timestep Consumption Time: 2.60936
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 4.89862

Cumulative Model Updates: 113,444
Cumulative Timesteps: 946,018,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 946018590...
Checkpoint 946018590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,597.83797
Policy Entropy: 3.76391
Value Function Loss: 0.02350

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.36708
Value Function Update Magnitude: 0.48213

Collected Steps per Second: 18,253.76476
Overall Steps per Second: 9,599.29246

Timestep Collection Time: 2.74135
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 5.21288

Cumulative Model Updates: 113,450
Cumulative Timesteps: 946,068,630

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,495.38938
Policy Entropy: 3.74221
Value Function Loss: 0.02406

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.35433
Value Function Update Magnitude: 0.43704

Collected Steps per Second: 18,932.85494
Overall Steps per Second: 9,599.04113

Timestep Collection Time: 2.64207
Timestep Consumption Time: 2.56907
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 5.21115

Cumulative Model Updates: 113,456
Cumulative Timesteps: 946,118,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 946118652...
Checkpoint 946118652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,851.93870
Policy Entropy: 3.75532
Value Function Loss: 0.02021

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.37149
Value Function Update Magnitude: 0.46228

Collected Steps per Second: 18,841.71155
Overall Steps per Second: 9,348.76878

Timestep Collection Time: 2.65517
Timestep Consumption Time: 2.69612
PPO Batch Consumption Time: 0.31705
Total Iteration Time: 5.35129

Cumulative Model Updates: 113,462
Cumulative Timesteps: 946,168,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,300.58532
Policy Entropy: 3.74557
Value Function Loss: 0.02254

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.36693
Value Function Update Magnitude: 0.49093

Collected Steps per Second: 20,693.50638
Overall Steps per Second: 10,275.02350

Timestep Collection Time: 2.41680
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.86734

Cumulative Model Updates: 113,468
Cumulative Timesteps: 946,218,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946218692...
Checkpoint 946218692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,217.51139
Policy Entropy: 3.74389
Value Function Loss: 0.02023

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.38577
Value Function Update Magnitude: 0.48195

Collected Steps per Second: 21,576.55781
Overall Steps per Second: 10,241.90334

Timestep Collection Time: 2.31844
Timestep Consumption Time: 2.56581
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.88425

Cumulative Model Updates: 113,474
Cumulative Timesteps: 946,268,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,418.15750
Policy Entropy: 3.74666
Value Function Loss: 0.02043

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.39101
Value Function Update Magnitude: 0.55517

Collected Steps per Second: 21,423.99288
Overall Steps per Second: 10,262.74865

Timestep Collection Time: 2.33402
Timestep Consumption Time: 2.53836
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.87238

Cumulative Model Updates: 113,480
Cumulative Timesteps: 946,318,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 946318720...
Checkpoint 946318720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,418.15750
Policy Entropy: 3.73505
Value Function Loss: 0.01882

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.38584
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 21,268.56922
Overall Steps per Second: 10,347.92256

Timestep Collection Time: 2.35098
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.83208

Cumulative Model Updates: 113,486
Cumulative Timesteps: 946,368,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,418.15750
Policy Entropy: 3.72980
Value Function Loss: 0.01900

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.39500
Value Function Update Magnitude: 0.54261

Collected Steps per Second: 20,984.89458
Overall Steps per Second: 9,857.03301

Timestep Collection Time: 2.38343
Timestep Consumption Time: 2.69071
PPO Batch Consumption Time: 0.31463
Total Iteration Time: 5.07414

Cumulative Model Updates: 113,492
Cumulative Timesteps: 946,418,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 946418738...
Checkpoint 946418738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,976.62669
Policy Entropy: 3.72108
Value Function Loss: 0.01899

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.38633
Value Function Update Magnitude: 0.55397

Collected Steps per Second: 20,974.63419
Overall Steps per Second: 9,858.94516

Timestep Collection Time: 2.38526
Timestep Consumption Time: 2.68932
PPO Batch Consumption Time: 0.31602
Total Iteration Time: 5.07458

Cumulative Model Updates: 113,498
Cumulative Timesteps: 946,468,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,976.62669
Policy Entropy: 3.71774
Value Function Loss: 0.01984

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.38162
Value Function Update Magnitude: 0.57580

Collected Steps per Second: 20,490.71124
Overall Steps per Second: 9,870.98128

Timestep Collection Time: 2.44130
Timestep Consumption Time: 2.62648
PPO Batch Consumption Time: 0.30836
Total Iteration Time: 5.06778

Cumulative Model Updates: 113,504
Cumulative Timesteps: 946,518,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 946518792...
Checkpoint 946518792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,976.62669
Policy Entropy: 3.71570
Value Function Loss: 0.02170

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.37830
Value Function Update Magnitude: 0.46421

Collected Steps per Second: 17,990.69565
Overall Steps per Second: 9,406.80224

Timestep Collection Time: 2.78055
Timestep Consumption Time: 2.53731
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 5.31785

Cumulative Model Updates: 113,510
Cumulative Timesteps: 946,568,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,976.62669
Policy Entropy: 3.71386
Value Function Loss: 0.02161

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.36765
Value Function Update Magnitude: 0.36483

Collected Steps per Second: 20,836.59877
Overall Steps per Second: 10,250.20550

Timestep Collection Time: 2.40078
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.88029

Cumulative Model Updates: 113,516
Cumulative Timesteps: 946,618,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 946618840...
Checkpoint 946618840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,027.27115
Policy Entropy: 3.72036
Value Function Loss: 0.02335

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.40154
Value Function Update Magnitude: 0.38507

Collected Steps per Second: 18,644.15307
Overall Steps per Second: 9,628.56766

Timestep Collection Time: 2.68341
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 5.19600

Cumulative Model Updates: 113,522
Cumulative Timesteps: 946,668,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,949.29737
Policy Entropy: 3.73348
Value Function Loss: 0.02254

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.42770
Value Function Update Magnitude: 0.50953

Collected Steps per Second: 21,543.58810
Overall Steps per Second: 10,460.02543

Timestep Collection Time: 2.32310
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.78469

Cumulative Model Updates: 113,528
Cumulative Timesteps: 946,718,918

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 946718918...
Checkpoint 946718918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.73961
Value Function Loss: 0.02250

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.42849
Value Function Update Magnitude: 0.52428

Collected Steps per Second: 21,440.54233
Overall Steps per Second: 10,174.26489

Timestep Collection Time: 2.33334
Timestep Consumption Time: 2.58378
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.91711

Cumulative Model Updates: 113,534
Cumulative Timesteps: 946,768,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.73524
Value Function Loss: 0.02060

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.41845
Value Function Update Magnitude: 0.44342

Collected Steps per Second: 19,325.39276
Overall Steps per Second: 9,674.69491

Timestep Collection Time: 2.58882
Timestep Consumption Time: 2.58240
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 5.17122

Cumulative Model Updates: 113,540
Cumulative Timesteps: 946,818,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 946818976...
Checkpoint 946818976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.72401
Value Function Loss: 0.01974

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.38981
Value Function Update Magnitude: 0.38621

Collected Steps per Second: 19,219.08112
Overall Steps per Second: 9,473.22623

Timestep Collection Time: 2.60241
Timestep Consumption Time: 2.67731
PPO Batch Consumption Time: 0.31181
Total Iteration Time: 5.27972

Cumulative Model Updates: 113,546
Cumulative Timesteps: 946,868,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.72763
Value Function Loss: 0.01915

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.39378
Value Function Update Magnitude: 0.35852

Collected Steps per Second: 20,438.52086
Overall Steps per Second: 10,186.83714

Timestep Collection Time: 2.44783
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.91124

Cumulative Model Updates: 113,552
Cumulative Timesteps: 946,919,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 946919022...
Checkpoint 946919022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.72432
Value Function Loss: 0.02043

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.41253
Value Function Update Magnitude: 0.37081

Collected Steps per Second: 21,356.39403
Overall Steps per Second: 10,274.49288

Timestep Collection Time: 2.34216
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.86837

Cumulative Model Updates: 113,558
Cumulative Timesteps: 946,969,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,018.03353
Policy Entropy: 3.72031
Value Function Loss: 0.01954

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.40085
Value Function Update Magnitude: 0.32895

Collected Steps per Second: 18,401.90416
Overall Steps per Second: 9,537.29697

Timestep Collection Time: 2.71863
Timestep Consumption Time: 2.52688
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 5.24551

Cumulative Model Updates: 113,564
Cumulative Timesteps: 947,019,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 947019070...
Checkpoint 947019070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,760.81213
Policy Entropy: 3.72073
Value Function Loss: 0.02126

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.39498
Value Function Update Magnitude: 0.28297

Collected Steps per Second: 19,362.77025
Overall Steps per Second: 9,785.26829

Timestep Collection Time: 2.58258
Timestep Consumption Time: 2.52775
PPO Batch Consumption Time: 0.30451
Total Iteration Time: 5.11034

Cumulative Model Updates: 113,570
Cumulative Timesteps: 947,069,076

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,725.79344
Policy Entropy: 3.73187
Value Function Loss: 0.02151

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.41000
Value Function Update Magnitude: 0.27962

Collected Steps per Second: 17,146.63587
Overall Steps per Second: 8,884.16299

Timestep Collection Time: 2.91602
Timestep Consumption Time: 2.71197
PPO Batch Consumption Time: 0.31728
Total Iteration Time: 5.62799

Cumulative Model Updates: 113,576
Cumulative Timesteps: 947,119,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 947119076...
Checkpoint 947119076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,725.79344
Policy Entropy: 3.72796
Value Function Loss: 0.02322

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.42524
Value Function Update Magnitude: 0.30559

Collected Steps per Second: 20,046.94586
Overall Steps per Second: 9,970.87728

Timestep Collection Time: 2.49534
Timestep Consumption Time: 2.52167
PPO Batch Consumption Time: 0.29752
Total Iteration Time: 5.01701

Cumulative Model Updates: 113,582
Cumulative Timesteps: 947,169,100

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349,843.05722
Policy Entropy: 3.74143
Value Function Loss: 0.02144

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.46095
Value Function Update Magnitude: 0.37588

Collected Steps per Second: 20,910.68946
Overall Steps per Second: 10,156.48018

Timestep Collection Time: 2.39189
Timestep Consumption Time: 2.53265
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.92454

Cumulative Model Updates: 113,588
Cumulative Timesteps: 947,219,116

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 947219116...
Checkpoint 947219116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,833.31476
Policy Entropy: 3.74499
Value Function Loss: 0.02163

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.48911
Value Function Update Magnitude: 0.48159

Collected Steps per Second: 20,387.73045
Overall Steps per Second: 10,068.02762

Timestep Collection Time: 2.45344
Timestep Consumption Time: 2.51477
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.96820

Cumulative Model Updates: 113,594
Cumulative Timesteps: 947,269,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,314.76874
Policy Entropy: 3.74790
Value Function Loss: 0.02281

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.50693
Value Function Update Magnitude: 0.56353

Collected Steps per Second: 22,024.07074
Overall Steps per Second: 10,222.66623

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.62253
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 4.89422

Cumulative Model Updates: 113,600
Cumulative Timesteps: 947,319,168

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 947319168...
Checkpoint 947319168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.51383
Policy Entropy: 3.74137
Value Function Loss: 0.02256

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.52436
Value Function Update Magnitude: 0.57802

Collected Steps per Second: 20,901.77969
Overall Steps per Second: 10,202.01766

Timestep Collection Time: 2.39281
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.90236

Cumulative Model Updates: 113,606
Cumulative Timesteps: 947,369,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.51383
Policy Entropy: 3.74717
Value Function Loss: 0.01956

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.47786
Value Function Update Magnitude: 0.58059

Collected Steps per Second: 19,328.70084
Overall Steps per Second: 9,735.85500

Timestep Collection Time: 2.58848
Timestep Consumption Time: 2.55046
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 5.13894

Cumulative Model Updates: 113,612
Cumulative Timesteps: 947,419,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 947419214...
Checkpoint 947419214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.51383
Policy Entropy: 3.72908
Value Function Loss: 0.01937

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.41779
Value Function Update Magnitude: 0.50508

Collected Steps per Second: 20,590.75369
Overall Steps per Second: 10,076.46621

Timestep Collection Time: 2.42954
Timestep Consumption Time: 2.53510
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.96464

Cumulative Model Updates: 113,618
Cumulative Timesteps: 947,469,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.51383
Policy Entropy: 3.71782
Value Function Loss: 0.02220

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.46233
Value Function Update Magnitude: 0.41639

Collected Steps per Second: 17,723.83583
Overall Steps per Second: 8,851.55037

Timestep Collection Time: 2.82117
Timestep Consumption Time: 2.82778
PPO Batch Consumption Time: 0.32548
Total Iteration Time: 5.64895

Cumulative Model Updates: 113,624
Cumulative Timesteps: 947,519,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 947519242...
Checkpoint 947519242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.51383
Policy Entropy: 3.70633
Value Function Loss: 0.02534

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.43821

Collected Steps per Second: 17,236.97534
Overall Steps per Second: 9,202.28706

Timestep Collection Time: 2.90295
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.30507
Total Iteration Time: 5.43756

Cumulative Model Updates: 113,630
Cumulative Timesteps: 947,569,280

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,787.76113
Policy Entropy: 3.71705
Value Function Loss: 0.02492

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.52673
Value Function Update Magnitude: 0.49928

Collected Steps per Second: 18,977.99278
Overall Steps per Second: 9,617.97004

Timestep Collection Time: 2.63516
Timestep Consumption Time: 2.56448
PPO Batch Consumption Time: 0.30596
Total Iteration Time: 5.19964

Cumulative Model Updates: 113,636
Cumulative Timesteps: 947,619,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 947619290...
Checkpoint 947619290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,787.76113
Policy Entropy: 3.71012
Value Function Loss: 0.02329

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.50978
Value Function Update Magnitude: 0.54831

Collected Steps per Second: 18,230.69804
Overall Steps per Second: 9,373.54276

Timestep Collection Time: 2.74383
Timestep Consumption Time: 2.59268
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.33651

Cumulative Model Updates: 113,642
Cumulative Timesteps: 947,669,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,601.91363
Policy Entropy: 3.71509
Value Function Loss: 0.02735

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.72662

Collected Steps per Second: 20,042.11192
Overall Steps per Second: 9,711.70655

Timestep Collection Time: 2.49545
Timestep Consumption Time: 2.65442
PPO Batch Consumption Time: 0.31601
Total Iteration Time: 5.14987

Cumulative Model Updates: 113,648
Cumulative Timesteps: 947,719,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 947719326...
Checkpoint 947719326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,980.88485
Policy Entropy: 3.73837
Value Function Loss: 0.03125

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 19,565.23032
Overall Steps per Second: 9,929.64115

Timestep Collection Time: 2.55617
Timestep Consumption Time: 2.48047
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 5.03664

Cumulative Model Updates: 113,654
Cumulative Timesteps: 947,769,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,062.98928
Policy Entropy: 3.75122
Value Function Loss: 0.02962

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 19,589.54676
Overall Steps per Second: 9,593.13915

Timestep Collection Time: 2.55381
Timestep Consumption Time: 2.66117
PPO Batch Consumption Time: 0.31531
Total Iteration Time: 5.21498

Cumulative Model Updates: 113,660
Cumulative Timesteps: 947,819,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 947819366...
Checkpoint 947819366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,607.00257
Policy Entropy: 3.74930
Value Function Loss: 0.02762

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.55711
Value Function Update Magnitude: 0.55826

Collected Steps per Second: 18,820.72971
Overall Steps per Second: 9,559.15093

Timestep Collection Time: 2.65675
Timestep Consumption Time: 2.57405
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 5.23080

Cumulative Model Updates: 113,666
Cumulative Timesteps: 947,869,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,607.00257
Policy Entropy: 3.73773
Value Function Loss: 0.02305

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.52815
Value Function Update Magnitude: 0.52981

Collected Steps per Second: 20,480.25971
Overall Steps per Second: 9,932.95395

Timestep Collection Time: 2.44157
Timestep Consumption Time: 2.59258
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 5.03415

Cumulative Model Updates: 113,672
Cumulative Timesteps: 947,919,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947919372...
Checkpoint 947919372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,607.00257
Policy Entropy: 3.73449
Value Function Loss: 0.02124

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.47400
Value Function Update Magnitude: 0.50225

Collected Steps per Second: 21,301.58530
Overall Steps per Second: 10,329.62083

Timestep Collection Time: 2.34762
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.84122

Cumulative Model Updates: 113,678
Cumulative Timesteps: 947,969,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,607.00257
Policy Entropy: 3.72715
Value Function Loss: 0.02130

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.46888
Value Function Update Magnitude: 0.49929

Collected Steps per Second: 21,123.78984
Overall Steps per Second: 10,212.97533

Timestep Collection Time: 2.36937
Timestep Consumption Time: 2.53126
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.90063

Cumulative Model Updates: 113,684
Cumulative Timesteps: 948,019,430

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 948019430...
Checkpoint 948019430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318,742.53128
Policy Entropy: 3.72388
Value Function Loss: 0.02600

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.51379
Value Function Update Magnitude: 0.57677

Collected Steps per Second: 21,301.34593
Overall Steps per Second: 10,399.20001

Timestep Collection Time: 2.34746
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.80845

Cumulative Model Updates: 113,690
Cumulative Timesteps: 948,069,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,808.81756
Policy Entropy: 3.73915
Value Function Loss: 0.02697

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 20,376.85404
Overall Steps per Second: 10,114.34084

Timestep Collection Time: 2.45406
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.94407

Cumulative Model Updates: 113,696
Cumulative Timesteps: 948,119,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 948119440...
Checkpoint 948119440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,238.02542
Policy Entropy: 3.73663
Value Function Loss: 0.02870

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.59386
Value Function Update Magnitude: 0.66293

Collected Steps per Second: 20,572.42317
Overall Steps per Second: 10,254.21412

Timestep Collection Time: 2.43073
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.87663

Cumulative Model Updates: 113,702
Cumulative Timesteps: 948,169,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,332.82692
Policy Entropy: 3.73591
Value Function Loss: 0.02603

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.60302
Value Function Update Magnitude: 0.66413

Collected Steps per Second: 21,279.70718
Overall Steps per Second: 10,357.55489

Timestep Collection Time: 2.35097
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.83010

Cumulative Model Updates: 113,708
Cumulative Timesteps: 948,219,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948219474...
Checkpoint 948219474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,821.38622
Policy Entropy: 3.72512
Value Function Loss: 0.02672

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.60923
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 20,874.76635
Overall Steps per Second: 10,233.22762

Timestep Collection Time: 2.39533
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.88624

Cumulative Model Updates: 113,714
Cumulative Timesteps: 948,269,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,101.08537
Policy Entropy: 3.73707
Value Function Loss: 0.02703

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.60648
Value Function Update Magnitude: 0.59304

Collected Steps per Second: 21,627.88312
Overall Steps per Second: 10,412.28553

Timestep Collection Time: 2.31220
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.80279

Cumulative Model Updates: 113,720
Cumulative Timesteps: 948,319,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 948319484...
Checkpoint 948319484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,622.74753
Policy Entropy: 3.74803
Value Function Loss: 0.02931

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15246
Policy Update Magnitude: 0.60143
Value Function Update Magnitude: 0.67808

Collected Steps per Second: 20,816.11399
Overall Steps per Second: 10,156.89221

Timestep Collection Time: 2.40343
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.92572

Cumulative Model Updates: 113,726
Cumulative Timesteps: 948,369,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,213.94655
Policy Entropy: 3.73923
Value Function Loss: 0.03214

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.62623
Value Function Update Magnitude: 0.63977

Collected Steps per Second: 19,392.10885
Overall Steps per Second: 9,575.50809

Timestep Collection Time: 2.57847
Timestep Consumption Time: 2.64339
PPO Batch Consumption Time: 0.31313
Total Iteration Time: 5.22186

Cumulative Model Updates: 113,732
Cumulative Timesteps: 948,419,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 948419516...
Checkpoint 948419516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,887.76876
Policy Entropy: 3.71027
Value Function Loss: 0.03473

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.58938
Value Function Update Magnitude: 0.66726

Collected Steps per Second: 19,897.97532
Overall Steps per Second: 9,734.86339

Timestep Collection Time: 2.51302
Timestep Consumption Time: 2.62357
PPO Batch Consumption Time: 0.32276
Total Iteration Time: 5.13659

Cumulative Model Updates: 113,738
Cumulative Timesteps: 948,469,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,488.78839
Policy Entropy: 3.70548
Value Function Loss: 0.03625

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.57338
Value Function Update Magnitude: 0.57246

Collected Steps per Second: 20,106.00008
Overall Steps per Second: 9,899.36856

Timestep Collection Time: 2.48772
Timestep Consumption Time: 2.56493
PPO Batch Consumption Time: 0.31172
Total Iteration Time: 5.05265

Cumulative Model Updates: 113,744
Cumulative Timesteps: 948,519,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948519538...
Checkpoint 948519538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,960.53001
Policy Entropy: 3.69554
Value Function Loss: 0.03080

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.59189
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 18,079.03020
Overall Steps per Second: 9,340.53454

Timestep Collection Time: 2.76619
Timestep Consumption Time: 2.58790
PPO Batch Consumption Time: 0.30166
Total Iteration Time: 5.35408

Cumulative Model Updates: 113,750
Cumulative Timesteps: 948,569,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,960.53001
Policy Entropy: 3.71588
Value Function Loss: 0.02459

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.56483
Value Function Update Magnitude: 0.63164

Collected Steps per Second: 20,870.95805
Overall Steps per Second: 10,150.83956

Timestep Collection Time: 2.39587
Timestep Consumption Time: 2.53023
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.92609

Cumulative Model Updates: 113,756
Cumulative Timesteps: 948,619,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 948619552...
Checkpoint 948619552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,960.53001
Policy Entropy: 3.70026
Value Function Loss: 0.02433

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.50157
Value Function Update Magnitude: 0.53729

Collected Steps per Second: 19,975.18155
Overall Steps per Second: 9,635.31912

Timestep Collection Time: 2.50451
Timestep Consumption Time: 2.68764
PPO Batch Consumption Time: 0.32006
Total Iteration Time: 5.19215

Cumulative Model Updates: 113,762
Cumulative Timesteps: 948,669,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,960.53001
Policy Entropy: 3.70868
Value Function Loss: 0.02418

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.49932
Value Function Update Magnitude: 0.48246

Collected Steps per Second: 20,801.74274
Overall Steps per Second: 9,935.82466

Timestep Collection Time: 2.40393
Timestep Consumption Time: 2.62897
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 5.03290

Cumulative Model Updates: 113,768
Cumulative Timesteps: 948,719,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 948719586...
Checkpoint 948719586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,960.53001
Policy Entropy: 3.69967
Value Function Loss: 0.02536

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.49996
Value Function Update Magnitude: 0.44109

Collected Steps per Second: 20,246.93396
Overall Steps per Second: 10,153.66661

Timestep Collection Time: 2.47208
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.92945

Cumulative Model Updates: 113,774
Cumulative Timesteps: 948,769,638

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336,883.66650
Policy Entropy: 3.71442
Value Function Loss: 0.02597

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.46591
Value Function Update Magnitude: 0.43114

Collected Steps per Second: 22,068.01875
Overall Steps per Second: 10,319.98347

Timestep Collection Time: 2.26572
Timestep Consumption Time: 2.57925
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.84497

Cumulative Model Updates: 113,780
Cumulative Timesteps: 948,819,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 948819638...
Checkpoint 948819638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,210.89440
Policy Entropy: 3.70670
Value Function Loss: 0.02718

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.46417
Value Function Update Magnitude: 0.42668

Collected Steps per Second: 20,081.40879
Overall Steps per Second: 9,938.76829

Timestep Collection Time: 2.49086
Timestep Consumption Time: 2.54196
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 5.03282

Cumulative Model Updates: 113,786
Cumulative Timesteps: 948,869,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,469.02728
Policy Entropy: 3.72603
Value Function Loss: 0.02480

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.46604
Value Function Update Magnitude: 0.46354

Collected Steps per Second: 21,770.70836
Overall Steps per Second: 10,376.33277

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.82155

Cumulative Model Updates: 113,792
Cumulative Timesteps: 948,919,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 948919688...
Checkpoint 948919688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,904.62721
Policy Entropy: 3.70632
Value Function Loss: 0.02678

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.46525
Value Function Update Magnitude: 0.48116

Collected Steps per Second: 19,676.71507
Overall Steps per Second: 9,686.91121

Timestep Collection Time: 2.54260
Timestep Consumption Time: 2.62210
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 5.16470

Cumulative Model Updates: 113,798
Cumulative Timesteps: 948,969,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,904.62721
Policy Entropy: 3.70347
Value Function Loss: 0.02588

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.47147
Value Function Update Magnitude: 0.51003

Collected Steps per Second: 19,444.80399
Overall Steps per Second: 9,959.84694

Timestep Collection Time: 2.57190
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 5.02116

Cumulative Model Updates: 113,804
Cumulative Timesteps: 949,019,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 949019728...
Checkpoint 949019728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304,124.15453
Policy Entropy: 3.68231
Value Function Loss: 0.02916

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.47254
Value Function Update Magnitude: 0.46678

Collected Steps per Second: 20,012.13225
Overall Steps per Second: 10,204.10161

Timestep Collection Time: 2.49978
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.90254

Cumulative Model Updates: 113,810
Cumulative Timesteps: 949,069,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,834.43185
Policy Entropy: 3.69885
Value Function Loss: 0.02661

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.48428
Value Function Update Magnitude: 0.45421

Collected Steps per Second: 20,518.34197
Overall Steps per Second: 10,346.41850

Timestep Collection Time: 2.43860
Timestep Consumption Time: 2.39747
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.83607

Cumulative Model Updates: 113,816
Cumulative Timesteps: 949,119,790

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 949119790...
Checkpoint 949119790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,575.09239
Policy Entropy: 3.71392
Value Function Loss: 0.02903

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.47356
Value Function Update Magnitude: 0.42382

Collected Steps per Second: 20,507.17376
Overall Steps per Second: 10,240.15920

Timestep Collection Time: 2.43934
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.88508

Cumulative Model Updates: 113,822
Cumulative Timesteps: 949,169,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,334.28614
Policy Entropy: 3.73301
Value Function Loss: 0.02650

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.46274
Value Function Update Magnitude: 0.37659

Collected Steps per Second: 21,445.07245
Overall Steps per Second: 9,996.13845

Timestep Collection Time: 2.33163
Timestep Consumption Time: 2.67050
PPO Batch Consumption Time: 0.31683
Total Iteration Time: 5.00213

Cumulative Model Updates: 113,828
Cumulative Timesteps: 949,219,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 949219816...
Checkpoint 949219816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,790.17229
Policy Entropy: 3.72741
Value Function Loss: 0.02603

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.47025
Value Function Update Magnitude: 0.43691

Collected Steps per Second: 20,475.88791
Overall Steps per Second: 9,934.18177

Timestep Collection Time: 2.44209
Timestep Consumption Time: 2.59144
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 5.03353

Cumulative Model Updates: 113,834
Cumulative Timesteps: 949,269,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,516.07324
Policy Entropy: 3.74127
Value Function Loss: 0.02435

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.46948
Value Function Update Magnitude: 0.49395

Collected Steps per Second: 21,609.63768
Overall Steps per Second: 10,311.60206

Timestep Collection Time: 2.31517
Timestep Consumption Time: 2.53665
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.85182

Cumulative Model Updates: 113,840
Cumulative Timesteps: 949,319,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 949319850...
Checkpoint 949319850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,954.55942
Policy Entropy: 3.73799
Value Function Loss: 0.02645

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.49466
Value Function Update Magnitude: 0.49110

Collected Steps per Second: 20,348.67884
Overall Steps per Second: 9,998.79104

Timestep Collection Time: 2.45775
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 5.00180

Cumulative Model Updates: 113,846
Cumulative Timesteps: 949,369,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,631.19061
Policy Entropy: 3.75541
Value Function Loss: 0.02608

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.54177

Collected Steps per Second: 21,395.07326
Overall Steps per Second: 10,285.37769

Timestep Collection Time: 2.33755
Timestep Consumption Time: 2.52489
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.86244

Cumulative Model Updates: 113,852
Cumulative Timesteps: 949,419,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 949419874...
Checkpoint 949419874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,586.36091
Policy Entropy: 3.73585
Value Function Loss: 0.02731

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.57877

Collected Steps per Second: 21,102.76546
Overall Steps per Second: 10,193.39535

Timestep Collection Time: 2.37050
Timestep Consumption Time: 2.53700
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.90749

Cumulative Model Updates: 113,858
Cumulative Timesteps: 949,469,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,564.87884
Policy Entropy: 3.73789
Value Function Loss: 0.02450

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.50186
Value Function Update Magnitude: 0.51648

Collected Steps per Second: 19,519.73612
Overall Steps per Second: 9,639.77815

Timestep Collection Time: 2.56212
Timestep Consumption Time: 2.62596
PPO Batch Consumption Time: 0.30586
Total Iteration Time: 5.18809

Cumulative Model Updates: 113,864
Cumulative Timesteps: 949,519,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 949519910...
Checkpoint 949519910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,570.81924
Policy Entropy: 3.72448
Value Function Loss: 0.03026

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.44515
Value Function Update Magnitude: 0.44182

Collected Steps per Second: 20,275.52211
Overall Steps per Second: 9,874.55299

Timestep Collection Time: 2.46761
Timestep Consumption Time: 2.59916
PPO Batch Consumption Time: 0.30411
Total Iteration Time: 5.06676

Cumulative Model Updates: 113,870
Cumulative Timesteps: 949,569,942

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,688.17486
Policy Entropy: 3.73355
Value Function Loss: 0.02833

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.44148
Value Function Update Magnitude: 0.36441

Collected Steps per Second: 20,370.43992
Overall Steps per Second: 10,009.23184

Timestep Collection Time: 2.45493
Timestep Consumption Time: 2.54126
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.99619

Cumulative Model Updates: 113,876
Cumulative Timesteps: 949,619,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 949619950...
Checkpoint 949619950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.72501
Value Function Loss: 0.03239

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.48061
Value Function Update Magnitude: 0.45881

Collected Steps per Second: 19,773.26889
Overall Steps per Second: 9,923.89184

Timestep Collection Time: 2.53069
Timestep Consumption Time: 2.51169
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 5.04238

Cumulative Model Updates: 113,882
Cumulative Timesteps: 949,669,990

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.72349
Value Function Loss: 0.03176

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.51908

Collected Steps per Second: 20,173.42906
Overall Steps per Second: 10,138.22098

Timestep Collection Time: 2.47940
Timestep Consumption Time: 2.45421
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.93361

Cumulative Model Updates: 113,888
Cumulative Timesteps: 949,720,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949720008...
Checkpoint 949720008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.72207
Value Function Loss: 0.02874

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.50307

Collected Steps per Second: 20,599.99960
Overall Steps per Second: 10,220.18696

Timestep Collection Time: 2.42728
Timestep Consumption Time: 2.46519
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.89247

Cumulative Model Updates: 113,894
Cumulative Timesteps: 949,770,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71259
Value Function Loss: 0.02637

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.54148
Value Function Update Magnitude: 0.44929

Collected Steps per Second: 19,835.24509
Overall Steps per Second: 10,029.33527

Timestep Collection Time: 2.52167
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.98717

Cumulative Model Updates: 113,900
Cumulative Timesteps: 949,820,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949820028...
Checkpoint 949820028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71956
Value Function Loss: 0.02446

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.50709
Value Function Update Magnitude: 0.38512

Collected Steps per Second: 20,464.13375
Overall Steps per Second: 10,244.19579

Timestep Collection Time: 2.44477
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.88374

Cumulative Model Updates: 113,906
Cumulative Timesteps: 949,870,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.72090
Value Function Loss: 0.02562

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.47220
Value Function Update Magnitude: 0.32296

Collected Steps per Second: 21,846.42940
Overall Steps per Second: 10,391.52222

Timestep Collection Time: 2.28999
Timestep Consumption Time: 2.52432
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.81431

Cumulative Model Updates: 113,912
Cumulative Timesteps: 949,920,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 949920086...
Checkpoint 949920086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71877
Value Function Loss: 0.02373

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.48466
Value Function Update Magnitude: 0.34475

Collected Steps per Second: 20,947.37609
Overall Steps per Second: 10,148.44104

Timestep Collection Time: 2.38693
Timestep Consumption Time: 2.53993
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.92687

Cumulative Model Updates: 113,918
Cumulative Timesteps: 949,970,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71463
Value Function Loss: 0.02483

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13957
Policy Update Magnitude: 0.48226
Value Function Update Magnitude: 0.40660

Collected Steps per Second: 21,256.46182
Overall Steps per Second: 10,144.63950

Timestep Collection Time: 2.35307
Timestep Consumption Time: 2.57741
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.93049

Cumulative Model Updates: 113,924
Cumulative Timesteps: 950,020,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 950020104...
Checkpoint 950020104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71057
Value Function Loss: 0.02307

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.52784
Value Function Update Magnitude: 0.48588

Collected Steps per Second: 21,326.52322
Overall Steps per Second: 10,198.17331

Timestep Collection Time: 2.34506
Timestep Consumption Time: 2.55895
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.90402

Cumulative Model Updates: 113,930
Cumulative Timesteps: 950,070,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.72976
Value Function Loss: 0.02287

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.56096

Collected Steps per Second: 21,940.00431
Overall Steps per Second: 10,476.59896

Timestep Collection Time: 2.27985
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.77445

Cumulative Model Updates: 113,936
Cumulative Timesteps: 950,120,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950120136...
Checkpoint 950120136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.73319
Value Function Loss: 0.02019

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.52134
Value Function Update Magnitude: 0.51311

Collected Steps per Second: 20,990.13215
Overall Steps per Second: 10,262.70836

Timestep Collection Time: 2.38436
Timestep Consumption Time: 2.49233
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.87669

Cumulative Model Updates: 113,942
Cumulative Timesteps: 950,170,184

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.74409
Value Function Loss: 0.01706

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.46239
Value Function Update Magnitude: 0.43072

Collected Steps per Second: 21,981.01684
Overall Steps per Second: 10,445.45168

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.51319
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.78888

Cumulative Model Updates: 113,948
Cumulative Timesteps: 950,220,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 950220206...
Checkpoint 950220206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71257
Value Function Loss: 0.01763

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.41554
Value Function Update Magnitude: 0.37158

Collected Steps per Second: 18,339.28752
Overall Steps per Second: 9,431.76535

Timestep Collection Time: 2.72900
Timestep Consumption Time: 2.57732
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 5.30632

Cumulative Model Updates: 113,954
Cumulative Timesteps: 950,270,254

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.71574
Value Function Loss: 0.01830

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.42434
Value Function Update Magnitude: 0.37642

Collected Steps per Second: 18,883.11655
Overall Steps per Second: 9,980.31336

Timestep Collection Time: 2.64861
Timestep Consumption Time: 2.36266
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 5.01127

Cumulative Model Updates: 113,960
Cumulative Timesteps: 950,320,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 950320268...
Checkpoint 950320268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,509.47066
Policy Entropy: 3.70180
Value Function Loss: 0.02192

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.45963
Value Function Update Magnitude: 0.41239

Collected Steps per Second: 20,068.43642
Overall Steps per Second: 10,192.89359

Timestep Collection Time: 2.49347
Timestep Consumption Time: 2.41583
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.90930

Cumulative Model Updates: 113,966
Cumulative Timesteps: 950,370,308

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.73153
Value Function Loss: 0.02307

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.47611
Value Function Update Magnitude: 0.43348

Collected Steps per Second: 20,003.97584
Overall Steps per Second: 10,001.45337

Timestep Collection Time: 2.50060
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 5.00147

Cumulative Model Updates: 113,972
Cumulative Timesteps: 950,420,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 950420330...
Checkpoint 950420330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.71798
Value Function Loss: 0.02426

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.46307
Value Function Update Magnitude: 0.45182

Collected Steps per Second: 21,234.41498
Overall Steps per Second: 10,179.36402

Timestep Collection Time: 2.35552
Timestep Consumption Time: 2.55815
PPO Batch Consumption Time: 0.29876
Total Iteration Time: 4.91367

Cumulative Model Updates: 113,978
Cumulative Timesteps: 950,470,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.71302
Value Function Loss: 0.02253

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.48910
Value Function Update Magnitude: 0.61055

Collected Steps per Second: 20,787.39252
Overall Steps per Second: 10,030.29301

Timestep Collection Time: 2.40627
Timestep Consumption Time: 2.58063
PPO Batch Consumption Time: 0.30510
Total Iteration Time: 4.98689

Cumulative Model Updates: 113,984
Cumulative Timesteps: 950,520,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950520368...
Checkpoint 950520368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.69501
Value Function Loss: 0.02288

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.50317
Value Function Update Magnitude: 0.64774

Collected Steps per Second: 20,019.88139
Overall Steps per Second: 9,938.50360

Timestep Collection Time: 2.49842
Timestep Consumption Time: 2.53433
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 5.03275

Cumulative Model Updates: 113,990
Cumulative Timesteps: 950,570,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.70165
Value Function Loss: 0.02335

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.49245
Value Function Update Magnitude: 0.61684

Collected Steps per Second: 20,320.26397
Overall Steps per Second: 9,997.40410

Timestep Collection Time: 2.46119
Timestep Consumption Time: 2.54131
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 5.00250

Cumulative Model Updates: 113,996
Cumulative Timesteps: 950,620,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 950620398...
Checkpoint 950620398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,512.96898
Policy Entropy: 3.70598
Value Function Loss: 0.02234

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.47349
Value Function Update Magnitude: 0.54439

Collected Steps per Second: 20,581.54005
Overall Steps per Second: 10,018.89252

Timestep Collection Time: 2.42956
Timestep Consumption Time: 2.56142
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.99097

Cumulative Model Updates: 114,002
Cumulative Timesteps: 950,670,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,940.10695
Policy Entropy: 3.72042
Value Function Loss: 0.02285

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.46190
Value Function Update Magnitude: 0.49311

Collected Steps per Second: 20,774.22332
Overall Steps per Second: 10,230.03824

Timestep Collection Time: 2.40808
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.89011

Cumulative Model Updates: 114,008
Cumulative Timesteps: 950,720,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 950720428...
Checkpoint 950720428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,940.10695
Policy Entropy: 3.72215
Value Function Loss: 0.02105

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.46869
Value Function Update Magnitude: 0.49097

Collected Steps per Second: 21,388.13448
Overall Steps per Second: 10,309.94895

Timestep Collection Time: 2.33877
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.85182

Cumulative Model Updates: 114,014
Cumulative Timesteps: 950,770,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,940.10695
Policy Entropy: 3.70617
Value Function Loss: 0.02293

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.46736
Value Function Update Magnitude: 0.52204

Collected Steps per Second: 20,596.90421
Overall Steps per Second: 10,085.11600

Timestep Collection Time: 2.42852
Timestep Consumption Time: 2.53126
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.95978

Cumulative Model Updates: 114,020
Cumulative Timesteps: 950,820,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950820470...
Checkpoint 950820470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 444,940.10695
Policy Entropy: 3.68686
Value Function Loss: 0.02423

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.48655
Value Function Update Magnitude: 0.50804

Collected Steps per Second: 20,676.44636
Overall Steps per Second: 9,842.59214

Timestep Collection Time: 2.41850
Timestep Consumption Time: 2.66207
PPO Batch Consumption Time: 0.31135
Total Iteration Time: 5.08057

Cumulative Model Updates: 114,026
Cumulative Timesteps: 950,870,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,389.26381
Policy Entropy: 3.68033
Value Function Loss: 0.02759

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.50444
Value Function Update Magnitude: 0.46731

Collected Steps per Second: 20,339.85728
Overall Steps per Second: 10,052.17574

Timestep Collection Time: 2.45833
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.97425

Cumulative Model Updates: 114,032
Cumulative Timesteps: 950,920,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 950920478...
Checkpoint 950920478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,745.21364
Policy Entropy: 3.69843
Value Function Loss: 0.02627

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.48050

Collected Steps per Second: 20,654.18232
Overall Steps per Second: 10,107.93856

Timestep Collection Time: 2.42227
Timestep Consumption Time: 2.52731
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.94957

Cumulative Model Updates: 114,038
Cumulative Timesteps: 950,970,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.71373
Value Function Loss: 0.02596

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.52376

Collected Steps per Second: 21,581.13626
Overall Steps per Second: 10,353.71351

Timestep Collection Time: 2.31739
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.83034

Cumulative Model Updates: 114,044
Cumulative Timesteps: 951,020,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 951020520...
Checkpoint 951020520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.71956
Value Function Loss: 0.02335

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.55890

Collected Steps per Second: 20,132.70472
Overall Steps per Second: 9,987.55200

Timestep Collection Time: 2.48461
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 5.00843

Cumulative Model Updates: 114,050
Cumulative Timesteps: 951,070,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.70996
Value Function Loss: 0.02544

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.49471

Collected Steps per Second: 21,720.85695
Overall Steps per Second: 10,242.86116

Timestep Collection Time: 2.30341
Timestep Consumption Time: 2.58116
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.88457

Cumulative Model Updates: 114,056
Cumulative Timesteps: 951,120,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 951120574...
Checkpoint 951120574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.70843
Value Function Loss: 0.02420

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.52531
Value Function Update Magnitude: 0.40179

Collected Steps per Second: 20,504.94808
Overall Steps per Second: 9,803.83142

Timestep Collection Time: 2.43863
Timestep Consumption Time: 2.66182
PPO Batch Consumption Time: 0.31426
Total Iteration Time: 5.10045

Cumulative Model Updates: 114,062
Cumulative Timesteps: 951,170,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.69550
Value Function Loss: 0.02644

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.35645

Collected Steps per Second: 20,032.49092
Overall Steps per Second: 9,644.52595

Timestep Collection Time: 2.49694
Timestep Consumption Time: 2.68942
PPO Batch Consumption Time: 0.31619
Total Iteration Time: 5.18636

Cumulative Model Updates: 114,068
Cumulative Timesteps: 951,220,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 951220598...
Checkpoint 951220598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,640.90052
Policy Entropy: 3.70496
Value Function Loss: 0.02554

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.50448
Value Function Update Magnitude: 0.37789

Collected Steps per Second: 19,262.97570
Overall Steps per Second: 9,530.52313

Timestep Collection Time: 2.59659
Timestep Consumption Time: 2.65160
PPO Batch Consumption Time: 0.30914
Total Iteration Time: 5.24819

Cumulative Model Updates: 114,074
Cumulative Timesteps: 951,270,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,514.61316
Policy Entropy: 3.70667
Value Function Loss: 0.02514

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.50823
Value Function Update Magnitude: 0.49942

Collected Steps per Second: 19,785.51267
Overall Steps per Second: 9,883.42390

Timestep Collection Time: 2.52751
Timestep Consumption Time: 2.53228
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 5.05979

Cumulative Model Updates: 114,080
Cumulative Timesteps: 951,320,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 951320624...
Checkpoint 951320624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,281.98897
Policy Entropy: 3.72983
Value Function Loss: 0.02353

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.49349

Collected Steps per Second: 19,559.21949
Overall Steps per Second: 9,612.61326

Timestep Collection Time: 2.55705
Timestep Consumption Time: 2.64590
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 5.20296

Cumulative Model Updates: 114,086
Cumulative Timesteps: 951,370,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,281.98897
Policy Entropy: 3.71786
Value Function Loss: 0.02303

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.53704

Collected Steps per Second: 18,759.19513
Overall Steps per Second: 9,673.04101

Timestep Collection Time: 2.66717
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 5.17252

Cumulative Model Updates: 114,092
Cumulative Timesteps: 951,420,672

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 951420672...
Checkpoint 951420672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,281.98897
Policy Entropy: 3.72027
Value Function Loss: 0.01912

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.54106

Collected Steps per Second: 19,762.06477
Overall Steps per Second: 9,897.69871

Timestep Collection Time: 2.53020
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.30310
Total Iteration Time: 5.05188

Cumulative Model Updates: 114,098
Cumulative Timesteps: 951,470,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,281.98897
Policy Entropy: 3.71894
Value Function Loss: 0.01758

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.46894
Value Function Update Magnitude: 0.56016

Collected Steps per Second: 19,226.32887
Overall Steps per Second: 9,928.67111

Timestep Collection Time: 2.60070
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 5.03612

Cumulative Model Updates: 114,104
Cumulative Timesteps: 951,520,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 951520676...
Checkpoint 951520676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,281.98897
Policy Entropy: 3.72966
Value Function Loss: 0.01691

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.43876
Value Function Update Magnitude: 0.53343

Collected Steps per Second: 19,250.77902
Overall Steps per Second: 9,936.55677

Timestep Collection Time: 2.59844
Timestep Consumption Time: 2.43570
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 5.03414

Cumulative Model Updates: 114,110
Cumulative Timesteps: 951,570,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,445.82585
Policy Entropy: 3.72520
Value Function Loss: 0.01986

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.46127
Value Function Update Magnitude: 0.55197

Collected Steps per Second: 21,498.16602
Overall Steps per Second: 10,359.75030

Timestep Collection Time: 2.32671
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.82830

Cumulative Model Updates: 114,116
Cumulative Timesteps: 951,620,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 951620718...
Checkpoint 951620718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,567.01653
Policy Entropy: 3.72919
Value Function Loss: 0.01936

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.68127

Collected Steps per Second: 21,275.21765
Overall Steps per Second: 10,488.28979

Timestep Collection Time: 2.35137
Timestep Consumption Time: 2.41833
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.76970

Cumulative Model Updates: 114,122
Cumulative Timesteps: 951,670,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307,533.20459
Policy Entropy: 3.74423
Value Function Loss: 0.01952

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.83519

Collected Steps per Second: 22,041.09165
Overall Steps per Second: 10,363.55443

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.55642
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.82518

Cumulative Model Updates: 114,128
Cumulative Timesteps: 951,720,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 951720750...
Checkpoint 951720750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831,615.83161
Policy Entropy: 3.72868
Value Function Loss: 0.02071

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.55954
Value Function Update Magnitude: 0.78697

Collected Steps per Second: 20,793.18218
Overall Steps per Second: 10,339.57201

Timestep Collection Time: 2.40492
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.83637

Cumulative Model Updates: 114,134
Cumulative Timesteps: 951,770,756

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,616.15759
Policy Entropy: 3.72971
Value Function Loss: 0.01972

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.75501

Collected Steps per Second: 21,986.84913
Overall Steps per Second: 10,395.61545

Timestep Collection Time: 2.27445
Timestep Consumption Time: 2.53604
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.81049

Cumulative Model Updates: 114,140
Cumulative Timesteps: 951,820,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 951820764...
Checkpoint 951820764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,616.15759
Policy Entropy: 3.73022
Value Function Loss: 0.01981

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.53146
Value Function Update Magnitude: 0.70463

Collected Steps per Second: 18,273.60439
Overall Steps per Second: 9,562.24116

Timestep Collection Time: 2.73695
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 5.23036

Cumulative Model Updates: 114,146
Cumulative Timesteps: 951,870,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,616.15759
Policy Entropy: 3.73346
Value Function Loss: 0.01957

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.52268
Value Function Update Magnitude: 0.59752

Collected Steps per Second: 21,438.84970
Overall Steps per Second: 9,913.81164

Timestep Collection Time: 2.33287
Timestep Consumption Time: 2.71201
PPO Batch Consumption Time: 0.31168
Total Iteration Time: 5.04488

Cumulative Model Updates: 114,152
Cumulative Timesteps: 951,920,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 951920792...
Checkpoint 951920792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,616.15759
Policy Entropy: 3.71906
Value Function Loss: 0.02056

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.49080
Value Function Update Magnitude: 0.57878

Collected Steps per Second: 19,480.90399
Overall Steps per Second: 9,882.96905

Timestep Collection Time: 2.56692
Timestep Consumption Time: 2.49289
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 5.05982

Cumulative Model Updates: 114,158
Cumulative Timesteps: 951,970,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907,497.24858
Policy Entropy: 3.71585
Value Function Loss: 0.02124

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.47570
Value Function Update Magnitude: 0.55844

Collected Steps per Second: 21,025.63102
Overall Steps per Second: 10,422.89205

Timestep Collection Time: 2.37843
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.79790

Cumulative Model Updates: 114,164
Cumulative Timesteps: 952,020,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 952020806...
Checkpoint 952020806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,647.12739
Policy Entropy: 3.73261
Value Function Loss: 0.01962

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.48355
Value Function Update Magnitude: 0.58576

Collected Steps per Second: 21,100.67804
Overall Steps per Second: 10,323.36836

Timestep Collection Time: 2.36959
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.84338

Cumulative Model Updates: 114,170
Cumulative Timesteps: 952,070,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,647.12739
Policy Entropy: 3.72573
Value Function Loss: 0.01924

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.47426
Value Function Update Magnitude: 0.61670

Collected Steps per Second: 21,620.90842
Overall Steps per Second: 10,405.44947

Timestep Collection Time: 2.31313
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.80633

Cumulative Model Updates: 114,176
Cumulative Timesteps: 952,120,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 952120818...
Checkpoint 952120818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 518,469.84541
Policy Entropy: 3.72822
Value Function Loss: 0.01860

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.47408
Value Function Update Magnitude: 0.53137

Collected Steps per Second: 21,662.58781
Overall Steps per Second: 10,342.69570

Timestep Collection Time: 2.30951
Timestep Consumption Time: 2.52772
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.83723

Cumulative Model Updates: 114,182
Cumulative Timesteps: 952,170,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688,068.07204
Policy Entropy: 3.70527
Value Function Loss: 0.02162

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.48623
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 22,121.05091
Overall Steps per Second: 10,386.39080

Timestep Collection Time: 2.26228
Timestep Consumption Time: 2.55595
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.81823

Cumulative Model Updates: 114,188
Cumulative Timesteps: 952,220,892

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 952220892...
Checkpoint 952220892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533,455.85533
Policy Entropy: 3.72435
Value Function Loss: 0.02098

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.79416

Collected Steps per Second: 21,211.59433
Overall Steps per Second: 10,145.37656

Timestep Collection Time: 2.35805
Timestep Consumption Time: 2.57208
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.93013

Cumulative Model Updates: 114,194
Cumulative Timesteps: 952,270,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022,171.11015
Policy Entropy: 3.71292
Value Function Loss: 0.02244

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.96517

Collected Steps per Second: 21,697.51682
Overall Steps per Second: 10,330.01842

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.53656
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.84162

Cumulative Model Updates: 114,200
Cumulative Timesteps: 952,320,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 952320924...
Checkpoint 952320924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827,965.48987
Policy Entropy: 3.72288
Value Function Loss: 0.01936

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.53591
Value Function Update Magnitude: 0.87804

Collected Steps per Second: 20,619.92739
Overall Steps per Second: 10,054.89086

Timestep Collection Time: 2.42484
Timestep Consumption Time: 2.54787
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.97270

Cumulative Model Updates: 114,206
Cumulative Timesteps: 952,370,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,944.90645
Policy Entropy: 3.71670
Value Function Loss: 0.02267

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.54045
Value Function Update Magnitude: 0.84464

Collected Steps per Second: 21,191.56865
Overall Steps per Second: 9,897.54844

Timestep Collection Time: 2.35952
Timestep Consumption Time: 2.69243
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 5.05196

Cumulative Model Updates: 114,212
Cumulative Timesteps: 952,420,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 952420926...
Checkpoint 952420926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562,944.90645
Policy Entropy: 3.71611
Value Function Loss: 0.02407

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.78682

Collected Steps per Second: 20,406.44503
Overall Steps per Second: 9,847.02355

Timestep Collection Time: 2.45030
Timestep Consumption Time: 2.62758
PPO Batch Consumption Time: 0.31067
Total Iteration Time: 5.07788

Cumulative Model Updates: 114,218
Cumulative Timesteps: 952,470,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,497.19380
Policy Entropy: 3.72505
Value Function Loss: 0.02902

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.66561

Collected Steps per Second: 20,799.77212
Overall Steps per Second: 10,091.12526

Timestep Collection Time: 2.40406
Timestep Consumption Time: 2.55118
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.95525

Cumulative Model Updates: 114,224
Cumulative Timesteps: 952,520,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 952520932...
Checkpoint 952520932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,411.36817
Policy Entropy: 3.72253
Value Function Loss: 0.02828

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.76087

Collected Steps per Second: 18,366.98012
Overall Steps per Second: 9,967.60707

Timestep Collection Time: 2.72337
Timestep Consumption Time: 2.29489
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 5.01826

Cumulative Model Updates: 114,230
Cumulative Timesteps: 952,570,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,583.14242
Policy Entropy: 3.73474
Value Function Loss: 0.03344

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.60242
Value Function Update Magnitude: 0.76162

Collected Steps per Second: 19,443.61468
Overall Steps per Second: 9,875.49757

Timestep Collection Time: 2.57236
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 5.06466

Cumulative Model Updates: 114,236
Cumulative Timesteps: 952,620,968

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 952620968...
Checkpoint 952620968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,823.55976
Policy Entropy: 3.73272
Value Function Loss: 0.03379

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.63714
Value Function Update Magnitude: 0.68844

Collected Steps per Second: 20,565.94097
Overall Steps per Second: 10,156.31214

Timestep Collection Time: 2.43120
Timestep Consumption Time: 2.49184
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.92305

Cumulative Model Updates: 114,242
Cumulative Timesteps: 952,670,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,226.85204
Policy Entropy: 3.72928
Value Function Loss: 0.03363

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.67029
Value Function Update Magnitude: 0.77380

Collected Steps per Second: 20,881.37292
Overall Steps per Second: 9,982.87729

Timestep Collection Time: 2.39572
Timestep Consumption Time: 2.61546
PPO Batch Consumption Time: 0.31298
Total Iteration Time: 5.01118

Cumulative Model Updates: 114,248
Cumulative Timesteps: 952,720,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 952720994...
Checkpoint 952720994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,715.80009
Policy Entropy: 3.72223
Value Function Loss: 0.02968

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.65367
Value Function Update Magnitude: 0.92201

Collected Steps per Second: 21,338.54662
Overall Steps per Second: 10,254.37422

Timestep Collection Time: 2.34355
Timestep Consumption Time: 2.53320
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.87675

Cumulative Model Updates: 114,254
Cumulative Timesteps: 952,771,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,118.64997
Policy Entropy: 3.72229
Value Function Loss: 0.02678

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.60814
Value Function Update Magnitude: 0.84738

Collected Steps per Second: 18,338.40847
Overall Steps per Second: 9,574.64018

Timestep Collection Time: 2.72695
Timestep Consumption Time: 2.49601
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 5.22296

Cumulative Model Updates: 114,260
Cumulative Timesteps: 952,821,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 952821010...
Checkpoint 952821010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,648.17662
Policy Entropy: 3.71215
Value Function Loss: 0.02892

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.57548
Value Function Update Magnitude: 0.68806

Collected Steps per Second: 18,402.23818
Overall Steps per Second: 9,487.43884

Timestep Collection Time: 2.71706
Timestep Consumption Time: 2.55307
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 5.27013

Cumulative Model Updates: 114,266
Cumulative Timesteps: 952,871,010

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,936.33899
Policy Entropy: 3.71816
Value Function Loss: 0.02969

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.56768
Value Function Update Magnitude: 0.55867

Collected Steps per Second: 18,681.07585
Overall Steps per Second: 9,643.05782

Timestep Collection Time: 2.67725
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 5.18653

Cumulative Model Updates: 114,272
Cumulative Timesteps: 952,921,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 952921024...
Checkpoint 952921024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 478,647.27317
Policy Entropy: 3.71148
Value Function Loss: 0.02965

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.53299

Collected Steps per Second: 18,393.66932
Overall Steps per Second: 9,522.28820

Timestep Collection Time: 2.71876
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 5.25168

Cumulative Model Updates: 114,278
Cumulative Timesteps: 952,971,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.72536
Value Function Loss: 0.02576

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.48610

Collected Steps per Second: 18,091.47784
Overall Steps per Second: 9,157.36533

Timestep Collection Time: 2.76506
Timestep Consumption Time: 2.69765
PPO Batch Consumption Time: 0.30651
Total Iteration Time: 5.46271

Cumulative Model Updates: 114,284
Cumulative Timesteps: 953,021,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 953021056...
Checkpoint 953021056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.73952
Value Function Loss: 0.02449

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.47058
Value Function Update Magnitude: 0.42158

Collected Steps per Second: 18,184.94664
Overall Steps per Second: 9,342.48107

Timestep Collection Time: 2.75129
Timestep Consumption Time: 2.60404
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 5.35532

Cumulative Model Updates: 114,290
Cumulative Timesteps: 953,071,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.73256
Value Function Loss: 0.02081

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14624
Policy Update Magnitude: 0.45188
Value Function Update Magnitude: 0.50756

Collected Steps per Second: 17,832.37051
Overall Steps per Second: 9,085.15596

Timestep Collection Time: 2.80490
Timestep Consumption Time: 2.70057
PPO Batch Consumption Time: 0.31173
Total Iteration Time: 5.50546

Cumulative Model Updates: 114,296
Cumulative Timesteps: 953,121,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 953121106...
Checkpoint 953121106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.71661
Value Function Loss: 0.02380

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.63739

Collected Steps per Second: 16,526.06686
Overall Steps per Second: 9,095.89989

Timestep Collection Time: 3.02564
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 5.49720

Cumulative Model Updates: 114,302
Cumulative Timesteps: 953,171,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.70302
Value Function Loss: 0.02522

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17333
Policy Update Magnitude: 0.61301
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 16,401.54968
Overall Steps per Second: 8,898.43227

Timestep Collection Time: 3.05118
Timestep Consumption Time: 2.57274
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 5.62391

Cumulative Model Updates: 114,308
Cumulative Timesteps: 953,221,152

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 953221152...
Checkpoint 953221152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.71358
Value Function Loss: 0.02429

Mean KL Divergence: 0.02660
SB3 Clip Fraction: 0.28056
Policy Update Magnitude: 0.59244
Value Function Update Magnitude: 0.59972

Collected Steps per Second: 16,710.19721
Overall Steps per Second: 9,115.36157

Timestep Collection Time: 2.99422
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 5.48898

Cumulative Model Updates: 114,314
Cumulative Timesteps: 953,271,186

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,384.73215
Policy Entropy: 3.74406
Value Function Loss: 0.02512

Mean KL Divergence: 0.02808
SB3 Clip Fraction: 0.27535
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.53524

Collected Steps per Second: 17,437.23916
Overall Steps per Second: 9,111.23098

Timestep Collection Time: 2.86766
Timestep Consumption Time: 2.62052
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 5.48817

Cumulative Model Updates: 114,320
Cumulative Timesteps: 953,321,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 953321190...
Checkpoint 953321190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,016.29250
Policy Entropy: 3.78008
Value Function Loss: 0.02989

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.22220
Policy Update Magnitude: 0.61537
Value Function Update Magnitude: 0.42581

Collected Steps per Second: 17,625.55583
Overall Steps per Second: 9,235.22335

Timestep Collection Time: 2.83747
Timestep Consumption Time: 2.57788
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 5.41535

Cumulative Model Updates: 114,326
Cumulative Timesteps: 953,371,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,016.29250
Policy Entropy: 3.80232
Value Function Loss: 0.03962

Mean KL Divergence: 0.02202
SB3 Clip Fraction: 0.22318
Policy Update Magnitude: 0.66678
Value Function Update Magnitude: 0.35682

Collected Steps per Second: 17,828.72768
Overall Steps per Second: 9,131.47112

Timestep Collection Time: 2.80603
Timestep Consumption Time: 2.67260
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 5.47864

Cumulative Model Updates: 114,332
Cumulative Timesteps: 953,421,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 953421230...
Checkpoint 953421230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,688.09154
Policy Entropy: 3.82155
Value Function Loss: 0.03630

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.68434
Value Function Update Magnitude: 0.31139

Collected Steps per Second: 16,904.92428
Overall Steps per Second: 8,956.03238

Timestep Collection Time: 2.95949
Timestep Consumption Time: 2.62669
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 5.58618

Cumulative Model Updates: 114,338
Cumulative Timesteps: 953,471,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,916.42018
Policy Entropy: 3.82647
Value Function Loss: 0.04155

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.76384
Value Function Update Magnitude: 0.42399

Collected Steps per Second: 17,550.13466
Overall Steps per Second: 8,960.72612

Timestep Collection Time: 2.85035
Timestep Consumption Time: 2.73223
PPO Batch Consumption Time: 0.31359
Total Iteration Time: 5.58258

Cumulative Model Updates: 114,344
Cumulative Timesteps: 953,521,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 953521284...
Checkpoint 953521284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,458.82444
Policy Entropy: 3.82458
Value Function Loss: 0.03404

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.79959
Value Function Update Magnitude: 0.37227

Collected Steps per Second: 16,689.71449
Overall Steps per Second: 8,658.22893

Timestep Collection Time: 2.99753
Timestep Consumption Time: 2.78055
PPO Batch Consumption Time: 0.32028
Total Iteration Time: 5.77809

Cumulative Model Updates: 114,350
Cumulative Timesteps: 953,571,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,995.93840
Policy Entropy: 3.83294
Value Function Loss: 0.02903

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.76955
Value Function Update Magnitude: 0.44265

Collected Steps per Second: 18,935.89453
Overall Steps per Second: 9,781.70762

Timestep Collection Time: 2.64059
Timestep Consumption Time: 2.47119
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 5.11179

Cumulative Model Updates: 114,356
Cumulative Timesteps: 953,621,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 953621314...
Checkpoint 953621314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,743.91177
Policy Entropy: 3.83716
Value Function Loss: 0.02733

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.79415
Value Function Update Magnitude: 0.55127

Collected Steps per Second: 20,871.63863
Overall Steps per Second: 10,227.64058

Timestep Collection Time: 2.39588
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.88930

Cumulative Model Updates: 114,362
Cumulative Timesteps: 953,671,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229,046.27249
Policy Entropy: 3.79499
Value Function Loss: 0.02727

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.82411
Value Function Update Magnitude: 0.67362

Collected Steps per Second: 18,581.26291
Overall Steps per Second: 9,665.61417

Timestep Collection Time: 2.69131
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 5.17380

Cumulative Model Updates: 114,368
Cumulative Timesteps: 953,721,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 953721328...
Checkpoint 953721328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,472.12831
Policy Entropy: 3.78424
Value Function Loss: 0.02921

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.85058
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 19,732.41912
Overall Steps per Second: 9,759.73617

Timestep Collection Time: 2.53431
Timestep Consumption Time: 2.58960
PPO Batch Consumption Time: 0.30117
Total Iteration Time: 5.12391

Cumulative Model Updates: 114,374
Cumulative Timesteps: 953,771,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,040.97361
Policy Entropy: 3.77966
Value Function Loss: 0.02822

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06696
Policy Update Magnitude: 0.84304
Value Function Update Magnitude: 0.57117

Collected Steps per Second: 18,478.84646
Overall Steps per Second: 9,549.99666

Timestep Collection Time: 2.70612
Timestep Consumption Time: 2.53011
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.23623

Cumulative Model Updates: 114,380
Cumulative Timesteps: 953,821,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 953821342...
Checkpoint 953821342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891,843.77791
Policy Entropy: 3.78219
Value Function Loss: 0.03008

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.82542
Value Function Update Magnitude: 0.68034

Collected Steps per Second: 20,266.85120
Overall Steps per Second: 9,995.74821

Timestep Collection Time: 2.46708
Timestep Consumption Time: 2.53504
PPO Batch Consumption Time: 0.30631
Total Iteration Time: 5.00213

Cumulative Model Updates: 114,386
Cumulative Timesteps: 953,871,342

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,398.64419
Policy Entropy: 3.77606
Value Function Loss: 0.02918

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.79354
Value Function Update Magnitude: 0.76962

Collected Steps per Second: 20,675.29511
Overall Steps per Second: 9,881.77893

Timestep Collection Time: 2.41844
Timestep Consumption Time: 2.64158
PPO Batch Consumption Time: 0.31539
Total Iteration Time: 5.06002

Cumulative Model Updates: 114,392
Cumulative Timesteps: 953,921,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 953921344...
Checkpoint 953921344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,398.64419
Policy Entropy: 3.75752
Value Function Loss: 0.02546

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.75590
Value Function Update Magnitude: 0.83596

Collected Steps per Second: 20,849.30313
Overall Steps per Second: 10,369.72864

Timestep Collection Time: 2.39893
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.82327

Cumulative Model Updates: 114,398
Cumulative Timesteps: 953,971,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298,469.96258
Policy Entropy: 3.75447
Value Function Loss: 0.02316

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07138
Policy Update Magnitude: 0.70470
Value Function Update Magnitude: 0.71479

Collected Steps per Second: 19,807.24251
Overall Steps per Second: 9,835.30002

Timestep Collection Time: 2.52534
Timestep Consumption Time: 2.56042
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 5.08576

Cumulative Model Updates: 114,404
Cumulative Timesteps: 954,021,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 954021380...
Checkpoint 954021380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.75353
Value Function Loss: 0.02035

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05205
Policy Update Magnitude: 0.68023
Value Function Update Magnitude: 0.61104

Collected Steps per Second: 17,990.32047
Overall Steps per Second: 9,199.85955

Timestep Collection Time: 2.78094
Timestep Consumption Time: 2.65719
PPO Batch Consumption Time: 0.30974
Total Iteration Time: 5.43813

Cumulative Model Updates: 114,410
Cumulative Timesteps: 954,071,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.75434
Value Function Loss: 0.01993

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07390
Policy Update Magnitude: 0.64639
Value Function Update Magnitude: 0.56163

Collected Steps per Second: 20,609.34983
Overall Steps per Second: 10,175.56119

Timestep Collection Time: 2.42647
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.91452

Cumulative Model Updates: 114,416
Cumulative Timesteps: 954,121,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 954121418...
Checkpoint 954121418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.76686
Value Function Loss: 0.01647

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06236
Policy Update Magnitude: 0.58920
Value Function Update Magnitude: 0.48706

Collected Steps per Second: 21,680.27365
Overall Steps per Second: 10,305.77699

Timestep Collection Time: 2.30726
Timestep Consumption Time: 2.54652
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.85378

Cumulative Model Updates: 114,422
Cumulative Timesteps: 954,171,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.76788
Value Function Loss: 0.01390

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.53251

Collected Steps per Second: 20,054.11138
Overall Steps per Second: 9,895.61333

Timestep Collection Time: 2.49415
Timestep Consumption Time: 2.56041
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 5.05456

Cumulative Model Updates: 114,428
Cumulative Timesteps: 954,221,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 954221458...
Checkpoint 954221458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.76980
Value Function Loss: 0.01225

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.52951
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 20,086.47124
Overall Steps per Second: 9,869.98541

Timestep Collection Time: 2.49063
Timestep Consumption Time: 2.57807
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 5.06870

Cumulative Model Updates: 114,434
Cumulative Timesteps: 954,271,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.75488
Value Function Loss: 0.01274

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06876
Policy Update Magnitude: 0.52935
Value Function Update Magnitude: 0.60171

Collected Steps per Second: 20,531.43329
Overall Steps per Second: 10,089.33764

Timestep Collection Time: 2.43626
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.95771

Cumulative Model Updates: 114,440
Cumulative Timesteps: 954,321,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 954321506...
Checkpoint 954321506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,764.50449
Policy Entropy: 3.73738
Value Function Loss: 0.01348

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07547
Policy Update Magnitude: 0.52653
Value Function Update Magnitude: 0.54474

Collected Steps per Second: 20,566.50383
Overall Steps per Second: 10,115.35504

Timestep Collection Time: 2.43250
Timestep Consumption Time: 2.51325
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.94575

Cumulative Model Updates: 114,446
Cumulative Timesteps: 954,371,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280,566.21448
Policy Entropy: 3.74265
Value Function Loss: 0.02133

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.49103
Value Function Update Magnitude: 0.54698

Collected Steps per Second: 20,446.34315
Overall Steps per Second: 10,042.31320

Timestep Collection Time: 2.44621
Timestep Consumption Time: 2.53432
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.98053

Cumulative Model Updates: 114,452
Cumulative Timesteps: 954,421,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 954421550...
Checkpoint 954421550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,712.95024
Policy Entropy: 3.75631
Value Function Loss: 0.02723

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.19640
Policy Update Magnitude: 0.53783
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 20,777.76293
Overall Steps per Second: 10,166.33502

Timestep Collection Time: 2.40738
Timestep Consumption Time: 2.51278
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.92016

Cumulative Model Updates: 114,458
Cumulative Timesteps: 954,471,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,029.39701
Policy Entropy: 3.76051
Value Function Loss: 0.03181

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.20795
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.65722

Collected Steps per Second: 20,610.77254
Overall Steps per Second: 10,159.57214

Timestep Collection Time: 2.42708
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.92383

Cumulative Model Updates: 114,464
Cumulative Timesteps: 954,521,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 954521594...
Checkpoint 954521594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,029.39701
Policy Entropy: 3.75620
Value Function Loss: 0.02558

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.52378
Value Function Update Magnitude: 0.64498

Collected Steps per Second: 20,306.66753
Overall Steps per Second: 10,167.98887

Timestep Collection Time: 2.46382
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.92054

Cumulative Model Updates: 114,470
Cumulative Timesteps: 954,571,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,665.98778
Policy Entropy: 3.71133
Value Function Loss: 0.02448

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.45983
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 20,527.31790
Overall Steps per Second: 10,016.25714

Timestep Collection Time: 2.43666
Timestep Consumption Time: 2.55703
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.99368

Cumulative Model Updates: 114,476
Cumulative Timesteps: 954,621,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 954621644...
Checkpoint 954621644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,236.27823
Policy Entropy: 3.72240
Value Function Loss: 0.02222

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.45095
Value Function Update Magnitude: 0.49783

Collected Steps per Second: 20,899.09742
Overall Steps per Second: 10,114.86774

Timestep Collection Time: 2.39321
Timestep Consumption Time: 2.55159
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.94480

Cumulative Model Updates: 114,482
Cumulative Timesteps: 954,671,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,570.26688
Policy Entropy: 3.70491
Value Function Loss: 0.02896

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.48838
Value Function Update Magnitude: 0.45550

Collected Steps per Second: 19,500.58385
Overall Steps per Second: 9,695.47917

Timestep Collection Time: 2.56454
Timestep Consumption Time: 2.59354
PPO Batch Consumption Time: 0.30060
Total Iteration Time: 5.15807

Cumulative Model Updates: 114,488
Cumulative Timesteps: 954,721,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 954721670...
Checkpoint 954721670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,052.55071
Policy Entropy: 3.72982
Value Function Loss: 0.02741

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.50792

Collected Steps per Second: 20,837.94486
Overall Steps per Second: 9,989.68775

Timestep Collection Time: 2.40024
Timestep Consumption Time: 2.60653
PPO Batch Consumption Time: 0.30254
Total Iteration Time: 5.00676

Cumulative Model Updates: 114,494
Cumulative Timesteps: 954,771,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746,255.62358
Policy Entropy: 3.72418
Value Function Loss: 0.02750

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.68684

Collected Steps per Second: 20,988.63065
Overall Steps per Second: 10,014.88854

Timestep Collection Time: 2.38243
Timestep Consumption Time: 2.61053
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 4.99297

Cumulative Model Updates: 114,500
Cumulative Timesteps: 954,821,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 954821690...
Checkpoint 954821690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680,107.92664
Policy Entropy: 3.74160
Value Function Loss: 0.02312

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.53063
Value Function Update Magnitude: 0.72739

Collected Steps per Second: 20,314.65464
Overall Steps per Second: 9,918.35162

Timestep Collection Time: 2.46285
Timestep Consumption Time: 2.58153
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.04439

Cumulative Model Updates: 114,506
Cumulative Timesteps: 954,871,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,224.06191
Policy Entropy: 3.73306
Value Function Loss: 0.02075

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16123
Policy Update Magnitude: 0.49451
Value Function Update Magnitude: 0.57433

Collected Steps per Second: 20,220.73732
Overall Steps per Second: 9,958.45203

Timestep Collection Time: 2.47340
Timestep Consumption Time: 2.54887
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 5.02227

Cumulative Model Updates: 114,512
Cumulative Timesteps: 954,921,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 954921736...
Checkpoint 954921736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,224.06191
Policy Entropy: 3.73182
Value Function Loss: 0.02045

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.43873
Value Function Update Magnitude: 0.43042

Collected Steps per Second: 20,364.86424
Overall Steps per Second: 9,982.55289

Timestep Collection Time: 2.45521
Timestep Consumption Time: 2.55353
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 5.00874

Cumulative Model Updates: 114,518
Cumulative Timesteps: 954,971,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,224.06191
Policy Entropy: 3.72975
Value Function Loss: 0.02257

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.45752
Value Function Update Magnitude: 0.30480

Collected Steps per Second: 20,162.01995
Overall Steps per Second: 9,773.18037

Timestep Collection Time: 2.48140
Timestep Consumption Time: 2.63771
PPO Batch Consumption Time: 0.30749
Total Iteration Time: 5.11911

Cumulative Model Updates: 114,524
Cumulative Timesteps: 955,021,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 955021766...
Checkpoint 955021766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,955.18720
Policy Entropy: 3.74355
Value Function Loss: 0.02136

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.20440
Policy Update Magnitude: 0.47673
Value Function Update Magnitude: 0.32437

Collected Steps per Second: 18,748.34763
Overall Steps per Second: 9,607.69815

Timestep Collection Time: 2.66776
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.30170
Total Iteration Time: 5.20583

Cumulative Model Updates: 114,530
Cumulative Timesteps: 955,071,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,763.17542
Policy Entropy: 3.74895
Value Function Loss: 0.02945

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.18673
Policy Update Magnitude: 0.54258
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 20,176.53053
Overall Steps per Second: 10,016.35917

Timestep Collection Time: 2.47951
Timestep Consumption Time: 2.51511
PPO Batch Consumption Time: 0.30212
Total Iteration Time: 4.99463

Cumulative Model Updates: 114,536
Cumulative Timesteps: 955,121,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 955121810...
Checkpoint 955121810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,912.00929
Policy Entropy: 3.75265
Value Function Loss: 0.03741

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.21481
Policy Update Magnitude: 0.70243
Value Function Update Magnitude: 0.72842

Collected Steps per Second: 20,419.94309
Overall Steps per Second: 10,108.74427

Timestep Collection Time: 2.45006
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.94918

Cumulative Model Updates: 114,542
Cumulative Timesteps: 955,171,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,791.72777
Policy Entropy: 3.74081
Value Function Loss: 0.04262

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.20950
Policy Update Magnitude: 0.81309
Value Function Update Magnitude: 0.92710

Collected Steps per Second: 20,597.85925
Overall Steps per Second: 10,095.50872

Timestep Collection Time: 2.42841
Timestep Consumption Time: 2.52627
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.95468

Cumulative Model Updates: 114,548
Cumulative Timesteps: 955,221,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 955221860...
Checkpoint 955221860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,739.08395
Policy Entropy: 3.74570
Value Function Loss: 0.03766

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.85645
Value Function Update Magnitude: 0.90277

Collected Steps per Second: 20,270.08568
Overall Steps per Second: 10,070.01650

Timestep Collection Time: 2.46708
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.96603

Cumulative Model Updates: 114,554
Cumulative Timesteps: 955,271,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,175.30269
Policy Entropy: 3.74181
Value Function Loss: 0.03367

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12534
Policy Update Magnitude: 0.94922
Value Function Update Magnitude: 0.96829

Collected Steps per Second: 20,585.80370
Overall Steps per Second: 10,131.95368

Timestep Collection Time: 2.42905
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.93528

Cumulative Model Updates: 114,560
Cumulative Timesteps: 955,321,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 955321872...
Checkpoint 955321872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221,939.66488
Policy Entropy: 3.73397
Value Function Loss: 0.03663

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.89438
Value Function Update Magnitude: 0.94149

Collected Steps per Second: 20,838.76617
Overall Steps per Second: 10,202.03088

Timestep Collection Time: 2.40091
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.90412

Cumulative Model Updates: 114,566
Cumulative Timesteps: 955,371,904

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,130.77441
Policy Entropy: 3.76503
Value Function Loss: 0.03784

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.77995
Value Function Update Magnitude: 1.13234

Collected Steps per Second: 20,891.03471
Overall Steps per Second: 10,064.24044

Timestep Collection Time: 2.39375
Timestep Consumption Time: 2.57513
PPO Batch Consumption Time: 0.30218
Total Iteration Time: 4.96888

Cumulative Model Updates: 114,572
Cumulative Timesteps: 955,421,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 955421912...
Checkpoint 955421912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,647.66819
Policy Entropy: 3.74973
Value Function Loss: 0.04273

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.70874
Value Function Update Magnitude: 0.86792

Collected Steps per Second: 20,665.77467
Overall Steps per Second: 9,856.90244

Timestep Collection Time: 2.41975
Timestep Consumption Time: 2.65345
PPO Batch Consumption Time: 0.31656
Total Iteration Time: 5.07320

Cumulative Model Updates: 114,578
Cumulative Timesteps: 955,471,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,647.66819
Policy Entropy: 3.74028
Value Function Loss: 0.03576

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.67769
Value Function Update Magnitude: 0.68320

Collected Steps per Second: 21,447.01708
Overall Steps per Second: 10,149.17295

Timestep Collection Time: 2.33179
Timestep Consumption Time: 2.59570
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.92750

Cumulative Model Updates: 114,584
Cumulative Timesteps: 955,521,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 955521928...
Checkpoint 955521928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,741.35588
Policy Entropy: 3.72072
Value Function Loss: 0.03229

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.64392
Value Function Update Magnitude: 0.62045

Collected Steps per Second: 21,041.47032
Overall Steps per Second: 10,175.98352

Timestep Collection Time: 2.37702
Timestep Consumption Time: 2.53808
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.91510

Cumulative Model Updates: 114,590
Cumulative Timesteps: 955,571,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,504.59982
Policy Entropy: 3.72633
Value Function Loss: 0.02929

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.55832
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 20,892.14383
Overall Steps per Second: 10,090.83385

Timestep Collection Time: 2.39420
Timestep Consumption Time: 2.56277
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.95697

Cumulative Model Updates: 114,596
Cumulative Timesteps: 955,621,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 955621964...
Checkpoint 955621964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,058.76252
Policy Entropy: 3.74002
Value Function Loss: 0.03149

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.51514
Value Function Update Magnitude: 0.58055

Collected Steps per Second: 20,514.78586
Overall Steps per Second: 9,952.68980

Timestep Collection Time: 2.43814
Timestep Consumption Time: 2.58743
PPO Batch Consumption Time: 0.29957
Total Iteration Time: 5.02558

Cumulative Model Updates: 114,602
Cumulative Timesteps: 955,671,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,920.01000
Policy Entropy: 3.74051
Value Function Loss: 0.02803

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.51007
Value Function Update Magnitude: 0.60048

Collected Steps per Second: 21,006.90600
Overall Steps per Second: 10,168.40671

Timestep Collection Time: 2.38093
Timestep Consumption Time: 2.53783
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.91876

Cumulative Model Updates: 114,608
Cumulative Timesteps: 955,721,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 955721998...
Checkpoint 955721998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,920.01000
Policy Entropy: 3.74006
Value Function Loss: 0.02412

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.49447
Value Function Update Magnitude: 0.67473

Collected Steps per Second: 20,982.37831
Overall Steps per Second: 10,046.92979

Timestep Collection Time: 2.38410
Timestep Consumption Time: 2.59494
PPO Batch Consumption Time: 0.30150
Total Iteration Time: 4.97903

Cumulative Model Updates: 114,614
Cumulative Timesteps: 955,772,022

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,920.01000
Policy Entropy: 3.73215
Value Function Loss: 0.01934

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.43997
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 19,924.98272
Overall Steps per Second: 9,941.21102

Timestep Collection Time: 2.51012
Timestep Consumption Time: 2.52086
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 5.03098

Cumulative Model Updates: 114,620
Cumulative Timesteps: 955,822,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 955822036...
Checkpoint 955822036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,607.55109
Policy Entropy: 3.71913
Value Function Loss: 0.01939

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.40459
Value Function Update Magnitude: 0.66057

Collected Steps per Second: 20,040.75924
Overall Steps per Second: 9,778.93440

Timestep Collection Time: 2.49661
Timestep Consumption Time: 2.61990
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 5.11651

Cumulative Model Updates: 114,626
Cumulative Timesteps: 955,872,070

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,554.16241
Policy Entropy: 3.72879
Value Function Loss: 0.02133

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.40415
Value Function Update Magnitude: 0.73505

Collected Steps per Second: 20,437.12954
Overall Steps per Second: 9,927.66964

Timestep Collection Time: 2.44760
Timestep Consumption Time: 2.59104
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 5.03864

Cumulative Model Updates: 114,632
Cumulative Timesteps: 955,922,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 955922092...
Checkpoint 955922092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,725.19726
Policy Entropy: 3.75280
Value Function Loss: 0.02363

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.42973
Value Function Update Magnitude: 0.68160

Collected Steps per Second: 20,266.32488
Overall Steps per Second: 9,776.05733

Timestep Collection Time: 2.46764
Timestep Consumption Time: 2.64792
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 5.11556

Cumulative Model Updates: 114,638
Cumulative Timesteps: 955,972,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,712.66795
Policy Entropy: 3.75811
Value Function Loss: 0.02376

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.45273
Value Function Update Magnitude: 0.73410

Collected Steps per Second: 19,312.17267
Overall Steps per Second: 9,749.81485

Timestep Collection Time: 2.58997
Timestep Consumption Time: 2.54018
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 5.13015

Cumulative Model Updates: 114,644
Cumulative Timesteps: 956,022,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 956022120...
Checkpoint 956022120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,163.13942
Policy Entropy: 3.75050
Value Function Loss: 0.02549

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.46750
Value Function Update Magnitude: 0.70703

Collected Steps per Second: 21,031.96765
Overall Steps per Second: 10,206.70558

Timestep Collection Time: 2.37790
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.89992

Cumulative Model Updates: 114,650
Cumulative Timesteps: 956,072,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,184.94428
Policy Entropy: 3.73498
Value Function Loss: 0.02462

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.47692
Value Function Update Magnitude: 0.68030

Collected Steps per Second: 21,082.44135
Overall Steps per Second: 10,106.90067

Timestep Collection Time: 2.37231
Timestep Consumption Time: 2.57619
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.94850

Cumulative Model Updates: 114,656
Cumulative Timesteps: 956,122,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 956122146...
Checkpoint 956122146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,497.68933
Policy Entropy: 3.72605
Value Function Loss: 0.02595

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.48045
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 20,643.80403
Overall Steps per Second: 10,011.51342

Timestep Collection Time: 2.42271
Timestep Consumption Time: 2.57294
PPO Batch Consumption Time: 0.29977
Total Iteration Time: 4.99565

Cumulative Model Updates: 114,662
Cumulative Timesteps: 956,172,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,246.03829
Policy Entropy: 3.72588
Value Function Loss: 0.02627

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.50837
Value Function Update Magnitude: 0.67240

Collected Steps per Second: 20,804.69561
Overall Steps per Second: 9,699.83800

Timestep Collection Time: 2.40388
Timestep Consumption Time: 2.75208
PPO Batch Consumption Time: 0.32274
Total Iteration Time: 5.15596

Cumulative Model Updates: 114,668
Cumulative Timesteps: 956,222,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 956222172...
Checkpoint 956222172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.73492
Value Function Loss: 0.02618

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.48915
Value Function Update Magnitude: 0.66277

Collected Steps per Second: 20,315.39028
Overall Steps per Second: 9,698.40719

Timestep Collection Time: 2.46148
Timestep Consumption Time: 2.69462
PPO Batch Consumption Time: 0.31380
Total Iteration Time: 5.15610

Cumulative Model Updates: 114,674
Cumulative Timesteps: 956,272,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.72996
Value Function Loss: 0.02293

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.50865
Value Function Update Magnitude: 0.65942

Collected Steps per Second: 19,967.49094
Overall Steps per Second: 9,744.73160

Timestep Collection Time: 2.50447
Timestep Consumption Time: 2.62733
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 5.13180

Cumulative Model Updates: 114,680
Cumulative Timesteps: 956,322,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 956322186...
Checkpoint 956322186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.72263
Value Function Loss: 0.02104

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.49278
Value Function Update Magnitude: 0.64302

Collected Steps per Second: 20,370.60906
Overall Steps per Second: 10,003.49542

Timestep Collection Time: 2.45550
Timestep Consumption Time: 2.54475
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 5.00025

Cumulative Model Updates: 114,686
Cumulative Timesteps: 956,372,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.70848
Value Function Loss: 0.02072

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15049
Policy Update Magnitude: 0.42530
Value Function Update Magnitude: 0.50543

Collected Steps per Second: 20,207.28571
Overall Steps per Second: 9,874.33377

Timestep Collection Time: 2.47465
Timestep Consumption Time: 2.58959
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 5.06424

Cumulative Model Updates: 114,692
Cumulative Timesteps: 956,422,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 956422212...
Checkpoint 956422212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.70519
Value Function Loss: 0.02180

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.41779
Value Function Update Magnitude: 0.40256

Collected Steps per Second: 19,984.65203
Overall Steps per Second: 9,806.70903

Timestep Collection Time: 2.50222
Timestep Consumption Time: 2.59694
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 5.09916

Cumulative Model Updates: 114,698
Cumulative Timesteps: 956,472,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.70180
Value Function Loss: 0.02211

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.43707
Value Function Update Magnitude: 0.37367

Collected Steps per Second: 19,229.16022
Overall Steps per Second: 9,507.64794

Timestep Collection Time: 2.60074
Timestep Consumption Time: 2.65924
PPO Batch Consumption Time: 0.31178
Total Iteration Time: 5.25998

Cumulative Model Updates: 114,704
Cumulative Timesteps: 956,522,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 956522228...
Checkpoint 956522228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.71842
Value Function Loss: 0.02000

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.41166
Value Function Update Magnitude: 0.38052

Collected Steps per Second: 19,738.55825
Overall Steps per Second: 9,840.19861

Timestep Collection Time: 2.53321
Timestep Consumption Time: 2.54819
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 5.08140

Cumulative Model Updates: 114,710
Cumulative Timesteps: 956,572,230

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,889.22491
Policy Entropy: 3.72688
Value Function Loss: 0.01876

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.38992
Value Function Update Magnitude: 0.39388

Collected Steps per Second: 19,627.33109
Overall Steps per Second: 9,696.28555

Timestep Collection Time: 2.54808
Timestep Consumption Time: 2.60977
PPO Batch Consumption Time: 0.30476
Total Iteration Time: 5.15785

Cumulative Model Updates: 114,716
Cumulative Timesteps: 956,622,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 956622242...
Checkpoint 956622242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,314.28953
Policy Entropy: 3.73798
Value Function Loss: 0.01803

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.40835
Value Function Update Magnitude: 0.48099

Collected Steps per Second: 18,569.89886
Overall Steps per Second: 9,219.98238

Timestep Collection Time: 2.69490
Timestep Consumption Time: 2.73288
PPO Batch Consumption Time: 0.31711
Total Iteration Time: 5.42778

Cumulative Model Updates: 114,722
Cumulative Timesteps: 956,672,286

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,955.20425
Policy Entropy: 3.72129
Value Function Loss: 0.01991

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.43042
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 18,843.70005
Overall Steps per Second: 9,481.00209

Timestep Collection Time: 2.65574
Timestep Consumption Time: 2.62260
PPO Batch Consumption Time: 0.31059
Total Iteration Time: 5.27834

Cumulative Model Updates: 114,728
Cumulative Timesteps: 956,722,330

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 956722330...
Checkpoint 956722330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,955.20425
Policy Entropy: 3.70624
Value Function Loss: 0.02332

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.47589
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 20,411.54604
Overall Steps per Second: 10,010.70894

Timestep Collection Time: 2.44999
Timestep Consumption Time: 2.54546
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.99545

Cumulative Model Updates: 114,734
Cumulative Timesteps: 956,772,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,568.41309
Policy Entropy: 3.69094
Value Function Loss: 0.02414

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.49762
Value Function Update Magnitude: 0.54701

Collected Steps per Second: 20,692.57922
Overall Steps per Second: 9,877.86734

Timestep Collection Time: 2.41729
Timestep Consumption Time: 2.64655
PPO Batch Consumption Time: 0.30530
Total Iteration Time: 5.06385

Cumulative Model Updates: 114,740
Cumulative Timesteps: 956,822,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956822358...
Checkpoint 956822358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,568.41309
Policy Entropy: 3.70079
Value Function Loss: 0.02433

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14338
Policy Update Magnitude: 0.49658
Value Function Update Magnitude: 0.52430

Collected Steps per Second: 19,503.39854
Overall Steps per Second: 9,816.10614

Timestep Collection Time: 2.56530
Timestep Consumption Time: 2.53163
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 5.09693

Cumulative Model Updates: 114,746
Cumulative Timesteps: 956,872,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,568.41309
Policy Entropy: 3.72468
Value Function Loss: 0.02208

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.47501
Value Function Update Magnitude: 0.46711

Collected Steps per Second: 21,800.31444
Overall Steps per Second: 10,467.62108

Timestep Collection Time: 2.29354
Timestep Consumption Time: 2.48309
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.77663

Cumulative Model Updates: 114,752
Cumulative Timesteps: 956,922,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 956922390...
Checkpoint 956922390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,568.41309
Policy Entropy: 3.71140
Value Function Loss: 0.02173

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.43423
Value Function Update Magnitude: 0.41802

Collected Steps per Second: 20,186.30214
Overall Steps per Second: 9,988.63523

Timestep Collection Time: 2.47891
Timestep Consumption Time: 2.53078
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 5.00969

Cumulative Model Updates: 114,758
Cumulative Timesteps: 956,972,430

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,568.41309
Policy Entropy: 3.71771
Value Function Loss: 0.01938

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.39985
Value Function Update Magnitude: 0.38035

Collected Steps per Second: 21,524.95925
Overall Steps per Second: 10,354.00428

Timestep Collection Time: 2.32307
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.82944

Cumulative Model Updates: 114,764
Cumulative Timesteps: 957,022,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 957022434...
Checkpoint 957022434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,358.43639
Policy Entropy: 3.69877
Value Function Loss: 0.02081

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.37874
Value Function Update Magnitude: 0.40627

Collected Steps per Second: 20,437.15626
Overall Steps per Second: 9,861.01901

Timestep Collection Time: 2.44760
Timestep Consumption Time: 2.62510
PPO Batch Consumption Time: 0.32016
Total Iteration Time: 5.07270

Cumulative Model Updates: 114,770
Cumulative Timesteps: 957,072,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,518.14498
Policy Entropy: 3.73352
Value Function Loss: 0.01950

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.38788
Value Function Update Magnitude: 0.38491

Collected Steps per Second: 20,018.60368
Overall Steps per Second: 10,004.92007

Timestep Collection Time: 2.49908
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 5.00034

Cumulative Model Updates: 114,776
Cumulative Timesteps: 957,122,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 957122484...
Checkpoint 957122484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,613.14009
Policy Entropy: 3.74740
Value Function Loss: 0.02094

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.40666
Value Function Update Magnitude: 0.42694

Collected Steps per Second: 19,988.08581
Overall Steps per Second: 9,948.99133

Timestep Collection Time: 2.50189
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 5.02644

Cumulative Model Updates: 114,782
Cumulative Timesteps: 957,172,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,183.71967
Policy Entropy: 3.76462
Value Function Loss: 0.01986

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.41992
Value Function Update Magnitude: 0.53806

Collected Steps per Second: 19,638.57855
Overall Steps per Second: 9,816.42285

Timestep Collection Time: 2.54723
Timestep Consumption Time: 2.54872
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 5.09595

Cumulative Model Updates: 114,788
Cumulative Timesteps: 957,222,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 957222516...
Checkpoint 957222516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,689.28479
Policy Entropy: 3.73963
Value Function Loss: 0.01991

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.42223
Value Function Update Magnitude: 0.56406

Collected Steps per Second: 20,355.73556
Overall Steps per Second: 10,120.66009

Timestep Collection Time: 2.45808
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.94395

Cumulative Model Updates: 114,794
Cumulative Timesteps: 957,272,552

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,689.28479
Policy Entropy: 3.72606
Value Function Loss: 0.02033

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.44973
Value Function Update Magnitude: 0.57617

Collected Steps per Second: 21,554.52217
Overall Steps per Second: 9,973.91834

Timestep Collection Time: 2.31998
Timestep Consumption Time: 2.69370
PPO Batch Consumption Time: 0.31520
Total Iteration Time: 5.01368

Cumulative Model Updates: 114,800
Cumulative Timesteps: 957,322,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 957322558...
Checkpoint 957322558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,382.90325
Policy Entropy: 3.73559
Value Function Loss: 0.02047

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.46476
Value Function Update Magnitude: 0.55049

Collected Steps per Second: 21,284.81630
Overall Steps per Second: 10,157.03312

Timestep Collection Time: 2.35088
Timestep Consumption Time: 2.57556
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.92644

Cumulative Model Updates: 114,806
Cumulative Timesteps: 957,372,596

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,145.47235
Policy Entropy: 3.72911
Value Function Loss: 0.02463

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.48452
Value Function Update Magnitude: 0.56470

Collected Steps per Second: 20,318.27964
Overall Steps per Second: 10,038.71972

Timestep Collection Time: 2.46182
Timestep Consumption Time: 2.52088
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.98271

Cumulative Model Updates: 114,812
Cumulative Timesteps: 957,422,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 957422616...
Checkpoint 957422616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,638.98358
Policy Entropy: 3.74280
Value Function Loss: 0.02482

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.52350
Value Function Update Magnitude: 0.63463

Collected Steps per Second: 21,561.32723
Overall Steps per Second: 10,449.66031

Timestep Collection Time: 2.31943
Timestep Consumption Time: 2.46637
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.78580

Cumulative Model Updates: 114,818
Cumulative Timesteps: 957,472,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,615.54841
Policy Entropy: 3.71233
Value Function Loss: 0.02819

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.69997

Collected Steps per Second: 21,416.04869
Overall Steps per Second: 10,347.15152

Timestep Collection Time: 2.33638
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.83573

Cumulative Model Updates: 114,824
Cumulative Timesteps: 957,522,662

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 957522662...
Checkpoint 957522662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,615.54841
Policy Entropy: 3.71977
Value Function Loss: 0.02641

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.51472
Value Function Update Magnitude: 0.64456

Collected Steps per Second: 21,302.40071
Overall Steps per Second: 10,176.18253

Timestep Collection Time: 2.34847
Timestep Consumption Time: 2.56772
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.91619

Cumulative Model Updates: 114,830
Cumulative Timesteps: 957,572,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,494.82523
Policy Entropy: 3.71070
Value Function Loss: 0.02639

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.49460
Value Function Update Magnitude: 0.61663

Collected Steps per Second: 20,533.76455
Overall Steps per Second: 10,109.49902

Timestep Collection Time: 2.43531
Timestep Consumption Time: 2.51113
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 4.94644

Cumulative Model Updates: 114,836
Cumulative Timesteps: 957,622,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 957622696...
Checkpoint 957622696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,494.82523
Policy Entropy: 3.71333
Value Function Loss: 0.02635

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.47173
Value Function Update Magnitude: 0.50107

Collected Steps per Second: 20,465.07333
Overall Steps per Second: 10,262.87630

Timestep Collection Time: 2.44338
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.87232

Cumulative Model Updates: 114,842
Cumulative Timesteps: 957,672,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,494.82523
Policy Entropy: 3.71363
Value Function Loss: 0.02159

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.44470
Value Function Update Magnitude: 0.47451

Collected Steps per Second: 20,732.30778
Overall Steps per Second: 10,333.93279

Timestep Collection Time: 2.41276
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.84056

Cumulative Model Updates: 114,848
Cumulative Timesteps: 957,722,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 957722722...
Checkpoint 957722722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,642.78850
Policy Entropy: 3.70729
Value Function Loss: 0.02196

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.45108
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 20,630.77120
Overall Steps per Second: 10,221.59329

Timestep Collection Time: 2.42386
Timestep Consumption Time: 2.46834
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.89219

Cumulative Model Updates: 114,854
Cumulative Timesteps: 957,772,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,642.78850
Policy Entropy: 3.72731
Value Function Loss: 0.02168

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.45643
Value Function Update Magnitude: 0.51072

Collected Steps per Second: 21,277.02475
Overall Steps per Second: 10,327.08499

Timestep Collection Time: 2.35080
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.84338

Cumulative Model Updates: 114,860
Cumulative Timesteps: 957,822,746

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 957822746...
Checkpoint 957822746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,642.78850
Policy Entropy: 3.71523
Value Function Loss: 0.02175

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.43068
Value Function Update Magnitude: 0.47557

Collected Steps per Second: 22,134.85171
Overall Steps per Second: 10,483.22653

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.51195
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.77200

Cumulative Model Updates: 114,866
Cumulative Timesteps: 957,872,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,642.78850
Policy Entropy: 3.73473
Value Function Loss: 0.02129

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.40718
Value Function Update Magnitude: 0.46204

Collected Steps per Second: 20,511.75955
Overall Steps per Second: 9,953.90610

Timestep Collection Time: 2.43997
Timestep Consumption Time: 2.58801
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 5.02798

Cumulative Model Updates: 114,872
Cumulative Timesteps: 957,922,820

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 957922820...
Checkpoint 957922820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,642.78850
Policy Entropy: 3.72152
Value Function Loss: 0.02959

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13453
Policy Update Magnitude: 0.42444
Value Function Update Magnitude: 0.36844

Collected Steps per Second: 20,556.53275
Overall Steps per Second: 10,012.34512

Timestep Collection Time: 2.43368
Timestep Consumption Time: 2.56295
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.99663

Cumulative Model Updates: 114,878
Cumulative Timesteps: 957,972,848

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,217.77993
Policy Entropy: 3.73234
Value Function Loss: 0.02767

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.49943
Value Function Update Magnitude: 0.41803

Collected Steps per Second: 21,350.85829
Overall Steps per Second: 10,212.70919

Timestep Collection Time: 2.34333
Timestep Consumption Time: 2.55567
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.89899

Cumulative Model Updates: 114,884
Cumulative Timesteps: 958,022,880

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 958022880...
Checkpoint 958022880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,441.72177
Policy Entropy: 3.70279
Value Function Loss: 0.03038

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.51096
Value Function Update Magnitude: 0.48453

Collected Steps per Second: 21,273.70751
Overall Steps per Second: 10,318.62702

Timestep Collection Time: 2.35070
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.84638

Cumulative Model Updates: 114,890
Cumulative Timesteps: 958,072,888

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,441.72177
Policy Entropy: 3.71726
Value Function Loss: 0.02862

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.51321
Value Function Update Magnitude: 0.50561

Collected Steps per Second: 21,867.72806
Overall Steps per Second: 10,465.93679

Timestep Collection Time: 2.28666
Timestep Consumption Time: 2.49113
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.77779

Cumulative Model Updates: 114,896
Cumulative Timesteps: 958,122,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 958122892...
Checkpoint 958122892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304,076.76286
Policy Entropy: 3.70543
Value Function Loss: 0.02989

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.48371
Value Function Update Magnitude: 0.50008

Collected Steps per Second: 19,932.83099
Overall Steps per Second: 10,099.88093

Timestep Collection Time: 2.50973
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.95313

Cumulative Model Updates: 114,902
Cumulative Timesteps: 958,172,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,505.32570
Policy Entropy: 3.72319
Value Function Loss: 0.02914

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.50146
Value Function Update Magnitude: 0.44088

Collected Steps per Second: 20,335.59094
Overall Steps per Second: 10,137.48087

Timestep Collection Time: 2.45874
Timestep Consumption Time: 2.47345
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.93219

Cumulative Model Updates: 114,908
Cumulative Timesteps: 958,222,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 958222918...
Checkpoint 958222918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,730.58001
Policy Entropy: 3.71166
Value Function Loss: 0.02897

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.52715
Value Function Update Magnitude: 0.43810

Collected Steps per Second: 21,391.56542
Overall Steps per Second: 10,338.13203

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.49999
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.83820

Cumulative Model Updates: 114,914
Cumulative Timesteps: 958,272,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245,730.58001
Policy Entropy: 3.71453
Value Function Loss: 0.02384

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,375.73150
Overall Steps per Second: 10,730.60639

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.42510
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.65976

Cumulative Model Updates: 114,920
Cumulative Timesteps: 958,322,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 958322938...
Checkpoint 958322938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,730.58001
Policy Entropy: 3.70913
Value Function Loss: 0.02156

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.53426
Value Function Update Magnitude: 0.78619

Collected Steps per Second: 21,644.99167
Overall Steps per Second: 10,444.18959

Timestep Collection Time: 2.31093
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.78927

Cumulative Model Updates: 114,926
Cumulative Timesteps: 958,372,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,311.43060
Policy Entropy: 3.71562
Value Function Loss: 0.02262

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.50676
Value Function Update Magnitude: 0.72525

Collected Steps per Second: 22,321.81120
Overall Steps per Second: 10,657.03121

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.69211

Cumulative Model Updates: 114,932
Cumulative Timesteps: 958,422,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 958422962...
Checkpoint 958422962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,253.16213
Policy Entropy: 3.72390
Value Function Loss: 0.02322

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.51659
Value Function Update Magnitude: 0.73870

Collected Steps per Second: 22,182.05052
Overall Steps per Second: 10,616.74853

Timestep Collection Time: 2.25615
Timestep Consumption Time: 2.45772
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.71387

Cumulative Model Updates: 114,938
Cumulative Timesteps: 958,473,008

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,615.66939
Policy Entropy: 3.72449
Value Function Loss: 0.02843

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.79020

Collected Steps per Second: 22,301.83213
Overall Steps per Second: 10,579.22908

Timestep Collection Time: 2.24269
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.72775

Cumulative Model Updates: 114,944
Cumulative Timesteps: 958,523,024

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 958523024...
Checkpoint 958523024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,143.83840
Policy Entropy: 3.72123
Value Function Loss: 0.03179

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.59314
Value Function Update Magnitude: 0.74729

Collected Steps per Second: 21,598.69548
Overall Steps per Second: 10,360.38625

Timestep Collection Time: 2.31625
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.82878

Cumulative Model Updates: 114,950
Cumulative Timesteps: 958,573,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,750.62219
Policy Entropy: 3.72981
Value Function Loss: 0.03376

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.65776
Value Function Update Magnitude: 0.73424

Collected Steps per Second: 21,987.64398
Overall Steps per Second: 10,438.77780

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.51694
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.79194

Cumulative Model Updates: 114,956
Cumulative Timesteps: 958,623,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 958623074...
Checkpoint 958623074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,719.78067
Policy Entropy: 3.74675
Value Function Loss: 0.03330

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.71728
Value Function Update Magnitude: 0.76306

Collected Steps per Second: 21,648.45781
Overall Steps per Second: 10,548.39726

Timestep Collection Time: 2.30991
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.74063

Cumulative Model Updates: 114,962
Cumulative Timesteps: 958,673,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,801.87733
Policy Entropy: 3.75463
Value Function Loss: 0.03081

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.70097
Value Function Update Magnitude: 0.78016

Collected Steps per Second: 22,159.21806
Overall Steps per Second: 10,431.06903

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.53769
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.79471

Cumulative Model Updates: 114,968
Cumulative Timesteps: 958,723,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 958723094...
Checkpoint 958723094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,891.72231
Policy Entropy: 3.74955
Value Function Loss: 0.02841

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.63000
Value Function Update Magnitude: 0.73593

Collected Steps per Second: 21,956.61267
Overall Steps per Second: 10,589.40357

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.72491

Cumulative Model Updates: 114,974
Cumulative Timesteps: 958,773,128

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,991.19110
Policy Entropy: 3.73480
Value Function Loss: 0.02451

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.54741
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 22,310.41910
Overall Steps per Second: 10,488.28013

Timestep Collection Time: 2.24137
Timestep Consumption Time: 2.52642
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.76780

Cumulative Model Updates: 114,980
Cumulative Timesteps: 958,823,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 958823134...
Checkpoint 958823134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,991.19110
Policy Entropy: 3.73152
Value Function Loss: 0.02201

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.51724
Value Function Update Magnitude: 0.50684

Collected Steps per Second: 21,311.40356
Overall Steps per Second: 10,571.67351

Timestep Collection Time: 2.34766
Timestep Consumption Time: 2.38498
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73265

Cumulative Model Updates: 114,986
Cumulative Timesteps: 958,873,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,318.93129
Policy Entropy: 3.72020
Value Function Loss: 0.02005

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.47310

Collected Steps per Second: 19,465.35890
Overall Steps per Second: 10,002.68429

Timestep Collection Time: 2.56908
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.99946

Cumulative Model Updates: 114,992
Cumulative Timesteps: 958,923,174

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 958923174...
Checkpoint 958923174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,989.73171
Policy Entropy: 3.72414
Value Function Loss: 0.02054

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.55758

Collected Steps per Second: 19,903.56673
Overall Steps per Second: 9,848.31143

Timestep Collection Time: 2.51251
Timestep Consumption Time: 2.56531
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 5.07782

Cumulative Model Updates: 114,998
Cumulative Timesteps: 958,973,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,989.73171
Policy Entropy: 3.71962
Value Function Loss: 0.02081

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.76754

Collected Steps per Second: 20,350.33822
Overall Steps per Second: 10,012.60416

Timestep Collection Time: 2.45706
Timestep Consumption Time: 2.53685
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.99391

Cumulative Model Updates: 115,004
Cumulative Timesteps: 959,023,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 959023184...
Checkpoint 959023184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,165.77180
Policy Entropy: 3.71677
Value Function Loss: 0.02219

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.67881
Value Function Update Magnitude: 0.74775

Collected Steps per Second: 21,425.16133
Overall Steps per Second: 10,073.44820

Timestep Collection Time: 2.33445
Timestep Consumption Time: 2.63068
PPO Batch Consumption Time: 0.31047
Total Iteration Time: 4.96513

Cumulative Model Updates: 115,010
Cumulative Timesteps: 959,073,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,165.77180
Policy Entropy: 3.72632
Value Function Loss: 0.02002

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.70553
Value Function Update Magnitude: 0.56863

Collected Steps per Second: 22,336.00163
Overall Steps per Second: 10,564.66317

Timestep Collection Time: 2.23979
Timestep Consumption Time: 2.49562
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.73541

Cumulative Model Updates: 115,016
Cumulative Timesteps: 959,123,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 959123228...
Checkpoint 959123228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,165.77180
Policy Entropy: 3.72429
Value Function Loss: 0.01708

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.47131

Collected Steps per Second: 20,249.98845
Overall Steps per Second: 9,964.50407

Timestep Collection Time: 2.47003
Timestep Consumption Time: 2.54959
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 5.01962

Cumulative Model Updates: 115,022
Cumulative Timesteps: 959,173,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 329,098.98327
Policy Entropy: 3.72363
Value Function Loss: 0.01895

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15378
Policy Update Magnitude: 0.46015
Value Function Update Magnitude: 0.49136

Collected Steps per Second: 20,274.13629
Overall Steps per Second: 9,978.99789

Timestep Collection Time: 2.46639
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 5.01092

Cumulative Model Updates: 115,028
Cumulative Timesteps: 959,223,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 959223250...
Checkpoint 959223250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,906.03453
Policy Entropy: 3.71798
Value Function Loss: 0.02136

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15123
Policy Update Magnitude: 0.49430
Value Function Update Magnitude: 0.45963

Collected Steps per Second: 20,287.27857
Overall Steps per Second: 9,998.43236

Timestep Collection Time: 2.46509
Timestep Consumption Time: 2.53669
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 5.00178

Cumulative Model Updates: 115,034
Cumulative Timesteps: 959,273,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,906.03453
Policy Entropy: 3.71886
Value Function Loss: 0.02155

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.53638
Value Function Update Magnitude: 0.51680

Collected Steps per Second: 19,726.08756
Overall Steps per Second: 9,892.80520

Timestep Collection Time: 2.53553
Timestep Consumption Time: 2.52027
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 5.05580

Cumulative Model Updates: 115,040
Cumulative Timesteps: 959,323,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 959323276...
Checkpoint 959323276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,906.03453
Policy Entropy: 3.73566
Value Function Loss: 0.01799

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.60025

Collected Steps per Second: 20,427.45268
Overall Steps per Second: 10,145.08494

Timestep Collection Time: 2.44778
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.92869

Cumulative Model Updates: 115,046
Cumulative Timesteps: 959,373,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,906.03453
Policy Entropy: 3.72448
Value Function Loss: 0.01765

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.17408
Policy Update Magnitude: 0.53938
Value Function Update Magnitude: 0.48830

Collected Steps per Second: 20,516.17525
Overall Steps per Second: 10,203.95673

Timestep Collection Time: 2.43788
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.90163

Cumulative Model Updates: 115,052
Cumulative Timesteps: 959,423,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 959423294...
Checkpoint 959423294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,484.24351
Policy Entropy: 3.73228
Value Function Loss: 0.02017

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.46774
Value Function Update Magnitude: 0.46667

Collected Steps per Second: 21,442.80617
Overall Steps per Second: 10,650.34361

Timestep Collection Time: 2.33262
Timestep Consumption Time: 2.36375
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.69637

Cumulative Model Updates: 115,058
Cumulative Timesteps: 959,473,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,069.16737
Policy Entropy: 3.73114
Value Function Loss: 0.02498

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.47208
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 20,338.38607
Overall Steps per Second: 10,137.65219

Timestep Collection Time: 2.45870
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.93270

Cumulative Model Updates: 115,064
Cumulative Timesteps: 959,523,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 959523318...
Checkpoint 959523318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,975.25178
Policy Entropy: 3.75810
Value Function Loss: 0.02464

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.50391
Value Function Update Magnitude: 0.57352

Collected Steps per Second: 20,497.89200
Overall Steps per Second: 10,176.17133

Timestep Collection Time: 2.44035
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.91560

Cumulative Model Updates: 115,070
Cumulative Timesteps: 959,573,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,202.22285
Policy Entropy: 3.75683
Value Function Loss: 0.02293

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14506
Policy Update Magnitude: 0.48721
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,110.35167
Overall Steps per Second: 10,520.72368

Timestep Collection Time: 2.26301
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.75595

Cumulative Model Updates: 115,076
Cumulative Timesteps: 959,623,376

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 959623376...
Checkpoint 959623376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,202.22285
Policy Entropy: 3.75605
Value Function Loss: 0.01828

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.44178
Value Function Update Magnitude: 0.54322

Collected Steps per Second: 21,825.90584
Overall Steps per Second: 10,467.09363

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.77764

Cumulative Model Updates: 115,082
Cumulative Timesteps: 959,673,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,202.22285
Policy Entropy: 3.74257
Value Function Loss: 0.01799

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.42324
Value Function Update Magnitude: 0.55181

Collected Steps per Second: 22,347.36017
Overall Steps per Second: 10,483.98639

Timestep Collection Time: 2.23812
Timestep Consumption Time: 2.53259
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.77070

Cumulative Model Updates: 115,088
Cumulative Timesteps: 959,723,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 959723400...
Checkpoint 959723400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.74798
Value Function Loss: 0.01729

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14613
Policy Update Magnitude: 0.47778
Value Function Update Magnitude: 0.62240

Collected Steps per Second: 22,104.87416
Overall Steps per Second: 10,604.70057

Timestep Collection Time: 2.26222
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.71546

Cumulative Model Updates: 115,094
Cumulative Timesteps: 959,773,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.75580
Value Function Loss: 0.01723

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.48363
Value Function Update Magnitude: 0.65699

Collected Steps per Second: 22,254.80839
Overall Steps per Second: 10,411.38954

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.55695
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.80474

Cumulative Model Updates: 115,100
Cumulative Timesteps: 959,823,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 959823430...
Checkpoint 959823430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.73954
Value Function Loss: 0.01752

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.46670
Value Function Update Magnitude: 0.56367

Collected Steps per Second: 22,019.29933
Overall Steps per Second: 10,597.97105

Timestep Collection Time: 2.27201
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.72053

Cumulative Model Updates: 115,106
Cumulative Timesteps: 959,873,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.70873
Value Function Loss: 0.01915

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.43335
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 21,675.47008
Overall Steps per Second: 10,351.53700

Timestep Collection Time: 2.30814
Timestep Consumption Time: 2.52496
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.83310

Cumulative Model Updates: 115,112
Cumulative Timesteps: 959,923,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 959923488...
Checkpoint 959923488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.69832
Value Function Loss: 0.01910

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.42538
Value Function Update Magnitude: 0.47753

Collected Steps per Second: 22,248.84660
Overall Steps per Second: 10,487.56749

Timestep Collection Time: 2.24857
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.77022

Cumulative Model Updates: 115,118
Cumulative Timesteps: 959,973,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.70887
Value Function Loss: 0.02181

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.42093
Value Function Update Magnitude: 0.39023

Collected Steps per Second: 21,716.85178
Overall Steps per Second: 10,546.10294

Timestep Collection Time: 2.30236
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.74109

Cumulative Model Updates: 115,124
Cumulative Timesteps: 960,023,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 960023516...
Checkpoint 960023516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.74049
Value Function Loss: 0.01931

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.41456
Value Function Update Magnitude: 0.33872

Collected Steps per Second: 21,435.70824
Overall Steps per Second: 10,502.94502

Timestep Collection Time: 2.33368
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.76285

Cumulative Model Updates: 115,130
Cumulative Timesteps: 960,073,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.72680
Value Function Loss: 0.01982

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.41403
Value Function Update Magnitude: 0.41856

Collected Steps per Second: 21,419.86036
Overall Steps per Second: 10,489.08495

Timestep Collection Time: 2.33447
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.76724

Cumulative Model Updates: 115,136
Cumulative Timesteps: 960,123,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 960123544...
Checkpoint 960123544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,893.16681
Policy Entropy: 3.72464
Value Function Loss: 0.01963

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.54699

Collected Steps per Second: 21,777.21776
Overall Steps per Second: 10,598.93474

Timestep Collection Time: 2.29690
Timestep Consumption Time: 2.42245
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.71934

Cumulative Model Updates: 115,142
Cumulative Timesteps: 960,173,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,737.99840
Policy Entropy: 3.71827
Value Function Loss: 0.02057

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.43981
Value Function Update Magnitude: 0.60508

Collected Steps per Second: 22,058.64624
Overall Steps per Second: 10,488.44809

Timestep Collection Time: 2.26859
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.77115

Cumulative Model Updates: 115,148
Cumulative Timesteps: 960,223,606

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 960223606...
Checkpoint 960223606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,737.99840
Policy Entropy: 3.71401
Value Function Loss: 0.01875

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.45156
Value Function Update Magnitude: 0.66789

Collected Steps per Second: 22,102.49912
Overall Steps per Second: 10,577.53614

Timestep Collection Time: 2.26237
Timestep Consumption Time: 2.46501
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.72738

Cumulative Model Updates: 115,154
Cumulative Timesteps: 960,273,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615,737.99840
Policy Entropy: 3.71563
Value Function Loss: 0.01800

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.43126
Value Function Update Magnitude: 0.64693

Collected Steps per Second: 22,264.64562
Overall Steps per Second: 10,536.13922

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.74880

Cumulative Model Updates: 115,160
Cumulative Timesteps: 960,323,644

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 960323644...
Checkpoint 960323644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,519.76633
Policy Entropy: 3.71866
Value Function Loss: 0.01701

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.40417
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 21,713.48168
Overall Steps per Second: 10,332.48331

Timestep Collection Time: 2.30437
Timestep Consumption Time: 2.53822
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.84259

Cumulative Model Updates: 115,166
Cumulative Timesteps: 960,373,680

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,519.76633
Policy Entropy: 3.72460
Value Function Loss: 0.01690

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.40074
Value Function Update Magnitude: 0.59105

Collected Steps per Second: 22,243.89779
Overall Steps per Second: 10,508.29578

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.75834

Cumulative Model Updates: 115,172
Cumulative Timesteps: 960,423,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 960423682...
Checkpoint 960423682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,519.76633
Policy Entropy: 3.71932
Value Function Loss: 0.01651

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.39329
Value Function Update Magnitude: 0.53703

Collected Steps per Second: 22,211.60299
Overall Steps per Second: 10,466.39667

Timestep Collection Time: 2.25252
Timestep Consumption Time: 2.52773
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.78025

Cumulative Model Updates: 115,178
Cumulative Timesteps: 960,473,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,519.76633
Policy Entropy: 3.72601
Value Function Loss: 0.01555

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.37434
Value Function Update Magnitude: 0.44171

Collected Steps per Second: 22,298.01320
Overall Steps per Second: 10,479.25758

Timestep Collection Time: 2.24307
Timestep Consumption Time: 2.52979
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77286

Cumulative Model Updates: 115,184
Cumulative Timesteps: 960,523,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 960523730...
Checkpoint 960523730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,490.76711
Policy Entropy: 3.73687
Value Function Loss: 0.01732

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14657
Policy Update Magnitude: 0.39103
Value Function Update Magnitude: 0.37598

Collected Steps per Second: 21,047.17238
Overall Steps per Second: 10,392.71844

Timestep Collection Time: 2.37590
Timestep Consumption Time: 2.43574
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.81164

Cumulative Model Updates: 115,190
Cumulative Timesteps: 960,573,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,490.76711
Policy Entropy: 3.73634
Value Function Loss: 0.01745

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.40913
Value Function Update Magnitude: 0.49838

Collected Steps per Second: 21,602.96487
Overall Steps per Second: 10,647.78436

Timestep Collection Time: 2.31505
Timestep Consumption Time: 2.38189
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.69694

Cumulative Model Updates: 115,196
Cumulative Timesteps: 960,623,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 960623748...
Checkpoint 960623748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,490.76711
Policy Entropy: 3.73931
Value Function Loss: 0.01711

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14642
Policy Update Magnitude: 0.46541
Value Function Update Magnitude: 0.58811

Collected Steps per Second: 21,652.69259
Overall Steps per Second: 10,562.84270

Timestep Collection Time: 2.30955
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.73433

Cumulative Model Updates: 115,202
Cumulative Timesteps: 960,673,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,490.76711
Policy Entropy: 3.72967
Value Function Loss: 0.01979

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.47633
Value Function Update Magnitude: 0.54947

Collected Steps per Second: 20,663.34612
Overall Steps per Second: 9,934.78461

Timestep Collection Time: 2.42091
Timestep Consumption Time: 2.61433
PPO Batch Consumption Time: 0.30673
Total Iteration Time: 5.03524

Cumulative Model Updates: 115,208
Cumulative Timesteps: 960,723,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 960723780...
Checkpoint 960723780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,164.58318
Policy Entropy: 3.73563
Value Function Loss: 0.01944

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.45560
Value Function Update Magnitude: 0.46660

Collected Steps per Second: 20,943.94988
Overall Steps per Second: 10,204.18738

Timestep Collection Time: 2.38837
Timestep Consumption Time: 2.51373
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.90211

Cumulative Model Updates: 115,214
Cumulative Timesteps: 960,773,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,267.61464
Policy Entropy: 3.72916
Value Function Loss: 0.02144

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.44057
Value Function Update Magnitude: 0.48606

Collected Steps per Second: 20,568.27910
Overall Steps per Second: 10,166.22572

Timestep Collection Time: 2.43190
Timestep Consumption Time: 2.48831
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.92021

Cumulative Model Updates: 115,220
Cumulative Timesteps: 960,823,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 960823822...
Checkpoint 960823822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,996.65432
Policy Entropy: 3.74104
Value Function Loss: 0.02206

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.48624
Value Function Update Magnitude: 0.70869

Collected Steps per Second: 21,178.28663
Overall Steps per Second: 10,364.76190

Timestep Collection Time: 2.36261
Timestep Consumption Time: 2.46490
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.82751

Cumulative Model Updates: 115,226
Cumulative Timesteps: 960,873,858

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,434.45667
Policy Entropy: 3.75486
Value Function Loss: 0.02462

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.50932
Value Function Update Magnitude: 0.63793

Collected Steps per Second: 20,461.24425
Overall Steps per Second: 10,022.61700

Timestep Collection Time: 2.44501
Timestep Consumption Time: 2.54650
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.99151

Cumulative Model Updates: 115,232
Cumulative Timesteps: 960,923,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 960923886...
Checkpoint 960923886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,960.32633
Policy Entropy: 3.74785
Value Function Loss: 0.02410

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.52837
Value Function Update Magnitude: 0.58214

Collected Steps per Second: 20,443.55049
Overall Steps per Second: 10,136.73053

Timestep Collection Time: 2.44635
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.93374

Cumulative Model Updates: 115,238
Cumulative Timesteps: 960,973,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,581.12887
Policy Entropy: 3.74760
Value Function Loss: 0.02234

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.61158

Collected Steps per Second: 21,390.68355
Overall Steps per Second: 10,204.33126

Timestep Collection Time: 2.33812
Timestep Consumption Time: 2.56313
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.90125

Cumulative Model Updates: 115,244
Cumulative Timesteps: 961,023,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 961023912...
Checkpoint 961023912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694,300.99132
Policy Entropy: 3.72760
Value Function Loss: 0.02341

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.48482
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 21,418.91396
Overall Steps per Second: 10,326.66247

Timestep Collection Time: 2.33476
Timestep Consumption Time: 2.50785
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.84261

Cumulative Model Updates: 115,250
Cumulative Timesteps: 961,073,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,098.24321
Policy Entropy: 3.73539
Value Function Loss: 0.02168

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.49732
Value Function Update Magnitude: 0.59677

Collected Steps per Second: 21,442.09586
Overall Steps per Second: 10,267.83047

Timestep Collection Time: 2.33223
Timestep Consumption Time: 2.53812
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.87036

Cumulative Model Updates: 115,256
Cumulative Timesteps: 961,123,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 961123928...
Checkpoint 961123928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,426.58623
Policy Entropy: 3.73414
Value Function Loss: 0.02340

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.48843
Value Function Update Magnitude: 0.53944

Collected Steps per Second: 22,036.66882
Overall Steps per Second: 10,467.31547

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.77983

Cumulative Model Updates: 115,262
Cumulative Timesteps: 961,173,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,851.12138
Policy Entropy: 3.74519
Value Function Loss: 0.02024

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.45662
Value Function Update Magnitude: 0.49019

Collected Steps per Second: 21,214.31805
Overall Steps per Second: 10,424.20896

Timestep Collection Time: 2.35794
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.79864

Cumulative Model Updates: 115,268
Cumulative Timesteps: 961,223,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 961223982...
Checkpoint 961223982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.73974
Value Function Loss: 0.02076

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.42436
Value Function Update Magnitude: 0.49279

Collected Steps per Second: 20,854.32704
Overall Steps per Second: 10,419.09250

Timestep Collection Time: 2.39873
Timestep Consumption Time: 2.40245
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.80119

Cumulative Model Updates: 115,274
Cumulative Timesteps: 961,274,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.75656
Value Function Loss: 0.01779

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.40525
Value Function Update Magnitude: 0.50206

Collected Steps per Second: 20,749.28442
Overall Steps per Second: 10,270.70443

Timestep Collection Time: 2.41020
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.86919

Cumulative Model Updates: 115,280
Cumulative Timesteps: 961,324,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961324016...
Checkpoint 961324016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.73320
Value Function Loss: 0.02014

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.39084
Value Function Update Magnitude: 0.51205

Collected Steps per Second: 20,182.43172
Overall Steps per Second: 9,974.21640

Timestep Collection Time: 2.47899
Timestep Consumption Time: 2.53715
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 5.01613

Cumulative Model Updates: 115,286
Cumulative Timesteps: 961,374,048

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.73408
Value Function Loss: 0.01862

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.42436
Value Function Update Magnitude: 0.45519

Collected Steps per Second: 20,587.26831
Overall Steps per Second: 10,143.70149

Timestep Collection Time: 2.43053
Timestep Consumption Time: 2.50238
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.93291

Cumulative Model Updates: 115,292
Cumulative Timesteps: 961,424,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 961424086...
Checkpoint 961424086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.70574
Value Function Loss: 0.01733

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.41491
Value Function Update Magnitude: 0.46943

Collected Steps per Second: 22,079.16718
Overall Steps per Second: 10,657.70946

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69444

Cumulative Model Updates: 115,298
Cumulative Timesteps: 961,474,118

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,659.99965
Policy Entropy: 3.72804
Value Function Loss: 0.01695

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.41440
Value Function Update Magnitude: 0.43887

Collected Steps per Second: 21,718.57202
Overall Steps per Second: 10,395.71316

Timestep Collection Time: 2.30245
Timestep Consumption Time: 2.50780
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.81025

Cumulative Model Updates: 115,304
Cumulative Timesteps: 961,524,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 961524124...
Checkpoint 961524124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,664.96037
Policy Entropy: 3.72394
Value Function Loss: 0.01844

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.41553
Value Function Update Magnitude: 0.47875

Collected Steps per Second: 21,046.62082
Overall Steps per Second: 9,998.43455

Timestep Collection Time: 2.37644
Timestep Consumption Time: 2.62594
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 5.00238

Cumulative Model Updates: 115,310
Cumulative Timesteps: 961,574,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,880.97720
Policy Entropy: 3.71608
Value Function Loss: 0.02265

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.43811
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 20,085.74630
Overall Steps per Second: 10,134.96914

Timestep Collection Time: 2.49032
Timestep Consumption Time: 2.44506
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.93539

Cumulative Model Updates: 115,316
Cumulative Timesteps: 961,624,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 961624160...
Checkpoint 961624160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,116.25864
Policy Entropy: 3.72651
Value Function Loss: 0.02459

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.54517

Collected Steps per Second: 22,036.42748
Overall Steps per Second: 10,382.86676

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.54869
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.81948

Cumulative Model Updates: 115,322
Cumulative Timesteps: 961,674,200

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,306.65234
Policy Entropy: 3.71748
Value Function Loss: 0.02638

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.49743

Collected Steps per Second: 20,583.98347
Overall Steps per Second: 9,920.14958

Timestep Collection Time: 2.42927
Timestep Consumption Time: 2.61138
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 5.04065

Cumulative Model Updates: 115,328
Cumulative Timesteps: 961,724,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 961724204...
Checkpoint 961724204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.84843
Policy Entropy: 3.72347
Value Function Loss: 0.02539

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.51331
Value Function Update Magnitude: 0.49468

Collected Steps per Second: 19,265.31121
Overall Steps per Second: 9,810.70939

Timestep Collection Time: 2.59690
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 5.09953

Cumulative Model Updates: 115,334
Cumulative Timesteps: 961,774,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.84843
Policy Entropy: 3.71354
Value Function Loss: 0.02548

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.50977
Value Function Update Magnitude: 0.49243

Collected Steps per Second: 21,037.86669
Overall Steps per Second: 10,089.89211

Timestep Collection Time: 2.37733
Timestep Consumption Time: 2.57951
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.95684

Cumulative Model Updates: 115,340
Cumulative Timesteps: 961,824,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 961824248...
Checkpoint 961824248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.84843
Policy Entropy: 3.72478
Value Function Loss: 0.02279

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.49845
Value Function Update Magnitude: 0.44824

Collected Steps per Second: 21,401.82786
Overall Steps per Second: 10,300.42211

Timestep Collection Time: 2.33653
Timestep Consumption Time: 2.51822
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.85475

Cumulative Model Updates: 115,346
Cumulative Timesteps: 961,874,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.84843
Policy Entropy: 3.73335
Value Function Loss: 0.02146

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.48764
Value Function Update Magnitude: 0.54151

Collected Steps per Second: 19,569.27101
Overall Steps per Second: 9,991.53335

Timestep Collection Time: 2.55574
Timestep Consumption Time: 2.44990
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 5.00564

Cumulative Model Updates: 115,352
Cumulative Timesteps: 961,924,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 961924268...
Checkpoint 961924268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 397,069.14976
Policy Entropy: 3.72923
Value Function Loss: 0.02262

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.46730
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 19,567.19493
Overall Steps per Second: 9,666.29895

Timestep Collection Time: 2.55632
Timestep Consumption Time: 2.61836
PPO Batch Consumption Time: 0.31810
Total Iteration Time: 5.17468

Cumulative Model Updates: 115,358
Cumulative Timesteps: 961,974,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,874.07806
Policy Entropy: 3.72880
Value Function Loss: 0.02351

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.48626
Value Function Update Magnitude: 0.65956

Collected Steps per Second: 20,336.03736
Overall Steps per Second: 10,305.17301

Timestep Collection Time: 2.45967
Timestep Consumption Time: 2.39420
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.85387

Cumulative Model Updates: 115,364
Cumulative Timesteps: 962,024,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 962024308...
Checkpoint 962024308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,874.07806
Policy Entropy: 3.72075
Value Function Loss: 0.02332

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.50242
Value Function Update Magnitude: 0.64546

Collected Steps per Second: 19,960.91888
Overall Steps per Second: 9,992.14189

Timestep Collection Time: 2.50499
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 5.00413

Cumulative Model Updates: 115,370
Cumulative Timesteps: 962,074,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,874.07806
Policy Entropy: 3.71996
Value Function Loss: 0.02249

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.48427
Value Function Update Magnitude: 0.53281

Collected Steps per Second: 20,841.84915
Overall Steps per Second: 10,114.86697

Timestep Collection Time: 2.39921
Timestep Consumption Time: 2.54440
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.94361

Cumulative Model Updates: 115,376
Cumulative Timesteps: 962,124,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 962124314...
Checkpoint 962124314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,604.08119
Policy Entropy: 3.71721
Value Function Loss: 0.02098

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.46840
Value Function Update Magnitude: 0.51437

Collected Steps per Second: 19,868.51805
Overall Steps per Second: 9,946.64081

Timestep Collection Time: 2.51735
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 5.02843

Cumulative Model Updates: 115,382
Cumulative Timesteps: 962,174,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,604.08119
Policy Entropy: 3.72009
Value Function Loss: 0.01964

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.45282
Value Function Update Magnitude: 0.47596

Collected Steps per Second: 20,450.95969
Overall Steps per Second: 9,949.34499

Timestep Collection Time: 2.44566
Timestep Consumption Time: 2.58141
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 5.02706

Cumulative Model Updates: 115,388
Cumulative Timesteps: 962,224,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 962224346...
Checkpoint 962224346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,604.08119
Policy Entropy: 3.72521
Value Function Loss: 0.01652

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.43717
Value Function Update Magnitude: 0.42664

Collected Steps per Second: 20,276.98228
Overall Steps per Second: 10,186.91067

Timestep Collection Time: 2.46684
Timestep Consumption Time: 2.44339
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.91022

Cumulative Model Updates: 115,394
Cumulative Timesteps: 962,274,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,604.08119
Policy Entropy: 3.72717
Value Function Loss: 0.01665

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.41489
Value Function Update Magnitude: 0.44732

Collected Steps per Second: 20,751.67578
Overall Steps per Second: 10,051.38354

Timestep Collection Time: 2.41060
Timestep Consumption Time: 2.56623
PPO Batch Consumption Time: 0.29836
Total Iteration Time: 4.97683

Cumulative Model Updates: 115,400
Cumulative Timesteps: 962,324,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 962324390...
Checkpoint 962324390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,501.73146
Policy Entropy: 3.72411
Value Function Loss: 0.02056

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.45762
Value Function Update Magnitude: 0.53969

Collected Steps per Second: 19,698.32145
Overall Steps per Second: 9,576.67350

Timestep Collection Time: 2.53879
Timestep Consumption Time: 2.68327
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 5.22206

Cumulative Model Updates: 115,406
Cumulative Timesteps: 962,374,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,280.63266
Policy Entropy: 3.71960
Value Function Loss: 0.02274

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 0.53795
Value Function Update Magnitude: 0.67420

Collected Steps per Second: 20,634.51803
Overall Steps per Second: 9,999.99940

Timestep Collection Time: 2.42351
Timestep Consumption Time: 2.57729
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 5.00080

Cumulative Model Updates: 115,412
Cumulative Timesteps: 962,424,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 962424408...
Checkpoint 962424408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,449.36942
Policy Entropy: 3.72014
Value Function Loss: 0.02545

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.63676

Collected Steps per Second: 19,877.40505
Overall Steps per Second: 9,768.24166

Timestep Collection Time: 2.51612
Timestep Consumption Time: 2.60394
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 5.12006

Cumulative Model Updates: 115,418
Cumulative Timesteps: 962,474,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,449.36942
Policy Entropy: 3.71606
Value Function Loss: 0.02345

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.51067
Value Function Update Magnitude: 0.55535

Collected Steps per Second: 20,223.09031
Overall Steps per Second: 9,927.35551

Timestep Collection Time: 2.47361
Timestep Consumption Time: 2.56540
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 5.03901

Cumulative Model Updates: 115,424
Cumulative Timesteps: 962,524,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 962524446...
Checkpoint 962524446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,449.36942
Policy Entropy: 3.70493
Value Function Loss: 0.02225

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.48543

Collected Steps per Second: 18,654.39807
Overall Steps per Second: 9,390.78018

Timestep Collection Time: 2.68141
Timestep Consumption Time: 2.64510
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 5.32650

Cumulative Model Updates: 115,430
Cumulative Timesteps: 962,574,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,449.36942
Policy Entropy: 3.70342
Value Function Loss: 0.02145

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.49590
Value Function Update Magnitude: 0.51737

Collected Steps per Second: 17,158.72638
Overall Steps per Second: 9,031.73495

Timestep Collection Time: 2.91479
Timestep Consumption Time: 2.62280
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 5.53759

Cumulative Model Updates: 115,436
Cumulative Timesteps: 962,624,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 962624480...
Checkpoint 962624480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,135.89987
Policy Entropy: 3.70669
Value Function Loss: 0.02038

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 18,481.46466
Overall Steps per Second: 9,249.49778

Timestep Collection Time: 2.70617
Timestep Consumption Time: 2.70104
PPO Batch Consumption Time: 0.30877
Total Iteration Time: 5.40721

Cumulative Model Updates: 115,442
Cumulative Timesteps: 962,674,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837,682.38305
Policy Entropy: 3.72056
Value Function Loss: 0.02242

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.53771
Value Function Update Magnitude: 0.73592

Collected Steps per Second: 20,174.80394
Overall Steps per Second: 9,886.76373

Timestep Collection Time: 2.47943
Timestep Consumption Time: 2.58006
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 5.05949

Cumulative Model Updates: 115,448
Cumulative Timesteps: 962,724,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 962724516...
Checkpoint 962724516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,776.12534
Policy Entropy: 3.75139
Value Function Loss: 0.02451

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.77035

Collected Steps per Second: 20,980.18896
Overall Steps per Second: 10,026.14027

Timestep Collection Time: 2.38473
Timestep Consumption Time: 2.60543
PPO Batch Consumption Time: 0.29994
Total Iteration Time: 4.99016

Cumulative Model Updates: 115,454
Cumulative Timesteps: 962,774,548

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,579.64161
Policy Entropy: 3.77268
Value Function Loss: 0.02441

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.63641
Value Function Update Magnitude: 0.81349

Collected Steps per Second: 21,593.91732
Overall Steps per Second: 10,359.67381

Timestep Collection Time: 2.31565
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.82679

Cumulative Model Updates: 115,460
Cumulative Timesteps: 962,824,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 962824552...
Checkpoint 962824552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.53364
Policy Entropy: 3.77026
Value Function Loss: 0.02385

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.73740
Value Function Update Magnitude: 0.86102

Collected Steps per Second: 21,565.26751
Overall Steps per Second: 10,192.34778

Timestep Collection Time: 2.32077
Timestep Consumption Time: 2.58958
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 4.91035

Cumulative Model Updates: 115,466
Cumulative Timesteps: 962,874,600

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,860.41456
Policy Entropy: 3.74325
Value Function Loss: 0.02290

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.21249
Policy Update Magnitude: 0.68022
Value Function Update Magnitude: 0.69101

Collected Steps per Second: 21,606.79352
Overall Steps per Second: 10,426.70693

Timestep Collection Time: 2.31409
Timestep Consumption Time: 2.48129
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.79538

Cumulative Model Updates: 115,472
Cumulative Timesteps: 962,924,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 962924600...
Checkpoint 962924600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,229.05388
Policy Entropy: 3.68200
Value Function Loss: 0.03845

Mean KL Divergence: 0.02839
SB3 Clip Fraction: 0.29563
Policy Update Magnitude: 0.51835
Value Function Update Magnitude: 0.53409

Collected Steps per Second: 20,510.51360
Overall Steps per Second: 10,104.82080

Timestep Collection Time: 2.43904
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.30112
Total Iteration Time: 4.95071

Cumulative Model Updates: 115,478
Cumulative Timesteps: 962,974,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613,596.13953
Policy Entropy: 3.67838
Value Function Loss: 0.04482

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.20602
Policy Update Magnitude: 0.61671
Value Function Update Magnitude: 0.55581

Collected Steps per Second: 19,593.12967
Overall Steps per Second: 9,919.27422

Timestep Collection Time: 2.55202
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 5.04089

Cumulative Model Updates: 115,484
Cumulative Timesteps: 963,024,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963024628...
Checkpoint 963024628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,563.61262
Policy Entropy: 3.70632
Value Function Loss: 0.04645

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.22243
Policy Update Magnitude: 0.76326
Value Function Update Magnitude: 0.74273

Collected Steps per Second: 19,973.55098
Overall Steps per Second: 9,970.78742

Timestep Collection Time: 2.50391
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 5.01585

Cumulative Model Updates: 115,490
Cumulative Timesteps: 963,074,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296,109.94305
Policy Entropy: 3.73786
Value Function Loss: 0.03544

Mean KL Divergence: 0.02831
SB3 Clip Fraction: 0.28581
Policy Update Magnitude: 0.74366
Value Function Update Magnitude: 0.75012

Collected Steps per Second: 19,377.69625
Overall Steps per Second: 10,025.25896

Timestep Collection Time: 2.58132
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.98940

Cumulative Model Updates: 115,496
Cumulative Timesteps: 963,124,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963124660...
Checkpoint 963124660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,721.13602
Policy Entropy: 3.77506
Value Function Loss: 0.03374

Mean KL Divergence: 0.03132
SB3 Clip Fraction: 0.31180
Policy Update Magnitude: 0.63754
Value Function Update Magnitude: 0.74987

Collected Steps per Second: 20,932.50097
Overall Steps per Second: 10,410.77767

Timestep Collection Time: 2.38882
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.80310

Cumulative Model Updates: 115,502
Cumulative Timesteps: 963,174,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,162.14074
Policy Entropy: 3.78894
Value Function Loss: 0.04015

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.21446
Policy Update Magnitude: 0.76919
Value Function Update Magnitude: 0.79982

Collected Steps per Second: 20,171.24843
Overall Steps per Second: 9,918.29850

Timestep Collection Time: 2.48096
Timestep Consumption Time: 2.56467
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.04562

Cumulative Model Updates: 115,508
Cumulative Timesteps: 963,224,708

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 963224708...
Checkpoint 963224708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,700.37518
Policy Entropy: 3.83049
Value Function Loss: 0.04407

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.19735
Policy Update Magnitude: 0.80794
Value Function Update Magnitude: 0.75753

Collected Steps per Second: 21,591.87574
Overall Steps per Second: 10,266.91306

Timestep Collection Time: 2.31670
Timestep Consumption Time: 2.55545
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.87216

Cumulative Model Updates: 115,514
Cumulative Timesteps: 963,274,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.54694
Policy Entropy: 3.83357
Value Function Loss: 0.03990

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.81175
Value Function Update Magnitude: 0.96435

Collected Steps per Second: 20,803.55844
Overall Steps per Second: 10,043.60258

Timestep Collection Time: 2.40478
Timestep Consumption Time: 2.57630
PPO Batch Consumption Time: 0.30226
Total Iteration Time: 4.98108

Cumulative Model Updates: 115,520
Cumulative Timesteps: 963,324,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 963324758...
Checkpoint 963324758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,824.31251
Policy Entropy: 3.79616
Value Function Loss: 0.03497

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.80116
Value Function Update Magnitude: 0.93172

Collected Steps per Second: 20,521.80790
Overall Steps per Second: 10,158.72185

Timestep Collection Time: 2.43692
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.92286

Cumulative Model Updates: 115,526
Cumulative Timesteps: 963,374,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,291.18041
Policy Entropy: 3.74803
Value Function Loss: 0.02992

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.81293
Value Function Update Magnitude: 0.93785

Collected Steps per Second: 19,821.77206
Overall Steps per Second: 9,682.41527

Timestep Collection Time: 2.52369
Timestep Consumption Time: 2.64279
PPO Batch Consumption Time: 0.30484
Total Iteration Time: 5.16648

Cumulative Model Updates: 115,532
Cumulative Timesteps: 963,424,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 963424792...
Checkpoint 963424792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,827.74178
Policy Entropy: 3.74547
Value Function Loss: 0.03619

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16534
Policy Update Magnitude: 0.78419
Value Function Update Magnitude: 0.92747

Collected Steps per Second: 21,149.00550
Overall Steps per Second: 10,205.48379

Timestep Collection Time: 2.36550
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.90207

Cumulative Model Updates: 115,538
Cumulative Timesteps: 963,474,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.21244
Policy Entropy: 3.79098
Value Function Loss: 0.03755

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15365
Policy Update Magnitude: 0.78938
Value Function Update Magnitude: 1.01959

Collected Steps per Second: 21,153.80491
Overall Steps per Second: 10,430.61896

Timestep Collection Time: 2.36411
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.79454

Cumulative Model Updates: 115,544
Cumulative Timesteps: 963,524,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 963524830...
Checkpoint 963524830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,324.47649
Policy Entropy: 3.84259
Value Function Loss: 0.04212

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.92157
Value Function Update Magnitude: 0.92751

Collected Steps per Second: 22,175.25482
Overall Steps per Second: 10,660.17637

Timestep Collection Time: 2.25594
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.69279

Cumulative Model Updates: 115,550
Cumulative Timesteps: 963,574,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,640.48115
Policy Entropy: 3.84783
Value Function Loss: 0.04217

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.99925
Value Function Update Magnitude: 0.80913

Collected Steps per Second: 22,148.82590
Overall Steps per Second: 10,417.21895

Timestep Collection Time: 2.25764
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.80013

Cumulative Model Updates: 115,556
Cumulative Timesteps: 963,624,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 963624860...
Checkpoint 963624860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,024.18166
Policy Entropy: 3.82602
Value Function Loss: 0.03662

Mean KL Divergence: 0.02156
SB3 Clip Fraction: 0.25386
Policy Update Magnitude: 0.82560
Value Function Update Magnitude: 0.72245

Collected Steps per Second: 22,126.79465
Overall Steps per Second: 10,382.79653

Timestep Collection Time: 2.25979
Timestep Consumption Time: 2.55606
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.81585

Cumulative Model Updates: 115,562
Cumulative Timesteps: 963,674,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,595.92935
Policy Entropy: 3.77645
Value Function Loss: 0.04084

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.24546
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.70751

Collected Steps per Second: 21,839.72276
Overall Steps per Second: 10,175.03426

Timestep Collection Time: 2.29115
Timestep Consumption Time: 2.62658
PPO Batch Consumption Time: 0.30989
Total Iteration Time: 4.91772

Cumulative Model Updates: 115,568
Cumulative Timesteps: 963,724,900

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 963724900...
Checkpoint 963724900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,164.67722
Policy Entropy: 3.75330
Value Function Loss: 0.04583

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.21932
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.72205

Collected Steps per Second: 20,509.82166
Overall Steps per Second: 10,062.98146

Timestep Collection Time: 2.43854
Timestep Consumption Time: 2.53156
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.97010

Cumulative Model Updates: 115,574
Cumulative Timesteps: 963,774,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,462.58267
Policy Entropy: 3.74875
Value Function Loss: 0.04960

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.19547
Policy Update Magnitude: 0.64862
Value Function Update Magnitude: 0.69626

Collected Steps per Second: 20,217.19870
Overall Steps per Second: 10,042.22097

Timestep Collection Time: 2.47453
Timestep Consumption Time: 2.50724
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.98177

Cumulative Model Updates: 115,580
Cumulative Timesteps: 963,824,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 963824942...
Checkpoint 963824942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,227.87162
Policy Entropy: 3.79813
Value Function Loss: 0.05329

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.70164
Value Function Update Magnitude: 0.70800

Collected Steps per Second: 19,712.48108
Overall Steps per Second: 9,853.12616

Timestep Collection Time: 2.53859
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 5.07879

Cumulative Model Updates: 115,586
Cumulative Timesteps: 963,874,984

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325,369.71777
Policy Entropy: 3.87765
Value Function Loss: 0.04826

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.14645
Policy Update Magnitude: 0.83985
Value Function Update Magnitude: 0.93362

Collected Steps per Second: 19,626.24499
Overall Steps per Second: 9,906.49939

Timestep Collection Time: 2.54802
Timestep Consumption Time: 2.49998
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 5.04800

Cumulative Model Updates: 115,592
Cumulative Timesteps: 963,924,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 963924992...
Checkpoint 963924992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.36275
Policy Entropy: 3.93753
Value Function Loss: 0.04478

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.96893
Value Function Update Magnitude: 0.97477

Collected Steps per Second: 19,712.60626
Overall Steps per Second: 9,722.38152

Timestep Collection Time: 2.53756
Timestep Consumption Time: 2.60747
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 5.14504

Cumulative Model Updates: 115,598
Cumulative Timesteps: 963,975,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,979.72497
Policy Entropy: 4.03385
Value Function Loss: 0.03526

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 1.13719
Value Function Update Magnitude: 0.98155

Collected Steps per Second: 20,691.14395
Overall Steps per Second: 10,244.91689

Timestep Collection Time: 2.41717
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.30580
Total Iteration Time: 4.88184

Cumulative Model Updates: 115,604
Cumulative Timesteps: 964,025,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 964025028...
Checkpoint 964025028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.72468
Policy Entropy: 4.09750
Value Function Loss: 0.02816

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08890
Policy Update Magnitude: 1.21898
Value Function Update Magnitude: 1.23767

Collected Steps per Second: 18,950.40031
Overall Steps per Second: 9,517.64261

Timestep Collection Time: 2.63931
Timestep Consumption Time: 2.61577
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 5.25508

Cumulative Model Updates: 115,610
Cumulative Timesteps: 964,075,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.80240
Policy Entropy: 4.12138
Value Function Loss: 0.02896

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.07872
Policy Update Magnitude: 1.12854
Value Function Update Magnitude: 1.28715

Collected Steps per Second: 20,928.12721
Overall Steps per Second: 10,048.77590

Timestep Collection Time: 2.38970
Timestep Consumption Time: 2.58722
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.97692

Cumulative Model Updates: 115,616
Cumulative Timesteps: 964,125,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 964125056...
Checkpoint 964125056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.01441
Policy Entropy: 4.11334
Value Function Loss: 0.03193

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 1.02802
Value Function Update Magnitude: 1.29982

Collected Steps per Second: 20,677.36654
Overall Steps per Second: 10,108.61300

Timestep Collection Time: 2.41810
Timestep Consumption Time: 2.52817
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.94628

Cumulative Model Updates: 115,622
Cumulative Timesteps: 964,175,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,496.09873
Policy Entropy: 4.08436
Value Function Loss: 0.03385

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06242
Policy Update Magnitude: 0.98395
Value Function Update Magnitude: 1.21481

Collected Steps per Second: 20,909.92622
Overall Steps per Second: 10,160.47638

Timestep Collection Time: 2.39236
Timestep Consumption Time: 2.53103
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.92339

Cumulative Model Updates: 115,628
Cumulative Timesteps: 964,225,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 964225080...
Checkpoint 964225080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.75994
Policy Entropy: 4.07470
Value Function Loss: 0.03316

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06165
Policy Update Magnitude: 0.97039
Value Function Update Magnitude: 1.19189

Collected Steps per Second: 20,581.31620
Overall Steps per Second: 9,935.98259

Timestep Collection Time: 2.42968
Timestep Consumption Time: 2.60314
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 5.03282

Cumulative Model Updates: 115,634
Cumulative Timesteps: 964,275,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,345.32489
Policy Entropy: 4.04071
Value Function Loss: 0.03141

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.94439
Value Function Update Magnitude: 1.20813

Collected Steps per Second: 20,465.42099
Overall Steps per Second: 10,174.97064

Timestep Collection Time: 2.44412
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.91598

Cumulative Model Updates: 115,640
Cumulative Timesteps: 964,325,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 964325106...
Checkpoint 964325106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.80599
Policy Entropy: 4.00712
Value Function Loss: 0.03374

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06469
Policy Update Magnitude: 0.93456
Value Function Update Magnitude: 1.18346

Collected Steps per Second: 21,179.28579
Overall Steps per Second: 10,472.40801

Timestep Collection Time: 2.36297
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.77884

Cumulative Model Updates: 115,646
Cumulative Timesteps: 964,375,152

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.43346
Policy Entropy: 3.95933
Value Function Loss: 0.03412

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06606
Policy Update Magnitude: 0.92000
Value Function Update Magnitude: 1.05000

Collected Steps per Second: 21,329.07667
Overall Steps per Second: 10,428.85698

Timestep Collection Time: 2.34525
Timestep Consumption Time: 2.45125
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.79650

Cumulative Model Updates: 115,652
Cumulative Timesteps: 964,425,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 964425174...
Checkpoint 964425174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554.45572
Policy Entropy: 3.94115
Value Function Loss: 0.03107

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.87405
Value Function Update Magnitude: 0.95870

Collected Steps per Second: 20,977.46426
Overall Steps per Second: 10,331.63302

Timestep Collection Time: 2.38399
Timestep Consumption Time: 2.45649
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.84047

Cumulative Model Updates: 115,658
Cumulative Timesteps: 964,475,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.60312
Policy Entropy: 3.92191
Value Function Loss: 0.02977

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.79716
Value Function Update Magnitude: 0.90988

Collected Steps per Second: 21,842.80128
Overall Steps per Second: 10,339.20468

Timestep Collection Time: 2.28954
Timestep Consumption Time: 2.54739
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.83693

Cumulative Model Updates: 115,664
Cumulative Timesteps: 964,525,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 964525194...
Checkpoint 964525194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231.93270
Policy Entropy: 3.92798
Value Function Loss: 0.03037

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05121
Policy Update Magnitude: 0.76789
Value Function Update Magnitude: 0.91529

Collected Steps per Second: 21,893.52649
Overall Steps per Second: 10,354.52337

Timestep Collection Time: 2.28415
Timestep Consumption Time: 2.54543
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.82958

Cumulative Model Updates: 115,670
Cumulative Timesteps: 964,575,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,855.29829
Policy Entropy: 3.91922
Value Function Loss: 0.03332

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.84466
Value Function Update Magnitude: 0.87506

Collected Steps per Second: 21,734.29827
Overall Steps per Second: 10,251.57245

Timestep Collection Time: 2.30116
Timestep Consumption Time: 2.57751
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.87867

Cumulative Model Updates: 115,676
Cumulative Timesteps: 964,625,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 964625216...
Checkpoint 964625216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.36789
Policy Entropy: 3.91096
Value Function Loss: 0.03319

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08003
Policy Update Magnitude: 0.79258
Value Function Update Magnitude: 0.90235

Collected Steps per Second: 21,943.14833
Overall Steps per Second: 10,405.57114

Timestep Collection Time: 2.28108
Timestep Consumption Time: 2.52923
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.81031

Cumulative Model Updates: 115,682
Cumulative Timesteps: 964,675,270

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,182.90747
Policy Entropy: 3.86333
Value Function Loss: 0.04050

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.17006
Policy Update Magnitude: 0.62547
Value Function Update Magnitude: 0.74041

Collected Steps per Second: 21,861.97748
Overall Steps per Second: 10,349.67054

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.54410
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.83126

Cumulative Model Updates: 115,688
Cumulative Timesteps: 964,725,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 964725272...
Checkpoint 964725272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,768.61578
Policy Entropy: 3.84104
Value Function Loss: 0.04443

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.63075
Value Function Update Magnitude: 0.72412

Collected Steps per Second: 20,903.69651
Overall Steps per Second: 10,166.45403

Timestep Collection Time: 2.39211
Timestep Consumption Time: 2.52642
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.91853

Cumulative Model Updates: 115,694
Cumulative Timesteps: 964,775,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,771.20546
Policy Entropy: 3.84984
Value Function Loss: 0.04512

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.19589
Policy Update Magnitude: 0.69568
Value Function Update Magnitude: 0.65932

Collected Steps per Second: 20,898.02079
Overall Steps per Second: 10,386.53569

Timestep Collection Time: 2.39353
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.81585

Cumulative Model Updates: 115,700
Cumulative Timesteps: 964,825,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 964825296...
Checkpoint 964825296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,839.68428
Policy Entropy: 3.85918
Value Function Loss: 0.03909

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15944
Policy Update Magnitude: 0.61431
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 20,174.61353
Overall Steps per Second: 10,240.10321

Timestep Collection Time: 2.47945
Timestep Consumption Time: 2.40546
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.88491

Cumulative Model Updates: 115,706
Cumulative Timesteps: 964,875,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,748.42600
Policy Entropy: 3.88128
Value Function Loss: 0.03394

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.60282
Value Function Update Magnitude: 0.70280

Collected Steps per Second: 20,176.97714
Overall Steps per Second: 10,041.74214

Timestep Collection Time: 2.48025
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29761
Total Iteration Time: 4.98360

Cumulative Model Updates: 115,712
Cumulative Timesteps: 964,925,362

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 964925362...
Checkpoint 964925362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391.01246
Policy Entropy: 3.86031
Value Function Loss: 0.03473

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17238
Policy Update Magnitude: 0.61094
Value Function Update Magnitude: 0.79943

Collected Steps per Second: 19,764.17122
Overall Steps per Second: 9,878.27044

Timestep Collection Time: 2.53044
Timestep Consumption Time: 2.53239
PPO Batch Consumption Time: 0.30622
Total Iteration Time: 5.06283

Cumulative Model Updates: 115,718
Cumulative Timesteps: 964,975,374

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.84738
Policy Entropy: 3.89266
Value Function Loss: 0.03320

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11394
Policy Update Magnitude: 0.74198
Value Function Update Magnitude: 0.75491

Collected Steps per Second: 20,455.18240
Overall Steps per Second: 10,101.91589

Timestep Collection Time: 2.44525
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.95134

Cumulative Model Updates: 115,724
Cumulative Timesteps: 965,025,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 965025392...
Checkpoint 965025392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,639.97015
Policy Entropy: 3.89237
Value Function Loss: 0.03537

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.84501
Value Function Update Magnitude: 0.71308

Collected Steps per Second: 20,287.40902
Overall Steps per Second: 10,068.73255

Timestep Collection Time: 2.46537
Timestep Consumption Time: 2.50209
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.96746

Cumulative Model Updates: 115,730
Cumulative Timesteps: 965,075,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,333.74221
Policy Entropy: 3.89189
Value Function Loss: 0.03613

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.84002
Value Function Update Magnitude: 0.76876

Collected Steps per Second: 21,077.84871
Overall Steps per Second: 9,921.06668

Timestep Collection Time: 2.37282
Timestep Consumption Time: 2.66837
PPO Batch Consumption Time: 0.31824
Total Iteration Time: 5.04119

Cumulative Model Updates: 115,736
Cumulative Timesteps: 965,125,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 965125422...
Checkpoint 965125422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,520.90919
Policy Entropy: 3.85207
Value Function Loss: 0.03614

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.16041
Policy Update Magnitude: 0.82660
Value Function Update Magnitude: 0.75284

Collected Steps per Second: 21,177.89350
Overall Steps per Second: 10,484.56392

Timestep Collection Time: 2.36152
Timestep Consumption Time: 2.40854
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.77006

Cumulative Model Updates: 115,742
Cumulative Timesteps: 965,175,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,598.58684
Policy Entropy: 3.80380
Value Function Loss: 0.04598

Mean KL Divergence: 0.02694
SB3 Clip Fraction: 0.27805
Policy Update Magnitude: 0.62061
Value Function Update Magnitude: 0.64483

Collected Steps per Second: 21,606.81980
Overall Steps per Second: 10,214.81595

Timestep Collection Time: 2.31557
Timestep Consumption Time: 2.58242
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 4.89798

Cumulative Model Updates: 115,748
Cumulative Timesteps: 965,225,466

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 965225466...
Checkpoint 965225466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.71557
Policy Entropy: 3.85915
Value Function Loss: 0.05516

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.22438
Policy Update Magnitude: 0.59350
Value Function Update Magnitude: 0.54264

Collected Steps per Second: 20,344.68680
Overall Steps per Second: 9,931.66378

Timestep Collection Time: 2.45892
Timestep Consumption Time: 2.57810
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 5.03702

Cumulative Model Updates: 115,754
Cumulative Timesteps: 965,275,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,734.71335
Policy Entropy: 3.91576
Value Function Loss: 0.05522

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.17479
Policy Update Magnitude: 0.62626
Value Function Update Magnitude: 0.54424

Collected Steps per Second: 20,739.20094
Overall Steps per Second: 10,115.62844

Timestep Collection Time: 2.41205
Timestep Consumption Time: 2.53317
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.94522

Cumulative Model Updates: 115,760
Cumulative Timesteps: 965,325,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 965325516...
Checkpoint 965325516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,781.31930
Policy Entropy: 3.99740
Value Function Loss: 0.04563

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.91461
Value Function Update Magnitude: 0.69689

Collected Steps per Second: 19,367.98071
Overall Steps per Second: 9,831.88572

Timestep Collection Time: 2.58251
Timestep Consumption Time: 2.50482
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 5.08733

Cumulative Model Updates: 115,766
Cumulative Timesteps: 965,375,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.77984
Policy Entropy: 4.01164
Value Function Loss: 0.03786

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 1.10819
Value Function Update Magnitude: 0.92478

Collected Steps per Second: 20,758.88006
Overall Steps per Second: 10,131.71554

Timestep Collection Time: 2.40996
Timestep Consumption Time: 2.52781
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.93776

Cumulative Model Updates: 115,772
Cumulative Timesteps: 965,425,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 965425562...
Checkpoint 965425562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.53417
Policy Entropy: 3.97939
Value Function Loss: 0.03744

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08132
Policy Update Magnitude: 1.10164
Value Function Update Magnitude: 0.82262

Collected Steps per Second: 20,942.12784
Overall Steps per Second: 10,168.14512

Timestep Collection Time: 2.38887
Timestep Consumption Time: 2.53120
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.92007

Cumulative Model Updates: 115,778
Cumulative Timesteps: 965,475,590

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,472.26289
Policy Entropy: 3.95548
Value Function Loss: 0.04097

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 1.09560
Value Function Update Magnitude: 0.87130

Collected Steps per Second: 20,629.55630
Overall Steps per Second: 9,997.13362

Timestep Collection Time: 2.42371
Timestep Consumption Time: 2.57773
PPO Batch Consumption Time: 0.30253
Total Iteration Time: 5.00143

Cumulative Model Updates: 115,784
Cumulative Timesteps: 965,525,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 965525590...
Checkpoint 965525590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.39534
Policy Entropy: 3.94848
Value Function Loss: 0.03988

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 1.10754
Value Function Update Magnitude: 1.00127

Collected Steps per Second: 19,976.91647
Overall Steps per Second: 9,821.34522

Timestep Collection Time: 2.50369
Timestep Consumption Time: 2.58889
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.09258

Cumulative Model Updates: 115,790
Cumulative Timesteps: 965,575,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.55736
Policy Entropy: 3.93907
Value Function Loss: 0.04051

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06925
Policy Update Magnitude: 1.05001
Value Function Update Magnitude: 1.05946

Collected Steps per Second: 19,915.54167
Overall Steps per Second: 9,916.86292

Timestep Collection Time: 2.51201
Timestep Consumption Time: 2.53273
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 5.04474

Cumulative Model Updates: 115,796
Cumulative Timesteps: 965,625,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 965625634...
Checkpoint 965625634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.84039
Policy Entropy: 3.91092
Value Function Loss: 0.04181

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 1.02074
Value Function Update Magnitude: 0.82379

Collected Steps per Second: 19,066.73039
Overall Steps per Second: 9,812.46158

Timestep Collection Time: 2.62352
Timestep Consumption Time: 2.47428
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 5.09780

Cumulative Model Updates: 115,802
Cumulative Timesteps: 965,675,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387.46308
Policy Entropy: 3.87226
Value Function Loss: 0.04257

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.96233
Value Function Update Magnitude: 0.72706

Collected Steps per Second: 20,018.30931
Overall Steps per Second: 10,048.00573

Timestep Collection Time: 2.49971
Timestep Consumption Time: 2.48038
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.98009

Cumulative Model Updates: 115,808
Cumulative Timesteps: 965,725,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 965725696...
Checkpoint 965725696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.15908
Policy Entropy: 3.84983
Value Function Loss: 0.03360

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.76282
Value Function Update Magnitude: 0.57854

Collected Steps per Second: 18,748.91594
Overall Steps per Second: 9,481.78607

Timestep Collection Time: 2.66821
Timestep Consumption Time: 2.60780
PPO Batch Consumption Time: 0.30930
Total Iteration Time: 5.27601

Cumulative Model Updates: 115,814
Cumulative Timesteps: 965,775,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.75740
Policy Entropy: 3.81278
Value Function Loss: 0.02782

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.52299
Value Function Update Magnitude: 0.58907

Collected Steps per Second: 20,137.16526
Overall Steps per Second: 9,715.12095

Timestep Collection Time: 2.48387
Timestep Consumption Time: 2.66460
PPO Batch Consumption Time: 0.32191
Total Iteration Time: 5.14847

Cumulative Model Updates: 115,820
Cumulative Timesteps: 965,825,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 965825740...
Checkpoint 965825740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,762.19796
Policy Entropy: 3.79532
Value Function Loss: 0.02559

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.41167
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 20,585.22283
Overall Steps per Second: 10,169.72020

Timestep Collection Time: 2.42922
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.91715

Cumulative Model Updates: 115,826
Cumulative Timesteps: 965,875,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.45173
Policy Entropy: 3.78346
Value Function Loss: 0.03002

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15296
Policy Update Magnitude: 0.39762
Value Function Update Magnitude: 0.79462

Collected Steps per Second: 21,994.90374
Overall Steps per Second: 10,096.91704

Timestep Collection Time: 2.27425
Timestep Consumption Time: 2.67993
PPO Batch Consumption Time: 0.29859
Total Iteration Time: 4.95419

Cumulative Model Updates: 115,832
Cumulative Timesteps: 965,925,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 965925768...
Checkpoint 965925768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.18770
Policy Entropy: 3.80562
Value Function Loss: 0.03161

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.49429
Value Function Update Magnitude: 0.86602

Collected Steps per Second: 20,555.01837
Overall Steps per Second: 10,114.30605

Timestep Collection Time: 2.43376
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.94606

Cumulative Model Updates: 115,838
Cumulative Timesteps: 965,975,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,962.65541
Policy Entropy: 3.81397
Value Function Loss: 0.04013

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.52571
Value Function Update Magnitude: 0.70974

Collected Steps per Second: 20,882.09858
Overall Steps per Second: 10,063.12919

Timestep Collection Time: 2.39583
Timestep Consumption Time: 2.57578
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.97161

Cumulative Model Updates: 115,844
Cumulative Timesteps: 966,025,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 966025824...
Checkpoint 966025824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,950.35337
Policy Entropy: 3.84654
Value Function Loss: 0.04039

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.52983
Value Function Update Magnitude: 0.73459

Collected Steps per Second: 20,530.53838
Overall Steps per Second: 10,218.58470

Timestep Collection Time: 2.43579
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.89383

Cumulative Model Updates: 115,850
Cumulative Timesteps: 966,075,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180.45964
Policy Entropy: 3.83589
Value Function Loss: 0.04146

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.53571
Value Function Update Magnitude: 0.73993

Collected Steps per Second: 21,443.04555
Overall Steps per Second: 10,412.02473

Timestep Collection Time: 2.33278
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.80425

Cumulative Model Updates: 115,856
Cumulative Timesteps: 966,125,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 966125854...
Checkpoint 966125854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,221.76705
Policy Entropy: 3.82797
Value Function Loss: 0.03730

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.56989
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 21,037.46056
Overall Steps per Second: 10,324.58305

Timestep Collection Time: 2.37766
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.84475

Cumulative Model Updates: 115,862
Cumulative Timesteps: 966,175,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,828.74405
Policy Entropy: 3.80338
Value Function Loss: 0.03960

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 19,971.77478
Overall Steps per Second: 9,890.43739

Timestep Collection Time: 2.50514
Timestep Consumption Time: 2.55349
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 5.05862

Cumulative Model Updates: 115,868
Cumulative Timesteps: 966,225,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 966225906...
Checkpoint 966225906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.75778
Policy Entropy: 3.83045
Value Function Loss: 0.04101

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.62271
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 20,119.15200
Overall Steps per Second: 9,951.33447

Timestep Collection Time: 2.48639
Timestep Consumption Time: 2.54048
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 5.02686

Cumulative Model Updates: 115,874
Cumulative Timesteps: 966,275,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.58253
Policy Entropy: 3.81740
Value Function Loss: 0.04127

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.56609

Collected Steps per Second: 17,959.18690
Overall Steps per Second: 9,287.01033

Timestep Collection Time: 2.78565
Timestep Consumption Time: 2.60123
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 5.38688

Cumulative Model Updates: 115,880
Cumulative Timesteps: 966,325,958

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 966325958...
Checkpoint 966325958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,057.68563
Policy Entropy: 3.79263
Value Function Loss: 0.03921

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.50051
Value Function Update Magnitude: 0.53887

Collected Steps per Second: 19,104.83809
Overall Steps per Second: 9,710.12134

Timestep Collection Time: 2.61871
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 5.15236

Cumulative Model Updates: 115,886
Cumulative Timesteps: 966,375,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,657.19401
Policy Entropy: 3.76290
Value Function Loss: 0.03400

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15330
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.66153

Collected Steps per Second: 19,897.63034
Overall Steps per Second: 9,671.13780

Timestep Collection Time: 2.51326
Timestep Consumption Time: 2.65759
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 5.17085

Cumulative Model Updates: 115,892
Cumulative Timesteps: 966,425,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 966425996...
Checkpoint 966425996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,005.49424
Policy Entropy: 3.73659
Value Function Loss: 0.03136

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.43948
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 18,336.89939
Overall Steps per Second: 9,267.92320

Timestep Collection Time: 2.72761
Timestep Consumption Time: 2.66906
PPO Batch Consumption Time: 0.30182
Total Iteration Time: 5.39668

Cumulative Model Updates: 115,898
Cumulative Timesteps: 966,476,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,034.17026
Policy Entropy: 3.74840
Value Function Loss: 0.02568

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15134
Policy Update Magnitude: 0.43504
Value Function Update Magnitude: 0.55386

Collected Steps per Second: 19,869.60039
Overall Steps per Second: 9,814.43432

Timestep Collection Time: 2.51761
Timestep Consumption Time: 2.57937
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 5.09698

Cumulative Model Updates: 115,904
Cumulative Timesteps: 966,526,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 966526036...
Checkpoint 966526036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,616.22438
Policy Entropy: 3.72328
Value Function Loss: 0.02304

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.15424
Policy Update Magnitude: 0.39547
Value Function Update Magnitude: 0.44190

Collected Steps per Second: 18,598.52593
Overall Steps per Second: 9,408.46231

Timestep Collection Time: 2.68839
Timestep Consumption Time: 2.62598
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 5.31436

Cumulative Model Updates: 115,910
Cumulative Timesteps: 966,576,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,409.38780
Policy Entropy: 3.72804
Value Function Loss: 0.01861

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.36334
Value Function Update Magnitude: 0.42180

Collected Steps per Second: 19,719.08620
Overall Steps per Second: 9,777.50335

Timestep Collection Time: 2.53663
Timestep Consumption Time: 2.57920
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 5.11583

Cumulative Model Updates: 115,916
Cumulative Timesteps: 966,626,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 966626056...
Checkpoint 966626056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,915.52934
Policy Entropy: 3.70745
Value Function Loss: 0.02127

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.35507
Value Function Update Magnitude: 0.44012

Collected Steps per Second: 20,124.09645
Overall Steps per Second: 9,532.25762

Timestep Collection Time: 2.48518
Timestep Consumption Time: 2.76143
PPO Batch Consumption Time: 0.32259
Total Iteration Time: 5.24661

Cumulative Model Updates: 115,922
Cumulative Timesteps: 966,676,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,156.89519
Policy Entropy: 3.73358
Value Function Loss: 0.01978

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.15017
Policy Update Magnitude: 0.34264
Value Function Update Magnitude: 0.40187

Collected Steps per Second: 20,136.28369
Overall Steps per Second: 10,069.92095

Timestep Collection Time: 2.48507
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.96925

Cumulative Model Updates: 115,928
Cumulative Timesteps: 966,726,108

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 966726108...
Checkpoint 966726108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,014.85045
Policy Entropy: 3.71762
Value Function Loss: 0.02280

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.33966
Value Function Update Magnitude: 0.46462

Collected Steps per Second: 20,359.32706
Overall Steps per Second: 9,899.30573

Timestep Collection Time: 2.45686
Timestep Consumption Time: 2.59602
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 5.05288

Cumulative Model Updates: 115,934
Cumulative Timesteps: 966,776,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,073.37695
Policy Entropy: 3.72718
Value Function Loss: 0.02816

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.37106
Value Function Update Magnitude: 0.48304

Collected Steps per Second: 20,109.32910
Overall Steps per Second: 9,764.70902

Timestep Collection Time: 2.48700
Timestep Consumption Time: 2.63470
PPO Batch Consumption Time: 0.31042
Total Iteration Time: 5.12171

Cumulative Model Updates: 115,940
Cumulative Timesteps: 966,826,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 966826140...
Checkpoint 966826140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,384.86599
Policy Entropy: 3.74603
Value Function Loss: 0.02868

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.41492
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 19,913.49984
Overall Steps per Second: 9,860.65828

Timestep Collection Time: 2.51206
Timestep Consumption Time: 2.56102
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 5.07309

Cumulative Model Updates: 115,946
Cumulative Timesteps: 966,876,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,428.20875
Policy Entropy: 3.75908
Value Function Loss: 0.02897

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.45957
Value Function Update Magnitude: 0.57748

Collected Steps per Second: 20,197.35575
Overall Steps per Second: 10,023.07030

Timestep Collection Time: 2.47607
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.98949

Cumulative Model Updates: 115,952
Cumulative Timesteps: 966,926,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 966926174...
Checkpoint 966926174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,428.20875
Policy Entropy: 3.74578
Value Function Loss: 0.02341

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.46203
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 21,211.45042
Overall Steps per Second: 10,379.50393

Timestep Collection Time: 2.35722
Timestep Consumption Time: 2.45997
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.81719

Cumulative Model Updates: 115,958
Cumulative Timesteps: 966,976,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,055.98081
Policy Entropy: 3.71217
Value Function Loss: 0.02547

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14964
Policy Update Magnitude: 0.41668
Value Function Update Magnitude: 0.57397

Collected Steps per Second: 21,349.42265
Overall Steps per Second: 10,233.06281

Timestep Collection Time: 2.34292
Timestep Consumption Time: 2.54516
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.88808

Cumulative Model Updates: 115,964
Cumulative Timesteps: 967,026,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 967026194...
Checkpoint 967026194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,643.64099
Policy Entropy: 3.71845
Value Function Loss: 0.02287

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.37298
Value Function Update Magnitude: 0.49248

Collected Steps per Second: 20,403.62093
Overall Steps per Second: 9,950.83432

Timestep Collection Time: 2.45221
Timestep Consumption Time: 2.57591
PPO Batch Consumption Time: 0.29908
Total Iteration Time: 5.02812

Cumulative Model Updates: 115,970
Cumulative Timesteps: 967,076,228

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,011.66016
Policy Entropy: 3.71182
Value Function Loss: 0.02651

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14993
Policy Update Magnitude: 0.37593
Value Function Update Magnitude: 0.47548

Collected Steps per Second: 21,567.14592
Overall Steps per Second: 10,378.52208

Timestep Collection Time: 2.31955
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.82015

Cumulative Model Updates: 115,976
Cumulative Timesteps: 967,126,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 967126254...
Checkpoint 967126254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,011.66016
Policy Entropy: 3.71344
Value Function Loss: 0.02297

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.42154
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 20,879.51851
Overall Steps per Second: 10,114.86417

Timestep Collection Time: 2.39498
Timestep Consumption Time: 2.54883
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.94381

Cumulative Model Updates: 115,982
Cumulative Timesteps: 967,176,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.92264
Policy Entropy: 3.70333
Value Function Loss: 0.02453

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 0.42147
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 21,296.02742
Overall Steps per Second: 10,344.00709

Timestep Collection Time: 2.34898
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.83604

Cumulative Model Updates: 115,988
Cumulative Timesteps: 967,226,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 967226284...
Checkpoint 967226284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,811.96269
Policy Entropy: 3.73387
Value Function Loss: 0.02167

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.43786
Value Function Update Magnitude: 0.66474

Collected Steps per Second: 20,315.56998
Overall Steps per Second: 10,084.99077

Timestep Collection Time: 2.46225
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.96004

Cumulative Model Updates: 115,994
Cumulative Timesteps: 967,276,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,059.43479
Policy Entropy: 3.74431
Value Function Loss: 0.02342

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.44041
Value Function Update Magnitude: 0.63242

Collected Steps per Second: 21,286.11105
Overall Steps per Second: 10,045.76946

Timestep Collection Time: 2.35008
Timestep Consumption Time: 2.62953
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.97961

Cumulative Model Updates: 116,000
Cumulative Timesteps: 967,326,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 967326330...
Checkpoint 967326330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211.66002
Policy Entropy: 3.76380
Value Function Loss: 0.02233

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.46361
Value Function Update Magnitude: 0.77433

Collected Steps per Second: 21,079.81065
Overall Steps per Second: 10,325.25801

Timestep Collection Time: 2.37327
Timestep Consumption Time: 2.47194
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.84521

Cumulative Model Updates: 116,006
Cumulative Timesteps: 967,376,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,306.39849
Policy Entropy: 3.76021
Value Function Loss: 0.02568

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14908
Policy Update Magnitude: 0.48207
Value Function Update Magnitude: 0.75415

Collected Steps per Second: 20,711.64548
Overall Steps per Second: 9,906.44854

Timestep Collection Time: 2.41545
Timestep Consumption Time: 2.63459
PPO Batch Consumption Time: 0.31109
Total Iteration Time: 5.05004

Cumulative Model Updates: 116,012
Cumulative Timesteps: 967,426,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 967426386...
Checkpoint 967426386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,965.25727
Policy Entropy: 3.74973
Value Function Loss: 0.02691

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14361
Policy Update Magnitude: 0.52109
Value Function Update Magnitude: 0.76009

Collected Steps per Second: 20,320.31803
Overall Steps per Second: 9,780.73178

Timestep Collection Time: 2.46138
Timestep Consumption Time: 2.65235
PPO Batch Consumption Time: 0.30854
Total Iteration Time: 5.11373

Cumulative Model Updates: 116,018
Cumulative Timesteps: 967,476,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,014.33114
Policy Entropy: 3.72249
Value Function Loss: 0.03119

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.55329
Value Function Update Magnitude: 0.73383

Collected Steps per Second: 21,157.50141
Overall Steps per Second: 10,008.90365

Timestep Collection Time: 2.36351
Timestep Consumption Time: 2.63264
PPO Batch Consumption Time: 0.31024
Total Iteration Time: 4.99615

Cumulative Model Updates: 116,024
Cumulative Timesteps: 967,526,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 967526408...
Checkpoint 967526408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,581.06556
Policy Entropy: 3.71978
Value Function Loss: 0.02938

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.58431
Value Function Update Magnitude: 0.67734

Collected Steps per Second: 20,606.93054
Overall Steps per Second: 10,043.10322

Timestep Collection Time: 2.42734
Timestep Consumption Time: 2.55319
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 4.98053

Cumulative Model Updates: 116,030
Cumulative Timesteps: 967,576,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,678.06817
Policy Entropy: 3.71648
Value Function Loss: 0.03460

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.58417

Collected Steps per Second: 21,750.78800
Overall Steps per Second: 10,210.08951

Timestep Collection Time: 2.30005
Timestep Consumption Time: 2.59980
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.89986

Cumulative Model Updates: 116,036
Cumulative Timesteps: 967,626,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 967626456...
Checkpoint 967626456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,678.06817
Policy Entropy: 3.72863
Value Function Loss: 0.02906

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.53885
Value Function Update Magnitude: 0.50479

Collected Steps per Second: 19,108.60920
Overall Steps per Second: 9,585.60390

Timestep Collection Time: 2.61788
Timestep Consumption Time: 2.60078
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 5.21866

Cumulative Model Updates: 116,042
Cumulative Timesteps: 967,676,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,678.06817
Policy Entropy: 3.70290
Value Function Loss: 0.03399

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.50514
Value Function Update Magnitude: 0.43929

Collected Steps per Second: 20,151.34691
Overall Steps per Second: 9,870.40663

Timestep Collection Time: 2.48341
Timestep Consumption Time: 2.58670
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 5.07011

Cumulative Model Updates: 116,048
Cumulative Timesteps: 967,726,524

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 967726524...
Checkpoint 967726524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,678.06817
Policy Entropy: 3.70935
Value Function Loss: 0.03147

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.45811

Collected Steps per Second: 19,216.85441
Overall Steps per Second: 9,650.31274

Timestep Collection Time: 2.60334
Timestep Consumption Time: 2.58074
PPO Batch Consumption Time: 0.31099
Total Iteration Time: 5.18408

Cumulative Model Updates: 116,054
Cumulative Timesteps: 967,776,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,510.66726
Policy Entropy: 3.70387
Value Function Loss: 0.03389

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.15025
Policy Update Magnitude: 0.53962
Value Function Update Magnitude: 0.55997

Collected Steps per Second: 18,921.25821
Overall Steps per Second: 9,541.13899

Timestep Collection Time: 2.64264
Timestep Consumption Time: 2.59804
PPO Batch Consumption Time: 0.31216
Total Iteration Time: 5.24067

Cumulative Model Updates: 116,060
Cumulative Timesteps: 967,826,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 967826554...
Checkpoint 967826554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,715.02209
Policy Entropy: 3.72586
Value Function Loss: 0.02848

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.51244
Value Function Update Magnitude: 0.57794

Collected Steps per Second: 18,519.95152
Overall Steps per Second: 9,464.51057

Timestep Collection Time: 2.70217
Timestep Consumption Time: 2.58538
PPO Batch Consumption Time: 0.30958
Total Iteration Time: 5.28754

Cumulative Model Updates: 116,066
Cumulative Timesteps: 967,876,598

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,854.36654
Policy Entropy: 3.73181
Value Function Loss: 0.02808

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.48774
Value Function Update Magnitude: 0.54425

Collected Steps per Second: 19,328.64976
Overall Steps per Second: 9,477.99731

Timestep Collection Time: 2.58787
Timestep Consumption Time: 2.68962
PPO Batch Consumption Time: 0.31557
Total Iteration Time: 5.27749

Cumulative Model Updates: 116,072
Cumulative Timesteps: 967,926,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 967926618...
Checkpoint 967926618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,741.88374
Policy Entropy: 3.73967
Value Function Loss: 0.02419

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.46540
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 19,600.55629
Overall Steps per Second: 9,579.02001

Timestep Collection Time: 2.55227
Timestep Consumption Time: 2.67018
PPO Batch Consumption Time: 0.31463
Total Iteration Time: 5.22245

Cumulative Model Updates: 116,078
Cumulative Timesteps: 967,976,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,489.74635
Policy Entropy: 3.74901
Value Function Loss: 0.02294

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.43815
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 19,611.53658
Overall Steps per Second: 9,578.98149

Timestep Collection Time: 2.54983
Timestep Consumption Time: 2.67056
PPO Batch Consumption Time: 0.31761
Total Iteration Time: 5.22039

Cumulative Model Updates: 116,084
Cumulative Timesteps: 968,026,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 968026650...
Checkpoint 968026650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,850.24777
Policy Entropy: 3.73868
Value Function Loss: 0.02282

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.40328
Value Function Update Magnitude: 0.51647

Collected Steps per Second: 19,985.94280
Overall Steps per Second: 9,703.51594

Timestep Collection Time: 2.50306
Timestep Consumption Time: 2.65239
PPO Batch Consumption Time: 0.30775
Total Iteration Time: 5.15545

Cumulative Model Updates: 116,090
Cumulative Timesteps: 968,076,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,850.24777
Policy Entropy: 3.72974
Value Function Loss: 0.02004

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.40398
Value Function Update Magnitude: 0.53337

Collected Steps per Second: 20,108.92259
Overall Steps per Second: 9,660.37497

Timestep Collection Time: 2.48795
Timestep Consumption Time: 2.69094
PPO Batch Consumption Time: 0.31520
Total Iteration Time: 5.17889

Cumulative Model Updates: 116,096
Cumulative Timesteps: 968,126,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 968126706...
Checkpoint 968126706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,850.24777
Policy Entropy: 3.72042
Value Function Loss: 0.02159

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.41005
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 18,278.36450
Overall Steps per Second: 9,212.64142

Timestep Collection Time: 2.73547
Timestep Consumption Time: 2.69185
PPO Batch Consumption Time: 0.31182
Total Iteration Time: 5.42733

Cumulative Model Updates: 116,102
Cumulative Timesteps: 968,176,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,990.39900
Policy Entropy: 3.72160
Value Function Loss: 0.02133

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.43569
Value Function Update Magnitude: 0.63271

Collected Steps per Second: 20,188.48508
Overall Steps per Second: 9,710.77101

Timestep Collection Time: 2.47676
Timestep Consumption Time: 2.67237
PPO Batch Consumption Time: 0.30651
Total Iteration Time: 5.14913

Cumulative Model Updates: 116,108
Cumulative Timesteps: 968,226,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 968226708...
Checkpoint 968226708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.71728
Value Function Loss: 0.02264

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.15029
Policy Update Magnitude: 0.46816
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 20,198.76173
Overall Steps per Second: 9,773.27847

Timestep Collection Time: 2.47560
Timestep Consumption Time: 2.64080
PPO Batch Consumption Time: 0.30615
Total Iteration Time: 5.11640

Cumulative Model Updates: 116,114
Cumulative Timesteps: 968,276,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.70625
Value Function Loss: 0.02609

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.45590
Value Function Update Magnitude: 0.48514

Collected Steps per Second: 19,295.48231
Overall Steps per Second: 9,570.65970

Timestep Collection Time: 2.59263
Timestep Consumption Time: 2.63439
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 5.22702

Cumulative Model Updates: 116,120
Cumulative Timesteps: 968,326,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 968326738...
Checkpoint 968326738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.70431
Value Function Loss: 0.02449

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.48004
Value Function Update Magnitude: 0.44529

Collected Steps per Second: 19,944.85894
Overall Steps per Second: 9,645.03677

Timestep Collection Time: 2.50771
Timestep Consumption Time: 2.67796
PPO Batch Consumption Time: 0.30724
Total Iteration Time: 5.18567

Cumulative Model Updates: 116,126
Cumulative Timesteps: 968,376,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.69616
Value Function Loss: 0.02641

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.46746
Value Function Update Magnitude: 0.41740

Collected Steps per Second: 19,585.42947
Overall Steps per Second: 9,580.15718

Timestep Collection Time: 2.55394
Timestep Consumption Time: 2.66727
PPO Batch Consumption Time: 0.31114
Total Iteration Time: 5.22121

Cumulative Model Updates: 116,132
Cumulative Timesteps: 968,426,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 968426774...
Checkpoint 968426774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.69584
Value Function Loss: 0.02327

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.45837
Value Function Update Magnitude: 0.43525

Collected Steps per Second: 20,361.87088
Overall Steps per Second: 9,555.46554

Timestep Collection Time: 2.45714
Timestep Consumption Time: 2.77881
PPO Batch Consumption Time: 0.31289
Total Iteration Time: 5.23596

Cumulative Model Updates: 116,138
Cumulative Timesteps: 968,476,806

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.70857
Value Function Loss: 0.02444

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.46442

Collected Steps per Second: 19,751.69178
Overall Steps per Second: 9,736.78826

Timestep Collection Time: 2.53244
Timestep Consumption Time: 2.60478
PPO Batch Consumption Time: 0.30237
Total Iteration Time: 5.13722

Cumulative Model Updates: 116,144
Cumulative Timesteps: 968,526,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 968526826...
Checkpoint 968526826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,667.59750
Policy Entropy: 3.70615
Value Function Loss: 0.02374

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.46426
Value Function Update Magnitude: 0.49045

Collected Steps per Second: 18,941.70303
Overall Steps per Second: 9,527.74435

Timestep Collection Time: 2.64190
Timestep Consumption Time: 2.61034
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.25224

Cumulative Model Updates: 116,150
Cumulative Timesteps: 968,576,868

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,949.74049
Policy Entropy: 3.71963
Value Function Loss: 0.02298

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.45871
Value Function Update Magnitude: 0.48865

Collected Steps per Second: 19,885.25675
Overall Steps per Second: 9,509.24040

Timestep Collection Time: 2.51473
Timestep Consumption Time: 2.74395
PPO Batch Consumption Time: 0.30907
Total Iteration Time: 5.25867

Cumulative Model Updates: 116,156
Cumulative Timesteps: 968,626,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 968626874...
Checkpoint 968626874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,557.83149
Policy Entropy: 3.72394
Value Function Loss: 0.02159

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.42622
Value Function Update Magnitude: 0.45194

Collected Steps per Second: 18,335.62388
Overall Steps per Second: 9,274.51403

Timestep Collection Time: 2.72802
Timestep Consumption Time: 2.66525
PPO Batch Consumption Time: 0.32544
Total Iteration Time: 5.39327

Cumulative Model Updates: 116,162
Cumulative Timesteps: 968,676,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,761.64547
Policy Entropy: 3.73829
Value Function Loss: 0.02225

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.40642
Value Function Update Magnitude: 0.47044

Collected Steps per Second: 17,994.08479
Overall Steps per Second: 9,155.30287

Timestep Collection Time: 2.77958
Timestep Consumption Time: 2.68348
PPO Batch Consumption Time: 0.32410
Total Iteration Time: 5.46306

Cumulative Model Updates: 116,168
Cumulative Timesteps: 968,726,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 968726910...
Checkpoint 968726910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,761.64547
Policy Entropy: 3.72519
Value Function Loss: 0.02269

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.44792
Value Function Update Magnitude: 0.54432

Collected Steps per Second: 17,212.91559
Overall Steps per Second: 9,092.74116

Timestep Collection Time: 2.90642
Timestep Consumption Time: 2.59555
PPO Batch Consumption Time: 0.30841
Total Iteration Time: 5.50197

Cumulative Model Updates: 116,174
Cumulative Timesteps: 968,776,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,102.40095
Policy Entropy: 3.71814
Value Function Loss: 0.02808

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.46319
Value Function Update Magnitude: 0.56991

Collected Steps per Second: 19,655.11886
Overall Steps per Second: 9,909.21609

Timestep Collection Time: 2.54539
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 5.04884

Cumulative Model Updates: 116,180
Cumulative Timesteps: 968,826,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 968826968...
Checkpoint 968826968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,591.22861
Policy Entropy: 3.71607
Value Function Loss: 0.02978

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.55223

Collected Steps per Second: 20,332.57110
Overall Steps per Second: 9,271.68143

Timestep Collection Time: 2.46098
Timestep Consumption Time: 2.93589
PPO Batch Consumption Time: 0.35707
Total Iteration Time: 5.39686

Cumulative Model Updates: 116,186
Cumulative Timesteps: 968,877,006

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,120.73172
Policy Entropy: 3.72122
Value Function Loss: 0.03048

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.15194
Policy Update Magnitude: 0.53027
Value Function Update Magnitude: 0.54223

Collected Steps per Second: 18,214.67358
Overall Steps per Second: 9,244.98489

Timestep Collection Time: 2.74614
Timestep Consumption Time: 2.66436
PPO Batch Consumption Time: 0.31895
Total Iteration Time: 5.41050

Cumulative Model Updates: 116,192
Cumulative Timesteps: 968,927,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 968927026...
Checkpoint 968927026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,657.12915
Policy Entropy: 3.73578
Value Function Loss: 0.02774

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.49359
Value Function Update Magnitude: 0.50812

Collected Steps per Second: 19,046.91104
Overall Steps per Second: 9,491.20971

Timestep Collection Time: 2.62573
Timestep Consumption Time: 2.64357
PPO Batch Consumption Time: 0.30406
Total Iteration Time: 5.26930

Cumulative Model Updates: 116,198
Cumulative Timesteps: 968,977,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,657.12915
Policy Entropy: 3.73332
Value Function Loss: 0.02352

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15217
Policy Update Magnitude: 0.47169
Value Function Update Magnitude: 0.50925

Collected Steps per Second: 19,389.43993
Overall Steps per Second: 9,533.13944

Timestep Collection Time: 2.58089
Timestep Consumption Time: 2.66838
PPO Batch Consumption Time: 0.30752
Total Iteration Time: 5.24927

Cumulative Model Updates: 116,204
Cumulative Timesteps: 969,027,080

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 969027080...
Checkpoint 969027080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,657.12915
Policy Entropy: 3.71756
Value Function Loss: 0.02269

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.45228
Value Function Update Magnitude: 0.48013

Collected Steps per Second: 20,586.92116
Overall Steps per Second: 9,711.39752

Timestep Collection Time: 2.42902
Timestep Consumption Time: 2.72019
PPO Batch Consumption Time: 0.30588
Total Iteration Time: 5.14921

Cumulative Model Updates: 116,210
Cumulative Timesteps: 969,077,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.72040
Value Function Loss: 0.02184

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14876
Policy Update Magnitude: 0.44522
Value Function Update Magnitude: 0.47491

Collected Steps per Second: 19,691.15053
Overall Steps per Second: 9,523.72141

Timestep Collection Time: 2.54053
Timestep Consumption Time: 2.71225
PPO Batch Consumption Time: 0.31666
Total Iteration Time: 5.25278

Cumulative Model Updates: 116,216
Cumulative Timesteps: 969,127,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 969127112...
Checkpoint 969127112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.71704
Value Function Loss: 0.02280

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14906
Policy Update Magnitude: 0.43343
Value Function Update Magnitude: 0.47749

Collected Steps per Second: 19,510.60135
Overall Steps per Second: 9,634.96694

Timestep Collection Time: 2.56363
Timestep Consumption Time: 2.62767
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 5.19130

Cumulative Model Updates: 116,222
Cumulative Timesteps: 969,177,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.72324
Value Function Loss: 0.02034

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.43748
Value Function Update Magnitude: 0.47053

Collected Steps per Second: 20,349.36246
Overall Steps per Second: 9,483.99940

Timestep Collection Time: 2.45787
Timestep Consumption Time: 2.81586
PPO Batch Consumption Time: 0.33388
Total Iteration Time: 5.27372

Cumulative Model Updates: 116,228
Cumulative Timesteps: 969,227,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 969227146...
Checkpoint 969227146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.72337
Value Function Loss: 0.01791

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.40907
Value Function Update Magnitude: 0.48180

Collected Steps per Second: 19,631.08137
Overall Steps per Second: 9,407.00879

Timestep Collection Time: 2.54769
Timestep Consumption Time: 2.76898
PPO Batch Consumption Time: 0.32718
Total Iteration Time: 5.31667

Cumulative Model Updates: 116,234
Cumulative Timesteps: 969,277,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.72477
Value Function Loss: 0.01723

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.36703
Value Function Update Magnitude: 0.49486

Collected Steps per Second: 19,327.80747
Overall Steps per Second: 9,434.77550

Timestep Collection Time: 2.58788
Timestep Consumption Time: 2.71357
PPO Batch Consumption Time: 0.31788
Total Iteration Time: 5.30145

Cumulative Model Updates: 116,240
Cumulative Timesteps: 969,327,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 969327178...
Checkpoint 969327178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,065.17798
Policy Entropy: 3.73681
Value Function Loss: 0.01623

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.35382
Value Function Update Magnitude: 0.46248

Collected Steps per Second: 19,659.45524
Overall Steps per Second: 9,820.94926

Timestep Collection Time: 2.54341
Timestep Consumption Time: 2.54795
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 5.09136

Cumulative Model Updates: 116,246
Cumulative Timesteps: 969,377,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 411,376.68616
Policy Entropy: 3.73028
Value Function Loss: 0.02203

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.37171
Value Function Update Magnitude: 0.43414

Collected Steps per Second: 20,825.93392
Overall Steps per Second: 10,257.24164

Timestep Collection Time: 2.40306
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.87909

Cumulative Model Updates: 116,252
Cumulative Timesteps: 969,427,226

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 969427226...
Checkpoint 969427226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,145.92478
Policy Entropy: 3.75105
Value Function Loss: 0.02515

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.49415
Value Function Update Magnitude: 0.51313

Collected Steps per Second: 20,211.10744
Overall Steps per Second: 10,029.88975

Timestep Collection Time: 2.47478
Timestep Consumption Time: 2.51212
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.98689

Cumulative Model Updates: 116,258
Cumulative Timesteps: 969,477,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,073.80914
Policy Entropy: 3.74780
Value Function Loss: 0.02821

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.58533

Collected Steps per Second: 21,006.92311
Overall Steps per Second: 10,267.19878

Timestep Collection Time: 2.38150
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.87260

Cumulative Model Updates: 116,264
Cumulative Timesteps: 969,527,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 969527272...
Checkpoint 969527272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597.36980
Policy Entropy: 3.74532
Value Function Loss: 0.02759

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.52274
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 19,669.29750
Overall Steps per Second: 9,652.52102

Timestep Collection Time: 2.54274
Timestep Consumption Time: 2.63870
PPO Batch Consumption Time: 0.31681
Total Iteration Time: 5.18144

Cumulative Model Updates: 116,270
Cumulative Timesteps: 969,577,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,420.81979
Policy Entropy: 3.71805
Value Function Loss: 0.02761

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.53943
Value Function Update Magnitude: 0.56246

Collected Steps per Second: 19,562.40893
Overall Steps per Second: 9,715.73576

Timestep Collection Time: 2.55664
Timestep Consumption Time: 2.59109
PPO Batch Consumption Time: 0.30087
Total Iteration Time: 5.14773

Cumulative Model Updates: 116,276
Cumulative Timesteps: 969,627,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 969627300...
Checkpoint 969627300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,499.67542
Policy Entropy: 3.71514
Value Function Loss: 0.03106

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.66267

Collected Steps per Second: 20,179.81121
Overall Steps per Second: 10,009.58503

Timestep Collection Time: 2.47802
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.99581

Cumulative Model Updates: 116,282
Cumulative Timesteps: 969,677,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,034.31125
Policy Entropy: 3.72398
Value Function Loss: 0.03186

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.58143
Value Function Update Magnitude: 0.61512

Collected Steps per Second: 21,832.83035
Overall Steps per Second: 10,398.40455

Timestep Collection Time: 2.29022
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.80862

Cumulative Model Updates: 116,288
Cumulative Timesteps: 969,727,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 969727308...
Checkpoint 969727308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,638.74741
Policy Entropy: 3.72698
Value Function Loss: 0.03151

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14458
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 21,047.59723
Overall Steps per Second: 10,236.88713

Timestep Collection Time: 2.37652
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.88625

Cumulative Model Updates: 116,294
Cumulative Timesteps: 969,777,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,694.41135
Policy Entropy: 3.73248
Value Function Loss: 0.02772

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.53088
Value Function Update Magnitude: 0.57279

Collected Steps per Second: 20,004.79462
Overall Steps per Second: 9,832.81521

Timestep Collection Time: 2.50030
Timestep Consumption Time: 2.58654
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 5.08684

Cumulative Model Updates: 116,300
Cumulative Timesteps: 969,827,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 969827346...
Checkpoint 969827346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,521.39945
Policy Entropy: 3.72440
Value Function Loss: 0.02499

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.48953
Value Function Update Magnitude: 0.60527

Collected Steps per Second: 20,447.31037
Overall Steps per Second: 9,850.27977

Timestep Collection Time: 2.44541
Timestep Consumption Time: 2.63079
PPO Batch Consumption Time: 0.30835
Total Iteration Time: 5.07620

Cumulative Model Updates: 116,306
Cumulative Timesteps: 969,877,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,402.18798
Policy Entropy: 3.71845
Value Function Loss: 0.02650

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.47419
Value Function Update Magnitude: 0.65694

Collected Steps per Second: 20,796.83794
Overall Steps per Second: 10,040.80172

Timestep Collection Time: 2.40527
Timestep Consumption Time: 2.57660
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.98187

Cumulative Model Updates: 116,312
Cumulative Timesteps: 969,927,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 969927370...
Checkpoint 969927370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,448.19358
Policy Entropy: 3.71796
Value Function Loss: 0.02597

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.48694
Value Function Update Magnitude: 0.63337

Collected Steps per Second: 21,190.17919
Overall Steps per Second: 10,293.35760

Timestep Collection Time: 2.36034
Timestep Consumption Time: 2.49872
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.85906

Cumulative Model Updates: 116,318
Cumulative Timesteps: 969,977,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285,448.19358
Policy Entropy: 3.69757
Value Function Loss: 0.02750

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.48302
Value Function Update Magnitude: 0.56139

Collected Steps per Second: 21,748.45490
Overall Steps per Second: 10,471.52972

Timestep Collection Time: 2.29993
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.77676

Cumulative Model Updates: 116,324
Cumulative Timesteps: 970,027,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 970027406...
Checkpoint 970027406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,448.19358
Policy Entropy: 3.70606
Value Function Loss: 0.02387

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14615
Policy Update Magnitude: 0.47449
Value Function Update Magnitude: 0.54744

Collected Steps per Second: 20,050.09798
Overall Steps per Second: 9,797.95154

Timestep Collection Time: 2.49415
Timestep Consumption Time: 2.60977
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 5.10392

Cumulative Model Updates: 116,330
Cumulative Timesteps: 970,077,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,211.48674
Policy Entropy: 3.70440
Value Function Loss: 0.02670

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14453
Policy Update Magnitude: 0.46756
Value Function Update Magnitude: 0.48719

Collected Steps per Second: 19,922.26944
Overall Steps per Second: 9,939.49403

Timestep Collection Time: 2.51006
Timestep Consumption Time: 2.52099
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 5.03104

Cumulative Model Updates: 116,336
Cumulative Timesteps: 970,127,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 970127420...
Checkpoint 970127420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,404.36469
Policy Entropy: 3.72833
Value Function Loss: 0.02399

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.48016
Value Function Update Magnitude: 0.58214

Collected Steps per Second: 21,624.01695
Overall Steps per Second: 10,334.74826

Timestep Collection Time: 2.31261
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.83882

Cumulative Model Updates: 116,342
Cumulative Timesteps: 970,177,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,822.40974
Policy Entropy: 3.72325
Value Function Loss: 0.02534

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.48777
Value Function Update Magnitude: 0.58727

Collected Steps per Second: 21,993.05730
Overall Steps per Second: 10,420.07331

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.52680
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.80189

Cumulative Model Updates: 116,348
Cumulative Timesteps: 970,227,464

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 970227464...
Checkpoint 970227464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,822.40974
Policy Entropy: 3.72565
Value Function Loss: 0.02296

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.53978

Collected Steps per Second: 21,613.65630
Overall Steps per Second: 10,094.97472

Timestep Collection Time: 2.31381
Timestep Consumption Time: 2.64014
PPO Batch Consumption Time: 0.31176
Total Iteration Time: 4.95395

Cumulative Model Updates: 116,354
Cumulative Timesteps: 970,277,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,753.27264
Policy Entropy: 3.72566
Value Function Loss: 0.02232

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14920
Policy Update Magnitude: 0.45884
Value Function Update Magnitude: 0.55632

Collected Steps per Second: 20,262.10468
Overall Steps per Second: 10,016.51497

Timestep Collection Time: 2.46875
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.30168
Total Iteration Time: 4.99395

Cumulative Model Updates: 116,360
Cumulative Timesteps: 970,327,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 970327496...
Checkpoint 970327496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,255.34840
Policy Entropy: 3.72373
Value Function Loss: 0.02441

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.48608
Value Function Update Magnitude: 0.61069

Collected Steps per Second: 19,816.33896
Overall Steps per Second: 9,903.91802

Timestep Collection Time: 2.52428
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.30774
Total Iteration Time: 5.05073

Cumulative Model Updates: 116,366
Cumulative Timesteps: 970,377,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,178.10360
Policy Entropy: 3.73313
Value Function Loss: 0.02375

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.90703

Collected Steps per Second: 20,178.71621
Overall Steps per Second: 9,987.18381

Timestep Collection Time: 2.47905
Timestep Consumption Time: 2.52977
PPO Batch Consumption Time: 0.29959
Total Iteration Time: 5.00882

Cumulative Model Updates: 116,372
Cumulative Timesteps: 970,427,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 970427542...
Checkpoint 970427542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,217.03618
Policy Entropy: 3.72887
Value Function Loss: 0.02466

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.90531

Collected Steps per Second: 18,036.90146
Overall Steps per Second: 9,481.36631

Timestep Collection Time: 2.77387
Timestep Consumption Time: 2.50301
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 5.27688

Cumulative Model Updates: 116,378
Cumulative Timesteps: 970,477,574

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,233.92350
Policy Entropy: 3.74106
Value Function Loss: 0.02370

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.51051
Value Function Update Magnitude: 0.84364

Collected Steps per Second: 20,746.98175
Overall Steps per Second: 10,060.74315

Timestep Collection Time: 2.41124
Timestep Consumption Time: 2.56115
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.97240

Cumulative Model Updates: 116,384
Cumulative Timesteps: 970,527,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 970527600...
Checkpoint 970527600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,681.17662
Policy Entropy: 3.73399
Value Function Loss: 0.02604

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.77830

Collected Steps per Second: 18,178.08740
Overall Steps per Second: 9,253.55786

Timestep Collection Time: 2.75155
Timestep Consumption Time: 2.65372
PPO Batch Consumption Time: 0.31130
Total Iteration Time: 5.40527

Cumulative Model Updates: 116,390
Cumulative Timesteps: 970,577,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,821.94982
Policy Entropy: 3.72601
Value Function Loss: 0.02389

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.89049

Collected Steps per Second: 21,749.82500
Overall Steps per Second: 10,304.31605

Timestep Collection Time: 2.29942
Timestep Consumption Time: 2.55408
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.85350

Cumulative Model Updates: 116,396
Cumulative Timesteps: 970,627,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 970627630...
Checkpoint 970627630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,821.94982
Policy Entropy: 3.71784
Value Function Loss: 0.02533

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.75749

Collected Steps per Second: 21,393.95195
Overall Steps per Second: 10,411.07185

Timestep Collection Time: 2.33776
Timestep Consumption Time: 2.46616
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.80392

Cumulative Model Updates: 116,402
Cumulative Timesteps: 970,677,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 404,285.00945
Policy Entropy: 3.70956
Value Function Loss: 0.02673

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.48661
Value Function Update Magnitude: 0.53181

Collected Steps per Second: 21,599.24224
Overall Steps per Second: 10,436.88872

Timestep Collection Time: 2.31545
Timestep Consumption Time: 2.47640
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.79185

Cumulative Model Updates: 116,408
Cumulative Timesteps: 970,727,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 970727656...
Checkpoint 970727656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,463.84216
Policy Entropy: 3.71443
Value Function Loss: 0.02632

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.51727

Collected Steps per Second: 20,211.98541
Overall Steps per Second: 9,986.13226

Timestep Collection Time: 2.47467
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 5.00875

Cumulative Model Updates: 116,414
Cumulative Timesteps: 970,777,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,415.40211
Policy Entropy: 3.71657
Value Function Loss: 0.02640

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.54992
Value Function Update Magnitude: 0.70957

Collected Steps per Second: 20,517.52250
Overall Steps per Second: 10,046.27132

Timestep Collection Time: 2.43694
Timestep Consumption Time: 2.54003
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.97697

Cumulative Model Updates: 116,420
Cumulative Timesteps: 970,827,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 970827674...
Checkpoint 970827674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,211.47284
Policy Entropy: 3.72299
Value Function Loss: 0.02496

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.86446

Collected Steps per Second: 22,041.12420
Overall Steps per Second: 10,371.23354

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.55479
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.82527

Cumulative Model Updates: 116,426
Cumulative Timesteps: 970,877,718

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,947.40746
Policy Entropy: 3.71870
Value Function Loss: 0.02493

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.87530

Collected Steps per Second: 20,316.62787
Overall Steps per Second: 10,192.20338

Timestep Collection Time: 2.46143
Timestep Consumption Time: 2.44506
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.90650

Cumulative Model Updates: 116,432
Cumulative Timesteps: 970,927,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 970927726...
Checkpoint 970927726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,292.46988
Policy Entropy: 3.73449
Value Function Loss: 0.02743

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.85238

Collected Steps per Second: 21,085.16584
Overall Steps per Second: 10,068.74959

Timestep Collection Time: 2.37295
Timestep Consumption Time: 2.59629
PPO Batch Consumption Time: 0.31219
Total Iteration Time: 4.96924

Cumulative Model Updates: 116,438
Cumulative Timesteps: 970,977,760

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,219.31138
Policy Entropy: 3.73195
Value Function Loss: 0.02926

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.75056

Collected Steps per Second: 19,335.02696
Overall Steps per Second: 9,704.10514

Timestep Collection Time: 2.58608
Timestep Consumption Time: 2.56658
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 5.15266

Cumulative Model Updates: 116,444
Cumulative Timesteps: 971,027,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 971027762...
Checkpoint 971027762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.19035
Policy Entropy: 3.72433
Value Function Loss: 0.02684

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 20,750.93553
Overall Steps per Second: 10,202.37062

Timestep Collection Time: 2.40963
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.90102

Cumulative Model Updates: 116,450
Cumulative Timesteps: 971,077,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.72963
Value Function Loss: 0.02177

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.49120
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 20,502.69675
Overall Steps per Second: 10,043.07337

Timestep Collection Time: 2.44036
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.30033
Total Iteration Time: 4.98194

Cumulative Model Updates: 116,456
Cumulative Timesteps: 971,127,798

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 971127798...
Checkpoint 971127798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.71314
Value Function Loss: 0.02084

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.47457
Value Function Update Magnitude: 0.63359

Collected Steps per Second: 19,183.00191
Overall Steps per Second: 9,830.78897

Timestep Collection Time: 2.60679
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 5.08667

Cumulative Model Updates: 116,462
Cumulative Timesteps: 971,177,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.69252
Value Function Loss: 0.02192

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.45465
Value Function Update Magnitude: 0.63342

Collected Steps per Second: 20,588.76815
Overall Steps per Second: 9,995.73444

Timestep Collection Time: 2.42977
Timestep Consumption Time: 2.57496
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 5.00473

Cumulative Model Updates: 116,468
Cumulative Timesteps: 971,227,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 971227830...
Checkpoint 971227830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.67992
Value Function Loss: 0.02259

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15402
Policy Update Magnitude: 0.43476
Value Function Update Magnitude: 0.56372

Collected Steps per Second: 21,422.44357
Overall Steps per Second: 10,212.72370

Timestep Collection Time: 2.33512
Timestep Consumption Time: 2.56308
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.89820

Cumulative Model Updates: 116,474
Cumulative Timesteps: 971,277,854

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.68814
Value Function Loss: 0.02461

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.41671
Value Function Update Magnitude: 0.63064

Collected Steps per Second: 21,011.62509
Overall Steps per Second: 10,173.11215

Timestep Collection Time: 2.38011
Timestep Consumption Time: 2.53579
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.91590

Cumulative Model Updates: 116,480
Cumulative Timesteps: 971,327,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 971327864...
Checkpoint 971327864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.69050
Value Function Loss: 0.02519

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.43203
Value Function Update Magnitude: 0.59124

Collected Steps per Second: 21,621.89169
Overall Steps per Second: 10,396.90434

Timestep Collection Time: 2.31377
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.81182

Cumulative Model Updates: 116,486
Cumulative Timesteps: 971,377,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.68930
Value Function Loss: 0.02352

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.43014
Value Function Update Magnitude: 0.55340

Collected Steps per Second: 21,603.33656
Overall Steps per Second: 10,468.44205

Timestep Collection Time: 2.31446
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.77626

Cumulative Model Updates: 116,492
Cumulative Timesteps: 971,427,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 971427892...
Checkpoint 971427892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,429.10309
Policy Entropy: 3.68361
Value Function Loss: 0.02237

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.39947
Value Function Update Magnitude: 0.48264

Collected Steps per Second: 22,106.56929
Overall Steps per Second: 10,433.95116

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.53139
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.79416

Cumulative Model Updates: 116,498
Cumulative Timesteps: 971,477,914

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,181.61112
Policy Entropy: 3.68539
Value Function Loss: 0.02257

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.36763
Value Function Update Magnitude: 0.38740

Collected Steps per Second: 21,189.56242
Overall Steps per Second: 10,370.87288

Timestep Collection Time: 2.35975
Timestep Consumption Time: 2.46164
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.82139

Cumulative Model Updates: 116,504
Cumulative Timesteps: 971,527,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 971527916...
Checkpoint 971527916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,181.61112
Policy Entropy: 3.70011
Value Function Loss: 0.02087

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.15012
Policy Update Magnitude: 0.37316
Value Function Update Magnitude: 0.33592

Collected Steps per Second: 20,209.92031
Overall Steps per Second: 10,126.45698

Timestep Collection Time: 2.47433
Timestep Consumption Time: 2.46382
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.93815

Cumulative Model Updates: 116,510
Cumulative Timesteps: 971,577,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,686.13897
Policy Entropy: 3.70094
Value Function Loss: 0.02327

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.38063
Value Function Update Magnitude: 0.38161

Collected Steps per Second: 21,021.71417
Overall Steps per Second: 10,241.14119

Timestep Collection Time: 2.37849
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.88227

Cumulative Model Updates: 116,516
Cumulative Timesteps: 971,627,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 971627922...
Checkpoint 971627922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,542.32883
Policy Entropy: 3.72851
Value Function Loss: 0.02179

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.44171
Value Function Update Magnitude: 0.52928

Collected Steps per Second: 21,550.63236
Overall Steps per Second: 10,363.79536

Timestep Collection Time: 2.32142
Timestep Consumption Time: 2.50577
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.82719

Cumulative Model Updates: 116,522
Cumulative Timesteps: 971,677,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653,749.42349
Policy Entropy: 3.70591
Value Function Loss: 0.02773

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.47041
Value Function Update Magnitude: 0.55462

Collected Steps per Second: 21,075.43559
Overall Steps per Second: 10,282.08198

Timestep Collection Time: 2.37262
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.86322

Cumulative Model Updates: 116,528
Cumulative Timesteps: 971,727,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 971727954...
Checkpoint 971727954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,662.61784
Policy Entropy: 3.74637
Value Function Loss: 0.02576

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.53237
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 21,139.24680
Overall Steps per Second: 10,086.80140

Timestep Collection Time: 2.36565
Timestep Consumption Time: 2.59212
PPO Batch Consumption Time: 0.30433
Total Iteration Time: 4.95777

Cumulative Model Updates: 116,534
Cumulative Timesteps: 971,777,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,662.61784
Policy Entropy: 3.70134
Value Function Loss: 0.02517

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.53105
Value Function Update Magnitude: 0.65942

Collected Steps per Second: 20,534.94766
Overall Steps per Second: 10,160.23764

Timestep Collection Time: 2.43692
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.92528

Cumulative Model Updates: 116,540
Cumulative Timesteps: 971,828,004

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 971828004...
Checkpoint 971828004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,662.61784
Policy Entropy: 3.72156
Value Function Loss: 0.02069

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.48571
Value Function Update Magnitude: 0.62319

Collected Steps per Second: 21,463.13965
Overall Steps per Second: 10,218.17730

Timestep Collection Time: 2.32958
Timestep Consumption Time: 2.56367
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.89324

Cumulative Model Updates: 116,546
Cumulative Timesteps: 971,878,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,736.04164
Policy Entropy: 3.71050
Value Function Loss: 0.02059

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14995
Policy Update Magnitude: 0.45182
Value Function Update Magnitude: 0.69147

Collected Steps per Second: 21,554.63924
Overall Steps per Second: 10,107.86547

Timestep Collection Time: 2.31996
Timestep Consumption Time: 2.62727
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.94724

Cumulative Model Updates: 116,552
Cumulative Timesteps: 971,928,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 971928010...
Checkpoint 971928010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,027.15474
Policy Entropy: 3.73300
Value Function Loss: 0.02114

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.15251
Policy Update Magnitude: 0.45089
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 21,325.41078
Overall Steps per Second: 10,183.00063

Timestep Collection Time: 2.34537
Timestep Consumption Time: 2.56634
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.91172

Cumulative Model Updates: 116,558
Cumulative Timesteps: 971,978,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.74074
Value Function Loss: 0.02080

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.46455
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 20,407.55310
Overall Steps per Second: 9,823.35302

Timestep Collection Time: 2.45164
Timestep Consumption Time: 2.64153
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 5.09317

Cumulative Model Updates: 116,564
Cumulative Timesteps: 972,028,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 972028058...
Checkpoint 972028058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.73318
Value Function Loss: 0.01828

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.43092
Value Function Update Magnitude: 0.63121

Collected Steps per Second: 19,585.01303
Overall Steps per Second: 10,018.14781

Timestep Collection Time: 2.55450
Timestep Consumption Time: 2.43943
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.99394

Cumulative Model Updates: 116,570
Cumulative Timesteps: 972,078,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.73069
Value Function Loss: 0.01566

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.38020
Value Function Update Magnitude: 0.56711

Collected Steps per Second: 19,573.02777
Overall Steps per Second: 9,921.33538

Timestep Collection Time: 2.55505
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 5.04065

Cumulative Model Updates: 116,576
Cumulative Timesteps: 972,128,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 972128098...
Checkpoint 972128098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.72923
Value Function Loss: 0.01386

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.32667
Value Function Update Magnitude: 0.45763

Collected Steps per Second: 20,401.83764
Overall Steps per Second: 10,119.00257

Timestep Collection Time: 2.45164
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.94298

Cumulative Model Updates: 116,582
Cumulative Timesteps: 972,178,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.72681
Value Function Loss: 0.01411

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.33561
Value Function Update Magnitude: 0.44776

Collected Steps per Second: 19,607.70484
Overall Steps per Second: 9,950.72049

Timestep Collection Time: 2.55196
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 5.02858

Cumulative Model Updates: 116,588
Cumulative Timesteps: 972,228,154

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 972228154...
Checkpoint 972228154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,623.48451
Policy Entropy: 3.72920
Value Function Loss: 0.01345

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.36081
Value Function Update Magnitude: 0.49325

Collected Steps per Second: 21,430.50667
Overall Steps per Second: 10,127.90862

Timestep Collection Time: 2.33452
Timestep Consumption Time: 2.60529
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.93982

Cumulative Model Updates: 116,594
Cumulative Timesteps: 972,278,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205,732.74264
Policy Entropy: 3.73264
Value Function Loss: 0.01865

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.39883
Value Function Update Magnitude: 0.67077

Collected Steps per Second: 19,587.81397
Overall Steps per Second: 9,785.25914

Timestep Collection Time: 2.55363
Timestep Consumption Time: 2.55814
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 5.11177

Cumulative Model Updates: 116,600
Cumulative Timesteps: 972,328,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 972328204...
Checkpoint 972328204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,086.62455
Policy Entropy: 3.75108
Value Function Loss: 0.02169

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 0.84198

Collected Steps per Second: 18,803.94656
Overall Steps per Second: 9,372.30802

Timestep Collection Time: 2.65923
Timestep Consumption Time: 2.67606
PPO Batch Consumption Time: 0.31786
Total Iteration Time: 5.33529

Cumulative Model Updates: 116,606
Cumulative Timesteps: 972,378,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,415.32623
Policy Entropy: 3.75301
Value Function Loss: 0.02659

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.53357
Value Function Update Magnitude: 0.86611

Collected Steps per Second: 21,263.81094
Overall Steps per Second: 10,423.70334

Timestep Collection Time: 2.35170
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.79734

Cumulative Model Updates: 116,612
Cumulative Timesteps: 972,428,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 972428214...
Checkpoint 972428214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,254.92371
Policy Entropy: 3.75855
Value Function Loss: 0.02654

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.89426

Collected Steps per Second: 20,425.60964
Overall Steps per Second: 9,796.85639

Timestep Collection Time: 2.44820
Timestep Consumption Time: 2.65609
PPO Batch Consumption Time: 0.31124
Total Iteration Time: 5.10429

Cumulative Model Updates: 116,618
Cumulative Timesteps: 972,478,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314,473.32640
Policy Entropy: 3.73873
Value Function Loss: 0.02805

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.59837
Value Function Update Magnitude: 0.81277

Collected Steps per Second: 20,248.24796
Overall Steps per Second: 9,902.49339

Timestep Collection Time: 2.46955
Timestep Consumption Time: 2.58009
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 5.04964

Cumulative Model Updates: 116,624
Cumulative Timesteps: 972,528,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 972528224...
Checkpoint 972528224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,662.96637
Policy Entropy: 3.73823
Value Function Loss: 0.02513

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.67429

Collected Steps per Second: 21,292.42190
Overall Steps per Second: 10,075.72370

Timestep Collection Time: 2.34825
Timestep Consumption Time: 2.61417
PPO Batch Consumption Time: 0.30696
Total Iteration Time: 4.96242

Cumulative Model Updates: 116,630
Cumulative Timesteps: 972,578,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,662.96637
Policy Entropy: 3.71858
Value Function Loss: 0.02311

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.48467
Value Function Update Magnitude: 0.59659

Collected Steps per Second: 20,899.72440
Overall Steps per Second: 9,705.67292

Timestep Collection Time: 2.39324
Timestep Consumption Time: 2.76024
PPO Batch Consumption Time: 0.32692
Total Iteration Time: 5.15348

Cumulative Model Updates: 116,636
Cumulative Timesteps: 972,628,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 972628242...
Checkpoint 972628242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,792.67733
Policy Entropy: 3.72163
Value Function Loss: 0.01947

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.44733
Value Function Update Magnitude: 0.47853

Collected Steps per Second: 18,643.57154
Overall Steps per Second: 9,672.15119

Timestep Collection Time: 2.68350
Timestep Consumption Time: 2.48908
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 5.17258

Cumulative Model Updates: 116,642
Cumulative Timesteps: 972,678,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,294.78713
Policy Entropy: 3.72520
Value Function Loss: 0.01853

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14720
Policy Update Magnitude: 0.41023
Value Function Update Magnitude: 0.51500

Collected Steps per Second: 19,300.28554
Overall Steps per Second: 9,864.25116

Timestep Collection Time: 2.59126
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 5.07002

Cumulative Model Updates: 116,648
Cumulative Timesteps: 972,728,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 972728284...
Checkpoint 972728284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,187.65403
Policy Entropy: 3.73170
Value Function Loss: 0.01635

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.38710
Value Function Update Magnitude: 0.60869

Collected Steps per Second: 20,742.09205
Overall Steps per Second: 10,199.33040

Timestep Collection Time: 2.41171
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.90464

Cumulative Model Updates: 116,654
Cumulative Timesteps: 972,778,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,249.45339
Policy Entropy: 3.72073
Value Function Loss: 0.01692

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.16211
Policy Update Magnitude: 0.37094
Value Function Update Magnitude: 0.69990

Collected Steps per Second: 21,662.10324
Overall Steps per Second: 10,465.54825

Timestep Collection Time: 2.30901
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.77930

Cumulative Model Updates: 116,660
Cumulative Timesteps: 972,828,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 972828326...
Checkpoint 972828326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.71544
Value Function Loss: 0.01881

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16842
Policy Update Magnitude: 0.42205
Value Function Update Magnitude: 0.67853

Collected Steps per Second: 21,951.71676
Overall Steps per Second: 10,534.62928

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.74663

Cumulative Model Updates: 116,666
Cumulative Timesteps: 972,878,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.70851
Value Function Loss: 0.01855

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.46795
Value Function Update Magnitude: 0.74213

Collected Steps per Second: 20,546.66261
Overall Steps per Second: 9,935.60582

Timestep Collection Time: 2.43514
Timestep Consumption Time: 2.60069
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 5.03583

Cumulative Model Updates: 116,672
Cumulative Timesteps: 972,928,364

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 972928364...
Checkpoint 972928364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.72776
Value Function Loss: 0.01736

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15891
Policy Update Magnitude: 0.50605
Value Function Update Magnitude: 0.76395

Collected Steps per Second: 18,656.63429
Overall Steps per Second: 9,400.91039

Timestep Collection Time: 2.68066
Timestep Consumption Time: 2.63926
PPO Batch Consumption Time: 0.30621
Total Iteration Time: 5.31991

Cumulative Model Updates: 116,678
Cumulative Timesteps: 972,978,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73939
Value Function Loss: 0.01433

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.50515
Value Function Update Magnitude: 0.71370

Collected Steps per Second: 18,585.40733
Overall Steps per Second: 9,542.36976

Timestep Collection Time: 2.69114
Timestep Consumption Time: 2.55032
PPO Batch Consumption Time: 0.30349
Total Iteration Time: 5.24147

Cumulative Model Updates: 116,684
Cumulative Timesteps: 973,028,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 973028392...
Checkpoint 973028392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73349
Value Function Loss: 0.01285

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16094
Policy Update Magnitude: 0.44987
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 19,609.63190
Overall Steps per Second: 9,957.24655

Timestep Collection Time: 2.55079
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 5.02348

Cumulative Model Updates: 116,690
Cumulative Timesteps: 973,078,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.71752
Value Function Loss: 0.01426

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.44381
Value Function Update Magnitude: 0.59144

Collected Steps per Second: 18,958.75877
Overall Steps per Second: 9,623.16869

Timestep Collection Time: 2.63804
Timestep Consumption Time: 2.55921
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 5.19725

Cumulative Model Updates: 116,696
Cumulative Timesteps: 973,128,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 973128426...
Checkpoint 973128426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.71406
Value Function Loss: 0.01431

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.56816

Collected Steps per Second: 19,508.22715
Overall Steps per Second: 9,565.34570

Timestep Collection Time: 2.56394
Timestep Consumption Time: 2.66514
PPO Batch Consumption Time: 0.31221
Total Iteration Time: 5.22908

Cumulative Model Updates: 116,702
Cumulative Timesteps: 973,178,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.70627
Value Function Loss: 0.01475

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06884
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.51827

Collected Steps per Second: 20,005.80496
Overall Steps per Second: 9,791.10227

Timestep Collection Time: 2.50027
Timestep Consumption Time: 2.60845
PPO Batch Consumption Time: 0.30493
Total Iteration Time: 5.10872

Cumulative Model Updates: 116,708
Cumulative Timesteps: 973,228,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 973228464...
Checkpoint 973228464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73329
Value Function Loss: 0.01344

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.42742

Collected Steps per Second: 21,660.41199
Overall Steps per Second: 10,070.72733

Timestep Collection Time: 2.31030
Timestep Consumption Time: 2.65876
PPO Batch Consumption Time: 0.30634
Total Iteration Time: 4.96906

Cumulative Model Updates: 116,714
Cumulative Timesteps: 973,278,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73872
Value Function Loss: 0.01346

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.50854
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 18,680.02017
Overall Steps per Second: 9,687.63431

Timestep Collection Time: 2.67805
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 5.16390

Cumulative Model Updates: 116,720
Cumulative Timesteps: 973,328,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 973328532...
Checkpoint 973328532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.75228
Value Function Loss: 0.01156

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.46709
Value Function Update Magnitude: 0.24862

Collected Steps per Second: 20,232.09766
Overall Steps per Second: 9,793.09948

Timestep Collection Time: 2.47261
Timestep Consumption Time: 2.63569
PPO Batch Consumption Time: 0.30549
Total Iteration Time: 5.10829

Cumulative Model Updates: 116,726
Cumulative Timesteps: 973,378,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.74246
Value Function Loss: 0.01248

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05975
Policy Update Magnitude: 0.47249
Value Function Update Magnitude: 0.27299

Collected Steps per Second: 20,116.05074
Overall Steps per Second: 9,518.71554

Timestep Collection Time: 2.48667
Timestep Consumption Time: 2.76845
PPO Batch Consumption Time: 0.32523
Total Iteration Time: 5.25512

Cumulative Model Updates: 116,732
Cumulative Timesteps: 973,428,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 973428580...
Checkpoint 973428580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73447
Value Function Loss: 0.01218

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.05607
Policy Update Magnitude: 0.51994
Value Function Update Magnitude: 0.36538

Collected Steps per Second: 21,247.63333
Overall Steps per Second: 10,207.62214

Timestep Collection Time: 2.35367
Timestep Consumption Time: 2.54561
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.89928

Cumulative Model Updates: 116,738
Cumulative Timesteps: 973,478,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.72795
Value Function Loss: 0.01372

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.39997

Collected Steps per Second: 17,211.19154
Overall Steps per Second: 9,210.15965

Timestep Collection Time: 2.90544
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 5.42944

Cumulative Model Updates: 116,744
Cumulative Timesteps: 973,528,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 973528596...
Checkpoint 973528596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.74681
Value Function Loss: 0.01294

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16576
Policy Update Magnitude: 0.41920
Value Function Update Magnitude: 0.41347

Collected Steps per Second: 18,765.14691
Overall Steps per Second: 9,721.90507

Timestep Collection Time: 2.66494
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 5.14385

Cumulative Model Updates: 116,750
Cumulative Timesteps: 973,578,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.71942
Value Function Loss: 0.01606

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.19504
Policy Update Magnitude: 0.40138
Value Function Update Magnitude: 0.41857

Collected Steps per Second: 17,720.20114
Overall Steps per Second: 9,248.00204

Timestep Collection Time: 2.82164
Timestep Consumption Time: 2.58493
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 5.40657

Cumulative Model Updates: 116,756
Cumulative Timesteps: 973,628,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 973628604...
Checkpoint 973628604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.71020
Value Function Loss: 0.01615

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.21226
Policy Update Magnitude: 0.45682
Value Function Update Magnitude: 0.50132

Collected Steps per Second: 20,518.89048
Overall Steps per Second: 10,032.89315

Timestep Collection Time: 2.43756
Timestep Consumption Time: 2.54764
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.98520

Cumulative Model Updates: 116,762
Cumulative Timesteps: 973,678,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.70169
Value Function Loss: 0.01662

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.21031
Policy Update Magnitude: 0.50132
Value Function Update Magnitude: 0.54686

Collected Steps per Second: 20,915.78436
Overall Steps per Second: 10,289.42748

Timestep Collection Time: 2.39150
Timestep Consumption Time: 2.46981
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.86130

Cumulative Model Updates: 116,768
Cumulative Timesteps: 973,728,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 973728640...
Checkpoint 973728640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,319.70975
Policy Entropy: 3.73416
Value Function Loss: 0.01662

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.20564
Policy Update Magnitude: 0.57945
Value Function Update Magnitude: 0.58984

Collected Steps per Second: 19,743.61881
Overall Steps per Second: 9,610.89372

Timestep Collection Time: 2.53277
Timestep Consumption Time: 2.67029
PPO Batch Consumption Time: 0.31598
Total Iteration Time: 5.20305

Cumulative Model Updates: 116,774
Cumulative Timesteps: 973,778,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,786.84995
Policy Entropy: 3.74901
Value Function Loss: 0.01835

Mean KL Divergence: 0.02019
SB3 Clip Fraction: 0.23872
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.64343

Collected Steps per Second: 21,111.59540
Overall Steps per Second: 9,689.20578

Timestep Collection Time: 2.36912
Timestep Consumption Time: 2.79291
PPO Batch Consumption Time: 0.30808
Total Iteration Time: 5.16203

Cumulative Model Updates: 116,780
Cumulative Timesteps: 973,828,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 973828662...
Checkpoint 973828662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,973.27407
Policy Entropy: 3.77612
Value Function Loss: 0.02353

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.22099
Policy Update Magnitude: 0.63525
Value Function Update Magnitude: 0.72995

Collected Steps per Second: 18,142.45232
Overall Steps per Second: 9,784.39544

Timestep Collection Time: 2.75652
Timestep Consumption Time: 2.35468
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 5.11120

Cumulative Model Updates: 116,786
Cumulative Timesteps: 973,878,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,774.90712
Policy Entropy: 3.80814
Value Function Loss: 0.02771

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.19695
Policy Update Magnitude: 0.67467
Value Function Update Magnitude: 0.88631

Collected Steps per Second: 19,521.87560
Overall Steps per Second: 9,112.61794

Timestep Collection Time: 2.56266
Timestep Consumption Time: 2.92731
PPO Batch Consumption Time: 0.36201
Total Iteration Time: 5.48997

Cumulative Model Updates: 116,792
Cumulative Timesteps: 973,928,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 973928700...
Checkpoint 973928700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,592.01267
Policy Entropy: 3.83190
Value Function Loss: 0.02930

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.19602
Policy Update Magnitude: 0.73467
Value Function Update Magnitude: 0.93366

Collected Steps per Second: 18,170.36389
Overall Steps per Second: 9,729.97462

Timestep Collection Time: 2.75228
Timestep Consumption Time: 2.38750
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 5.13979

Cumulative Model Updates: 116,798
Cumulative Timesteps: 973,978,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,089.25813
Policy Entropy: 3.83447
Value Function Loss: 0.02728

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.19676
Policy Update Magnitude: 0.69363
Value Function Update Magnitude: 0.79431

Collected Steps per Second: 20,802.84157
Overall Steps per Second: 10,097.65034

Timestep Collection Time: 2.40352
Timestep Consumption Time: 2.54813
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.95165

Cumulative Model Updates: 116,804
Cumulative Timesteps: 974,028,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 974028710...
Checkpoint 974028710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,717.90180
Policy Entropy: 3.81897
Value Function Loss: 0.02528

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.19095
Policy Update Magnitude: 0.64714
Value Function Update Magnitude: 0.86163

Collected Steps per Second: 19,179.78602
Overall Steps per Second: 9,880.23059

Timestep Collection Time: 2.60848
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 5.06365

Cumulative Model Updates: 116,810
Cumulative Timesteps: 974,078,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762,658.02118
Policy Entropy: 3.77417
Value Function Loss: 0.02768

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.17688
Policy Update Magnitude: 0.63369
Value Function Update Magnitude: 0.75125

Collected Steps per Second: 19,268.12550
Overall Steps per Second: 10,043.52784

Timestep Collection Time: 2.59652
Timestep Consumption Time: 2.38480
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.98132

Cumulative Model Updates: 116,816
Cumulative Timesteps: 974,128,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 974128770...
Checkpoint 974128770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265,917.48247
Policy Entropy: 3.74466
Value Function Loss: 0.02557

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16806
Policy Update Magnitude: 0.61922
Value Function Update Magnitude: 0.67578

Collected Steps per Second: 19,967.51417
Overall Steps per Second: 9,901.85331

Timestep Collection Time: 2.50497
Timestep Consumption Time: 2.54641
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 5.05138

Cumulative Model Updates: 116,822
Cumulative Timesteps: 974,178,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,708.46058
Policy Entropy: 3.72360
Value Function Loss: 0.02546

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.63149
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 19,511.42563
Overall Steps per Second: 9,814.98614

Timestep Collection Time: 2.56363
Timestep Consumption Time: 2.53266
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 5.09629

Cumulative Model Updates: 116,828
Cumulative Timesteps: 974,228,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 974228808...
Checkpoint 974228808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,847.00603
Policy Entropy: 3.73709
Value Function Loss: 0.02560

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.17236
Policy Update Magnitude: 0.58331
Value Function Update Magnitude: 0.63172

Collected Steps per Second: 19,421.95278
Overall Steps per Second: 9,865.09587

Timestep Collection Time: 2.57451
Timestep Consumption Time: 2.49407
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 5.06858

Cumulative Model Updates: 116,834
Cumulative Timesteps: 974,278,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,942.12163
Policy Entropy: 3.72914
Value Function Loss: 0.02815

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.19225
Policy Update Magnitude: 0.60494
Value Function Update Magnitude: 0.59934

Collected Steps per Second: 17,857.11990
Overall Steps per Second: 9,249.33705

Timestep Collection Time: 2.80056
Timestep Consumption Time: 2.60631
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 5.40687

Cumulative Model Updates: 116,840
Cumulative Timesteps: 974,328,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 974328820...
Checkpoint 974328820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,061.20097
Policy Entropy: 3.73950
Value Function Loss: 0.02745

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.20595
Policy Update Magnitude: 0.59925
Value Function Update Magnitude: 0.51046

Collected Steps per Second: 15,627.47753
Overall Steps per Second: 8,418.63121

Timestep Collection Time: 3.20064
Timestep Consumption Time: 2.74070
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 5.94135

Cumulative Model Updates: 116,846
Cumulative Timesteps: 974,378,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,061.20097
Policy Entropy: 3.71589
Value Function Loss: 0.02433

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.19055
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.48176

Collected Steps per Second: 14,103.40221
Overall Steps per Second: 7,832.24658

Timestep Collection Time: 3.54737
Timestep Consumption Time: 2.84032
PPO Batch Consumption Time: 0.30527
Total Iteration Time: 6.38769

Cumulative Model Updates: 116,852
Cumulative Timesteps: 974,428,868

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 974428868...
Checkpoint 974428868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 505,832.79982
Policy Entropy: 3.72844
Value Function Loss: 0.03220

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17840
Policy Update Magnitude: 0.60781
Value Function Update Magnitude: 0.43473

Collected Steps per Second: 13,099.06781
Overall Steps per Second: 7,596.23171

Timestep Collection Time: 3.81981
Timestep Consumption Time: 2.76714
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 6.58695

Cumulative Model Updates: 116,858
Cumulative Timesteps: 974,478,904

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,038.79387
Policy Entropy: 3.72879
Value Function Loss: 0.03746

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.72843
Value Function Update Magnitude: 0.56013

Collected Steps per Second: 14,321.02566
Overall Steps per Second: 7,976.46692

Timestep Collection Time: 3.49151
Timestep Consumption Time: 2.77718
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 6.26869

Cumulative Model Updates: 116,864
Cumulative Timesteps: 974,528,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974528906...
Checkpoint 974528906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.21112
Policy Entropy: 3.76414
Value Function Loss: 0.04115

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.85504
Value Function Update Magnitude: 0.63309

Collected Steps per Second: 15,533.78065
Overall Steps per Second: 8,742.26602

Timestep Collection Time: 3.22047
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 5.72231

Cumulative Model Updates: 116,870
Cumulative Timesteps: 974,578,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.03914
Policy Entropy: 3.78481
Value Function Loss: 0.04034

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.85090
Value Function Update Magnitude: 0.58799

Collected Steps per Second: 19,731.14102
Overall Steps per Second: 9,726.76978

Timestep Collection Time: 2.53518
Timestep Consumption Time: 2.60753
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 5.14271

Cumulative Model Updates: 116,876
Cumulative Timesteps: 974,628,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 974628954...
Checkpoint 974628954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.81630
Policy Entropy: 3.76661
Value Function Loss: 0.03876

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.81081
Value Function Update Magnitude: 0.55908

Collected Steps per Second: 18,923.51693
Overall Steps per Second: 9,546.38260

Timestep Collection Time: 2.64486
Timestep Consumption Time: 2.59797
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 5.24282

Cumulative Model Updates: 116,882
Cumulative Timesteps: 974,679,004

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,948.19123
Policy Entropy: 3.74268
Value Function Loss: 0.03971

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.80450
Value Function Update Magnitude: 0.53527

Collected Steps per Second: 18,600.82802
Overall Steps per Second: 9,561.30014

Timestep Collection Time: 2.68913
Timestep Consumption Time: 2.54238
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 5.23151

Cumulative Model Updates: 116,888
Cumulative Timesteps: 974,729,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 974729024...
Checkpoint 974729024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,822.49443
Policy Entropy: 3.74014
Value Function Loss: 0.03907

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.90529
Value Function Update Magnitude: 0.51616

Collected Steps per Second: 18,393.12946
Overall Steps per Second: 9,368.22622

Timestep Collection Time: 2.71884
Timestep Consumption Time: 2.61920
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 5.33804

Cumulative Model Updates: 116,894
Cumulative Timesteps: 974,779,032

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.63723
Policy Entropy: 3.74150
Value Function Loss: 0.03579

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.96024
Value Function Update Magnitude: 0.47891

Collected Steps per Second: 18,501.23290
Overall Steps per Second: 9,388.34181

Timestep Collection Time: 2.70285
Timestep Consumption Time: 2.62355
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 5.32639

Cumulative Model Updates: 116,900
Cumulative Timesteps: 974,829,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 974829038...
Checkpoint 974829038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233.39383
Policy Entropy: 3.74891
Value Function Loss: 0.02991

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07457
Policy Update Magnitude: 0.86048
Value Function Update Magnitude: 0.46241

Collected Steps per Second: 18,867.52164
Overall Steps per Second: 9,681.60767

Timestep Collection Time: 2.65069
Timestep Consumption Time: 2.51498
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 5.16567

Cumulative Model Updates: 116,906
Cumulative Timesteps: 974,879,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.58424
Policy Entropy: 3.76184
Value Function Loss: 0.02386

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.71283
Value Function Update Magnitude: 0.60444

Collected Steps per Second: 21,214.06979
Overall Steps per Second: 10,237.33338

Timestep Collection Time: 2.35711
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.88448

Cumulative Model Updates: 116,912
Cumulative Timesteps: 974,929,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 974929054...
Checkpoint 974929054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,311.71846
Policy Entropy: 3.75095
Value Function Loss: 0.02433

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08924
Policy Update Magnitude: 0.61934
Value Function Update Magnitude: 0.74923

Collected Steps per Second: 21,157.96202
Overall Steps per Second: 10,190.49231

Timestep Collection Time: 2.36365
Timestep Consumption Time: 2.54387
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.90752

Cumulative Model Updates: 116,918
Cumulative Timesteps: 974,979,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,611.38108
Policy Entropy: 3.76403
Value Function Loss: 0.02492

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.62041
Value Function Update Magnitude: 0.74673

Collected Steps per Second: 20,569.99994
Overall Steps per Second: 10,042.38112

Timestep Collection Time: 2.43286
Timestep Consumption Time: 2.55042
PPO Batch Consumption Time: 0.29734
Total Iteration Time: 4.98328

Cumulative Model Updates: 116,924
Cumulative Timesteps: 975,029,108

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 975029108...
Checkpoint 975029108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.66332
Policy Entropy: 3.75184
Value Function Loss: 0.02578

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.57157
Value Function Update Magnitude: 0.75986

Collected Steps per Second: 19,173.76263
Overall Steps per Second: 9,274.90733

Timestep Collection Time: 2.60877
Timestep Consumption Time: 2.78427
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 5.39305

Cumulative Model Updates: 116,930
Cumulative Timesteps: 975,079,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,625.72815
Policy Entropy: 3.75363
Value Function Loss: 0.02685

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.57225
Value Function Update Magnitude: 0.71616

Collected Steps per Second: 13,861.08193
Overall Steps per Second: 8,077.20896

Timestep Collection Time: 3.60881
Timestep Consumption Time: 2.58417
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 6.19298

Cumulative Model Updates: 116,936
Cumulative Timesteps: 975,129,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 975129150...
Checkpoint 975129150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,099.92674
Policy Entropy: 3.72179
Value Function Loss: 0.02667

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.70838

Collected Steps per Second: 14,451.55753
Overall Steps per Second: 8,277.00477

Timestep Collection Time: 3.46163
Timestep Consumption Time: 2.58234
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 6.04397

Cumulative Model Updates: 116,942
Cumulative Timesteps: 975,179,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,127.11562
Policy Entropy: 3.72147
Value Function Loss: 0.02638

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.47541
Value Function Update Magnitude: 0.69009

Collected Steps per Second: 13,938.79827
Overall Steps per Second: 8,056.46166

Timestep Collection Time: 3.58811
Timestep Consumption Time: 2.61982
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 6.20794

Cumulative Model Updates: 116,948
Cumulative Timesteps: 975,229,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 975229190...
Checkpoint 975229190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301,555.48978
Policy Entropy: 3.72278
Value Function Loss: 0.02522

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.42048
Value Function Update Magnitude: 0.66898

Collected Steps per Second: 14,443.73718
Overall Steps per Second: 8,202.16079

Timestep Collection Time: 3.46198
Timestep Consumption Time: 2.63446
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 6.09644

Cumulative Model Updates: 116,954
Cumulative Timesteps: 975,279,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,869.50704
Policy Entropy: 3.74757
Value Function Loss: 0.02528

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15200
Policy Update Magnitude: 0.47349
Value Function Update Magnitude: 0.66023

Collected Steps per Second: 14,493.46944
Overall Steps per Second: 8,112.96217

Timestep Collection Time: 3.45204
Timestep Consumption Time: 2.71488
PPO Batch Consumption Time: 0.30693
Total Iteration Time: 6.16692

Cumulative Model Updates: 116,960
Cumulative Timesteps: 975,329,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 975329226...
Checkpoint 975329226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,117.23807
Policy Entropy: 3.74906
Value Function Loss: 0.02892

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.46472
Value Function Update Magnitude: 0.57125

Collected Steps per Second: 13,976.70443
Overall Steps per Second: 7,963.71603

Timestep Collection Time: 3.57810
Timestep Consumption Time: 2.70164
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 6.27973

Cumulative Model Updates: 116,966
Cumulative Timesteps: 975,379,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.46733
Policy Entropy: 3.77352
Value Function Loss: 0.02772

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.47027
Value Function Update Magnitude: 0.46380

Collected Steps per Second: 15,173.43421
Overall Steps per Second: 8,439.29685

Timestep Collection Time: 3.29629
Timestep Consumption Time: 2.63027
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 5.92656

Cumulative Model Updates: 116,972
Cumulative Timesteps: 975,429,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 975429252...
Checkpoint 975429252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.47881
Policy Entropy: 3.77779
Value Function Loss: 0.02303

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.44856
Value Function Update Magnitude: 0.51980

Collected Steps per Second: 13,825.01934
Overall Steps per Second: 7,728.30205

Timestep Collection Time: 3.61692
Timestep Consumption Time: 2.85332
PPO Batch Consumption Time: 0.32484
Total Iteration Time: 6.47024

Cumulative Model Updates: 116,978
Cumulative Timesteps: 975,479,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.55050
Policy Entropy: 3.76525
Value Function Loss: 0.02217

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.42918
Value Function Update Magnitude: 0.59037

Collected Steps per Second: 12,766.17714
Overall Steps per Second: 7,253.56271

Timestep Collection Time: 3.92036
Timestep Consumption Time: 2.97942
PPO Batch Consumption Time: 0.32244
Total Iteration Time: 6.89978

Cumulative Model Updates: 116,984
Cumulative Timesteps: 975,529,304

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 975529304...
Checkpoint 975529304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.76804
Policy Entropy: 3.75027
Value Function Loss: 0.02229

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.43946
Value Function Update Magnitude: 0.58829

Collected Steps per Second: 15,183.35717
Overall Steps per Second: 8,235.52082

Timestep Collection Time: 3.29506
Timestep Consumption Time: 2.77985
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 6.07490

Cumulative Model Updates: 116,990
Cumulative Timesteps: 975,579,334

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,919.87066
Policy Entropy: 3.71416
Value Function Loss: 0.02594

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.46112
Value Function Update Magnitude: 0.63548

Collected Steps per Second: 14,116.15789
Overall Steps per Second: 7,882.82922

Timestep Collection Time: 3.54275
Timestep Consumption Time: 2.80142
PPO Batch Consumption Time: 0.30849
Total Iteration Time: 6.34417

Cumulative Model Updates: 116,996
Cumulative Timesteps: 975,629,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 975629344...
Checkpoint 975629344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,253.55122
Policy Entropy: 3.73375
Value Function Loss: 0.02424

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.48058
Value Function Update Magnitude: 0.66304

Collected Steps per Second: 17,203.82679
Overall Steps per Second: 9,091.35209

Timestep Collection Time: 2.90738
Timestep Consumption Time: 2.59434
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 5.50171

Cumulative Model Updates: 117,002
Cumulative Timesteps: 975,679,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,786.60415
Policy Entropy: 3.73034
Value Function Loss: 0.02962

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.46463
Value Function Update Magnitude: 0.65130

Collected Steps per Second: 17,455.91291
Overall Steps per Second: 9,216.01663

Timestep Collection Time: 2.86493
Timestep Consumption Time: 2.56149
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 5.42642

Cumulative Model Updates: 117,008
Cumulative Timesteps: 975,729,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 975729372...
Checkpoint 975729372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,259.14273
Policy Entropy: 3.76070
Value Function Loss: 0.02680

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.61694

Collected Steps per Second: 18,686.04567
Overall Steps per Second: 9,564.91070

Timestep Collection Time: 2.67740
Timestep Consumption Time: 2.55318
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 5.23058

Cumulative Model Updates: 117,014
Cumulative Timesteps: 975,779,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,643.41033
Policy Entropy: 3.72929
Value Function Loss: 0.02769

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.50197
Value Function Update Magnitude: 0.70842

Collected Steps per Second: 18,963.09335
Overall Steps per Second: 9,517.76571

Timestep Collection Time: 2.63776
Timestep Consumption Time: 2.61768
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 5.25544

Cumulative Model Updates: 117,020
Cumulative Timesteps: 975,829,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 975829422...
Checkpoint 975829422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,817.61132
Policy Entropy: 3.74603
Value Function Loss: 0.02707

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.48281
Value Function Update Magnitude: 0.63752

Collected Steps per Second: 18,261.69054
Overall Steps per Second: 9,365.86803

Timestep Collection Time: 2.73830
Timestep Consumption Time: 2.60087
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 5.33917

Cumulative Model Updates: 117,026
Cumulative Timesteps: 975,879,428

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,317.75211
Policy Entropy: 3.74270
Value Function Loss: 0.02679

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.68804

Collected Steps per Second: 19,094.31480
Overall Steps per Second: 9,704.04166

Timestep Collection Time: 2.62057
Timestep Consumption Time: 2.53584
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 5.15641

Cumulative Model Updates: 117,032
Cumulative Timesteps: 975,929,466

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 975929466...
Checkpoint 975929466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,288.96318
Policy Entropy: 3.76604
Value Function Loss: 0.02503

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.48869
Value Function Update Magnitude: 0.52891

Collected Steps per Second: 18,629.52471
Overall Steps per Second: 9,503.79042

Timestep Collection Time: 2.68499
Timestep Consumption Time: 2.57818
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 5.26316

Cumulative Model Updates: 117,038
Cumulative Timesteps: 975,979,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,647.40831
Policy Entropy: 3.76033
Value Function Loss: 0.02161

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.48572
Value Function Update Magnitude: 0.45567

Collected Steps per Second: 18,372.87077
Overall Steps per Second: 9,177.31167

Timestep Collection Time: 2.72260
Timestep Consumption Time: 2.72801
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 5.45062

Cumulative Model Updates: 117,044
Cumulative Timesteps: 976,029,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 976029508...
Checkpoint 976029508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,601.78866
Policy Entropy: 3.74863
Value Function Loss: 0.02140

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.46997
Value Function Update Magnitude: 0.52585

Collected Steps per Second: 18,951.44720
Overall Steps per Second: 9,531.66194

Timestep Collection Time: 2.63980
Timestep Consumption Time: 2.60881
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 5.24861

Cumulative Model Updates: 117,050
Cumulative Timesteps: 976,079,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,601.78866
Policy Entropy: 3.72890
Value Function Loss: 0.02080

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.47336
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 18,579.09343
Overall Steps per Second: 9,421.54320

Timestep Collection Time: 2.69238
Timestep Consumption Time: 2.61694
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 5.30932

Cumulative Model Updates: 117,056
Cumulative Timesteps: 976,129,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 976129558...
Checkpoint 976129558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,601.78866
Policy Entropy: 3.72336
Value Function Loss: 0.02071

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.45912
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 18,600.97627
Overall Steps per Second: 9,334.85719

Timestep Collection Time: 2.69029
Timestep Consumption Time: 2.67048
PPO Batch Consumption Time: 0.30608
Total Iteration Time: 5.36077

Cumulative Model Updates: 117,062
Cumulative Timesteps: 976,179,600

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,601.78866
Policy Entropy: 3.72522
Value Function Loss: 0.01887

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.43737
Value Function Update Magnitude: 0.57746

Collected Steps per Second: 18,375.18989
Overall Steps per Second: 9,369.76910

Timestep Collection Time: 2.72128
Timestep Consumption Time: 2.61546
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 5.33674

Cumulative Model Updates: 117,068
Cumulative Timesteps: 976,229,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 976229604...
Checkpoint 976229604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,622.30426
Policy Entropy: 3.74436
Value Function Loss: 0.01905

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.42656
Value Function Update Magnitude: 0.54188

Collected Steps per Second: 19,086.85151
Overall Steps per Second: 9,632.06323

Timestep Collection Time: 2.62086
Timestep Consumption Time: 2.57263
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 5.19349

Cumulative Model Updates: 117,074
Cumulative Timesteps: 976,279,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,388.47029
Policy Entropy: 3.75332
Value Function Loss: 0.01932

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.40877
Value Function Update Magnitude: 0.55389

Collected Steps per Second: 19,549.25942
Overall Steps per Second: 9,823.77499

Timestep Collection Time: 2.55866
Timestep Consumption Time: 2.53306
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 5.09173

Cumulative Model Updates: 117,080
Cumulative Timesteps: 976,329,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 976329648...
Checkpoint 976329648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,917.63193
Policy Entropy: 3.75123
Value Function Loss: 0.02029

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.40935
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 19,818.83578
Overall Steps per Second: 9,961.55529

Timestep Collection Time: 2.52406
Timestep Consumption Time: 2.49764
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 5.02171

Cumulative Model Updates: 117,086
Cumulative Timesteps: 976,379,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,961.86223
Policy Entropy: 3.74068
Value Function Loss: 0.02083

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.45286
Value Function Update Magnitude: 0.55440

Collected Steps per Second: 19,675.16672
Overall Steps per Second: 9,757.25575

Timestep Collection Time: 2.54361
Timestep Consumption Time: 2.58549
PPO Batch Consumption Time: 0.31401
Total Iteration Time: 5.12911

Cumulative Model Updates: 117,092
Cumulative Timesteps: 976,429,718

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 976429718...
Checkpoint 976429718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,961.86223
Policy Entropy: 3.75695
Value Function Loss: 0.01996

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15417
Policy Update Magnitude: 0.43624
Value Function Update Magnitude: 0.44860

Collected Steps per Second: 20,590.51981
Overall Steps per Second: 9,970.93975

Timestep Collection Time: 2.42927
Timestep Consumption Time: 2.58731
PPO Batch Consumption Time: 0.30639
Total Iteration Time: 5.01658

Cumulative Model Updates: 117,098
Cumulative Timesteps: 976,479,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,419.06578
Policy Entropy: 3.75837
Value Function Loss: 0.01980

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.39612
Value Function Update Magnitude: 0.42869

Collected Steps per Second: 19,209.88106
Overall Steps per Second: 9,787.71947

Timestep Collection Time: 2.60481
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 5.11232

Cumulative Model Updates: 117,104
Cumulative Timesteps: 976,529,776

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 976529776...
Checkpoint 976529776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,123.27885
Policy Entropy: 3.75780
Value Function Loss: 0.01674

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.41292
Value Function Update Magnitude: 0.53405

Collected Steps per Second: 19,227.13900
Overall Steps per Second: 9,741.77212

Timestep Collection Time: 2.60049
Timestep Consumption Time: 2.53205
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 5.13254

Cumulative Model Updates: 117,110
Cumulative Timesteps: 976,579,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,008.03318
Policy Entropy: 3.75162
Value Function Loss: 0.01763

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.42252
Value Function Update Magnitude: 0.59621

Collected Steps per Second: 19,103.92616
Overall Steps per Second: 9,465.30240

Timestep Collection Time: 2.61779
Timestep Consumption Time: 2.66572
PPO Batch Consumption Time: 0.30541
Total Iteration Time: 5.28351

Cumulative Model Updates: 117,116
Cumulative Timesteps: 976,629,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 976629786...
Checkpoint 976629786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,764.95937
Policy Entropy: 3.76731
Value Function Loss: 0.01637

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.42874
Value Function Update Magnitude: 0.70591

Collected Steps per Second: 18,038.68714
Overall Steps per Second: 9,267.22775

Timestep Collection Time: 2.77282
Timestep Consumption Time: 2.62448
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 5.39730

Cumulative Model Updates: 117,122
Cumulative Timesteps: 976,679,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,565.93325
Policy Entropy: 3.75678
Value Function Loss: 0.02076

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.42334
Value Function Update Magnitude: 0.72432

Collected Steps per Second: 15,248.28742
Overall Steps per Second: 8,366.81940

Timestep Collection Time: 3.27997
Timestep Consumption Time: 2.69768
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 5.97766

Cumulative Model Updates: 117,128
Cumulative Timesteps: 976,729,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 976729818...
Checkpoint 976729818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,859.64598
Policy Entropy: 3.74992
Value Function Loss: 0.02060

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 14,121.33229
Overall Steps per Second: 7,668.19029

Timestep Collection Time: 3.54074
Timestep Consumption Time: 2.97970
PPO Batch Consumption Time: 0.32505
Total Iteration Time: 6.52044

Cumulative Model Updates: 117,134
Cumulative Timesteps: 976,779,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,202.87571
Policy Entropy: 3.72581
Value Function Loss: 0.02833

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.50927
Value Function Update Magnitude: 0.62225

Collected Steps per Second: 15,499.13402
Overall Steps per Second: 8,723.50907

Timestep Collection Time: 3.22766
Timestep Consumption Time: 2.50695
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 5.73462

Cumulative Model Updates: 117,140
Cumulative Timesteps: 976,829,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976829844...
Checkpoint 976829844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,951.72573
Policy Entropy: 3.73642
Value Function Loss: 0.03063

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.47981

Collected Steps per Second: 20,070.20238
Overall Steps per Second: 9,716.63844

Timestep Collection Time: 2.49265
Timestep Consumption Time: 2.65604
PPO Batch Consumption Time: 0.30913
Total Iteration Time: 5.14869

Cumulative Model Updates: 117,146
Cumulative Timesteps: 976,879,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372.62949
Policy Entropy: 3.73832
Value Function Loss: 0.03320

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.56813
Value Function Update Magnitude: 0.43500

Collected Steps per Second: 18,567.27124
Overall Steps per Second: 9,345.16848

Timestep Collection Time: 2.69345
Timestep Consumption Time: 2.65798
PPO Batch Consumption Time: 0.30832
Total Iteration Time: 5.35143

Cumulative Model Updates: 117,152
Cumulative Timesteps: 976,929,882

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 976929882...
Checkpoint 976929882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10465
Policy Entropy: 3.75041
Value Function Loss: 0.02839

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.58167
Value Function Update Magnitude: 0.47388

Collected Steps per Second: 20,646.59397
Overall Steps per Second: 9,729.04830

Timestep Collection Time: 2.42306
Timestep Consumption Time: 2.71906
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 5.14213

Cumulative Model Updates: 117,158
Cumulative Timesteps: 976,979,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10465
Policy Entropy: 3.74208
Value Function Loss: 0.02495

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14452
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.54248

Collected Steps per Second: 15,422.98026
Overall Steps per Second: 8,321.10911

Timestep Collection Time: 3.24347
Timestep Consumption Time: 2.76823
PPO Batch Consumption Time: 0.31270
Total Iteration Time: 6.01170

Cumulative Model Updates: 117,164
Cumulative Timesteps: 977,029,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 977029934...
Checkpoint 977029934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10465
Policy Entropy: 3.71596
Value Function Loss: 0.02250

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.48352
Value Function Update Magnitude: 0.59101

Collected Steps per Second: 15,819.35616
Overall Steps per Second: 8,592.24056

Timestep Collection Time: 3.16119
Timestep Consumption Time: 2.65894
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 5.82013

Cumulative Model Updates: 117,170
Cumulative Timesteps: 977,079,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10465
Policy Entropy: 3.72236
Value Function Loss: 0.02083

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.48103
Value Function Update Magnitude: 0.48419

Collected Steps per Second: 17,711.06390
Overall Steps per Second: 8,990.19116

Timestep Collection Time: 2.82309
Timestep Consumption Time: 2.73852
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 5.56162

Cumulative Model Updates: 117,176
Cumulative Timesteps: 977,129,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 977129942...
Checkpoint 977129942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249.10465
Policy Entropy: 3.71616
Value Function Loss: 0.02233

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14881
Policy Update Magnitude: 0.44322
Value Function Update Magnitude: 0.36519

Collected Steps per Second: 18,055.21379
Overall Steps per Second: 8,635.10450

Timestep Collection Time: 2.77117
Timestep Consumption Time: 3.02309
PPO Batch Consumption Time: 0.32654
Total Iteration Time: 5.79426

Cumulative Model Updates: 117,182
Cumulative Timesteps: 977,179,976

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,691.94680
Policy Entropy: 3.74351
Value Function Loss: 0.02121

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.39559
Value Function Update Magnitude: 0.30749

Collected Steps per Second: 19,723.63802
Overall Steps per Second: 9,781.16137

Timestep Collection Time: 2.53625
Timestep Consumption Time: 2.57807
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 5.11432

Cumulative Model Updates: 117,188
Cumulative Timesteps: 977,230,000

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 977230000...
Checkpoint 977230000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,691.94680
Policy Entropy: 3.73686
Value Function Loss: 0.02076

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.43456
Value Function Update Magnitude: 0.36394

Collected Steps per Second: 20,964.95389
Overall Steps per Second: 9,938.81855

Timestep Collection Time: 2.38512
Timestep Consumption Time: 2.64606
PPO Batch Consumption Time: 0.30900
Total Iteration Time: 5.03118

Cumulative Model Updates: 117,194
Cumulative Timesteps: 977,280,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,691.94680
Policy Entropy: 3.76001
Value Function Loss: 0.01602

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.49625
Value Function Update Magnitude: 0.49190

Collected Steps per Second: 20,408.30398
Overall Steps per Second: 10,052.56575

Timestep Collection Time: 2.45096
Timestep Consumption Time: 2.52488
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.97584

Cumulative Model Updates: 117,200
Cumulative Timesteps: 977,330,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 977330024...
Checkpoint 977330024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457,691.94680
Policy Entropy: 3.74134
Value Function Loss: 0.01319

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.47171
Value Function Update Magnitude: 0.55755

Collected Steps per Second: 21,286.00288
Overall Steps per Second: 10,318.40520

Timestep Collection Time: 2.34906
Timestep Consumption Time: 2.49685
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.84590

Cumulative Model Updates: 117,206
Cumulative Timesteps: 977,380,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,691.94680
Policy Entropy: 3.74720
Value Function Loss: 0.01364

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05331
Policy Update Magnitude: 0.49891
Value Function Update Magnitude: 0.53061

Collected Steps per Second: 21,556.40224
Overall Steps per Second: 10,128.30660

Timestep Collection Time: 2.32005
Timestep Consumption Time: 2.61779
PPO Batch Consumption Time: 0.30398
Total Iteration Time: 4.93784

Cumulative Model Updates: 117,212
Cumulative Timesteps: 977,430,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 977430038...
Checkpoint 977430038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,766.58266
Policy Entropy: 3.72665
Value Function Loss: 0.01491

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.53171
Value Function Update Magnitude: 0.55811

Collected Steps per Second: 19,898.04579
Overall Steps per Second: 10,048.47499

Timestep Collection Time: 2.51301
Timestep Consumption Time: 2.46327
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.97628

Cumulative Model Updates: 117,218
Cumulative Timesteps: 977,480,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,766.58266
Policy Entropy: 3.72673
Value Function Loss: 0.01810

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06384
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.49428

Collected Steps per Second: 19,797.57214
Overall Steps per Second: 10,044.12702

Timestep Collection Time: 2.52688
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.98062

Cumulative Model Updates: 117,224
Cumulative Timesteps: 977,530,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 977530068...
Checkpoint 977530068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731,766.58266
Policy Entropy: 3.71839
Value Function Loss: 0.01941

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.58730
Value Function Update Magnitude: 0.38589

Collected Steps per Second: 19,440.12366
Overall Steps per Second: 9,738.90661

Timestep Collection Time: 2.57406
Timestep Consumption Time: 2.56410
PPO Batch Consumption Time: 0.30132
Total Iteration Time: 5.13815

Cumulative Model Updates: 117,230
Cumulative Timesteps: 977,580,108

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731,766.58266
Policy Entropy: 3.71672
Value Function Loss: 0.02058

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.18708
Policy Update Magnitude: 0.48631
Value Function Update Magnitude: 0.35686

Collected Steps per Second: 21,504.95667
Overall Steps per Second: 10,419.69004

Timestep Collection Time: 2.32644
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.80149

Cumulative Model Updates: 117,236
Cumulative Timesteps: 977,630,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 977630138...
Checkpoint 977630138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,768.61285
Policy Entropy: 3.71611
Value Function Loss: 0.02534

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.18696
Policy Update Magnitude: 0.44391
Value Function Update Magnitude: 0.34927

Collected Steps per Second: 20,632.46596
Overall Steps per Second: 10,013.71037

Timestep Collection Time: 2.42337
Timestep Consumption Time: 2.56979
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 4.99315

Cumulative Model Updates: 117,242
Cumulative Timesteps: 977,680,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,728.95521
Policy Entropy: 3.72365
Value Function Loss: 0.02639

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.17996
Policy Update Magnitude: 0.46242
Value Function Update Magnitude: 0.41682

Collected Steps per Second: 21,552.02030
Overall Steps per Second: 10,190.21732

Timestep Collection Time: 2.32136
Timestep Consumption Time: 2.58825
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.90961

Cumulative Model Updates: 117,248
Cumulative Timesteps: 977,730,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 977730168...
Checkpoint 977730168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318,230.74446
Policy Entropy: 3.74475
Value Function Loss: 0.02625

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17004
Policy Update Magnitude: 0.51790
Value Function Update Magnitude: 0.44543

Collected Steps per Second: 21,314.67433
Overall Steps per Second: 10,116.38573

Timestep Collection Time: 2.34834
Timestep Consumption Time: 2.59948
PPO Batch Consumption Time: 0.30334
Total Iteration Time: 4.94781

Cumulative Model Updates: 117,254
Cumulative Timesteps: 977,780,222

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,888.49727
Policy Entropy: 3.77153
Value Function Loss: 0.01957

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.51373
Value Function Update Magnitude: 0.66396

Collected Steps per Second: 19,472.68944
Overall Steps per Second: 9,561.27555

Timestep Collection Time: 2.56986
Timestep Consumption Time: 2.66396
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 5.23382

Cumulative Model Updates: 117,260
Cumulative Timesteps: 977,830,264

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 977830264...
Checkpoint 977830264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,207.95008
Policy Entropy: 3.79546
Value Function Loss: 0.01733

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.49213
Value Function Update Magnitude: 0.75447

Collected Steps per Second: 15,995.45848
Overall Steps per Second: 6,753.92610

Timestep Collection Time: 3.12776
Timestep Consumption Time: 4.27978
PPO Batch Consumption Time: 0.56269
Total Iteration Time: 7.40754

Cumulative Model Updates: 117,266
Cumulative Timesteps: 977,880,294

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.23006
Policy Entropy: 3.79095
Value Function Loss: 0.01524

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.45466
Value Function Update Magnitude: 0.72982

Collected Steps per Second: 12,739.79336
Overall Steps per Second: 7,190.81742

Timestep Collection Time: 3.92659
Timestep Consumption Time: 3.03006
PPO Batch Consumption Time: 0.31365
Total Iteration Time: 6.95665

Cumulative Model Updates: 117,272
Cumulative Timesteps: 977,930,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 977930318...
Checkpoint 977930318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.10493
Policy Entropy: 3.75650
Value Function Loss: 0.01660

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.40506
Value Function Update Magnitude: 0.73484

Collected Steps per Second: 19,013.56838
Overall Steps per Second: 9,522.59141

Timestep Collection Time: 2.62981
Timestep Consumption Time: 2.62108
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 5.25088

Cumulative Model Updates: 117,278
Cumulative Timesteps: 977,980,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582.10493
Policy Entropy: 3.74050
Value Function Loss: 0.01787

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.41769
Value Function Update Magnitude: 0.72682

Collected Steps per Second: 17,217.52242
Overall Steps per Second: 9,056.74450

Timestep Collection Time: 2.90576
Timestep Consumption Time: 2.61830
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 5.52406

Cumulative Model Updates: 117,284
Cumulative Timesteps: 978,030,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 978030350...
Checkpoint 978030350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.10493
Policy Entropy: 3.71953
Value Function Loss: 0.01959

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.44289
Value Function Update Magnitude: 0.66746

Collected Steps per Second: 16,436.55965
Overall Steps per Second: 8,794.24301

Timestep Collection Time: 3.04212
Timestep Consumption Time: 2.64364
PPO Batch Consumption Time: 0.30777
Total Iteration Time: 5.68577

Cumulative Model Updates: 117,290
Cumulative Timesteps: 978,080,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,555.97554
Policy Entropy: 3.72211
Value Function Loss: 0.02303

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.44365
Value Function Update Magnitude: 0.52122

Collected Steps per Second: 17,019.77852
Overall Steps per Second: 9,185.21345

Timestep Collection Time: 2.93823
Timestep Consumption Time: 2.50617
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 5.44440

Cumulative Model Updates: 117,296
Cumulative Timesteps: 978,130,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 978130360...
Checkpoint 978130360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,607.94969
Policy Entropy: 3.72859
Value Function Loss: 0.02211

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.49419
Value Function Update Magnitude: 0.50794

Collected Steps per Second: 18,111.25729
Overall Steps per Second: 9,618.49953

Timestep Collection Time: 2.76105
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 5.19894

Cumulative Model Updates: 117,302
Cumulative Timesteps: 978,180,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,488.66551
Policy Entropy: 3.74448
Value Function Loss: 0.02095

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 19,935.35501
Overall Steps per Second: 9,772.88145

Timestep Collection Time: 2.50841
Timestep Consumption Time: 2.60840
PPO Batch Consumption Time: 0.29870
Total Iteration Time: 5.11681

Cumulative Model Updates: 117,308
Cumulative Timesteps: 978,230,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 978230372...
Checkpoint 978230372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,470.66266
Policy Entropy: 3.75694
Value Function Loss: 0.01811

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.49303
Value Function Update Magnitude: 0.74825

Collected Steps per Second: 20,193.78605
Overall Steps per Second: 10,023.77384

Timestep Collection Time: 2.47650
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.98914

Cumulative Model Updates: 117,314
Cumulative Timesteps: 978,280,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,547.71919
Policy Entropy: 3.72930
Value Function Loss: 0.01981

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.48577
Value Function Update Magnitude: 0.72609

Collected Steps per Second: 20,823.45970
Overall Steps per Second: 10,144.41831

Timestep Collection Time: 2.40181
Timestep Consumption Time: 2.52839
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.93020

Cumulative Model Updates: 117,320
Cumulative Timesteps: 978,330,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 978330396...
Checkpoint 978330396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,113.47434
Policy Entropy: 3.72974
Value Function Loss: 0.01995

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.47651
Value Function Update Magnitude: 0.70738

Collected Steps per Second: 20,950.09866
Overall Steps per Second: 9,904.61966

Timestep Collection Time: 2.38691
Timestep Consumption Time: 2.66185
PPO Batch Consumption Time: 0.30711
Total Iteration Time: 5.04876

Cumulative Model Updates: 117,326
Cumulative Timesteps: 978,380,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,019.93807
Policy Entropy: 3.72762
Value Function Loss: 0.02237

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.48825
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 19,474.62069
Overall Steps per Second: 9,628.97962

Timestep Collection Time: 2.56744
Timestep Consumption Time: 2.62521
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 5.19266

Cumulative Model Updates: 117,332
Cumulative Timesteps: 978,430,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 978430402...
Checkpoint 978430402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,654.20598
Policy Entropy: 3.74352
Value Function Loss: 0.01792

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.44365
Value Function Update Magnitude: 0.57194

Collected Steps per Second: 20,051.39000
Overall Steps per Second: 9,659.38207

Timestep Collection Time: 2.49539
Timestep Consumption Time: 2.68465
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 5.18004

Cumulative Model Updates: 117,338
Cumulative Timesteps: 978,480,438

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,654.20598
Policy Entropy: 3.73276
Value Function Loss: 0.01537

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.42463
Value Function Update Magnitude: 0.62254

Collected Steps per Second: 17,664.37109
Overall Steps per Second: 9,074.91015

Timestep Collection Time: 2.83169
Timestep Consumption Time: 2.68021
PPO Batch Consumption Time: 0.30368
Total Iteration Time: 5.51190

Cumulative Model Updates: 117,344
Cumulative Timesteps: 978,530,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978530458...
Checkpoint 978530458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,654.20598
Policy Entropy: 3.73128
Value Function Loss: 0.01416

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.39346
Value Function Update Magnitude: 0.58524

Collected Steps per Second: 18,560.69498
Overall Steps per Second: 9,381.47932

Timestep Collection Time: 2.69516
Timestep Consumption Time: 2.63705
PPO Batch Consumption Time: 0.30620
Total Iteration Time: 5.33221

Cumulative Model Updates: 117,350
Cumulative Timesteps: 978,580,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,654.20598
Policy Entropy: 3.71712
Value Function Loss: 0.01540

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.41215
Value Function Update Magnitude: 0.52614

Collected Steps per Second: 16,919.26223
Overall Steps per Second: 8,843.78871

Timestep Collection Time: 2.95521
Timestep Consumption Time: 2.69847
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 5.65369

Cumulative Model Updates: 117,356
Cumulative Timesteps: 978,630,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 978630482...
Checkpoint 978630482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,984.11104
Policy Entropy: 3.70967
Value Function Loss: 0.02116

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.45279
Value Function Update Magnitude: 0.51341

Collected Steps per Second: 13,918.36660
Overall Steps per Second: 7,924.34927

Timestep Collection Time: 3.59410
Timestep Consumption Time: 2.71860
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 6.31270

Cumulative Model Updates: 117,362
Cumulative Timesteps: 978,680,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,036.66768
Policy Entropy: 3.72393
Value Function Loss: 0.02125

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.46611
Value Function Update Magnitude: 0.51890

Collected Steps per Second: 13,858.32921
Overall Steps per Second: 7,756.51435

Timestep Collection Time: 3.61010
Timestep Consumption Time: 2.83996
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 6.45006

Cumulative Model Updates: 117,368
Cumulative Timesteps: 978,730,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 978730536...
Checkpoint 978730536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,036.66768
Policy Entropy: 3.72688
Value Function Loss: 0.02080

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.46636
Value Function Update Magnitude: 0.48809

Collected Steps per Second: 13,476.32959
Overall Steps per Second: 7,652.26315

Timestep Collection Time: 3.71288
Timestep Consumption Time: 2.82584
PPO Batch Consumption Time: 0.29986
Total Iteration Time: 6.53872

Cumulative Model Updates: 117,374
Cumulative Timesteps: 978,780,572

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361,476.04930
Policy Entropy: 3.71787
Value Function Loss: 0.02323

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.47615
Value Function Update Magnitude: 0.46149

Collected Steps per Second: 12,150.35777
Overall Steps per Second: 6,882.76950

Timestep Collection Time: 4.11659
Timestep Consumption Time: 3.15055
PPO Batch Consumption Time: 0.34316
Total Iteration Time: 7.26713

Cumulative Model Updates: 117,380
Cumulative Timesteps: 978,830,590

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 978830590...
Checkpoint 978830590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,476.04930
Policy Entropy: 3.69870
Value Function Loss: 0.02807

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.53110

Collected Steps per Second: 12,649.31552
Overall Steps per Second: 7,326.22276

Timestep Collection Time: 3.95484
Timestep Consumption Time: 2.87351
PPO Batch Consumption Time: 0.30324
Total Iteration Time: 6.82835

Cumulative Model Updates: 117,386
Cumulative Timesteps: 978,880,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,837.57992
Policy Entropy: 3.71901
Value Function Loss: 0.02635

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.54039
Value Function Update Magnitude: 0.66088

Collected Steps per Second: 13,615.69580
Overall Steps per Second: 7,616.63817

Timestep Collection Time: 3.67297
Timestep Consumption Time: 2.89292
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 6.56589

Cumulative Model Updates: 117,392
Cumulative Timesteps: 978,930,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 978930626...
Checkpoint 978930626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,703.00199
Policy Entropy: 3.73157
Value Function Loss: 0.02782

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 13,461.13610
Overall Steps per Second: 7,273.38960

Timestep Collection Time: 3.71648
Timestep Consumption Time: 3.16175
PPO Batch Consumption Time: 0.36361
Total Iteration Time: 6.87822

Cumulative Model Updates: 117,398
Cumulative Timesteps: 978,980,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,227.42514
Policy Entropy: 3.76345
Value Function Loss: 0.02491

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 14,651.62758
Overall Steps per Second: 7,901.31846

Timestep Collection Time: 3.41436
Timestep Consumption Time: 2.91698
PPO Batch Consumption Time: 0.32931
Total Iteration Time: 6.33135

Cumulative Model Updates: 117,404
Cumulative Timesteps: 979,030,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 979030680...
Checkpoint 979030680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,065.79941
Policy Entropy: 3.73595
Value Function Loss: 0.02539

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.53578
Value Function Update Magnitude: 0.62302

Collected Steps per Second: 14,451.69607
Overall Steps per Second: 7,639.97646

Timestep Collection Time: 3.46188
Timestep Consumption Time: 3.08657
PPO Batch Consumption Time: 0.33702
Total Iteration Time: 6.54845

Cumulative Model Updates: 117,410
Cumulative Timesteps: 979,080,710

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,321.49549
Policy Entropy: 3.74684
Value Function Loss: 0.02433

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.63821

Collected Steps per Second: 13,435.41643
Overall Steps per Second: 7,583.20853

Timestep Collection Time: 3.72404
Timestep Consumption Time: 2.87396
PPO Batch Consumption Time: 0.30960
Total Iteration Time: 6.59800

Cumulative Model Updates: 117,416
Cumulative Timesteps: 979,130,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 979130744...
Checkpoint 979130744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,189.31607
Policy Entropy: 3.74436
Value Function Loss: 0.02534

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13916
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.73947

Collected Steps per Second: 13,536.40997
Overall Steps per Second: 7,488.38360

Timestep Collection Time: 3.69507
Timestep Consumption Time: 2.98434
PPO Batch Consumption Time: 0.33090
Total Iteration Time: 6.67941

Cumulative Model Updates: 117,422
Cumulative Timesteps: 979,180,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,712.22085
Policy Entropy: 3.77336
Value Function Loss: 0.02603

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.59891
Value Function Update Magnitude: 0.69073

Collected Steps per Second: 13,333.59785
Overall Steps per Second: 7,421.52653

Timestep Collection Time: 3.75023
Timestep Consumption Time: 2.98747
PPO Batch Consumption Time: 0.31355
Total Iteration Time: 6.73770

Cumulative Model Updates: 117,428
Cumulative Timesteps: 979,230,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 979230766...
Checkpoint 979230766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.54285
Policy Entropy: 3.77971
Value Function Loss: 0.02823

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.58952
Value Function Update Magnitude: 0.64471

Collected Steps per Second: 12,653.21954
Overall Steps per Second: 7,137.04618

Timestep Collection Time: 3.95393
Timestep Consumption Time: 3.05597
PPO Batch Consumption Time: 0.32585
Total Iteration Time: 7.00990

Cumulative Model Updates: 117,434
Cumulative Timesteps: 979,280,796

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153.64096
Policy Entropy: 3.79403
Value Function Loss: 0.02646

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.63651

Collected Steps per Second: 13,726.63114
Overall Steps per Second: 7,532.93061

Timestep Collection Time: 3.64576
Timestep Consumption Time: 2.99760
PPO Batch Consumption Time: 0.33131
Total Iteration Time: 6.64336

Cumulative Model Updates: 117,440
Cumulative Timesteps: 979,330,840

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 979330840...
Checkpoint 979330840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,800.09453
Policy Entropy: 3.77757
Value Function Loss: 0.02612

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.50933
Value Function Update Magnitude: 0.56289

Collected Steps per Second: 13,135.86998
Overall Steps per Second: 7,254.67710

Timestep Collection Time: 3.80744
Timestep Consumption Time: 3.08660
PPO Batch Consumption Time: 0.34723
Total Iteration Time: 6.89404

Cumulative Model Updates: 117,446
Cumulative Timesteps: 979,380,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,701.52845
Policy Entropy: 3.78088
Value Function Loss: 0.02546

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15265
Policy Update Magnitude: 0.52209
Value Function Update Magnitude: 0.46652

Collected Steps per Second: 14,581.17614
Overall Steps per Second: 7,843.72643

Timestep Collection Time: 3.43155
Timestep Consumption Time: 2.94756
PPO Batch Consumption Time: 0.32768
Total Iteration Time: 6.37911

Cumulative Model Updates: 117,452
Cumulative Timesteps: 979,430,890

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 979430890...
Checkpoint 979430890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.65457
Policy Entropy: 3.76062
Value Function Loss: 0.02669

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.60960

Collected Steps per Second: 13,912.34262
Overall Steps per Second: 7,844.55421

Timestep Collection Time: 3.59609
Timestep Consumption Time: 2.78159
PPO Batch Consumption Time: 0.30069
Total Iteration Time: 6.37767

Cumulative Model Updates: 117,458
Cumulative Timesteps: 979,480,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,507.05039
Policy Entropy: 3.76371
Value Function Loss: 0.02651

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.56944

Collected Steps per Second: 14,550.61960
Overall Steps per Second: 8,007.42117

Timestep Collection Time: 3.43793
Timestep Consumption Time: 2.80928
PPO Batch Consumption Time: 0.30718
Total Iteration Time: 6.24720

Cumulative Model Updates: 117,464
Cumulative Timesteps: 979,530,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 979530944...
Checkpoint 979530944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,777.49722
Policy Entropy: 3.75607
Value Function Loss: 0.02723

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.15420
Policy Update Magnitude: 0.48221
Value Function Update Magnitude: 0.50127

Collected Steps per Second: 13,563.69336
Overall Steps per Second: 7,725.23513

Timestep Collection Time: 3.69000
Timestep Consumption Time: 2.78877
PPO Batch Consumption Time: 0.30942
Total Iteration Time: 6.47877

Cumulative Model Updates: 117,470
Cumulative Timesteps: 979,580,994

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,334.16723
Policy Entropy: 3.77732
Value Function Loss: 0.02693

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.46842
Value Function Update Magnitude: 0.53644

Collected Steps per Second: 12,795.09553
Overall Steps per Second: 7,373.92161

Timestep Collection Time: 3.90775
Timestep Consumption Time: 2.87291
PPO Batch Consumption Time: 0.31370
Total Iteration Time: 6.78065

Cumulative Model Updates: 117,476
Cumulative Timesteps: 979,630,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 979630994...
Checkpoint 979630994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,189.80894
Policy Entropy: 3.76873
Value Function Loss: 0.02933

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.49022
Value Function Update Magnitude: 0.60609

Collected Steps per Second: 15,162.70683
Overall Steps per Second: 8,278.73833

Timestep Collection Time: 3.30007
Timestep Consumption Time: 2.74409
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 6.04416

Cumulative Model Updates: 117,482
Cumulative Timesteps: 979,681,032

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,116.55185
Policy Entropy: 3.76292
Value Function Loss: 0.02833

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.49636
Value Function Update Magnitude: 0.60221

Collected Steps per Second: 15,896.07935
Overall Steps per Second: 8,599.19546

Timestep Collection Time: 3.14694
Timestep Consumption Time: 2.67035
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 5.81729

Cumulative Model Updates: 117,488
Cumulative Timesteps: 979,731,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 979731056...
Checkpoint 979731056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,375.70109
Policy Entropy: 3.74302
Value Function Loss: 0.02483

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.47460
Value Function Update Magnitude: 0.68745

Collected Steps per Second: 16,045.84652
Overall Steps per Second: 8,518.86655

Timestep Collection Time: 3.11757
Timestep Consumption Time: 2.75458
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 5.87214

Cumulative Model Updates: 117,494
Cumulative Timesteps: 979,781,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,266.73419
Policy Entropy: 3.74381
Value Function Loss: 0.02028

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.43665
Value Function Update Magnitude: 0.75459

Collected Steps per Second: 16,422.37484
Overall Steps per Second: 8,643.05759

Timestep Collection Time: 3.04499
Timestep Consumption Time: 2.74069
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 5.78568

Cumulative Model Updates: 117,500
Cumulative Timesteps: 979,831,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 979831086...
Checkpoint 979831086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,752.76744
Policy Entropy: 3.73559
Value Function Loss: 0.01917

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.41145
Value Function Update Magnitude: 0.76782

Collected Steps per Second: 15,914.18565
Overall Steps per Second: 8,505.38647

Timestep Collection Time: 3.14424
Timestep Consumption Time: 2.73886
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 5.88310

Cumulative Model Updates: 117,506
Cumulative Timesteps: 979,881,124

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,150.46846
Policy Entropy: 3.74810
Value Function Loss: 0.01735

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14688
Policy Update Magnitude: 0.37655
Value Function Update Magnitude: 0.65988

Collected Steps per Second: 15,956.98332
Overall Steps per Second: 8,448.80869

Timestep Collection Time: 3.13530
Timestep Consumption Time: 2.78624
PPO Batch Consumption Time: 0.30995
Total Iteration Time: 5.92154

Cumulative Model Updates: 117,512
Cumulative Timesteps: 979,931,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 979931154...
Checkpoint 979931154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.16879
Policy Entropy: 3.75237
Value Function Loss: 0.01696

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.33562
Value Function Update Magnitude: 0.58864

Collected Steps per Second: 16,662.37996
Overall Steps per Second: 8,744.71803

Timestep Collection Time: 3.00269
Timestep Consumption Time: 2.71870
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 5.72140

Cumulative Model Updates: 117,518
Cumulative Timesteps: 979,981,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.16879
Policy Entropy: 3.74346
Value Function Loss: 0.01530

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14763
Policy Update Magnitude: 0.31972
Value Function Update Magnitude: 0.52764

Collected Steps per Second: 15,811.31910
Overall Steps per Second: 8,319.75646

Timestep Collection Time: 3.16381
Timestep Consumption Time: 2.84887
PPO Batch Consumption Time: 0.31290
Total Iteration Time: 6.01268

Cumulative Model Updates: 117,524
Cumulative Timesteps: 980,031,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 980031210...
Checkpoint 980031210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.16879
Policy Entropy: 3.72141
Value Function Loss: 0.01715

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.35846
Value Function Update Magnitude: 0.51904

Collected Steps per Second: 16,107.08420
Overall Steps per Second: 8,564.26888

Timestep Collection Time: 3.10609
Timestep Consumption Time: 2.73563
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 5.84171

Cumulative Model Updates: 117,530
Cumulative Timesteps: 980,081,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 400,152.28653
Policy Entropy: 3.72285
Value Function Loss: 0.01694

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.40807
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 16,281.59713
Overall Steps per Second: 8,628.49770

Timestep Collection Time: 3.07095
Timestep Consumption Time: 2.72380
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 5.79475

Cumulative Model Updates: 117,536
Cumulative Timesteps: 980,131,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 980131240...
Checkpoint 980131240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,123.25024
Policy Entropy: 3.72065
Value Function Loss: 0.01940

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.45839
Value Function Update Magnitude: 0.68428

Collected Steps per Second: 16,215.15686
Overall Steps per Second: 8,549.21131

Timestep Collection Time: 3.08600
Timestep Consumption Time: 2.76717
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 5.85317

Cumulative Model Updates: 117,542
Cumulative Timesteps: 980,181,280

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,123.25024
Policy Entropy: 3.73477
Value Function Loss: 0.01772

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.43347
Value Function Update Magnitude: 0.67048

Collected Steps per Second: 16,490.54297
Overall Steps per Second: 8,603.46862

Timestep Collection Time: 3.03240
Timestep Consumption Time: 2.77990
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 5.81231

Cumulative Model Updates: 117,548
Cumulative Timesteps: 980,231,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 980231286...
Checkpoint 980231286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,584.27732
Policy Entropy: 3.73008
Value Function Loss: 0.01914

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.41100
Value Function Update Magnitude: 0.56422

Collected Steps per Second: 16,090.01450
Overall Steps per Second: 8,544.48221

Timestep Collection Time: 3.10777
Timestep Consumption Time: 2.74443
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 5.85220

Cumulative Model Updates: 117,554
Cumulative Timesteps: 980,281,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,584.27732
Policy Entropy: 3.73518
Value Function Loss: 0.01946

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.39161
Value Function Update Magnitude: 0.43640

Collected Steps per Second: 15,242.63056
Overall Steps per Second: 8,076.54602

Timestep Collection Time: 3.28159
Timestep Consumption Time: 2.91166
PPO Batch Consumption Time: 0.31617
Total Iteration Time: 6.19324

Cumulative Model Updates: 117,560
Cumulative Timesteps: 980,331,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980331310...
Checkpoint 980331310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673,584.27732
Policy Entropy: 3.73299
Value Function Loss: 0.02000

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.42617
Value Function Update Magnitude: 0.43848

Collected Steps per Second: 15,170.40602
Overall Steps per Second: 8,233.94385

Timestep Collection Time: 3.29629
Timestep Consumption Time: 2.77687
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 6.07315

Cumulative Model Updates: 117,566
Cumulative Timesteps: 980,381,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673,584.27732
Policy Entropy: 3.72264
Value Function Loss: 0.01976

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14735
Policy Update Magnitude: 0.42077
Value Function Update Magnitude: 0.43396

Collected Steps per Second: 16,010.68010
Overall Steps per Second: 8,338.24419

Timestep Collection Time: 3.12342
Timestep Consumption Time: 2.87401
PPO Batch Consumption Time: 0.31561
Total Iteration Time: 5.99743

Cumulative Model Updates: 117,572
Cumulative Timesteps: 980,431,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 980431324...
Checkpoint 980431324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895,771.78739
Policy Entropy: 3.71430
Value Function Loss: 0.01785

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.40989
Value Function Update Magnitude: 0.47643

Collected Steps per Second: 15,291.61695
Overall Steps per Second: 8,321.98838

Timestep Collection Time: 3.26977
Timestep Consumption Time: 2.73841
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 6.00818

Cumulative Model Updates: 117,578
Cumulative Timesteps: 980,481,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,003.51618
Policy Entropy: 3.71462
Value Function Loss: 0.01798

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.15481
Policy Update Magnitude: 0.37922
Value Function Update Magnitude: 0.50038

Collected Steps per Second: 16,242.04908
Overall Steps per Second: 8,567.28553

Timestep Collection Time: 3.07904
Timestep Consumption Time: 2.75828
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 5.83732

Cumulative Model Updates: 117,584
Cumulative Timesteps: 980,531,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 980531334...
Checkpoint 980531334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,916.18586
Policy Entropy: 3.71438
Value Function Loss: 0.02515

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.42524
Value Function Update Magnitude: 0.53947

Collected Steps per Second: 15,646.05459
Overall Steps per Second: 8,355.77214

Timestep Collection Time: 3.19697
Timestep Consumption Time: 2.78931
PPO Batch Consumption Time: 0.30761
Total Iteration Time: 5.98628

Cumulative Model Updates: 117,590
Cumulative Timesteps: 980,581,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,795.05634
Policy Entropy: 3.73254
Value Function Loss: 0.02986

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.52227
Value Function Update Magnitude: 0.47941

Collected Steps per Second: 14,857.69361
Overall Steps per Second: 8,210.27845

Timestep Collection Time: 3.36701
Timestep Consumption Time: 2.72608
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 6.09309

Cumulative Model Updates: 117,596
Cumulative Timesteps: 980,631,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 980631380...
Checkpoint 980631380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,225.05579
Policy Entropy: 3.72394
Value Function Loss: 0.03280

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.47179

Collected Steps per Second: 14,846.79203
Overall Steps per Second: 8,088.02235

Timestep Collection Time: 3.36800
Timestep Consumption Time: 2.81448
PPO Batch Consumption Time: 0.30831
Total Iteration Time: 6.18248

Cumulative Model Updates: 117,602
Cumulative Timesteps: 980,681,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,414.93185
Policy Entropy: 3.73395
Value Function Loss: 0.02622

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.59601
Value Function Update Magnitude: 0.60590

Collected Steps per Second: 14,918.97223
Overall Steps per Second: 7,891.97552

Timestep Collection Time: 3.35144
Timestep Consumption Time: 2.98411
PPO Batch Consumption Time: 0.33385
Total Iteration Time: 6.33555

Cumulative Model Updates: 117,608
Cumulative Timesteps: 980,731,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 980731384...
Checkpoint 980731384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,529.70031
Policy Entropy: 3.71084
Value Function Loss: 0.02745

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.74299

Collected Steps per Second: 16,013.92143
Overall Steps per Second: 8,523.07376

Timestep Collection Time: 3.12278
Timestep Consumption Time: 2.74458
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 5.86737

Cumulative Model Updates: 117,614
Cumulative Timesteps: 980,781,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,946.64231
Policy Entropy: 3.72365
Value Function Loss: 0.02378

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.78784

Collected Steps per Second: 15,731.37205
Overall Steps per Second: 8,570.85880

Timestep Collection Time: 3.18090
Timestep Consumption Time: 2.65748
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 5.83839

Cumulative Model Updates: 117,620
Cumulative Timesteps: 980,831,432

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 980831432...
Checkpoint 980831432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,764.42633
Policy Entropy: 3.69638
Value Function Loss: 0.02808

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.73615

Collected Steps per Second: 16,184.90608
Overall Steps per Second: 8,402.24272

Timestep Collection Time: 3.09029
Timestep Consumption Time: 2.86241
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 5.95270

Cumulative Model Updates: 117,626
Cumulative Timesteps: 980,881,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273,987.18283
Policy Entropy: 3.73274
Value Function Loss: 0.02775

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.57662
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 17,897.05971
Overall Steps per Second: 9,131.39261

Timestep Collection Time: 2.79532
Timestep Consumption Time: 2.68336
PPO Batch Consumption Time: 0.30877
Total Iteration Time: 5.47868

Cumulative Model Updates: 117,632
Cumulative Timesteps: 980,931,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 980931476...
Checkpoint 980931476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,397.48067
Policy Entropy: 3.71989
Value Function Loss: 0.03283

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.58335
Value Function Update Magnitude: 0.58590

Collected Steps per Second: 17,089.74313
Overall Steps per Second: 9,171.33337

Timestep Collection Time: 2.92608
Timestep Consumption Time: 2.52634
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 5.45242

Cumulative Model Updates: 117,638
Cumulative Timesteps: 980,981,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,722.95932
Policy Entropy: 3.73673
Value Function Loss: 0.02770

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.61274
Value Function Update Magnitude: 0.70129

Collected Steps per Second: 17,232.19053
Overall Steps per Second: 8,880.91477

Timestep Collection Time: 2.90422
Timestep Consumption Time: 2.73101
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 5.63523

Cumulative Model Updates: 117,644
Cumulative Timesteps: 981,031,528

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 981031528...
Checkpoint 981031528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,404.78686
Policy Entropy: 3.71267
Value Function Loss: 0.03254

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.60929
Value Function Update Magnitude: 0.67267

Collected Steps per Second: 17,082.54117
Overall Steps per Second: 8,950.49497

Timestep Collection Time: 2.92802
Timestep Consumption Time: 2.66028
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 5.58829

Cumulative Model Updates: 117,650
Cumulative Timesteps: 981,081,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,586.14140
Policy Entropy: 3.72955
Value Function Loss: 0.02970

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.61611
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 17,933.77980
Overall Steps per Second: 9,293.26770

Timestep Collection Time: 2.78971
Timestep Consumption Time: 2.59376
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 5.38347

Cumulative Model Updates: 117,656
Cumulative Timesteps: 981,131,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 981131576...
Checkpoint 981131576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,498.99959
Policy Entropy: 3.72800
Value Function Loss: 0.03515

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.60275
Value Function Update Magnitude: 0.57403

Collected Steps per Second: 17,694.65545
Overall Steps per Second: 9,086.66646

Timestep Collection Time: 2.82616
Timestep Consumption Time: 2.67728
PPO Batch Consumption Time: 0.30283
Total Iteration Time: 5.50345

Cumulative Model Updates: 117,662
Cumulative Timesteps: 981,181,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,670.15542
Policy Entropy: 3.74175
Value Function Loss: 0.03079

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.67110
Value Function Update Magnitude: 0.65218

Collected Steps per Second: 17,463.29298
Overall Steps per Second: 9,227.79217

Timestep Collection Time: 2.86475
Timestep Consumption Time: 2.55670
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 5.42145

Cumulative Model Updates: 117,668
Cumulative Timesteps: 981,231,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 981231612...
Checkpoint 981231612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,670.15542
Policy Entropy: 3.71788
Value Function Loss: 0.02795

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.62008
Value Function Update Magnitude: 0.69327

Collected Steps per Second: 18,323.17863
Overall Steps per Second: 9,465.58712

Timestep Collection Time: 2.73031
Timestep Consumption Time: 2.55494
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 5.28525

Cumulative Model Updates: 117,674
Cumulative Timesteps: 981,281,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,396.55329
Policy Entropy: 3.72086
Value Function Loss: 0.02114

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.59210

Collected Steps per Second: 18,037.69890
Overall Steps per Second: 9,339.47519

Timestep Collection Time: 2.77253
Timestep Consumption Time: 2.58216
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 5.35469

Cumulative Model Updates: 117,680
Cumulative Timesteps: 981,331,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 981331650...
Checkpoint 981331650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,973.97340
Policy Entropy: 3.72545
Value Function Loss: 0.01841

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.49464
Value Function Update Magnitude: 0.58116

Collected Steps per Second: 17,967.05260
Overall Steps per Second: 9,081.16342

Timestep Collection Time: 2.78454
Timestep Consumption Time: 2.72466
PPO Batch Consumption Time: 0.30297
Total Iteration Time: 5.50921

Cumulative Model Updates: 117,686
Cumulative Timesteps: 981,381,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,982.89089
Policy Entropy: 3.76230
Value Function Loss: 0.01875

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.48264
Value Function Update Magnitude: 0.71115

Collected Steps per Second: 17,681.56875
Overall Steps per Second: 9,269.64961

Timestep Collection Time: 2.82792
Timestep Consumption Time: 2.56625
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 5.39416

Cumulative Model Updates: 117,692
Cumulative Timesteps: 981,431,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 981431682...
Checkpoint 981431682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,228.02751
Policy Entropy: 3.78369
Value Function Loss: 0.01958

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.48092
Value Function Update Magnitude: 0.82780

Collected Steps per Second: 18,032.50920
Overall Steps per Second: 9,229.80162

Timestep Collection Time: 2.77410
Timestep Consumption Time: 2.64573
PPO Batch Consumption Time: 0.30330
Total Iteration Time: 5.41983

Cumulative Model Updates: 117,698
Cumulative Timesteps: 981,481,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,835.98682
Policy Entropy: 3.77576
Value Function Loss: 0.02492

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.73580

Collected Steps per Second: 16,549.17605
Overall Steps per Second: 8,800.20197

Timestep Collection Time: 3.02420
Timestep Consumption Time: 2.66294
PPO Batch Consumption Time: 0.31234
Total Iteration Time: 5.68714

Cumulative Model Updates: 117,704
Cumulative Timesteps: 981,531,754

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 981531754...
Checkpoint 981531754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,915.37172
Policy Entropy: 3.76968
Value Function Loss: 0.02673

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15234
Policy Update Magnitude: 0.61272
Value Function Update Magnitude: 0.74789

Collected Steps per Second: 17,699.62236
Overall Steps per Second: 9,355.73797

Timestep Collection Time: 2.82594
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 5.34624

Cumulative Model Updates: 117,710
Cumulative Timesteps: 981,581,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,976.20219
Policy Entropy: 3.75230
Value Function Loss: 0.02989

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.61603
Value Function Update Magnitude: 0.69794

Collected Steps per Second: 16,943.86019
Overall Steps per Second: 9,155.69674

Timestep Collection Time: 2.95246
Timestep Consumption Time: 2.51146
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 5.46392

Cumulative Model Updates: 117,716
Cumulative Timesteps: 981,631,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 981631798...
Checkpoint 981631798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,726.88608
Policy Entropy: 3.76882
Value Function Loss: 0.02601

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.59551

Collected Steps per Second: 17,894.93357
Overall Steps per Second: 9,423.58205

Timestep Collection Time: 2.79632
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 5.31008

Cumulative Model Updates: 117,722
Cumulative Timesteps: 981,681,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.97067
Policy Entropy: 3.76635
Value Function Loss: 0.02394

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.59285
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 16,511.38550
Overall Steps per Second: 8,962.85313

Timestep Collection Time: 3.02833
Timestep Consumption Time: 2.55047
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 5.57880

Cumulative Model Updates: 117,728
Cumulative Timesteps: 981,731,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 981731840...
Checkpoint 981731840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.97067
Policy Entropy: 3.76229
Value Function Loss: 0.01804

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.52398

Collected Steps per Second: 19,064.07927
Overall Steps per Second: 9,587.96812

Timestep Collection Time: 2.62347
Timestep Consumption Time: 2.59286
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 5.21633

Cumulative Model Updates: 117,734
Cumulative Timesteps: 981,781,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.97067
Policy Entropy: 3.74950
Value Function Loss: 0.01406

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07843
Policy Update Magnitude: 0.55196
Value Function Update Magnitude: 0.50162

Collected Steps per Second: 18,299.04845
Overall Steps per Second: 9,143.81400

Timestep Collection Time: 2.73271
Timestep Consumption Time: 2.73612
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 5.46883

Cumulative Model Updates: 117,740
Cumulative Timesteps: 981,831,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 981831860...
Checkpoint 981831860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.97067
Policy Entropy: 3.73593
Value Function Loss: 0.01507

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11192
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.48705

Collected Steps per Second: 18,392.44512
Overall Steps per Second: 9,497.03927

Timestep Collection Time: 2.71851
Timestep Consumption Time: 2.54629
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 5.26480

Cumulative Model Updates: 117,746
Cumulative Timesteps: 981,881,860

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.97067
Policy Entropy: 3.73120
Value Function Loss: 0.01639

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06232
Policy Update Magnitude: 0.62438
Value Function Update Magnitude: 0.52084

Collected Steps per Second: 18,769.83761
Overall Steps per Second: 9,354.13219

Timestep Collection Time: 2.66523
Timestep Consumption Time: 2.68278
PPO Batch Consumption Time: 0.30059
Total Iteration Time: 5.34801

Cumulative Model Updates: 117,752
Cumulative Timesteps: 981,931,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 981931886...
Checkpoint 981931886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,230.34961
Policy Entropy: 3.73929
Value Function Loss: 0.01925

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.63639
Value Function Update Magnitude: 0.41471

Collected Steps per Second: 17,720.59860
Overall Steps per Second: 8,956.25805

Timestep Collection Time: 2.82406
Timestep Consumption Time: 2.76354
PPO Batch Consumption Time: 0.31462
Total Iteration Time: 5.58760

Cumulative Model Updates: 117,758
Cumulative Timesteps: 981,981,930

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,787.10010
Policy Entropy: 3.75365
Value Function Loss: 0.03146

Mean KL Divergence: 0.03257
SB3 Clip Fraction: 0.29279
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.38274

Collected Steps per Second: 18,196.62972
Overall Steps per Second: 9,237.30104

Timestep Collection Time: 2.74798
Timestep Consumption Time: 2.66529
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 5.41327

Cumulative Model Updates: 117,764
Cumulative Timesteps: 982,031,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982031934...
Checkpoint 982031934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,296.96414
Policy Entropy: 3.71536
Value Function Loss: 0.03747

Mean KL Divergence: 0.02312
SB3 Clip Fraction: 0.25674
Policy Update Magnitude: 0.67321
Value Function Update Magnitude: 0.46015

Collected Steps per Second: 18,000.04010
Overall Steps per Second: 9,129.24141

Timestep Collection Time: 2.77788
Timestep Consumption Time: 2.69924
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 5.47713

Cumulative Model Updates: 117,770
Cumulative Timesteps: 982,081,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,044.20002
Policy Entropy: 3.72023
Value Function Loss: 0.04011

Mean KL Divergence: 0.01938
SB3 Clip Fraction: 0.21965
Policy Update Magnitude: 0.85099
Value Function Update Magnitude: 0.58047

Collected Steps per Second: 18,355.57753
Overall Steps per Second: 9,507.65487

Timestep Collection Time: 2.72419
Timestep Consumption Time: 2.53516
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 5.25934

Cumulative Model Updates: 117,776
Cumulative Timesteps: 982,131,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982131940...
Checkpoint 982131940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,983.21598
Policy Entropy: 3.76941
Value Function Loss: 0.03129

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.21685
Policy Update Magnitude: 0.77281
Value Function Update Magnitude: 0.61983

Collected Steps per Second: 18,244.88614
Overall Steps per Second: 9,420.27103

Timestep Collection Time: 2.74302
Timestep Consumption Time: 2.56957
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 5.31259

Cumulative Model Updates: 117,782
Cumulative Timesteps: 982,181,986

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845,699.26318
Policy Entropy: 3.80308
Value Function Loss: 0.03497

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.71515
Value Function Update Magnitude: 0.84840

Collected Steps per Second: 17,976.15690
Overall Steps per Second: 9,307.44596

Timestep Collection Time: 2.78213
Timestep Consumption Time: 2.59120
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 5.37333

Cumulative Model Updates: 117,788
Cumulative Timesteps: 982,231,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 982231998...
Checkpoint 982231998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364.75961
Policy Entropy: 3.82987
Value Function Loss: 0.03798

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.80030
Value Function Update Magnitude: 0.90792

Collected Steps per Second: 18,623.96796
Overall Steps per Second: 9,563.72971

Timestep Collection Time: 2.68493
Timestep Consumption Time: 2.54358
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 5.22850

Cumulative Model Updates: 117,794
Cumulative Timesteps: 982,282,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.37573
Policy Entropy: 3.82516
Value Function Loss: 0.03832

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17330
Policy Update Magnitude: 0.83306
Value Function Update Magnitude: 0.87691

Collected Steps per Second: 18,671.24654
Overall Steps per Second: 9,596.38822

Timestep Collection Time: 2.67984
Timestep Consumption Time: 2.53420
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 5.21405

Cumulative Model Updates: 117,800
Cumulative Timesteps: 982,332,038

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 982332038...
Checkpoint 982332038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520,802.87950
Policy Entropy: 3.77419
Value Function Loss: 0.04796

Mean KL Divergence: 0.02362
SB3 Clip Fraction: 0.25383
Policy Update Magnitude: 0.68857
Value Function Update Magnitude: 0.61854

Collected Steps per Second: 17,243.13234
Overall Steps per Second: 8,967.83391

Timestep Collection Time: 2.90040
Timestep Consumption Time: 2.67642
PPO Batch Consumption Time: 0.30536
Total Iteration Time: 5.57682

Cumulative Model Updates: 117,806
Cumulative Timesteps: 982,382,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,550.40954
Policy Entropy: 3.76227
Value Function Loss: 0.05136

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.73016
Value Function Update Magnitude: 0.59224

Collected Steps per Second: 19,428.14596
Overall Steps per Second: 9,739.71653

Timestep Collection Time: 2.57626
Timestep Consumption Time: 2.56270
PPO Batch Consumption Time: 0.30512
Total Iteration Time: 5.13896

Cumulative Model Updates: 117,812
Cumulative Timesteps: 982,432,102

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 982432102...
Checkpoint 982432102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434.22420
Policy Entropy: 3.74792
Value Function Loss: 0.05248

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.19054
Policy Update Magnitude: 0.90278
Value Function Update Magnitude: 0.77012

Collected Steps per Second: 16,734.60331
Overall Steps per Second: 9,214.44396

Timestep Collection Time: 2.98830
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 5.42713

Cumulative Model Updates: 117,818
Cumulative Timesteps: 982,482,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,480.82809
Policy Entropy: 3.77806
Value Function Loss: 0.04746

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18077
Policy Update Magnitude: 0.84285
Value Function Update Magnitude: 0.66629

Collected Steps per Second: 19,361.03401
Overall Steps per Second: 9,603.26675

Timestep Collection Time: 2.58364
Timestep Consumption Time: 2.62521
PPO Batch Consumption Time: 0.31219
Total Iteration Time: 5.20885

Cumulative Model Updates: 117,824
Cumulative Timesteps: 982,532,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 982532132...
Checkpoint 982532132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,368.51947
Policy Entropy: 3.77232
Value Function Loss: 0.03679

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.70662
Value Function Update Magnitude: 0.51221

Collected Steps per Second: 18,648.89122
Overall Steps per Second: 10,061.01878

Timestep Collection Time: 2.68316
Timestep Consumption Time: 2.29029
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.97345

Cumulative Model Updates: 117,830
Cumulative Timesteps: 982,582,170

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,368.51947
Policy Entropy: 3.71641
Value Function Loss: 0.03328

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.17092
Policy Update Magnitude: 0.61380
Value Function Update Magnitude: 0.51241

Collected Steps per Second: 19,144.46433
Overall Steps per Second: 9,613.48755

Timestep Collection Time: 2.61214
Timestep Consumption Time: 2.58972
PPO Batch Consumption Time: 0.31281
Total Iteration Time: 5.20186

Cumulative Model Updates: 117,836
Cumulative Timesteps: 982,632,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982632178...
Checkpoint 982632178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,485.69944
Policy Entropy: 3.71433
Value Function Loss: 0.03391

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.59616
Value Function Update Magnitude: 0.50782

Collected Steps per Second: 18,499.34830
Overall Steps per Second: 9,513.40351

Timestep Collection Time: 2.70539
Timestep Consumption Time: 2.55540
PPO Batch Consumption Time: 0.30917
Total Iteration Time: 5.26079

Cumulative Model Updates: 117,842
Cumulative Timesteps: 982,682,226

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,609.49894
Policy Entropy: 3.72677
Value Function Loss: 0.03278

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 18,130.40402
Overall Steps per Second: 9,491.49072

Timestep Collection Time: 2.75923
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.30776
Total Iteration Time: 5.27062

Cumulative Model Updates: 117,848
Cumulative Timesteps: 982,732,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 982732252...
Checkpoint 982732252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.17211
Policy Entropy: 3.77042
Value Function Loss: 0.03574

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.58410
Value Function Update Magnitude: 0.64765

Collected Steps per Second: 21,365.86500
Overall Steps per Second: 10,698.52108

Timestep Collection Time: 2.34140
Timestep Consumption Time: 2.33458
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.67597

Cumulative Model Updates: 117,854
Cumulative Timesteps: 982,782,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132.65527
Policy Entropy: 3.77607
Value Function Loss: 0.03705

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.60906
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 21,754.37565
Overall Steps per Second: 10,453.92269

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.78404

Cumulative Model Updates: 117,860
Cumulative Timesteps: 982,832,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 982832290...
Checkpoint 982832290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.52882
Policy Entropy: 3.77395
Value Function Loss: 0.03573

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.65057
Value Function Update Magnitude: 0.57519

Collected Steps per Second: 22,586.38949
Overall Steps per Second: 10,649.86193

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.48227
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69696

Cumulative Model Updates: 117,866
Cumulative Timesteps: 982,882,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,710.66914
Policy Entropy: 3.74971
Value Function Loss: 0.03334

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.67675
Value Function Update Magnitude: 0.60592

Collected Steps per Second: 22,341.67934
Overall Steps per Second: 10,616.30665

Timestep Collection Time: 2.23922
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.71237

Cumulative Model Updates: 117,872
Cumulative Timesteps: 982,932,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 982932340...
Checkpoint 982932340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,192.75993
Policy Entropy: 3.74487
Value Function Loss: 0.03292

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.63087
Value Function Update Magnitude: 0.56950

Collected Steps per Second: 22,566.02808
Overall Steps per Second: 10,582.29132

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.51016
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.72676

Cumulative Model Updates: 117,878
Cumulative Timesteps: 982,982,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,632.03899
Policy Entropy: 3.73886
Value Function Loss: 0.03209

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.58398
Value Function Update Magnitude: 0.57820

Collected Steps per Second: 22,299.12998
Overall Steps per Second: 10,523.45678

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.75395

Cumulative Model Updates: 117,884
Cumulative Timesteps: 983,032,388

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 983032388...
Checkpoint 983032388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,663.71836
Policy Entropy: 3.74532
Value Function Loss: 0.03409

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.50052

Collected Steps per Second: 22,538.52125
Overall Steps per Second: 10,564.97862

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.73489

Cumulative Model Updates: 117,890
Cumulative Timesteps: 983,082,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,870.79579
Policy Entropy: 3.75395
Value Function Loss: 0.02964

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.49855

Collected Steps per Second: 22,393.31823
Overall Steps per Second: 10,595.42797

Timestep Collection Time: 2.23361
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72072

Cumulative Model Updates: 117,896
Cumulative Timesteps: 983,132,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 983132430...
Checkpoint 983132430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,947.74083
Policy Entropy: 3.76464
Value Function Loss: 0.02885

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.52823
Value Function Update Magnitude: 0.59670

Collected Steps per Second: 22,581.50351
Overall Steps per Second: 10,788.86304

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.63700

Cumulative Model Updates: 117,902
Cumulative Timesteps: 983,182,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,890.94394
Policy Entropy: 3.77119
Value Function Loss: 0.02846

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.53208
Value Function Update Magnitude: 0.65558

Collected Steps per Second: 22,157.86698
Overall Steps per Second: 10,494.90431

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.50818
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.76517

Cumulative Model Updates: 117,908
Cumulative Timesteps: 983,232,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 983232468...
Checkpoint 983232468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,306.76259
Policy Entropy: 3.77303
Value Function Loss: 0.02751

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.66918

Collected Steps per Second: 22,855.92834
Overall Steps per Second: 10,686.35968

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.68129

Cumulative Model Updates: 117,914
Cumulative Timesteps: 983,282,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,306.76259
Policy Entropy: 3.74885
Value Function Loss: 0.02562

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.49361
Value Function Update Magnitude: 0.56445

Collected Steps per Second: 22,145.55315
Overall Steps per Second: 10,433.05915

Timestep Collection Time: 2.25842
Timestep Consumption Time: 2.53538
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.79380

Cumulative Model Updates: 117,920
Cumulative Timesteps: 983,332,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 983332508...
Checkpoint 983332508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,306.76259
Policy Entropy: 3.73822
Value Function Loss: 0.02369

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.47379
Value Function Update Magnitude: 0.45928

Collected Steps per Second: 22,091.05417
Overall Steps per Second: 10,676.31016

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68533

Cumulative Model Updates: 117,926
Cumulative Timesteps: 983,382,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,306.76259
Policy Entropy: 3.72644
Value Function Loss: 0.02282

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.42203

Collected Steps per Second: 21,940.40604
Overall Steps per Second: 10,630.72722

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70504

Cumulative Model Updates: 117,932
Cumulative Timesteps: 983,432,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 983432548...
Checkpoint 983432548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,306.76259
Policy Entropy: 3.72996
Value Function Loss: 0.02276

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.47466
Value Function Update Magnitude: 0.54640

Collected Steps per Second: 21,657.57390
Overall Steps per Second: 10,417.17827

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.80111

Cumulative Model Updates: 117,938
Cumulative Timesteps: 983,482,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,871.39788
Policy Entropy: 3.73785
Value Function Loss: 0.02817

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.45483
Value Function Update Magnitude: 0.50932

Collected Steps per Second: 22,442.13363
Overall Steps per Second: 10,626.04025

Timestep Collection Time: 2.22867
Timestep Consumption Time: 2.47826
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70693

Cumulative Model Updates: 117,944
Cumulative Timesteps: 983,532,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 983532578...
Checkpoint 983532578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,871.39788
Policy Entropy: 3.73308
Value Function Loss: 0.02909

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.46330
Value Function Update Magnitude: 0.42404

Collected Steps per Second: 22,877.21368
Overall Steps per Second: 10,883.34480

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59620

Cumulative Model Updates: 117,950
Cumulative Timesteps: 983,582,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,112.46133
Policy Entropy: 3.74419
Value Function Loss: 0.02476

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.45602
Value Function Update Magnitude: 0.47389

Collected Steps per Second: 22,399.70096
Overall Steps per Second: 10,503.34329

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.76267

Cumulative Model Updates: 117,956
Cumulative Timesteps: 983,632,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 983632624...
Checkpoint 983632624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,986.00247
Policy Entropy: 3.73201
Value Function Loss: 0.02259

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.44565
Value Function Update Magnitude: 0.58476

Collected Steps per Second: 22,789.38169
Overall Steps per Second: 10,652.34862

Timestep Collection Time: 2.19541
Timestep Consumption Time: 2.50140
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.69680

Cumulative Model Updates: 117,962
Cumulative Timesteps: 983,682,656

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,986.00247
Policy Entropy: 3.73934
Value Function Loss: 0.02182

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.44690
Value Function Update Magnitude: 0.53931

Collected Steps per Second: 22,440.04880
Overall Steps per Second: 10,561.86708

Timestep Collection Time: 2.22834
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73439

Cumulative Model Updates: 117,968
Cumulative Timesteps: 983,732,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983732660...
Checkpoint 983732660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,832.02855
Policy Entropy: 3.73035
Value Function Loss: 0.02516

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.43159
Value Function Update Magnitude: 0.46219

Collected Steps per Second: 21,725.98433
Overall Steps per Second: 10,565.27586

Timestep Collection Time: 2.30139
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.73248

Cumulative Model Updates: 117,974
Cumulative Timesteps: 983,782,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,914.40782
Policy Entropy: 3.76051
Value Function Loss: 0.02098

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.46428
Value Function Update Magnitude: 0.46693

Collected Steps per Second: 22,362.31939
Overall Steps per Second: 10,556.37683

Timestep Collection Time: 2.23608
Timestep Consumption Time: 2.50077
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.73685

Cumulative Model Updates: 117,980
Cumulative Timesteps: 983,832,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 983832664...
Checkpoint 983832664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,775.92821
Policy Entropy: 3.76249
Value Function Loss: 0.02483

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.45941
Value Function Update Magnitude: 0.48660

Collected Steps per Second: 22,758.42071
Overall Steps per Second: 10,715.98095

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.66686

Cumulative Model Updates: 117,986
Cumulative Timesteps: 983,882,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,394.05431
Policy Entropy: 3.75929
Value Function Loss: 0.02205

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.43969
Value Function Update Magnitude: 0.50406

Collected Steps per Second: 22,550.04974
Overall Steps per Second: 10,694.88146

Timestep Collection Time: 2.21844
Timestep Consumption Time: 2.45912
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.67756

Cumulative Model Updates: 117,992
Cumulative Timesteps: 983,932,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 983932700...
Checkpoint 983932700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,738.80427
Policy Entropy: 3.72263
Value Function Loss: 0.02538

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.44303
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 21,643.85934
Overall Steps per Second: 10,712.40629

Timestep Collection Time: 2.31105
Timestep Consumption Time: 2.35830
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.66935

Cumulative Model Updates: 117,998
Cumulative Timesteps: 983,982,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,738.80427
Policy Entropy: 3.71531
Value Function Loss: 0.02190

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.44455
Value Function Update Magnitude: 0.47330

Collected Steps per Second: 21,836.99626
Overall Steps per Second: 10,576.49760

Timestep Collection Time: 2.28969
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.72746

Cumulative Model Updates: 118,004
Cumulative Timesteps: 984,032,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 984032720...
Checkpoint 984032720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,738.80427
Policy Entropy: 3.71724
Value Function Loss: 0.02167

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.43519
Value Function Update Magnitude: 0.41250

Collected Steps per Second: 22,037.84138
Overall Steps per Second: 10,644.46137

Timestep Collection Time: 2.27028
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.70028

Cumulative Model Updates: 118,010
Cumulative Timesteps: 984,082,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,875.85514
Policy Entropy: 3.71643
Value Function Loss: 0.02072

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.45650
Value Function Update Magnitude: 0.43877

Collected Steps per Second: 22,731.19332
Overall Steps per Second: 10,844.63536

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.61242

Cumulative Model Updates: 118,016
Cumulative Timesteps: 984,132,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 984132772...
Checkpoint 984132772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,875.85514
Policy Entropy: 3.70625
Value Function Loss: 0.02485

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.45304
Value Function Update Magnitude: 0.40849

Collected Steps per Second: 22,551.10541
Overall Steps per Second: 10,718.61639

Timestep Collection Time: 2.21798
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.66646

Cumulative Model Updates: 118,022
Cumulative Timesteps: 984,182,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,875.85514
Policy Entropy: 3.71418
Value Function Loss: 0.02381

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.48864
Value Function Update Magnitude: 0.36693

Collected Steps per Second: 22,538.83076
Overall Steps per Second: 10,548.44288

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.74060

Cumulative Model Updates: 118,028
Cumulative Timesteps: 984,232,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 984232796...
Checkpoint 984232796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,875.85514
Policy Entropy: 3.70819
Value Function Loss: 0.02493

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15338
Policy Update Magnitude: 0.46262
Value Function Update Magnitude: 0.38707

Collected Steps per Second: 22,888.16085
Overall Steps per Second: 10,655.39089

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.69453

Cumulative Model Updates: 118,034
Cumulative Timesteps: 984,282,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,435.38188
Policy Entropy: 3.72970
Value Function Loss: 0.02245

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.44917
Value Function Update Magnitude: 0.41709

Collected Steps per Second: 22,859.33282
Overall Steps per Second: 10,802.90365

Timestep Collection Time: 2.18764
Timestep Consumption Time: 2.44149
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.62913

Cumulative Model Updates: 118,040
Cumulative Timesteps: 984,332,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 984332826...
Checkpoint 984332826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,100.13568
Policy Entropy: 3.73106
Value Function Loss: 0.02089

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.44304
Value Function Update Magnitude: 0.49994

Collected Steps per Second: 22,891.09399
Overall Steps per Second: 10,640.25386

Timestep Collection Time: 2.18452
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69970

Cumulative Model Updates: 118,046
Cumulative Timesteps: 984,382,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,978.17538
Policy Entropy: 3.73757
Value Function Loss: 0.01978

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.43659
Value Function Update Magnitude: 0.63649

Collected Steps per Second: 22,549.49717
Overall Steps per Second: 10,566.10059

Timestep Collection Time: 2.21797
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.73344

Cumulative Model Updates: 118,052
Cumulative Timesteps: 984,432,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 984432846...
Checkpoint 984432846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,430.66341
Policy Entropy: 3.74280
Value Function Loss: 0.01974

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.51793
Value Function Update Magnitude: 0.74970

Collected Steps per Second: 22,799.75775
Overall Steps per Second: 10,687.27484

Timestep Collection Time: 2.19406
Timestep Consumption Time: 2.48665
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.68071

Cumulative Model Updates: 118,058
Cumulative Timesteps: 984,482,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,286.50035
Policy Entropy: 3.74002
Value Function Loss: 0.02077

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 22,791.55511
Overall Steps per Second: 10,797.53421

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.63421

Cumulative Model Updates: 118,064
Cumulative Timesteps: 984,532,908

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 984532908...
Checkpoint 984532908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.10842
Policy Entropy: 3.75899
Value Function Loss: 0.02042

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.49141
Value Function Update Magnitude: 0.56508

Collected Steps per Second: 22,812.20776
Overall Steps per Second: 10,646.02394

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69659

Cumulative Model Updates: 118,070
Cumulative Timesteps: 984,582,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,524.82386
Policy Entropy: 3.73518
Value Function Loss: 0.02078

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.44944
Value Function Update Magnitude: 0.56135

Collected Steps per Second: 22,566.22672
Overall Steps per Second: 10,739.71908

Timestep Collection Time: 2.21694
Timestep Consumption Time: 2.44128
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.65822

Cumulative Model Updates: 118,076
Cumulative Timesteps: 984,632,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 984632936...
Checkpoint 984632936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,583.03713
Policy Entropy: 3.73055
Value Function Loss: 0.02314

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.47925
Value Function Update Magnitude: 0.68865

Collected Steps per Second: 22,478.02089
Overall Steps per Second: 10,708.02644

Timestep Collection Time: 2.22484
Timestep Consumption Time: 2.44549
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.67033

Cumulative Model Updates: 118,082
Cumulative Timesteps: 984,682,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,687.89143
Policy Entropy: 3.72400
Value Function Loss: 0.02338

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.56251
Value Function Update Magnitude: 0.81126

Collected Steps per Second: 22,533.85383
Overall Steps per Second: 10,590.40222

Timestep Collection Time: 2.21959
Timestep Consumption Time: 2.50317
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.72277

Cumulative Model Updates: 118,088
Cumulative Timesteps: 984,732,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 984732962...
Checkpoint 984732962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,715.45715
Policy Entropy: 3.74010
Value Function Loss: 0.02629

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.61117
Value Function Update Magnitude: 0.90258

Collected Steps per Second: 22,530.64167
Overall Steps per Second: 10,534.90873

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.74613

Cumulative Model Updates: 118,094
Cumulative Timesteps: 984,782,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,263.19400
Policy Entropy: 3.75537
Value Function Loss: 0.02534

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.60768
Value Function Update Magnitude: 0.94233

Collected Steps per Second: 22,481.31530
Overall Steps per Second: 10,534.22546

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.52388
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.74928

Cumulative Model Updates: 118,100
Cumulative Timesteps: 984,832,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 984832992...
Checkpoint 984832992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,472.96694
Policy Entropy: 3.74145
Value Function Loss: 0.02666

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.77012

Collected Steps per Second: 22,660.46697
Overall Steps per Second: 10,583.10343

Timestep Collection Time: 2.20684
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.72527

Cumulative Model Updates: 118,106
Cumulative Timesteps: 984,883,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,472.96694
Policy Entropy: 3.73922
Value Function Loss: 0.02224

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.51890
Value Function Update Magnitude: 0.73104

Collected Steps per Second: 22,502.08441
Overall Steps per Second: 10,550.48680

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.74082

Cumulative Model Updates: 118,112
Cumulative Timesteps: 984,933,018

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 984933018...
Checkpoint 984933018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,948.42781
Policy Entropy: 3.71857
Value Function Loss: 0.02746

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.49640
Value Function Update Magnitude: 0.74433

Collected Steps per Second: 22,862.95071
Overall Steps per Second: 10,657.97105

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.69226

Cumulative Model Updates: 118,118
Cumulative Timesteps: 984,983,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,139.45629
Policy Entropy: 3.75292
Value Function Loss: 0.02780

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.66310

Collected Steps per Second: 22,581.25765
Overall Steps per Second: 10,725.69872

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.44796
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.66263

Cumulative Model Updates: 118,124
Cumulative Timesteps: 985,033,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 985033038...
Checkpoint 985033038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,331.87767
Policy Entropy: 3.75882
Value Function Loss: 0.02810

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.54582
Value Function Update Magnitude: 0.58962

Collected Steps per Second: 22,672.51988
Overall Steps per Second: 10,739.91993

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.45120
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.65739

Cumulative Model Updates: 118,130
Cumulative Timesteps: 985,083,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.18795
Policy Entropy: 3.77710
Value Function Loss: 0.02245

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.49626
Value Function Update Magnitude: 0.53516

Collected Steps per Second: 22,783.47922
Overall Steps per Second: 10,808.35698

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.62642

Cumulative Model Updates: 118,136
Cumulative Timesteps: 985,133,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 985133062...
Checkpoint 985133062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.18795
Policy Entropy: 3.73271
Value Function Loss: 0.02171

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.47635

Collected Steps per Second: 21,631.62891
Overall Steps per Second: 10,712.51798

Timestep Collection Time: 2.31291
Timestep Consumption Time: 2.35751
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67042

Cumulative Model Updates: 118,142
Cumulative Timesteps: 985,183,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.18795
Policy Entropy: 3.72319
Value Function Loss: 0.01817

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.47651

Collected Steps per Second: 22,003.20033
Overall Steps per Second: 10,651.80532

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.69442

Cumulative Model Updates: 118,148
Cumulative Timesteps: 985,233,098

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 985233098...
Checkpoint 985233098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.18795
Policy Entropy: 3.68625
Value Function Loss: 0.02139

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.18078
Policy Update Magnitude: 0.47181
Value Function Update Magnitude: 0.50478

Collected Steps per Second: 22,140.74856
Overall Steps per Second: 10,833.15676

Timestep Collection Time: 2.25954
Timestep Consumption Time: 2.35850
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61804

Cumulative Model Updates: 118,154
Cumulative Timesteps: 985,283,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,571.47027
Policy Entropy: 3.72218
Value Function Loss: 0.02236

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.51368
Value Function Update Magnitude: 0.46964

Collected Steps per Second: 21,959.61162
Overall Steps per Second: 10,519.54032

Timestep Collection Time: 2.27691
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.75306

Cumulative Model Updates: 118,160
Cumulative Timesteps: 985,333,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985333126...
Checkpoint 985333126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,603.75748
Policy Entropy: 3.72379
Value Function Loss: 0.02391

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.42332

Collected Steps per Second: 22,447.36000
Overall Steps per Second: 10,649.17335

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.69708

Cumulative Model Updates: 118,166
Cumulative Timesteps: 985,383,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,603.75748
Policy Entropy: 3.73159
Value Function Loss: 0.02061

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15678
Policy Update Magnitude: 0.54254
Value Function Update Magnitude: 0.40035

Collected Steps per Second: 22,624.08227
Overall Steps per Second: 10,822.72749

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.62046

Cumulative Model Updates: 118,172
Cumulative Timesteps: 985,433,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 985433152...
Checkpoint 985433152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,603.75748
Policy Entropy: 3.72304
Value Function Loss: 0.02152

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.48492
Value Function Update Magnitude: 0.41974

Collected Steps per Second: 22,494.17301
Overall Steps per Second: 10,747.84694

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.65247

Cumulative Model Updates: 118,178
Cumulative Timesteps: 985,483,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,186.38343
Policy Entropy: 3.72402
Value Function Loss: 0.02265

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15506
Policy Update Magnitude: 0.48393
Value Function Update Magnitude: 0.49071

Collected Steps per Second: 22,859.49678
Overall Steps per Second: 10,815.20780

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.62404

Cumulative Model Updates: 118,184
Cumulative Timesteps: 985,533,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 985533166...
Checkpoint 985533166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,028.12943
Policy Entropy: 3.72979
Value Function Loss: 0.02462

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.50935
Value Function Update Magnitude: 0.57218

Collected Steps per Second: 22,342.71217
Overall Steps per Second: 10,669.88675

Timestep Collection Time: 2.23858
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.68758

Cumulative Model Updates: 118,190
Cumulative Timesteps: 985,583,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,956.18427
Policy Entropy: 3.74493
Value Function Loss: 0.02501

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.68912

Collected Steps per Second: 22,648.99685
Overall Steps per Second: 10,600.74896

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.50925
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.71703

Cumulative Model Updates: 118,196
Cumulative Timesteps: 985,633,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 985633186...
Checkpoint 985633186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,956.18427
Policy Entropy: 3.73041
Value Function Loss: 0.02558

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.59722
Value Function Update Magnitude: 0.61522

Collected Steps per Second: 22,583.35954
Overall Steps per Second: 10,555.41410

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.73918

Cumulative Model Updates: 118,202
Cumulative Timesteps: 985,683,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,932.93385
Policy Entropy: 3.73060
Value Function Loss: 0.02439

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.54560
Value Function Update Magnitude: 0.56639

Collected Steps per Second: 22,756.17904
Overall Steps per Second: 10,678.81232

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.68254

Cumulative Model Updates: 118,208
Cumulative Timesteps: 985,733,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 985733214...
Checkpoint 985733214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,108.00974
Policy Entropy: 3.73226
Value Function Loss: 0.02470

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15028
Policy Update Magnitude: 0.53414
Value Function Update Magnitude: 0.67054

Collected Steps per Second: 22,312.30058
Overall Steps per Second: 10,599.51993

Timestep Collection Time: 2.24217
Timestep Consumption Time: 2.47767
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.71984

Cumulative Model Updates: 118,214
Cumulative Timesteps: 985,783,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,695.98232
Policy Entropy: 3.74615
Value Function Loss: 0.02315

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.17084
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.64843

Collected Steps per Second: 21,954.13876
Overall Steps per Second: 10,579.24509

Timestep Collection Time: 2.27757
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.72642

Cumulative Model Updates: 118,220
Cumulative Timesteps: 985,833,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 985833244...
Checkpoint 985833244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,227.47150
Policy Entropy: 3.69981
Value Function Loss: 0.02894

Mean KL Divergence: 0.03215
SB3 Clip Fraction: 0.29755
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.54827

Collected Steps per Second: 22,275.41830
Overall Steps per Second: 10,678.27548

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.68315

Cumulative Model Updates: 118,226
Cumulative Timesteps: 985,883,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,053.18460
Policy Entropy: 3.76692
Value Function Loss: 0.04178

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.22343
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.45417

Collected Steps per Second: 22,035.94646
Overall Steps per Second: 10,534.36758

Timestep Collection Time: 2.26984
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.74808

Cumulative Model Updates: 118,232
Cumulative Timesteps: 985,933,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 985933270...
Checkpoint 985933270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,930.62269
Policy Entropy: 3.76924
Value Function Loss: 0.03928

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.17330
Policy Update Magnitude: 0.65279
Value Function Update Magnitude: 0.46468

Collected Steps per Second: 21,916.87712
Overall Steps per Second: 10,616.54833

Timestep Collection Time: 2.28217
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71132

Cumulative Model Updates: 118,238
Cumulative Timesteps: 985,983,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,042.39666
Policy Entropy: 3.77177
Value Function Loss: 0.03878

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.18821
Policy Update Magnitude: 0.70707
Value Function Update Magnitude: 0.40858

Collected Steps per Second: 21,963.87242
Overall Steps per Second: 10,444.35356

Timestep Collection Time: 2.27647
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.78728

Cumulative Model Updates: 118,244
Cumulative Timesteps: 986,033,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 986033288...
Checkpoint 986033288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,073.16163
Policy Entropy: 3.76830
Value Function Loss: 0.03252

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.71875
Value Function Update Magnitude: 0.60040

Collected Steps per Second: 22,340.78727
Overall Steps per Second: 10,689.82680

Timestep Collection Time: 2.23886
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.67903

Cumulative Model Updates: 118,250
Cumulative Timesteps: 986,083,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,788.93070
Policy Entropy: 3.74438
Value Function Loss: 0.03523

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.74222
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 22,594.27192
Overall Steps per Second: 10,641.42643

Timestep Collection Time: 2.21313
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69899

Cumulative Model Updates: 118,256
Cumulative Timesteps: 986,133,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 986133310...
Checkpoint 986133310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,788.93070
Policy Entropy: 3.72942
Value Function Loss: 0.02831

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16857
Policy Update Magnitude: 0.71433
Value Function Update Magnitude: 0.47942

Collected Steps per Second: 22,628.24747
Overall Steps per Second: 10,786.16308

Timestep Collection Time: 2.21078
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.63798

Cumulative Model Updates: 118,262
Cumulative Timesteps: 986,183,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,339.68372
Policy Entropy: 3.70959
Value Function Loss: 0.02961

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16159
Policy Update Magnitude: 0.65109
Value Function Update Magnitude: 0.50500

Collected Steps per Second: 22,655.35409
Overall Steps per Second: 10,545.80353

Timestep Collection Time: 2.20751
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.74236

Cumulative Model Updates: 118,268
Cumulative Timesteps: 986,233,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 986233348...
Checkpoint 986233348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,689.17363
Policy Entropy: 3.71937
Value Function Loss: 0.02644

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08352
Policy Update Magnitude: 0.73775
Value Function Update Magnitude: 0.52100

Collected Steps per Second: 22,421.57392
Overall Steps per Second: 10,622.20454

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.70844

Cumulative Model Updates: 118,274
Cumulative Timesteps: 986,283,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290,802.23283
Policy Entropy: 3.73970
Value Function Loss: 0.02600

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.78282
Value Function Update Magnitude: 0.50919

Collected Steps per Second: 22,509.50203
Overall Steps per Second: 10,581.42705

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.50428
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72583

Cumulative Model Updates: 118,280
Cumulative Timesteps: 986,333,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 986333368...
Checkpoint 986333368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.75327
Value Function Loss: 0.02257

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.70747
Value Function Update Magnitude: 0.47667

Collected Steps per Second: 22,661.79427
Overall Steps per Second: 10,623.35358

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.70755

Cumulative Model Updates: 118,286
Cumulative Timesteps: 986,383,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.76453
Value Function Loss: 0.01829

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.60429
Value Function Update Magnitude: 0.42836

Collected Steps per Second: 23,108.17203
Overall Steps per Second: 10,782.18040

Timestep Collection Time: 2.16443
Timestep Consumption Time: 2.47434
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.63876

Cumulative Model Updates: 118,292
Cumulative Timesteps: 986,433,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 986433394...
Checkpoint 986433394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.75092
Value Function Loss: 0.01511

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06353
Policy Update Magnitude: 0.53352
Value Function Update Magnitude: 0.42594

Collected Steps per Second: 22,514.40342
Overall Steps per Second: 10,632.46294

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.70333

Cumulative Model Updates: 118,298
Cumulative Timesteps: 986,483,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.76147
Value Function Loss: 0.01388

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05103
Policy Update Magnitude: 0.51135
Value Function Update Magnitude: 0.45088

Collected Steps per Second: 22,613.32315
Overall Steps per Second: 10,624.04854

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.49751
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.71063

Cumulative Model Updates: 118,304
Cumulative Timesteps: 986,533,448

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 986533448...
Checkpoint 986533448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.77282
Value Function Loss: 0.01323

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05048
Policy Update Magnitude: 0.49208
Value Function Update Magnitude: 0.39264

Collected Steps per Second: 22,924.00354
Overall Steps per Second: 10,855.07162

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.42570
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.60743

Cumulative Model Updates: 118,310
Cumulative Timesteps: 986,583,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,546.14118
Policy Entropy: 3.77731
Value Function Loss: 0.01221

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06062
Policy Update Magnitude: 0.46185
Value Function Update Magnitude: 0.36056

Collected Steps per Second: 22,581.46269
Overall Steps per Second: 10,568.25688

Timestep Collection Time: 2.21518
Timestep Consumption Time: 2.51805
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.73323

Cumulative Model Updates: 118,316
Cumulative Timesteps: 986,633,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986633484...
Checkpoint 986633484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78003
Value Function Loss: 0.01173

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.05091
Policy Update Magnitude: 0.42983
Value Function Update Magnitude: 0.31918

Collected Steps per Second: 22,507.35194
Overall Steps per Second: 10,591.83885

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.72269

Cumulative Model Updates: 118,322
Cumulative Timesteps: 986,683,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78567
Value Function Loss: 0.01137

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04902
Policy Update Magnitude: 0.42531
Value Function Update Magnitude: 0.30989

Collected Steps per Second: 22,727.30474
Overall Steps per Second: 10,643.74979

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.69872

Cumulative Model Updates: 118,328
Cumulative Timesteps: 986,733,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 986733518...
Checkpoint 986733518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78771
Value Function Loss: 0.01068

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05049
Policy Update Magnitude: 0.39807
Value Function Update Magnitude: 0.30159

Collected Steps per Second: 22,925.54593
Overall Steps per Second: 10,831.54457

Timestep Collection Time: 2.18132
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.61689

Cumulative Model Updates: 118,334
Cumulative Timesteps: 986,783,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.77886
Value Function Loss: 0.00965

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04802
Policy Update Magnitude: 0.40038
Value Function Update Magnitude: 0.33443

Collected Steps per Second: 22,933.79095
Overall Steps per Second: 10,715.49360

Timestep Collection Time: 2.18071
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.66726

Cumulative Model Updates: 118,340
Cumulative Timesteps: 986,833,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 986833538...
Checkpoint 986833538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.77430
Value Function Loss: 0.00904

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.04372
Policy Update Magnitude: 0.38017
Value Function Update Magnitude: 0.30332

Collected Steps per Second: 21,951.64704
Overall Steps per Second: 10,798.64389

Timestep Collection Time: 2.27855
Timestep Consumption Time: 2.35332
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.63188

Cumulative Model Updates: 118,346
Cumulative Timesteps: 986,883,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78140
Value Function Loss: 0.00932

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.39156
Value Function Update Magnitude: 0.32018

Collected Steps per Second: 22,141.55100
Overall Steps per Second: 10,716.31955

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.40855
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66765

Cumulative Model Updates: 118,352
Cumulative Timesteps: 986,933,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 986933576...
Checkpoint 986933576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78256
Value Function Loss: 0.01003

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06989
Policy Update Magnitude: 0.43172
Value Function Update Magnitude: 0.44747

Collected Steps per Second: 21,563.18524
Overall Steps per Second: 10,497.95581

Timestep Collection Time: 2.32007
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.76550

Cumulative Model Updates: 118,358
Cumulative Timesteps: 986,983,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,099.36310
Policy Entropy: 3.78836
Value Function Loss: 0.00984

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06739
Policy Update Magnitude: 0.46561
Value Function Update Magnitude: 0.49984

Collected Steps per Second: 23,032.73920
Overall Steps per Second: 10,872.84385

Timestep Collection Time: 2.17082
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.59861

Cumulative Model Updates: 118,364
Cumulative Timesteps: 987,033,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 987033604...
Checkpoint 987033604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,790.34430
Policy Entropy: 3.76389
Value Function Loss: 0.01269

Mean KL Divergence: 0.02175
SB3 Clip Fraction: 0.25375
Policy Update Magnitude: 0.41419
Value Function Update Magnitude: 0.50594

Collected Steps per Second: 22,202.50895
Overall Steps per Second: 10,726.62253

Timestep Collection Time: 2.25308
Timestep Consumption Time: 2.41046
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.66354

Cumulative Model Updates: 118,370
Cumulative Timesteps: 987,083,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 582,081.25324
Policy Entropy: 3.72056
Value Function Loss: 0.03929

Mean KL Divergence: 0.02921
SB3 Clip Fraction: 0.27797
Policy Update Magnitude: 0.43229
Value Function Update Magnitude: 0.70336

Collected Steps per Second: 22,541.17001
Overall Steps per Second: 10,805.59662

Timestep Collection Time: 2.21958
Timestep Consumption Time: 2.41061
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.63019

Cumulative Model Updates: 118,376
Cumulative Timesteps: 987,133,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 987133660...
Checkpoint 987133660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,974.45675
Policy Entropy: 3.79158
Value Function Loss: 0.05707

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.20467
Policy Update Magnitude: 0.71887
Value Function Update Magnitude: 0.74057

Collected Steps per Second: 22,438.31482
Overall Steps per Second: 10,708.27394

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.44232
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.67190

Cumulative Model Updates: 118,382
Cumulative Timesteps: 987,183,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,639.90515
Policy Entropy: 3.88734
Value Function Loss: 0.05768

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.16881
Policy Update Magnitude: 0.95733
Value Function Update Magnitude: 0.81656

Collected Steps per Second: 22,795.96098
Overall Steps per Second: 10,839.27510

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.61544

Cumulative Model Updates: 118,388
Cumulative Timesteps: 987,233,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 987233716...
Checkpoint 987233716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,647.83945
Policy Entropy: 3.96104
Value Function Loss: 0.05037

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 1.28307
Value Function Update Magnitude: 0.96528

Collected Steps per Second: 22,301.09139
Overall Steps per Second: 10,663.75604

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69122

Cumulative Model Updates: 118,394
Cumulative Timesteps: 987,283,742

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,798.35677
Policy Entropy: 3.91650
Value Function Loss: 0.04715

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 1.35627
Value Function Update Magnitude: 0.91990

Collected Steps per Second: 22,263.08740
Overall Steps per Second: 10,842.80297

Timestep Collection Time: 2.24614
Timestep Consumption Time: 2.36577
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61191

Cumulative Model Updates: 118,400
Cumulative Timesteps: 987,333,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 987333748...
Checkpoint 987333748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,500.77446
Policy Entropy: 3.87253
Value Function Loss: 0.04897

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 1.21431
Value Function Update Magnitude: 0.76890

Collected Steps per Second: 21,627.26482
Overall Steps per Second: 10,694.09397

Timestep Collection Time: 2.31190
Timestep Consumption Time: 2.36358
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67548

Cumulative Model Updates: 118,406
Cumulative Timesteps: 987,383,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.93150
Policy Entropy: 3.84022
Value Function Loss: 0.04218

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 1.10492
Value Function Update Magnitude: 0.86021

Collected Steps per Second: 22,260.42463
Overall Steps per Second: 10,840.07716

Timestep Collection Time: 2.24704
Timestep Consumption Time: 2.36732
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.61436

Cumulative Model Updates: 118,412
Cumulative Timesteps: 987,433,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 987433768...
Checkpoint 987433768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.59541
Policy Entropy: 3.83905
Value Function Loss: 0.04007

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09931
Policy Update Magnitude: 1.01186
Value Function Update Magnitude: 0.88124

Collected Steps per Second: 21,581.34834
Overall Steps per Second: 10,678.83337

Timestep Collection Time: 2.31746
Timestep Consumption Time: 2.36601
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.68347

Cumulative Model Updates: 118,418
Cumulative Timesteps: 987,483,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,633.08990
Policy Entropy: 3.81996
Value Function Loss: 0.03841

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07868
Policy Update Magnitude: 0.95054
Value Function Update Magnitude: 0.69678

Collected Steps per Second: 22,241.24308
Overall Steps per Second: 10,730.96220

Timestep Collection Time: 2.24853
Timestep Consumption Time: 2.41182
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.66035

Cumulative Model Updates: 118,424
Cumulative Timesteps: 987,533,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 987533792...
Checkpoint 987533792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367.13832
Policy Entropy: 3.80965
Value Function Loss: 0.03072

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.81608
Value Function Update Magnitude: 0.56198

Collected Steps per Second: 22,074.50585
Overall Steps per Second: 10,806.05293

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.36340
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62981

Cumulative Model Updates: 118,430
Cumulative Timesteps: 987,583,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.79929
Value Function Loss: 0.02436

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07302
Policy Update Magnitude: 0.69503
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 22,040.71809
Overall Steps per Second: 10,535.33345

Timestep Collection Time: 2.26935
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.74764

Cumulative Model Updates: 118,436
Cumulative Timesteps: 987,633,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 987633840...
Checkpoint 987633840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.79628
Value Function Loss: 0.01759

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05869
Policy Update Magnitude: 0.62143
Value Function Update Magnitude: 0.49294

Collected Steps per Second: 22,409.29187
Overall Steps per Second: 10,647.83701

Timestep Collection Time: 2.23211
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.69767

Cumulative Model Updates: 118,442
Cumulative Timesteps: 987,683,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.77541
Value Function Loss: 0.01416

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.53868
Value Function Update Magnitude: 0.42048

Collected Steps per Second: 22,989.06145
Overall Steps per Second: 10,804.11874

Timestep Collection Time: 2.17599
Timestep Consumption Time: 2.45409
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.63009

Cumulative Model Updates: 118,448
Cumulative Timesteps: 987,733,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 987733884...
Checkpoint 987733884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.73032
Value Function Loss: 0.01606

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.42968
Value Function Update Magnitude: 0.41312

Collected Steps per Second: 22,620.51654
Overall Steps per Second: 10,786.66414

Timestep Collection Time: 2.21056
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.63572

Cumulative Model Updates: 118,454
Cumulative Timesteps: 987,783,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.73507
Value Function Loss: 0.01614

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.47265
Value Function Update Magnitude: 0.47467

Collected Steps per Second: 23,050.72575
Overall Steps per Second: 10,874.99633

Timestep Collection Time: 2.16913
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59770

Cumulative Model Updates: 118,460
Cumulative Timesteps: 987,833,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 987833888...
Checkpoint 987833888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.19454
Policy Entropy: 3.75543
Value Function Loss: 0.01599

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.18171
Policy Update Magnitude: 0.48854
Value Function Update Magnitude: 0.48514

Collected Steps per Second: 22,384.75537
Overall Steps per Second: 10,604.02187

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.48173
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.71557

Cumulative Model Updates: 118,466
Cumulative Timesteps: 987,883,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,252.20155
Policy Entropy: 3.78903
Value Function Loss: 0.01406

Mean KL Divergence: 0.01684
SB3 Clip Fraction: 0.20361
Policy Update Magnitude: 0.38670
Value Function Update Magnitude: 0.46605

Collected Steps per Second: 22,585.43640
Overall Steps per Second: 10,579.73034

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.51301
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72753

Cumulative Model Updates: 118,472
Cumulative Timesteps: 987,933,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 987933908...
Checkpoint 987933908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,126.00475
Policy Entropy: 3.74317
Value Function Loss: 0.01489

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.19289
Policy Update Magnitude: 0.35439
Value Function Update Magnitude: 0.50038

Collected Steps per Second: 22,791.29780
Overall Steps per Second: 10,687.75781

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.67937

Cumulative Model Updates: 118,478
Cumulative Timesteps: 987,983,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,126.00475
Policy Entropy: 3.73234
Value Function Loss: 0.01584

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08735
Policy Update Magnitude: 0.45221
Value Function Update Magnitude: 0.56472

Collected Steps per Second: 22,087.41671
Overall Steps per Second: 10,793.57498

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.37026
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.63554

Cumulative Model Updates: 118,484
Cumulative Timesteps: 988,033,954

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 988033954...
Checkpoint 988033954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,126.00475
Policy Entropy: 3.71054
Value Function Loss: 0.01676

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16773
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.58419

Collected Steps per Second: 21,499.58995
Overall Steps per Second: 10,596.77894

Timestep Collection Time: 2.32656
Timestep Consumption Time: 2.39375
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.72030

Cumulative Model Updates: 118,490
Cumulative Timesteps: 988,083,974

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,825.05591
Policy Entropy: 3.68715
Value Function Loss: 0.02111

Mean KL Divergence: 0.04298
SB3 Clip Fraction: 0.36219
Policy Update Magnitude: 0.48705
Value Function Update Magnitude: 0.52654

Collected Steps per Second: 21,622.78855
Overall Steps per Second: 10,469.55581

Timestep Collection Time: 2.31238
Timestep Consumption Time: 2.46338
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.77575

Cumulative Model Updates: 118,496
Cumulative Timesteps: 988,133,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988133974...
Checkpoint 988133974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,520.34812
Policy Entropy: 3.76450
Value Function Loss: 0.03962

Mean KL Divergence: 0.05081
SB3 Clip Fraction: 0.31633
Policy Update Magnitude: 0.51321
Value Function Update Magnitude: 0.56838

Collected Steps per Second: 21,551.47436
Overall Steps per Second: 10,585.32922

Timestep Collection Time: 2.32105
Timestep Consumption Time: 2.40455
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.72560

Cumulative Model Updates: 118,502
Cumulative Timesteps: 988,183,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,306.41908
Policy Entropy: 3.79609
Value Function Loss: 0.04532

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.21853
Policy Update Magnitude: 0.88812
Value Function Update Magnitude: 0.54296

Collected Steps per Second: 22,619.56000
Overall Steps per Second: 10,699.68049

Timestep Collection Time: 2.21074
Timestep Consumption Time: 2.46286
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.67360

Cumulative Model Updates: 118,508
Cumulative Timesteps: 988,234,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 988234002...
Checkpoint 988234002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,508.95539
Policy Entropy: 3.80695
Value Function Loss: 0.04051

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 1.08025
Value Function Update Magnitude: 0.69192

Collected Steps per Second: 22,644.42636
Overall Steps per Second: 10,833.63092

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.40779
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.61637

Cumulative Model Updates: 118,514
Cumulative Timesteps: 988,284,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,748.04719
Policy Entropy: 3.81016
Value Function Loss: 0.03752

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 1.06152
Value Function Update Magnitude: 0.71543

Collected Steps per Second: 22,649.78267
Overall Steps per Second: 10,715.73984

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.45851
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.66603

Cumulative Model Updates: 118,520
Cumulative Timesteps: 988,334,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988334014...
Checkpoint 988334014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,679.36010
Policy Entropy: 3.80338
Value Function Loss: 0.03020

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09436
Policy Update Magnitude: 0.94607
Value Function Update Magnitude: 0.83641

Collected Steps per Second: 22,660.79487
Overall Steps per Second: 10,781.38135

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.63911

Cumulative Model Updates: 118,526
Cumulative Timesteps: 988,384,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,280.30041
Policy Entropy: 3.77363
Value Function Loss: 0.02736

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11089
Policy Update Magnitude: 0.86226
Value Function Update Magnitude: 0.87475

Collected Steps per Second: 22,861.50909
Overall Steps per Second: 10,619.76337

Timestep Collection Time: 2.18822
Timestep Consumption Time: 2.52243
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.71065

Cumulative Model Updates: 118,532
Cumulative Timesteps: 988,434,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 988434056...
Checkpoint 988434056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,041.05812
Policy Entropy: 3.76844
Value Function Loss: 0.02492

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.21692
Policy Update Magnitude: 0.69680
Value Function Update Magnitude: 0.81284

Collected Steps per Second: 22,480.31894
Overall Steps per Second: 10,556.29229

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.73897

Cumulative Model Updates: 118,538
Cumulative Timesteps: 988,484,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,617.63095
Policy Entropy: 3.73560
Value Function Loss: 0.02167

Mean KL Divergence: 0.02501
SB3 Clip Fraction: 0.29496
Policy Update Magnitude: 0.52265
Value Function Update Magnitude: 0.79187

Collected Steps per Second: 22,774.64054
Overall Steps per Second: 10,688.26365

Timestep Collection Time: 2.19578
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.67878

Cumulative Model Updates: 118,544
Cumulative Timesteps: 988,534,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 988534090...
Checkpoint 988534090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,716.74927
Policy Entropy: 3.73569
Value Function Loss: 0.02895

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.25668
Policy Update Magnitude: 0.44371
Value Function Update Magnitude: 0.76049

Collected Steps per Second: 22,266.05383
Overall Steps per Second: 10,538.43612

Timestep Collection Time: 2.24602
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74549

Cumulative Model Updates: 118,550
Cumulative Timesteps: 988,584,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,211.64617
Policy Entropy: 3.77261
Value Function Loss: 0.04377

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.19002
Policy Update Magnitude: 0.54394
Value Function Update Magnitude: 0.73276

Collected Steps per Second: 21,930.16779
Overall Steps per Second: 10,464.78175

Timestep Collection Time: 2.28097
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.78003

Cumulative Model Updates: 118,556
Cumulative Timesteps: 988,634,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 988634122...
Checkpoint 988634122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,353.35954
Policy Entropy: 3.85864
Value Function Loss: 0.05282

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.21918
Policy Update Magnitude: 0.69510
Value Function Update Magnitude: 0.65162

Collected Steps per Second: 22,456.14338
Overall Steps per Second: 10,650.93986

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.69442

Cumulative Model Updates: 118,562
Cumulative Timesteps: 988,684,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,722.46984
Policy Entropy: 3.99734
Value Function Loss: 0.06311

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.79361
Value Function Update Magnitude: 0.67312

Collected Steps per Second: 22,939.62407
Overall Steps per Second: 10,772.20234

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.46243
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.64250

Cumulative Model Updates: 118,568
Cumulative Timesteps: 988,734,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 988734132...
Checkpoint 988734132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.14310
Policy Entropy: 4.05656
Value Function Loss: 0.04479

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 1.03697
Value Function Update Magnitude: 0.70310

Collected Steps per Second: 22,566.95656
Overall Steps per Second: 10,836.91103

Timestep Collection Time: 2.21581
Timestep Consumption Time: 2.39842
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.61423

Cumulative Model Updates: 118,574
Cumulative Timesteps: 988,784,136

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,430.02087
Policy Entropy: 4.05862
Value Function Loss: 0.03864

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08828
Policy Update Magnitude: 1.15716
Value Function Update Magnitude: 0.85868

Collected Steps per Second: 23,010.80938
Overall Steps per Second: 10,677.26133

Timestep Collection Time: 2.17376
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68472

Cumulative Model Updates: 118,580
Cumulative Timesteps: 988,834,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 988834156...
Checkpoint 988834156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,904.97285
Policy Entropy: 4.04765
Value Function Loss: 0.03581

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07574
Policy Update Magnitude: 1.13880
Value Function Update Magnitude: 1.11605

Collected Steps per Second: 22,293.95968
Overall Steps per Second: 10,634.41803

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.70435

Cumulative Model Updates: 118,586
Cumulative Timesteps: 988,884,184

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.98361
Policy Entropy: 4.03652
Value Function Loss: 0.03433

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 1.05403
Value Function Update Magnitude: 1.18725

Collected Steps per Second: 23,017.49135
Overall Steps per Second: 10,825.33743

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.62175

Cumulative Model Updates: 118,592
Cumulative Timesteps: 988,934,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 988934216...
Checkpoint 988934216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,260.87496
Policy Entropy: 4.00672
Value Function Loss: 0.03195

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05870
Policy Update Magnitude: 0.92777
Value Function Update Magnitude: 0.97048

Collected Steps per Second: 22,369.82353
Overall Steps per Second: 10,721.14584

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.42892
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.66443

Cumulative Model Updates: 118,598
Cumulative Timesteps: 988,984,224

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,200.16544
Policy Entropy: 3.94115
Value Function Loss: 0.03382

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10920
Policy Update Magnitude: 0.77725
Value Function Update Magnitude: 0.90664

Collected Steps per Second: 23,057.44441
Overall Steps per Second: 10,786.22150

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.46843
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.63814

Cumulative Model Updates: 118,604
Cumulative Timesteps: 989,034,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 989034252...
Checkpoint 989034252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.93913
Policy Entropy: 3.88644
Value Function Loss: 0.03323

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.69082
Value Function Update Magnitude: 0.84543

Collected Steps per Second: 21,990.05661
Overall Steps per Second: 10,477.00642

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.49990
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.77484

Cumulative Model Updates: 118,610
Cumulative Timesteps: 989,084,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,149.65080
Policy Entropy: 3.83419
Value Function Loss: 0.04010

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.60923
Value Function Update Magnitude: 0.71451

Collected Steps per Second: 22,874.58540
Overall Steps per Second: 10,817.82876

Timestep Collection Time: 2.18618
Timestep Consumption Time: 2.43656
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.62274

Cumulative Model Updates: 118,616
Cumulative Timesteps: 989,134,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 989134286...
Checkpoint 989134286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218.13204
Policy Entropy: 3.84543
Value Function Loss: 0.03764

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14253
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.74724

Collected Steps per Second: 22,511.04906
Overall Steps per Second: 10,595.94871

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.72048

Cumulative Model Updates: 118,622
Cumulative Timesteps: 989,184,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,680.44406
Policy Entropy: 3.81768
Value Function Loss: 0.03986

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.58972
Value Function Update Magnitude: 0.72669

Collected Steps per Second: 22,977.44665
Overall Steps per Second: 10,698.97663

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.67409

Cumulative Model Updates: 118,628
Cumulative Timesteps: 989,234,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 989234312...
Checkpoint 989234312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,537.92010
Policy Entropy: 3.82090
Value Function Loss: 0.03532

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.20223
Policy Update Magnitude: 0.53284
Value Function Update Magnitude: 0.71970

Collected Steps per Second: 22,048.06050
Overall Steps per Second: 10,455.53415

Timestep Collection Time: 2.26805
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.78273

Cumulative Model Updates: 118,634
Cumulative Timesteps: 989,284,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,003.57653
Policy Entropy: 3.78652
Value Function Loss: 0.03347

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.50864
Value Function Update Magnitude: 0.75262

Collected Steps per Second: 22,777.76020
Overall Steps per Second: 10,782.83880

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.63904

Cumulative Model Updates: 118,640
Cumulative Timesteps: 989,334,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 989334340...
Checkpoint 989334340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,841.11907
Policy Entropy: 3.80881
Value Function Loss: 0.03231

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07089
Policy Update Magnitude: 0.64830
Value Function Update Magnitude: 0.63891

Collected Steps per Second: 22,520.77896
Overall Steps per Second: 10,757.12426

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.64883

Cumulative Model Updates: 118,646
Cumulative Timesteps: 989,384,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.42834
Policy Entropy: 3.79873
Value Function Loss: 0.02661

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07113
Policy Update Magnitude: 0.73546
Value Function Update Magnitude: 0.68086

Collected Steps per Second: 22,897.53721
Overall Steps per Second: 10,783.02064

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.63711

Cumulative Model Updates: 118,652
Cumulative Timesteps: 989,434,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 989434350...
Checkpoint 989434350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,104.84616
Policy Entropy: 3.80506
Value Function Loss: 0.02675

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07185
Policy Update Magnitude: 0.69863
Value Function Update Magnitude: 0.75944

Collected Steps per Second: 22,372.68684
Overall Steps per Second: 10,720.03540

Timestep Collection Time: 2.23514
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.66472

Cumulative Model Updates: 118,658
Cumulative Timesteps: 989,484,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,841.20161
Policy Entropy: 3.81487
Value Function Loss: 0.02640

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.70773
Value Function Update Magnitude: 0.78714

Collected Steps per Second: 22,734.90259
Overall Steps per Second: 10,794.93987

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.63291

Cumulative Model Updates: 118,664
Cumulative Timesteps: 989,534,368

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 989534368...
Checkpoint 989534368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.71137
Policy Entropy: 3.83565
Value Function Loss: 0.02756

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.72247
Value Function Update Magnitude: 0.73168

Collected Steps per Second: 22,838.34824
Overall Steps per Second: 10,760.59476

Timestep Collection Time: 2.18956
Timestep Consumption Time: 2.45758
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.64714

Cumulative Model Updates: 118,670
Cumulative Timesteps: 989,584,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,418.04366
Policy Entropy: 3.83390
Value Function Loss: 0.02748

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.21918
Policy Update Magnitude: 0.62325
Value Function Update Magnitude: 0.74978

Collected Steps per Second: 22,943.22167
Overall Steps per Second: 10,792.10882

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.63561

Cumulative Model Updates: 118,676
Cumulative Timesteps: 989,634,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 989634402...
Checkpoint 989634402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,049.40837
Policy Entropy: 3.82625
Value Function Loss: 0.04144

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.22088
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.70568

Collected Steps per Second: 22,154.74547
Overall Steps per Second: 10,631.82710

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.70380

Cumulative Model Updates: 118,682
Cumulative Timesteps: 989,684,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.27052
Policy Entropy: 3.83723
Value Function Loss: 0.05283

Mean KL Divergence: 0.02030
SB3 Clip Fraction: 0.19429
Policy Update Magnitude: 0.54595
Value Function Update Magnitude: 0.66660

Collected Steps per Second: 22,480.65328
Overall Steps per Second: 10,627.31603

Timestep Collection Time: 2.22556
Timestep Consumption Time: 2.48231
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70787

Cumulative Model Updates: 118,688
Cumulative Timesteps: 989,734,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 989734444...
Checkpoint 989734444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,922.30212
Policy Entropy: 3.88709
Value Function Loss: 0.05328

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.70815
Value Function Update Magnitude: 0.90992

Collected Steps per Second: 22,677.37656
Overall Steps per Second: 10,590.63226

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.51752
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.72342

Cumulative Model Updates: 118,694
Cumulative Timesteps: 989,784,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.44449
Policy Entropy: 3.92469
Value Function Loss: 0.04994

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.85820
Value Function Update Magnitude: 0.97431

Collected Steps per Second: 22,785.48810
Overall Steps per Second: 10,874.02274

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.40393
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.59848

Cumulative Model Updates: 118,700
Cumulative Timesteps: 989,834,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 989834472...
Checkpoint 989834472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,670.46186
Policy Entropy: 3.92735
Value Function Loss: 0.04219

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.80863
Value Function Update Magnitude: 0.75606

Collected Steps per Second: 21,561.06788
Overall Steps per Second: 10,567.58430

Timestep Collection Time: 2.31946
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.73240

Cumulative Model Updates: 118,706
Cumulative Timesteps: 989,884,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,563.31060
Policy Entropy: 3.87290
Value Function Loss: 0.04016

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.70531
Value Function Update Magnitude: 0.75210

Collected Steps per Second: 21,759.11129
Overall Steps per Second: 10,416.63565

Timestep Collection Time: 2.29927
Timestep Consumption Time: 2.50363
PPO Batch Consumption Time: 0.30294
Total Iteration Time: 4.80289

Cumulative Model Updates: 118,712
Cumulative Timesteps: 989,934,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 989934512...
Checkpoint 989934512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.80198
Policy Entropy: 3.83164
Value Function Loss: 0.03361

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.59912
Value Function Update Magnitude: 0.77217

Collected Steps per Second: 21,858.17097
Overall Steps per Second: 10,506.25937

Timestep Collection Time: 2.28757
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.75926

Cumulative Model Updates: 118,718
Cumulative Timesteps: 989,984,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,185.55090
Policy Entropy: 3.79024
Value Function Loss: 0.02899

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.56474
Value Function Update Magnitude: 0.75901

Collected Steps per Second: 22,901.81406
Overall Steps per Second: 10,717.96042

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.66656

Cumulative Model Updates: 118,724
Cumulative Timesteps: 990,034,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 990034530...
Checkpoint 990034530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,116.46100
Policy Entropy: 3.73593
Value Function Loss: 0.02691

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.43847
Value Function Update Magnitude: 0.66506

Collected Steps per Second: 22,194.06043
Overall Steps per Second: 10,614.65339

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.45761
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.71047

Cumulative Model Updates: 118,730
Cumulative Timesteps: 990,084,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,291.01485
Policy Entropy: 3.72295
Value Function Loss: 0.02294

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.18858
Policy Update Magnitude: 0.42736
Value Function Update Magnitude: 0.61661

Collected Steps per Second: 22,539.76659
Overall Steps per Second: 10,552.59426

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.74120

Cumulative Model Updates: 118,736
Cumulative Timesteps: 990,134,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 990134562...
Checkpoint 990134562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,562.73668
Policy Entropy: 3.74722
Value Function Loss: 0.03998

Mean KL Divergence: 0.02326
SB3 Clip Fraction: 0.26042
Policy Update Magnitude: 0.36579
Value Function Update Magnitude: 0.54980

Collected Steps per Second: 22,193.90244
Overall Steps per Second: 10,593.08843

Timestep Collection Time: 2.25386
Timestep Consumption Time: 2.46827
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.72214

Cumulative Model Updates: 118,742
Cumulative Timesteps: 990,184,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,072.62988
Policy Entropy: 3.76381
Value Function Loss: 0.05269

Mean KL Divergence: 0.02625
SB3 Clip Fraction: 0.24414
Policy Update Magnitude: 0.39448
Value Function Update Magnitude: 0.46580

Collected Steps per Second: 23,082.90614
Overall Steps per Second: 10,889.86175

Timestep Collection Time: 2.16714
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59363

Cumulative Model Updates: 118,748
Cumulative Timesteps: 990,234,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 990234608...
Checkpoint 990234608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,808.61464
Policy Entropy: 3.78027
Value Function Loss: 0.05947

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.20895
Policy Update Magnitude: 0.50848
Value Function Update Magnitude: 0.55453

Collected Steps per Second: 22,433.39008
Overall Steps per Second: 10,622.64778

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.47939
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.70937

Cumulative Model Updates: 118,754
Cumulative Timesteps: 990,284,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,430.74005
Policy Entropy: 3.81850
Value Function Loss: 0.05565

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.18777
Policy Update Magnitude: 0.50419
Value Function Update Magnitude: 0.77601

Collected Steps per Second: 22,702.36887
Overall Steps per Second: 10,863.49755

Timestep Collection Time: 2.20338
Timestep Consumption Time: 2.40121
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60459

Cumulative Model Updates: 118,760
Cumulative Timesteps: 990,334,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 990334656...
Checkpoint 990334656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,175.71108
Policy Entropy: 3.81903
Value Function Loss: 0.06050

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.46704
Value Function Update Magnitude: 0.66486

Collected Steps per Second: 22,800.85960
Overall Steps per Second: 10,728.81938

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.46942
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.66407

Cumulative Model Updates: 118,766
Cumulative Timesteps: 990,384,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,511.98998
Policy Entropy: 3.87675
Value Function Loss: 0.05487

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 22,666.51163
Overall Steps per Second: 10,824.82692

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.41408
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62086

Cumulative Model Updates: 118,772
Cumulative Timesteps: 990,434,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 990434716...
Checkpoint 990434716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.85704
Policy Entropy: 3.93883
Value Function Loss: 0.04762

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.63544
Value Function Update Magnitude: 0.73885

Collected Steps per Second: 22,309.73891
Overall Steps per Second: 10,690.60153

Timestep Collection Time: 2.24252
Timestep Consumption Time: 2.43729
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.67981

Cumulative Model Updates: 118,778
Cumulative Timesteps: 990,484,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.33469
Policy Entropy: 4.04927
Value Function Loss: 0.03527

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08044
Policy Update Magnitude: 0.78017
Value Function Update Magnitude: 0.76415

Collected Steps per Second: 22,902.98730
Overall Steps per Second: 10,861.23353

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.42070
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60408

Cumulative Model Updates: 118,784
Cumulative Timesteps: 990,534,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 990534752...
Checkpoint 990534752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,622.17881
Policy Entropy: 4.09657
Value Function Loss: 0.02907

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.83576
Value Function Update Magnitude: 0.93707

Collected Steps per Second: 22,168.67884
Overall Steps per Second: 10,638.35603

Timestep Collection Time: 2.25616
Timestep Consumption Time: 2.44532
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.70148

Cumulative Model Updates: 118,790
Cumulative Timesteps: 990,584,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152.92455
Policy Entropy: 4.12895
Value Function Loss: 0.02258

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06634
Policy Update Magnitude: 0.89641
Value Function Update Magnitude: 1.00363

Collected Steps per Second: 22,423.75115
Overall Steps per Second: 10,532.69897

Timestep Collection Time: 2.23058
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.74883

Cumulative Model Updates: 118,796
Cumulative Timesteps: 990,634,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 990634786...
Checkpoint 990634786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 354.85316
Policy Entropy: 4.14294
Value Function Loss: 0.01924

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 0.94972
Value Function Update Magnitude: 0.96000

Collected Steps per Second: 22,452.99006
Overall Steps per Second: 10,627.38968

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70708

Cumulative Model Updates: 118,802
Cumulative Timesteps: 990,684,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.85886
Policy Entropy: 4.12287
Value Function Loss: 0.01862

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06682
Policy Update Magnitude: 0.91292
Value Function Update Magnitude: 0.97880

Collected Steps per Second: 22,838.95386
Overall Steps per Second: 10,949.04808

Timestep Collection Time: 2.18933
Timestep Consumption Time: 2.37746
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.56679

Cumulative Model Updates: 118,808
Cumulative Timesteps: 990,734,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 990734812...
Checkpoint 990734812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.83864
Policy Entropy: 4.08246
Value Function Loss: 0.02315

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06870
Policy Update Magnitude: 0.84228
Value Function Update Magnitude: 0.91453

Collected Steps per Second: 22,692.86279
Overall Steps per Second: 10,623.53472

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.50430
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.70860

Cumulative Model Updates: 118,814
Cumulative Timesteps: 990,784,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.57588
Policy Entropy: 4.02022
Value Function Loss: 0.02838

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06660
Policy Update Magnitude: 0.79753
Value Function Update Magnitude: 0.80986

Collected Steps per Second: 22,856.53180
Overall Steps per Second: 10,810.92508

Timestep Collection Time: 2.18826
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.62643

Cumulative Model Updates: 118,820
Cumulative Timesteps: 990,834,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 990834850...
Checkpoint 990834850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,777.36724
Policy Entropy: 3.95243
Value Function Loss: 0.04129

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.07072
Policy Update Magnitude: 0.76959
Value Function Update Magnitude: 0.72505

Collected Steps per Second: 22,339.25823
Overall Steps per Second: 10,680.37660

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.44366
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.68223

Cumulative Model Updates: 118,826
Cumulative Timesteps: 990,884,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218.97125
Policy Entropy: 3.92542
Value Function Loss: 0.04002

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07110
Policy Update Magnitude: 0.73120
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 22,751.23379
Overall Steps per Second: 10,652.64486

Timestep Collection Time: 2.19874
Timestep Consumption Time: 2.49719
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69592

Cumulative Model Updates: 118,832
Cumulative Timesteps: 990,934,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 990934882...
Checkpoint 990934882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.10260
Policy Entropy: 3.90230
Value Function Loss: 0.03745

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.63326
Value Function Update Magnitude: 0.52725

Collected Steps per Second: 22,694.91887
Overall Steps per Second: 10,649.06963

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.69806

Cumulative Model Updates: 118,838
Cumulative Timesteps: 990,984,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,801.42592
Policy Entropy: 3.88706
Value Function Loss: 0.03666

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.51425
Value Function Update Magnitude: 0.52716

Collected Steps per Second: 23,123.97058
Overall Steps per Second: 10,724.86462

Timestep Collection Time: 2.16330
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.66430

Cumulative Model Updates: 118,844
Cumulative Timesteps: 991,034,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 991034936...
Checkpoint 991034936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,435.59082
Policy Entropy: 3.84366
Value Function Loss: 0.03584

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.44488
Value Function Update Magnitude: 0.52861

Collected Steps per Second: 22,432.32465
Overall Steps per Second: 10,642.44210

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.69892

Cumulative Model Updates: 118,850
Cumulative Timesteps: 991,084,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160.24567
Policy Entropy: 3.83940
Value Function Loss: 0.03494

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.43734
Value Function Update Magnitude: 0.65114

Collected Steps per Second: 22,899.55224
Overall Steps per Second: 10,844.23894

Timestep Collection Time: 2.18458
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61314

Cumulative Model Updates: 118,856
Cumulative Timesteps: 991,134,970

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 991134970...
Checkpoint 991134970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,969.80191
Policy Entropy: 3.82028
Value Function Loss: 0.03524

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.47304
Value Function Update Magnitude: 0.64987

Collected Steps per Second: 22,608.04996
Overall Steps per Second: 10,728.60363

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.66212

Cumulative Model Updates: 118,862
Cumulative Timesteps: 991,184,988

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,125.50137
Policy Entropy: 3.79775
Value Function Loss: 0.03361

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.45210
Value Function Update Magnitude: 0.53208

Collected Steps per Second: 22,807.37950
Overall Steps per Second: 10,734.93144

Timestep Collection Time: 2.19227
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.65769

Cumulative Model Updates: 118,868
Cumulative Timesteps: 991,234,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 991234988...
Checkpoint 991234988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,584.71175
Policy Entropy: 3.78144
Value Function Loss: 0.03244

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15008
Policy Update Magnitude: 0.40596
Value Function Update Magnitude: 0.48813

Collected Steps per Second: 22,307.64549
Overall Steps per Second: 10,729.31829

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.42029
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.66311

Cumulative Model Updates: 118,874
Cumulative Timesteps: 991,285,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.39479
Policy Entropy: 3.75954
Value Function Loss: 0.03103

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.35237
Value Function Update Magnitude: 0.52235

Collected Steps per Second: 21,978.39276
Overall Steps per Second: 10,632.56402

Timestep Collection Time: 2.27614
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.70498

Cumulative Model Updates: 118,880
Cumulative Timesteps: 991,335,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 991335046...
Checkpoint 991335046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,071.09305
Policy Entropy: 3.75128
Value Function Loss: 0.02994

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.33632
Value Function Update Magnitude: 0.58684

Collected Steps per Second: 22,048.39668
Overall Steps per Second: 10,661.49000

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68996

Cumulative Model Updates: 118,886
Cumulative Timesteps: 991,385,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,646.15548
Policy Entropy: 3.73434
Value Function Loss: 0.03185

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.33231
Value Function Update Magnitude: 0.48533

Collected Steps per Second: 22,118.42988
Overall Steps per Second: 10,787.96635

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.37471
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.63572

Cumulative Model Updates: 118,892
Cumulative Timesteps: 991,435,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 991435058...
Checkpoint 991435058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,647.62966
Policy Entropy: 3.73941
Value Function Loss: 0.02851

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.15010
Policy Update Magnitude: 0.33083
Value Function Update Magnitude: 0.43552

Collected Steps per Second: 21,834.08020
Overall Steps per Second: 10,606.28450

Timestep Collection Time: 2.29000
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.71419

Cumulative Model Updates: 118,898
Cumulative Timesteps: 991,485,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,007.44308
Policy Entropy: 3.71342
Value Function Loss: 0.02718

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.32954
Value Function Update Magnitude: 0.38884

Collected Steps per Second: 22,735.26145
Overall Steps per Second: 10,738.44230

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.65896

Cumulative Model Updates: 118,904
Cumulative Timesteps: 991,535,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 991535088...
Checkpoint 991535088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,113.00343
Policy Entropy: 3.72484
Value Function Loss: 0.02248

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.32043
Value Function Update Magnitude: 0.45178

Collected Steps per Second: 22,812.63010
Overall Steps per Second: 10,887.03548

Timestep Collection Time: 2.19273
Timestep Consumption Time: 2.40191
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.59464

Cumulative Model Updates: 118,910
Cumulative Timesteps: 991,585,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,256.41674
Policy Entropy: 3.71508
Value Function Loss: 0.02541

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.32108
Value Function Update Magnitude: 0.54928

Collected Steps per Second: 22,727.78702
Overall Steps per Second: 10,664.65186

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69007

Cumulative Model Updates: 118,916
Cumulative Timesteps: 991,635,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 991635128...
Checkpoint 991635128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,528.90677
Policy Entropy: 3.71129
Value Function Loss: 0.02760

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.35923
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,517.60710
Overall Steps per Second: 10,806.85402

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62947

Cumulative Model Updates: 118,922
Cumulative Timesteps: 991,685,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,456.76060
Policy Entropy: 3.68921
Value Function Loss: 0.03053

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.39458
Value Function Update Magnitude: 0.56485

Collected Steps per Second: 21,280.15980
Overall Steps per Second: 10,254.25032

Timestep Collection Time: 2.34970
Timestep Consumption Time: 2.52652
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.87622

Cumulative Model Updates: 118,928
Cumulative Timesteps: 991,735,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 991735160...
Checkpoint 991735160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,456.76060
Policy Entropy: 3.68701
Value Function Loss: 0.03079

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.40641
Value Function Update Magnitude: 0.53952

Collected Steps per Second: 21,617.18240
Overall Steps per Second: 10,443.58464

Timestep Collection Time: 2.31353
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.78878

Cumulative Model Updates: 118,934
Cumulative Timesteps: 991,785,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,674.71676
Policy Entropy: 3.70644
Value Function Loss: 0.02711

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.41108
Value Function Update Magnitude: 0.53138

Collected Steps per Second: 22,898.21251
Overall Steps per Second: 10,650.91177

Timestep Collection Time: 2.18428
Timestep Consumption Time: 2.51166
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.69594

Cumulative Model Updates: 118,940
Cumulative Timesteps: 991,835,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 991835188...
Checkpoint 991835188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,263.63841
Policy Entropy: 3.70551
Value Function Loss: 0.02625

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.38507
Value Function Update Magnitude: 0.47140

Collected Steps per Second: 22,615.47145
Overall Steps per Second: 10,622.12960

Timestep Collection Time: 2.21096
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.70734

Cumulative Model Updates: 118,946
Cumulative Timesteps: 991,885,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,263.63841
Policy Entropy: 3.71721
Value Function Loss: 0.01995

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.34966
Value Function Update Magnitude: 0.47268

Collected Steps per Second: 23,049.82879
Overall Steps per Second: 10,798.41297

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.46238
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.63272

Cumulative Model Updates: 118,952
Cumulative Timesteps: 991,935,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 991935216...
Checkpoint 991935216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,247.93924
Policy Entropy: 3.68828
Value Function Loss: 0.02696

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.34696
Value Function Update Magnitude: 0.47591

Collected Steps per Second: 22,914.66553
Overall Steps per Second: 10,635.38502

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70148

Cumulative Model Updates: 118,958
Cumulative Timesteps: 991,985,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,090.28464
Policy Entropy: 3.71985
Value Function Loss: 0.02702

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.40559
Value Function Update Magnitude: 0.43810

Collected Steps per Second: 22,842.33580
Overall Steps per Second: 10,789.02026

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.63434

Cumulative Model Updates: 118,964
Cumulative Timesteps: 992,035,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 992035218...
Checkpoint 992035218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.61470
Policy Entropy: 3.72590
Value Function Loss: 0.03161

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.44108
Value Function Update Magnitude: 0.44541

Collected Steps per Second: 22,569.00066
Overall Steps per Second: 10,756.06266

Timestep Collection Time: 2.21658
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.65096

Cumulative Model Updates: 118,970
Cumulative Timesteps: 992,085,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,939.12914
Policy Entropy: 3.74675
Value Function Loss: 0.02827

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14471
Policy Update Magnitude: 0.42135
Value Function Update Magnitude: 0.43299

Collected Steps per Second: 23,099.04826
Overall Steps per Second: 10,868.25252

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.60221

Cumulative Model Updates: 118,976
Cumulative Timesteps: 992,135,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 992135262...
Checkpoint 992135262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,193.54176
Policy Entropy: 3.70210
Value Function Loss: 0.02818

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14969
Policy Update Magnitude: 0.39592
Value Function Update Magnitude: 0.41984

Collected Steps per Second: 22,740.32098
Overall Steps per Second: 10,658.61385

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.69236

Cumulative Model Updates: 118,982
Cumulative Timesteps: 992,185,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,718.65888
Policy Entropy: 3.70377
Value Function Loss: 0.02968

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.38584
Value Function Update Magnitude: 0.43030

Collected Steps per Second: 23,071.72398
Overall Steps per Second: 10,833.26111

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61560

Cumulative Model Updates: 118,988
Cumulative Timesteps: 992,235,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 992235278...
Checkpoint 992235278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,786.99386
Policy Entropy: 3.71571
Value Function Loss: 0.02982

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.43399
Value Function Update Magnitude: 0.50049

Collected Steps per Second: 22,081.27711
Overall Steps per Second: 10,637.91989

Timestep Collection Time: 2.26572
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.70299

Cumulative Model Updates: 118,994
Cumulative Timesteps: 992,285,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,255.20351
Policy Entropy: 3.70778
Value Function Loss: 0.03197

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.46160
Value Function Update Magnitude: 0.49684

Collected Steps per Second: 22,852.47748
Overall Steps per Second: 10,679.88504

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68189

Cumulative Model Updates: 119,000
Cumulative Timesteps: 992,335,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 992335310...
Checkpoint 992335310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,847.46069
Policy Entropy: 3.72183
Value Function Loss: 0.02879

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.45248
Value Function Update Magnitude: 0.49795

Collected Steps per Second: 22,471.47710
Overall Steps per Second: 10,624.29531

Timestep Collection Time: 2.22638
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.70902

Cumulative Model Updates: 119,006
Cumulative Timesteps: 992,385,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,831.98254
Policy Entropy: 3.70757
Value Function Loss: 0.02863

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14896
Policy Update Magnitude: 0.43772
Value Function Update Magnitude: 0.49749

Collected Steps per Second: 22,602.16395
Overall Steps per Second: 10,718.83679

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.66562

Cumulative Model Updates: 119,012
Cumulative Timesteps: 992,435,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 992435350...
Checkpoint 992435350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.71446
Value Function Loss: 0.02682

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.41149
Value Function Update Magnitude: 0.46208

Collected Steps per Second: 22,416.21150
Overall Steps per Second: 10,760.61842

Timestep Collection Time: 2.23196
Timestep Consumption Time: 2.41759
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.64955

Cumulative Model Updates: 119,018
Cumulative Timesteps: 992,485,382

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.68756
Value Function Loss: 0.02783

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.39587
Value Function Update Magnitude: 0.46994

Collected Steps per Second: 22,885.16835
Overall Steps per Second: 10,802.97771

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62983

Cumulative Model Updates: 119,024
Cumulative Timesteps: 992,535,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 992535398...
Checkpoint 992535398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.68612
Value Function Loss: 0.02514

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14568
Policy Update Magnitude: 0.39982
Value Function Update Magnitude: 0.48790

Collected Steps per Second: 22,478.68004
Overall Steps per Second: 10,655.81263

Timestep Collection Time: 2.22531
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.69434

Cumulative Model Updates: 119,030
Cumulative Timesteps: 992,585,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.66821
Value Function Loss: 0.02446

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14956
Policy Update Magnitude: 0.37955
Value Function Update Magnitude: 0.48397

Collected Steps per Second: 21,971.45170
Overall Steps per Second: 10,654.63343

Timestep Collection Time: 2.27632
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.69411

Cumulative Model Updates: 119,036
Cumulative Timesteps: 992,635,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 992635434...
Checkpoint 992635434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.67314
Value Function Loss: 0.02274

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.36601
Value Function Update Magnitude: 0.46389

Collected Steps per Second: 21,926.97242
Overall Steps per Second: 10,649.41505

Timestep Collection Time: 2.28130
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69716

Cumulative Model Updates: 119,042
Cumulative Timesteps: 992,685,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,232.75900
Policy Entropy: 3.67259
Value Function Loss: 0.02267

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15094
Policy Update Magnitude: 0.37177
Value Function Update Magnitude: 0.42270

Collected Steps per Second: 22,476.31283
Overall Steps per Second: 10,698.63932

Timestep Collection Time: 2.22590
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.67630

Cumulative Model Updates: 119,048
Cumulative Timesteps: 992,735,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 992735486...
Checkpoint 992735486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,515.24207
Policy Entropy: 3.69239
Value Function Loss: 0.02328

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.15280
Policy Update Magnitude: 0.35485
Value Function Update Magnitude: 0.38591

Collected Steps per Second: 22,656.31626
Overall Steps per Second: 10,645.86950

Timestep Collection Time: 2.20724
Timestep Consumption Time: 2.49017
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69741

Cumulative Model Updates: 119,054
Cumulative Timesteps: 992,785,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,526.30710
Policy Entropy: 3.71206
Value Function Loss: 0.02152

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.36128
Value Function Update Magnitude: 0.45590

Collected Steps per Second: 22,861.96539
Overall Steps per Second: 10,865.79402

Timestep Collection Time: 2.18783
Timestep Consumption Time: 2.41543
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.60325

Cumulative Model Updates: 119,060
Cumulative Timesteps: 992,835,512

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 992835512...
Checkpoint 992835512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,511.95855
Policy Entropy: 3.72827
Value Function Loss: 0.02312

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.36783
Value Function Update Magnitude: 0.49072

Collected Steps per Second: 22,516.45521
Overall Steps per Second: 10,663.97307

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.68943

Cumulative Model Updates: 119,066
Cumulative Timesteps: 992,885,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.68259
Policy Entropy: 3.74180
Value Function Loss: 0.01923

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.36732
Value Function Update Magnitude: 0.49739

Collected Steps per Second: 23,135.65068
Overall Steps per Second: 10,883.48553

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.59651

Cumulative Model Updates: 119,072
Cumulative Timesteps: 992,935,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 992935546...
Checkpoint 992935546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.66289
Policy Entropy: 3.71696
Value Function Loss: 0.02239

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.37402
Value Function Update Magnitude: 0.54032

Collected Steps per Second: 22,534.69500
Overall Steps per Second: 10,763.47763

Timestep Collection Time: 2.21960
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.64701

Cumulative Model Updates: 119,078
Cumulative Timesteps: 992,985,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.66289
Policy Entropy: 3.72466
Value Function Loss: 0.02057

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.39550
Value Function Update Magnitude: 0.65136

Collected Steps per Second: 22,944.95513
Overall Steps per Second: 10,799.86835

Timestep Collection Time: 2.18026
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.63209

Cumulative Model Updates: 119,084
Cumulative Timesteps: 993,035,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 993035590...
Checkpoint 993035590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,917.90742
Policy Entropy: 3.71039
Value Function Loss: 0.02382

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.44311
Value Function Update Magnitude: 0.69500

Collected Steps per Second: 22,252.60637
Overall Steps per Second: 10,670.21279

Timestep Collection Time: 2.24774
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.68763

Cumulative Model Updates: 119,090
Cumulative Timesteps: 993,085,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,816.72873
Policy Entropy: 3.70504
Value Function Loss: 0.02491

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.45985
Value Function Update Magnitude: 0.62835

Collected Steps per Second: 22,660.30802
Overall Steps per Second: 10,669.70308

Timestep Collection Time: 2.20703
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.68729

Cumulative Model Updates: 119,096
Cumulative Timesteps: 993,135,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 993135620...
Checkpoint 993135620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221,956.57412
Policy Entropy: 3.70073
Value Function Loss: 0.02732

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.47010
Value Function Update Magnitude: 0.55451

Collected Steps per Second: 22,822.19788
Overall Steps per Second: 10,845.84114

Timestep Collection Time: 2.19120
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61080

Cumulative Model Updates: 119,102
Cumulative Timesteps: 993,185,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,546.35954
Policy Entropy: 3.70461
Value Function Loss: 0.02543

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.46686
Value Function Update Magnitude: 0.50444

Collected Steps per Second: 22,732.09582
Overall Steps per Second: 10,610.77207

Timestep Collection Time: 2.20059
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.71445

Cumulative Model Updates: 119,108
Cumulative Timesteps: 993,235,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 993235652...
Checkpoint 993235652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,546.35954
Policy Entropy: 3.71321
Value Function Loss: 0.02155

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14708
Policy Update Magnitude: 0.42970
Value Function Update Magnitude: 0.45151

Collected Steps per Second: 22,426.10515
Overall Steps per Second: 10,574.55721

Timestep Collection Time: 2.23017
Timestep Consumption Time: 2.49949
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.72965

Cumulative Model Updates: 119,114
Cumulative Timesteps: 993,285,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,546.35954
Policy Entropy: 3.70552
Value Function Loss: 0.01896

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14722
Policy Update Magnitude: 0.36650
Value Function Update Magnitude: 0.38947

Collected Steps per Second: 22,945.67658
Overall Steps per Second: 10,833.37194

Timestep Collection Time: 2.17984
Timestep Consumption Time: 2.43719
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61703

Cumulative Model Updates: 119,120
Cumulative Timesteps: 993,335,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 993335684...
Checkpoint 993335684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,953.37772
Policy Entropy: 3.71172
Value Function Loss: 0.02028

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.36977
Value Function Update Magnitude: 0.39824

Collected Steps per Second: 22,470.76633
Overall Steps per Second: 10,682.14942

Timestep Collection Time: 2.22600
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.68258

Cumulative Model Updates: 119,126
Cumulative Timesteps: 993,385,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,666.46249
Policy Entropy: 3.71027
Value Function Loss: 0.02161

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.40414
Value Function Update Magnitude: 0.45739

Collected Steps per Second: 22,803.82243
Overall Steps per Second: 10,777.12705

Timestep Collection Time: 2.19332
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.64094

Cumulative Model Updates: 119,132
Cumulative Timesteps: 993,435,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 993435720...
Checkpoint 993435720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,511.80851
Policy Entropy: 3.71636
Value Function Loss: 0.02356

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.41892
Value Function Update Magnitude: 0.47552

Collected Steps per Second: 22,441.81040
Overall Steps per Second: 10,707.04861

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.67132

Cumulative Model Updates: 119,138
Cumulative Timesteps: 993,485,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,745.76531
Policy Entropy: 3.71989
Value Function Loss: 0.02795

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.44248
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 23,109.69805
Overall Steps per Second: 10,869.11309

Timestep Collection Time: 2.16532
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60387

Cumulative Model Updates: 119,144
Cumulative Timesteps: 993,535,776

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 993535776...
Checkpoint 993535776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 259,935.63353
Policy Entropy: 3.72826
Value Function Loss: 0.02638

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.46988
Value Function Update Magnitude: 0.64569

Collected Steps per Second: 22,548.30860
Overall Steps per Second: 10,769.66095

Timestep Collection Time: 2.21888
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.64564

Cumulative Model Updates: 119,150
Cumulative Timesteps: 993,585,808

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,312.78351
Policy Entropy: 3.72324
Value Function Loss: 0.02601

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.45106
Value Function Update Magnitude: 0.59007

Collected Steps per Second: 22,744.31755
Overall Steps per Second: 10,790.21948

Timestep Collection Time: 2.19862
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.63438

Cumulative Model Updates: 119,156
Cumulative Timesteps: 993,635,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 993635814...
Checkpoint 993635814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,110.82306
Policy Entropy: 3.74803
Value Function Loss: 0.02239

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13952
Policy Update Magnitude: 0.41010
Value Function Update Magnitude: 0.47969

Collected Steps per Second: 22,446.90266
Overall Steps per Second: 10,688.89663

Timestep Collection Time: 2.22846
Timestep Consumption Time: 2.45135
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.67981

Cumulative Model Updates: 119,162
Cumulative Timesteps: 993,685,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,653.38387
Policy Entropy: 3.74562
Value Function Loss: 0.02329

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.39615
Value Function Update Magnitude: 0.47625

Collected Steps per Second: 23,011.66632
Overall Steps per Second: 10,830.92446

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.61900

Cumulative Model Updates: 119,168
Cumulative Timesteps: 993,735,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 993735864...
Checkpoint 993735864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,724.23685
Policy Entropy: 3.76103
Value Function Loss: 0.02243

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.39334
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 22,686.23054
Overall Steps per Second: 10,793.04060

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.63521

Cumulative Model Updates: 119,174
Cumulative Timesteps: 993,785,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,634.21960
Policy Entropy: 3.73790
Value Function Loss: 0.02495

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.40304
Value Function Update Magnitude: 0.59661

Collected Steps per Second: 23,015.16207
Overall Steps per Second: 10,814.13923

Timestep Collection Time: 2.17248
Timestep Consumption Time: 2.45110
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62358

Cumulative Model Updates: 119,180
Cumulative Timesteps: 993,835,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 993835892...
Checkpoint 993835892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,261.26947
Policy Entropy: 3.75583
Value Function Loss: 0.02583

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.44710
Value Function Update Magnitude: 0.67089

Collected Steps per Second: 22,324.22197
Overall Steps per Second: 10,683.03325

Timestep Collection Time: 2.24062
Timestep Consumption Time: 2.44158
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.68219

Cumulative Model Updates: 119,186
Cumulative Timesteps: 993,885,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,716.19141
Policy Entropy: 3.77391
Value Function Loss: 0.02776

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.48059
Value Function Update Magnitude: 0.75478

Collected Steps per Second: 22,712.48646
Overall Steps per Second: 10,643.52250

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.49636
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69788

Cumulative Model Updates: 119,192
Cumulative Timesteps: 993,935,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 993935914...
Checkpoint 993935914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,159.88926
Policy Entropy: 3.77976
Value Function Loss: 0.02887

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.54436
Value Function Update Magnitude: 0.70098

Collected Steps per Second: 22,557.94345
Overall Steps per Second: 10,647.30942

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69846

Cumulative Model Updates: 119,198
Cumulative Timesteps: 993,985,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,543.78880
Policy Entropy: 3.75990
Value Function Loss: 0.02896

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.58108

Collected Steps per Second: 22,751.55516
Overall Steps per Second: 10,681.14684

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.68208

Cumulative Model Updates: 119,204
Cumulative Timesteps: 994,035,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 994035950...
Checkpoint 994035950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,268.96928
Policy Entropy: 3.75075
Value Function Loss: 0.02588

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.54082
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 22,571.93297
Overall Steps per Second: 10,628.99732

Timestep Collection Time: 2.21558
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.70505

Cumulative Model Updates: 119,210
Cumulative Timesteps: 994,085,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,268.96928
Policy Entropy: 3.73667
Value Function Loss: 0.02631

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.50277
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 22,884.66960
Overall Steps per Second: 10,701.14305

Timestep Collection Time: 2.18609
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.67501

Cumulative Model Updates: 119,216
Cumulative Timesteps: 994,135,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 994135988...
Checkpoint 994135988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,768.85136
Policy Entropy: 3.72552
Value Function Loss: 0.02467

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.46301
Value Function Update Magnitude: 0.43326

Collected Steps per Second: 22,704.08245
Overall Steps per Second: 10,806.73479

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.42556
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62878

Cumulative Model Updates: 119,222
Cumulative Timesteps: 994,186,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,182.23308
Policy Entropy: 3.72564
Value Function Loss: 0.02395

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.43713
Value Function Update Magnitude: 0.54465

Collected Steps per Second: 23,277.45029
Overall Steps per Second: 10,907.18140

Timestep Collection Time: 2.14809
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.58432

Cumulative Model Updates: 119,228
Cumulative Timesteps: 994,236,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 994236012...
Checkpoint 994236012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,792.07226
Policy Entropy: 3.73571
Value Function Loss: 0.03097

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.43488
Value Function Update Magnitude: 0.54671

Collected Steps per Second: 22,439.10990
Overall Steps per Second: 10,680.37339

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.68411

Cumulative Model Updates: 119,234
Cumulative Timesteps: 994,286,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,258.09092
Policy Entropy: 3.74332
Value Function Loss: 0.03025

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.46376
Value Function Update Magnitude: 0.51755

Collected Steps per Second: 22,850.94058
Overall Steps per Second: 10,689.70707

Timestep Collection Time: 2.18906
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.67945

Cumulative Model Updates: 119,240
Cumulative Timesteps: 994,336,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994336062...
Checkpoint 994336062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,609.50288
Policy Entropy: 3.74110
Value Function Loss: 0.02710

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.47439
Value Function Update Magnitude: 0.53319

Collected Steps per Second: 22,685.99681
Overall Steps per Second: 10,794.36296

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.63427

Cumulative Model Updates: 119,246
Cumulative Timesteps: 994,386,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.92815
Policy Entropy: 3.74410
Value Function Loss: 0.02266

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.45917
Value Function Update Magnitude: 0.49607

Collected Steps per Second: 22,605.57390
Overall Steps per Second: 10,577.19970

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.72980

Cumulative Model Updates: 119,252
Cumulative Timesteps: 994,436,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 994436114...
Checkpoint 994436114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,212.97572
Policy Entropy: 3.74524
Value Function Loss: 0.02161

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13833
Policy Update Magnitude: 0.42063
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,581.20659
Overall Steps per Second: 10,597.71907

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.50397
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.71837

Cumulative Model Updates: 119,258
Cumulative Timesteps: 994,486,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,724.43559
Policy Entropy: 3.74306
Value Function Loss: 0.02220

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.43859
Value Function Update Magnitude: 0.53778

Collected Steps per Second: 23,059.42488
Overall Steps per Second: 10,869.30719

Timestep Collection Time: 2.16831
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60011

Cumulative Model Updates: 119,264
Cumulative Timesteps: 994,536,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 994536118...
Checkpoint 994536118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,730.70296
Policy Entropy: 3.73472
Value Function Loss: 0.02687

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.47835
Value Function Update Magnitude: 0.53509

Collected Steps per Second: 21,966.81938
Overall Steps per Second: 10,670.85556

Timestep Collection Time: 2.27616
Timestep Consumption Time: 2.40950
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68566

Cumulative Model Updates: 119,270
Cumulative Timesteps: 994,586,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,090.17752
Policy Entropy: 3.74094
Value Function Loss: 0.02468

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.48196
Value Function Update Magnitude: 0.57001

Collected Steps per Second: 22,235.82930
Overall Steps per Second: 10,828.46830

Timestep Collection Time: 2.24997
Timestep Consumption Time: 2.37026
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.62023

Cumulative Model Updates: 119,276
Cumulative Timesteps: 994,636,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 994636148...
Checkpoint 994636148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,474.87964
Policy Entropy: 3.73125
Value Function Loss: 0.02378

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.45731
Value Function Update Magnitude: 0.53648

Collected Steps per Second: 21,356.35887
Overall Steps per Second: 10,633.94509

Timestep Collection Time: 2.34263
Timestep Consumption Time: 2.36212
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.70475

Cumulative Model Updates: 119,282
Cumulative Timesteps: 994,686,178

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.72225
Value Function Loss: 0.02310

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.44094
Value Function Update Magnitude: 0.60433

Collected Steps per Second: 21,961.31593
Overall Steps per Second: 10,550.93954

Timestep Collection Time: 2.27791
Timestep Consumption Time: 2.46346
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.74138

Cumulative Model Updates: 119,288
Cumulative Timesteps: 994,736,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 994736204...
Checkpoint 994736204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.71660
Value Function Loss: 0.02274

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.42581
Value Function Update Magnitude: 0.59321

Collected Steps per Second: 22,571.77856
Overall Steps per Second: 10,637.25796

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.70272

Cumulative Model Updates: 119,294
Cumulative Timesteps: 994,786,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.70999
Value Function Loss: 0.02136

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.42929
Value Function Update Magnitude: 0.59213

Collected Steps per Second: 23,059.81300
Overall Steps per Second: 10,907.78820

Timestep Collection Time: 2.16966
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.58681

Cumulative Model Updates: 119,300
Cumulative Timesteps: 994,836,260

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 994836260...
Checkpoint 994836260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.71373
Value Function Loss: 0.02083

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.43228
Value Function Update Magnitude: 0.54289

Collected Steps per Second: 22,280.90933
Overall Steps per Second: 10,687.42265

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.68083

Cumulative Model Updates: 119,306
Cumulative Timesteps: 994,886,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.71642
Value Function Loss: 0.02052

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.40462
Value Function Update Magnitude: 0.45901

Collected Steps per Second: 22,902.37185
Overall Steps per Second: 10,823.17686

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62452

Cumulative Model Updates: 119,312
Cumulative Timesteps: 994,936,338

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 994936338...
Checkpoint 994936338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.73071
Value Function Loss: 0.01944

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.40881
Value Function Update Magnitude: 0.44814

Collected Steps per Second: 22,408.84462
Overall Steps per Second: 10,747.53445

Timestep Collection Time: 2.23207
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.65390

Cumulative Model Updates: 119,318
Cumulative Timesteps: 994,986,356

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,299.65537
Policy Entropy: 3.72116
Value Function Loss: 0.02065

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.40375
Value Function Update Magnitude: 0.42008

Collected Steps per Second: 22,795.78292
Overall Steps per Second: 10,798.24878

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.43797
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63223

Cumulative Model Updates: 119,324
Cumulative Timesteps: 995,036,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 995036376...
Checkpoint 995036376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,718.35632
Policy Entropy: 3.72706
Value Function Loss: 0.01999

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.41523
Value Function Update Magnitude: 0.42152

Collected Steps per Second: 22,508.00255
Overall Steps per Second: 10,748.26527

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.65247

Cumulative Model Updates: 119,330
Cumulative Timesteps: 995,086,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.72541
Value Function Loss: 0.02198

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.42848
Value Function Update Magnitude: 0.56701

Collected Steps per Second: 22,396.94909
Overall Steps per Second: 10,617.74457

Timestep Collection Time: 2.23325
Timestep Consumption Time: 2.47754
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.71079

Cumulative Model Updates: 119,336
Cumulative Timesteps: 995,136,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 995136400...
Checkpoint 995136400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.73097
Value Function Loss: 0.02397

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.43443
Value Function Update Magnitude: 0.47033

Collected Steps per Second: 22,638.34680
Overall Steps per Second: 10,805.18012

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.41974
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.62926

Cumulative Model Updates: 119,342
Cumulative Timesteps: 995,186,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.72150
Value Function Loss: 0.02150

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.44299
Value Function Update Magnitude: 0.43300

Collected Steps per Second: 22,886.71497
Overall Steps per Second: 10,712.82814

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.48273
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.66749

Cumulative Model Updates: 119,348
Cumulative Timesteps: 995,236,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 995236422...
Checkpoint 995236422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.71763
Value Function Loss: 0.01994

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.44217
Value Function Update Magnitude: 0.39772

Collected Steps per Second: 22,198.62155
Overall Steps per Second: 10,532.65505

Timestep Collection Time: 2.25257
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.74752

Cumulative Model Updates: 119,354
Cumulative Timesteps: 995,286,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.72267
Value Function Loss: 0.01716

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.43281
Value Function Update Magnitude: 0.49250

Collected Steps per Second: 22,042.67400
Overall Steps per Second: 10,800.94507

Timestep Collection Time: 2.26933
Timestep Consumption Time: 2.36194
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.63126

Cumulative Model Updates: 119,360
Cumulative Timesteps: 995,336,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 995336448...
Checkpoint 995336448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,456.29895
Policy Entropy: 3.71320
Value Function Loss: 0.02297

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.44541
Value Function Update Magnitude: 0.44435

Collected Steps per Second: 21,824.85497
Overall Steps per Second: 10,691.64159

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.38616
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.67767

Cumulative Model Updates: 119,366
Cumulative Timesteps: 995,386,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,590.11824
Policy Entropy: 3.73416
Value Function Loss: 0.02305

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.48284
Value Function Update Magnitude: 0.43693

Collected Steps per Second: 21,853.66522
Overall Steps per Second: 10,444.50596

Timestep Collection Time: 2.28831
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.78797

Cumulative Model Updates: 119,372
Cumulative Timesteps: 995,436,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 995436468...
Checkpoint 995436468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,374.94536
Policy Entropy: 3.73876
Value Function Loss: 0.02403

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.49530
Value Function Update Magnitude: 0.47442

Collected Steps per Second: 22,544.59340
Overall Steps per Second: 10,619.14513

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.70923

Cumulative Model Updates: 119,378
Cumulative Timesteps: 995,486,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,929.56882
Policy Entropy: 3.74773
Value Function Loss: 0.02222

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.48845
Value Function Update Magnitude: 0.50477

Collected Steps per Second: 22,987.39954
Overall Steps per Second: 10,864.63331

Timestep Collection Time: 2.17580
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.60356

Cumulative Model Updates: 119,384
Cumulative Timesteps: 995,536,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 995536492...
Checkpoint 995536492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.32540
Policy Entropy: 3.74092
Value Function Loss: 0.02364

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.48899
Value Function Update Magnitude: 0.55060

Collected Steps per Second: 22,638.37287
Overall Steps per Second: 10,683.25323

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.68022

Cumulative Model Updates: 119,390
Cumulative Timesteps: 995,586,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,715.45879
Policy Entropy: 3.74614
Value Function Loss: 0.02375

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.48145
Value Function Update Magnitude: 0.56189

Collected Steps per Second: 22,610.84426
Overall Steps per Second: 10,622.05119

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.70964

Cumulative Model Updates: 119,396
Cumulative Timesteps: 995,636,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 995636518...
Checkpoint 995636518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,438.87728
Policy Entropy: 3.76333
Value Function Loss: 0.02492

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.46902
Value Function Update Magnitude: 0.50790

Collected Steps per Second: 22,450.25453
Overall Steps per Second: 10,547.70620

Timestep Collection Time: 2.22804
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.74226

Cumulative Model Updates: 119,402
Cumulative Timesteps: 995,686,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,044.18410
Policy Entropy: 3.77433
Value Function Loss: 0.02354

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.45934
Value Function Update Magnitude: 0.54851

Collected Steps per Second: 22,516.02970
Overall Steps per Second: 10,764.37199

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.64663

Cumulative Model Updates: 119,408
Cumulative Timesteps: 995,736,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 995736556...
Checkpoint 995736556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,853.75024
Policy Entropy: 3.77194
Value Function Loss: 0.02190

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.44392
Value Function Update Magnitude: 0.57386

Collected Steps per Second: 22,181.64321
Overall Steps per Second: 10,659.90204

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.69123

Cumulative Model Updates: 119,414
Cumulative Timesteps: 995,786,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,853.75024
Policy Entropy: 3.72556
Value Function Loss: 0.01945

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.41494
Value Function Update Magnitude: 0.56413

Collected Steps per Second: 22,814.71988
Overall Steps per Second: 10,704.81331

Timestep Collection Time: 2.19218
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.67210

Cumulative Model Updates: 119,420
Cumulative Timesteps: 995,836,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 995836578...
Checkpoint 995836578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,853.75024
Policy Entropy: 3.71058
Value Function Loss: 0.01775

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.39911
Value Function Update Magnitude: 0.46032

Collected Steps per Second: 22,381.55803
Overall Steps per Second: 10,421.63887

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.56373
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 4.79771

Cumulative Model Updates: 119,426
Cumulative Timesteps: 995,886,578

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,948.32932
Policy Entropy: 3.70033
Value Function Loss: 0.01781

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.37009
Value Function Update Magnitude: 0.46976

Collected Steps per Second: 23,108.45272
Overall Steps per Second: 10,733.56014

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.49597
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.66090

Cumulative Model Updates: 119,432
Cumulative Timesteps: 995,936,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 995936606...
Checkpoint 995936606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,948.32932
Policy Entropy: 3.72300
Value Function Loss: 0.01975

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.36578
Value Function Update Magnitude: 0.46284

Collected Steps per Second: 21,868.84611
Overall Steps per Second: 10,787.37999

Timestep Collection Time: 2.28773
Timestep Consumption Time: 2.35010
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.63783

Cumulative Model Updates: 119,438
Cumulative Timesteps: 995,986,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,948.32932
Policy Entropy: 3.72202
Value Function Loss: 0.02059

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.40026
Value Function Update Magnitude: 0.48447

Collected Steps per Second: 21,998.69329
Overall Steps per Second: 10,655.73334

Timestep Collection Time: 2.27304
Timestep Consumption Time: 2.41964
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69268

Cumulative Model Updates: 119,444
Cumulative Timesteps: 996,036,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 996036640...
Checkpoint 996036640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,309.58057
Policy Entropy: 3.73118
Value Function Loss: 0.02166

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.42718
Value Function Update Magnitude: 0.50801

Collected Steps per Second: 21,876.41779
Overall Steps per Second: 10,457.08359

Timestep Collection Time: 2.28657
Timestep Consumption Time: 2.49698
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.78355

Cumulative Model Updates: 119,450
Cumulative Timesteps: 996,086,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,184.99463
Policy Entropy: 3.73760
Value Function Loss: 0.02229

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.45372
Value Function Update Magnitude: 0.59218

Collected Steps per Second: 22,602.61925
Overall Steps per Second: 10,688.44607

Timestep Collection Time: 2.21275
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67926

Cumulative Model Updates: 119,456
Cumulative Timesteps: 996,136,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 996136676...
Checkpoint 996136676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,289.12925
Policy Entropy: 3.74436
Value Function Loss: 0.02248

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.49882
Value Function Update Magnitude: 0.57306

Collected Steps per Second: 22,651.79748
Overall Steps per Second: 10,849.70567

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.40176
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60971

Cumulative Model Updates: 119,462
Cumulative Timesteps: 996,186,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,629.78029
Policy Entropy: 3.72544
Value Function Loss: 0.02278

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.49945
Value Function Update Magnitude: 0.48974

Collected Steps per Second: 22,583.39702
Overall Steps per Second: 10,588.09758

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.50877
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.72323

Cumulative Model Updates: 119,468
Cumulative Timesteps: 996,236,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 996236700...
Checkpoint 996236700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,307.30613
Policy Entropy: 3.72077
Value Function Loss: 0.02230

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.48401
Value Function Update Magnitude: 0.46009

Collected Steps per Second: 22,466.00575
Overall Steps per Second: 10,521.24554

Timestep Collection Time: 2.22612
Timestep Consumption Time: 2.52731
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.75343

Cumulative Model Updates: 119,474
Cumulative Timesteps: 996,286,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,983.39398
Policy Entropy: 3.70796
Value Function Loss: 0.02364

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.47011
Value Function Update Magnitude: 0.44086

Collected Steps per Second: 22,783.33354
Overall Steps per Second: 10,669.20684

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.49220
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68713

Cumulative Model Updates: 119,480
Cumulative Timesteps: 996,336,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 996336720...
Checkpoint 996336720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547,586.87381
Policy Entropy: 3.72266
Value Function Loss: 0.02178

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.47133
Value Function Update Magnitude: 0.41521

Collected Steps per Second: 22,675.97345
Overall Steps per Second: 10,801.58388

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.62969

Cumulative Model Updates: 119,486
Cumulative Timesteps: 996,386,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007,190.37553
Policy Entropy: 3.71039
Value Function Loss: 0.02240

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.48282
Value Function Update Magnitude: 0.48197

Collected Steps per Second: 22,561.58910
Overall Steps per Second: 10,580.70333

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.72577

Cumulative Model Updates: 119,492
Cumulative Timesteps: 996,436,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 996436730...
Checkpoint 996436730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,547.52587
Policy Entropy: 3.74569
Value Function Loss: 0.02133

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.48119
Value Function Update Magnitude: 0.48322

Collected Steps per Second: 22,832.81852
Overall Steps per Second: 10,660.22116

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.50190
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.69296

Cumulative Model Updates: 119,498
Cumulative Timesteps: 996,486,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.92753
Policy Entropy: 3.75473
Value Function Loss: 0.02320

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.50207
Value Function Update Magnitude: 0.51458

Collected Steps per Second: 22,696.80901
Overall Steps per Second: 10,787.45673

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.43235
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.63557

Cumulative Model Updates: 119,504
Cumulative Timesteps: 996,536,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 996536764...
Checkpoint 996536764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.67025
Policy Entropy: 3.76552
Value Function Loss: 0.02267

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.51615
Value Function Update Magnitude: 0.54286

Collected Steps per Second: 21,521.10940
Overall Steps per Second: 10,641.50126

Timestep Collection Time: 2.32358
Timestep Consumption Time: 2.37557
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.69915

Cumulative Model Updates: 119,510
Cumulative Timesteps: 996,586,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,754.85705
Policy Entropy: 3.75162
Value Function Loss: 0.02297

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16097
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.47229

Collected Steps per Second: 21,775.56270
Overall Steps per Second: 10,574.85753

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.72895

Cumulative Model Updates: 119,516
Cumulative Timesteps: 996,636,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 996636778...
Checkpoint 996636778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,016.89708
Policy Entropy: 3.75239
Value Function Loss: 0.02246

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17867
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.48412

Collected Steps per Second: 22,000.97393
Overall Steps per Second: 10,591.35458

Timestep Collection Time: 2.27326
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.72215

Cumulative Model Updates: 119,522
Cumulative Timesteps: 996,686,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,700.10115
Policy Entropy: 3.73448
Value Function Loss: 0.02152

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.52979

Collected Steps per Second: 22,753.61915
Overall Steps per Second: 10,837.79726

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.41700
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61533

Cumulative Model Updates: 119,528
Cumulative Timesteps: 996,736,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 996736812...
Checkpoint 996736812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,700.10115
Policy Entropy: 3.71222
Value Function Loss: 0.02055

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16257
Policy Update Magnitude: 0.53246
Value Function Update Magnitude: 0.53867

Collected Steps per Second: 22,666.29004
Overall Steps per Second: 10,697.06742

Timestep Collection Time: 2.20662
Timestep Consumption Time: 2.46905
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.67567

Cumulative Model Updates: 119,534
Cumulative Timesteps: 996,786,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,794.27181
Policy Entropy: 3.69868
Value Function Loss: 0.02458

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.53267
Value Function Update Magnitude: 0.58599

Collected Steps per Second: 22,904.64911
Overall Steps per Second: 10,808.13229

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62781

Cumulative Model Updates: 119,540
Cumulative Timesteps: 996,836,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 996836846...
Checkpoint 996836846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,360.42722
Policy Entropy: 3.71534
Value Function Loss: 0.02656

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.68345

Collected Steps per Second: 22,219.33115
Overall Steps per Second: 10,673.12869

Timestep Collection Time: 2.25137
Timestep Consumption Time: 2.43554
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.68691

Cumulative Model Updates: 119,546
Cumulative Timesteps: 996,886,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,623.09443
Policy Entropy: 3.73839
Value Function Loss: 0.03217

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.60320
Value Function Update Magnitude: 0.68332

Collected Steps per Second: 22,573.64675
Overall Steps per Second: 10,594.50986

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.50445
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71943

Cumulative Model Updates: 119,552
Cumulative Timesteps: 996,936,870

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 996936870...
Checkpoint 996936870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,623.09443
Policy Entropy: 3.73922
Value Function Loss: 0.03078

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.66964
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 22,430.61809
Overall Steps per Second: 10,562.45685

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73507

Cumulative Model Updates: 119,558
Cumulative Timesteps: 996,986,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,623.09443
Policy Entropy: 3.71347
Value Function Loss: 0.02977

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.67546
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,681.86344
Overall Steps per Second: 10,652.95885

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.69447

Cumulative Model Updates: 119,564
Cumulative Timesteps: 997,036,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 997036894...
Checkpoint 997036894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,949.80897
Policy Entropy: 3.71547
Value Function Loss: 0.02593

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.60280
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,607.02326
Overall Steps per Second: 10,648.38698

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69592

Cumulative Model Updates: 119,570
Cumulative Timesteps: 997,086,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.72879
Value Function Loss: 0.02513

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.51988
Value Function Update Magnitude: 0.56524

Collected Steps per Second: 23,096.00123
Overall Steps per Second: 10,715.11478

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.66705

Cumulative Model Updates: 119,576
Cumulative Timesteps: 997,136,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 997136906...
Checkpoint 997136906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.73941
Value Function Loss: 0.01982

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.47287
Value Function Update Magnitude: 0.53764

Collected Steps per Second: 21,955.81351
Overall Steps per Second: 10,647.62214

Timestep Collection Time: 2.27821
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.69776

Cumulative Model Updates: 119,582
Cumulative Timesteps: 997,186,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.72666
Value Function Loss: 0.01923

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.43486
Value Function Update Magnitude: 0.51489

Collected Steps per Second: 22,078.64333
Overall Steps per Second: 10,816.22266

Timestep Collection Time: 2.26463
Timestep Consumption Time: 2.35805
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62269

Cumulative Model Updates: 119,588
Cumulative Timesteps: 997,236,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 997236926...
Checkpoint 997236926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.71748
Value Function Loss: 0.01805

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.40667
Value Function Update Magnitude: 0.47596

Collected Steps per Second: 21,696.88408
Overall Steps per Second: 10,750.13115

Timestep Collection Time: 2.30522
Timestep Consumption Time: 2.34738
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.65259

Cumulative Model Updates: 119,594
Cumulative Timesteps: 997,286,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.72462
Value Function Loss: 0.01675

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.41348
Value Function Update Magnitude: 0.41195

Collected Steps per Second: 22,044.96298
Overall Steps per Second: 10,566.05904

Timestep Collection Time: 2.26882
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.73365

Cumulative Model Updates: 119,600
Cumulative Timesteps: 997,336,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 997336958...
Checkpoint 997336958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,581.89960
Policy Entropy: 3.71254
Value Function Loss: 0.01739

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.40811
Value Function Update Magnitude: 0.49452

Collected Steps per Second: 22,790.34225
Overall Steps per Second: 10,911.74374

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.38955
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.58460

Cumulative Model Updates: 119,606
Cumulative Timesteps: 997,386,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,501.26804
Policy Entropy: 3.72853
Value Function Loss: 0.01679

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.43227
Value Function Update Magnitude: 0.60406

Collected Steps per Second: 22,893.96861
Overall Steps per Second: 10,844.96160

Timestep Collection Time: 2.18512
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61283

Cumulative Model Updates: 119,612
Cumulative Timesteps: 997,437,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 997437010...
Checkpoint 997437010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,504.36637
Policy Entropy: 3.71343
Value Function Loss: 0.02018

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14961
Policy Update Magnitude: 0.45641
Value Function Update Magnitude: 0.55506

Collected Steps per Second: 22,460.01222
Overall Steps per Second: 10,761.70167

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.42041
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.64703

Cumulative Model Updates: 119,618
Cumulative Timesteps: 997,487,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,243.07191
Policy Entropy: 3.74191
Value Function Loss: 0.01791

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.44401
Value Function Update Magnitude: 0.64881

Collected Steps per Second: 22,683.46261
Overall Steps per Second: 10,797.62949

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.63194

Cumulative Model Updates: 119,624
Cumulative Timesteps: 997,537,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 997537034...
Checkpoint 997537034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,562.00435
Policy Entropy: 3.72236
Value Function Loss: 0.01833

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.40614
Value Function Update Magnitude: 0.63907

Collected Steps per Second: 22,593.49287
Overall Steps per Second: 10,794.65278

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.63396

Cumulative Model Updates: 119,630
Cumulative Timesteps: 997,587,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,562.00435
Policy Entropy: 3.73080
Value Function Loss: 0.01596

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.37895
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 23,212.45208
Overall Steps per Second: 10,825.03448

Timestep Collection Time: 2.15488
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.62077

Cumulative Model Updates: 119,636
Cumulative Timesteps: 997,637,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 997637076...
Checkpoint 997637076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,001.89276
Policy Entropy: 3.72510
Value Function Loss: 0.01794

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.41690
Value Function Update Magnitude: 0.65494

Collected Steps per Second: 22,920.59731
Overall Steps per Second: 10,659.79689

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.51008
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.69240

Cumulative Model Updates: 119,642
Cumulative Timesteps: 997,687,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.74315
Value Function Loss: 0.01664

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.48126
Value Function Update Magnitude: 0.76972

Collected Steps per Second: 21,549.62802
Overall Steps per Second: 10,519.42582

Timestep Collection Time: 2.32162
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.75596

Cumulative Model Updates: 119,648
Cumulative Timesteps: 997,737,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 997737126...
Checkpoint 997737126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.73825
Value Function Loss: 0.01629

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.48049
Value Function Update Magnitude: 0.75255

Collected Steps per Second: 22,177.76384
Overall Steps per Second: 10,717.42219

Timestep Collection Time: 2.25559
Timestep Consumption Time: 2.41195
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66754

Cumulative Model Updates: 119,654
Cumulative Timesteps: 997,787,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.74237
Value Function Loss: 0.01531

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.41569
Value Function Update Magnitude: 0.67594

Collected Steps per Second: 22,359.67254
Overall Steps per Second: 10,739.32691

Timestep Collection Time: 2.23769
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.65895

Cumulative Model Updates: 119,660
Cumulative Timesteps: 997,837,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 997837184...
Checkpoint 997837184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.73262
Value Function Loss: 0.01624

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.43209
Value Function Update Magnitude: 0.68094

Collected Steps per Second: 22,493.56387
Overall Steps per Second: 10,654.96326

Timestep Collection Time: 2.22366
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.69434

Cumulative Model Updates: 119,666
Cumulative Timesteps: 997,887,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.71825
Value Function Loss: 0.02225

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.46689
Value Function Update Magnitude: 0.68088

Collected Steps per Second: 22,253.88497
Overall Steps per Second: 10,584.32333

Timestep Collection Time: 2.24779
Timestep Consumption Time: 2.47826
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.72605

Cumulative Model Updates: 119,672
Cumulative Timesteps: 997,937,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 997937224...
Checkpoint 997937224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,244.88902
Policy Entropy: 3.71599
Value Function Loss: 0.02356

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.51422
Value Function Update Magnitude: 0.56095

Collected Steps per Second: 22,645.39223
Overall Steps per Second: 10,609.44653

Timestep Collection Time: 2.21043
Timestep Consumption Time: 2.50763
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.71806

Cumulative Model Updates: 119,678
Cumulative Timesteps: 997,987,280

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,568.37918
Policy Entropy: 3.68079
Value Function Loss: 0.02956

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.49319

Collected Steps per Second: 22,472.17154
Overall Steps per Second: 10,572.56360

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73206

Cumulative Model Updates: 119,684
Cumulative Timesteps: 998,037,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 998037310...
Checkpoint 998037310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,553.89365
Policy Entropy: 3.69215
Value Function Loss: 0.02670

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.50048

Collected Steps per Second: 22,725.15944
Overall Steps per Second: 10,657.01312

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.69437

Cumulative Model Updates: 119,690
Cumulative Timesteps: 998,087,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287,905.03399
Policy Entropy: 3.68500
Value Function Loss: 0.02953

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.47757

Collected Steps per Second: 22,441.11999
Overall Steps per Second: 10,325.40916

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.61489
PPO Batch Consumption Time: 0.30745
Total Iteration Time: 4.84339

Cumulative Model Updates: 119,696
Cumulative Timesteps: 998,137,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 998137348...
Checkpoint 998137348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,932.66335
Policy Entropy: 3.73007
Value Function Loss: 0.02377

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.47253

Collected Steps per Second: 22,359.29987
Overall Steps per Second: 10,630.16683

Timestep Collection Time: 2.23755
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.70642

Cumulative Model Updates: 119,702
Cumulative Timesteps: 998,187,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,826.89432
Policy Entropy: 3.73817
Value Function Loss: 0.02234

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.54918
Value Function Update Magnitude: 0.60390

Collected Steps per Second: 23,244.87007
Overall Steps per Second: 10,928.88317

Timestep Collection Time: 2.15136
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.57576

Cumulative Model Updates: 119,708
Cumulative Timesteps: 998,237,386

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 998237386...
Checkpoint 998237386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,826.89432
Policy Entropy: 3.74271
Value Function Loss: 0.01895

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.49968
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 23,019.30859
Overall Steps per Second: 10,715.58867

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.66685

Cumulative Model Updates: 119,714
Cumulative Timesteps: 998,287,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,826.89432
Policy Entropy: 3.71542
Value Function Loss: 0.01934

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.51800
Value Function Update Magnitude: 0.64121

Collected Steps per Second: 22,940.76199
Overall Steps per Second: 10,797.93002

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.63107

Cumulative Model Updates: 119,720
Cumulative Timesteps: 998,337,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 998337400...
Checkpoint 998337400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,752.09959
Policy Entropy: 3.69918
Value Function Loss: 0.02258

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.52020
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 22,978.55300
Overall Steps per Second: 10,710.56417

Timestep Collection Time: 2.17603
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.66847

Cumulative Model Updates: 119,726
Cumulative Timesteps: 998,387,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,752.09959
Policy Entropy: 3.70585
Value Function Loss: 0.02093

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.71806

Collected Steps per Second: 22,779.81720
Overall Steps per Second: 10,812.06316

Timestep Collection Time: 2.19572
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.62613

Cumulative Model Updates: 119,732
Cumulative Timesteps: 998,437,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 998437420...
Checkpoint 998437420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511,752.09959
Policy Entropy: 3.70043
Value Function Loss: 0.02064

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.50140
Value Function Update Magnitude: 0.64776

Collected Steps per Second: 22,728.38485
Overall Steps per Second: 10,647.83081

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69805

Cumulative Model Updates: 119,738
Cumulative Timesteps: 998,487,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 511,752.09959
Policy Entropy: 3.72049
Value Function Loss: 0.01912

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.49826
Value Function Update Magnitude: 0.59753

Collected Steps per Second: 22,538.50880
Overall Steps per Second: 10,677.16803

Timestep Collection Time: 2.21967
Timestep Consumption Time: 2.46584
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.68551

Cumulative Model Updates: 119,744
Cumulative Timesteps: 998,537,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 998537472...
Checkpoint 998537472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,665.11110
Policy Entropy: 3.71925
Value Function Loss: 0.02344

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.50996
Value Function Update Magnitude: 0.63642

Collected Steps per Second: 22,718.69193
Overall Steps per Second: 10,815.88080

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62542

Cumulative Model Updates: 119,750
Cumulative Timesteps: 998,587,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,245.16470
Policy Entropy: 3.76401
Value Function Loss: 0.02403

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.57261
Value Function Update Magnitude: 0.53232

Collected Steps per Second: 22,808.39770
Overall Steps per Second: 10,703.10359

Timestep Collection Time: 2.19375
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.67491

Cumulative Model Updates: 119,756
Cumulative Timesteps: 998,637,536

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 998637536...
Checkpoint 998637536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,134.27493
Policy Entropy: 3.75528
Value Function Loss: 0.02375

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.56953

Collected Steps per Second: 22,358.23934
Overall Steps per Second: 10,942.51917

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.33311
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.56951

Cumulative Model Updates: 119,762
Cumulative Timesteps: 998,687,538

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.29662
Policy Entropy: 3.75608
Value Function Loss: 0.02347

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.53633
Value Function Update Magnitude: 0.52052

Collected Steps per Second: 21,922.55352
Overall Steps per Second: 10,815.15239

Timestep Collection Time: 2.28194
Timestep Consumption Time: 2.34361
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.62555

Cumulative Model Updates: 119,768
Cumulative Timesteps: 998,737,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 998737564...
Checkpoint 998737564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682,922.63817
Policy Entropy: 3.73226
Value Function Loss: 0.02410

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.53966

Collected Steps per Second: 22,355.28150
Overall Steps per Second: 10,720.70624

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.66406

Cumulative Model Updates: 119,774
Cumulative Timesteps: 998,787,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,948.08667
Policy Entropy: 3.72690
Value Function Loss: 0.02440

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.55588
Value Function Update Magnitude: 0.69198

Collected Steps per Second: 21,887.40869
Overall Steps per Second: 10,500.98289

Timestep Collection Time: 2.28497
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.76260

Cumulative Model Updates: 119,780
Cumulative Timesteps: 998,837,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 998837578...
Checkpoint 998837578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,700.69222
Policy Entropy: 3.72441
Value Function Loss: 0.02524

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.65264

Collected Steps per Second: 23,015.55085
Overall Steps per Second: 10,945.93888

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.39556
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.56809

Cumulative Model Updates: 119,786
Cumulative Timesteps: 998,887,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,700.69222
Policy Entropy: 3.70550
Value Function Loss: 0.02632

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.49960

Collected Steps per Second: 22,686.95415
Overall Steps per Second: 10,733.33503

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.65913

Cumulative Model Updates: 119,792
Cumulative Timesteps: 998,937,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 998937588...
Checkpoint 998937588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,700.69222
Policy Entropy: 3.70935
Value Function Loss: 0.02155

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.49830
Value Function Update Magnitude: 0.50531

Collected Steps per Second: 22,857.01751
Overall Steps per Second: 10,864.46197

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.41542
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.60363

Cumulative Model Updates: 119,798
Cumulative Timesteps: 998,987,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,700.69222
Policy Entropy: 3.70042
Value Function Loss: 0.02102

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.51951
Value Function Update Magnitude: 0.67059

Collected Steps per Second: 22,820.19509
Overall Steps per Second: 10,683.75270

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.68206

Cumulative Model Updates: 119,804
Cumulative Timesteps: 999,037,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 999037626...
Checkpoint 999037626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 367,700.69222
Policy Entropy: 3.71669
Value Function Loss: 0.02218

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.59140

Collected Steps per Second: 22,872.26885
Overall Steps per Second: 10,843.27452

Timestep Collection Time: 2.18719
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.61355

Cumulative Model Updates: 119,810
Cumulative Timesteps: 999,087,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,579.34942
Policy Entropy: 3.69286
Value Function Loss: 0.02840

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.52109

Collected Steps per Second: 22,422.07326
Overall Steps per Second: 10,530.12052

Timestep Collection Time: 2.23155
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.75170

Cumulative Model Updates: 119,816
Cumulative Timesteps: 999,137,688

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 999137688...
Checkpoint 999137688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 448,504.32829
Policy Entropy: 3.69991
Value Function Loss: 0.02729

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.47905

Collected Steps per Second: 22,658.81825
Overall Steps per Second: 10,650.85200

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.48931
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.69728

Cumulative Model Updates: 119,822
Cumulative Timesteps: 999,187,718

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,504.32829
Policy Entropy: 3.70338
Value Function Loss: 0.02587

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.42748

Collected Steps per Second: 22,872.07584
Overall Steps per Second: 10,838.23171

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61459

Cumulative Model Updates: 119,828
Cumulative Timesteps: 999,237,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 999237732...
Checkpoint 999237732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796,751.46953
Policy Entropy: 3.71960
Value Function Loss: 0.02376

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.37611

Collected Steps per Second: 22,812.16553
Overall Steps per Second: 10,637.75947

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.50973
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.70268

Cumulative Model Updates: 119,834
Cumulative Timesteps: 999,287,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796,751.46953
Policy Entropy: 3.70046
Value Function Loss: 0.02524

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.52424
Value Function Update Magnitude: 0.41528

Collected Steps per Second: 21,737.75540
Overall Steps per Second: 10,581.29917

Timestep Collection Time: 2.30033
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.72570

Cumulative Model Updates: 119,840
Cumulative Timesteps: 999,337,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 999337762...
Checkpoint 999337762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796,751.46953
Policy Entropy: 3.70565
Value Function Loss: 0.02290

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.50719
Value Function Update Magnitude: 0.44457

Collected Steps per Second: 22,115.62656
Overall Steps per Second: 10,728.37792

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.40017
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.66147

Cumulative Model Updates: 119,846
Cumulative Timesteps: 999,387,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689,662.88389
Policy Entropy: 3.71265
Value Function Loss: 0.02116

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14749
Policy Update Magnitude: 0.47607
Value Function Update Magnitude: 0.40593

Collected Steps per Second: 22,463.22814
Overall Steps per Second: 10,699.20686

Timestep Collection Time: 2.22675
Timestep Consumption Time: 2.44836
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.67511

Cumulative Model Updates: 119,852
Cumulative Timesteps: 999,437,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999437792...
Checkpoint 999437792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 452,489.43317
Policy Entropy: 3.73999
Value Function Loss: 0.01859

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.46309
Value Function Update Magnitude: 0.41240

Collected Steps per Second: 22,866.35200
Overall Steps per Second: 10,750.08404

Timestep Collection Time: 2.18714
Timestep Consumption Time: 2.46510
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.65224

Cumulative Model Updates: 119,858
Cumulative Timesteps: 999,487,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,282.07628
Policy Entropy: 3.73599
Value Function Loss: 0.02325

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.46312
Value Function Update Magnitude: 0.49133

Collected Steps per Second: 22,943.90231
Overall Steps per Second: 10,808.92353

Timestep Collection Time: 2.17993
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.62729

Cumulative Model Updates: 119,864
Cumulative Timesteps: 999,537,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 999537820...
Checkpoint 999537820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,967.60016
Policy Entropy: 3.73760
Value Function Loss: 0.02391

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.50125
Value Function Update Magnitude: 0.44450

Collected Steps per Second: 22,768.34854
Overall Steps per Second: 10,626.95620

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.50939
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70577

Cumulative Model Updates: 119,870
Cumulative Timesteps: 999,587,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,111.60942
Policy Entropy: 3.72842
Value Function Loss: 0.02321

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.51665
Value Function Update Magnitude: 0.43632

Collected Steps per Second: 22,916.70217
Overall Steps per Second: 10,844.14594

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.61281

Cumulative Model Updates: 119,876
Cumulative Timesteps: 999,637,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 999637850...
Checkpoint 999637850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,111.60942
Policy Entropy: 3.72807
Value Function Loss: 0.01943

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.50949
Value Function Update Magnitude: 0.46020

Collected Steps per Second: 22,937.80836
Overall Steps per Second: 10,660.44445

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.51183
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.69286

Cumulative Model Updates: 119,882
Cumulative Timesteps: 999,687,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,111.60942
Policy Entropy: 3.71884
Value Function Loss: 0.01701

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.46673
Value Function Update Magnitude: 0.46703

Collected Steps per Second: 22,700.94281
Overall Steps per Second: 10,667.40661

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.68792

Cumulative Model Updates: 119,888
Cumulative Timesteps: 999,737,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 999737886...
Checkpoint 999737886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,111.60942
Policy Entropy: 3.71361
Value Function Loss: 0.01752

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.45021
Value Function Update Magnitude: 0.55556

Collected Steps per Second: 22,825.94697
Overall Steps per Second: 10,867.71034

Timestep Collection Time: 2.19128
Timestep Consumption Time: 2.41116
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.60244

Cumulative Model Updates: 119,894
Cumulative Timesteps: 999,787,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,621.00971
Policy Entropy: 3.72310
Value Function Loss: 0.01859

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.67390

Collected Steps per Second: 22,973.14311
Overall Steps per Second: 10,871.86740

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.60197

Cumulative Model Updates: 119,900
Cumulative Timesteps: 999,837,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 999837936...
Checkpoint 999837936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,976.45463
Policy Entropy: 3.73065
Value Function Loss: 0.02053

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.60282
Value Function Update Magnitude: 0.74393

Collected Steps per Second: 22,253.98368
Overall Steps per Second: 10,757.49292

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.40161
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.64885

Cumulative Model Updates: 119,906
Cumulative Timesteps: 999,887,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245,154.86172
Policy Entropy: 3.74348
Value Function Loss: 0.02156

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.56875
Value Function Update Magnitude: 0.75420

Collected Steps per Second: 21,937.19225
Overall Steps per Second: 10,807.10419

Timestep Collection Time: 2.27969
Timestep Consumption Time: 2.34782
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.62751

Cumulative Model Updates: 119,912
Cumulative Timesteps: 999,937,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 999937956...
Checkpoint 999937956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,574.34937
Policy Entropy: 3.74229
Value Function Loss: 0.02176

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.53130
Value Function Update Magnitude: 0.71109

Collected Steps per Second: 22,299.85426
Overall Steps per Second: 10,775.47021

Timestep Collection Time: 2.24297
Timestep Consumption Time: 2.39886
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.64184

Cumulative Model Updates: 119,918
Cumulative Timesteps: 999,987,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,574.34937
Policy Entropy: 3.72372
Value Function Loss: 0.02021

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.50230
Value Function Update Magnitude: 0.59711

Collected Steps per Second: 22,913.05581
Overall Steps per Second: 10,882.67903

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.41239
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.59464

Cumulative Model Updates: 119,924
Cumulative Timesteps: 1,000,037,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1000037976...
Checkpoint 1000037976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,574.34937
Policy Entropy: 3.72701
Value Function Loss: 0.01762

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.45108
Value Function Update Magnitude: 0.46069

Collected Steps per Second: 22,963.37650
Overall Steps per Second: 10,806.51522

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.45034
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.62850

Cumulative Model Updates: 119,930
Cumulative Timesteps: 1,000,087,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386,758.39931
Policy Entropy: 3.72718
Value Function Loss: 0.01922

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.45005
Value Function Update Magnitude: 0.40487

Collected Steps per Second: 22,794.93643
Overall Steps per Second: 10,739.00156

Timestep Collection Time: 2.19461
Timestep Consumption Time: 2.46374
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.65835

Cumulative Model Updates: 119,936
Cumulative Timesteps: 1,000,138,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1000138020...
Checkpoint 1000138020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,291.43257
Policy Entropy: 3.73045
Value Function Loss: 0.02195

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.47387
Value Function Update Magnitude: 0.45045

Collected Steps per Second: 22,677.30254
Overall Steps per Second: 10,603.28009

Timestep Collection Time: 2.20591
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.71779

Cumulative Model Updates: 119,942
Cumulative Timesteps: 1,000,188,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313,291.43257
Policy Entropy: 3.72425
Value Function Loss: 0.02372

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.47857
Value Function Update Magnitude: 0.48456

Collected Steps per Second: 23,018.63276
Overall Steps per Second: 10,867.64477

Timestep Collection Time: 2.17302
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60265

Cumulative Model Updates: 119,948
Cumulative Timesteps: 1,000,238,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1000238064...
Checkpoint 1000238064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,291.43257
Policy Entropy: 3.73085
Value Function Loss: 0.02035

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.47232
Value Function Update Magnitude: 0.47591

Collected Steps per Second: 23,026.88611
Overall Steps per Second: 10,713.70248

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.67103

Cumulative Model Updates: 119,954
Cumulative Timesteps: 1,000,288,108

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313,291.43257
Policy Entropy: 3.71699
Value Function Loss: 0.01956

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.45529
Value Function Update Magnitude: 0.52821

Collected Steps per Second: 22,877.13841
Overall Steps per Second: 10,835.33467

Timestep Collection Time: 2.18620
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61582

Cumulative Model Updates: 119,960
Cumulative Timesteps: 1,000,338,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000338122...
Checkpoint 1000338122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,995.24989
Policy Entropy: 3.73698
Value Function Loss: 0.01893

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.46768
Value Function Update Magnitude: 0.52479

Collected Steps per Second: 22,848.80330
Overall Steps per Second: 10,695.71936

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.67645

Cumulative Model Updates: 119,966
Cumulative Timesteps: 1,000,388,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,080.09469
Policy Entropy: 3.72559
Value Function Loss: 0.02088

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.46005
Value Function Update Magnitude: 0.52009

Collected Steps per Second: 22,982.76614
Overall Steps per Second: 10,829.11754

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.44310
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61995

Cumulative Model Updates: 119,972
Cumulative Timesteps: 1,000,438,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000438170...
Checkpoint 1000438170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,080.09469
Policy Entropy: 3.74287
Value Function Loss: 0.01996

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.47148
Value Function Update Magnitude: 0.52736

Collected Steps per Second: 22,539.22158
Overall Steps per Second: 10,702.98904

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.67309

Cumulative Model Updates: 119,978
Cumulative Timesteps: 1,000,488,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,080.09469
Policy Entropy: 3.72504
Value Function Loss: 0.01935

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.45791
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,827.53451
Overall Steps per Second: 10,834.21999

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61519

Cumulative Model Updates: 119,984
Cumulative Timesteps: 1,000,538,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1000538188...
Checkpoint 1000538188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,080.09469
Policy Entropy: 3.73319
Value Function Loss: 0.02027

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.48249
Value Function Update Magnitude: 0.71431

Collected Steps per Second: 22,885.86449
Overall Steps per Second: 10,704.89485

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.67076

Cumulative Model Updates: 119,990
Cumulative Timesteps: 1,000,588,188

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,351.95007
Policy Entropy: 3.72997
Value Function Loss: 0.02411

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.74872

Collected Steps per Second: 22,842.01907
Overall Steps per Second: 10,845.70050

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.42175
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.61123

Cumulative Model Updates: 119,996
Cumulative Timesteps: 1,000,638,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1000638200...
Checkpoint 1000638200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,351.95007
Policy Entropy: 3.73702
Value Function Loss: 0.02379

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.64316

Collected Steps per Second: 22,240.93706
Overall Steps per Second: 10,692.64944

Timestep Collection Time: 2.25026
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68060

Cumulative Model Updates: 120,002
Cumulative Timesteps: 1,000,688,248

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,351.95007
Policy Entropy: 3.72631
Value Function Loss: 0.02417

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.53156
Value Function Update Magnitude: 0.60668

Collected Steps per Second: 22,032.55593
Overall Steps per Second: 10,819.26944

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.35249
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62231

Cumulative Model Updates: 120,008
Cumulative Timesteps: 1,000,738,258

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1000738258...
Checkpoint 1000738258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333,756.04374
Policy Entropy: 3.72415
Value Function Loss: 0.02224

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.51308
Value Function Update Magnitude: 0.53790

Collected Steps per Second: 21,942.30277
Overall Steps per Second: 10,680.32249

Timestep Collection Time: 2.27889
Timestep Consumption Time: 2.40300
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.68188

Cumulative Model Updates: 120,014
Cumulative Timesteps: 1,000,788,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,756.04374
Policy Entropy: 3.71687
Value Function Loss: 0.02287

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.16143
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.55140

Collected Steps per Second: 22,951.19658
Overall Steps per Second: 10,890.41346

Timestep Collection Time: 2.17906
Timestep Consumption Time: 2.41324
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.59230

Cumulative Model Updates: 120,020
Cumulative Timesteps: 1,000,838,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1000838274...
Checkpoint 1000838274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,180.56026
Policy Entropy: 3.71881
Value Function Loss: 0.02354

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.47542
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 22,950.10891
Overall Steps per Second: 10,715.89400

Timestep Collection Time: 2.17960
Timestep Consumption Time: 2.48842
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.66802

Cumulative Model Updates: 120,026
Cumulative Timesteps: 1,000,888,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,134.30202
Policy Entropy: 3.73594
Value Function Loss: 0.02453

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.49116
Value Function Update Magnitude: 0.67374

Collected Steps per Second: 22,771.98994
Overall Steps per Second: 10,840.83125

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.41767
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61441

Cumulative Model Updates: 120,032
Cumulative Timesteps: 1,000,938,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1000938320...
Checkpoint 1000938320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.72657
Value Function Loss: 0.02320

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.52070
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 22,829.32506
Overall Steps per Second: 10,722.64204

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.47445
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.66601

Cumulative Model Updates: 120,038
Cumulative Timesteps: 1,000,988,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.72158
Value Function Loss: 0.02134

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.50690
Value Function Update Magnitude: 0.60448

Collected Steps per Second: 22,863.71349
Overall Steps per Second: 10,833.37090

Timestep Collection Time: 2.18740
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61648

Cumulative Model Updates: 120,044
Cumulative Timesteps: 1,001,038,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1001038364...
Checkpoint 1001038364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.70476
Value Function Loss: 0.02058

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15675
Policy Update Magnitude: 0.52569
Value Function Update Magnitude: 0.58733

Collected Steps per Second: 22,578.02674
Overall Steps per Second: 10,698.33046

Timestep Collection Time: 2.21507
Timestep Consumption Time: 2.45967
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.67475

Cumulative Model Updates: 120,050
Cumulative Timesteps: 1,001,088,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.70609
Value Function Loss: 0.02160

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.51948
Value Function Update Magnitude: 0.51068

Collected Steps per Second: 22,735.62753
Overall Steps per Second: 10,848.22338

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.41121
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.61163

Cumulative Model Updates: 120,056
Cumulative Timesteps: 1,001,138,404

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1001138404...
Checkpoint 1001138404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.72744
Value Function Loss: 0.01968

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.53641

Collected Steps per Second: 22,863.81850
Overall Steps per Second: 10,696.04656

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.67687

Cumulative Model Updates: 120,062
Cumulative Timesteps: 1,001,188,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,631.72522
Policy Entropy: 3.71370
Value Function Loss: 0.02246

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14534
Policy Update Magnitude: 0.53494
Value Function Update Magnitude: 0.55235

Collected Steps per Second: 22,253.79569
Overall Steps per Second: 10,879.98988

Timestep Collection Time: 2.24753
Timestep Consumption Time: 2.34954
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.59706

Cumulative Model Updates: 120,068
Cumulative Timesteps: 1,001,238,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1001238444...
Checkpoint 1001238444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,282.40920
Policy Entropy: 3.73200
Value Function Loss: 0.02255

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 22,294.49510
Overall Steps per Second: 10,739.57008

Timestep Collection Time: 2.24387
Timestep Consumption Time: 2.41423
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.65810

Cumulative Model Updates: 120,074
Cumulative Timesteps: 1,001,288,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,605.89429
Policy Entropy: 3.70903
Value Function Loss: 0.02708

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.54811
Value Function Update Magnitude: 0.62260

Collected Steps per Second: 22,025.25704
Overall Steps per Second: 10,571.69952

Timestep Collection Time: 2.27076
Timestep Consumption Time: 2.46018
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.73093

Cumulative Model Updates: 120,080
Cumulative Timesteps: 1,001,338,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1001338484...
Checkpoint 1001338484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 421,583.06672
Policy Entropy: 3.71519
Value Function Loss: 0.02409

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 23,089.47407
Overall Steps per Second: 10,971.17648

Timestep Collection Time: 2.16722
Timestep Consumption Time: 2.39382
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.56104

Cumulative Model Updates: 120,086
Cumulative Timesteps: 1,001,388,524

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,138.55086
Policy Entropy: 3.70843
Value Function Loss: 0.02569

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.53017
Value Function Update Magnitude: 0.70485

Collected Steps per Second: 22,954.14073
Overall Steps per Second: 10,827.99878

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.61932

Cumulative Model Updates: 120,092
Cumulative Timesteps: 1,001,438,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1001438542...
Checkpoint 1001438542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,835.36513
Policy Entropy: 3.74542
Value Function Loss: 0.02243

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.50811
Value Function Update Magnitude: 0.66463

Collected Steps per Second: 23,067.23172
Overall Steps per Second: 10,752.86082

Timestep Collection Time: 2.16870
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.65234

Cumulative Model Updates: 120,098
Cumulative Timesteps: 1,001,488,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,296.62730
Policy Entropy: 3.74639
Value Function Loss: 0.02122

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.50612
Value Function Update Magnitude: 0.68865

Collected Steps per Second: 23,011.06823
Overall Steps per Second: 10,806.91588

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.62667

Cumulative Model Updates: 120,104
Cumulative Timesteps: 1,001,538,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1001538568...
Checkpoint 1001538568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255,292.28760
Policy Entropy: 3.74250
Value Function Loss: 0.01964

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.49652
Value Function Update Magnitude: 0.69778

Collected Steps per Second: 22,844.01186
Overall Steps per Second: 10,658.28670

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.69119

Cumulative Model Updates: 120,110
Cumulative Timesteps: 1,001,588,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,292.28760
Policy Entropy: 3.71669
Value Function Loss: 0.01753

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.47378
Value Function Update Magnitude: 0.66066

Collected Steps per Second: 22,909.61974
Overall Steps per Second: 10,794.15543

Timestep Collection Time: 2.18293
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.63306

Cumulative Model Updates: 120,116
Cumulative Timesteps: 1,001,638,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1001638578...
Checkpoint 1001638578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,723.25806
Policy Entropy: 3.71545
Value Function Loss: 0.01871

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.48500
Value Function Update Magnitude: 0.54511

Collected Steps per Second: 22,692.47680
Overall Steps per Second: 10,724.42174

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.66487

Cumulative Model Updates: 120,122
Cumulative Timesteps: 1,001,688,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,840.94690
Policy Entropy: 3.73052
Value Function Loss: 0.01893

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.52645
Value Function Update Magnitude: 0.54222

Collected Steps per Second: 22,492.57737
Overall Steps per Second: 10,621.30063

Timestep Collection Time: 2.22313
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.70790

Cumulative Model Updates: 120,128
Cumulative Timesteps: 1,001,738,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1001738610...
Checkpoint 1001738610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,858.87302
Policy Entropy: 3.73993
Value Function Loss: 0.02231

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.67664
Value Function Update Magnitude: 0.52720

Collected Steps per Second: 22,703.55337
Overall Steps per Second: 10,707.84009

Timestep Collection Time: 2.20265
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67022

Cumulative Model Updates: 120,134
Cumulative Timesteps: 1,001,788,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,045.74642
Policy Entropy: 3.75228
Value Function Loss: 0.02226

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.72418
Value Function Update Magnitude: 0.50223

Collected Steps per Second: 22,873.52473
Overall Steps per Second: 10,665.58882

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.50304
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.68985

Cumulative Model Updates: 120,140
Cumulative Timesteps: 1,001,838,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1001838638...
Checkpoint 1001838638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,045.74642
Policy Entropy: 3.74740
Value Function Loss: 0.02034

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.61052
Value Function Update Magnitude: 0.53250

Collected Steps per Second: 22,257.20792
Overall Steps per Second: 10,697.57366

Timestep Collection Time: 2.24682
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.67470

Cumulative Model Updates: 120,146
Cumulative Timesteps: 1,001,888,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,340.72688
Policy Entropy: 3.74434
Value Function Loss: 0.02207

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.17323
Policy Update Magnitude: 0.62833
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 22,240.51854
Overall Steps per Second: 10,924.61225

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.32895
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.57737

Cumulative Model Updates: 120,152
Cumulative Timesteps: 1,001,938,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001938652...
Checkpoint 1001938652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,541.82270
Policy Entropy: 3.71935
Value Function Loss: 0.02569

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.18969
Policy Update Magnitude: 0.61887
Value Function Update Magnitude: 0.58263

Collected Steps per Second: 22,112.72435
Overall Steps per Second: 10,724.05429

Timestep Collection Time: 2.26340
Timestep Consumption Time: 2.40368
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.66708

Cumulative Model Updates: 120,158
Cumulative Timesteps: 1,001,988,702

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,870.53904
Policy Entropy: 3.72988
Value Function Loss: 0.02865

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.66971
Value Function Update Magnitude: 0.49142

Collected Steps per Second: 22,239.89863
Overall Steps per Second: 10,733.76423

Timestep Collection Time: 2.24857
Timestep Consumption Time: 2.41037
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.65894

Cumulative Model Updates: 120,164
Cumulative Timesteps: 1,002,038,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1002038710...
Checkpoint 1002038710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,870.53904
Policy Entropy: 3.74196
Value Function Loss: 0.02119

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.63805
Value Function Update Magnitude: 0.41613

Collected Steps per Second: 22,561.34186
Overall Steps per Second: 10,676.65738

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68574

Cumulative Model Updates: 120,170
Cumulative Timesteps: 1,002,088,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273,294.63401
Policy Entropy: 3.75013
Value Function Loss: 0.03167

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.19473
Policy Update Magnitude: 0.63958
Value Function Update Magnitude: 0.57254

Collected Steps per Second: 22,650.38380
Overall Steps per Second: 10,855.23671

Timestep Collection Time: 2.20844
Timestep Consumption Time: 2.39966
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.60810

Cumulative Model Updates: 120,176
Cumulative Timesteps: 1,002,138,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1002138760...
Checkpoint 1002138760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,056.38143
Policy Entropy: 3.71977
Value Function Loss: 0.04292

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.17376
Policy Update Magnitude: 0.81403
Value Function Update Magnitude: 0.70114

Collected Steps per Second: 22,172.57648
Overall Steps per Second: 10,720.09445

Timestep Collection Time: 2.25585
Timestep Consumption Time: 2.40997
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.66582

Cumulative Model Updates: 120,182
Cumulative Timesteps: 1,002,188,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310,534.47424
Policy Entropy: 3.73310
Value Function Loss: 0.05095

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.15916
Policy Update Magnitude: 0.98294
Value Function Update Magnitude: 0.67208

Collected Steps per Second: 22,414.87544
Overall Steps per Second: 10,625.77088

Timestep Collection Time: 2.23129
Timestep Consumption Time: 2.47557
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.70686

Cumulative Model Updates: 120,188
Cumulative Timesteps: 1,002,238,792

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1002238792...
Checkpoint 1002238792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,502.34131
Policy Entropy: 3.73182
Value Function Loss: 0.04899

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.17477
Policy Update Magnitude: 0.97226
Value Function Update Magnitude: 0.78478

Collected Steps per Second: 22,635.16745
Overall Steps per Second: 10,809.79849

Timestep Collection Time: 2.21037
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62839

Cumulative Model Updates: 120,194
Cumulative Timesteps: 1,002,288,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,605.96477
Policy Entropy: 3.74452
Value Function Loss: 0.04888

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.19293
Policy Update Magnitude: 0.88368
Value Function Update Magnitude: 0.71878

Collected Steps per Second: 22,727.81404
Overall Steps per Second: 10,664.28456

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.48870
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68873

Cumulative Model Updates: 120,200
Cumulative Timesteps: 1,002,338,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1002338826...
Checkpoint 1002338826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,470.19460
Policy Entropy: 3.75338
Value Function Loss: 0.04464

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16362
Policy Update Magnitude: 0.83006
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,793.39664
Overall Steps per Second: 10,734.71056

Timestep Collection Time: 2.19485
Timestep Consumption Time: 2.46555
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66040

Cumulative Model Updates: 120,206
Cumulative Timesteps: 1,002,388,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,338.92690
Policy Entropy: 3.74701
Value Function Loss: 0.04410

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14577
Policy Update Magnitude: 0.77746
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 23,156.65905
Overall Steps per Second: 10,722.80574

Timestep Collection Time: 2.15981
Timestep Consumption Time: 2.50445
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.66426

Cumulative Model Updates: 120,212
Cumulative Timesteps: 1,002,438,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1002438868...
Checkpoint 1002438868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,641.34090
Policy Entropy: 3.76905
Value Function Loss: 0.03897

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.75579
Value Function Update Magnitude: 0.74353

Collected Steps per Second: 22,878.83846
Overall Steps per Second: 10,686.70134

Timestep Collection Time: 2.18578
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67946

Cumulative Model Updates: 120,218
Cumulative Timesteps: 1,002,488,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,913.95575
Policy Entropy: 3.74261
Value Function Loss: 0.04382

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14721
Policy Update Magnitude: 0.71271
Value Function Update Magnitude: 0.68223

Collected Steps per Second: 22,936.70255
Overall Steps per Second: 10,873.71165

Timestep Collection Time: 2.17991
Timestep Consumption Time: 2.41833
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.59825

Cumulative Model Updates: 120,224
Cumulative Timesteps: 1,002,538,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1002538876...
Checkpoint 1002538876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,984.49082
Policy Entropy: 3.76121
Value Function Loss: 0.03638

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.67661
Value Function Update Magnitude: 0.58190

Collected Steps per Second: 22,571.73572
Overall Steps per Second: 10,609.14413

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.49885
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71499

Cumulative Model Updates: 120,230
Cumulative Timesteps: 1,002,588,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,468.64192
Policy Entropy: 3.73711
Value Function Loss: 0.03662

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.64669
Value Function Update Magnitude: 0.50235

Collected Steps per Second: 22,716.55910
Overall Steps per Second: 10,806.98041

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.62812

Cumulative Model Updates: 120,236
Cumulative Timesteps: 1,002,638,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1002638914...
Checkpoint 1002638914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,585.84476
Policy Entropy: 3.74368
Value Function Loss: 0.03045

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.66571
Value Function Update Magnitude: 0.60377

Collected Steps per Second: 22,757.58626
Overall Steps per Second: 10,690.94832

Timestep Collection Time: 2.19839
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.67966

Cumulative Model Updates: 120,242
Cumulative Timesteps: 1,002,688,944

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,471.23270
Policy Entropy: 3.72619
Value Function Loss: 0.03070

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.62738
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 23,077.61472
Overall Steps per Second: 10,860.60244

Timestep Collection Time: 2.16764
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60601

Cumulative Model Updates: 120,248
Cumulative Timesteps: 1,002,738,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1002738968...
Checkpoint 1002738968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,270.39453
Policy Entropy: 3.74472
Value Function Loss: 0.02525

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.54774
Value Function Update Magnitude: 0.58620

Collected Steps per Second: 22,716.14008
Overall Steps per Second: 10,701.62159

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.47210
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.67406

Cumulative Model Updates: 120,254
Cumulative Timesteps: 1,002,788,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,270.39453
Policy Entropy: 3.73514
Value Function Loss: 0.02619

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14103
Policy Update Magnitude: 0.49992
Value Function Update Magnitude: 0.53942

Collected Steps per Second: 22,802.62969
Overall Steps per Second: 10,830.13720

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61970

Cumulative Model Updates: 120,260
Cumulative Timesteps: 1,002,839,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1002839020...
Checkpoint 1002839020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,761.87035
Policy Entropy: 3.74695
Value Function Loss: 0.02339

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.49032
Value Function Update Magnitude: 0.47369

Collected Steps per Second: 22,792.76341
Overall Steps per Second: 10,721.17893

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.66479

Cumulative Model Updates: 120,266
Cumulative Timesteps: 1,002,889,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,761.87035
Policy Entropy: 3.72997
Value Function Loss: 0.02245

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.60381

Collected Steps per Second: 23,089.57627
Overall Steps per Second: 10,902.89240

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58667

Cumulative Model Updates: 120,272
Cumulative Timesteps: 1,002,939,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1002939040...
Checkpoint 1002939040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270,450.78419
Policy Entropy: 3.74504
Value Function Loss: 0.02049

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.46182
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 22,630.35561
Overall Steps per Second: 10,643.83838

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.69962

Cumulative Model Updates: 120,278
Cumulative Timesteps: 1,002,989,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,307.10629
Policy Entropy: 3.72560
Value Function Loss: 0.02166

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.46925
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 22,051.23470
Overall Steps per Second: 10,823.69983

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.35336
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.62208

Cumulative Model Updates: 120,284
Cumulative Timesteps: 1,003,039,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1003039090...
Checkpoint 1003039090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,651.25900
Policy Entropy: 3.73734
Value Function Loss: 0.02151

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.49724
Value Function Update Magnitude: 0.65148

Collected Steps per Second: 22,120.06605
Overall Steps per Second: 10,712.84304

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.40825
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.66991

Cumulative Model Updates: 120,290
Cumulative Timesteps: 1,003,089,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,164.29716
Policy Entropy: 3.72225
Value Function Loss: 0.02072

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.45676
Value Function Update Magnitude: 0.57168

Collected Steps per Second: 22,485.29107
Overall Steps per Second: 10,955.59116

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.34039
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.56424

Cumulative Model Updates: 120,296
Cumulative Timesteps: 1,003,139,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1003139122...
Checkpoint 1003139122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,164.29716
Policy Entropy: 3.74298
Value Function Loss: 0.01740

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.40514
Value Function Update Magnitude: 0.49866

Collected Steps per Second: 22,007.74632
Overall Steps per Second: 10,632.42407

Timestep Collection Time: 2.27238
Timestep Consumption Time: 2.43116
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.70354

Cumulative Model Updates: 120,302
Cumulative Timesteps: 1,003,189,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,164.29716
Policy Entropy: 3.72629
Value Function Loss: 0.01650

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.38780
Value Function Update Magnitude: 0.52598

Collected Steps per Second: 23,048.83583
Overall Steps per Second: 10,873.28053

Timestep Collection Time: 2.17043
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.60082

Cumulative Model Updates: 120,308
Cumulative Timesteps: 1,003,239,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1003239158...
Checkpoint 1003239158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,164.29716
Policy Entropy: 3.72391
Value Function Loss: 0.01598

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13930
Policy Update Magnitude: 0.39953
Value Function Update Magnitude: 0.56482

Collected Steps per Second: 22,865.16494
Overall Steps per Second: 10,643.96023

Timestep Collection Time: 2.18682
Timestep Consumption Time: 2.51087
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.69769

Cumulative Model Updates: 120,314
Cumulative Timesteps: 1,003,289,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,164.29716
Policy Entropy: 3.71859
Value Function Loss: 0.01611

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.42309
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 22,875.45524
Overall Steps per Second: 10,831.16699

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61723

Cumulative Model Updates: 120,320
Cumulative Timesteps: 1,003,339,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1003339170...
Checkpoint 1003339170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,621.38432
Policy Entropy: 3.73296
Value Function Loss: 0.02040

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.44182
Value Function Update Magnitude: 0.58253

Collected Steps per Second: 22,540.79100
Overall Steps per Second: 10,691.71930

Timestep Collection Time: 2.21829
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.67670

Cumulative Model Updates: 120,326
Cumulative Timesteps: 1,003,389,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,533.35781
Policy Entropy: 3.74208
Value Function Loss: 0.02377

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.51324
Value Function Update Magnitude: 0.53205

Collected Steps per Second: 22,982.88870
Overall Steps per Second: 10,873.07874

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59962

Cumulative Model Updates: 120,332
Cumulative Timesteps: 1,003,439,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1003439184...
Checkpoint 1003439184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,153.82182
Policy Entropy: 3.75120
Value Function Loss: 0.02558

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.60687

Collected Steps per Second: 22,720.86980
Overall Steps per Second: 10,711.43145

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.46857
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.67034

Cumulative Model Updates: 120,338
Cumulative Timesteps: 1,003,489,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,807.44078
Policy Entropy: 3.76447
Value Function Loss: 0.02489

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.51679
Value Function Update Magnitude: 0.62343

Collected Steps per Second: 23,175.54766
Overall Steps per Second: 10,949.57183

Timestep Collection Time: 2.15822
Timestep Consumption Time: 2.40981
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.56803

Cumulative Model Updates: 120,344
Cumulative Timesteps: 1,003,539,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1003539228...
Checkpoint 1003539228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,384.03521
Policy Entropy: 3.75159
Value Function Loss: 0.02310

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.48326
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 22,114.68796
Overall Steps per Second: 10,672.37408

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.68556

Cumulative Model Updates: 120,350
Cumulative Timesteps: 1,003,589,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,953.99038
Policy Entropy: 3.74807
Value Function Loss: 0.02135

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.46628
Value Function Update Magnitude: 0.59286

Collected Steps per Second: 22,275.57300
Overall Steps per Second: 10,901.09746

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.34311
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.58871

Cumulative Model Updates: 120,356
Cumulative Timesteps: 1,003,639,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1003639256...
Checkpoint 1003639256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,009.17258
Policy Entropy: 3.74171
Value Function Loss: 0.02128

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.52226

Collected Steps per Second: 22,031.58677
Overall Steps per Second: 10,658.95931

Timestep Collection Time: 2.27056
Timestep Consumption Time: 2.42258
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.69314

Cumulative Model Updates: 120,362
Cumulative Timesteps: 1,003,689,280

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668,009.17258
Policy Entropy: 3.74667
Value Function Loss: 0.02197

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.47508
Value Function Update Magnitude: 0.47874

Collected Steps per Second: 22,339.13420
Overall Steps per Second: 10,776.91687

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.40161
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.64010

Cumulative Model Updates: 120,368
Cumulative Timesteps: 1,003,739,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1003739286...
Checkpoint 1003739286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668,009.17258
Policy Entropy: 3.73579
Value Function Loss: 0.02171

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.45333
Value Function Update Magnitude: 0.39442

Collected Steps per Second: 22,420.52272
Overall Steps per Second: 10,706.23641

Timestep Collection Time: 2.23108
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.67223

Cumulative Model Updates: 120,374
Cumulative Timesteps: 1,003,789,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657,660.78312
Policy Entropy: 3.72505
Value Function Loss: 0.02557

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.42625
Value Function Update Magnitude: 0.35920

Collected Steps per Second: 23,003.30406
Overall Steps per Second: 10,935.48373

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.57520

Cumulative Model Updates: 120,380
Cumulative Timesteps: 1,003,839,340

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1003839340...
Checkpoint 1003839340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,639.04439
Policy Entropy: 3.72531
Value Function Loss: 0.02939

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.45310
Value Function Update Magnitude: 0.35621

Collected Steps per Second: 22,779.35560
Overall Steps per Second: 10,643.81162

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.50300
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.69832

Cumulative Model Updates: 120,386
Cumulative Timesteps: 1,003,889,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,783.28868
Policy Entropy: 3.73061
Value Function Loss: 0.02981

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.49458
Value Function Update Magnitude: 0.45357

Collected Steps per Second: 22,867.84468
Overall Steps per Second: 10,821.26788

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.62090

Cumulative Model Updates: 120,392
Cumulative Timesteps: 1,003,939,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1003939352...
Checkpoint 1003939352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,453.55289
Policy Entropy: 3.74650
Value Function Loss: 0.03085

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.61421

Collected Steps per Second: 22,493.00601
Overall Steps per Second: 10,707.50370

Timestep Collection Time: 2.22398
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.67186

Cumulative Model Updates: 120,398
Cumulative Timesteps: 1,003,989,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,811.13354
Policy Entropy: 3.75019
Value Function Loss: 0.03188

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.78446

Collected Steps per Second: 22,646.39290
Overall Steps per Second: 10,798.27916

Timestep Collection Time: 2.20954
Timestep Consumption Time: 2.42435
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.63389

Cumulative Model Updates: 120,404
Cumulative Timesteps: 1,004,039,414

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1004039414...
Checkpoint 1004039414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,527.70849
Policy Entropy: 3.74045
Value Function Loss: 0.02923

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.56583
Value Function Update Magnitude: 0.86024

Collected Steps per Second: 22,511.49467
Overall Steps per Second: 10,761.44589

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64696

Cumulative Model Updates: 120,410
Cumulative Timesteps: 1,004,089,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,975.34961
Policy Entropy: 3.73377
Value Function Loss: 0.02772

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.71890

Collected Steps per Second: 22,630.47871
Overall Steps per Second: 10,797.49075

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63256

Cumulative Model Updates: 120,416
Cumulative Timesteps: 1,004,139,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1004139442...
Checkpoint 1004139442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,601.94722
Policy Entropy: 3.72343
Value Function Loss: 0.02779

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.60079

Collected Steps per Second: 22,525.72216
Overall Steps per Second: 10,755.08550

Timestep Collection Time: 2.22013
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.64989

Cumulative Model Updates: 120,422
Cumulative Timesteps: 1,004,189,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,082.54620
Policy Entropy: 3.71837
Value Function Loss: 0.02823

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.58055
Value Function Update Magnitude: 0.88016

Collected Steps per Second: 22,934.89770
Overall Steps per Second: 10,818.26187

Timestep Collection Time: 2.18148
Timestep Consumption Time: 2.44329
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62477

Cumulative Model Updates: 120,428
Cumulative Timesteps: 1,004,239,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1004239484...
Checkpoint 1004239484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,830.79610
Policy Entropy: 3.72727
Value Function Loss: 0.02717

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.57647
Value Function Update Magnitude: 0.94655

Collected Steps per Second: 22,739.67892
Overall Steps per Second: 10,680.38042

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.68279

Cumulative Model Updates: 120,434
Cumulative Timesteps: 1,004,289,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,612.15384
Policy Entropy: 3.72692
Value Function Loss: 0.02699

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.86589

Collected Steps per Second: 22,800.16776
Overall Steps per Second: 10,848.79963

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.61157

Cumulative Model Updates: 120,440
Cumulative Timesteps: 1,004,339,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1004339528...
Checkpoint 1004339528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,193.24265
Policy Entropy: 3.73046
Value Function Loss: 0.02919

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.60277
Value Function Update Magnitude: 0.76935

Collected Steps per Second: 22,318.24901
Overall Steps per Second: 10,748.51685

Timestep Collection Time: 2.24157
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.65441

Cumulative Model Updates: 120,446
Cumulative Timesteps: 1,004,389,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.71969
Value Function Loss: 0.02911

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.60699
Value Function Update Magnitude: 0.59524

Collected Steps per Second: 22,835.03486
Overall Steps per Second: 10,838.40595

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61507

Cumulative Model Updates: 120,452
Cumulative Timesteps: 1,004,439,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1004439576...
Checkpoint 1004439576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.72314
Value Function Loss: 0.02464

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.54302
Value Function Update Magnitude: 0.56777

Collected Steps per Second: 22,787.72545
Overall Steps per Second: 10,659.19510

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69135

Cumulative Model Updates: 120,458
Cumulative Timesteps: 1,004,489,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.71866
Value Function Loss: 0.02095

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14283
Policy Update Magnitude: 0.49354
Value Function Update Magnitude: 0.57874

Collected Steps per Second: 22,115.75142
Overall Steps per Second: 10,852.11486

Timestep Collection Time: 2.26228
Timestep Consumption Time: 2.34807
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.61035

Cumulative Model Updates: 120,464
Cumulative Timesteps: 1,004,539,614

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1004539614...
Checkpoint 1004539614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.71435
Value Function Loss: 0.02069

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.47377
Value Function Update Magnitude: 0.51751

Collected Steps per Second: 21,606.72996
Overall Steps per Second: 10,757.15486

Timestep Collection Time: 2.31539
Timestep Consumption Time: 2.33528
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.65067

Cumulative Model Updates: 120,470
Cumulative Timesteps: 1,004,589,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.70743
Value Function Loss: 0.02339

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.46388
Value Function Update Magnitude: 0.47256

Collected Steps per Second: 21,992.76353
Overall Steps per Second: 10,509.38826

Timestep Collection Time: 2.27420
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.75917

Cumulative Model Updates: 120,476
Cumulative Timesteps: 1,004,639,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1004639658...
Checkpoint 1004639658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.71280
Value Function Loss: 0.02252

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14345
Policy Update Magnitude: 0.45433
Value Function Update Magnitude: 0.46124

Collected Steps per Second: 22,751.46918
Overall Steps per Second: 10,765.41665

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.44723
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.64525

Cumulative Model Updates: 120,482
Cumulative Timesteps: 1,004,689,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.70292
Value Function Loss: 0.02234

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.42284
Value Function Update Magnitude: 0.40625

Collected Steps per Second: 22,971.42141
Overall Steps per Second: 10,734.84531

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66034

Cumulative Model Updates: 120,488
Cumulative Timesteps: 1,004,739,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1004739694...
Checkpoint 1004739694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,559.44509
Policy Entropy: 3.71506
Value Function Loss: 0.01924

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.38486
Value Function Update Magnitude: 0.36099

Collected Steps per Second: 22,646.68285
Overall Steps per Second: 10,634.60833

Timestep Collection Time: 2.20809
Timestep Consumption Time: 2.49410
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70219

Cumulative Model Updates: 120,494
Cumulative Timesteps: 1,004,789,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,536.56156
Policy Entropy: 3.70979
Value Function Loss: 0.02231

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.38171
Value Function Update Magnitude: 0.38162

Collected Steps per Second: 22,710.02000
Overall Steps per Second: 10,790.96929

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.43193
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.63369

Cumulative Model Updates: 120,500
Cumulative Timesteps: 1,004,839,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1004839702...
Checkpoint 1004839702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,993.21058
Policy Entropy: 3.74275
Value Function Loss: 0.02062

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.44166
Value Function Update Magnitude: 0.70353

Collected Steps per Second: 23,124.32868
Overall Steps per Second: 10,695.39640

Timestep Collection Time: 2.16326
Timestep Consumption Time: 2.51389
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.67715

Cumulative Model Updates: 120,506
Cumulative Timesteps: 1,004,889,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,067.79876
Policy Entropy: 3.72949
Value Function Loss: 0.02220

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.48407
Value Function Update Magnitude: 0.87023

Collected Steps per Second: 23,279.73953
Overall Steps per Second: 10,934.25212

Timestep Collection Time: 2.14813
Timestep Consumption Time: 2.42538
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.57352

Cumulative Model Updates: 120,512
Cumulative Timesteps: 1,004,939,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1004939734...
Checkpoint 1004939734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,161.34161
Policy Entropy: 3.74572
Value Function Loss: 0.02257

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.50165
Value Function Update Magnitude: 0.74055

Collected Steps per Second: 22,851.35523
Overall Steps per Second: 10,676.59894

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.68539

Cumulative Model Updates: 120,518
Cumulative Timesteps: 1,004,989,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,312.41799
Policy Entropy: 3.71225
Value Function Loss: 0.02735

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.49327
Value Function Update Magnitude: 0.63943

Collected Steps per Second: 23,212.01824
Overall Steps per Second: 10,913.86087

Timestep Collection Time: 2.15509
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.58353

Cumulative Model Updates: 120,524
Cumulative Timesteps: 1,005,039,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1005039782...
Checkpoint 1005039782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,920.54092
Policy Entropy: 3.72833
Value Function Loss: 0.02534

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 23,000.73619
Overall Steps per Second: 10,711.67311

Timestep Collection Time: 2.17471
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.66967

Cumulative Model Updates: 120,530
Cumulative Timesteps: 1,005,089,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,600.10617
Policy Entropy: 3.71844
Value Function Loss: 0.02460

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.76708

Collected Steps per Second: 23,072.96861
Overall Steps per Second: 10,926.99393

Timestep Collection Time: 2.16756
Timestep Consumption Time: 2.40936
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.57692

Cumulative Model Updates: 120,536
Cumulative Timesteps: 1,005,139,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1005139814...
Checkpoint 1005139814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,629.60558
Policy Entropy: 3.73494
Value Function Loss: 0.02227

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.50895
Value Function Update Magnitude: 0.80803

Collected Steps per Second: 22,820.85800
Overall Steps per Second: 10,677.55688

Timestep Collection Time: 2.19256
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68609

Cumulative Model Updates: 120,542
Cumulative Timesteps: 1,005,189,850

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,095.76791
Policy Entropy: 3.72408
Value Function Loss: 0.02261

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15454
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.84745

Collected Steps per Second: 23,171.74407
Overall Steps per Second: 10,814.81201

Timestep Collection Time: 2.15953
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.62699

Cumulative Model Updates: 120,548
Cumulative Timesteps: 1,005,239,890

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1005239890...
Checkpoint 1005239890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,067.45210
Policy Entropy: 3.72972
Value Function Loss: 0.02550

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.82956

Collected Steps per Second: 22,323.93094
Overall Steps per Second: 10,632.61804

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.70646

Cumulative Model Updates: 120,554
Cumulative Timesteps: 1,005,289,932

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,229.32610
Policy Entropy: 3.72226
Value Function Loss: 0.02818

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.55348
Value Function Update Magnitude: 0.81578

Collected Steps per Second: 22,687.58445
Overall Steps per Second: 10,633.55391

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.70228

Cumulative Model Updates: 120,560
Cumulative Timesteps: 1,005,339,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1005339934...
Checkpoint 1005339934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.38160
Policy Entropy: 3.73963
Value Function Loss: 0.02885

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.57776
Value Function Update Magnitude: 0.80137

Collected Steps per Second: 22,633.04583
Overall Steps per Second: 10,823.92797

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.62180

Cumulative Model Updates: 120,566
Cumulative Timesteps: 1,005,389,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,849.25828
Policy Entropy: 3.72327
Value Function Loss: 0.03147

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.68801

Collected Steps per Second: 22,816.44255
Overall Steps per Second: 10,677.80128

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.68430

Cumulative Model Updates: 120,572
Cumulative Timesteps: 1,005,439,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1005439978...
Checkpoint 1005439978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,039.19049
Policy Entropy: 3.74431
Value Function Loss: 0.02766

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.58675
Value Function Update Magnitude: 0.62036

Collected Steps per Second: 22,926.21056
Overall Steps per Second: 10,860.31455

Timestep Collection Time: 2.18135
Timestep Consumption Time: 2.42349
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.60484

Cumulative Model Updates: 120,578
Cumulative Timesteps: 1,005,489,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,012.59439
Policy Entropy: 3.75270
Value Function Loss: 0.02685

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.58350

Collected Steps per Second: 22,967.74420
Overall Steps per Second: 10,734.30905

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66038

Cumulative Model Updates: 120,584
Cumulative Timesteps: 1,005,540,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1005540014...
Checkpoint 1005540014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,289.11139
Policy Entropy: 3.76533
Value Function Loss: 0.02176

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.51063
Value Function Update Magnitude: 0.56313

Collected Steps per Second: 23,045.98769
Overall Steps per Second: 10,871.83938

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.60180

Cumulative Model Updates: 120,590
Cumulative Timesteps: 1,005,590,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,719.12257
Policy Entropy: 3.73804
Value Function Loss: 0.02637

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.48492
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 23,016.28873
Overall Steps per Second: 10,854.38567

Timestep Collection Time: 2.17333
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60846

Cumulative Model Updates: 120,596
Cumulative Timesteps: 1,005,640,066

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1005640066...
Checkpoint 1005640066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,745.05441
Policy Entropy: 3.72889
Value Function Loss: 0.02683

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.51632
Value Function Update Magnitude: 0.63939

Collected Steps per Second: 22,692.16652
Overall Steps per Second: 10,781.86173

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.63927

Cumulative Model Updates: 120,602
Cumulative Timesteps: 1,005,690,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,111.63604
Policy Entropy: 3.73081
Value Function Loss: 0.02739

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.52163
Value Function Update Magnitude: 0.75137

Collected Steps per Second: 23,057.21082
Overall Steps per Second: 10,886.80969

Timestep Collection Time: 2.16956
Timestep Consumption Time: 2.42536
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.59492

Cumulative Model Updates: 120,608
Cumulative Timesteps: 1,005,740,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1005740110...
Checkpoint 1005740110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,167.68969
Policy Entropy: 3.73983
Value Function Loss: 0.02132

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.50271
Value Function Update Magnitude: 0.69690

Collected Steps per Second: 22,835.03269
Overall Steps per Second: 10,665.32129

Timestep Collection Time: 2.18997
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.68884

Cumulative Model Updates: 120,614
Cumulative Timesteps: 1,005,790,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,167.68969
Policy Entropy: 3.74356
Value Function Loss: 0.01738

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14803
Policy Update Magnitude: 0.47921
Value Function Update Magnitude: 0.68636

Collected Steps per Second: 22,835.76698
Overall Steps per Second: 10,825.65647

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.43047
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62124

Cumulative Model Updates: 120,620
Cumulative Timesteps: 1,005,840,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1005840146...
Checkpoint 1005840146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,167.68969
Policy Entropy: 3.72936
Value Function Loss: 0.01549

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.45243
Value Function Update Magnitude: 0.60458

Collected Steps per Second: 22,917.02089
Overall Steps per Second: 10,655.40112

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.69415

Cumulative Model Updates: 120,626
Cumulative Timesteps: 1,005,890,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,167.68969
Policy Entropy: 3.72364
Value Function Loss: 0.01582

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.16372
Policy Update Magnitude: 0.42896
Value Function Update Magnitude: 0.50459

Collected Steps per Second: 22,825.02033
Overall Steps per Second: 10,850.78434

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.61073

Cumulative Model Updates: 120,632
Cumulative Timesteps: 1,005,940,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1005940194...
Checkpoint 1005940194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,167.68969
Policy Entropy: 3.71262
Value Function Loss: 0.01924

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.18973
Policy Update Magnitude: 0.46111
Value Function Update Magnitude: 0.50612

Collected Steps per Second: 22,897.55665
Overall Steps per Second: 10,704.00383

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.67115

Cumulative Model Updates: 120,638
Cumulative Timesteps: 1,005,990,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,851.43012
Policy Entropy: 3.73043
Value Function Loss: 0.02246

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.59725
Value Function Update Magnitude: 0.55581

Collected Steps per Second: 22,453.87709
Overall Steps per Second: 10,609.86660

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.48591
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.71278

Cumulative Model Updates: 120,644
Cumulative Timesteps: 1,006,040,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1006040196...
Checkpoint 1006040196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,439.21625
Policy Entropy: 3.73987
Value Function Loss: 0.02662

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.64116
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 22,850.26911
Overall Steps per Second: 10,827.93973

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.61953

Cumulative Model Updates: 120,650
Cumulative Timesteps: 1,006,090,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,450.88005
Policy Entropy: 3.77165
Value Function Loss: 0.02912

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.67352
Value Function Update Magnitude: 0.50997

Collected Steps per Second: 22,358.13219
Overall Steps per Second: 10,556.44008

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.50132
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.73872

Cumulative Model Updates: 120,656
Cumulative Timesteps: 1,006,140,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006140240...
Checkpoint 1006140240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,744.90521
Policy Entropy: 3.77212
Value Function Loss: 0.03051

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.61008
Value Function Update Magnitude: 0.59276

Collected Steps per Second: 22,858.63250
Overall Steps per Second: 10,672.90767

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.68626

Cumulative Model Updates: 120,662
Cumulative Timesteps: 1,006,190,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.76861
Policy Entropy: 3.76755
Value Function Loss: 0.02857

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.68102
Value Function Update Magnitude: 0.72661

Collected Steps per Second: 22,908.10846
Overall Steps per Second: 10,800.25515

Timestep Collection Time: 2.18290
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.63008

Cumulative Model Updates: 120,668
Cumulative Timesteps: 1,006,240,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1006240262...
Checkpoint 1006240262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,008.71501
Policy Entropy: 3.77745
Value Function Loss: 0.02516

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09670
Policy Update Magnitude: 0.80504
Value Function Update Magnitude: 0.69928

Collected Steps per Second: 23,109.07823
Overall Steps per Second: 10,733.01676

Timestep Collection Time: 2.16599
Timestep Consumption Time: 2.49757
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.66355

Cumulative Model Updates: 120,674
Cumulative Timesteps: 1,006,290,316

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,986.12687
Policy Entropy: 3.76615
Value Function Loss: 0.02085

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.80267
Value Function Update Magnitude: 0.68370

Collected Steps per Second: 23,042.87902
Overall Steps per Second: 10,826.90937

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.44914
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61979

Cumulative Model Updates: 120,680
Cumulative Timesteps: 1,006,340,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1006340334...
Checkpoint 1006340334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,363.94731
Policy Entropy: 3.74904
Value Function Loss: 0.01913

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.17289
Policy Update Magnitude: 0.67951
Value Function Update Magnitude: 0.83887

Collected Steps per Second: 22,863.09989
Overall Steps per Second: 10,708.90993

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.67181

Cumulative Model Updates: 120,686
Cumulative Timesteps: 1,006,390,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,426.41450
Policy Entropy: 3.74552
Value Function Loss: 0.01894

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.19699
Policy Update Magnitude: 0.51701
Value Function Update Magnitude: 0.77805

Collected Steps per Second: 22,355.97977
Overall Steps per Second: 10,876.10232

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.36211
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.59999

Cumulative Model Updates: 120,692
Cumulative Timesteps: 1,006,440,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1006440394...
Checkpoint 1006440394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,065.12009
Policy Entropy: 3.71926
Value Function Loss: 0.02652

Mean KL Divergence: 0.03443
SB3 Clip Fraction: 0.31007
Policy Update Magnitude: 0.45096
Value Function Update Magnitude: 0.76893

Collected Steps per Second: 22,169.93468
Overall Steps per Second: 10,681.25972

Timestep Collection Time: 2.25531
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.68110

Cumulative Model Updates: 120,698
Cumulative Timesteps: 1,006,490,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.94371
Policy Entropy: 3.73320
Value Function Loss: 0.03302

Mean KL Divergence: 0.01908
SB3 Clip Fraction: 0.22354
Policy Update Magnitude: 0.64781
Value Function Update Magnitude: 0.79945

Collected Steps per Second: 22,086.56859
Overall Steps per Second: 10,803.25021

Timestep Collection Time: 2.26418
Timestep Consumption Time: 2.36480
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.62898

Cumulative Model Updates: 120,704
Cumulative Timesteps: 1,006,540,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1006540402...
Checkpoint 1006540402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,126.69104
Policy Entropy: 3.73105
Value Function Loss: 0.03346

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.20568
Policy Update Magnitude: 0.69491
Value Function Update Magnitude: 0.78531

Collected Steps per Second: 21,035.92031
Overall Steps per Second: 10,296.36210

Timestep Collection Time: 2.37936
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.86113

Cumulative Model Updates: 120,710
Cumulative Timesteps: 1,006,590,454

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,758.70411
Policy Entropy: 3.73158
Value Function Loss: 0.03678

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17662
Policy Update Magnitude: 0.67460
Value Function Update Magnitude: 0.76357

Collected Steps per Second: 22,443.30957
Overall Steps per Second: 10,671.10364

Timestep Collection Time: 2.22837
Timestep Consumption Time: 2.45831
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68668

Cumulative Model Updates: 120,716
Cumulative Timesteps: 1,006,640,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1006640466...
Checkpoint 1006640466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,656.04463
Policy Entropy: 3.73609
Value Function Loss: 0.03324

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17627
Policy Update Magnitude: 0.60724
Value Function Update Magnitude: 0.71315

Collected Steps per Second: 23,067.84536
Overall Steps per Second: 10,915.19960

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.41335
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.58095

Cumulative Model Updates: 120,722
Cumulative Timesteps: 1,006,690,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,303.53659
Policy Entropy: 3.72917
Value Function Loss: 0.03280

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16907
Policy Update Magnitude: 0.61078
Value Function Update Magnitude: 0.67111

Collected Steps per Second: 22,814.84322
Overall Steps per Second: 10,818.65216

Timestep Collection Time: 2.19182
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.62220

Cumulative Model Updates: 120,728
Cumulative Timesteps: 1,006,740,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1006740474...
Checkpoint 1006740474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,303.53659
Policy Entropy: 3.73033
Value Function Loss: 0.02788

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 22,668.74324
Overall Steps per Second: 10,683.51582

Timestep Collection Time: 2.20639
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.68160

Cumulative Model Updates: 120,734
Cumulative Timesteps: 1,006,790,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,303.53659
Policy Entropy: 3.71431
Value Function Loss: 0.02571

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.48800
Value Function Update Magnitude: 0.43413

Collected Steps per Second: 22,825.28935
Overall Steps per Second: 10,841.68554

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.42244
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61404

Cumulative Model Updates: 120,740
Cumulative Timesteps: 1,006,840,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1006840514...
Checkpoint 1006840514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,303.53659
Policy Entropy: 3.70900
Value Function Loss: 0.02473

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.46403
Value Function Update Magnitude: 0.38343

Collected Steps per Second: 22,673.96885
Overall Steps per Second: 10,763.27816

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.44103
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.64691

Cumulative Model Updates: 120,746
Cumulative Timesteps: 1,006,890,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,114.10140
Policy Entropy: 3.71779
Value Function Loss: 0.02394

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.46558
Value Function Update Magnitude: 0.43991

Collected Steps per Second: 23,098.05330
Overall Steps per Second: 10,920.42091

Timestep Collection Time: 2.16529
Timestep Consumption Time: 2.41457
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.57986

Cumulative Model Updates: 120,752
Cumulative Timesteps: 1,006,940,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1006940544...
Checkpoint 1006940544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,837.84650
Policy Entropy: 3.71326
Value Function Loss: 0.02120

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.47617
Value Function Update Magnitude: 0.55112

Collected Steps per Second: 22,865.28931
Overall Steps per Second: 10,659.07506

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.69347

Cumulative Model Updates: 120,758
Cumulative Timesteps: 1,006,990,572

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296,569.05689
Policy Entropy: 3.70566
Value Function Loss: 0.02383

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.47431
Value Function Update Magnitude: 0.50726

Collected Steps per Second: 22,185.31667
Overall Steps per Second: 10,838.88798

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.36041
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.61523

Cumulative Model Updates: 120,764
Cumulative Timesteps: 1,007,040,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1007040596...
Checkpoint 1007040596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,346.64098
Policy Entropy: 3.71433
Value Function Loss: 0.02552

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.50645
Value Function Update Magnitude: 0.51471

Collected Steps per Second: 22,159.79435
Overall Steps per Second: 10,703.09724

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.41714
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.67528

Cumulative Model Updates: 120,770
Cumulative Timesteps: 1,007,090,636

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,661.44921
Policy Entropy: 3.73033
Value Function Loss: 0.02719

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.76245

Collected Steps per Second: 22,068.79247
Overall Steps per Second: 10,842.69261

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.34698
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.61380

Cumulative Model Updates: 120,776
Cumulative Timesteps: 1,007,140,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1007140662...
Checkpoint 1007140662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,760.00959
Policy Entropy: 3.74952
Value Function Loss: 0.02649

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.73215

Collected Steps per Second: 22,373.15501
Overall Steps per Second: 10,677.01073

Timestep Collection Time: 2.23545
Timestep Consumption Time: 2.44882
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.68427

Cumulative Model Updates: 120,782
Cumulative Timesteps: 1,007,190,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,816.70837
Policy Entropy: 3.74843
Value Function Loss: 0.02475

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.64669

Collected Steps per Second: 23,012.53700
Overall Steps per Second: 10,861.78885

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.60495

Cumulative Model Updates: 120,788
Cumulative Timesteps: 1,007,240,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007240694...
Checkpoint 1007240694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,112.54557
Policy Entropy: 3.73335
Value Function Loss: 0.02361

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.50704
Value Function Update Magnitude: 0.58526

Collected Steps per Second: 22,917.16238
Overall Steps per Second: 10,753.54581

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.46815
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.65019

Cumulative Model Updates: 120,794
Cumulative Timesteps: 1,007,290,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,190.23140
Policy Entropy: 3.74278
Value Function Loss: 0.02155

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.48120
Value Function Update Magnitude: 0.53478

Collected Steps per Second: 22,788.74291
Overall Steps per Second: 10,861.71101

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.41013
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.60498

Cumulative Model Updates: 120,800
Cumulative Timesteps: 1,007,340,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1007340718...
Checkpoint 1007340718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,190.23140
Policy Entropy: 3.70479
Value Function Loss: 0.02174

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14218
Policy Update Magnitude: 0.46397
Value Function Update Magnitude: 0.51324

Collected Steps per Second: 23,030.31157
Overall Steps per Second: 10,756.63113

Timestep Collection Time: 2.17244
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.65127

Cumulative Model Updates: 120,806
Cumulative Timesteps: 1,007,390,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,968.98285
Policy Entropy: 3.71861
Value Function Loss: 0.02061

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.47234
Value Function Update Magnitude: 0.48511

Collected Steps per Second: 23,126.11599
Overall Steps per Second: 10,722.28644

Timestep Collection Time: 2.16266
Timestep Consumption Time: 2.50183
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.66449

Cumulative Model Updates: 120,812
Cumulative Timesteps: 1,007,440,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1007440764...
Checkpoint 1007440764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,058.32583
Policy Entropy: 3.71060
Value Function Loss: 0.02276

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.47661
Value Function Update Magnitude: 0.46925

Collected Steps per Second: 22,783.30553
Overall Steps per Second: 10,663.70226

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.49521
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69068

Cumulative Model Updates: 120,818
Cumulative Timesteps: 1,007,490,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,182.17538
Policy Entropy: 3.74446
Value Function Loss: 0.02057

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.47662
Value Function Update Magnitude: 0.47950

Collected Steps per Second: 22,705.89183
Overall Steps per Second: 10,829.22611

Timestep Collection Time: 2.20269
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.61843

Cumulative Model Updates: 120,824
Cumulative Timesteps: 1,007,540,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1007540798...
Checkpoint 1007540798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,182.17538
Policy Entropy: 3.74041
Value Function Loss: 0.02018

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.45798
Value Function Update Magnitude: 0.49835

Collected Steps per Second: 22,898.59935
Overall Steps per Second: 10,730.63420

Timestep Collection Time: 2.18424
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.66105

Cumulative Model Updates: 120,830
Cumulative Timesteps: 1,007,590,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,262.94796
Policy Entropy: 3.74032
Value Function Loss: 0.01886

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.43838
Value Function Update Magnitude: 0.49373

Collected Steps per Second: 21,980.33499
Overall Steps per Second: 10,819.70683

Timestep Collection Time: 2.27476
Timestep Consumption Time: 2.34644
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.62120

Cumulative Model Updates: 120,836
Cumulative Timesteps: 1,007,640,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1007640814...
Checkpoint 1007640814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,262.94796
Policy Entropy: 3.72332
Value Function Loss: 0.01861

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.44010
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 22,376.43803
Overall Steps per Second: 10,733.42910

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.65983

Cumulative Model Updates: 120,842
Cumulative Timesteps: 1,007,690,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,262.94796
Policy Entropy: 3.71882
Value Function Loss: 0.01908

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.45158
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,294.02028
Overall Steps per Second: 10,630.93453

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.70589

Cumulative Model Updates: 120,848
Cumulative Timesteps: 1,007,740,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1007740858...
Checkpoint 1007740858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,450.18735
Policy Entropy: 3.71076
Value Function Loss: 0.02128

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.49319
Value Function Update Magnitude: 0.62230

Collected Steps per Second: 23,142.58348
Overall Steps per Second: 10,881.15560

Timestep Collection Time: 2.16104
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.59620

Cumulative Model Updates: 120,854
Cumulative Timesteps: 1,007,790,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,967.64622
Policy Entropy: 3.71784
Value Function Loss: 0.02147

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.52326
Value Function Update Magnitude: 0.53334

Collected Steps per Second: 22,726.03682
Overall Steps per Second: 10,875.01571

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59990

Cumulative Model Updates: 120,860
Cumulative Timesteps: 1,007,840,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1007840894...
Checkpoint 1007840894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,967.64622
Policy Entropy: 3.71795
Value Function Loss: 0.02286

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.50755

Collected Steps per Second: 22,897.35154
Overall Steps per Second: 10,665.28984

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68867

Cumulative Model Updates: 120,866
Cumulative Timesteps: 1,007,890,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,325.63078
Policy Entropy: 3.73755
Value Function Loss: 0.02227

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.61321

Collected Steps per Second: 23,017.05706
Overall Steps per Second: 10,884.65875

Timestep Collection Time: 2.17274
Timestep Consumption Time: 2.42180
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.59454

Cumulative Model Updates: 120,872
Cumulative Timesteps: 1,007,940,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1007940910...
Checkpoint 1007940910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,916.86152
Policy Entropy: 3.72908
Value Function Loss: 0.02156

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 22,950.13743
Overall Steps per Second: 10,687.49905

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.68005

Cumulative Model Updates: 120,878
Cumulative Timesteps: 1,007,990,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,093.68591
Policy Entropy: 3.73321
Value Function Loss: 0.02077

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.55771

Collected Steps per Second: 22,699.32264
Overall Steps per Second: 10,788.07701

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.43204
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63475

Cumulative Model Updates: 120,884
Cumulative Timesteps: 1,008,040,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1008040928...
Checkpoint 1008040928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,093.68591
Policy Entropy: 3.71305
Value Function Loss: 0.01883

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.49394

Collected Steps per Second: 22,692.37665
Overall Steps per Second: 10,709.30571

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.46703
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.67182

Cumulative Model Updates: 120,890
Cumulative Timesteps: 1,008,090,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,094.96644
Policy Entropy: 3.71783
Value Function Loss: 0.01959

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.48245

Collected Steps per Second: 22,764.93221
Overall Steps per Second: 10,722.52858

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.66550

Cumulative Model Updates: 120,896
Cumulative Timesteps: 1,008,140,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1008140986...
Checkpoint 1008140986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,094.96644
Policy Entropy: 3.71245
Value Function Loss: 0.02217

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.48656
Value Function Update Magnitude: 0.43749

Collected Steps per Second: 22,765.42533
Overall Steps per Second: 10,840.70201

Timestep Collection Time: 2.19746
Timestep Consumption Time: 2.41719
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.61465

Cumulative Model Updates: 120,902
Cumulative Timesteps: 1,008,191,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,094.96644
Policy Entropy: 3.71840
Value Function Loss: 0.02157

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.51208
Value Function Update Magnitude: 0.53182

Collected Steps per Second: 22,100.95844
Overall Steps per Second: 10,823.89334

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.35744
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62015

Cumulative Model Updates: 120,908
Cumulative Timesteps: 1,008,241,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1008241020...
Checkpoint 1008241020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,094.96644
Policy Entropy: 3.71787
Value Function Loss: 0.02068

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.49975
Value Function Update Magnitude: 0.63126

Collected Steps per Second: 22,114.45995
Overall Steps per Second: 10,700.09087

Timestep Collection Time: 2.26214
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.67529

Cumulative Model Updates: 120,914
Cumulative Timesteps: 1,008,291,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,356.48980
Policy Entropy: 3.73059
Value Function Loss: 0.02084

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.49436
Value Function Update Magnitude: 0.55339

Collected Steps per Second: 22,119.65132
Overall Steps per Second: 10,532.35300

Timestep Collection Time: 2.26116
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.74880

Cumulative Model Updates: 120,920
Cumulative Timesteps: 1,008,341,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1008341062...
Checkpoint 1008341062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,085.22678
Policy Entropy: 3.73318
Value Function Loss: 0.02103

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 22,873.31967
Overall Steps per Second: 10,761.52163

Timestep Collection Time: 2.18613
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.64655

Cumulative Model Updates: 120,926
Cumulative Timesteps: 1,008,391,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,799.64882
Policy Entropy: 3.73844
Value Function Loss: 0.02235

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.51854
Value Function Update Magnitude: 0.63869

Collected Steps per Second: 22,962.97374
Overall Steps per Second: 10,737.34429

Timestep Collection Time: 2.17829
Timestep Consumption Time: 2.48022
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.65851

Cumulative Model Updates: 120,932
Cumulative Timesteps: 1,008,441,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1008441086...
Checkpoint 1008441086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,330.74263
Policy Entropy: 3.74379
Value Function Loss: 0.02215

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.52116
Value Function Update Magnitude: 0.55780

Collected Steps per Second: 22,901.91335
Overall Steps per Second: 10,674.60858

Timestep Collection Time: 2.18322
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.68401

Cumulative Model Updates: 120,938
Cumulative Timesteps: 1,008,491,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,721.39832
Policy Entropy: 3.73675
Value Function Loss: 0.02236

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14126
Policy Update Magnitude: 0.50632
Value Function Update Magnitude: 0.47882

Collected Steps per Second: 22,917.15967
Overall Steps per Second: 10,842.50256

Timestep Collection Time: 2.18221
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.61240

Cumulative Model Updates: 120,944
Cumulative Timesteps: 1,008,541,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1008541096...
Checkpoint 1008541096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326,433.51244
Policy Entropy: 3.74451
Value Function Loss: 0.02035

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.51025
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 22,930.72442
Overall Steps per Second: 10,667.06717

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.50835
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.69014

Cumulative Model Updates: 120,950
Cumulative Timesteps: 1,008,591,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,012.65605
Policy Entropy: 3.72499
Value Function Loss: 0.02546

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.62167

Collected Steps per Second: 22,837.02500
Overall Steps per Second: 10,838.84141

Timestep Collection Time: 2.18995
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61415

Cumulative Model Updates: 120,956
Cumulative Timesteps: 1,008,641,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1008641138...
Checkpoint 1008641138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,522.84471
Policy Entropy: 3.74766
Value Function Loss: 0.02574

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.61801
Value Function Update Magnitude: 0.67205

Collected Steps per Second: 22,988.84602
Overall Steps per Second: 10,687.49371

Timestep Collection Time: 2.17540
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.67930

Cumulative Model Updates: 120,962
Cumulative Timesteps: 1,008,691,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,153.70238
Policy Entropy: 3.74163
Value Function Loss: 0.03037

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.64111
Value Function Update Magnitude: 0.69118

Collected Steps per Second: 22,801.85512
Overall Steps per Second: 10,845.63016

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.41783
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61107

Cumulative Model Updates: 120,968
Cumulative Timesteps: 1,008,741,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1008741158...
Checkpoint 1008741158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,349.29702
Policy Entropy: 3.75731
Value Function Loss: 0.02542

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.61833
Value Function Update Magnitude: 0.68995

Collected Steps per Second: 22,707.85418
Overall Steps per Second: 10,729.26527

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.45916
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.66183

Cumulative Model Updates: 120,974
Cumulative Timesteps: 1,008,791,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,349.29702
Policy Entropy: 3.72845
Value Function Loss: 0.02283

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.65840

Collected Steps per Second: 22,140.35471
Overall Steps per Second: 10,852.74824

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.34928
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60805

Cumulative Model Updates: 120,980
Cumulative Timesteps: 1,008,841,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1008841186...
Checkpoint 1008841186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,876.61554
Policy Entropy: 3.73026
Value Function Loss: 0.01951

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.51812
Value Function Update Magnitude: 0.53956

Collected Steps per Second: 22,057.32991
Overall Steps per Second: 10,668.32727

Timestep Collection Time: 2.26700
Timestep Consumption Time: 2.42014
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.68715

Cumulative Model Updates: 120,986
Cumulative Timesteps: 1,008,891,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,075.68185
Policy Entropy: 3.75073
Value Function Loss: 0.02061

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.56081

Collected Steps per Second: 22,186.14164
Overall Steps per Second: 10,871.76982

Timestep Collection Time: 2.25366
Timestep Consumption Time: 2.34541
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.59907

Cumulative Model Updates: 120,992
Cumulative Timesteps: 1,008,941,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1008941190...
Checkpoint 1008941190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,829.55696
Policy Entropy: 3.76185
Value Function Loss: 0.02455

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.59481
Value Function Update Magnitude: 0.63980

Collected Steps per Second: 22,135.38912
Overall Steps per Second: 10,685.11032

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.67997

Cumulative Model Updates: 120,998
Cumulative Timesteps: 1,008,991,196

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,606.04586
Policy Entropy: 3.76607
Value Function Loss: 0.02404

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.60611
Value Function Update Magnitude: 0.72794

Collected Steps per Second: 22,966.31107
Overall Steps per Second: 10,926.09439

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.40044
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57876

Cumulative Model Updates: 121,004
Cumulative Timesteps: 1,009,041,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1009041224...
Checkpoint 1009041224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,992.29872
Policy Entropy: 3.74126
Value Function Loss: 0.02407

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14815
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.72527

Collected Steps per Second: 22,973.91754
Overall Steps per Second: 10,780.84758

Timestep Collection Time: 2.17716
Timestep Consumption Time: 2.46236
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.63952

Cumulative Model Updates: 121,010
Cumulative Timesteps: 1,009,091,242

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,556.62403
Policy Entropy: 3.74734
Value Function Loss: 0.02186

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.50419
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 22,937.99426
Overall Steps per Second: 10,714.04883

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.66770

Cumulative Model Updates: 121,016
Cumulative Timesteps: 1,009,141,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1009141252...
Checkpoint 1009141252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,134.78083
Policy Entropy: 3.74873
Value Function Loss: 0.02416

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.49204
Value Function Update Magnitude: 0.51978

Collected Steps per Second: 22,984.45585
Overall Steps per Second: 10,711.43547

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.49292
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.66866

Cumulative Model Updates: 121,022
Cumulative Timesteps: 1,009,191,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550,002.30963
Policy Entropy: 3.76149
Value Function Loss: 0.02600

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.58221

Collected Steps per Second: 22,744.11861
Overall Steps per Second: 10,805.71690

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62811

Cumulative Model Updates: 121,028
Cumulative Timesteps: 1,009,241,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1009241270...
Checkpoint 1009241270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,727.09674
Policy Entropy: 3.76957
Value Function Loss: 0.02703

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.59530
Value Function Update Magnitude: 0.69165

Collected Steps per Second: 22,686.44564
Overall Steps per Second: 10,644.93362

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.69876

Cumulative Model Updates: 121,034
Cumulative Timesteps: 1,009,291,288

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,340.18835
Policy Entropy: 3.75842
Value Function Loss: 0.02860

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.61518
Value Function Update Magnitude: 0.85828

Collected Steps per Second: 22,819.97959
Overall Steps per Second: 10,726.10674

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.47155
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.66357

Cumulative Model Updates: 121,040
Cumulative Timesteps: 1,009,341,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1009341310...
Checkpoint 1009341310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,600.34871
Policy Entropy: 3.75174
Value Function Loss: 0.02713

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.60825
Value Function Update Magnitude: 0.81333

Collected Steps per Second: 22,803.58862
Overall Steps per Second: 10,848.45220

Timestep Collection Time: 2.19351
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.61080

Cumulative Model Updates: 121,046
Cumulative Timesteps: 1,009,391,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268,319.99144
Policy Entropy: 3.73732
Value Function Loss: 0.02820

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14870
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.62876

Collected Steps per Second: 22,776.70721
Overall Steps per Second: 10,697.33624

Timestep Collection Time: 2.19593
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.67556

Cumulative Model Updates: 121,052
Cumulative Timesteps: 1,009,441,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1009441346...
Checkpoint 1009441346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,810.17499
Policy Entropy: 3.72971
Value Function Loss: 0.02788

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.15177
Policy Update Magnitude: 0.49598
Value Function Update Magnitude: 0.53270

Collected Steps per Second: 22,785.65001
Overall Steps per Second: 10,825.92330

Timestep Collection Time: 2.19559
Timestep Consumption Time: 2.42554
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.62113

Cumulative Model Updates: 121,058
Cumulative Timesteps: 1,009,491,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,833.72769
Policy Entropy: 3.74245
Value Function Loss: 0.03015

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.59170

Collected Steps per Second: 22,651.91048
Overall Steps per Second: 10,675.15590

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.68471

Cumulative Model Updates: 121,064
Cumulative Timesteps: 1,009,541,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1009541384...
Checkpoint 1009541384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,301.26954
Policy Entropy: 3.74119
Value Function Loss: 0.02790

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14392
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.70861

Collected Steps per Second: 23,003.30613
Overall Steps per Second: 10,884.25162

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.42019
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.59379

Cumulative Model Updates: 121,070
Cumulative Timesteps: 1,009,591,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,301.26954
Policy Entropy: 3.73467
Value Function Loss: 0.02358

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14809
Policy Update Magnitude: 0.55697
Value Function Update Magnitude: 0.66354

Collected Steps per Second: 22,792.10951
Overall Steps per Second: 10,702.11130

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.67403

Cumulative Model Updates: 121,076
Cumulative Timesteps: 1,009,641,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1009641406...
Checkpoint 1009641406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,793.85242
Policy Entropy: 3.72294
Value Function Loss: 0.02202

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.51494
Value Function Update Magnitude: 0.55034

Collected Steps per Second: 22,887.90679
Overall Steps per Second: 10,835.07049

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61520

Cumulative Model Updates: 121,082
Cumulative Timesteps: 1,009,691,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.07483
Policy Entropy: 3.71794
Value Function Loss: 0.02002

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.58643

Collected Steps per Second: 22,527.67077
Overall Steps per Second: 10,621.08214

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.71007

Cumulative Model Updates: 121,088
Cumulative Timesteps: 1,009,741,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1009741438...
Checkpoint 1009741438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.07483
Policy Entropy: 3.71895
Value Function Loss: 0.02042

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.53599
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,918.57008
Overall Steps per Second: 10,744.96467

Timestep Collection Time: 2.18260
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.65539

Cumulative Model Updates: 121,094
Cumulative Timesteps: 1,009,791,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.07483
Policy Entropy: 3.71973
Value Function Loss: 0.01831

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.50461
Value Function Update Magnitude: 0.56712

Collected Steps per Second: 22,898.01385
Overall Steps per Second: 10,723.32839

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.66273

Cumulative Model Updates: 121,100
Cumulative Timesteps: 1,009,841,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1009841460...
Checkpoint 1009841460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.07483
Policy Entropy: 3.71372
Value Function Loss: 0.01646

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.44189
Value Function Update Magnitude: 0.48500

Collected Steps per Second: 22,762.54527
Overall Steps per Second: 10,614.09882

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.51443
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.71128

Cumulative Model Updates: 121,106
Cumulative Timesteps: 1,009,891,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.07483
Policy Entropy: 3.72590
Value Function Loss: 0.01674

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.41268
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 22,838.72724
Overall Steps per Second: 10,844.12532

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.42269
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.61300

Cumulative Model Updates: 121,112
Cumulative Timesteps: 1,009,941,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1009941490...
Checkpoint 1009941490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,465.71670
Policy Entropy: 3.73113
Value Function Loss: 0.01704

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14702
Policy Update Magnitude: 0.45093
Value Function Update Magnitude: 0.64131

Collected Steps per Second: 22,744.40585
Overall Steps per Second: 10,738.21654

Timestep Collection Time: 2.19922
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.65813

Cumulative Model Updates: 121,118
Cumulative Timesteps: 1,009,991,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,594.66608
Policy Entropy: 3.73914
Value Function Loss: 0.01713

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.45172
Value Function Update Magnitude: 0.74096

Collected Steps per Second: 22,551.98541
Overall Steps per Second: 10,799.19950

Timestep Collection Time: 2.21763
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.63108

Cumulative Model Updates: 121,124
Cumulative Timesteps: 1,010,041,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010041522...
Checkpoint 1010041522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,833.24466
Policy Entropy: 3.73776
Value Function Loss: 0.01651

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.40580
Value Function Update Magnitude: 0.72672

Collected Steps per Second: 22,593.51399
Overall Steps per Second: 10,711.57920

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.66785

Cumulative Model Updates: 121,130
Cumulative Timesteps: 1,010,091,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,456.04699
Policy Entropy: 3.72179
Value Function Loss: 0.01725

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.39875
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 22,079.45195
Overall Steps per Second: 10,845.86422

Timestep Collection Time: 2.26536
Timestep Consumption Time: 2.34635
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.61171

Cumulative Model Updates: 121,136
Cumulative Timesteps: 1,010,141,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1010141540...
Checkpoint 1010141540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,456.04699
Policy Entropy: 3.71803
Value Function Loss: 0.01634

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.39781
Value Function Update Magnitude: 0.55839

Collected Steps per Second: 22,047.21245
Overall Steps per Second: 10,711.34710

Timestep Collection Time: 2.26913
Timestep Consumption Time: 2.40143
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.67056

Cumulative Model Updates: 121,142
Cumulative Timesteps: 1,010,191,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,929.14122
Policy Entropy: 3.70750
Value Function Loss: 0.01859

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.41812
Value Function Update Magnitude: 0.50058

Collected Steps per Second: 22,093.82830
Overall Steps per Second: 10,853.88512

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.34385
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.60720

Cumulative Model Updates: 121,148
Cumulative Timesteps: 1,010,241,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1010241574...
Checkpoint 1010241574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,351.00338
Policy Entropy: 3.71481
Value Function Loss: 0.02109

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.45910
Value Function Update Magnitude: 0.50610

Collected Steps per Second: 22,093.55858
Overall Steps per Second: 10,739.03704

Timestep Collection Time: 2.26401
Timestep Consumption Time: 2.39376
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.65777

Cumulative Model Updates: 121,154
Cumulative Timesteps: 1,010,291,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,510.92768
Policy Entropy: 3.70989
Value Function Loss: 0.02478

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.51071
Value Function Update Magnitude: 0.62197

Collected Steps per Second: 22,980.43336
Overall Steps per Second: 10,886.11121

Timestep Collection Time: 2.17629
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.59411

Cumulative Model Updates: 121,160
Cumulative Timesteps: 1,010,341,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010341606...
Checkpoint 1010341606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,242.81186
Policy Entropy: 3.71929
Value Function Loss: 0.02456

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.52425
Value Function Update Magnitude: 0.59314

Collected Steps per Second: 22,914.18853
Overall Steps per Second: 10,800.39766

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.44819
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.63094

Cumulative Model Updates: 121,166
Cumulative Timesteps: 1,010,391,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,473.63504
Policy Entropy: 3.70979
Value Function Loss: 0.02135

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.49466
Value Function Update Magnitude: 0.59128

Collected Steps per Second: 22,907.01780
Overall Steps per Second: 10,721.84557

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.66524

Cumulative Model Updates: 121,172
Cumulative Timesteps: 1,010,441,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1010441642...
Checkpoint 1010441642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,488.35934
Policy Entropy: 3.71642
Value Function Loss: 0.02090

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14314
Policy Update Magnitude: 0.49393
Value Function Update Magnitude: 0.68689

Collected Steps per Second: 22,815.42572
Overall Steps per Second: 10,649.41998

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.50399
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.69584

Cumulative Model Updates: 121,178
Cumulative Timesteps: 1,010,491,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,549.09249
Policy Entropy: 3.72186
Value Function Loss: 0.02143

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.70224

Collected Steps per Second: 22,915.42548
Overall Steps per Second: 10,844.90115

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.61175

Cumulative Model Updates: 121,184
Cumulative Timesteps: 1,010,541,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1010541664...
Checkpoint 1010541664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,883.47984
Policy Entropy: 3.74095
Value Function Loss: 0.02174

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.58663
Value Function Update Magnitude: 0.72174

Collected Steps per Second: 23,086.38291
Overall Steps per Second: 10,700.56964

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.67470

Cumulative Model Updates: 121,190
Cumulative Timesteps: 1,010,591,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,871.62693
Policy Entropy: 3.75771
Value Function Loss: 0.02067

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.76761

Collected Steps per Second: 22,904.02456
Overall Steps per Second: 10,828.06058

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61800

Cumulative Model Updates: 121,196
Cumulative Timesteps: 1,010,641,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1010641690...
Checkpoint 1010641690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,095.50653
Policy Entropy: 3.75295
Value Function Loss: 0.02157

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.69529

Collected Steps per Second: 22,752.24449
Overall Steps per Second: 10,715.78729

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.66676

Cumulative Model Updates: 121,202
Cumulative Timesteps: 1,010,691,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,176.43908
Policy Entropy: 3.73512
Value Function Loss: 0.01911

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.69732

Collected Steps per Second: 22,907.21734
Overall Steps per Second: 10,844.51351

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.61081

Cumulative Model Updates: 121,208
Cumulative Timesteps: 1,010,741,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1010741700...
Checkpoint 1010741700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,653.66303
Policy Entropy: 3.71714
Value Function Loss: 0.02150

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.50953
Value Function Update Magnitude: 0.67326

Collected Steps per Second: 22,544.74750
Overall Steps per Second: 10,718.99637

Timestep Collection Time: 2.21790
Timestep Consumption Time: 2.44690
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.66480

Cumulative Model Updates: 121,214
Cumulative Timesteps: 1,010,791,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,369.16553
Policy Entropy: 3.72933
Value Function Loss: 0.02110

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.73400

Collected Steps per Second: 22,761.29204
Overall Steps per Second: 10,815.44910

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.62450

Cumulative Model Updates: 121,220
Cumulative Timesteps: 1,010,841,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1010841718...
Checkpoint 1010841718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,749.45192
Policy Entropy: 3.73760
Value Function Loss: 0.02445

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14206
Policy Update Magnitude: 0.53658
Value Function Update Magnitude: 0.81537

Collected Steps per Second: 22,198.21698
Overall Steps per Second: 10,689.44347

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.68163

Cumulative Model Updates: 121,226
Cumulative Timesteps: 1,010,891,762

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,478.19879
Policy Entropy: 3.75171
Value Function Loss: 0.02335

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.83307

Collected Steps per Second: 22,168.95856
Overall Steps per Second: 10,869.99046

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.34498
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.60092

Cumulative Model Updates: 121,232
Cumulative Timesteps: 1,010,941,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1010941774...
Checkpoint 1010941774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,589.41445
Policy Entropy: 3.73911
Value Function Loss: 0.02115

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.62477
Value Function Update Magnitude: 0.86490

Collected Steps per Second: 22,269.77989
Overall Steps per Second: 10,687.82643

Timestep Collection Time: 2.24555
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.67897

Cumulative Model Updates: 121,238
Cumulative Timesteps: 1,010,991,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,444.74046
Policy Entropy: 3.75410
Value Function Loss: 0.01810

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.63712
Value Function Update Magnitude: 0.78102

Collected Steps per Second: 22,690.08412
Overall Steps per Second: 10,911.69098

Timestep Collection Time: 2.20449
Timestep Consumption Time: 2.37959
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.58407

Cumulative Model Updates: 121,244
Cumulative Timesteps: 1,011,041,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1011041802...
Checkpoint 1011041802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,162.81663
Policy Entropy: 3.74113
Value Function Loss: 0.01787

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.18239
Policy Update Magnitude: 0.64432
Value Function Update Magnitude: 0.72370

Collected Steps per Second: 21,924.41558
Overall Steps per Second: 10,687.69755

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.39771
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.67828

Cumulative Model Updates: 121,250
Cumulative Timesteps: 1,011,091,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,696.44423
Policy Entropy: 3.75602
Value Function Loss: 0.02206

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.20118
Policy Update Magnitude: 0.61561
Value Function Update Magnitude: 0.60732

Collected Steps per Second: 22,816.55531
Overall Steps per Second: 10,888.49819

Timestep Collection Time: 2.19271
Timestep Consumption Time: 2.40205
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.59476

Cumulative Model Updates: 121,256
Cumulative Timesteps: 1,011,141,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1011141832...
Checkpoint 1011141832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,951.68223
Policy Entropy: 3.76336
Value Function Loss: 0.02359

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.21549
Policy Update Magnitude: 0.69952
Value Function Update Magnitude: 0.66389

Collected Steps per Second: 22,096.48548
Overall Steps per Second: 10,595.06857

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.45647
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.71937

Cumulative Model Updates: 121,262
Cumulative Timesteps: 1,011,191,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,754.85406
Policy Entropy: 3.81014
Value Function Loss: 0.02691

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.80560
Value Function Update Magnitude: 0.78820

Collected Steps per Second: 23,025.19557
Overall Steps per Second: 10,944.63689

Timestep Collection Time: 2.17179
Timestep Consumption Time: 2.39720
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.56900

Cumulative Model Updates: 121,268
Cumulative Timesteps: 1,011,241,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1011241840...
Checkpoint 1011241840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.22144
Policy Entropy: 3.84565
Value Function Loss: 0.02757

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.93776
Value Function Update Magnitude: 0.96971

Collected Steps per Second: 22,916.28040
Overall Steps per Second: 10,824.02605

Timestep Collection Time: 2.18273
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.62120

Cumulative Model Updates: 121,274
Cumulative Timesteps: 1,011,291,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.45327
Policy Entropy: 3.81658
Value Function Loss: 0.02859

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.93691
Value Function Update Magnitude: 1.10441

Collected Steps per Second: 23,166.28353
Overall Steps per Second: 10,704.51846

Timestep Collection Time: 2.15917
Timestep Consumption Time: 2.51362
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.67279

Cumulative Model Updates: 121,280
Cumulative Timesteps: 1,011,341,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1011341880...
Checkpoint 1011341880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,876.43971
Policy Entropy: 3.79204
Value Function Loss: 0.02662

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.84779
Value Function Update Magnitude: 0.97301

Collected Steps per Second: 22,927.82134
Overall Steps per Second: 10,698.44155

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.67358

Cumulative Model Updates: 121,286
Cumulative Timesteps: 1,011,391,880

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,238.84424
Policy Entropy: 3.75889
Value Function Loss: 0.02545

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.66849
Value Function Update Magnitude: 0.74355

Collected Steps per Second: 22,737.04382
Overall Steps per Second: 10,772.22212

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.44320
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.64287

Cumulative Model Updates: 121,292
Cumulative Timesteps: 1,011,441,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1011441894...
Checkpoint 1011441894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,285.67727
Policy Entropy: 3.78262
Value Function Loss: 0.03165

Mean KL Divergence: 0.02644
SB3 Clip Fraction: 0.26602
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.62879

Collected Steps per Second: 22,483.09209
Overall Steps per Second: 10,786.31420

Timestep Collection Time: 2.22630
Timestep Consumption Time: 2.41421
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.64051

Cumulative Model Updates: 121,298
Cumulative Timesteps: 1,011,491,948

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,240.86155
Policy Entropy: 3.76509
Value Function Loss: 0.03690

Mean KL Divergence: 0.02344
SB3 Clip Fraction: 0.23753
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.71655

Collected Steps per Second: 22,910.16559
Overall Steps per Second: 10,861.62521

Timestep Collection Time: 2.18252
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.60355

Cumulative Model Updates: 121,304
Cumulative Timesteps: 1,011,541,950

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1011541950...
Checkpoint 1011541950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,194.38602
Policy Entropy: 3.75901
Value Function Loss: 0.03952

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.17083
Policy Update Magnitude: 0.64766
Value Function Update Magnitude: 0.74999

Collected Steps per Second: 22,401.58678
Overall Steps per Second: 10,609.25937

Timestep Collection Time: 2.23306
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.71513

Cumulative Model Updates: 121,310
Cumulative Timesteps: 1,011,591,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,373.90282
Policy Entropy: 3.75280
Value Function Loss: 0.03966

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.22424
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.70550

Collected Steps per Second: 22,854.40802
Overall Steps per Second: 10,824.96742

Timestep Collection Time: 2.18890
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62135

Cumulative Model Updates: 121,316
Cumulative Timesteps: 1,011,642,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1011642000...
Checkpoint 1011642000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,812.34540
Policy Entropy: 3.77572
Value Function Loss: 0.03844

Mean KL Divergence: 0.02083
SB3 Clip Fraction: 0.22924
Policy Update Magnitude: 0.63637
Value Function Update Magnitude: 0.63368

Collected Steps per Second: 22,374.99112
Overall Steps per Second: 10,745.36286

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.65391

Cumulative Model Updates: 121,322
Cumulative Timesteps: 1,011,692,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,941.70821
Policy Entropy: 3.79310
Value Function Loss: 0.04029

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.19856
Policy Update Magnitude: 0.64836
Value Function Update Magnitude: 0.54912

Collected Steps per Second: 22,880.05990
Overall Steps per Second: 10,844.71605

Timestep Collection Time: 2.18627
Timestep Consumption Time: 2.42630
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.61257

Cumulative Model Updates: 121,328
Cumulative Timesteps: 1,011,742,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1011742030...
Checkpoint 1011742030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,859.47485
Policy Entropy: 3.79154
Value Function Loss: 0.04155

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.81211
Value Function Update Magnitude: 0.68858

Collected Steps per Second: 22,838.66793
Overall Steps per Second: 10,684.07257

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.68267

Cumulative Model Updates: 121,334
Cumulative Timesteps: 1,011,792,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,289.35157
Policy Entropy: 3.80566
Value Function Loss: 0.03733

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.93508
Value Function Update Magnitude: 0.76063

Collected Steps per Second: 23,234.03799
Overall Steps per Second: 10,872.42860

Timestep Collection Time: 2.15279
Timestep Consumption Time: 2.44765
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.60044

Cumulative Model Updates: 121,340
Cumulative Timesteps: 1,011,842,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1011842078...
Checkpoint 1011842078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.50202
Policy Entropy: 3.78713
Value Function Loss: 0.03196

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.91922
Value Function Update Magnitude: 0.71227

Collected Steps per Second: 22,732.43836
Overall Steps per Second: 10,674.50670

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.68855

Cumulative Model Updates: 121,346
Cumulative Timesteps: 1,011,892,126

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,422.01955
Policy Entropy: 3.80332
Value Function Loss: 0.02331

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.79473
Value Function Update Magnitude: 0.78969

Collected Steps per Second: 22,993.15245
Overall Steps per Second: 10,879.86580

Timestep Collection Time: 2.17482
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.59620

Cumulative Model Updates: 121,352
Cumulative Timesteps: 1,011,942,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1011942132...
Checkpoint 1011942132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,999.20087
Policy Entropy: 3.79588
Value Function Loss: 0.02406

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15700
Policy Update Magnitude: 0.65812
Value Function Update Magnitude: 0.70959

Collected Steps per Second: 22,511.68446
Overall Steps per Second: 10,682.81840

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.68041

Cumulative Model Updates: 121,358
Cumulative Timesteps: 1,011,992,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,813.31172
Policy Entropy: 3.80060
Value Function Loss: 0.02350

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07412
Policy Update Magnitude: 0.60021
Value Function Update Magnitude: 0.57971

Collected Steps per Second: 23,115.72830
Overall Steps per Second: 10,893.38234

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.59251

Cumulative Model Updates: 121,364
Cumulative Timesteps: 1,012,042,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1012042160...
Checkpoint 1012042160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,973.10181
Policy Entropy: 3.81495
Value Function Loss: 0.02353

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05634
Policy Update Magnitude: 0.67089
Value Function Update Magnitude: 0.65052

Collected Steps per Second: 22,722.43982
Overall Steps per Second: 10,624.98825

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70664

Cumulative Model Updates: 121,370
Cumulative Timesteps: 1,012,092,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,810.29222
Policy Entropy: 3.82977
Value Function Loss: 0.02272

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06182
Policy Update Magnitude: 0.70487
Value Function Update Magnitude: 0.73777

Collected Steps per Second: 22,916.59315
Overall Steps per Second: 10,852.95817

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.60759

Cumulative Model Updates: 121,376
Cumulative Timesteps: 1,012,142,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1012142174...
Checkpoint 1012142174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,739.28558
Policy Entropy: 3.83174
Value Function Loss: 0.02237

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06215
Policy Update Magnitude: 0.70359
Value Function Update Magnitude: 0.70658

Collected Steps per Second: 22,792.83002
Overall Steps per Second: 10,671.82288

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.68561

Cumulative Model Updates: 121,382
Cumulative Timesteps: 1,012,192,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,006.08062
Policy Entropy: 3.79244
Value Function Loss: 0.02125

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.66164
Value Function Update Magnitude: 0.65804

Collected Steps per Second: 22,872.17442
Overall Steps per Second: 10,852.05059

Timestep Collection Time: 2.18755
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.61056

Cumulative Model Updates: 121,388
Cumulative Timesteps: 1,012,242,212

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1012242212...
Checkpoint 1012242212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,560.71775
Policy Entropy: 3.75486
Value Function Loss: 0.02281

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.51711
Value Function Update Magnitude: 0.58734

Collected Steps per Second: 21,830.99646
Overall Steps per Second: 10,707.31237

Timestep Collection Time: 2.29050
Timestep Consumption Time: 2.37957
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.67008

Cumulative Model Updates: 121,394
Cumulative Timesteps: 1,012,292,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,368.41512
Policy Entropy: 3.74017
Value Function Loss: 0.02324

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15312
Policy Update Magnitude: 0.44108
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,015.13475
Overall Steps per Second: 10,849.15266

Timestep Collection Time: 2.27225
Timestep Consumption Time: 2.33861
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61087

Cumulative Model Updates: 121,400
Cumulative Timesteps: 1,012,342,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1012342240...
Checkpoint 1012342240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,072.12715
Policy Entropy: 3.73407
Value Function Loss: 0.02548

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16444
Policy Update Magnitude: 0.49627
Value Function Update Magnitude: 0.61682

Collected Steps per Second: 21,725.39289
Overall Steps per Second: 10,767.62681

Timestep Collection Time: 2.30201
Timestep Consumption Time: 2.34266
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.64466

Cumulative Model Updates: 121,406
Cumulative Timesteps: 1,012,392,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,673.71262
Policy Entropy: 3.77309
Value Function Loss: 0.02766

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.49588
Value Function Update Magnitude: 0.66917

Collected Steps per Second: 22,303.44526
Overall Steps per Second: 10,619.39359

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.71119

Cumulative Model Updates: 121,412
Cumulative Timesteps: 1,012,442,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1012442282...
Checkpoint 1012442282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,190.00890
Policy Entropy: 3.78484
Value Function Loss: 0.02764

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.48872
Value Function Update Magnitude: 0.69448

Collected Steps per Second: 22,915.88224
Overall Steps per Second: 10,961.97572

Timestep Collection Time: 2.18285
Timestep Consumption Time: 2.38038
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.56323

Cumulative Model Updates: 121,418
Cumulative Timesteps: 1,012,492,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,559.81900
Policy Entropy: 3.79131
Value Function Loss: 0.02772

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.49963
Value Function Update Magnitude: 0.71423

Collected Steps per Second: 22,631.54768
Overall Steps per Second: 10,842.42358

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.61336

Cumulative Model Updates: 121,424
Cumulative Timesteps: 1,012,542,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1012542324...
Checkpoint 1012542324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,937.29031
Policy Entropy: 3.78079
Value Function Loss: 0.02911

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.51880
Value Function Update Magnitude: 0.68494

Collected Steps per Second: 22,708.38127
Overall Steps per Second: 10,696.62543

Timestep Collection Time: 2.20253
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.67587

Cumulative Model Updates: 121,430
Cumulative Timesteps: 1,012,592,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.27537
Policy Entropy: 3.78704
Value Function Loss: 0.02837

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.68486

Collected Steps per Second: 22,996.85840
Overall Steps per Second: 10,873.87999

Timestep Collection Time: 2.17482
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.59946

Cumulative Model Updates: 121,436
Cumulative Timesteps: 1,012,642,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1012642354...
Checkpoint 1012642354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.87993
Policy Entropy: 3.77346
Value Function Loss: 0.02837

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.51873
Value Function Update Magnitude: 0.68108

Collected Steps per Second: 22,636.00465
Overall Steps per Second: 10,594.75531

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.51105
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.72045

Cumulative Model Updates: 121,442
Cumulative Timesteps: 1,012,692,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,879.58569
Policy Entropy: 3.75648
Value Function Loss: 0.02528

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.48910
Value Function Update Magnitude: 0.67208

Collected Steps per Second: 22,812.62576
Overall Steps per Second: 10,719.21934

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.47423
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.66732

Cumulative Model Updates: 121,448
Cumulative Timesteps: 1,012,742,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1012742396...
Checkpoint 1012742396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,044.69248
Policy Entropy: 3.73324
Value Function Loss: 0.02901

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.47634
Value Function Update Magnitude: 0.58733

Collected Steps per Second: 22,771.75641
Overall Steps per Second: 10,845.00384

Timestep Collection Time: 2.19667
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.61245

Cumulative Model Updates: 121,454
Cumulative Timesteps: 1,012,792,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,793.44200
Policy Entropy: 3.74771
Value Function Loss: 0.03018

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.69764

Collected Steps per Second: 23,119.66318
Overall Steps per Second: 10,893.44893

Timestep Collection Time: 2.16448
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.59377

Cumulative Model Updates: 121,460
Cumulative Timesteps: 1,012,842,460

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1012842460...
Checkpoint 1012842460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.59180
Policy Entropy: 3.74638
Value Function Loss: 0.02768

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.78029

Collected Steps per Second: 22,687.19865
Overall Steps per Second: 10,658.05055

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69223

Cumulative Model Updates: 121,466
Cumulative Timesteps: 1,012,892,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,188.96308
Policy Entropy: 3.76468
Value Function Loss: 0.02449

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.48134
Value Function Update Magnitude: 0.75244

Collected Steps per Second: 22,963.05281
Overall Steps per Second: 10,728.84529

Timestep Collection Time: 2.17828
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.66220

Cumulative Model Updates: 121,472
Cumulative Timesteps: 1,012,942,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1012942490...
Checkpoint 1012942490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,266.21993
Policy Entropy: 3.75071
Value Function Loss: 0.02222

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.46312
Value Function Update Magnitude: 0.74824

Collected Steps per Second: 22,729.49933
Overall Steps per Second: 10,825.37840

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.62062

Cumulative Model Updates: 121,478
Cumulative Timesteps: 1,012,992,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,266.21993
Policy Entropy: 3.73552
Value Function Loss: 0.02275

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.45777
Value Function Update Magnitude: 0.58853

Collected Steps per Second: 22,717.73552
Overall Steps per Second: 10,670.52284

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.68637

Cumulative Model Updates: 121,484
Cumulative Timesteps: 1,013,042,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1013042516...
Checkpoint 1013042516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,266.21993
Policy Entropy: 3.73267
Value Function Loss: 0.01842

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.46030
Value Function Update Magnitude: 0.54582

Collected Steps per Second: 22,405.54575
Overall Steps per Second: 10,593.03907

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.72197

Cumulative Model Updates: 121,490
Cumulative Timesteps: 1,013,092,536

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,594.28771
Policy Entropy: 3.71938
Value Function Loss: 0.01733

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.41199
Value Function Update Magnitude: 0.49938

Collected Steps per Second: 22,916.25283
Overall Steps per Second: 10,801.61352

Timestep Collection Time: 2.18282
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63097

Cumulative Model Updates: 121,496
Cumulative Timesteps: 1,013,142,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1013142558...
Checkpoint 1013142558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,935.43342
Policy Entropy: 3.73034
Value Function Loss: 0.01644

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.39994
Value Function Update Magnitude: 0.60283

Collected Steps per Second: 22,602.55446
Overall Steps per Second: 10,652.10700

Timestep Collection Time: 2.21302
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69578

Cumulative Model Updates: 121,502
Cumulative Timesteps: 1,013,192,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,174.52373
Policy Entropy: 3.74578
Value Function Loss: 0.01878

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.42268
Value Function Update Magnitude: 0.66608

Collected Steps per Second: 22,854.75694
Overall Steps per Second: 10,824.63581

Timestep Collection Time: 2.18808
Timestep Consumption Time: 2.43175
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.61983

Cumulative Model Updates: 121,508
Cumulative Timesteps: 1,013,242,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1013242586...
Checkpoint 1013242586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,874.89015
Policy Entropy: 3.76439
Value Function Loss: 0.01971

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.47185
Value Function Update Magnitude: 0.70350

Collected Steps per Second: 22,636.72849
Overall Steps per Second: 10,676.92289

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.68393

Cumulative Model Updates: 121,514
Cumulative Timesteps: 1,013,292,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,654.06385
Policy Entropy: 3.76227
Value Function Loss: 0.02305

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.48003
Value Function Update Magnitude: 0.62114

Collected Steps per Second: 23,284.70034
Overall Steps per Second: 10,891.76322

Timestep Collection Time: 2.14819
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59246

Cumulative Model Updates: 121,520
Cumulative Timesteps: 1,013,342,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1013342616...
Checkpoint 1013342616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,654.06385
Policy Entropy: 3.73906
Value Function Loss: 0.02207

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.49376
Value Function Update Magnitude: 0.64099

Collected Steps per Second: 22,342.51340
Overall Steps per Second: 10,725.89961

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66292

Cumulative Model Updates: 121,526
Cumulative Timesteps: 1,013,392,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,528.06229
Policy Entropy: 3.73834
Value Function Loss: 0.02512

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.50975
Value Function Update Magnitude: 0.69931

Collected Steps per Second: 22,470.54981
Overall Steps per Second: 10,857.87529

Timestep Collection Time: 2.22522
Timestep Consumption Time: 2.37991
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.60514

Cumulative Model Updates: 121,532
Cumulative Timesteps: 1,013,442,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1013442632...
Checkpoint 1013442632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,750.83248
Policy Entropy: 3.73841
Value Function Loss: 0.02499

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.56796
Value Function Update Magnitude: 0.79435

Collected Steps per Second: 21,904.00819
Overall Steps per Second: 10,662.37716

Timestep Collection Time: 2.28342
Timestep Consumption Time: 2.40747
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69089

Cumulative Model Updates: 121,538
Cumulative Timesteps: 1,013,492,648

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,766.33763
Policy Entropy: 3.76375
Value Function Loss: 0.02519

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.62037
Value Function Update Magnitude: 0.99228

Collected Steps per Second: 22,380.75268
Overall Steps per Second: 10,689.16608

Timestep Collection Time: 2.23451
Timestep Consumption Time: 2.44406
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.67857

Cumulative Model Updates: 121,544
Cumulative Timesteps: 1,013,542,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1013542658...
Checkpoint 1013542658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,777.41101
Policy Entropy: 3.75156
Value Function Loss: 0.02526

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.63146
Value Function Update Magnitude: 1.12176

Collected Steps per Second: 22,889.79472
Overall Steps per Second: 10,870.97382

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.41647
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.60216

Cumulative Model Updates: 121,550
Cumulative Timesteps: 1,013,592,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,052.47640
Policy Entropy: 3.76172
Value Function Loss: 0.02750

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.63430
Value Function Update Magnitude: 1.03982

Collected Steps per Second: 22,989.48409
Overall Steps per Second: 10,959.81917

Timestep Collection Time: 2.17586
Timestep Consumption Time: 2.38826
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.56413

Cumulative Model Updates: 121,556
Cumulative Timesteps: 1,013,642,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1013642710...
Checkpoint 1013642710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,781.86346
Policy Entropy: 3.75263
Value Function Loss: 0.02895

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.61298
Value Function Update Magnitude: 0.93704

Collected Steps per Second: 22,887.12233
Overall Steps per Second: 10,941.94348

Timestep Collection Time: 2.18481
Timestep Consumption Time: 2.38513
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.56994

Cumulative Model Updates: 121,562
Cumulative Timesteps: 1,013,692,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,080.99608
Policy Entropy: 3.75657
Value Function Loss: 0.02799

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.60624
Value Function Update Magnitude: 0.76954

Collected Steps per Second: 22,469.94084
Overall Steps per Second: 10,573.63246

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.50355
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.72874

Cumulative Model Updates: 121,568
Cumulative Timesteps: 1,013,742,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1013742714...
Checkpoint 1013742714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,504.07053
Policy Entropy: 3.75216
Value Function Loss: 0.02496

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.66126

Collected Steps per Second: 22,914.74472
Overall Steps per Second: 10,698.69004

Timestep Collection Time: 2.18279
Timestep Consumption Time: 2.49237
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67515

Cumulative Model Updates: 121,574
Cumulative Timesteps: 1,013,792,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,688.93037
Policy Entropy: 3.75221
Value Function Loss: 0.02621

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.52242
Value Function Update Magnitude: 0.62283

Collected Steps per Second: 22,716.46452
Overall Steps per Second: 10,822.08340

Timestep Collection Time: 2.20140
Timestep Consumption Time: 2.41952
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.62092

Cumulative Model Updates: 121,580
Cumulative Timesteps: 1,013,842,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1013842740...
Checkpoint 1013842740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,899.53261
Policy Entropy: 3.74515
Value Function Loss: 0.02800

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.58484
Value Function Update Magnitude: 0.71987

Collected Steps per Second: 22,431.60218
Overall Steps per Second: 10,596.90593

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.72006

Cumulative Model Updates: 121,586
Cumulative Timesteps: 1,013,892,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,344.09131
Policy Entropy: 3.73964
Value Function Loss: 0.02796

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.63270
Value Function Update Magnitude: 0.69812

Collected Steps per Second: 22,575.63499
Overall Steps per Second: 10,597.37796

Timestep Collection Time: 2.21504
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.71871

Cumulative Model Updates: 121,592
Cumulative Timesteps: 1,013,942,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1013942764...
Checkpoint 1013942764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,020.94498
Policy Entropy: 3.75311
Value Function Loss: 0.02723

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.57731
Value Function Update Magnitude: 0.59395

Collected Steps per Second: 22,709.13000
Overall Steps per Second: 10,720.84107

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.66456

Cumulative Model Updates: 121,598
Cumulative Timesteps: 1,013,992,772

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.24044
Policy Entropy: 3.76694
Value Function Loss: 0.02456

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.52803
Value Function Update Magnitude: 0.56830

Collected Steps per Second: 22,943.91802
Overall Steps per Second: 10,679.54037

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.50312
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68279

Cumulative Model Updates: 121,604
Cumulative Timesteps: 1,014,042,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1014042782...
Checkpoint 1014042782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,719.12643
Policy Entropy: 3.75792
Value Function Loss: 0.02740

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.48167
Value Function Update Magnitude: 0.59914

Collected Steps per Second: 22,763.77999
Overall Steps per Second: 10,651.91791

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69474

Cumulative Model Updates: 121,610
Cumulative Timesteps: 1,014,092,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,907.50463
Policy Entropy: 3.76640
Value Function Loss: 0.02528

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.66626

Collected Steps per Second: 23,030.68144
Overall Steps per Second: 10,890.49307

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.59134

Cumulative Model Updates: 121,616
Cumulative Timesteps: 1,014,142,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1014142792...
Checkpoint 1014142792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.84556
Policy Entropy: 3.75841
Value Function Loss: 0.02825

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.51975
Value Function Update Magnitude: 0.68650

Collected Steps per Second: 22,778.47155
Overall Steps per Second: 10,641.28296

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.69925

Cumulative Model Updates: 121,622
Cumulative Timesteps: 1,014,192,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408.59747
Policy Entropy: 3.75707
Value Function Loss: 0.02475

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.51700
Value Function Update Magnitude: 0.76816

Collected Steps per Second: 22,927.41986
Overall Steps per Second: 10,861.01025

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.60602

Cumulative Model Updates: 121,628
Cumulative Timesteps: 1,014,242,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1014242824...
Checkpoint 1014242824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,432.83794
Policy Entropy: 3.74145
Value Function Loss: 0.02552

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.79030

Collected Steps per Second: 22,942.43523
Overall Steps per Second: 10,669.44129

Timestep Collection Time: 2.17937
Timestep Consumption Time: 2.50691
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.68628

Cumulative Model Updates: 121,634
Cumulative Timesteps: 1,014,292,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,135.45327
Policy Entropy: 3.73036
Value Function Loss: 0.02638

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.50768
Value Function Update Magnitude: 0.66288

Collected Steps per Second: 22,677.35805
Overall Steps per Second: 10,694.75912

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.67743

Cumulative Model Updates: 121,640
Cumulative Timesteps: 1,014,342,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1014342848...
Checkpoint 1014342848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,135.45327
Policy Entropy: 3.72708
Value Function Loss: 0.02171

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.46154
Value Function Update Magnitude: 0.68445

Collected Steps per Second: 21,867.40674
Overall Steps per Second: 10,778.05746

Timestep Collection Time: 2.28669
Timestep Consumption Time: 2.35274
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63943

Cumulative Model Updates: 121,646
Cumulative Timesteps: 1,014,392,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,043.49832
Policy Entropy: 3.72358
Value Function Loss: 0.02285

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.45771
Value Function Update Magnitude: 0.67736

Collected Steps per Second: 21,823.42538
Overall Steps per Second: 10,586.92739

Timestep Collection Time: 2.29185
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.72432

Cumulative Model Updates: 121,652
Cumulative Timesteps: 1,014,442,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1014442868...
Checkpoint 1014442868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,023.31630
Policy Entropy: 3.74219
Value Function Loss: 0.02245

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.46480
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 22,117.64051
Overall Steps per Second: 10,705.46571

Timestep Collection Time: 2.26181
Timestep Consumption Time: 2.41113
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.67294

Cumulative Model Updates: 121,658
Cumulative Timesteps: 1,014,492,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,204.64255
Policy Entropy: 3.75289
Value Function Loss: 0.02592

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.47327
Value Function Update Magnitude: 0.59271

Collected Steps per Second: 21,874.60942
Overall Steps per Second: 10,769.95859

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.35773
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64440

Cumulative Model Updates: 121,664
Cumulative Timesteps: 1,014,542,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1014542914...
Checkpoint 1014542914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,439.21341
Policy Entropy: 3.76940
Value Function Loss: 0.02734

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.70195

Collected Steps per Second: 21,981.30262
Overall Steps per Second: 10,721.64075

Timestep Collection Time: 2.27575
Timestep Consumption Time: 2.38995
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.66570

Cumulative Model Updates: 121,670
Cumulative Timesteps: 1,014,592,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,310.96961
Policy Entropy: 3.74850
Value Function Loss: 0.02993

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.72565

Collected Steps per Second: 22,599.38968
Overall Steps per Second: 10,823.09897

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.40865
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.62234

Cumulative Model Updates: 121,676
Cumulative Timesteps: 1,014,642,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1014642966...
Checkpoint 1014642966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,167.46363
Policy Entropy: 3.74036
Value Function Loss: 0.02911

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.69183

Collected Steps per Second: 22,775.62655
Overall Steps per Second: 10,701.33716

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.67250

Cumulative Model Updates: 121,682
Cumulative Timesteps: 1,014,692,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,235.72903
Policy Entropy: 3.72110
Value Function Loss: 0.02751

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.68419

Collected Steps per Second: 23,367.38305
Overall Steps per Second: 10,837.25861

Timestep Collection Time: 2.14042
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.61519

Cumulative Model Updates: 121,688
Cumulative Timesteps: 1,014,742,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1014742984...
Checkpoint 1014742984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,874.95853
Policy Entropy: 3.73023
Value Function Loss: 0.02148

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.53737
Value Function Update Magnitude: 0.72588

Collected Steps per Second: 22,572.12048
Overall Steps per Second: 10,714.90657

Timestep Collection Time: 2.21565
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.66752

Cumulative Model Updates: 121,694
Cumulative Timesteps: 1,014,792,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,625.28980
Policy Entropy: 3.73654
Value Function Loss: 0.02263

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.47650
Value Function Update Magnitude: 0.66447

Collected Steps per Second: 23,081.09075
Overall Steps per Second: 10,906.33064

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.58651

Cumulative Model Updates: 121,700
Cumulative Timesteps: 1,014,843,018

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1014843018...
Checkpoint 1014843018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,491.82603
Policy Entropy: 3.75196
Value Function Loss: 0.02266

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.48868
Value Function Update Magnitude: 0.65228

Collected Steps per Second: 23,061.01372
Overall Steps per Second: 10,724.40134

Timestep Collection Time: 2.16912
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.66432

Cumulative Model Updates: 121,706
Cumulative Timesteps: 1,014,893,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 653.52662
Policy Entropy: 3.76082
Value Function Loss: 0.02605

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.71916

Collected Steps per Second: 22,776.71060
Overall Steps per Second: 10,884.67312

Timestep Collection Time: 2.19619
Timestep Consumption Time: 2.39945
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.59564

Cumulative Model Updates: 121,712
Cumulative Timesteps: 1,014,943,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1014943062...
Checkpoint 1014943062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,603.49709
Policy Entropy: 3.75636
Value Function Loss: 0.02715

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.65335

Collected Steps per Second: 22,764.02705
Overall Steps per Second: 10,710.06126

Timestep Collection Time: 2.19671
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66907

Cumulative Model Updates: 121,718
Cumulative Timesteps: 1,014,993,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,847.02739
Policy Entropy: 3.76028
Value Function Loss: 0.02642

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.63190
Value Function Update Magnitude: 0.61669

Collected Steps per Second: 22,882.41037
Overall Steps per Second: 10,774.67189

Timestep Collection Time: 2.18535
Timestep Consumption Time: 2.45572
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.64107

Cumulative Model Updates: 121,724
Cumulative Timesteps: 1,015,043,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1015043074...
Checkpoint 1015043074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,847.02739
Policy Entropy: 3.75122
Value Function Loss: 0.02479

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.59517

Collected Steps per Second: 22,785.17234
Overall Steps per Second: 10,662.12859

Timestep Collection Time: 2.19538
Timestep Consumption Time: 2.49618
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.69156

Cumulative Model Updates: 121,730
Cumulative Timesteps: 1,015,093,096

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,114.31705
Policy Entropy: 3.74169
Value Function Loss: 0.02280

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.54873
Value Function Update Magnitude: 0.61248

Collected Steps per Second: 22,883.47734
Overall Steps per Second: 10,859.12965

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60663

Cumulative Model Updates: 121,736
Cumulative Timesteps: 1,015,143,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1015143120...
Checkpoint 1015143120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,823.96214
Policy Entropy: 3.73094
Value Function Loss: 0.02382

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14632
Policy Update Magnitude: 0.55193
Value Function Update Magnitude: 0.69209

Collected Steps per Second: 22,883.93605
Overall Steps per Second: 10,691.65205

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.67729

Cumulative Model Updates: 121,742
Cumulative Timesteps: 1,015,193,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,061.68876
Policy Entropy: 3.73558
Value Function Loss: 0.02415

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.55584
Value Function Update Magnitude: 0.88084

Collected Steps per Second: 22,300.02360
Overall Steps per Second: 10,926.39053

Timestep Collection Time: 2.24403
Timestep Consumption Time: 2.33589
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.57992

Cumulative Model Updates: 121,748
Cumulative Timesteps: 1,015,243,170

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1015243170...
Checkpoint 1015243170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,388.04563
Policy Entropy: 3.73939
Value Function Loss: 0.02298

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.51588
Value Function Update Magnitude: 0.90496

Collected Steps per Second: 21,910.05983
Overall Steps per Second: 10,621.06083

Timestep Collection Time: 2.28233
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.70819

Cumulative Model Updates: 121,754
Cumulative Timesteps: 1,015,293,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,334.19530
Policy Entropy: 3.73617
Value Function Loss: 0.02308

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.50081
Value Function Update Magnitude: 0.83161

Collected Steps per Second: 21,875.49171
Overall Steps per Second: 10,505.33161

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.76158

Cumulative Model Updates: 121,760
Cumulative Timesteps: 1,015,343,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1015343198...
Checkpoint 1015343198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,738.83789
Policy Entropy: 3.72939
Value Function Loss: 0.02087

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.49449
Value Function Update Magnitude: 0.76310

Collected Steps per Second: 22,712.18935
Overall Steps per Second: 10,707.93363

Timestep Collection Time: 2.20261
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.67186

Cumulative Model Updates: 121,766
Cumulative Timesteps: 1,015,393,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,738.83789
Policy Entropy: 3.72616
Value Function Loss: 0.01965

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.46690
Value Function Update Magnitude: 0.67832

Collected Steps per Second: 23,054.62909
Overall Steps per Second: 10,738.03724

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.65690

Cumulative Model Updates: 121,772
Cumulative Timesteps: 1,015,443,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1015443230...
Checkpoint 1015443230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,738.83789
Policy Entropy: 3.72260
Value Function Loss: 0.01746

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.45719
Value Function Update Magnitude: 0.65576

Collected Steps per Second: 22,904.03234
Overall Steps per Second: 10,680.75549

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.68207

Cumulative Model Updates: 121,778
Cumulative Timesteps: 1,015,493,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,147.05265
Policy Entropy: 3.72890
Value Function Loss: 0.01910

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.45388
Value Function Update Magnitude: 0.64817

Collected Steps per Second: 22,674.13088
Overall Steps per Second: 10,813.12592

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.41905
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.62438

Cumulative Model Updates: 121,784
Cumulative Timesteps: 1,015,543,242

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1015543242...
Checkpoint 1015543242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,068.18509
Policy Entropy: 3.72993
Value Function Loss: 0.01980

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.45114
Value Function Update Magnitude: 0.54940

Collected Steps per Second: 22,647.52707
Overall Steps per Second: 10,732.04740

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.45159
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.65969

Cumulative Model Updates: 121,790
Cumulative Timesteps: 1,015,593,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,395.49964
Policy Entropy: 3.73698
Value Function Loss: 0.02454

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.46854
Value Function Update Magnitude: 0.56576

Collected Steps per Second: 22,746.60089
Overall Steps per Second: 10,802.56580

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62983

Cumulative Model Updates: 121,796
Cumulative Timesteps: 1,015,643,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1015643264...
Checkpoint 1015643264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,275.95059
Policy Entropy: 3.75250
Value Function Loss: 0.02199

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.51295
Value Function Update Magnitude: 0.67086

Collected Steps per Second: 22,824.95326
Overall Steps per Second: 10,689.59949

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67913

Cumulative Model Updates: 121,802
Cumulative Timesteps: 1,015,693,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,928.13105
Policy Entropy: 3.75266
Value Function Loss: 0.02793

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.77237

Collected Steps per Second: 22,620.85452
Overall Steps per Second: 10,686.10349

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.67972

Cumulative Model Updates: 121,808
Cumulative Timesteps: 1,015,743,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1015743290...
Checkpoint 1015743290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,234.07132
Policy Entropy: 3.77068
Value Function Loss: 0.02834

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.64846
Value Function Update Magnitude: 0.73283

Collected Steps per Second: 22,801.61189
Overall Steps per Second: 10,817.48775

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.62455

Cumulative Model Updates: 121,814
Cumulative Timesteps: 1,015,793,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,890.08168
Policy Entropy: 3.75443
Value Function Loss: 0.02902

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.63689
Value Function Update Magnitude: 0.91771

Collected Steps per Second: 21,896.84603
Overall Steps per Second: 10,639.23209

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.41673
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.70072

Cumulative Model Updates: 121,820
Cumulative Timesteps: 1,015,843,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1015843328...
Checkpoint 1015843328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,975.12134
Policy Entropy: 3.76373
Value Function Loss: 0.02837

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.63286
Value Function Update Magnitude: 0.95201

Collected Steps per Second: 22,080.01549
Overall Steps per Second: 10,764.00950

Timestep Collection Time: 2.26567
Timestep Consumption Time: 2.38186
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.64752

Cumulative Model Updates: 121,826
Cumulative Timesteps: 1,015,893,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,318.66781
Policy Entropy: 3.74651
Value Function Loss: 0.02793

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.70149
Value Function Update Magnitude: 0.84282

Collected Steps per Second: 21,654.68061
Overall Steps per Second: 10,690.86047

Timestep Collection Time: 2.31017
Timestep Consumption Time: 2.36915
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.67932

Cumulative Model Updates: 121,832
Cumulative Timesteps: 1,015,943,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1015943380...
Checkpoint 1015943380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,174.27339
Policy Entropy: 3.74539
Value Function Loss: 0.02793

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.69374
Value Function Update Magnitude: 0.78260

Collected Steps per Second: 22,134.52703
Overall Steps per Second: 10,612.38850

Timestep Collection Time: 2.25937
Timestep Consumption Time: 2.45305
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.71242

Cumulative Model Updates: 121,838
Cumulative Timesteps: 1,015,993,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.69646
Policy Entropy: 3.75068
Value Function Loss: 0.02838

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.65138
Value Function Update Magnitude: 0.79553

Collected Steps per Second: 22,899.25860
Overall Steps per Second: 10,888.65940

Timestep Collection Time: 2.18391
Timestep Consumption Time: 2.40894
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59285

Cumulative Model Updates: 121,844
Cumulative Timesteps: 1,016,043,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1016043400...
Checkpoint 1016043400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,997.58111
Policy Entropy: 3.76060
Value Function Loss: 0.02998

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.60592
Value Function Update Magnitude: 0.74493

Collected Steps per Second: 22,754.91178
Overall Steps per Second: 10,710.95190

Timestep Collection Time: 2.19847
Timestep Consumption Time: 2.47208
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.67055

Cumulative Model Updates: 121,850
Cumulative Timesteps: 1,016,093,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,403.62173
Policy Entropy: 3.77421
Value Function Loss: 0.03071

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.71486
Value Function Update Magnitude: 0.72513

Collected Steps per Second: 22,748.92971
Overall Steps per Second: 10,897.43660

Timestep Collection Time: 2.19791
Timestep Consumption Time: 2.39033
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.58824

Cumulative Model Updates: 121,856
Cumulative Timesteps: 1,016,143,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1016143426...
Checkpoint 1016143426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,576.73490
Policy Entropy: 3.77437
Value Function Loss: 0.03104

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.68189
Value Function Update Magnitude: 0.75246

Collected Steps per Second: 22,744.77504
Overall Steps per Second: 10,756.03306

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.65097

Cumulative Model Updates: 121,862
Cumulative Timesteps: 1,016,193,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,352.16535
Policy Entropy: 3.78273
Value Function Loss: 0.02972

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16560
Policy Update Magnitude: 0.63251
Value Function Update Magnitude: 0.66276

Collected Steps per Second: 22,759.79725
Overall Steps per Second: 10,729.31604

Timestep Collection Time: 2.19694
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.66032

Cumulative Model Updates: 121,868
Cumulative Timesteps: 1,016,243,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1016243454...
Checkpoint 1016243454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,356.74976
Policy Entropy: 3.74404
Value Function Loss: 0.02673

Mean KL Divergence: 0.02592
SB3 Clip Fraction: 0.26017
Policy Update Magnitude: 0.56685
Value Function Update Magnitude: 0.66379

Collected Steps per Second: 22,310.74873
Overall Steps per Second: 10,681.52187

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.68379

Cumulative Model Updates: 121,874
Cumulative Timesteps: 1,016,293,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,459.40949
Policy Entropy: 3.76132
Value Function Loss: 0.03442

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.20548
Policy Update Magnitude: 0.56087
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 22,096.40858
Overall Steps per Second: 10,491.61222

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.76781

Cumulative Model Updates: 121,880
Cumulative Timesteps: 1,016,343,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1016343506...
Checkpoint 1016343506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,043.20579
Policy Entropy: 3.76812
Value Function Loss: 0.04011

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.21850
Policy Update Magnitude: 0.74094
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 21,920.26577
Overall Steps per Second: 10,585.01273

Timestep Collection Time: 2.28182
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.72536

Cumulative Model Updates: 121,886
Cumulative Timesteps: 1,016,393,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.22406
Policy Entropy: 3.82059
Value Function Loss: 0.03695

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.18753
Policy Update Magnitude: 0.80763
Value Function Update Magnitude: 0.69328

Collected Steps per Second: 22,041.42480
Overall Steps per Second: 10,580.32543

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.72726

Cumulative Model Updates: 121,892
Cumulative Timesteps: 1,016,443,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1016443540...
Checkpoint 1016443540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,244.22603
Policy Entropy: 3.87463
Value Function Loss: 0.03117

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.86198
Value Function Update Magnitude: 0.77552

Collected Steps per Second: 22,192.14992
Overall Steps per Second: 10,517.87374

Timestep Collection Time: 2.25368
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.75514

Cumulative Model Updates: 121,898
Cumulative Timesteps: 1,016,493,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,066.00985
Policy Entropy: 3.87965
Value Function Loss: 0.02986

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.93526
Value Function Update Magnitude: 0.76599

Collected Steps per Second: 21,879.56125
Overall Steps per Second: 10,431.15308

Timestep Collection Time: 2.28542
Timestep Consumption Time: 2.50830
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.79372

Cumulative Model Updates: 121,904
Cumulative Timesteps: 1,016,543,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1016543558...
Checkpoint 1016543558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,866.74858
Policy Entropy: 3.86100
Value Function Loss: 0.02930

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.97426
Value Function Update Magnitude: 0.73303

Collected Steps per Second: 22,271.02177
Overall Steps per Second: 10,658.62208

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69291

Cumulative Model Updates: 121,910
Cumulative Timesteps: 1,016,593,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,407.64842
Policy Entropy: 3.86090
Value Function Loss: 0.03069

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 1.01025
Value Function Update Magnitude: 0.78768

Collected Steps per Second: 22,298.84916
Overall Steps per Second: 10,566.79049

Timestep Collection Time: 2.24308
Timestep Consumption Time: 2.49043
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.73351

Cumulative Model Updates: 121,916
Cumulative Timesteps: 1,016,643,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1016643596...
Checkpoint 1016643596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,968.96064
Policy Entropy: 3.85706
Value Function Loss: 0.03008

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 1.03913
Value Function Update Magnitude: 0.79360

Collected Steps per Second: 22,559.51965
Overall Steps per Second: 10,725.87896

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.44644
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66386

Cumulative Model Updates: 121,922
Cumulative Timesteps: 1,016,693,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,288.74433
Policy Entropy: 3.88835
Value Function Loss: 0.03086

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.08284
Policy Update Magnitude: 1.03992
Value Function Update Magnitude: 0.87819

Collected Steps per Second: 22,850.38912
Overall Steps per Second: 10,713.56356

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66810

Cumulative Model Updates: 121,928
Cumulative Timesteps: 1,016,743,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1016743632...
Checkpoint 1016743632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.64801
Policy Entropy: 3.88670
Value Function Loss: 0.03114

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07524
Policy Update Magnitude: 1.02436
Value Function Update Magnitude: 0.89905

Collected Steps per Second: 22,615.75961
Overall Steps per Second: 10,676.30091

Timestep Collection Time: 2.21164
Timestep Consumption Time: 2.47331
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.68496

Cumulative Model Updates: 121,934
Cumulative Timesteps: 1,016,793,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,785.38636
Policy Entropy: 3.88793
Value Function Loss: 0.03092

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07764
Policy Update Magnitude: 1.00667
Value Function Update Magnitude: 0.78944

Collected Steps per Second: 22,847.61081
Overall Steps per Second: 10,832.91592

Timestep Collection Time: 2.18859
Timestep Consumption Time: 2.42734
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.61593

Cumulative Model Updates: 121,940
Cumulative Timesteps: 1,016,843,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1016843654...
Checkpoint 1016843654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.63792
Policy Entropy: 3.88635
Value Function Loss: 0.03178

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07154
Policy Update Magnitude: 0.97650
Value Function Update Magnitude: 0.77841

Collected Steps per Second: 22,486.38310
Overall Steps per Second: 10,615.61167

Timestep Collection Time: 2.22437
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.71174

Cumulative Model Updates: 121,946
Cumulative Timesteps: 1,016,893,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,549.03518
Policy Entropy: 3.89933
Value Function Loss: 0.03004

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07951
Policy Update Magnitude: 0.92855
Value Function Update Magnitude: 0.76389

Collected Steps per Second: 22,489.69575
Overall Steps per Second: 10,681.54123

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.68228

Cumulative Model Updates: 121,952
Cumulative Timesteps: 1,016,943,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1016943686...
Checkpoint 1016943686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,621.73082
Policy Entropy: 3.88283
Value Function Loss: 0.03239

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08000
Policy Update Magnitude: 0.91049
Value Function Update Magnitude: 0.68600

Collected Steps per Second: 22,913.25351
Overall Steps per Second: 10,898.95929

Timestep Collection Time: 2.18267
Timestep Consumption Time: 2.40603
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.58869

Cumulative Model Updates: 121,958
Cumulative Timesteps: 1,016,993,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438.55646
Policy Entropy: 3.86419
Value Function Loss: 0.03311

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.91875
Value Function Update Magnitude: 0.81445

Collected Steps per Second: 23,079.07550
Overall Steps per Second: 10,947.91396

Timestep Collection Time: 2.16750
Timestep Consumption Time: 2.40177
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.56927

Cumulative Model Updates: 121,964
Cumulative Timesteps: 1,017,043,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1017043722...
Checkpoint 1017043722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.98491
Policy Entropy: 3.83207
Value Function Loss: 0.03173

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.90000
Value Function Update Magnitude: 0.87719

Collected Steps per Second: 23,003.64129
Overall Steps per Second: 10,961.47199

Timestep Collection Time: 2.17513
Timestep Consumption Time: 2.38958
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.56472

Cumulative Model Updates: 121,970
Cumulative Timesteps: 1,017,093,758

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,517.67043
Policy Entropy: 3.80169
Value Function Loss: 0.02969

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.75072
Value Function Update Magnitude: 0.89428

Collected Steps per Second: 22,485.55241
Overall Steps per Second: 10,701.82860

Timestep Collection Time: 2.22392
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.67266

Cumulative Model Updates: 121,976
Cumulative Timesteps: 1,017,143,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1017143764...
Checkpoint 1017143764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,233.88463
Policy Entropy: 3.76644
Value Function Loss: 0.03206

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15031
Policy Update Magnitude: 0.59765
Value Function Update Magnitude: 0.70702

Collected Steps per Second: 22,858.78020
Overall Steps per Second: 10,849.91147

Timestep Collection Time: 2.18752
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60870

Cumulative Model Updates: 121,982
Cumulative Timesteps: 1,017,193,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,546.84965
Policy Entropy: 3.76453
Value Function Loss: 0.03557

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.21691
Policy Update Magnitude: 0.55911
Value Function Update Magnitude: 0.61446

Collected Steps per Second: 22,640.63939
Overall Steps per Second: 10,735.11179

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.45027
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.65966

Cumulative Model Updates: 121,988
Cumulative Timesteps: 1,017,243,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1017243790...
Checkpoint 1017243790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,993.20652
Policy Entropy: 3.81067
Value Function Loss: 0.03736

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.16956
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 23,119.43084
Overall Steps per Second: 10,908.47697

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.58616

Cumulative Model Updates: 121,994
Cumulative Timesteps: 1,017,293,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.29862
Policy Entropy: 3.86010
Value Function Loss: 0.03632

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.69728
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 22,806.89471
Overall Steps per Second: 10,877.18776

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59678

Cumulative Model Updates: 122,000
Cumulative Timesteps: 1,017,343,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1017343818...
Checkpoint 1017343818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50221
Policy Entropy: 3.86936
Value Function Loss: 0.03198

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11417
Policy Update Magnitude: 0.68740
Value Function Update Magnitude: 0.73417

Collected Steps per Second: 22,963.06120
Overall Steps per Second: 10,770.93932

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.64416

Cumulative Model Updates: 122,006
Cumulative Timesteps: 1,017,393,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,925.02359
Policy Entropy: 3.84973
Value Function Loss: 0.03077

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.52353
Value Function Update Magnitude: 0.77726

Collected Steps per Second: 23,078.00506
Overall Steps per Second: 10,783.79056

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.47210
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.64048

Cumulative Model Updates: 122,012
Cumulative Timesteps: 1,017,443,882

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1017443882...
Checkpoint 1017443882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.55429
Policy Entropy: 3.83981
Value Function Loss: 0.02916

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.48150
Value Function Update Magnitude: 0.62391

Collected Steps per Second: 23,036.21685
Overall Steps per Second: 10,720.53656

Timestep Collection Time: 2.17145
Timestep Consumption Time: 2.49455
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.66600

Cumulative Model Updates: 122,018
Cumulative Timesteps: 1,017,493,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,390.09270
Policy Entropy: 3.81570
Value Function Loss: 0.03277

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.45556
Value Function Update Magnitude: 0.48308

Collected Steps per Second: 22,803.28658
Overall Steps per Second: 10,862.52000

Timestep Collection Time: 2.19416
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.60611

Cumulative Model Updates: 122,024
Cumulative Timesteps: 1,017,543,938

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1017543938...
Checkpoint 1017543938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,461.38970
Policy Entropy: 3.82132
Value Function Loss: 0.03083

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.49989
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 23,023.59626
Overall Steps per Second: 10,725.13186

Timestep Collection Time: 2.17264
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.66400

Cumulative Model Updates: 122,030
Cumulative Timesteps: 1,017,593,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,142.41912
Policy Entropy: 3.78309
Value Function Loss: 0.03177

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.51680
Value Function Update Magnitude: 0.74069

Collected Steps per Second: 23,013.85004
Overall Steps per Second: 10,851.09064

Timestep Collection Time: 2.17356
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.60986

Cumulative Model Updates: 122,036
Cumulative Timesteps: 1,017,643,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1017643982...
Checkpoint 1017643982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.37538
Policy Entropy: 3.77744
Value Function Loss: 0.02680

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.72715

Collected Steps per Second: 23,273.30702
Overall Steps per Second: 10,781.12782

Timestep Collection Time: 2.14916
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.63940

Cumulative Model Updates: 122,042
Cumulative Timesteps: 1,017,694,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,236.47190
Policy Entropy: 3.74998
Value Function Loss: 0.02564

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.49514
Value Function Update Magnitude: 0.62848

Collected Steps per Second: 23,006.73354
Overall Steps per Second: 10,774.71237

Timestep Collection Time: 2.17415
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.64235

Cumulative Model Updates: 122,048
Cumulative Timesteps: 1,017,744,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1017744020...
Checkpoint 1017744020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,236.47190
Policy Entropy: 3.75036
Value Function Loss: 0.02247

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.44866
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 22,952.95365
Overall Steps per Second: 10,692.33123

Timestep Collection Time: 2.17941
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.67849

Cumulative Model Updates: 122,054
Cumulative Timesteps: 1,017,794,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,266.18159
Policy Entropy: 3.73014
Value Function Loss: 0.02287

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.40257
Value Function Update Magnitude: 0.52094

Collected Steps per Second: 22,943.71444
Overall Steps per Second: 10,812.43447

Timestep Collection Time: 2.17951
Timestep Consumption Time: 2.44535
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.62486

Cumulative Model Updates: 122,060
Cumulative Timesteps: 1,017,844,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1017844050...
Checkpoint 1017844050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,584.51524
Policy Entropy: 3.72515
Value Function Loss: 0.02219

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.37618
Value Function Update Magnitude: 0.48986

Collected Steps per Second: 22,828.50736
Overall Steps per Second: 10,729.12433

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.47155
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.66320

Cumulative Model Updates: 122,066
Cumulative Timesteps: 1,017,894,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,402.51269
Policy Entropy: 3.72392
Value Function Loss: 0.02512

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.39332
Value Function Update Magnitude: 0.40898

Collected Steps per Second: 22,867.57110
Overall Steps per Second: 10,846.90981

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61071

Cumulative Model Updates: 122,072
Cumulative Timesteps: 1,017,944,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1017944094...
Checkpoint 1017944094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.42542
Policy Entropy: 3.74703
Value Function Loss: 0.02412

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.46933
Value Function Update Magnitude: 0.43680

Collected Steps per Second: 22,926.18946
Overall Steps per Second: 10,701.38869

Timestep Collection Time: 2.18205
Timestep Consumption Time: 2.49267
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.67472

Cumulative Model Updates: 122,078
Cumulative Timesteps: 1,017,994,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.49488
Policy Entropy: 3.74909
Value Function Loss: 0.02260

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.45885
Value Function Update Magnitude: 0.46252

Collected Steps per Second: 22,462.31129
Overall Steps per Second: 10,918.02348

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.35410
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.58050

Cumulative Model Updates: 122,084
Cumulative Timesteps: 1,018,044,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1018044130...
Checkpoint 1018044130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,145.16625
Policy Entropy: 3.74235
Value Function Loss: 0.02088

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.43966
Value Function Update Magnitude: 0.48583

Collected Steps per Second: 22,400.68749
Overall Steps per Second: 10,756.15980

Timestep Collection Time: 2.23234
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.64906

Cumulative Model Updates: 122,090
Cumulative Timesteps: 1,018,094,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,605.28588
Policy Entropy: 3.71952
Value Function Loss: 0.02073

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.43036
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 22,319.20252
Overall Steps per Second: 10,791.37754

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.39406
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.63518

Cumulative Model Updates: 122,096
Cumulative Timesteps: 1,018,144,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1018144156...
Checkpoint 1018144156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,605.28588
Policy Entropy: 3.70375
Value Function Loss: 0.02281

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.45714
Value Function Update Magnitude: 0.64814

Collected Steps per Second: 22,070.96631
Overall Steps per Second: 10,614.89352

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.71244

Cumulative Model Updates: 122,102
Cumulative Timesteps: 1,018,194,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,605.28588
Policy Entropy: 3.71189
Value Function Loss: 0.02090

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.48476
Value Function Update Magnitude: 0.58439

Collected Steps per Second: 22,912.46315
Overall Steps per Second: 10,910.56384

Timestep Collection Time: 2.18344
Timestep Consumption Time: 2.40184
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.58528

Cumulative Model Updates: 122,108
Cumulative Timesteps: 1,018,244,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1018244206...
Checkpoint 1018244206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,647.53336
Policy Entropy: 3.68657
Value Function Loss: 0.02403

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.46639
Value Function Update Magnitude: 0.49903

Collected Steps per Second: 22,876.87547
Overall Steps per Second: 10,759.27448

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64976

Cumulative Model Updates: 122,114
Cumulative Timesteps: 1,018,294,234

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.68071
Value Function Loss: 0.02347

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.44271
Value Function Update Magnitude: 0.36983

Collected Steps per Second: 22,880.48163
Overall Steps per Second: 10,862.43713

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.41968
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.60670

Cumulative Model Updates: 122,120
Cumulative Timesteps: 1,018,344,274

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1018344274...
Checkpoint 1018344274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.66715
Value Function Loss: 0.02547

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.42419
Value Function Update Magnitude: 0.35445

Collected Steps per Second: 22,994.09260
Overall Steps per Second: 10,762.48565

Timestep Collection Time: 2.17465
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.64614

Cumulative Model Updates: 122,126
Cumulative Timesteps: 1,018,394,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.70190
Value Function Loss: 0.01978

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.42962
Value Function Update Magnitude: 0.42900

Collected Steps per Second: 22,892.96891
Overall Steps per Second: 10,721.88362

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.66336

Cumulative Model Updates: 122,132
Cumulative Timesteps: 1,018,444,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1018444278...
Checkpoint 1018444278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.70659
Value Function Loss: 0.01747

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.38289
Value Function Update Magnitude: 0.47650

Collected Steps per Second: 22,879.33008
Overall Steps per Second: 10,634.20503

Timestep Collection Time: 2.18669
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.70463

Cumulative Model Updates: 122,138
Cumulative Timesteps: 1,018,494,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.71201
Value Function Loss: 0.01627

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.34522
Value Function Update Magnitude: 0.45618

Collected Steps per Second: 22,817.69681
Overall Steps per Second: 10,849.25021

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61064

Cumulative Model Updates: 122,144
Cumulative Timesteps: 1,018,544,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1018544330...
Checkpoint 1018544330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.70869
Value Function Loss: 0.01730

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.34195
Value Function Update Magnitude: 0.45701

Collected Steps per Second: 22,727.99276
Overall Steps per Second: 10,722.35458

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.66334

Cumulative Model Updates: 122,150
Cumulative Timesteps: 1,018,594,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.72085
Value Function Loss: 0.01577

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.37359
Value Function Update Magnitude: 0.45653

Collected Steps per Second: 22,216.44042
Overall Steps per Second: 10,845.09418

Timestep Collection Time: 2.25113
Timestep Consumption Time: 2.36036
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61149

Cumulative Model Updates: 122,156
Cumulative Timesteps: 1,018,644,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1018644344...
Checkpoint 1018644344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.72892
Value Function Loss: 0.01585

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14908
Policy Update Magnitude: 0.37800
Value Function Update Magnitude: 0.41542

Collected Steps per Second: 22,306.31988
Overall Steps per Second: 10,732.64439

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.41794
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.66017

Cumulative Model Updates: 122,162
Cumulative Timesteps: 1,018,694,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,542.80499
Policy Entropy: 3.71700
Value Function Loss: 0.01567

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.34537
Value Function Update Magnitude: 0.32458

Collected Steps per Second: 21,989.82316
Overall Steps per Second: 10,515.74026

Timestep Collection Time: 2.27487
Timestep Consumption Time: 2.48219
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.75706

Cumulative Model Updates: 122,168
Cumulative Timesteps: 1,018,744,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1018744384...
Checkpoint 1018744384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,750.10385
Policy Entropy: 3.72782
Value Function Loss: 0.01705

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.36484
Value Function Update Magnitude: 0.32218

Collected Steps per Second: 23,011.88843
Overall Steps per Second: 10,951.51371

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.39317
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.56631

Cumulative Model Updates: 122,174
Cumulative Timesteps: 1,018,794,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,485.03460
Policy Entropy: 3.73410
Value Function Loss: 0.01932

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.40100
Value Function Update Magnitude: 0.36169

Collected Steps per Second: 22,843.78288
Overall Steps per Second: 10,869.65569

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.41205
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.60162

Cumulative Model Updates: 122,180
Cumulative Timesteps: 1,018,844,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1018844410...
Checkpoint 1018844410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,781.50042
Policy Entropy: 3.73528
Value Function Loss: 0.02392

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.41753
Value Function Update Magnitude: 0.42237

Collected Steps per Second: 22,936.57479
Overall Steps per Second: 10,714.81557

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.66905

Cumulative Model Updates: 122,186
Cumulative Timesteps: 1,018,894,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,491.48771
Policy Entropy: 3.73851
Value Function Loss: 0.02600

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.43264
Value Function Update Magnitude: 0.46870

Collected Steps per Second: 22,488.00784
Overall Steps per Second: 10,557.17482

Timestep Collection Time: 2.22447
Timestep Consumption Time: 2.51391
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.73839

Cumulative Model Updates: 122,192
Cumulative Timesteps: 1,018,944,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1018944462...
Checkpoint 1018944462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,608.49730
Policy Entropy: 3.72158
Value Function Loss: 0.02757

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.47460
Value Function Update Magnitude: 0.46479

Collected Steps per Second: 22,929.02795
Overall Steps per Second: 10,757.74287

Timestep Collection Time: 2.18186
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.65042

Cumulative Model Updates: 122,198
Cumulative Timesteps: 1,018,994,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,481.53930
Policy Entropy: 3.74515
Value Function Loss: 0.02495

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.52477
Value Function Update Magnitude: 0.46251

Collected Steps per Second: 22,866.59902
Overall Steps per Second: 10,692.00643

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.67789

Cumulative Model Updates: 122,204
Cumulative Timesteps: 1,019,044,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1019044506...
Checkpoint 1019044506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,342.37010
Policy Entropy: 3.74695
Value Function Loss: 0.02522

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.53402

Collected Steps per Second: 23,123.44222
Overall Steps per Second: 10,781.05875

Timestep Collection Time: 2.16369
Timestep Consumption Time: 2.47704
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.64073

Cumulative Model Updates: 122,210
Cumulative Timesteps: 1,019,094,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,804.11383
Policy Entropy: 3.77220
Value Function Loss: 0.02244

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.52805
Value Function Update Magnitude: 0.64982

Collected Steps per Second: 22,958.84766
Overall Steps per Second: 10,756.53817

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.64908

Cumulative Model Updates: 122,216
Cumulative Timesteps: 1,019,144,546

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1019144546...
Checkpoint 1019144546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,845.63745
Policy Entropy: 3.76268
Value Function Loss: 0.02116

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14890
Policy Update Magnitude: 0.52311
Value Function Update Magnitude: 0.62045

Collected Steps per Second: 23,135.86263
Overall Steps per Second: 10,810.30546

Timestep Collection Time: 2.16210
Timestep Consumption Time: 2.46515
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.62725

Cumulative Model Updates: 122,222
Cumulative Timesteps: 1,019,194,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.31980
Policy Entropy: 3.76574
Value Function Loss: 0.01962

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.48134
Value Function Update Magnitude: 0.70092

Collected Steps per Second: 23,244.79808
Overall Steps per Second: 10,728.50152

Timestep Collection Time: 2.15102
Timestep Consumption Time: 2.50946
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.66048

Cumulative Model Updates: 122,228
Cumulative Timesteps: 1,019,244,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1019244568...
Checkpoint 1019244568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106.47248
Policy Entropy: 3.75918
Value Function Loss: 0.02111

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.49012
Value Function Update Magnitude: 0.67705

Collected Steps per Second: 22,744.75092
Overall Steps per Second: 10,655.99579

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69445

Cumulative Model Updates: 122,234
Cumulative Timesteps: 1,019,294,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,534.01926
Policy Entropy: 3.76937
Value Function Loss: 0.02130

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.49728
Value Function Update Magnitude: 0.52276

Collected Steps per Second: 22,033.15658
Overall Steps per Second: 10,835.55666

Timestep Collection Time: 2.27049
Timestep Consumption Time: 2.34635
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61684

Cumulative Model Updates: 122,240
Cumulative Timesteps: 1,019,344,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1019344618...
Checkpoint 1019344618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,450.86667
Policy Entropy: 3.76098
Value Function Loss: 0.02387

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.56819

Collected Steps per Second: 21,799.88136
Overall Steps per Second: 10,745.50611

Timestep Collection Time: 2.29451
Timestep Consumption Time: 2.36046
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.65497

Cumulative Model Updates: 122,246
Cumulative Timesteps: 1,019,394,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,031.07687
Policy Entropy: 3.76711
Value Function Loss: 0.02434

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.63672

Collected Steps per Second: 22,232.80306
Overall Steps per Second: 10,858.21624

Timestep Collection Time: 2.25019
Timestep Consumption Time: 2.35720
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.60739

Cumulative Model Updates: 122,252
Cumulative Timesteps: 1,019,444,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1019444666...
Checkpoint 1019444666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,066.74217
Policy Entropy: 3.77065
Value Function Loss: 0.02766

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.53320
Value Function Update Magnitude: 0.60952

Collected Steps per Second: 22,079.29117
Overall Steps per Second: 10,655.01404

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.69319

Cumulative Model Updates: 122,258
Cumulative Timesteps: 1,019,494,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.72999
Policy Entropy: 3.78047
Value Function Loss: 0.02670

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.51180
Value Function Update Magnitude: 0.54794

Collected Steps per Second: 22,269.35662
Overall Steps per Second: 10,878.58921

Timestep Collection Time: 2.24578
Timestep Consumption Time: 2.35151
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.59729

Cumulative Model Updates: 122,264
Cumulative Timesteps: 1,019,544,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019544684...
Checkpoint 1019544684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,035.61161
Policy Entropy: 3.77874
Value Function Loss: 0.02950

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 21,969.32298
Overall Steps per Second: 10,708.67624

Timestep Collection Time: 2.27663
Timestep Consumption Time: 2.39398
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.67061

Cumulative Model Updates: 122,270
Cumulative Timesteps: 1,019,594,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.74123
Policy Entropy: 3.77106
Value Function Loss: 0.02917

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.58326

Collected Steps per Second: 23,040.78572
Overall Steps per Second: 10,864.68743

Timestep Collection Time: 2.17059
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.60317

Cumulative Model Updates: 122,276
Cumulative Timesteps: 1,019,644,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1019644712...
Checkpoint 1019644712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,886.58479
Policy Entropy: 3.79636
Value Function Loss: 0.03228

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.55618

Collected Steps per Second: 23,041.84625
Overall Steps per Second: 10,790.21552

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.63438

Cumulative Model Updates: 122,282
Cumulative Timesteps: 1,019,694,718

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.35316
Policy Entropy: 3.82439
Value Function Loss: 0.03071

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 22,897.29751
Overall Steps per Second: 10,751.89497

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.65109

Cumulative Model Updates: 122,288
Cumulative Timesteps: 1,019,744,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1019744726...
Checkpoint 1019744726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,119.35644
Policy Entropy: 3.86116
Value Function Loss: 0.03087

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.57342
Value Function Update Magnitude: 0.59189

Collected Steps per Second: 22,797.94427
Overall Steps per Second: 10,749.35318

Timestep Collection Time: 2.19415
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.65349

Cumulative Model Updates: 122,294
Cumulative Timesteps: 1,019,794,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.36048
Policy Entropy: 3.85653
Value Function Loss: 0.02715

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 23,076.96887
Overall Steps per Second: 10,806.30601

Timestep Collection Time: 2.16710
Timestep Consumption Time: 2.46076
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.62785

Cumulative Model Updates: 122,300
Cumulative Timesteps: 1,019,844,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1019844758...
Checkpoint 1019844758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35416
Policy Entropy: 3.81300
Value Function Loss: 0.02698

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.50283
Value Function Update Magnitude: 0.71713

Collected Steps per Second: 22,983.88099
Overall Steps per Second: 10,750.75905

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.65139

Cumulative Model Updates: 122,306
Cumulative Timesteps: 1,019,894,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,946.15438
Policy Entropy: 3.78260
Value Function Loss: 0.02280

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.49776
Value Function Update Magnitude: 0.86904

Collected Steps per Second: 22,983.85458
Overall Steps per Second: 10,803.68894

Timestep Collection Time: 2.17570
Timestep Consumption Time: 2.45290
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62860

Cumulative Model Updates: 122,312
Cumulative Timesteps: 1,019,944,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1019944770...
Checkpoint 1019944770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,177.24144
Policy Entropy: 3.76419
Value Function Loss: 0.02817

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.52119
Value Function Update Magnitude: 0.80163

Collected Steps per Second: 22,472.27356
Overall Steps per Second: 10,634.06042

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.47790
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.70375

Cumulative Model Updates: 122,318
Cumulative Timesteps: 1,019,994,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,491.46666
Policy Entropy: 3.77725
Value Function Loss: 0.02932

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.53071
Value Function Update Magnitude: 0.62091

Collected Steps per Second: 22,742.85777
Overall Steps per Second: 10,803.51027

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.62905

Cumulative Model Updates: 122,324
Cumulative Timesteps: 1,020,044,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1020044800...
Checkpoint 1020044800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.01807
Policy Entropy: 3.77434
Value Function Loss: 0.03239

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 22,196.29268
Overall Steps per Second: 10,633.67485

Timestep Collection Time: 2.25380
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.70449

Cumulative Model Updates: 122,330
Cumulative Timesteps: 1,020,094,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.02041
Policy Entropy: 3.77732
Value Function Loss: 0.02935

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.57977

Collected Steps per Second: 22,682.89027
Overall Steps per Second: 10,615.00136

Timestep Collection Time: 2.20439
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.71050

Cumulative Model Updates: 122,336
Cumulative Timesteps: 1,020,144,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1020144828...
Checkpoint 1020144828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122.98044
Policy Entropy: 3.76374
Value Function Loss: 0.02786

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.50148
Value Function Update Magnitude: 0.51903

Collected Steps per Second: 22,637.43042
Overall Steps per Second: 10,634.29682

Timestep Collection Time: 2.20882
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.70196

Cumulative Model Updates: 122,342
Cumulative Timesteps: 1,020,194,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,235.10645
Policy Entropy: 3.76653
Value Function Loss: 0.02367

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.52610

Collected Steps per Second: 22,854.04284
Overall Steps per Second: 10,813.18127

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62676

Cumulative Model Updates: 122,348
Cumulative Timesteps: 1,020,244,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1020244860...
Checkpoint 1020244860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.07698
Policy Entropy: 3.76615
Value Function Loss: 0.02355

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.47777
Value Function Update Magnitude: 0.51361

Collected Steps per Second: 22,567.49243
Overall Steps per Second: 10,649.54608

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.69635

Cumulative Model Updates: 122,354
Cumulative Timesteps: 1,020,294,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.09485
Policy Entropy: 3.76147
Value Function Loss: 0.02161

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.48204
Value Function Update Magnitude: 0.44843

Collected Steps per Second: 23,001.05550
Overall Steps per Second: 10,883.23862

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59532

Cumulative Model Updates: 122,360
Cumulative Timesteps: 1,020,344,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1020344886...
Checkpoint 1020344886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.74673
Policy Entropy: 3.74782
Value Function Loss: 0.02276

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.48905
Value Function Update Magnitude: 0.42332

Collected Steps per Second: 22,780.19213
Overall Steps per Second: 10,690.56189

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.48442
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.68133

Cumulative Model Updates: 122,366
Cumulative Timesteps: 1,020,394,932

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.56678
Policy Entropy: 3.74096
Value Function Loss: 0.02002

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.48316

Collected Steps per Second: 22,805.25206
Overall Steps per Second: 10,805.46648

Timestep Collection Time: 2.19353
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62951

Cumulative Model Updates: 122,372
Cumulative Timesteps: 1,020,444,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1020444956...
Checkpoint 1020444956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.73805
Policy Entropy: 3.73401
Value Function Loss: 0.02091

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.49480
Value Function Update Magnitude: 0.52087

Collected Steps per Second: 22,804.28409
Overall Steps per Second: 10,737.77634

Timestep Collection Time: 2.19336
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.65813

Cumulative Model Updates: 122,378
Cumulative Timesteps: 1,020,494,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.53004
Policy Entropy: 3.73919
Value Function Loss: 0.02183

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.43828
Value Function Update Magnitude: 0.39218

Collected Steps per Second: 22,745.31690
Overall Steps per Second: 10,817.45930

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.62271

Cumulative Model Updates: 122,384
Cumulative Timesteps: 1,020,544,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1020544980...
Checkpoint 1020544980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311,307.88626
Policy Entropy: 3.74573
Value Function Loss: 0.02094

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.41404
Value Function Update Magnitude: 0.37528

Collected Steps per Second: 22,685.26256
Overall Steps per Second: 10,728.55125

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.66456

Cumulative Model Updates: 122,390
Cumulative Timesteps: 1,020,595,024

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,862.95298
Policy Entropy: 3.75015
Value Function Loss: 0.02147

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.43644
Value Function Update Magnitude: 0.41799

Collected Steps per Second: 22,903.38837
Overall Steps per Second: 10,836.67370

Timestep Collection Time: 2.18422
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61636

Cumulative Model Updates: 122,396
Cumulative Timesteps: 1,020,645,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020645050...
Checkpoint 1020645050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,443.95379
Policy Entropy: 3.74171
Value Function Loss: 0.02353

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.46178
Value Function Update Magnitude: 0.45773

Collected Steps per Second: 22,872.42451
Overall Steps per Second: 10,717.44468

Timestep Collection Time: 2.18630
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.66585

Cumulative Model Updates: 122,402
Cumulative Timesteps: 1,020,695,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,738.05952
Policy Entropy: 3.73659
Value Function Loss: 0.02093

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.48501
Value Function Update Magnitude: 0.49724

Collected Steps per Second: 23,044.66314
Overall Steps per Second: 10,885.87300

Timestep Collection Time: 2.17083
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.59550

Cumulative Model Updates: 122,408
Cumulative Timesteps: 1,020,745,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1020745082...
Checkpoint 1020745082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,120.09642
Policy Entropy: 3.73559
Value Function Loss: 0.02369

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.46327
Value Function Update Magnitude: 0.50940

Collected Steps per Second: 22,681.82543
Overall Steps per Second: 10,671.98856

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.48165
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68685

Cumulative Model Updates: 122,414
Cumulative Timesteps: 1,020,795,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,465.83902
Policy Entropy: 3.76566
Value Function Loss: 0.02047

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.48284
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,946.96146
Overall Steps per Second: 10,879.36905

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.41788
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.59769

Cumulative Model Updates: 122,420
Cumulative Timesteps: 1,020,845,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1020845120...
Checkpoint 1020845120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,350.27531
Policy Entropy: 3.75925
Value Function Loss: 0.02402

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.50854
Value Function Update Magnitude: 0.75128

Collected Steps per Second: 22,430.45161
Overall Steps per Second: 10,652.83856

Timestep Collection Time: 2.23036
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.69621

Cumulative Model Updates: 122,426
Cumulative Timesteps: 1,020,895,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,542.26432
Policy Entropy: 3.76436
Value Function Loss: 0.02303

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.50168
Value Function Update Magnitude: 0.65733

Collected Steps per Second: 23,105.14981
Overall Steps per Second: 10,915.84131

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.58343

Cumulative Model Updates: 122,432
Cumulative Timesteps: 1,020,945,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1020945180...
Checkpoint 1020945180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,618.18268
Policy Entropy: 3.74495
Value Function Loss: 0.02840

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.48408
Value Function Update Magnitude: 0.54067

Collected Steps per Second: 21,867.94076
Overall Steps per Second: 10,666.93723

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.68757

Cumulative Model Updates: 122,438
Cumulative Timesteps: 1,020,995,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,204.63681
Policy Entropy: 3.75203
Value Function Loss: 0.02656

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.51488
Value Function Update Magnitude: 0.51974

Collected Steps per Second: 22,575.42914
Overall Steps per Second: 10,923.11047

Timestep Collection Time: 2.21613
Timestep Consumption Time: 2.36407
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.58020

Cumulative Model Updates: 122,444
Cumulative Timesteps: 1,021,045,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1021045212...
Checkpoint 1021045212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,544.01943
Policy Entropy: 3.73414
Value Function Loss: 0.02997

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.54481
Value Function Update Magnitude: 0.53762

Collected Steps per Second: 21,960.18871
Overall Steps per Second: 10,637.34331

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.70305

Cumulative Model Updates: 122,450
Cumulative Timesteps: 1,021,095,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,583.83107
Policy Entropy: 3.74262
Value Function Loss: 0.02447

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.53362

Collected Steps per Second: 22,518.09525
Overall Steps per Second: 10,901.84515

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.36717
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.58876

Cumulative Model Updates: 122,456
Cumulative Timesteps: 1,021,145,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1021145266...
Checkpoint 1021145266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,249.67349
Policy Entropy: 3.74390
Value Function Loss: 0.02772

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.50963
Value Function Update Magnitude: 0.49288

Collected Steps per Second: 22,041.92259
Overall Steps per Second: 10,614.48241

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.71073

Cumulative Model Updates: 122,462
Cumulative Timesteps: 1,021,195,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,133.34193
Policy Entropy: 3.75100
Value Function Loss: 0.02584

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.50916
Value Function Update Magnitude: 0.50257

Collected Steps per Second: 22,907.60318
Overall Steps per Second: 10,891.38590

Timestep Collection Time: 2.18355
Timestep Consumption Time: 2.40907
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.59262

Cumulative Model Updates: 122,468
Cumulative Timesteps: 1,021,245,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1021245288...
Checkpoint 1021245288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.86840
Policy Entropy: 3.74158
Value Function Loss: 0.03115

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.54345
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 22,678.23708
Overall Steps per Second: 10,684.50543

Timestep Collection Time: 2.20670
Timestep Consumption Time: 2.47709
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68379

Cumulative Model Updates: 122,474
Cumulative Timesteps: 1,021,295,332

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,056.94652
Policy Entropy: 3.74451
Value Function Loss: 0.02947

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.59711
Value Function Update Magnitude: 0.54585

Collected Steps per Second: 23,125.40356
Overall Steps per Second: 10,903.53943

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.58970

Cumulative Model Updates: 122,480
Cumulative Timesteps: 1,021,345,376

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1021345376...
Checkpoint 1021345376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,563.96649
Policy Entropy: 3.72962
Value Function Loss: 0.02926

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.61232

Collected Steps per Second: 22,727.54436
Overall Steps per Second: 10,638.87540

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.70087

Cumulative Model Updates: 122,486
Cumulative Timesteps: 1,021,395,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,292.00237
Policy Entropy: 3.73855
Value Function Loss: 0.02910

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.50610
Value Function Update Magnitude: 0.75722

Collected Steps per Second: 23,141.41144
Overall Steps per Second: 10,913.07239

Timestep Collection Time: 2.16132
Timestep Consumption Time: 2.42181
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.58313

Cumulative Model Updates: 122,492
Cumulative Timesteps: 1,021,445,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1021445404...
Checkpoint 1021445404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,608.76965
Policy Entropy: 3.74697
Value Function Loss: 0.02670

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.56677
Value Function Update Magnitude: 0.88965

Collected Steps per Second: 22,974.98906
Overall Steps per Second: 10,706.01272

Timestep Collection Time: 2.17628
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.67027

Cumulative Model Updates: 122,498
Cumulative Timesteps: 1,021,495,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,464.74479
Policy Entropy: 3.75698
Value Function Loss: 0.02708

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.91967

Collected Steps per Second: 23,057.08597
Overall Steps per Second: 10,835.05138

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.44671
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.61576

Cumulative Model Updates: 122,504
Cumulative Timesteps: 1,021,545,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1021545416...
Checkpoint 1021545416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,756.10769
Policy Entropy: 3.76582
Value Function Loss: 0.02572

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.98452

Collected Steps per Second: 22,815.95069
Overall Steps per Second: 10,666.96445

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.49672
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68887

Cumulative Model Updates: 122,510
Cumulative Timesteps: 1,021,595,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,272.25864
Policy Entropy: 3.74800
Value Function Loss: 0.02344

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.52762
Value Function Update Magnitude: 0.95506

Collected Steps per Second: 22,353.25388
Overall Steps per Second: 10,584.24638

Timestep Collection Time: 2.23815
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.72684

Cumulative Model Updates: 122,516
Cumulative Timesteps: 1,021,645,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1021645462...
Checkpoint 1021645462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,939.28301
Policy Entropy: 3.75034
Value Function Loss: 0.02309

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.93689

Collected Steps per Second: 22,845.32916
Overall Steps per Second: 10,669.84451

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68779

Cumulative Model Updates: 122,522
Cumulative Timesteps: 1,021,695,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,575.55923
Policy Entropy: 3.72679
Value Function Loss: 0.02361

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15193
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.76610

Collected Steps per Second: 23,302.97987
Overall Steps per Second: 10,843.67324

Timestep Collection Time: 2.14685
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.61357

Cumulative Model Updates: 122,528
Cumulative Timesteps: 1,021,745,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1021745508...
Checkpoint 1021745508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,537.64718
Policy Entropy: 3.73220
Value Function Loss: 0.02370

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.52320
Value Function Update Magnitude: 0.60724

Collected Steps per Second: 22,745.32456
Overall Steps per Second: 10,650.14489

Timestep Collection Time: 2.19834
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.69496

Cumulative Model Updates: 122,534
Cumulative Timesteps: 1,021,795,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,098.56435
Policy Entropy: 3.72726
Value Function Loss: 0.02095

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.70259

Collected Steps per Second: 23,030.32043
Overall Steps per Second: 10,851.09292

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.43912
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61225

Cumulative Model Updates: 122,540
Cumulative Timesteps: 1,021,845,558

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1021845558...
Checkpoint 1021845558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,533.57616
Policy Entropy: 3.74617
Value Function Loss: 0.01832

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.45837
Value Function Update Magnitude: 0.79630

Collected Steps per Second: 22,837.37748
Overall Steps per Second: 10,660.92195

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.50123
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69115

Cumulative Model Updates: 122,546
Cumulative Timesteps: 1,021,895,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,822.40776
Policy Entropy: 3.75508
Value Function Loss: 0.02119

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.47529
Value Function Update Magnitude: 0.78083

Collected Steps per Second: 22,818.51509
Overall Steps per Second: 10,827.91452

Timestep Collection Time: 2.19147
Timestep Consumption Time: 2.42678
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.61825

Cumulative Model Updates: 122,552
Cumulative Timesteps: 1,021,945,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1021945576...
Checkpoint 1021945576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,739.95652
Policy Entropy: 3.76910
Value Function Loss: 0.02222

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.83089

Collected Steps per Second: 22,570.51368
Overall Steps per Second: 10,730.04687

Timestep Collection Time: 2.21634
Timestep Consumption Time: 2.44571
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.66205

Cumulative Model Updates: 122,558
Cumulative Timesteps: 1,021,995,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,355.45848
Policy Entropy: 3.75248
Value Function Loss: 0.02631

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.63235
Value Function Update Magnitude: 0.80949

Collected Steps per Second: 22,844.69844
Overall Steps per Second: 10,801.14635

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63062

Cumulative Model Updates: 122,564
Cumulative Timesteps: 1,022,045,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022045616...
Checkpoint 1022045616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.68309
Policy Entropy: 3.76390
Value Function Loss: 0.02551

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.59827
Value Function Update Magnitude: 0.78435

Collected Steps per Second: 22,624.93252
Overall Steps per Second: 10,716.60405

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.45787
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.66976

Cumulative Model Updates: 122,570
Cumulative Timesteps: 1,022,095,660

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541.06577
Policy Entropy: 3.74190
Value Function Loss: 0.02777

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.69758

Collected Steps per Second: 22,939.68400
Overall Steps per Second: 10,876.05322

Timestep Collection Time: 2.18068
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.59946

Cumulative Model Updates: 122,576
Cumulative Timesteps: 1,022,145,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1022145684...
Checkpoint 1022145684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,977.97328
Policy Entropy: 3.74371
Value Function Loss: 0.02626

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 22,446.52899
Overall Steps per Second: 10,778.20738

Timestep Collection Time: 2.22894
Timestep Consumption Time: 2.41302
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.64196

Cumulative Model Updates: 122,582
Cumulative Timesteps: 1,022,195,716

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,459.92645
Policy Entropy: 3.73986
Value Function Loss: 0.02788

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.59139

Collected Steps per Second: 22,661.80072
Overall Steps per Second: 10,763.62749

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.64527

Cumulative Model Updates: 122,588
Cumulative Timesteps: 1,022,245,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1022245716...
Checkpoint 1022245716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,646.29452
Policy Entropy: 3.77380
Value Function Loss: 0.02906

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 22,744.38241
Overall Steps per Second: 10,706.95941

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.47260
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.67191

Cumulative Model Updates: 122,594
Cumulative Timesteps: 1,022,295,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,930.49150
Policy Entropy: 3.79418
Value Function Loss: 0.03075

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.59786
Value Function Update Magnitude: 0.68216

Collected Steps per Second: 23,018.34281
Overall Steps per Second: 10,957.60337

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.39086
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.56304

Cumulative Model Updates: 122,600
Cumulative Timesteps: 1,022,345,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1022345738...
Checkpoint 1022345738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,658.13804
Policy Entropy: 3.79267
Value Function Loss: 0.03062

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.60891
Value Function Update Magnitude: 0.71475

Collected Steps per Second: 22,536.56606
Overall Steps per Second: 10,572.20445

Timestep Collection Time: 2.21977
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.73184

Cumulative Model Updates: 122,606
Cumulative Timesteps: 1,022,395,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,192.09240
Policy Entropy: 3.79167
Value Function Loss: 0.02831

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.61792
Value Function Update Magnitude: 0.73858

Collected Steps per Second: 23,099.91257
Overall Steps per Second: 10,884.27700

Timestep Collection Time: 2.16520
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.59525

Cumulative Model Updates: 122,612
Cumulative Timesteps: 1,022,445,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022445780...
Checkpoint 1022445780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,684.75141
Policy Entropy: 3.80396
Value Function Loss: 0.02816

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.59917
Value Function Update Magnitude: 0.66435

Collected Steps per Second: 22,873.02839
Overall Steps per Second: 10,644.93552

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.51119
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69726

Cumulative Model Updates: 122,618
Cumulative Timesteps: 1,022,495,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,452.23502
Policy Entropy: 3.79077
Value Function Loss: 0.03030

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.58468
Value Function Update Magnitude: 0.63625

Collected Steps per Second: 23,129.67923
Overall Steps per Second: 10,904.03773

Timestep Collection Time: 2.16242
Timestep Consumption Time: 2.42451
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.58692

Cumulative Model Updates: 122,624
Cumulative Timesteps: 1,022,545,798

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022545798...
Checkpoint 1022545798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,654.60236
Policy Entropy: 3.77418
Value Function Loss: 0.03213

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.59972
Value Function Update Magnitude: 0.72511

Collected Steps per Second: 22,619.91883
Overall Steps per Second: 10,682.80429

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.68173

Cumulative Model Updates: 122,630
Cumulative Timesteps: 1,022,595,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,491.21808
Policy Entropy: 3.76646
Value Function Loss: 0.03104

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.59350
Value Function Update Magnitude: 0.82153

Collected Steps per Second: 23,157.43244
Overall Steps per Second: 10,870.79955

Timestep Collection Time: 2.15991
Timestep Consumption Time: 2.44122
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.60113

Cumulative Model Updates: 122,636
Cumulative Timesteps: 1,022,645,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1022645830...
Checkpoint 1022645830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.37607
Policy Entropy: 3.78402
Value Function Loss: 0.02876

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.69370

Collected Steps per Second: 22,692.46264
Overall Steps per Second: 10,676.18606

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.48084
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.68501

Cumulative Model Updates: 122,642
Cumulative Timesteps: 1,022,695,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.28289
Policy Entropy: 3.80347
Value Function Loss: 0.02501

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.54338
Value Function Update Magnitude: 0.72356

Collected Steps per Second: 23,237.19468
Overall Steps per Second: 10,943.15930

Timestep Collection Time: 2.15181
Timestep Consumption Time: 2.41744
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.56925

Cumulative Model Updates: 122,648
Cumulative Timesteps: 1,022,745,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1022745850...
Checkpoint 1022745850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,814.00694
Policy Entropy: 3.79211
Value Function Loss: 0.02526

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.50652
Value Function Update Magnitude: 0.75237

Collected Steps per Second: 22,839.03042
Overall Steps per Second: 10,711.48339

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.66845

Cumulative Model Updates: 122,654
Cumulative Timesteps: 1,022,795,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,490.38670
Policy Entropy: 3.77804
Value Function Loss: 0.02594

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.49740
Value Function Update Magnitude: 0.69114

Collected Steps per Second: 23,028.95320
Overall Steps per Second: 10,781.66279

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.63992

Cumulative Model Updates: 122,660
Cumulative Timesteps: 1,022,845,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1022845882...
Checkpoint 1022845882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,759.52472
Policy Entropy: 3.75600
Value Function Loss: 0.02525

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.47917
Value Function Update Magnitude: 0.61337

Collected Steps per Second: 22,823.44793
Overall Steps per Second: 10,670.26721

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.68611

Cumulative Model Updates: 122,666
Cumulative Timesteps: 1,022,895,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,212.74917
Policy Entropy: 3.75045
Value Function Loss: 0.02431

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.48766
Value Function Update Magnitude: 0.65322

Collected Steps per Second: 22,719.04384
Overall Steps per Second: 10,798.18273

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.63189

Cumulative Model Updates: 122,672
Cumulative Timesteps: 1,022,945,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1022945900...
Checkpoint 1022945900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.72156
Value Function Loss: 0.02554

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.47974
Value Function Update Magnitude: 0.59365

Collected Steps per Second: 22,875.51548
Overall Steps per Second: 10,709.20887

Timestep Collection Time: 2.18723
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.67205

Cumulative Model Updates: 122,678
Cumulative Timesteps: 1,022,995,934

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.71251
Value Function Loss: 0.02425

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.50703
Value Function Update Magnitude: 0.56380

Collected Steps per Second: 22,805.86246
Overall Steps per Second: 10,838.93857

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.42145
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61466

Cumulative Model Updates: 122,684
Cumulative Timesteps: 1,023,045,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1023045952...
Checkpoint 1023045952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.70698
Value Function Loss: 0.02131

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.49679
Value Function Update Magnitude: 0.47199

Collected Steps per Second: 22,811.46648
Overall Steps per Second: 10,672.70325

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68504

Cumulative Model Updates: 122,690
Cumulative Timesteps: 1,023,095,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.71159
Value Function Loss: 0.01761

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.42147
Value Function Update Magnitude: 0.37235

Collected Steps per Second: 23,282.03352
Overall Steps per Second: 10,925.72652

Timestep Collection Time: 2.14947
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.58038

Cumulative Model Updates: 122,696
Cumulative Timesteps: 1,023,145,998

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1023145998...
Checkpoint 1023145998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.70622
Value Function Loss: 0.01748

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.37278
Value Function Update Magnitude: 0.32753

Collected Steps per Second: 22,845.75045
Overall Steps per Second: 10,686.74092

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.68113

Cumulative Model Updates: 122,702
Cumulative Timesteps: 1,023,196,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.72370
Value Function Loss: 0.01551

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.36195
Value Function Update Magnitude: 0.41755

Collected Steps per Second: 22,518.07039
Overall Steps per Second: 10,907.22513

Timestep Collection Time: 2.22133
Timestep Consumption Time: 2.36462
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.58595

Cumulative Model Updates: 122,708
Cumulative Timesteps: 1,023,246,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1023246044...
Checkpoint 1023246044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.71873
Value Function Loss: 0.01652

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.36463
Value Function Update Magnitude: 0.48637

Collected Steps per Second: 22,118.36923
Overall Steps per Second: 10,689.51862

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.67841

Cumulative Model Updates: 122,714
Cumulative Timesteps: 1,023,296,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.74543
Value Function Loss: 0.01462

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.37264
Value Function Update Magnitude: 0.47316

Collected Steps per Second: 22,554.23434
Overall Steps per Second: 10,810.79679

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.62519

Cumulative Model Updates: 122,720
Cumulative Timesteps: 1,023,346,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1023346056...
Checkpoint 1023346056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.72632
Value Function Loss: 0.01511

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.38377
Value Function Update Magnitude: 0.43419

Collected Steps per Second: 22,769.98202
Overall Steps per Second: 10,702.93150

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.67218

Cumulative Model Updates: 122,726
Cumulative Timesteps: 1,023,396,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,529.88677
Policy Entropy: 3.73374
Value Function Loss: 0.01429

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.39005
Value Function Update Magnitude: 0.45657

Collected Steps per Second: 23,230.63617
Overall Steps per Second: 10,886.54304

Timestep Collection Time: 2.15371
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.59577

Cumulative Model Updates: 122,732
Cumulative Timesteps: 1,023,446,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1023446094...
Checkpoint 1023446094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,527.52394
Policy Entropy: 3.71468
Value Function Loss: 0.01743

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.42575
Value Function Update Magnitude: 0.58534

Collected Steps per Second: 23,084.56025
Overall Steps per Second: 10,746.91142

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.65417

Cumulative Model Updates: 122,738
Cumulative Timesteps: 1,023,496,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,904.88662
Policy Entropy: 3.74140
Value Function Loss: 0.01870

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.46540
Value Function Update Magnitude: 0.72008

Collected Steps per Second: 23,179.12876
Overall Steps per Second: 10,812.21625

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.46857
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.62680

Cumulative Model Updates: 122,744
Cumulative Timesteps: 1,023,546,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1023546138...
Checkpoint 1023546138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,868.32154
Policy Entropy: 3.74410
Value Function Loss: 0.01896

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.70227

Collected Steps per Second: 22,703.74764
Overall Steps per Second: 10,614.46754

Timestep Collection Time: 2.20316
Timestep Consumption Time: 2.50928
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.71244

Cumulative Model Updates: 122,750
Cumulative Timesteps: 1,023,596,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,479.69370
Policy Entropy: 3.73820
Value Function Loss: 0.02008

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.44093
Value Function Update Magnitude: 0.61288

Collected Steps per Second: 22,996.60691
Overall Steps per Second: 10,851.63561

Timestep Collection Time: 2.17536
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61000

Cumulative Model Updates: 122,756
Cumulative Timesteps: 1,023,646,184

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1023646184...
Checkpoint 1023646184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,479.69370
Policy Entropy: 3.70605
Value Function Loss: 0.02117

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.44335
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 22,803.20598
Overall Steps per Second: 10,668.31702

Timestep Collection Time: 2.19346
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68846

Cumulative Model Updates: 122,762
Cumulative Timesteps: 1,023,696,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,883.31385
Policy Entropy: 3.70522
Value Function Loss: 0.02209

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.47898
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 23,194.16003
Overall Steps per Second: 10,919.73465

Timestep Collection Time: 2.15675
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.58106

Cumulative Model Updates: 122,768
Cumulative Timesteps: 1,023,746,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1023746226...
Checkpoint 1023746226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281,583.07981
Policy Entropy: 3.71461
Value Function Loss: 0.02621

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.50285
Value Function Update Magnitude: 0.49221

Collected Steps per Second: 22,577.58353
Overall Steps per Second: 10,675.15819

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.68583

Cumulative Model Updates: 122,774
Cumulative Timesteps: 1,023,796,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,549.33825
Policy Entropy: 3.74057
Value Function Loss: 0.02460

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 22,334.33984
Overall Steps per Second: 10,861.34221

Timestep Collection Time: 2.24005
Timestep Consumption Time: 2.36620
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60624

Cumulative Model Updates: 122,780
Cumulative Timesteps: 1,023,846,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1023846278...
Checkpoint 1023846278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,224.65155
Policy Entropy: 3.74598
Value Function Loss: 0.02696

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.57567
Value Function Update Magnitude: 0.70980

Collected Steps per Second: 22,131.26380
Overall Steps per Second: 10,678.49650

Timestep Collection Time: 2.26042
Timestep Consumption Time: 2.42432
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.68474

Cumulative Model Updates: 122,786
Cumulative Timesteps: 1,023,896,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,898.30323
Policy Entropy: 3.74466
Value Function Loss: 0.02383

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.65468

Collected Steps per Second: 22,291.35320
Overall Steps per Second: 10,874.11583

Timestep Collection Time: 2.24347
Timestep Consumption Time: 2.35552
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.59899

Cumulative Model Updates: 122,792
Cumulative Timesteps: 1,023,946,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1023946314...
Checkpoint 1023946314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,898.30323
Policy Entropy: 3.72367
Value Function Loss: 0.02232

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.53151
Value Function Update Magnitude: 0.57013

Collected Steps per Second: 21,820.88591
Overall Steps per Second: 10,676.63540

Timestep Collection Time: 2.29175
Timestep Consumption Time: 2.39212
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.68387

Cumulative Model Updates: 122,798
Cumulative Timesteps: 1,023,996,322

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,085.69608
Policy Entropy: 3.71364
Value Function Loss: 0.02094

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.51763
Value Function Update Magnitude: 0.55073

Collected Steps per Second: 23,035.51553
Overall Steps per Second: 10,870.31978

Timestep Collection Time: 2.17186
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.60244

Cumulative Model Updates: 122,804
Cumulative Timesteps: 1,024,046,352

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1024046352...
Checkpoint 1024046352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,782.60654
Policy Entropy: 3.71559
Value Function Loss: 0.02398

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.52149
Value Function Update Magnitude: 0.57048

Collected Steps per Second: 22,593.71719
Overall Steps per Second: 10,653.46225

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.48179
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.69613

Cumulative Model Updates: 122,810
Cumulative Timesteps: 1,024,096,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,447.70908
Policy Entropy: 3.72917
Value Function Loss: 0.02758

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.54531
Value Function Update Magnitude: 0.54240

Collected Steps per Second: 23,048.69990
Overall Steps per Second: 10,883.64322

Timestep Collection Time: 2.17045
Timestep Consumption Time: 2.42599
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.59644

Cumulative Model Updates: 122,816
Cumulative Timesteps: 1,024,146,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1024146408...
Checkpoint 1024146408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,881.77695
Policy Entropy: 3.74528
Value Function Loss: 0.03023

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.58229

Collected Steps per Second: 22,861.58329
Overall Steps per Second: 10,666.98971

Timestep Collection Time: 2.18769
Timestep Consumption Time: 2.50098
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.68867

Cumulative Model Updates: 122,822
Cumulative Timesteps: 1,024,196,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.66492
Policy Entropy: 3.74440
Value Function Loss: 0.02850

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.58377
Value Function Update Magnitude: 0.62016

Collected Steps per Second: 22,730.06280
Overall Steps per Second: 10,806.78098

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.62765

Cumulative Model Updates: 122,828
Cumulative Timesteps: 1,024,246,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1024246432...
Checkpoint 1024246432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.66492
Policy Entropy: 3.73416
Value Function Loss: 0.02455

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.59200

Collected Steps per Second: 23,104.28629
Overall Steps per Second: 10,702.30798

Timestep Collection Time: 2.16436
Timestep Consumption Time: 2.50809
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.67245

Cumulative Model Updates: 122,834
Cumulative Timesteps: 1,024,296,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,743.66492
Policy Entropy: 3.71503
Value Function Loss: 0.02007

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.15061
Policy Update Magnitude: 0.52064
Value Function Update Magnitude: 0.52902

Collected Steps per Second: 22,983.52817
Overall Steps per Second: 10,867.98081

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60122

Cumulative Model Updates: 122,840
Cumulative Timesteps: 1,024,346,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1024346444...
Checkpoint 1024346444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,822.43305
Policy Entropy: 3.69726
Value Function Loss: 0.02374

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.49187
Value Function Update Magnitude: 0.49039

Collected Steps per Second: 22,801.11252
Overall Steps per Second: 10,734.09987

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.46547
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.65861

Cumulative Model Updates: 122,846
Cumulative Timesteps: 1,024,396,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,839.42610
Policy Entropy: 3.71476
Value Function Loss: 0.02359

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14467
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.58579

Collected Steps per Second: 22,880.47856
Overall Steps per Second: 10,830.81402

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.61683

Cumulative Model Updates: 122,852
Cumulative Timesteps: 1,024,446,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1024446454...
Checkpoint 1024446454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,202.43541
Policy Entropy: 3.72369
Value Function Loss: 0.02341

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.54094
Value Function Update Magnitude: 0.63179

Collected Steps per Second: 22,973.54555
Overall Steps per Second: 10,711.65588

Timestep Collection Time: 2.17650
Timestep Consumption Time: 2.49150
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.66800

Cumulative Model Updates: 122,858
Cumulative Timesteps: 1,024,496,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,202.43541
Policy Entropy: 3.73562
Value Function Loss: 0.01728

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14505
Policy Update Magnitude: 0.51481
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 23,148.06461
Overall Steps per Second: 10,971.65938

Timestep Collection Time: 2.16139
Timestep Consumption Time: 2.39872
PPO Batch Consumption Time: 0.27565
Total Iteration Time: 4.56011

Cumulative Model Updates: 122,864
Cumulative Timesteps: 1,024,546,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1024546488...
Checkpoint 1024546488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,202.43541
Policy Entropy: 3.71290
Value Function Loss: 0.01897

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.50033
Value Function Update Magnitude: 0.67456

Collected Steps per Second: 22,078.74603
Overall Steps per Second: 10,740.19116

Timestep Collection Time: 2.26562
Timestep Consumption Time: 2.39184
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.65746

Cumulative Model Updates: 122,870
Cumulative Timesteps: 1,024,596,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,989.34139
Policy Entropy: 3.71305
Value Function Loss: 0.01937

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.72532

Collected Steps per Second: 21,884.55699
Overall Steps per Second: 10,718.26060

Timestep Collection Time: 2.28563
Timestep Consumption Time: 2.38117
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.66680

Cumulative Model Updates: 122,876
Cumulative Timesteps: 1,024,646,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1024646530...
Checkpoint 1024646530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,734.93638
Policy Entropy: 3.73144
Value Function Loss: 0.02209

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.53566
Value Function Update Magnitude: 0.68314

Collected Steps per Second: 22,328.01895
Overall Steps per Second: 10,709.53965

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.43027
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67042

Cumulative Model Updates: 122,882
Cumulative Timesteps: 1,024,696,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,468.23569
Policy Entropy: 3.74722
Value Function Loss: 0.02241

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.49224
Value Function Update Magnitude: 0.52335

Collected Steps per Second: 22,326.86480
Overall Steps per Second: 10,774.76664

Timestep Collection Time: 2.24026
Timestep Consumption Time: 2.40188
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.64214

Cumulative Model Updates: 122,888
Cumulative Timesteps: 1,024,746,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1024746566...
Checkpoint 1024746566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,468.23569
Policy Entropy: 3.72939
Value Function Loss: 0.01960

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15244
Policy Update Magnitude: 0.48188
Value Function Update Magnitude: 0.53049

Collected Steps per Second: 22,943.89551
Overall Steps per Second: 10,726.17348

Timestep Collection Time: 2.17949
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.66205

Cumulative Model Updates: 122,894
Cumulative Timesteps: 1,024,796,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,468.23569
Policy Entropy: 3.69433
Value Function Loss: 0.02063

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14946
Policy Update Magnitude: 0.47416
Value Function Update Magnitude: 0.58808

Collected Steps per Second: 22,328.99088
Overall Steps per Second: 10,798.91367

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.39200
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.63232

Cumulative Model Updates: 122,900
Cumulative Timesteps: 1,024,846,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1024846596...
Checkpoint 1024846596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,534.28151
Policy Entropy: 3.69473
Value Function Loss: 0.02162

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.48319
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 22,714.04910
Overall Steps per Second: 10,732.69968

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.45797
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.65978

Cumulative Model Updates: 122,906
Cumulative Timesteps: 1,024,896,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,239.59783
Policy Entropy: 3.69567
Value Function Loss: 0.02531

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.50677
Value Function Update Magnitude: 0.53248

Collected Steps per Second: 22,922.36294
Overall Steps per Second: 10,831.06390

Timestep Collection Time: 2.18180
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.61746

Cumulative Model Updates: 122,912
Cumulative Timesteps: 1,024,946,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1024946620...
Checkpoint 1024946620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,026.61652
Policy Entropy: 3.71495
Value Function Loss: 0.02316

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.50279
Value Function Update Magnitude: 0.54255

Collected Steps per Second: 22,955.97468
Overall Steps per Second: 10,708.69445

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.66985

Cumulative Model Updates: 122,918
Cumulative Timesteps: 1,024,996,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.71595
Value Function Loss: 0.02151

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.49696
Value Function Update Magnitude: 0.61514

Collected Steps per Second: 22,635.90040
Overall Steps per Second: 10,642.89293

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.69816

Cumulative Model Updates: 122,924
Cumulative Timesteps: 1,025,046,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1025046630...
Checkpoint 1025046630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.73822
Value Function Loss: 0.01987

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.45469
Value Function Update Magnitude: 0.56666

Collected Steps per Second: 23,287.53421
Overall Steps per Second: 10,953.75551

Timestep Collection Time: 2.14836
Timestep Consumption Time: 2.41902
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.56738

Cumulative Model Updates: 122,930
Cumulative Timesteps: 1,025,096,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.74460
Value Function Loss: 0.01695

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.40685
Value Function Update Magnitude: 0.41182

Collected Steps per Second: 23,158.89988
Overall Steps per Second: 10,934.03705

Timestep Collection Time: 2.15900
Timestep Consumption Time: 2.41388
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.57288

Cumulative Model Updates: 122,936
Cumulative Timesteps: 1,025,146,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025146660...
Checkpoint 1025146660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.73590
Value Function Loss: 0.01418

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.36079
Value Function Update Magnitude: 0.35248

Collected Steps per Second: 23,072.54920
Overall Steps per Second: 10,746.73387

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.48669
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.65481

Cumulative Model Updates: 122,942
Cumulative Timesteps: 1,025,196,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.72235
Value Function Loss: 0.01397

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.33833
Value Function Update Magnitude: 0.36253

Collected Steps per Second: 23,238.38046
Overall Steps per Second: 10,706.91369

Timestep Collection Time: 2.15170
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67007

Cumulative Model Updates: 122,948
Cumulative Timesteps: 1,025,246,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1025246686...
Checkpoint 1025246686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,598.88832
Policy Entropy: 3.71550
Value Function Loss: 0.01563

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.34754
Value Function Update Magnitude: 0.36332

Collected Steps per Second: 22,842.94210
Overall Steps per Second: 10,652.94762

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.69560

Cumulative Model Updates: 122,954
Cumulative Timesteps: 1,025,296,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,834.72859
Policy Entropy: 3.72151
Value Function Loss: 0.01672

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.38964
Value Function Update Magnitude: 0.41825

Collected Steps per Second: 23,002.78440
Overall Steps per Second: 10,838.85591

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61303

Cumulative Model Updates: 122,960
Cumulative Timesteps: 1,025,346,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1025346708...
Checkpoint 1025346708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,677.04602
Policy Entropy: 3.72381
Value Function Loss: 0.02036

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.42620
Value Function Update Magnitude: 0.46712

Collected Steps per Second: 22,980.46440
Overall Steps per Second: 10,713.38440

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.66781

Cumulative Model Updates: 122,966
Cumulative Timesteps: 1,025,396,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,924.08621
Policy Entropy: 3.73603
Value Function Loss: 0.02068

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.47287
Value Function Update Magnitude: 0.53877

Collected Steps per Second: 22,809.91271
Overall Steps per Second: 10,826.77800

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.42683
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.61947

Cumulative Model Updates: 122,972
Cumulative Timesteps: 1,025,446,730

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1025446730...
Checkpoint 1025446730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,988.48530
Policy Entropy: 3.73106
Value Function Loss: 0.02147

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.46289
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 22,804.93599
Overall Steps per Second: 10,734.23816

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.65874

Cumulative Model Updates: 122,978
Cumulative Timesteps: 1,025,496,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,731.16048
Policy Entropy: 3.73783
Value Function Loss: 0.02055

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.46485
Value Function Update Magnitude: 0.55122

Collected Steps per Second: 21,936.58479
Overall Steps per Second: 10,829.37059

Timestep Collection Time: 2.27984
Timestep Consumption Time: 2.33834
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.61818

Cumulative Model Updates: 122,984
Cumulative Timesteps: 1,025,546,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025546750...
Checkpoint 1025546750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,121.34151
Policy Entropy: 3.73219
Value Function Loss: 0.02259

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.46021
Value Function Update Magnitude: 0.54378

Collected Steps per Second: 22,182.38238
Overall Steps per Second: 10,712.64364

Timestep Collection Time: 2.25575
Timestep Consumption Time: 2.41518
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.67093

Cumulative Model Updates: 122,990
Cumulative Timesteps: 1,025,596,788

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,744.52399
Policy Entropy: 3.74088
Value Function Loss: 0.02119

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.45985
Value Function Update Magnitude: 0.52868

Collected Steps per Second: 22,308.30667
Overall Steps per Second: 10,880.69847

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.35454
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.59640

Cumulative Model Updates: 122,996
Cumulative Timesteps: 1,025,646,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1025646800...
Checkpoint 1025646800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,744.52399
Policy Entropy: 3.72406
Value Function Loss: 0.02021

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.43200
Value Function Update Magnitude: 0.45725

Collected Steps per Second: 22,196.63552
Overall Steps per Second: 10,652.20188

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.69687

Cumulative Model Updates: 123,002
Cumulative Timesteps: 1,025,696,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,744.52399
Policy Entropy: 3.73386
Value Function Loss: 0.01670

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.40374
Value Function Update Magnitude: 0.44496

Collected Steps per Second: 23,089.23837
Overall Steps per Second: 10,966.88185

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.56173

Cumulative Model Updates: 123,008
Cumulative Timesteps: 1,025,746,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1025746860...
Checkpoint 1025746860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,588.10065
Policy Entropy: 3.72561
Value Function Loss: 0.01837

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14394
Policy Update Magnitude: 0.39040
Value Function Update Magnitude: 0.40470

Collected Steps per Second: 23,089.89589
Overall Steps per Second: 10,847.31757

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.44535
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.61202

Cumulative Model Updates: 123,014
Cumulative Timesteps: 1,025,796,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,954.97815
Policy Entropy: 3.74506
Value Function Loss: 0.02049

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.40344
Value Function Update Magnitude: 0.46108

Collected Steps per Second: 22,797.31348
Overall Steps per Second: 10,669.84820

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.68873

Cumulative Model Updates: 123,020
Cumulative Timesteps: 1,025,846,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1025846916...
Checkpoint 1025846916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,409.46366
Policy Entropy: 3.73379
Value Function Loss: 0.02485

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.47936
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 22,693.43346
Overall Steps per Second: 10,613.28038

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.71334

Cumulative Model Updates: 123,026
Cumulative Timesteps: 1,025,896,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,531.47463
Policy Entropy: 3.74371
Value Function Loss: 0.02278

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.54426
Value Function Update Magnitude: 0.74416

Collected Steps per Second: 22,640.92618
Overall Steps per Second: 10,711.67343

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.66874

Cumulative Model Updates: 123,032
Cumulative Timesteps: 1,025,946,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1025946950...
Checkpoint 1025946950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,531.47463
Policy Entropy: 3.73222
Value Function Loss: 0.02070

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.53809
Value Function Update Magnitude: 0.66735

Collected Steps per Second: 22,801.39517
Overall Steps per Second: 10,813.08196

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.62440

Cumulative Model Updates: 123,038
Cumulative Timesteps: 1,025,996,954

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,502.03337
Policy Entropy: 3.73354
Value Function Loss: 0.01776

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.50552
Value Function Update Magnitude: 0.50085

Collected Steps per Second: 22,729.05778
Overall Steps per Second: 10,634.95731

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.50195
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70204

Cumulative Model Updates: 123,044
Cumulative Timesteps: 1,026,046,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1026046960...
Checkpoint 1026046960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,247.12051
Policy Entropy: 3.73441
Value Function Loss: 0.01950

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.45947
Value Function Update Magnitude: 0.47351

Collected Steps per Second: 23,179.46868
Overall Steps per Second: 10,920.82630

Timestep Collection Time: 2.15794
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.58024

Cumulative Model Updates: 123,050
Cumulative Timesteps: 1,026,096,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,042.32250
Policy Entropy: 3.73199
Value Function Loss: 0.01850

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14355
Policy Update Magnitude: 0.42235
Value Function Update Magnitude: 0.51991

Collected Steps per Second: 22,808.42478
Overall Steps per Second: 10,706.93124

Timestep Collection Time: 2.19305
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67174

Cumulative Model Updates: 123,056
Cumulative Timesteps: 1,026,147,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1026147000...
Checkpoint 1026147000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,042.32250
Policy Entropy: 3.72011
Value Function Loss: 0.01918

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.43032
Value Function Update Magnitude: 0.56028

Collected Steps per Second: 23,195.25301
Overall Steps per Second: 10,965.84419

Timestep Collection Time: 2.15604
Timestep Consumption Time: 2.40448
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.56052

Cumulative Model Updates: 123,062
Cumulative Timesteps: 1,026,197,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,793.47243
Policy Entropy: 3.73006
Value Function Loss: 0.01901

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.44975
Value Function Update Magnitude: 0.60052

Collected Steps per Second: 22,033.10260
Overall Steps per Second: 10,802.35895

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.36006
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.63010

Cumulative Model Updates: 123,068
Cumulative Timesteps: 1,026,247,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1026247026...
Checkpoint 1026247026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,652.64866
Policy Entropy: 3.72129
Value Function Loss: 0.02047

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.47420
Value Function Update Magnitude: 0.58666

Collected Steps per Second: 22,166.50754
Overall Steps per Second: 10,663.05046

Timestep Collection Time: 2.25638
Timestep Consumption Time: 2.43421
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69059

Cumulative Model Updates: 123,074
Cumulative Timesteps: 1,026,297,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,068.32308
Policy Entropy: 3.73273
Value Function Loss: 0.02046

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14169
Policy Update Magnitude: 0.49527
Value Function Update Magnitude: 0.65188

Collected Steps per Second: 21,907.78266
Overall Steps per Second: 10,666.70056

Timestep Collection Time: 2.28293
Timestep Consumption Time: 2.40586
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.68880

Cumulative Model Updates: 123,080
Cumulative Timesteps: 1,026,347,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1026347056...
Checkpoint 1026347056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,890.87814
Policy Entropy: 3.75290
Value Function Loss: 0.01953

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.52850
Value Function Update Magnitude: 0.59805

Collected Steps per Second: 22,234.03303
Overall Steps per Second: 10,664.73947

Timestep Collection Time: 2.24916
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.68910

Cumulative Model Updates: 123,086
Cumulative Timesteps: 1,026,397,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,582.84047
Policy Entropy: 3.75031
Value Function Loss: 0.01875

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.54280
Value Function Update Magnitude: 0.48767

Collected Steps per Second: 22,501.41579
Overall Steps per Second: 10,708.43175

Timestep Collection Time: 2.22262
Timestep Consumption Time: 2.44772
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.67034

Cumulative Model Updates: 123,092
Cumulative Timesteps: 1,026,447,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1026447076...
Checkpoint 1026447076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,582.84047
Policy Entropy: 3.77042
Value Function Loss: 0.01657

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.57736
Value Function Update Magnitude: 0.47550

Collected Steps per Second: 22,891.96764
Overall Steps per Second: 10,798.38952

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.44771
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.63328

Cumulative Model Updates: 123,098
Cumulative Timesteps: 1,026,497,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,511.87491
Policy Entropy: 3.74804
Value Function Loss: 0.01620

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.60544
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 23,330.71423
Overall Steps per Second: 10,735.52127

Timestep Collection Time: 2.14310
Timestep Consumption Time: 2.51434
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.65744

Cumulative Model Updates: 123,104
Cumulative Timesteps: 1,026,547,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1026547108...
Checkpoint 1026547108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,080.07222
Policy Entropy: 3.75917
Value Function Loss: 0.01525

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 0.60849
Value Function Update Magnitude: 0.71062

Collected Steps per Second: 22,911.86826
Overall Steps per Second: 10,709.53427

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.48666
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.66911

Cumulative Model Updates: 123,110
Cumulative Timesteps: 1,026,597,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,828.83003
Policy Entropy: 3.76833
Value Function Loss: 0.01594

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06552
Policy Update Magnitude: 0.60782
Value Function Update Magnitude: 0.74113

Collected Steps per Second: 23,278.97770
Overall Steps per Second: 10,840.45172

Timestep Collection Time: 2.14820
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.61309

Cumulative Model Updates: 123,116
Cumulative Timesteps: 1,026,647,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1026647120...
Checkpoint 1026647120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,071.89728
Policy Entropy: 3.78041
Value Function Loss: 0.01388

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06132
Policy Update Magnitude: 0.59572
Value Function Update Magnitude: 0.68895

Collected Steps per Second: 22,978.99200
Overall Steps per Second: 10,698.79274

Timestep Collection Time: 2.17616
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.67399

Cumulative Model Updates: 123,122
Cumulative Timesteps: 1,026,697,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,376.33372
Policy Entropy: 3.76752
Value Function Loss: 0.01422

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05296
Policy Update Magnitude: 0.58258
Value Function Update Magnitude: 0.65163

Collected Steps per Second: 22,823.43565
Overall Steps per Second: 10,846.14007

Timestep Collection Time: 2.19178
Timestep Consumption Time: 2.42037
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.61215

Cumulative Model Updates: 123,128
Cumulative Timesteps: 1,026,747,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1026747150...
Checkpoint 1026747150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,095.90202
Policy Entropy: 3.76464
Value Function Loss: 0.01678

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07956
Policy Update Magnitude: 0.61236
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 23,131.87124
Overall Steps per Second: 10,761.85264

Timestep Collection Time: 2.16152
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.64604

Cumulative Model Updates: 123,134
Cumulative Timesteps: 1,026,797,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,693.19955
Policy Entropy: 3.74942
Value Function Loss: 0.02104

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.07571
Policy Update Magnitude: 0.73970
Value Function Update Magnitude: 0.59368

Collected Steps per Second: 22,874.12027
Overall Steps per Second: 10,729.21674

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.66222

Cumulative Model Updates: 123,140
Cumulative Timesteps: 1,026,847,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1026847172...
Checkpoint 1026847172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,575.34272
Policy Entropy: 3.77856
Value Function Loss: 0.02064

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.74005
Value Function Update Magnitude: 0.64382

Collected Steps per Second: 22,671.09551
Overall Steps per Second: 10,679.19533

Timestep Collection Time: 2.20677
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.68481

Cumulative Model Updates: 123,146
Cumulative Timesteps: 1,026,897,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,575.34272
Policy Entropy: 3.78089
Value Function Loss: 0.01634

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.61815
Value Function Update Magnitude: 0.69762

Collected Steps per Second: 22,976.89729
Overall Steps per Second: 10,861.93068

Timestep Collection Time: 2.17697
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.60507

Cumulative Model Updates: 123,152
Cumulative Timesteps: 1,026,947,222

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1026947222...
Checkpoint 1026947222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,575.34272
Policy Entropy: 3.74350
Value Function Loss: 0.01855

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.69383
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 22,502.67280
Overall Steps per Second: 10,705.82272

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.67185

Cumulative Model Updates: 123,158
Cumulative Timesteps: 1,026,997,238

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,397.12832
Policy Entropy: 3.72770
Value Function Loss: 0.01815

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.77407
Value Function Update Magnitude: 0.60752

Collected Steps per Second: 22,609.02180
Overall Steps per Second: 10,785.16209

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.63674

Cumulative Model Updates: 123,164
Cumulative Timesteps: 1,027,047,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1027047246...
Checkpoint 1027047246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,826.73930
Policy Entropy: 3.72655
Value Function Loss: 0.02102

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.79220
Value Function Update Magnitude: 0.57249

Collected Steps per Second: 22,707.94310
Overall Steps per Second: 10,753.04349

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.65133

Cumulative Model Updates: 123,170
Cumulative Timesteps: 1,027,097,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,963.73182
Policy Entropy: 3.76748
Value Function Loss: 0.01621

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.75281
Value Function Update Magnitude: 0.52976

Collected Steps per Second: 22,410.85084
Overall Steps per Second: 10,910.09388

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.35251
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.58420

Cumulative Model Updates: 123,176
Cumulative Timesteps: 1,027,147,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1027147276...
Checkpoint 1027147276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,672.28341
Policy Entropy: 3.77544
Value Function Loss: 0.01451

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.59150
Value Function Update Magnitude: 0.54012

Collected Steps per Second: 22,299.56284
Overall Steps per Second: 10,765.22152

Timestep Collection Time: 2.24309
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.64644

Cumulative Model Updates: 123,182
Cumulative Timesteps: 1,027,197,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 443,371.04327
Policy Entropy: 3.76047
Value Function Loss: 0.02780

Mean KL Divergence: 0.01949
SB3 Clip Fraction: 0.22172
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.55089

Collected Steps per Second: 21,845.65824
Overall Steps per Second: 10,754.03131

Timestep Collection Time: 2.29089
Timestep Consumption Time: 2.36281
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.65370

Cumulative Model Updates: 123,188
Cumulative Timesteps: 1,027,247,342

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1027247342...
Checkpoint 1027247342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,659.45408
Policy Entropy: 3.75886
Value Function Loss: 0.04380

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.82323
Value Function Update Magnitude: 0.57129

Collected Steps per Second: 21,752.38376
Overall Steps per Second: 10,601.24173

Timestep Collection Time: 2.30016
Timestep Consumption Time: 2.41947
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.71964

Cumulative Model Updates: 123,194
Cumulative Timesteps: 1,027,297,376

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,419.04658
Policy Entropy: 3.77741
Value Function Loss: 0.04273

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.16584
Policy Update Magnitude: 1.09395
Value Function Update Magnitude: 0.92860

Collected Steps per Second: 23,046.32624
Overall Steps per Second: 10,923.13095

Timestep Collection Time: 2.17137
Timestep Consumption Time: 2.40992
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.58129

Cumulative Model Updates: 123,200
Cumulative Timesteps: 1,027,347,418

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1027347418...
Checkpoint 1027347418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,385.53274
Policy Entropy: 3.81255
Value Function Loss: 0.04271

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 0.96230
Value Function Update Magnitude: 0.93086

Collected Steps per Second: 22,570.13051
Overall Steps per Second: 10,675.90699

Timestep Collection Time: 2.21549
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68382

Cumulative Model Updates: 123,206
Cumulative Timesteps: 1,027,397,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370,467.98468
Policy Entropy: 3.81133
Value Function Loss: 0.04270

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 1.00201
Value Function Update Magnitude: 0.83658

Collected Steps per Second: 22,634.25624
Overall Steps per Second: 10,825.83839

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.62098

Cumulative Model Updates: 123,212
Cumulative Timesteps: 1,027,447,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1027447448...
Checkpoint 1027447448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.86132
Policy Entropy: 3.79532
Value Function Loss: 0.04250

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10974
Policy Update Magnitude: 1.02943
Value Function Update Magnitude: 0.70514

Collected Steps per Second: 22,311.38053
Overall Steps per Second: 10,785.77508

Timestep Collection Time: 2.24235
Timestep Consumption Time: 2.39616
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63852

Cumulative Model Updates: 123,218
Cumulative Timesteps: 1,027,497,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,386.88678
Policy Entropy: 3.76990
Value Function Loss: 0.04016

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10272
Policy Update Magnitude: 1.06524
Value Function Update Magnitude: 0.62041

Collected Steps per Second: 22,892.17476
Overall Steps per Second: 10,937.53394

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.38745
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.57178

Cumulative Model Updates: 123,224
Cumulative Timesteps: 1,027,547,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1027547482...
Checkpoint 1027547482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,878.30975
Policy Entropy: 3.77115
Value Function Loss: 0.03275

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.94901
Value Function Update Magnitude: 0.66554

Collected Steps per Second: 23,024.87328
Overall Steps per Second: 10,731.76605

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.66112

Cumulative Model Updates: 123,230
Cumulative Timesteps: 1,027,597,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,745.20296
Policy Entropy: 3.75356
Value Function Loss: 0.02712

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.21653
Policy Update Magnitude: 0.73270
Value Function Update Magnitude: 0.78776

Collected Steps per Second: 23,111.91205
Overall Steps per Second: 10,744.62841

Timestep Collection Time: 2.16347
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.65367

Cumulative Model Updates: 123,236
Cumulative Timesteps: 1,027,647,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027647506...
Checkpoint 1027647506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,780.73737
Policy Entropy: 3.78197
Value Function Loss: 0.02092

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.19137
Policy Update Magnitude: 0.61179
Value Function Update Magnitude: 0.86331

Collected Steps per Second: 23,012.98365
Overall Steps per Second: 10,688.93103

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.50575
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.67905

Cumulative Model Updates: 123,242
Cumulative Timesteps: 1,027,697,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,455.16457
Policy Entropy: 3.74681
Value Function Loss: 0.01993

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.18390
Policy Update Magnitude: 0.57679
Value Function Update Magnitude: 0.77144

Collected Steps per Second: 23,236.62235
Overall Steps per Second: 10,905.01624

Timestep Collection Time: 2.15186
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.58523

Cumulative Model Updates: 123,248
Cumulative Timesteps: 1,027,747,522

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1027747522...
Checkpoint 1027747522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,170.18652
Policy Entropy: 3.71931
Value Function Loss: 0.02133

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.19986
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.60969

Collected Steps per Second: 23,247.99139
Overall Steps per Second: 10,975.88060

Timestep Collection Time: 2.15150
Timestep Consumption Time: 2.40559
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.55708

Cumulative Model Updates: 123,254
Cumulative Timesteps: 1,027,797,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,287.68557
Policy Entropy: 3.69801
Value Function Loss: 0.03121

Mean KL Divergence: 0.03112
SB3 Clip Fraction: 0.29913
Policy Update Magnitude: 0.46559
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 22,633.36684
Overall Steps per Second: 10,624.61027

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.70662

Cumulative Model Updates: 123,260
Cumulative Timesteps: 1,027,847,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1027847546...
Checkpoint 1027847546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,053.23932
Policy Entropy: 3.75953
Value Function Loss: 0.03656

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.62719
Value Function Update Magnitude: 0.59120

Collected Steps per Second: 22,845.04328
Overall Steps per Second: 10,705.81058

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67447

Cumulative Model Updates: 123,266
Cumulative Timesteps: 1,027,897,590

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,501.90325
Policy Entropy: 3.82296
Value Function Loss: 0.03745

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.71036
Value Function Update Magnitude: 0.78797

Collected Steps per Second: 23,087.24971
Overall Steps per Second: 10,728.02538

Timestep Collection Time: 2.16587
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.66106

Cumulative Model Updates: 123,272
Cumulative Timesteps: 1,027,947,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1027947594...
Checkpoint 1027947594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,170.14313
Policy Entropy: 3.87123
Value Function Loss: 0.04204

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.64529
Value Function Update Magnitude: 0.79563

Collected Steps per Second: 23,201.39446
Overall Steps per Second: 10,883.47986

Timestep Collection Time: 2.15590
Timestep Consumption Time: 2.44005
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.59596

Cumulative Model Updates: 123,278
Cumulative Timesteps: 1,027,997,614

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 495.00649
Policy Entropy: 3.86189
Value Function Loss: 0.04183

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.59181
Value Function Update Magnitude: 0.72926

Collected Steps per Second: 22,534.13435
Overall Steps per Second: 10,695.54917

Timestep Collection Time: 2.22125
Timestep Consumption Time: 2.45864
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.67989

Cumulative Model Updates: 123,284
Cumulative Timesteps: 1,028,047,668

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1028047668...
Checkpoint 1028047668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.99017
Policy Entropy: 3.82031
Value Function Loss: 0.04352

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.82701

Collected Steps per Second: 22,697.96225
Overall Steps per Second: 10,696.50681

Timestep Collection Time: 2.20337
Timestep Consumption Time: 2.47218
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.67555

Cumulative Model Updates: 123,290
Cumulative Timesteps: 1,028,097,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.03382
Policy Entropy: 3.80172
Value Function Loss: 0.03895

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.52963
Value Function Update Magnitude: 0.78127

Collected Steps per Second: 23,161.03867
Overall Steps per Second: 10,795.73889

Timestep Collection Time: 2.15975
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.63349

Cumulative Model Updates: 123,296
Cumulative Timesteps: 1,028,147,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1028147702...
Checkpoint 1028147702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.19784
Policy Entropy: 3.79021
Value Function Loss: 0.03766

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15304
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.72970

Collected Steps per Second: 22,978.33052
Overall Steps per Second: 10,687.18556

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.67981

Cumulative Model Updates: 123,302
Cumulative Timesteps: 1,028,197,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,669.30838
Policy Entropy: 3.78102
Value Function Loss: 0.03151

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.51487
Value Function Update Magnitude: 0.64949

Collected Steps per Second: 22,961.43453
Overall Steps per Second: 10,855.40995

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.60637

Cumulative Model Updates: 123,308
Cumulative Timesteps: 1,028,247,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1028247720...
Checkpoint 1028247720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,303.18635
Policy Entropy: 3.76017
Value Function Loss: 0.02831

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.49863
Value Function Update Magnitude: 0.67923

Collected Steps per Second: 22,703.62861
Overall Steps per Second: 10,669.89732

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68908

Cumulative Model Updates: 123,314
Cumulative Timesteps: 1,028,297,752

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,274.41864
Policy Entropy: 3.75998
Value Function Loss: 0.02786

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.49175
Value Function Update Magnitude: 0.69136

Collected Steps per Second: 23,206.23507
Overall Steps per Second: 10,946.41867

Timestep Collection Time: 2.15597
Timestep Consumption Time: 2.41466
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.57063

Cumulative Model Updates: 123,320
Cumulative Timesteps: 1,028,347,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1028347784...
Checkpoint 1028347784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,718.88648
Policy Entropy: 3.76192
Value Function Loss: 0.02796

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.68423

Collected Steps per Second: 22,739.33980
Overall Steps per Second: 10,629.62878

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.70515

Cumulative Model Updates: 123,326
Cumulative Timesteps: 1,028,397,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.66954
Policy Entropy: 3.74370
Value Function Loss: 0.02947

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.48135
Value Function Update Magnitude: 0.65523

Collected Steps per Second: 22,742.46159
Overall Steps per Second: 10,798.77082

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.63016

Cumulative Model Updates: 123,332
Cumulative Timesteps: 1,028,447,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1028447798...
Checkpoint 1028447798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,752.60244
Policy Entropy: 3.75464
Value Function Loss: 0.02569

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14725
Policy Update Magnitude: 0.46844
Value Function Update Magnitude: 0.63617

Collected Steps per Second: 22,559.93310
Overall Steps per Second: 10,782.02953

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.42355
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.64217

Cumulative Model Updates: 123,338
Cumulative Timesteps: 1,028,497,850

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,965.47433
Policy Entropy: 3.74214
Value Function Loss: 0.02551

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.43235
Value Function Update Magnitude: 0.60116

Collected Steps per Second: 22,878.46765
Overall Steps per Second: 10,843.54127

Timestep Collection Time: 2.18616
Timestep Consumption Time: 2.42635
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.61252

Cumulative Model Updates: 123,344
Cumulative Timesteps: 1,028,547,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1028547866...
Checkpoint 1028547866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,270.25130
Policy Entropy: 3.75645
Value Function Loss: 0.02732

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.42660
Value Function Update Magnitude: 0.63251

Collected Steps per Second: 22,799.00926
Overall Steps per Second: 10,668.79391

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.68938

Cumulative Model Updates: 123,350
Cumulative Timesteps: 1,028,597,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,759.19554
Policy Entropy: 3.73479
Value Function Loss: 0.02848

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14847
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 23,016.09581
Overall Steps per Second: 10,872.15667

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.60166

Cumulative Model Updates: 123,356
Cumulative Timesteps: 1,028,647,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1028647926...
Checkpoint 1028647926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,112.87144
Policy Entropy: 3.71862
Value Function Loss: 0.02821

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.48392
Value Function Update Magnitude: 0.61251

Collected Steps per Second: 22,554.80084
Overall Steps per Second: 10,647.98246

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.47979
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.69742

Cumulative Model Updates: 123,362
Cumulative Timesteps: 1,028,697,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,037.74132
Policy Entropy: 3.72380
Value Function Loss: 0.02440

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.45581
Value Function Update Magnitude: 0.58649

Collected Steps per Second: 22,271.43024
Overall Steps per Second: 10,882.80848

Timestep Collection Time: 2.24530
Timestep Consumption Time: 2.34966
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.59495

Cumulative Model Updates: 123,368
Cumulative Timesteps: 1,028,747,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1028747950...
Checkpoint 1028747950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,186.71853
Policy Entropy: 3.72591
Value Function Loss: 0.02481

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.43355
Value Function Update Magnitude: 0.60640

Collected Steps per Second: 21,900.56617
Overall Steps per Second: 10,710.07107

Timestep Collection Time: 2.28305
Timestep Consumption Time: 2.38546
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.66850

Cumulative Model Updates: 123,374
Cumulative Timesteps: 1,028,797,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,641.46719
Policy Entropy: 3.74781
Value Function Loss: 0.02392

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.43226
Value Function Update Magnitude: 0.63665

Collected Steps per Second: 22,261.19343
Overall Steps per Second: 10,857.65768

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.35927
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.60560

Cumulative Model Updates: 123,380
Cumulative Timesteps: 1,028,847,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1028847956...
Checkpoint 1028847956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,996.63819
Policy Entropy: 3.75230
Value Function Loss: 0.02628

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.43694
Value Function Update Magnitude: 0.68101

Collected Steps per Second: 22,019.39731
Overall Steps per Second: 10,677.74971

Timestep Collection Time: 2.27109
Timestep Consumption Time: 2.41230
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68338

Cumulative Model Updates: 123,386
Cumulative Timesteps: 1,028,897,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,582.59298
Policy Entropy: 3.75467
Value Function Loss: 0.02381

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.46351
Value Function Update Magnitude: 0.75753

Collected Steps per Second: 22,571.63598
Overall Steps per Second: 10,820.12124

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62324

Cumulative Model Updates: 123,392
Cumulative Timesteps: 1,028,947,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1028947988...
Checkpoint 1028947988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,875.26393
Policy Entropy: 3.72316
Value Function Loss: 0.02412

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.45523
Value Function Update Magnitude: 0.91583

Collected Steps per Second: 22,433.41909
Overall Steps per Second: 10,707.33470

Timestep Collection Time: 2.22944
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.67100

Cumulative Model Updates: 123,398
Cumulative Timesteps: 1,028,998,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,875.26393
Policy Entropy: 3.70151
Value Function Loss: 0.02078

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 0.46059
Value Function Update Magnitude: 0.92593

Collected Steps per Second: 23,081.98798
Overall Steps per Second: 10,945.59835

Timestep Collection Time: 2.16740
Timestep Consumption Time: 2.40320
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.57060

Cumulative Model Updates: 123,404
Cumulative Timesteps: 1,029,048,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1029048030...
Checkpoint 1029048030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,775.97700
Policy Entropy: 3.70125
Value Function Loss: 0.01980

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.46688
Value Function Update Magnitude: 0.88250

Collected Steps per Second: 22,835.72849
Overall Steps per Second: 10,658.99578

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69237

Cumulative Model Updates: 123,410
Cumulative Timesteps: 1,029,098,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,483.45066
Policy Entropy: 3.71468
Value Function Loss: 0.01862

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.48920
Value Function Update Magnitude: 0.81558

Collected Steps per Second: 23,076.71330
Overall Steps per Second: 10,862.30168

Timestep Collection Time: 2.16712
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60400

Cumulative Model Updates: 123,416
Cumulative Timesteps: 1,029,148,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1029148056...
Checkpoint 1029148056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,998.67119
Policy Entropy: 3.75125
Value Function Loss: 0.02028

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.49806
Value Function Update Magnitude: 0.67466

Collected Steps per Second: 22,971.49117
Overall Steps per Second: 10,691.04220

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.67831

Cumulative Model Updates: 123,422
Cumulative Timesteps: 1,029,198,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,969.31357
Policy Entropy: 3.74862
Value Function Loss: 0.02051

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.64215

Collected Steps per Second: 22,967.99436
Overall Steps per Second: 10,856.58018

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60605

Cumulative Model Updates: 123,428
Cumulative Timesteps: 1,029,248,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1029248078...
Checkpoint 1029248078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,969.31357
Policy Entropy: 3.74852
Value Function Loss: 0.01980

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.44406
Value Function Update Magnitude: 0.62220

Collected Steps per Second: 22,642.76287
Overall Steps per Second: 10,683.65090

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.47223
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.68080

Cumulative Model Updates: 123,434
Cumulative Timesteps: 1,029,298,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,191.53709
Policy Entropy: 3.73695
Value Function Loss: 0.02050

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14966
Policy Update Magnitude: 0.41483
Value Function Update Magnitude: 0.54615

Collected Steps per Second: 22,901.33654
Overall Steps per Second: 10,861.28680

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.60535

Cumulative Model Updates: 123,440
Cumulative Timesteps: 1,029,348,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1029348106...
Checkpoint 1029348106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,149.90420
Policy Entropy: 3.73710
Value Function Loss: 0.02032

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.40319
Value Function Update Magnitude: 0.54550

Collected Steps per Second: 22,948.41332
Overall Steps per Second: 10,739.08026

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.65850

Cumulative Model Updates: 123,446
Cumulative Timesteps: 1,029,398,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,999.21290
Policy Entropy: 3.74140
Value Function Loss: 0.02099

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.15189
Policy Update Magnitude: 0.39849
Value Function Update Magnitude: 0.52206

Collected Steps per Second: 23,365.58185
Overall Steps per Second: 10,922.00946

Timestep Collection Time: 2.14058
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.57938

Cumulative Model Updates: 123,452
Cumulative Timesteps: 1,029,448,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1029448150...
Checkpoint 1029448150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,453.96127
Policy Entropy: 3.72535
Value Function Loss: 0.02205

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.38163
Value Function Update Magnitude: 0.50357

Collected Steps per Second: 22,157.72155
Overall Steps per Second: 10,728.92855

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.40452
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.66179

Cumulative Model Updates: 123,458
Cumulative Timesteps: 1,029,498,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,576.26261
Policy Entropy: 3.73232
Value Function Loss: 0.02293

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.37905
Value Function Update Magnitude: 0.46421

Collected Steps per Second: 22,134.27103
Overall Steps per Second: 10,808.94100

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.36695
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.62599

Cumulative Model Updates: 123,464
Cumulative Timesteps: 1,029,548,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1029548168...
Checkpoint 1029548168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,977.56286
Policy Entropy: 3.72807
Value Function Loss: 0.02380

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.41542
Value Function Update Magnitude: 0.50784

Collected Steps per Second: 22,274.22015
Overall Steps per Second: 10,732.77714

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.41388
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.65863

Cumulative Model Updates: 123,470
Cumulative Timesteps: 1,029,598,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.74554
Value Function Loss: 0.02218

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.45720
Value Function Update Magnitude: 0.58170

Collected Steps per Second: 22,481.46167
Overall Steps per Second: 10,769.03296

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.41986
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.64480

Cumulative Model Updates: 123,476
Cumulative Timesteps: 1,029,648,188

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1029648188...
Checkpoint 1029648188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.73105
Value Function Loss: 0.02322

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.46696
Value Function Update Magnitude: 0.59785

Collected Steps per Second: 22,566.84936
Overall Steps per Second: 10,646.68214

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.48076
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.69649

Cumulative Model Updates: 123,482
Cumulative Timesteps: 1,029,698,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.72300
Value Function Loss: 0.02074

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.45667
Value Function Update Magnitude: 0.51377

Collected Steps per Second: 23,200.90139
Overall Steps per Second: 10,927.58383

Timestep Collection Time: 2.15552
Timestep Consumption Time: 2.42097
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.57649

Cumulative Model Updates: 123,488
Cumulative Timesteps: 1,029,748,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1029748200...
Checkpoint 1029748200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.71097
Value Function Loss: 0.02041

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.15106
Policy Update Magnitude: 0.41308
Value Function Update Magnitude: 0.51137

Collected Steps per Second: 22,728.40277
Overall Steps per Second: 10,674.79096

Timestep Collection Time: 2.20024
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68468

Cumulative Model Updates: 123,494
Cumulative Timesteps: 1,029,798,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.72563
Value Function Loss: 0.01640

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.38710
Value Function Update Magnitude: 0.40566

Collected Steps per Second: 22,980.54191
Overall Steps per Second: 10,840.05271

Timestep Collection Time: 2.17593
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.61289

Cumulative Model Updates: 123,500
Cumulative Timesteps: 1,029,848,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1029848212...
Checkpoint 1029848212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.71735
Value Function Loss: 0.01660

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15804
Policy Update Magnitude: 0.37148
Value Function Update Magnitude: 0.36315

Collected Steps per Second: 22,928.36912
Overall Steps per Second: 10,696.29661

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.49381
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.67452

Cumulative Model Updates: 123,506
Cumulative Timesteps: 1,029,898,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.72125
Value Function Loss: 0.01417

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.35809
Value Function Update Magnitude: 0.39000

Collected Steps per Second: 23,147.94882
Overall Steps per Second: 10,860.91426

Timestep Collection Time: 2.16002
Timestep Consumption Time: 2.44365
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60366

Cumulative Model Updates: 123,512
Cumulative Timesteps: 1,029,948,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1029948212...
Checkpoint 1029948212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,342.28545
Policy Entropy: 3.71456
Value Function Loss: 0.01691

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.15716
Policy Update Magnitude: 0.37648
Value Function Update Magnitude: 0.40841

Collected Steps per Second: 22,145.77987
Overall Steps per Second: 10,597.68705

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.46113
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71971

Cumulative Model Updates: 123,518
Cumulative Timesteps: 1,029,998,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,615.74746
Policy Entropy: 3.70982
Value Function Loss: 0.02016

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.40485
Value Function Update Magnitude: 0.48882

Collected Steps per Second: 23,059.83082
Overall Steps per Second: 10,874.15167

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.43095
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60027

Cumulative Model Updates: 123,524
Cumulative Timesteps: 1,030,048,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030048254...
Checkpoint 1030048254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,962.05527
Policy Entropy: 3.71775
Value Function Loss: 0.02156

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.46496
Value Function Update Magnitude: 0.61640

Collected Steps per Second: 21,990.00055
Overall Steps per Second: 10,705.30293

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.39826
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.67338

Cumulative Model Updates: 123,530
Cumulative Timesteps: 1,030,098,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,524.13960
Policy Entropy: 3.72382
Value Function Loss: 0.02120

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.48113
Value Function Update Magnitude: 0.60005

Collected Steps per Second: 22,539.19358
Overall Steps per Second: 10,973.02576

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.33995
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.55991

Cumulative Model Updates: 123,536
Cumulative Timesteps: 1,030,148,320

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1030148320...
Checkpoint 1030148320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,524.13960
Policy Entropy: 3.72417
Value Function Loss: 0.02010

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.46800
Value Function Update Magnitude: 0.58562

Collected Steps per Second: 22,089.89309
Overall Steps per Second: 10,735.40370

Timestep Collection Time: 2.26420
Timestep Consumption Time: 2.39477
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.65898

Cumulative Model Updates: 123,542
Cumulative Timesteps: 1,030,198,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,524.13960
Policy Entropy: 3.71644
Value Function Loss: 0.01707

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.44834
Value Function Update Magnitude: 0.64933

Collected Steps per Second: 23,044.80844
Overall Steps per Second: 10,865.10169

Timestep Collection Time: 2.17090
Timestep Consumption Time: 2.43357
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.60447

Cumulative Model Updates: 123,548
Cumulative Timesteps: 1,030,248,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1030248364...
Checkpoint 1030248364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,524.13960
Policy Entropy: 3.71411
Value Function Loss: 0.01635

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.41987
Value Function Update Magnitude: 0.62745

Collected Steps per Second: 22,585.69131
Overall Steps per Second: 10,688.72101

Timestep Collection Time: 2.21415
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67858

Cumulative Model Updates: 123,554
Cumulative Timesteps: 1,030,298,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,512.49494
Policy Entropy: 3.71770
Value Function Loss: 0.01689

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.41790
Value Function Update Magnitude: 0.61194

Collected Steps per Second: 22,964.51035
Overall Steps per Second: 10,869.61152

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.60072

Cumulative Model Updates: 123,560
Cumulative Timesteps: 1,030,348,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1030348380...
Checkpoint 1030348380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,082.88095
Policy Entropy: 3.72586
Value Function Loss: 0.01747

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.49351
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 22,895.18384
Overall Steps per Second: 10,707.11461

Timestep Collection Time: 2.18465
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.67147

Cumulative Model Updates: 123,566
Cumulative Timesteps: 1,030,398,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,433.49176
Policy Entropy: 3.70172
Value Function Loss: 0.02073

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.70713

Collected Steps per Second: 22,822.60688
Overall Steps per Second: 10,823.30889

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.62021

Cumulative Model Updates: 123,572
Cumulative Timesteps: 1,030,448,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1030448404...
Checkpoint 1030448404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296,805.13224
Policy Entropy: 3.71671
Value Function Loss: 0.02191

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.52751
Value Function Update Magnitude: 0.75923

Collected Steps per Second: 22,215.94528
Overall Steps per Second: 10,623.67844

Timestep Collection Time: 2.25163
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.70854

Cumulative Model Updates: 123,578
Cumulative Timesteps: 1,030,498,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,161.98871
Policy Entropy: 3.70501
Value Function Loss: 0.02682

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.82326

Collected Steps per Second: 23,116.25944
Overall Steps per Second: 10,927.68555

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.57645

Cumulative Model Updates: 123,584
Cumulative Timesteps: 1,030,548,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1030548436...
Checkpoint 1030548436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,294.05738
Policy Entropy: 3.74789
Value Function Loss: 0.02595

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.81508

Collected Steps per Second: 22,979.21487
Overall Steps per Second: 10,743.51818

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65509

Cumulative Model Updates: 123,590
Cumulative Timesteps: 1,030,598,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,586.07465
Policy Entropy: 3.74588
Value Function Loss: 0.02550

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.80366

Collected Steps per Second: 22,571.53311
Overall Steps per Second: 10,745.66780

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.65527

Cumulative Model Updates: 123,596
Cumulative Timesteps: 1,030,648,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1030648472...
Checkpoint 1030648472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,488.72499
Policy Entropy: 3.75614
Value Function Loss: 0.02257

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.81585

Collected Steps per Second: 22,161.12471
Overall Steps per Second: 10,655.81391

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.69509

Cumulative Model Updates: 123,602
Cumulative Timesteps: 1,030,698,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,778.38904
Policy Entropy: 3.73654
Value Function Loss: 0.02202

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.15039
Policy Update Magnitude: 0.51356
Value Function Update Magnitude: 0.81325

Collected Steps per Second: 22,431.80050
Overall Steps per Second: 10,928.28379

Timestep Collection Time: 2.23041
Timestep Consumption Time: 2.34781
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.57821

Cumulative Model Updates: 123,608
Cumulative Timesteps: 1,030,748,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1030748534...
Checkpoint 1030748534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.80018
Policy Entropy: 3.74011
Value Function Loss: 0.02323

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.48658
Value Function Update Magnitude: 0.67892

Collected Steps per Second: 22,064.09596
Overall Steps per Second: 10,649.91676

Timestep Collection Time: 2.26748
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.69769

Cumulative Model Updates: 123,614
Cumulative Timesteps: 1,030,798,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.80018
Policy Entropy: 3.75149
Value Function Loss: 0.02017

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.44135
Value Function Update Magnitude: 0.52334

Collected Steps per Second: 23,221.71543
Overall Steps per Second: 10,896.05264

Timestep Collection Time: 2.15402
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.59065

Cumulative Model Updates: 123,620
Cumulative Timesteps: 1,030,848,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1030848584...
Checkpoint 1030848584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.80018
Policy Entropy: 3.73668
Value Function Loss: 0.01849

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.40898
Value Function Update Magnitude: 0.43172

Collected Steps per Second: 22,775.62931
Overall Steps per Second: 10,725.77087

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.66279

Cumulative Model Updates: 123,626
Cumulative Timesteps: 1,030,898,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,935.80018
Policy Entropy: 3.74753
Value Function Loss: 0.01451

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.39162
Value Function Update Magnitude: 0.43076

Collected Steps per Second: 22,959.69706
Overall Steps per Second: 10,898.36421

Timestep Collection Time: 2.17790
Timestep Consumption Time: 2.41031
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.58821

Cumulative Model Updates: 123,632
Cumulative Timesteps: 1,030,948,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1030948600...
Checkpoint 1030948600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,726.98787
Policy Entropy: 3.72236
Value Function Loss: 0.01776

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.38463
Value Function Update Magnitude: 0.44300

Collected Steps per Second: 22,919.16470
Overall Steps per Second: 10,727.73390

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.48053
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.66324

Cumulative Model Updates: 123,638
Cumulative Timesteps: 1,030,998,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,726.98787
Policy Entropy: 3.73746
Value Function Loss: 0.01628

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.42497
Value Function Update Magnitude: 0.62834

Collected Steps per Second: 22,900.26759
Overall Steps per Second: 10,758.79523

Timestep Collection Time: 2.18338
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.64736

Cumulative Model Updates: 123,644
Cumulative Timesteps: 1,031,048,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1031048626...
Checkpoint 1031048626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,726.98787
Policy Entropy: 3.72224
Value Function Loss: 0.02148

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.48740
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 22,682.30858
Overall Steps per Second: 10,608.21785

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71597

Cumulative Model Updates: 123,650
Cumulative Timesteps: 1,031,098,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,936.25896
Policy Entropy: 3.72611
Value Function Loss: 0.02248

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.51395
Value Function Update Magnitude: 0.57414

Collected Steps per Second: 22,815.28539
Overall Steps per Second: 10,828.40246

Timestep Collection Time: 2.19160
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61767

Cumulative Model Updates: 123,656
Cumulative Timesteps: 1,031,148,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031148656...
Checkpoint 1031148656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,936.25896
Policy Entropy: 3.72239
Value Function Loss: 0.02349

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14889
Policy Update Magnitude: 0.50653
Value Function Update Magnitude: 0.51074

Collected Steps per Second: 22,667.94967
Overall Steps per Second: 10,641.20926

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.69871

Cumulative Model Updates: 123,662
Cumulative Timesteps: 1,031,198,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,936.25896
Policy Entropy: 3.71806
Value Function Loss: 0.02333

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.47257
Value Function Update Magnitude: 0.45398

Collected Steps per Second: 22,943.27247
Overall Steps per Second: 10,726.44513

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.66250

Cumulative Model Updates: 123,668
Cumulative Timesteps: 1,031,248,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1031248668...
Checkpoint 1031248668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,936.25896
Policy Entropy: 3.73705
Value Function Loss: 0.02053

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.44871
Value Function Update Magnitude: 0.41065

Collected Steps per Second: 22,642.96877
Overall Steps per Second: 10,822.72675

Timestep Collection Time: 2.20881
Timestep Consumption Time: 2.41239
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.62120

Cumulative Model Updates: 123,674
Cumulative Timesteps: 1,031,298,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,936.25896
Policy Entropy: 3.73518
Value Function Loss: 0.02090

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.43862
Value Function Update Magnitude: 0.41328

Collected Steps per Second: 22,706.43925
Overall Steps per Second: 10,617.36460

Timestep Collection Time: 2.20308
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.71153

Cumulative Model Updates: 123,680
Cumulative Timesteps: 1,031,348,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1031348706...
Checkpoint 1031348706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,686.46111
Policy Entropy: 3.75816
Value Function Loss: 0.01801

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14774
Policy Update Magnitude: 0.44026
Value Function Update Magnitude: 0.51740

Collected Steps per Second: 22,879.77782
Overall Steps per Second: 10,731.49974

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.66049

Cumulative Model Updates: 123,686
Cumulative Timesteps: 1,031,398,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,902.48590
Policy Entropy: 3.74310
Value Function Loss: 0.01875

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.43576
Value Function Update Magnitude: 0.57143

Collected Steps per Second: 23,158.95416
Overall Steps per Second: 10,703.24897

Timestep Collection Time: 2.15908
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.67167

Cumulative Model Updates: 123,692
Cumulative Timesteps: 1,031,448,722

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1031448722...
Checkpoint 1031448722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,647.83492
Policy Entropy: 3.75715
Value Function Loss: 0.01759

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.46492
Value Function Update Magnitude: 0.63666

Collected Steps per Second: 23,110.93921
Overall Steps per Second: 10,785.47350

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.47357
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.63809

Cumulative Model Updates: 123,698
Cumulative Timesteps: 1,031,498,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,552.82811
Policy Entropy: 3.74083
Value Function Loss: 0.01940

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.46229
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 23,221.35057
Overall Steps per Second: 10,796.66195

Timestep Collection Time: 2.15422
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.63328

Cumulative Model Updates: 123,704
Cumulative Timesteps: 1,031,548,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1031548770...
Checkpoint 1031548770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,536.19074
Policy Entropy: 3.74848
Value Function Loss: 0.02150

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.48427
Value Function Update Magnitude: 0.61503

Collected Steps per Second: 22,083.13805
Overall Steps per Second: 10,684.26437

Timestep Collection Time: 2.26490
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68128

Cumulative Model Updates: 123,710
Cumulative Timesteps: 1,031,598,786

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.72670
Value Function Loss: 0.02402

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.66159

Collected Steps per Second: 22,591.83482
Overall Steps per Second: 10,841.27468

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.40025
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.61477

Cumulative Model Updates: 123,716
Cumulative Timesteps: 1,031,648,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1031648816...
Checkpoint 1031648816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.73726
Value Function Loss: 0.02410

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.76595

Collected Steps per Second: 22,426.15386
Overall Steps per Second: 10,796.30661

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.40263
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.63307

Cumulative Model Updates: 123,722
Cumulative Timesteps: 1,031,698,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.72947
Value Function Loss: 0.02225

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.52824
Value Function Update Magnitude: 0.75862

Collected Steps per Second: 22,370.58806
Overall Steps per Second: 10,811.04032

Timestep Collection Time: 2.23544
Timestep Consumption Time: 2.39021
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.62564

Cumulative Model Updates: 123,728
Cumulative Timesteps: 1,031,748,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1031748844...
Checkpoint 1031748844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.73058
Value Function Loss: 0.02078

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.48889
Value Function Update Magnitude: 0.71156

Collected Steps per Second: 22,996.72498
Overall Steps per Second: 10,957.85442

Timestep Collection Time: 2.17544
Timestep Consumption Time: 2.39005
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.56549

Cumulative Model Updates: 123,734
Cumulative Timesteps: 1,031,798,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.71694
Value Function Loss: 0.02049

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.45119
Value Function Update Magnitude: 0.66169

Collected Steps per Second: 22,974.64527
Overall Steps per Second: 10,717.67068

Timestep Collection Time: 2.17753
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66781

Cumulative Model Updates: 123,740
Cumulative Timesteps: 1,031,848,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1031848900...
Checkpoint 1031848900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.72670
Value Function Loss: 0.01949

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.42112
Value Function Update Magnitude: 0.48919

Collected Steps per Second: 22,803.70260
Overall Steps per Second: 10,828.26927

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.61810

Cumulative Model Updates: 123,746
Cumulative Timesteps: 1,031,898,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.72994
Value Function Loss: 0.02043

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.41178
Value Function Update Magnitude: 0.38218

Collected Steps per Second: 22,924.71402
Overall Steps per Second: 10,763.40406

Timestep Collection Time: 2.18149
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.64630

Cumulative Model Updates: 123,752
Cumulative Timesteps: 1,031,948,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1031948916...
Checkpoint 1031948916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.74315
Value Function Loss: 0.01635

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.37013
Value Function Update Magnitude: 0.38453

Collected Steps per Second: 22,806.19214
Overall Steps per Second: 10,833.65584

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.42364
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.61672

Cumulative Model Updates: 123,758
Cumulative Timesteps: 1,031,998,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.74157
Value Function Loss: 0.01591

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.34688
Value Function Update Magnitude: 0.39320

Collected Steps per Second: 22,866.31676
Overall Steps per Second: 10,683.27119

Timestep Collection Time: 2.18732
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68171

Cumulative Model Updates: 123,764
Cumulative Timesteps: 1,032,048,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1032048948...
Checkpoint 1032048948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.75151
Value Function Loss: 0.01386

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.15826
Policy Update Magnitude: 0.34852
Value Function Update Magnitude: 0.37638

Collected Steps per Second: 23,215.24076
Overall Steps per Second: 10,911.06165

Timestep Collection Time: 2.15453
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.58416

Cumulative Model Updates: 123,770
Cumulative Timesteps: 1,032,098,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.74494
Value Function Loss: 0.01481

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.36158
Value Function Update Magnitude: 0.41409

Collected Steps per Second: 22,719.72406
Overall Steps per Second: 10,664.34930

Timestep Collection Time: 2.20117
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.68946

Cumulative Model Updates: 123,776
Cumulative Timesteps: 1,032,148,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1032148976...
Checkpoint 1032148976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.75564
Value Function Loss: 0.01389

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.37982
Value Function Update Magnitude: 0.44489

Collected Steps per Second: 22,263.60566
Overall Steps per Second: 10,902.89204

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.34237
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.59034

Cumulative Model Updates: 123,782
Cumulative Timesteps: 1,032,199,024

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.73385
Value Function Loss: 0.01754

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.38534
Value Function Update Magnitude: 0.52184

Collected Steps per Second: 22,061.76173
Overall Steps per Second: 10,825.73156

Timestep Collection Time: 2.26754
Timestep Consumption Time: 2.35348
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62103

Cumulative Model Updates: 123,788
Cumulative Timesteps: 1,032,249,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1032249050...
Checkpoint 1032249050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.73824
Value Function Loss: 0.02114

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.42985
Value Function Update Magnitude: 0.44866

Collected Steps per Second: 22,156.45040
Overall Steps per Second: 10,727.94827

Timestep Collection Time: 2.25686
Timestep Consumption Time: 2.40424
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.66110

Cumulative Model Updates: 123,794
Cumulative Timesteps: 1,032,299,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,612.81977
Policy Entropy: 3.71883
Value Function Loss: 0.02427

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.49056
Value Function Update Magnitude: 0.37428

Collected Steps per Second: 22,597.60264
Overall Steps per Second: 10,835.18786

Timestep Collection Time: 2.21457
Timestep Consumption Time: 2.40408
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.61866

Cumulative Model Updates: 123,800
Cumulative Timesteps: 1,032,349,098

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1032349098...
Checkpoint 1032349098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,311.49098
Policy Entropy: 3.73735
Value Function Loss: 0.02424

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.52091
Value Function Update Magnitude: 0.36626

Collected Steps per Second: 22,362.34667
Overall Steps per Second: 10,788.31583

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.39874
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.63464

Cumulative Model Updates: 123,806
Cumulative Timesteps: 1,032,399,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,297.06074
Policy Entropy: 3.73180
Value Function Loss: 0.02182

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.47917
Value Function Update Magnitude: 0.36211

Collected Steps per Second: 22,857.69764
Overall Steps per Second: 10,815.23693

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.43595
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62366

Cumulative Model Updates: 123,812
Cumulative Timesteps: 1,032,449,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1032449104...
Checkpoint 1032449104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,297.06074
Policy Entropy: 3.74885
Value Function Loss: 0.01847

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.43323
Value Function Update Magnitude: 0.45034

Collected Steps per Second: 23,046.90183
Overall Steps per Second: 10,690.15948

Timestep Collection Time: 2.16949
Timestep Consumption Time: 2.50771
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.67720

Cumulative Model Updates: 123,818
Cumulative Timesteps: 1,032,499,104

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,297.06074
Policy Entropy: 3.73496
Value Function Loss: 0.01722

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.39685
Value Function Update Magnitude: 0.41244

Collected Steps per Second: 22,600.36461
Overall Steps per Second: 10,818.82831

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62435

Cumulative Model Updates: 123,824
Cumulative Timesteps: 1,032,549,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1032549134...
Checkpoint 1032549134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,297.06074
Policy Entropy: 3.72546
Value Function Loss: 0.02113

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.35719
Value Function Update Magnitude: 0.29869

Collected Steps per Second: 22,913.13293
Overall Steps per Second: 10,713.69513

Timestep Collection Time: 2.18259
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.66786

Cumulative Model Updates: 123,830
Cumulative Timesteps: 1,032,599,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,553.71622
Policy Entropy: 3.72072
Value Function Loss: 0.02012

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14266
Policy Update Magnitude: 0.40182
Value Function Update Magnitude: 0.32023

Collected Steps per Second: 22,891.06593
Overall Steps per Second: 10,840.88537

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.42879
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.61383

Cumulative Model Updates: 123,836
Cumulative Timesteps: 1,032,649,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1032649162...
Checkpoint 1032649162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,269.11752
Policy Entropy: 3.72587
Value Function Loss: 0.02117

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.42551
Value Function Update Magnitude: 0.38544

Collected Steps per Second: 22,924.91344
Overall Steps per Second: 10,707.05857

Timestep Collection Time: 2.18121
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.67019

Cumulative Model Updates: 123,842
Cumulative Timesteps: 1,032,699,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,131.67699
Policy Entropy: 3.74955
Value Function Loss: 0.01874

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.47020
Value Function Update Magnitude: 0.55716

Collected Steps per Second: 22,734.80561
Overall Steps per Second: 10,817.86771

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.42291
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.62235

Cumulative Model Updates: 123,848
Cumulative Timesteps: 1,032,749,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1032749170...
Checkpoint 1032749170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,340.61382
Policy Entropy: 3.74713
Value Function Loss: 0.02498

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.48948
Value Function Update Magnitude: 0.58247

Collected Steps per Second: 22,742.66067
Overall Steps per Second: 10,734.87911

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.65976

Cumulative Model Updates: 123,854
Cumulative Timesteps: 1,032,799,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,816.12784
Policy Entropy: 3.74180
Value Function Loss: 0.02431

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.54361
Value Function Update Magnitude: 0.63224

Collected Steps per Second: 23,006.68797
Overall Steps per Second: 10,885.10130

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.59582

Cumulative Model Updates: 123,860
Cumulative Timesteps: 1,032,849,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1032849218...
Checkpoint 1032849218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,280.04266
Policy Entropy: 3.72863
Value Function Loss: 0.02320

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.55532
Value Function Update Magnitude: 0.79703

Collected Steps per Second: 22,893.86404
Overall Steps per Second: 10,675.76345

Timestep Collection Time: 2.18530
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.68632

Cumulative Model Updates: 123,866
Cumulative Timesteps: 1,032,899,248

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,280.04266
Policy Entropy: 3.72290
Value Function Loss: 0.01955

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.53530
Value Function Update Magnitude: 0.75635

Collected Steps per Second: 22,905.88579
Overall Steps per Second: 10,859.24651

Timestep Collection Time: 2.18363
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.60603

Cumulative Model Updates: 123,872
Cumulative Timesteps: 1,032,949,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1032949266...
Checkpoint 1032949266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857,715.36433
Policy Entropy: 3.72399
Value Function Loss: 0.01813

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.49517
Value Function Update Magnitude: 0.65131

Collected Steps per Second: 23,185.95570
Overall Steps per Second: 10,770.29456

Timestep Collection Time: 2.15786
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.64537

Cumulative Model Updates: 123,878
Cumulative Timesteps: 1,032,999,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894,023.04574
Policy Entropy: 3.71924
Value Function Loss: 0.01984

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.66229

Collected Steps per Second: 22,780.46996
Overall Steps per Second: 10,828.19051

Timestep Collection Time: 2.19539
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.61868

Cumulative Model Updates: 123,884
Cumulative Timesteps: 1,033,049,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1033049310...
Checkpoint 1033049310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,254.72995
Policy Entropy: 3.72526
Value Function Loss: 0.02116

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.76405

Collected Steps per Second: 22,976.36512
Overall Steps per Second: 10,708.22696

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.49346
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.66987

Cumulative Model Updates: 123,890
Cumulative Timesteps: 1,033,099,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,442.72317
Policy Entropy: 3.72294
Value Function Loss: 0.02056

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.59183
Value Function Update Magnitude: 0.83070

Collected Steps per Second: 22,811.30004
Overall Steps per Second: 10,842.82747

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.61300

Cumulative Model Updates: 123,896
Cumulative Timesteps: 1,033,149,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1033149334...
Checkpoint 1033149334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,094.16227
Policy Entropy: 3.73064
Value Function Loss: 0.02060

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14408
Policy Update Magnitude: 0.56211
Value Function Update Magnitude: 0.72042

Collected Steps per Second: 22,908.45520
Overall Steps per Second: 10,718.29021

Timestep Collection Time: 2.18374
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66735

Cumulative Model Updates: 123,902
Cumulative Timesteps: 1,033,199,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,427.27897
Policy Entropy: 3.73223
Value Function Loss: 0.01998

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.57957

Collected Steps per Second: 23,199.79330
Overall Steps per Second: 10,812.05184

Timestep Collection Time: 2.15614
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.62650

Cumulative Model Updates: 123,908
Cumulative Timesteps: 1,033,249,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1033249382...
Checkpoint 1033249382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309,955.36843
Policy Entropy: 3.73862
Value Function Loss: 0.02036

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.53378
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 22,923.62544
Overall Steps per Second: 10,706.68419

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67054

Cumulative Model Updates: 123,914
Cumulative Timesteps: 1,033,299,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,430.64620
Policy Entropy: 3.73122
Value Function Loss: 0.02566

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.50701

Collected Steps per Second: 22,426.04135
Overall Steps per Second: 10,732.89474

Timestep Collection Time: 2.23089
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.66137

Cumulative Model Updates: 123,920
Cumulative Timesteps: 1,033,349,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1033349418...
Checkpoint 1033349418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,375.86292
Policy Entropy: 3.74243
Value Function Loss: 0.02255

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.53454
Value Function Update Magnitude: 0.44237

Collected Steps per Second: 22,942.49859
Overall Steps per Second: 10,735.59401

Timestep Collection Time: 2.18032
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.65945

Cumulative Model Updates: 123,926
Cumulative Timesteps: 1,033,399,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,391.43935
Policy Entropy: 3.73425
Value Function Loss: 0.02535

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.51081
Value Function Update Magnitude: 0.45329

Collected Steps per Second: 23,029.58150
Overall Steps per Second: 10,882.42783

Timestep Collection Time: 2.17199
Timestep Consumption Time: 2.42441
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.59640

Cumulative Model Updates: 123,932
Cumulative Timesteps: 1,033,449,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1033449460...
Checkpoint 1033449460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368,871.52812
Policy Entropy: 3.75431
Value Function Loss: 0.02346

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.48823

Collected Steps per Second: 22,897.94507
Overall Steps per Second: 10,659.36414

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.69259

Cumulative Model Updates: 123,938
Cumulative Timesteps: 1,033,499,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,942.15593
Policy Entropy: 3.73051
Value Function Loss: 0.03282

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.19780
Policy Update Magnitude: 0.61804
Value Function Update Magnitude: 0.48346

Collected Steps per Second: 22,539.10716
Overall Steps per Second: 10,633.40442

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.48469
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.70386

Cumulative Model Updates: 123,944
Cumulative Timesteps: 1,033,549,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1033549498...
Checkpoint 1033549498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,028.75502
Policy Entropy: 3.73835
Value Function Loss: 0.03546

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.20067
Policy Update Magnitude: 0.80721
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 23,264.92658
Overall Steps per Second: 10,874.10929

Timestep Collection Time: 2.14933
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59845

Cumulative Model Updates: 123,950
Cumulative Timesteps: 1,033,599,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,483.74210
Policy Entropy: 3.75227
Value Function Loss: 0.03197

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.19427
Policy Update Magnitude: 0.82462
Value Function Update Magnitude: 0.64687

Collected Steps per Second: 22,463.93378
Overall Steps per Second: 10,580.04744

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.72625

Cumulative Model Updates: 123,956
Cumulative Timesteps: 1,033,649,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1033649506...
Checkpoint 1033649506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 657,199.38301
Policy Entropy: 3.73682
Value Function Loss: 0.03568

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.19626
Policy Update Magnitude: 0.74922
Value Function Update Magnitude: 0.72724

Collected Steps per Second: 22,868.41389
Overall Steps per Second: 10,729.04749

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.47442
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.66136

Cumulative Model Updates: 123,962
Cumulative Timesteps: 1,033,699,518

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327,842.19792
Policy Entropy: 3.76448
Value Function Loss: 0.03808

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15846
Policy Update Magnitude: 0.78041
Value Function Update Magnitude: 0.93319

Collected Steps per Second: 22,892.27567
Overall Steps per Second: 10,718.14370

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.48154
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.66629

Cumulative Model Updates: 123,968
Cumulative Timesteps: 1,033,749,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1033749532...
Checkpoint 1033749532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,752.83680
Policy Entropy: 3.75799
Value Function Loss: 0.04249

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.15283
Policy Update Magnitude: 1.02134
Value Function Update Magnitude: 0.85613

Collected Steps per Second: 23,166.43242
Overall Steps per Second: 10,765.32886

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.64510

Cumulative Model Updates: 123,974
Cumulative Timesteps: 1,033,799,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,856.98239
Policy Entropy: 3.77368
Value Function Loss: 0.04486

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.18096
Policy Update Magnitude: 0.93219
Value Function Update Magnitude: 0.74195

Collected Steps per Second: 22,683.87900
Overall Steps per Second: 10,768.70542

Timestep Collection Time: 2.20518
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.64513

Cumulative Model Updates: 123,980
Cumulative Timesteps: 1,033,849,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1033849560...
Checkpoint 1033849560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,425.18854
Policy Entropy: 3.76495
Value Function Loss: 0.04245

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 1.03259
Value Function Update Magnitude: 0.62930

Collected Steps per Second: 22,571.67101
Overall Steps per Second: 10,677.10677

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.68348

Cumulative Model Updates: 123,986
Cumulative Timesteps: 1,033,899,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,996.84761
Policy Entropy: 3.77350
Value Function Loss: 0.03817

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 1.03972
Value Function Update Magnitude: 0.77484

Collected Steps per Second: 22,687.85663
Overall Steps per Second: 10,817.97421

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62471

Cumulative Model Updates: 123,992
Cumulative Timesteps: 1,033,949,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1033949596...
Checkpoint 1033949596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,055.76920
Policy Entropy: 3.83841
Value Function Loss: 0.03351

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.90482
Value Function Update Magnitude: 0.79638

Collected Steps per Second: 22,631.06154
Overall Steps per Second: 10,719.97399

Timestep Collection Time: 2.21050
Timestep Consumption Time: 2.45611
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.66662

Cumulative Model Updates: 123,998
Cumulative Timesteps: 1,033,999,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,476.47651
Policy Entropy: 3.86747
Value Function Loss: 0.03550

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.85395
Value Function Update Magnitude: 0.82687

Collected Steps per Second: 22,789.99138
Overall Steps per Second: 10,815.80014

Timestep Collection Time: 2.19403
Timestep Consumption Time: 2.42902
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.62305

Cumulative Model Updates: 124,004
Cumulative Timesteps: 1,034,049,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1034049624...
Checkpoint 1034049624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,342.09751
Policy Entropy: 3.88024
Value Function Loss: 0.03307

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15703
Policy Update Magnitude: 0.84073
Value Function Update Magnitude: 0.88339

Collected Steps per Second: 23,114.75080
Overall Steps per Second: 10,715.55296

Timestep Collection Time: 2.16355
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.66705

Cumulative Model Updates: 124,010
Cumulative Timesteps: 1,034,099,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.85922
Policy Entropy: 3.87410
Value Function Loss: 0.03250

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.17993
Policy Update Magnitude: 0.78363
Value Function Update Magnitude: 0.93559

Collected Steps per Second: 22,513.41715
Overall Steps per Second: 10,616.61797

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.71242

Cumulative Model Updates: 124,016
Cumulative Timesteps: 1,034,149,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1034149664...
Checkpoint 1034149664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.04734
Policy Entropy: 3.85759
Value Function Loss: 0.02874

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17508
Policy Update Magnitude: 0.76502
Value Function Update Magnitude: 0.88105

Collected Steps per Second: 23,209.13573
Overall Steps per Second: 10,926.03941

Timestep Collection Time: 2.15458
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.57677

Cumulative Model Updates: 124,022
Cumulative Timesteps: 1,034,199,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,532.64897
Policy Entropy: 3.85126
Value Function Loss: 0.03003

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.18998
Policy Update Magnitude: 0.70105
Value Function Update Magnitude: 0.84458

Collected Steps per Second: 22,689.87919
Overall Steps per Second: 10,660.61730

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.48773
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.69241

Cumulative Model Updates: 124,028
Cumulative Timesteps: 1,034,249,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034249694...
Checkpoint 1034249694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,710.42676
Policy Entropy: 3.84890
Value Function Loss: 0.02859

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.18168
Policy Update Magnitude: 0.72775
Value Function Update Magnitude: 0.76360

Collected Steps per Second: 23,019.13549
Overall Steps per Second: 10,864.44240

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.60217

Cumulative Model Updates: 124,034
Cumulative Timesteps: 1,034,299,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,900.58874
Policy Entropy: 3.81416
Value Function Loss: 0.02582

Mean KL Divergence: 0.01616
SB3 Clip Fraction: 0.19870
Policy Update Magnitude: 0.73125
Value Function Update Magnitude: 0.68378

Collected Steps per Second: 22,867.15674
Overall Steps per Second: 10,729.89083

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.66212

Cumulative Model Updates: 124,040
Cumulative Timesteps: 1,034,349,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034349718...
Checkpoint 1034349718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,999.46894
Policy Entropy: 3.81725
Value Function Loss: 0.02083

Mean KL Divergence: 0.03527
SB3 Clip Fraction: 0.32691
Policy Update Magnitude: 0.59927
Value Function Update Magnitude: 0.61077

Collected Steps per Second: 22,913.67739
Overall Steps per Second: 10,835.95072

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.61796

Cumulative Model Updates: 124,046
Cumulative Timesteps: 1,034,399,758

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987.82081
Policy Entropy: 3.77241
Value Function Loss: 0.02069

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.20952
Policy Update Magnitude: 0.49335
Value Function Update Magnitude: 0.58724

Collected Steps per Second: 22,654.82385
Overall Steps per Second: 10,653.04916

Timestep Collection Time: 2.20836
Timestep Consumption Time: 2.48795
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69631

Cumulative Model Updates: 124,052
Cumulative Timesteps: 1,034,449,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1034449788...
Checkpoint 1034449788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,393.72950
Policy Entropy: 3.79457
Value Function Loss: 0.02012

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.15877
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.58123

Collected Steps per Second: 23,035.75925
Overall Steps per Second: 10,901.02811

Timestep Collection Time: 2.17175
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58929

Cumulative Model Updates: 124,058
Cumulative Timesteps: 1,034,499,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,649.41760
Policy Entropy: 3.73805
Value Function Loss: 0.02947

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17814
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.61731

Collected Steps per Second: 22,649.99918
Overall Steps per Second: 10,721.48714

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.66465

Cumulative Model Updates: 124,064
Cumulative Timesteps: 1,034,549,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1034549828...
Checkpoint 1034549828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,849.80779
Policy Entropy: 3.72417
Value Function Loss: 0.03038

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.60664
Value Function Update Magnitude: 0.65626

Collected Steps per Second: 22,893.47700
Overall Steps per Second: 10,919.91592

Timestep Collection Time: 2.18499
Timestep Consumption Time: 2.39582
PPO Batch Consumption Time: 0.27626
Total Iteration Time: 4.58080

Cumulative Model Updates: 124,070
Cumulative Timesteps: 1,034,599,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,879.55812
Policy Entropy: 3.70854
Value Function Loss: 0.03625

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.62633
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 22,593.01868
Overall Steps per Second: 10,799.78735

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.41742
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63120

Cumulative Model Updates: 124,076
Cumulative Timesteps: 1,034,649,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1034649866...
Checkpoint 1034649866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,703.55492
Policy Entropy: 3.75370
Value Function Loss: 0.03066

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12025
Policy Update Magnitude: 0.60640
Value Function Update Magnitude: 0.53017

Collected Steps per Second: 22,165.97286
Overall Steps per Second: 10,668.70641

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68660

Cumulative Model Updates: 124,082
Cumulative Timesteps: 1,034,699,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,098.10731
Policy Entropy: 3.73943
Value Function Loss: 0.03244

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.54432

Collected Steps per Second: 21,876.38212
Overall Steps per Second: 10,674.52212

Timestep Collection Time: 2.28566
Timestep Consumption Time: 2.39858
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.68424

Cumulative Model Updates: 124,088
Cumulative Timesteps: 1,034,749,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1034749868...
Checkpoint 1034749868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,753.90399
Policy Entropy: 3.76080
Value Function Loss: 0.03097

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.55981
Value Function Update Magnitude: 0.56393

Collected Steps per Second: 22,255.10776
Overall Steps per Second: 10,902.71661

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.34121
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.58968

Cumulative Model Updates: 124,094
Cumulative Timesteps: 1,034,799,908

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.76989
Policy Entropy: 3.77547
Value Function Loss: 0.03391

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.54381

Collected Steps per Second: 22,116.69644
Overall Steps per Second: 10,835.84426

Timestep Collection Time: 2.26146
Timestep Consumption Time: 2.35433
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.61579

Cumulative Model Updates: 124,100
Cumulative Timesteps: 1,034,849,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1034849924...
Checkpoint 1034849924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.06377
Policy Entropy: 3.81501
Value Function Loss: 0.03223

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.58545
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,258.71399
Overall Steps per Second: 10,670.98090

Timestep Collection Time: 2.24757
Timestep Consumption Time: 2.44066
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.68823

Cumulative Model Updates: 124,106
Cumulative Timesteps: 1,034,899,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,051.09013
Policy Entropy: 3.80607
Value Function Loss: 0.03246

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.64524

Collected Steps per Second: 22,105.15157
Overall Steps per Second: 10,851.04995

Timestep Collection Time: 2.26300
Timestep Consumption Time: 2.34706
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.61006

Cumulative Model Updates: 124,112
Cumulative Timesteps: 1,034,949,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1034949976...
Checkpoint 1034949976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,197.03494
Policy Entropy: 3.80103
Value Function Loss: 0.03013

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.54611
Value Function Update Magnitude: 0.59722

Collected Steps per Second: 22,352.81828
Overall Steps per Second: 10,771.84579

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.40526
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.64247

Cumulative Model Updates: 124,118
Cumulative Timesteps: 1,034,999,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,247.94162
Policy Entropy: 3.77743
Value Function Loss: 0.02709

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.50187
Value Function Update Magnitude: 0.56581

Collected Steps per Second: 23,246.71606
Overall Steps per Second: 10,861.27416

Timestep Collection Time: 2.15179
Timestep Consumption Time: 2.45375
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.60554

Cumulative Model Updates: 124,124
Cumulative Timesteps: 1,035,050,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1035050006...
Checkpoint 1035050006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.20054
Policy Entropy: 3.77301
Value Function Loss: 0.02427

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.44335
Value Function Update Magnitude: 0.52872

Collected Steps per Second: 23,070.48567
Overall Steps per Second: 10,841.69356

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.61256

Cumulative Model Updates: 124,130
Cumulative Timesteps: 1,035,100,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 252.56670
Policy Entropy: 3.75417
Value Function Loss: 0.02114

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.41654
Value Function Update Magnitude: 0.58528

Collected Steps per Second: 23,028.96430
Overall Steps per Second: 10,682.78335

Timestep Collection Time: 2.17239
Timestep Consumption Time: 2.51065
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.68305

Cumulative Model Updates: 124,136
Cumulative Timesteps: 1,035,150,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1035150042...
Checkpoint 1035150042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,407.67725
Policy Entropy: 3.74332
Value Function Loss: 0.02223

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.38143
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 22,962.61547
Overall Steps per Second: 10,691.59019

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.49942
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.67713

Cumulative Model Updates: 124,142
Cumulative Timesteps: 1,035,200,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,811.21328
Policy Entropy: 3.75061
Value Function Loss: 0.02222

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.38825
Value Function Update Magnitude: 0.50812

Collected Steps per Second: 22,914.39526
Overall Steps per Second: 10,843.61202

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.61156

Cumulative Model Updates: 124,148
Cumulative Timesteps: 1,035,250,054

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1035250054...
Checkpoint 1035250054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,856.83037
Policy Entropy: 3.75512
Value Function Loss: 0.02100

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.38061
Value Function Update Magnitude: 0.48698

Collected Steps per Second: 22,749.01933
Overall Steps per Second: 10,646.49715

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.69826

Cumulative Model Updates: 124,154
Cumulative Timesteps: 1,035,300,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,742.28494
Policy Entropy: 3.76844
Value Function Loss: 0.01892

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.34973
Value Function Update Magnitude: 0.47790

Collected Steps per Second: 23,090.80800
Overall Steps per Second: 10,918.72423

Timestep Collection Time: 2.16649
Timestep Consumption Time: 2.41518
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.58167

Cumulative Model Updates: 124,160
Cumulative Timesteps: 1,035,350,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1035350100...
Checkpoint 1035350100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,742.28494
Policy Entropy: 3.73592
Value Function Loss: 0.01911

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.34641
Value Function Update Magnitude: 0.55616

Collected Steps per Second: 22,612.87446
Overall Steps per Second: 10,663.47588

Timestep Collection Time: 2.21157
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.68984

Cumulative Model Updates: 124,166
Cumulative Timesteps: 1,035,400,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,742.28494
Policy Entropy: 3.72170
Value Function Loss: 0.01850

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.37637
Value Function Update Magnitude: 0.60943

Collected Steps per Second: 22,218.39352
Overall Steps per Second: 10,868.61299

Timestep Collection Time: 2.25084
Timestep Consumption Time: 2.35049
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60132

Cumulative Model Updates: 124,172
Cumulative Timesteps: 1,035,450,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1035450120...
Checkpoint 1035450120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,742.28494
Policy Entropy: 3.70957
Value Function Loss: 0.01866

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.38318
Value Function Update Magnitude: 0.50627

Collected Steps per Second: 22,441.17368
Overall Steps per Second: 10,780.72427

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.41092
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.63995

Cumulative Model Updates: 124,178
Cumulative Timesteps: 1,035,500,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469,938.69021
Policy Entropy: 3.72937
Value Function Loss: 0.01648

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14494
Policy Update Magnitude: 0.36587
Value Function Update Magnitude: 0.49390

Collected Steps per Second: 22,243.55779
Overall Steps per Second: 10,817.28120

Timestep Collection Time: 2.24820
Timestep Consumption Time: 2.37477
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.62297

Cumulative Model Updates: 124,184
Cumulative Timesteps: 1,035,550,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1035550150...
Checkpoint 1035550150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191,551.61133
Policy Entropy: 3.74546
Value Function Loss: 0.01637

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.36987
Value Function Update Magnitude: 0.53716

Collected Steps per Second: 22,291.33772
Overall Steps per Second: 10,615.99179

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.46754
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.71119

Cumulative Model Updates: 124,190
Cumulative Timesteps: 1,035,600,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,456.56595
Policy Entropy: 3.74652
Value Function Loss: 0.01630

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.35918
Value Function Update Magnitude: 0.51892

Collected Steps per Second: 23,040.33915
Overall Steps per Second: 10,951.04505

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.39691
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.56815

Cumulative Model Updates: 124,196
Cumulative Timesteps: 1,035,650,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1035650190...
Checkpoint 1035650190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,514.14176
Policy Entropy: 3.74972
Value Function Loss: 0.01752

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.39178
Value Function Update Magnitude: 0.57946

Collected Steps per Second: 23,075.78554
Overall Steps per Second: 10,962.20387

Timestep Collection Time: 2.16729
Timestep Consumption Time: 2.39493
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.56222

Cumulative Model Updates: 124,202
Cumulative Timesteps: 1,035,700,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,041.98927
Policy Entropy: 3.74338
Value Function Loss: 0.01855

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.40525
Value Function Update Magnitude: 0.66543

Collected Steps per Second: 22,973.98703
Overall Steps per Second: 10,765.61368

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.64739

Cumulative Model Updates: 124,208
Cumulative Timesteps: 1,035,750,234

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1035750234...
Checkpoint 1035750234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,803.41572
Policy Entropy: 3.75395
Value Function Loss: 0.01975

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.43635
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 22,708.54258
Overall Steps per Second: 10,815.59068

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62481

Cumulative Model Updates: 124,214
Cumulative Timesteps: 1,035,800,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,155.72679
Policy Entropy: 3.74866
Value Function Loss: 0.01967

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.45071
Value Function Update Magnitude: 0.62712

Collected Steps per Second: 23,449.93163
Overall Steps per Second: 10,969.05350

Timestep Collection Time: 2.13348
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.56101

Cumulative Model Updates: 124,220
Cumulative Timesteps: 1,035,850,284

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1035850284...
Checkpoint 1035850284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,416.01745
Policy Entropy: 3.74035
Value Function Loss: 0.01952

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.44241
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 22,800.37250
Overall Steps per Second: 10,658.38004

Timestep Collection Time: 2.19330
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69189

Cumulative Model Updates: 124,226
Cumulative Timesteps: 1,035,900,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,757.55866
Policy Entropy: 3.73414
Value Function Loss: 0.01960

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.43413
Value Function Update Magnitude: 0.63221

Collected Steps per Second: 23,086.08354
Overall Steps per Second: 10,872.38239

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60028

Cumulative Model Updates: 124,232
Cumulative Timesteps: 1,035,950,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1035950308...
Checkpoint 1035950308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,366.85814
Policy Entropy: 3.71339
Value Function Loss: 0.02057

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.46861
Value Function Update Magnitude: 0.68990

Collected Steps per Second: 22,982.39833
Overall Steps per Second: 10,698.95482

Timestep Collection Time: 2.17636
Timestep Consumption Time: 2.49867
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.67504

Cumulative Model Updates: 124,238
Cumulative Timesteps: 1,036,000,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,698.98156
Policy Entropy: 3.72506
Value Function Loss: 0.02007

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.47295
Value Function Update Magnitude: 0.71450

Collected Steps per Second: 23,006.96940
Overall Steps per Second: 10,895.70941

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.41600
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.58951

Cumulative Model Updates: 124,244
Cumulative Timesteps: 1,036,050,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1036050332...
Checkpoint 1036050332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,213.38844
Policy Entropy: 3.73693
Value Function Loss: 0.01836

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.46953
Value Function Update Magnitude: 0.65647

Collected Steps per Second: 22,827.94778
Overall Steps per Second: 10,647.74710

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.69846

Cumulative Model Updates: 124,250
Cumulative Timesteps: 1,036,100,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,417.92486
Policy Entropy: 3.75217
Value Function Loss: 0.01713

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.46074
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 23,166.45124
Overall Steps per Second: 10,920.88409

Timestep Collection Time: 2.15924
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.58040

Cumulative Model Updates: 124,256
Cumulative Timesteps: 1,036,150,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1036150382...
Checkpoint 1036150382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,417.92486
Policy Entropy: 3.72755
Value Function Loss: 0.01904

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.45403
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 22,633.98907
Overall Steps per Second: 10,646.87152

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.69809

Cumulative Model Updates: 124,262
Cumulative Timesteps: 1,036,200,402

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,417.92486
Policy Entropy: 3.72375
Value Function Loss: 0.01991

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.45818
Value Function Update Magnitude: 0.49062

Collected Steps per Second: 23,091.42965
Overall Steps per Second: 10,893.94853

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.59246

Cumulative Model Updates: 124,268
Cumulative Timesteps: 1,036,250,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036250432...
Checkpoint 1036250432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,147.57243
Policy Entropy: 3.73574
Value Function Loss: 0.01942

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.50355
Value Function Update Magnitude: 0.49699

Collected Steps per Second: 22,952.43767
Overall Steps per Second: 10,716.53889

Timestep Collection Time: 2.17877
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.66643

Cumulative Model Updates: 124,274
Cumulative Timesteps: 1,036,300,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,555.05114
Policy Entropy: 3.75838
Value Function Loss: 0.02090

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.50260
Value Function Update Magnitude: 0.56053

Collected Steps per Second: 23,209.98360
Overall Steps per Second: 10,812.93300

Timestep Collection Time: 2.15562
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.62705

Cumulative Model Updates: 124,280
Cumulative Timesteps: 1,036,350,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1036350472...
Checkpoint 1036350472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,875.32197
Policy Entropy: 3.75624
Value Function Loss: 0.02145

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.50492
Value Function Update Magnitude: 0.58441

Collected Steps per Second: 22,776.59108
Overall Steps per Second: 10,647.50867

Timestep Collection Time: 2.19690
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69950

Cumulative Model Updates: 124,286
Cumulative Timesteps: 1,036,400,510

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.75382
Value Function Loss: 0.01969

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.51562
Value Function Update Magnitude: 0.52225

Collected Steps per Second: 23,443.61182
Overall Steps per Second: 10,908.36639

Timestep Collection Time: 2.13380
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.58584

Cumulative Model Updates: 124,292
Cumulative Timesteps: 1,036,450,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1036450534...
Checkpoint 1036450534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.73629
Value Function Loss: 0.01831

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.47726
Value Function Update Magnitude: 0.46866

Collected Steps per Second: 23,069.65495
Overall Steps per Second: 10,750.15014

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.65352

Cumulative Model Updates: 124,298
Cumulative Timesteps: 1,036,500,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.72503
Value Function Loss: 0.02005

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.45851
Value Function Update Magnitude: 0.44092

Collected Steps per Second: 22,900.73296
Overall Steps per Second: 10,863.59855

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.42084
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.60566

Cumulative Model Updates: 124,304
Cumulative Timesteps: 1,036,550,594

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1036550594...
Checkpoint 1036550594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.71057
Value Function Loss: 0.01990

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14726
Policy Update Magnitude: 0.48984
Value Function Update Magnitude: 0.54156

Collected Steps per Second: 22,717.75969
Overall Steps per Second: 10,682.41957

Timestep Collection Time: 2.20224
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.68340

Cumulative Model Updates: 124,310
Cumulative Timesteps: 1,036,600,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.70692
Value Function Loss: 0.02129

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14198
Policy Update Magnitude: 0.50818
Value Function Update Magnitude: 0.61747

Collected Steps per Second: 22,733.63921
Overall Steps per Second: 10,824.76198

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62052

Cumulative Model Updates: 124,316
Cumulative Timesteps: 1,036,650,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1036650640...
Checkpoint 1036650640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.70767
Value Function Loss: 0.02160

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.50414
Value Function Update Magnitude: 0.58457

Collected Steps per Second: 22,711.99352
Overall Steps per Second: 10,638.13470

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.70064

Cumulative Model Updates: 124,322
Cumulative Timesteps: 1,036,700,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,188.20909
Policy Entropy: 3.70938
Value Function Loss: 0.02158

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.49388
Value Function Update Magnitude: 0.48566

Collected Steps per Second: 22,924.74809
Overall Steps per Second: 10,842.28386

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.61268

Cumulative Model Updates: 124,328
Cumulative Timesteps: 1,036,750,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1036750658...
Checkpoint 1036750658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,582.26052
Policy Entropy: 3.71558
Value Function Loss: 0.02322

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.49276
Value Function Update Magnitude: 0.45177

Collected Steps per Second: 22,579.07485
Overall Steps per Second: 10,659.80710

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.69145

Cumulative Model Updates: 124,334
Cumulative Timesteps: 1,036,800,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,198.29487
Policy Entropy: 3.72116
Value Function Loss: 0.02536

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.52187
Value Function Update Magnitude: 0.46081

Collected Steps per Second: 22,943.24586
Overall Steps per Second: 10,847.58097

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.61061

Cumulative Model Updates: 124,340
Cumulative Timesteps: 1,036,850,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1036850682...
Checkpoint 1036850682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,172.53724
Policy Entropy: 3.72972
Value Function Loss: 0.02505

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.53940

Collected Steps per Second: 21,657.51419
Overall Steps per Second: 10,698.77634

Timestep Collection Time: 2.30978
Timestep Consumption Time: 2.36590
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.67567

Cumulative Model Updates: 124,346
Cumulative Timesteps: 1,036,900,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,586.83658
Policy Entropy: 3.74150
Value Function Loss: 0.02263

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.53152
Value Function Update Magnitude: 0.66865

Collected Steps per Second: 21,887.41913
Overall Steps per Second: 10,693.47861

Timestep Collection Time: 2.28579
Timestep Consumption Time: 2.39276
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.67855

Cumulative Model Updates: 124,352
Cumulative Timesteps: 1,036,950,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1036950736...
Checkpoint 1036950736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,586.83658
Policy Entropy: 3.73207
Value Function Loss: 0.02134

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.53443
Value Function Update Magnitude: 0.72187

Collected Steps per Second: 21,988.98212
Overall Steps per Second: 10,838.32188

Timestep Collection Time: 2.27478
Timestep Consumption Time: 2.34033
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61511

Cumulative Model Updates: 124,358
Cumulative Timesteps: 1,037,000,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,586.83658
Policy Entropy: 3.73602
Value Function Loss: 0.01894

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08242
Policy Update Magnitude: 0.63804
Value Function Update Magnitude: 0.73748

Collected Steps per Second: 22,232.05078
Overall Steps per Second: 10,566.97762

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.73267

Cumulative Model Updates: 124,364
Cumulative Timesteps: 1,037,050,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1037050766...
Checkpoint 1037050766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,586.83658
Policy Entropy: 3.73039
Value Function Loss: 0.01815

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.66680
Value Function Update Magnitude: 0.59845

Collected Steps per Second: 22,869.93338
Overall Steps per Second: 10,911.22089

Timestep Collection Time: 2.18698
Timestep Consumption Time: 2.39693
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.58390

Cumulative Model Updates: 124,370
Cumulative Timesteps: 1,037,100,782

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,083.98678
Policy Entropy: 3.74312
Value Function Loss: 0.01807

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.64204
Value Function Update Magnitude: 0.51062

Collected Steps per Second: 22,972.05971
Overall Steps per Second: 10,923.89577

Timestep Collection Time: 2.17751
Timestep Consumption Time: 2.40162
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.57914

Cumulative Model Updates: 124,376
Cumulative Timesteps: 1,037,150,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1037150804...
Checkpoint 1037150804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,693.95000
Policy Entropy: 3.74670
Value Function Loss: 0.01898

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.64515
Value Function Update Magnitude: 0.66920

Collected Steps per Second: 22,588.94142
Overall Steps per Second: 10,750.96739

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.65279

Cumulative Model Updates: 124,382
Cumulative Timesteps: 1,037,200,826

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,987.95959
Policy Entropy: 3.73572
Value Function Loss: 0.02240

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.70894
Value Function Update Magnitude: 0.69709

Collected Steps per Second: 22,844.36093
Overall Steps per Second: 10,806.64017

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.43855
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62771

Cumulative Model Updates: 124,388
Cumulative Timesteps: 1,037,250,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1037250836...
Checkpoint 1037250836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,771.59825
Policy Entropy: 3.75861
Value Function Loss: 0.02127

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.11814
Policy Update Magnitude: 0.70265
Value Function Update Magnitude: 0.67811

Collected Steps per Second: 23,013.90599
Overall Steps per Second: 10,694.60765

Timestep Collection Time: 2.17321
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67656

Cumulative Model Updates: 124,394
Cumulative Timesteps: 1,037,300,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,220.70295
Policy Entropy: 3.74036
Value Function Loss: 0.02504

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.19459
Policy Update Magnitude: 0.66313
Value Function Update Magnitude: 0.74450

Collected Steps per Second: 22,940.41804
Overall Steps per Second: 10,861.19380

Timestep Collection Time: 2.17973
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60391

Cumulative Model Updates: 124,400
Cumulative Timesteps: 1,037,350,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1037350854...
Checkpoint 1037350854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,701.86998
Policy Entropy: 3.75740
Value Function Loss: 0.03011

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.23363
Policy Update Magnitude: 0.63969
Value Function Update Magnitude: 0.67177

Collected Steps per Second: 22,426.43981
Overall Steps per Second: 10,704.43307

Timestep Collection Time: 2.23022
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.67246

Cumulative Model Updates: 124,406
Cumulative Timesteps: 1,037,400,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,964.49505
Policy Entropy: 3.72796
Value Function Loss: 0.04949

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15706
Policy Update Magnitude: 0.74327
Value Function Update Magnitude: 0.72403

Collected Steps per Second: 22,455.86758
Overall Steps per Second: 10,625.44992

Timestep Collection Time: 2.22695
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70644

Cumulative Model Updates: 124,412
Cumulative Timesteps: 1,037,450,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1037450878...
Checkpoint 1037450878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,728.19980
Policy Entropy: 3.75315
Value Function Loss: 0.06028

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.17318
Policy Update Magnitude: 0.99652
Value Function Update Magnitude: 0.59517

Collected Steps per Second: 22,828.67554
Overall Steps per Second: 10,829.23445

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.61898

Cumulative Model Updates: 124,418
Cumulative Timesteps: 1,037,500,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.59395
Policy Entropy: 3.75929
Value Function Loss: 0.04856

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.18045
Policy Update Magnitude: 0.96830
Value Function Update Magnitude: 0.54174

Collected Steps per Second: 22,758.18973
Overall Steps per Second: 10,651.39319

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.49721
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.69422

Cumulative Model Updates: 124,424
Cumulative Timesteps: 1,037,550,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037550898...
Checkpoint 1037550898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.59395
Policy Entropy: 3.76716
Value Function Loss: 0.04000

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.75265
Value Function Update Magnitude: 0.51316

Collected Steps per Second: 22,737.91565
Overall Steps per Second: 10,687.21425

Timestep Collection Time: 2.19950
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.67961

Cumulative Model Updates: 124,430
Cumulative Timesteps: 1,037,600,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,102.59395
Policy Entropy: 3.74105
Value Function Loss: 0.02953

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.58605
Value Function Update Magnitude: 0.49170

Collected Steps per Second: 22,954.22111
Overall Steps per Second: 10,751.32981

Timestep Collection Time: 2.17825
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.65059

Cumulative Model Updates: 124,436
Cumulative Timesteps: 1,037,650,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1037650910...
Checkpoint 1037650910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,197.45815
Policy Entropy: 3.72622
Value Function Loss: 0.03484

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.46590

Collected Steps per Second: 22,606.83463
Overall Steps per Second: 10,597.42760

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.71945

Cumulative Model Updates: 124,442
Cumulative Timesteps: 1,037,700,924

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,312.36049
Policy Entropy: 3.73421
Value Function Loss: 0.02876

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15326
Policy Update Magnitude: 0.51113
Value Function Update Magnitude: 0.46136

Collected Steps per Second: 22,952.48469
Overall Steps per Second: 10,882.17591

Timestep Collection Time: 2.17867
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.59522

Cumulative Model Updates: 124,448
Cumulative Timesteps: 1,037,750,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1037750930...
Checkpoint 1037750930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,735.80612
Policy Entropy: 3.74298
Value Function Loss: 0.02847

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.15441
Policy Update Magnitude: 0.47629
Value Function Update Magnitude: 0.57585

Collected Steps per Second: 21,813.52883
Overall Steps per Second: 10,690.51483

Timestep Collection Time: 2.29280
Timestep Consumption Time: 2.38556
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.67835

Cumulative Model Updates: 124,454
Cumulative Timesteps: 1,037,800,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,941.84588
Policy Entropy: 3.75881
Value Function Loss: 0.02435

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.49087
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 22,434.28092
Overall Steps per Second: 10,935.52871

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.34483
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.57481

Cumulative Model Updates: 124,460
Cumulative Timesteps: 1,037,850,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1037850972...
Checkpoint 1037850972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,769.79414
Policy Entropy: 3.76556
Value Function Loss: 0.02289

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14090
Policy Update Magnitude: 0.46357
Value Function Update Magnitude: 0.67317

Collected Steps per Second: 22,008.04966
Overall Steps per Second: 10,652.96837

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.42163
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.69353

Cumulative Model Updates: 124,466
Cumulative Timesteps: 1,037,900,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.54413
Policy Entropy: 3.79001
Value Function Loss: 0.02081

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.43175
Value Function Update Magnitude: 0.66091

Collected Steps per Second: 22,494.96047
Overall Steps per Second: 10,793.94205

Timestep Collection Time: 2.22308
Timestep Consumption Time: 2.40989
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63297

Cumulative Model Updates: 124,472
Cumulative Timesteps: 1,037,950,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1037950980...
Checkpoint 1037950980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 413.75461
Policy Entropy: 3.79872
Value Function Loss: 0.02003

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.37783
Value Function Update Magnitude: 0.57166

Collected Steps per Second: 22,985.49328
Overall Steps per Second: 10,737.52944

Timestep Collection Time: 2.17563
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.65731

Cumulative Model Updates: 124,478
Cumulative Timesteps: 1,038,000,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.43650
Policy Entropy: 3.79936
Value Function Loss: 0.01833

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.33832
Value Function Update Magnitude: 0.57765

Collected Steps per Second: 23,130.57487
Overall Steps per Second: 10,865.75876

Timestep Collection Time: 2.16251
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.60345

Cumulative Model Updates: 124,484
Cumulative Timesteps: 1,038,051,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1038051008...
Checkpoint 1038051008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,532.37373
Policy Entropy: 3.78080
Value Function Loss: 0.01841

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.33383
Value Function Update Magnitude: 0.49878

Collected Steps per Second: 22,688.39003
Overall Steps per Second: 10,630.64225

Timestep Collection Time: 2.20430
Timestep Consumption Time: 2.50021
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.70451

Cumulative Model Updates: 124,490
Cumulative Timesteps: 1,038,101,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,932.18062
Policy Entropy: 3.77317
Value Function Loss: 0.01757

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.37994
Value Function Update Magnitude: 0.49220

Collected Steps per Second: 23,180.31043
Overall Steps per Second: 10,908.09308

Timestep Collection Time: 2.15890
Timestep Consumption Time: 2.42889
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.58779

Cumulative Model Updates: 124,496
Cumulative Timesteps: 1,038,151,064

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1038151064...
Checkpoint 1038151064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,932.18062
Policy Entropy: 3.75441
Value Function Loss: 0.01968

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.39400
Value Function Update Magnitude: 0.56755

Collected Steps per Second: 22,656.55929
Overall Steps per Second: 10,671.07492

Timestep Collection Time: 2.20695
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68575

Cumulative Model Updates: 124,502
Cumulative Timesteps: 1,038,201,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,185.31917
Policy Entropy: 3.74592
Value Function Loss: 0.02282

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.43725
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 22,954.41857
Overall Steps per Second: 10,832.83451

Timestep Collection Time: 2.17954
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.61837

Cumulative Model Updates: 124,508
Cumulative Timesteps: 1,038,251,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1038251096...
Checkpoint 1038251096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,550.51399
Policy Entropy: 3.75826
Value Function Loss: 0.02516

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.48634
Value Function Update Magnitude: 0.50153

Collected Steps per Second: 22,871.88939
Overall Steps per Second: 10,701.95378

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.67410

Cumulative Model Updates: 124,514
Cumulative Timesteps: 1,038,301,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,259.89239
Policy Entropy: 3.76637
Value Function Loss: 0.02828

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.47206

Collected Steps per Second: 22,933.67392
Overall Steps per Second: 10,850.72292

Timestep Collection Time: 2.18151
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61075

Cumulative Model Updates: 124,520
Cumulative Timesteps: 1,038,351,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1038351148...
Checkpoint 1038351148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,259.89239
Policy Entropy: 3.76183
Value Function Loss: 0.02402

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.48559

Collected Steps per Second: 22,502.88202
Overall Steps per Second: 10,710.93981

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.67074

Cumulative Model Updates: 124,526
Cumulative Timesteps: 1,038,401,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,399.22103
Policy Entropy: 3.74044
Value Function Loss: 0.02393

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.46970

Collected Steps per Second: 22,910.75290
Overall Steps per Second: 10,867.47022

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.41967
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60310

Cumulative Model Updates: 124,532
Cumulative Timesteps: 1,038,451,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1038451200...
Checkpoint 1038451200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,828.74708
Policy Entropy: 3.75987
Value Function Loss: 0.02037

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.44780
Value Function Update Magnitude: 0.43558

Collected Steps per Second: 22,947.56490
Overall Steps per Second: 10,702.86054

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67426

Cumulative Model Updates: 124,538
Cumulative Timesteps: 1,038,501,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,213.80821
Policy Entropy: 3.75738
Value Function Loss: 0.02361

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.43053
Value Function Update Magnitude: 0.43851

Collected Steps per Second: 22,899.43355
Overall Steps per Second: 10,857.00420

Timestep Collection Time: 2.18363
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60569

Cumulative Model Updates: 124,544
Cumulative Timesteps: 1,038,551,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1038551232...
Checkpoint 1038551232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,043.89722
Policy Entropy: 3.77181
Value Function Loss: 0.02385

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.49297
Value Function Update Magnitude: 0.60299

Collected Steps per Second: 22,013.34762
Overall Steps per Second: 10,655.98548

Timestep Collection Time: 2.27199
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.69351

Cumulative Model Updates: 124,550
Cumulative Timesteps: 1,038,601,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,499.32272
Policy Entropy: 3.74481
Value Function Loss: 0.02676

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.77068

Collected Steps per Second: 22,164.13657
Overall Steps per Second: 10,863.89751

Timestep Collection Time: 2.25644
Timestep Consumption Time: 2.34707
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60350

Cumulative Model Updates: 124,556
Cumulative Timesteps: 1,038,651,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1038651258...
Checkpoint 1038651258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,499.32272
Policy Entropy: 3.73559
Value Function Loss: 0.02441

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.59933
Value Function Update Magnitude: 0.72962

Collected Steps per Second: 22,086.45687
Overall Steps per Second: 10,660.21809

Timestep Collection Time: 2.26410
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69090

Cumulative Model Updates: 124,562
Cumulative Timesteps: 1,038,701,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,525.51051
Policy Entropy: 3.73481
Value Function Loss: 0.02601

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.58499
Value Function Update Magnitude: 0.71190

Collected Steps per Second: 22,431.80434
Overall Steps per Second: 10,693.48448

Timestep Collection Time: 2.23023
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.67836

Cumulative Model Updates: 124,568
Cumulative Timesteps: 1,038,751,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1038751292...
Checkpoint 1038751292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,463.56039
Policy Entropy: 3.74474
Value Function Loss: 0.02600

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.80983

Collected Steps per Second: 22,504.70975
Overall Steps per Second: 10,829.99159

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.39524
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61718

Cumulative Model Updates: 124,574
Cumulative Timesteps: 1,038,801,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,381.97166
Policy Entropy: 3.75151
Value Function Loss: 0.02928

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.60299
Value Function Update Magnitude: 0.88087

Collected Steps per Second: 22,905.85674
Overall Steps per Second: 10,906.31243

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.58523

Cumulative Model Updates: 124,580
Cumulative Timesteps: 1,038,851,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1038851304...
Checkpoint 1038851304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,486.92903
Policy Entropy: 3.74501
Value Function Loss: 0.03026

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.57170
Value Function Update Magnitude: 0.69271

Collected Steps per Second: 22,799.37787
Overall Steps per Second: 10,680.05122

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.48998
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.68425

Cumulative Model Updates: 124,586
Cumulative Timesteps: 1,038,901,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,711.39049
Policy Entropy: 3.75138
Value Function Loss: 0.02820

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.53631
Value Function Update Magnitude: 0.57157

Collected Steps per Second: 23,225.20493
Overall Steps per Second: 10,944.34582

Timestep Collection Time: 2.15326
Timestep Consumption Time: 2.41622
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.56948

Cumulative Model Updates: 124,592
Cumulative Timesteps: 1,038,951,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1038951342...
Checkpoint 1038951342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.75549
Value Function Loss: 0.02390

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.52059
Value Function Update Magnitude: 0.58818

Collected Steps per Second: 22,849.29304
Overall Steps per Second: 10,676.37092

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.68380

Cumulative Model Updates: 124,598
Cumulative Timesteps: 1,039,001,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.76550
Value Function Loss: 0.02026

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.46409
Value Function Update Magnitude: 0.57639

Collected Steps per Second: 22,972.55619
Overall Steps per Second: 10,869.54184

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.60222

Cumulative Model Updates: 124,604
Cumulative Timesteps: 1,039,051,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1039051372...
Checkpoint 1039051372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.75395
Value Function Loss: 0.01778

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.39937
Value Function Update Magnitude: 0.59823

Collected Steps per Second: 22,952.43501
Overall Steps per Second: 10,692.89607

Timestep Collection Time: 2.17912
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67750

Cumulative Model Updates: 124,610
Cumulative Timesteps: 1,039,101,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.72506
Value Function Loss: 0.01821

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.39500
Value Function Update Magnitude: 0.52725

Collected Steps per Second: 23,104.87785
Overall Steps per Second: 10,894.36363

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.42548
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.58953

Cumulative Model Updates: 124,616
Cumulative Timesteps: 1,039,151,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1039151388...
Checkpoint 1039151388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.73130
Value Function Loss: 0.02015

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.40240
Value Function Update Magnitude: 0.44013

Collected Steps per Second: 22,524.75527
Overall Steps per Second: 10,613.48512

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.71193

Cumulative Model Updates: 124,622
Cumulative Timesteps: 1,039,201,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,196.11460
Policy Entropy: 3.73084
Value Function Loss: 0.02278

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.39102
Value Function Update Magnitude: 0.34428

Collected Steps per Second: 22,677.80122
Overall Steps per Second: 10,797.23421

Timestep Collection Time: 2.20577
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.63285

Cumulative Model Updates: 124,628
Cumulative Timesteps: 1,039,251,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1039251420...
Checkpoint 1039251420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,784.35319
Policy Entropy: 3.74224
Value Function Loss: 0.02198

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.41845
Value Function Update Magnitude: 0.31203

Collected Steps per Second: 22,731.18337
Overall Steps per Second: 10,694.05993

Timestep Collection Time: 2.19971
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67568

Cumulative Model Updates: 124,634
Cumulative Timesteps: 1,039,301,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,280.26262
Policy Entropy: 3.72801
Value Function Loss: 0.02245

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.40552
Value Function Update Magnitude: 0.30803

Collected Steps per Second: 23,026.58794
Overall Steps per Second: 10,911.38491

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.41164
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.58365

Cumulative Model Updates: 124,640
Cumulative Timesteps: 1,039,351,436

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1039351436...
Checkpoint 1039351436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,280.26262
Policy Entropy: 3.72822
Value Function Loss: 0.01808

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.41378
Value Function Update Magnitude: 0.32751

Collected Steps per Second: 22,068.03561
Overall Steps per Second: 10,655.58409

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69388

Cumulative Model Updates: 124,646
Cumulative Timesteps: 1,039,401,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,051.85346
Policy Entropy: 3.72401
Value Function Loss: 0.01852

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.41960
Value Function Update Magnitude: 0.37913

Collected Steps per Second: 22,264.07107
Overall Steps per Second: 10,870.52861

Timestep Collection Time: 2.24703
Timestep Consumption Time: 2.35514
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60217

Cumulative Model Updates: 124,652
Cumulative Timesteps: 1,039,451,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1039451480...
Checkpoint 1039451480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,609.23041
Policy Entropy: 3.73088
Value Function Loss: 0.01787

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.45037
Value Function Update Magnitude: 0.54520

Collected Steps per Second: 22,059.21540
Overall Steps per Second: 10,658.15356

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69124

Cumulative Model Updates: 124,658
Cumulative Timesteps: 1,039,501,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,691.67603
Policy Entropy: 3.71575
Value Function Loss: 0.02329

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.50007
Value Function Update Magnitude: 0.55858

Collected Steps per Second: 22,237.34328
Overall Steps per Second: 10,614.74422

Timestep Collection Time: 2.24955
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.71269

Cumulative Model Updates: 124,664
Cumulative Timesteps: 1,039,551,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1039551504...
Checkpoint 1039551504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.72226
Value Function Loss: 0.02226

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.56355

Collected Steps per Second: 23,085.87791
Overall Steps per Second: 10,935.37355

Timestep Collection Time: 2.16600
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.57268

Cumulative Model Updates: 124,670
Cumulative Timesteps: 1,039,601,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.72112
Value Function Loss: 0.01975

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.48585
Value Function Update Magnitude: 0.63178

Collected Steps per Second: 22,865.03716
Overall Steps per Second: 10,853.98791

Timestep Collection Time: 2.18718
Timestep Consumption Time: 2.42034
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.60752

Cumulative Model Updates: 124,676
Cumulative Timesteps: 1,039,651,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1039651518...
Checkpoint 1039651518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.72486
Value Function Loss: 0.01758

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.49429
Value Function Update Magnitude: 0.58580

Collected Steps per Second: 22,782.19819
Overall Steps per Second: 10,677.14627

Timestep Collection Time: 2.19566
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.68496

Cumulative Model Updates: 124,682
Cumulative Timesteps: 1,039,701,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.71583
Value Function Loss: 0.01680

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.51597
Value Function Update Magnitude: 0.55356

Collected Steps per Second: 22,862.88430
Overall Steps per Second: 10,723.00362

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.66511

Cumulative Model Updates: 124,688
Cumulative Timesteps: 1,039,751,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1039751564...
Checkpoint 1039751564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.72506
Value Function Loss: 0.01401

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.17953
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,707.21033
Overall Steps per Second: 10,816.71728

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.62543

Cumulative Model Updates: 124,694
Cumulative Timesteps: 1,039,801,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,376.31694
Policy Entropy: 3.74463
Value Function Loss: 0.01162

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.46445
Value Function Update Magnitude: 0.46293

Collected Steps per Second: 22,754.06829
Overall Steps per Second: 10,706.64934

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.67224

Cumulative Model Updates: 124,700
Cumulative Timesteps: 1,039,851,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1039851620...
Checkpoint 1039851620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,410.58529
Policy Entropy: 3.73958
Value Function Loss: 0.01512

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.43802
Value Function Update Magnitude: 0.39773

Collected Steps per Second: 23,027.67876
Overall Steps per Second: 10,951.37994

Timestep Collection Time: 2.17139
Timestep Consumption Time: 2.39443
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.56582

Cumulative Model Updates: 124,706
Cumulative Timesteps: 1,039,901,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,152.85164
Policy Entropy: 3.73146
Value Function Loss: 0.01651

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15583
Policy Update Magnitude: 0.49556
Value Function Update Magnitude: 0.47742

Collected Steps per Second: 22,772.94582
Overall Steps per Second: 10,835.35576

Timestep Collection Time: 2.19629
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61600

Cumulative Model Updates: 124,712
Cumulative Timesteps: 1,039,951,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1039951638...
Checkpoint 1039951638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,152.85164
Policy Entropy: 3.70212
Value Function Loss: 0.02527

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.21387
Policy Update Magnitude: 0.49454
Value Function Update Magnitude: 0.42711

Collected Steps per Second: 22,108.59021
Overall Steps per Second: 10,686.08678

Timestep Collection Time: 2.26175
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.67936

Cumulative Model Updates: 124,718
Cumulative Timesteps: 1,040,001,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,503.32744
Policy Entropy: 3.71866
Value Function Loss: 0.03072

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.22099
Policy Update Magnitude: 0.64258
Value Function Update Magnitude: 0.42717

Collected Steps per Second: 21,891.45900
Overall Steps per Second: 10,772.57735

Timestep Collection Time: 2.28464
Timestep Consumption Time: 2.35808
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.64271

Cumulative Model Updates: 124,724
Cumulative Timesteps: 1,040,051,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1040051656...
Checkpoint 1040051656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,577.70816
Policy Entropy: 3.69123
Value Function Loss: 0.03942

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.20608
Policy Update Magnitude: 0.67501
Value Function Update Magnitude: 0.38239

Collected Steps per Second: 21,696.10611
Overall Steps per Second: 10,628.96361

Timestep Collection Time: 2.30456
Timestep Consumption Time: 2.39957
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.70413

Cumulative Model Updates: 124,730
Cumulative Timesteps: 1,040,101,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,021.58044
Policy Entropy: 3.73896
Value Function Loss: 0.03697

Mean KL Divergence: 0.01705
SB3 Clip Fraction: 0.19529
Policy Update Magnitude: 0.71262
Value Function Update Magnitude: 0.35457

Collected Steps per Second: 22,183.13235
Overall Steps per Second: 10,553.56627

Timestep Collection Time: 2.25424
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.73830

Cumulative Model Updates: 124,736
Cumulative Timesteps: 1,040,151,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1040151662...
Checkpoint 1040151662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,331.58266
Policy Entropy: 3.74752
Value Function Loss: 0.03276

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17250
Policy Update Magnitude: 0.71038
Value Function Update Magnitude: 0.34637

Collected Steps per Second: 22,303.44509
Overall Steps per Second: 10,638.02798

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.45949
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70238

Cumulative Model Updates: 124,742
Cumulative Timesteps: 1,040,201,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,794.00653
Policy Entropy: 3.77141
Value Function Loss: 0.02736

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.70934
Value Function Update Magnitude: 0.50127

Collected Steps per Second: 22,070.69593
Overall Steps per Second: 10,481.12548

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.77296

Cumulative Model Updates: 124,748
Cumulative Timesteps: 1,040,251,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1040251712...
Checkpoint 1040251712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,794.00653
Policy Entropy: 3.75016
Value Function Loss: 0.02620

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.71398
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 22,622.84670
Overall Steps per Second: 10,578.06659

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.51661
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.72676

Cumulative Model Updates: 124,754
Cumulative Timesteps: 1,040,301,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,447.22369
Policy Entropy: 3.74822
Value Function Loss: 0.02559

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.78860
Value Function Update Magnitude: 0.57643

Collected Steps per Second: 22,381.30217
Overall Steps per Second: 10,571.72056

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.73073

Cumulative Model Updates: 124,760
Cumulative Timesteps: 1,040,351,724

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1040351724...
Checkpoint 1040351724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,447.22369
Policy Entropy: 3.72333
Value Function Loss: 0.02556

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.82744
Value Function Update Magnitude: 0.44528

Collected Steps per Second: 22,805.83760
Overall Steps per Second: 10,721.02839

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.66485

Cumulative Model Updates: 124,766
Cumulative Timesteps: 1,040,401,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,098.39379
Policy Entropy: 3.73960
Value Function Loss: 0.02509

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.70552
Value Function Update Magnitude: 0.41825

Collected Steps per Second: 22,765.16412
Overall Steps per Second: 10,729.34030

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.46467
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.66180

Cumulative Model Updates: 124,772
Cumulative Timesteps: 1,040,451,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1040451754...
Checkpoint 1040451754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,504.48093
Policy Entropy: 3.73246
Value Function Loss: 0.02520

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.60778
Value Function Update Magnitude: 0.48847

Collected Steps per Second: 22,876.41398
Overall Steps per Second: 10,699.31895

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.48774
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.67357

Cumulative Model Updates: 124,778
Cumulative Timesteps: 1,040,501,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,424.11535
Policy Entropy: 3.71424
Value Function Loss: 0.02502

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15020
Policy Update Magnitude: 0.57798
Value Function Update Magnitude: 0.50482

Collected Steps per Second: 22,246.72338
Overall Steps per Second: 10,892.43495

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.34385
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.59236

Cumulative Model Updates: 124,784
Cumulative Timesteps: 1,040,551,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1040551780...
Checkpoint 1040551780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.59201
Policy Entropy: 3.71119
Value Function Loss: 0.02584

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.50811

Collected Steps per Second: 22,132.72492
Overall Steps per Second: 10,724.49027

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.40351
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.66297

Cumulative Model Updates: 124,790
Cumulative Timesteps: 1,040,601,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.71617
Value Function Loss: 0.02587

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07749
Policy Update Magnitude: 0.70753
Value Function Update Magnitude: 0.47982

Collected Steps per Second: 22,120.29390
Overall Steps per Second: 10,789.50581

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.37443
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.63543

Cumulative Model Updates: 124,796
Cumulative Timesteps: 1,040,651,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1040651802...
Checkpoint 1040651802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.71942
Value Function Loss: 0.02291

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07345
Policy Update Magnitude: 0.81309
Value Function Update Magnitude: 0.41899

Collected Steps per Second: 22,264.92437
Overall Steps per Second: 10,597.25628

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.47252
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.71820

Cumulative Model Updates: 124,802
Cumulative Timesteps: 1,040,701,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.71775
Value Function Loss: 0.02144

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11871
Policy Update Magnitude: 0.74575
Value Function Update Magnitude: 0.34278

Collected Steps per Second: 22,319.17871
Overall Steps per Second: 10,662.82370

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.45112
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69332

Cumulative Model Updates: 124,808
Cumulative Timesteps: 1,040,751,846

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1040751846...
Checkpoint 1040751846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.73246
Value Function Loss: 0.01802

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.25406
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.31696

Collected Steps per Second: 22,846.05364
Overall Steps per Second: 10,933.73794

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.38492
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.57392

Cumulative Model Updates: 124,814
Cumulative Timesteps: 1,040,801,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.73095
Value Function Loss: 0.01764

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.29852
Policy Update Magnitude: 0.39248
Value Function Update Magnitude: 0.34645

Collected Steps per Second: 23,069.74345
Overall Steps per Second: 10,864.24764

Timestep Collection Time: 2.16821
Timestep Consumption Time: 2.43588
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.60409

Cumulative Model Updates: 124,820
Cumulative Timesteps: 1,040,851,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1040851876...
Checkpoint 1040851876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.74421
Value Function Loss: 0.01578

Mean KL Divergence: 0.02457
SB3 Clip Fraction: 0.30559
Policy Update Magnitude: 0.32136
Value Function Update Magnitude: 0.37008

Collected Steps per Second: 22,864.31878
Overall Steps per Second: 10,666.58661

Timestep Collection Time: 2.18795
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68997

Cumulative Model Updates: 124,826
Cumulative Timesteps: 1,040,901,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.69725
Value Function Loss: 0.02134

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.24839
Policy Update Magnitude: 0.27737
Value Function Update Magnitude: 0.40890

Collected Steps per Second: 22,503.38277
Overall Steps per Second: 10,636.28003

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.70221

Cumulative Model Updates: 124,832
Cumulative Timesteps: 1,040,951,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1040951916...
Checkpoint 1040951916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.27246
Policy Entropy: 3.67249
Value Function Loss: 0.03186

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.22812
Policy Update Magnitude: 0.30931
Value Function Update Magnitude: 0.47318

Collected Steps per Second: 22,854.72694
Overall Steps per Second: 10,825.49637

Timestep Collection Time: 2.18834
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.62002

Cumulative Model Updates: 124,838
Cumulative Timesteps: 1,041,001,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,060.20138
Policy Entropy: 3.66678
Value Function Loss: 0.04817

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.18559
Policy Update Magnitude: 0.42661
Value Function Update Magnitude: 0.45875

Collected Steps per Second: 22,782.63814
Overall Steps per Second: 10,681.31373

Timestep Collection Time: 2.19562
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.68313

Cumulative Model Updates: 124,844
Cumulative Timesteps: 1,041,051,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1041051952...
Checkpoint 1041051952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,459.88719
Policy Entropy: 3.72972
Value Function Loss: 0.05576

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.16054
Policy Update Magnitude: 0.58736
Value Function Update Magnitude: 0.45584

Collected Steps per Second: 22,703.85958
Overall Steps per Second: 10,863.09915

Timestep Collection Time: 2.20350
Timestep Consumption Time: 2.40181
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60532

Cumulative Model Updates: 124,850
Cumulative Timesteps: 1,041,101,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,155.52076
Policy Entropy: 3.82936
Value Function Loss: 0.05429

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.14781
Policy Update Magnitude: 0.74350
Value Function Update Magnitude: 0.64823

Collected Steps per Second: 22,625.22941
Overall Steps per Second: 10,724.53370

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.45366
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.66482

Cumulative Model Updates: 124,856
Cumulative Timesteps: 1,041,152,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1041152008...
Checkpoint 1041152008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,956.78256
Policy Entropy: 3.89638
Value Function Loss: 0.05123

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.80892
Value Function Update Magnitude: 0.75504

Collected Steps per Second: 22,687.73337
Overall Steps per Second: 10,893.59498

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.38659
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.59095

Cumulative Model Updates: 124,862
Cumulative Timesteps: 1,041,202,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,456.89613
Policy Entropy: 3.90343
Value Function Loss: 0.04523

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.79818
Value Function Update Magnitude: 0.72637

Collected Steps per Second: 22,753.44830
Overall Steps per Second: 10,844.12163

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.61374

Cumulative Model Updates: 124,868
Cumulative Timesteps: 1,041,252,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1041252052...
Checkpoint 1041252052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,696.47021
Policy Entropy: 3.86592
Value Function Loss: 0.04436

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.79284
Value Function Update Magnitude: 0.73269

Collected Steps per Second: 23,155.93640
Overall Steps per Second: 10,783.31163

Timestep Collection Time: 2.16048
Timestep Consumption Time: 2.47891
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.63939

Cumulative Model Updates: 124,874
Cumulative Timesteps: 1,041,302,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.55674
Policy Entropy: 3.82366
Value Function Loss: 0.04086

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.18300
Policy Update Magnitude: 0.76296
Value Function Update Magnitude: 0.82070

Collected Steps per Second: 22,851.91497
Overall Steps per Second: 10,916.52771

Timestep Collection Time: 2.18826
Timestep Consumption Time: 2.39250
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58076

Cumulative Model Updates: 124,880
Cumulative Timesteps: 1,041,352,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1041352086...
Checkpoint 1041352086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.98446
Policy Entropy: 3.80653
Value Function Loss: 0.04183

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.17718
Policy Update Magnitude: 0.71926
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 22,650.80326
Overall Steps per Second: 10,719.76088

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.45804
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.66652

Cumulative Model Updates: 124,886
Cumulative Timesteps: 1,041,402,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.98446
Policy Entropy: 3.79134
Value Function Loss: 0.04071

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15107
Policy Update Magnitude: 0.73481
Value Function Update Magnitude: 0.47905

Collected Steps per Second: 22,388.90363
Overall Steps per Second: 10,796.02566

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.39856
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.63226

Cumulative Model Updates: 124,892
Cumulative Timesteps: 1,041,452,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1041452120...
Checkpoint 1041452120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,635.18878
Policy Entropy: 3.77930
Value Function Loss: 0.03285

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17802
Policy Update Magnitude: 0.67547
Value Function Update Magnitude: 0.35581

Collected Steps per Second: 23,092.20884
Overall Steps per Second: 10,763.94362

Timestep Collection Time: 2.16567
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.64607

Cumulative Model Updates: 124,898
Cumulative Timesteps: 1,041,502,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,628.93535
Policy Entropy: 3.77219
Value Function Loss: 0.03279

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.61441
Value Function Update Magnitude: 0.41314

Collected Steps per Second: 22,970.84481
Overall Steps per Second: 10,772.71362

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.64377

Cumulative Model Updates: 124,904
Cumulative Timesteps: 1,041,552,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1041552156...
Checkpoint 1041552156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,619.54366
Policy Entropy: 3.77081
Value Function Loss: 0.03176

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.64899
Value Function Update Magnitude: 0.37138

Collected Steps per Second: 22,914.21908
Overall Steps per Second: 10,723.76657

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.66497

Cumulative Model Updates: 124,910
Cumulative Timesteps: 1,041,602,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,169.41685
Policy Entropy: 3.75845
Value Function Loss: 0.03565

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.70787
Value Function Update Magnitude: 0.42109

Collected Steps per Second: 22,723.34159
Overall Steps per Second: 10,810.93306

Timestep Collection Time: 2.20038
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62495

Cumulative Model Updates: 124,916
Cumulative Timesteps: 1,041,652,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041652182...
Checkpoint 1041652182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.58154
Policy Entropy: 3.80707
Value Function Loss: 0.03318

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.63221
Value Function Update Magnitude: 0.51438

Collected Steps per Second: 22,989.85796
Overall Steps per Second: 10,699.22109

Timestep Collection Time: 2.17609
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.67585

Cumulative Model Updates: 124,922
Cumulative Timesteps: 1,041,702,210

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,374.38156
Policy Entropy: 3.81228
Value Function Loss: 0.03473

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11453
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.52222

Collected Steps per Second: 22,655.37179
Overall Steps per Second: 10,789.46191

Timestep Collection Time: 2.20698
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.63415

Cumulative Model Updates: 124,928
Cumulative Timesteps: 1,041,752,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041752210...
Checkpoint 1041752210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,042.68281
Policy Entropy: 3.85057
Value Function Loss: 0.02895

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.53096
Value Function Update Magnitude: 0.55432

Collected Steps per Second: 22,565.38691
Overall Steps per Second: 10,684.13142

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.68002

Cumulative Model Updates: 124,934
Cumulative Timesteps: 1,041,802,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,187.89871
Policy Entropy: 3.81105
Value Function Loss: 0.03187

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.51766

Collected Steps per Second: 22,663.36973
Overall Steps per Second: 10,690.73245

Timestep Collection Time: 2.20629
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.67714

Cumulative Model Updates: 124,940
Cumulative Timesteps: 1,041,852,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1041852214...
Checkpoint 1041852214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.79494
Policy Entropy: 3.83355
Value Function Loss: 0.02659

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.52991
Value Function Update Magnitude: 0.54699

Collected Steps per Second: 22,910.69943
Overall Steps per Second: 10,881.33080

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.41370
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.59705

Cumulative Model Updates: 124,946
Cumulative Timesteps: 1,041,902,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.57781
Policy Entropy: 3.80974
Value Function Loss: 0.02676

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.52897
Value Function Update Magnitude: 0.61168

Collected Steps per Second: 22,936.87090
Overall Steps per Second: 10,851.16824

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60780

Cumulative Model Updates: 124,952
Cumulative Timesteps: 1,041,952,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1041952236...
Checkpoint 1041952236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.82625
Policy Entropy: 3.80126
Value Function Loss: 0.02024

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.48610
Value Function Update Magnitude: 0.55898

Collected Steps per Second: 23,056.45211
Overall Steps per Second: 10,727.85375

Timestep Collection Time: 2.16885
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.66132

Cumulative Model Updates: 124,958
Cumulative Timesteps: 1,042,002,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,092.15052
Policy Entropy: 3.74212
Value Function Loss: 0.01980

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14580
Policy Update Magnitude: 0.39909
Value Function Update Magnitude: 0.52040

Collected Steps per Second: 22,637.05176
Overall Steps per Second: 10,758.72459

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.43901
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.64813

Cumulative Model Updates: 124,964
Cumulative Timesteps: 1,042,052,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1042052250...
Checkpoint 1042052250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,561.77881
Policy Entropy: 3.74503
Value Function Loss: 0.01810

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.38378
Value Function Update Magnitude: 0.50583

Collected Steps per Second: 22,844.98427
Overall Steps per Second: 10,723.12516

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.66468

Cumulative Model Updates: 124,970
Cumulative Timesteps: 1,042,102,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,980.21527
Policy Entropy: 3.72842
Value Function Loss: 0.02081

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.41230
Value Function Update Magnitude: 0.45662

Collected Steps per Second: 22,241.98912
Overall Steps per Second: 10,866.07924

Timestep Collection Time: 2.24809
Timestep Consumption Time: 2.35357
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60166

Cumulative Model Updates: 124,976
Cumulative Timesteps: 1,042,152,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1042152272...
Checkpoint 1042152272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,032.74991
Policy Entropy: 3.76855
Value Function Loss: 0.01893

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.41969
Value Function Update Magnitude: 0.48320

Collected Steps per Second: 22,202.60458
Overall Steps per Second: 10,729.09459

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.66060

Cumulative Model Updates: 124,982
Cumulative Timesteps: 1,042,202,276

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,425.05859
Policy Entropy: 3.74762
Value Function Loss: 0.02157

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.43136
Value Function Update Magnitude: 0.55244

Collected Steps per Second: 22,150.33787
Overall Steps per Second: 10,820.93798

Timestep Collection Time: 2.25857
Timestep Consumption Time: 2.36469
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.62326

Cumulative Model Updates: 124,988
Cumulative Timesteps: 1,042,252,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1042252304...
Checkpoint 1042252304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,659.39253
Policy Entropy: 3.74208
Value Function Loss: 0.02311

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.45201
Value Function Update Magnitude: 0.54430

Collected Steps per Second: 22,262.08509
Overall Steps per Second: 10,689.57481

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.67933

Cumulative Model Updates: 124,994
Cumulative Timesteps: 1,042,302,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,583.41837
Policy Entropy: 3.73441
Value Function Loss: 0.02565

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.48360
Value Function Update Magnitude: 0.50448

Collected Steps per Second: 22,824.16242
Overall Steps per Second: 10,856.80063

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.60965

Cumulative Model Updates: 125,000
Cumulative Timesteps: 1,042,352,370

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1042352370...
Checkpoint 1042352370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.24916
Policy Entropy: 3.75467
Value Function Loss: 0.02802

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.58270

Collected Steps per Second: 23,084.99669
Overall Steps per Second: 10,792.48265

Timestep Collection Time: 2.16755
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.63638

Cumulative Model Updates: 125,006
Cumulative Timesteps: 1,042,402,408

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,163.80678
Policy Entropy: 3.78877
Value Function Loss: 0.03097

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.62513
Value Function Update Magnitude: 0.69950

Collected Steps per Second: 22,811.59395
Overall Steps per Second: 10,810.36637

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.62649

Cumulative Model Updates: 125,012
Cumulative Timesteps: 1,042,452,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1042452422...
Checkpoint 1042452422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.03436
Policy Entropy: 3.80573
Value Function Loss: 0.03107

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.63854
Value Function Update Magnitude: 0.81422

Collected Steps per Second: 22,909.18939
Overall Steps per Second: 10,776.26780

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.63983

Cumulative Model Updates: 125,018
Cumulative Timesteps: 1,042,502,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.25108
Policy Entropy: 3.80873
Value Function Loss: 0.02846

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.59374
Value Function Update Magnitude: 0.81461

Collected Steps per Second: 23,316.27745
Overall Steps per Second: 10,756.71178

Timestep Collection Time: 2.14571
Timestep Consumption Time: 2.50534
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.65105

Cumulative Model Updates: 125,024
Cumulative Timesteps: 1,042,552,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1042552452...
Checkpoint 1042552452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,303.49598
Policy Entropy: 3.77691
Value Function Loss: 0.02552

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.51907
Value Function Update Magnitude: 0.71890

Collected Steps per Second: 22,789.45768
Overall Steps per Second: 10,663.38257

Timestep Collection Time: 2.19514
Timestep Consumption Time: 2.49624
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.69138

Cumulative Model Updates: 125,030
Cumulative Timesteps: 1,042,602,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,950.84476
Policy Entropy: 3.74780
Value Function Loss: 0.02271

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.47072
Value Function Update Magnitude: 0.55891

Collected Steps per Second: 22,687.50918
Overall Steps per Second: 10,792.80372

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.42983
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.63457

Cumulative Model Updates: 125,036
Cumulative Timesteps: 1,042,652,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1042652498...
Checkpoint 1042652498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,448.30340
Policy Entropy: 3.72937
Value Function Loss: 0.02156

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.45847
Value Function Update Magnitude: 0.46801

Collected Steps per Second: 22,582.43793
Overall Steps per Second: 10,792.34574

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63514

Cumulative Model Updates: 125,042
Cumulative Timesteps: 1,042,702,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,480.73996
Policy Entropy: 3.71862
Value Function Loss: 0.02091

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.45271
Value Function Update Magnitude: 0.44468

Collected Steps per Second: 22,950.85231
Overall Steps per Second: 10,825.48803

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62205

Cumulative Model Updates: 125,048
Cumulative Timesteps: 1,042,752,558

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1042752558...
Checkpoint 1042752558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,123.25387
Policy Entropy: 3.71973
Value Function Loss: 0.01964

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.43616
Value Function Update Magnitude: 0.40794

Collected Steps per Second: 22,842.29852
Overall Steps per Second: 10,680.56228

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68215

Cumulative Model Updates: 125,054
Cumulative Timesteps: 1,042,802,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,398.78952
Policy Entropy: 3.72485
Value Function Loss: 0.02130

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.45479
Value Function Update Magnitude: 0.45912

Collected Steps per Second: 22,200.60538
Overall Steps per Second: 10,874.32655

Timestep Collection Time: 2.25318
Timestep Consumption Time: 2.34683
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.60001

Cumulative Model Updates: 125,060
Cumulative Timesteps: 1,042,852,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1042852588...
Checkpoint 1042852588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,271.02065
Policy Entropy: 3.73244
Value Function Loss: 0.02173

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.48262
Value Function Update Magnitude: 0.58142

Collected Steps per Second: 22,292.18868
Overall Steps per Second: 10,703.55017

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67209

Cumulative Model Updates: 125,066
Cumulative Timesteps: 1,042,902,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,088.89257
Policy Entropy: 3.73328
Value Function Loss: 0.02488

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.52452
Value Function Update Magnitude: 0.66507

Collected Steps per Second: 22,094.45561
Overall Steps per Second: 10,825.33551

Timestep Collection Time: 2.26355
Timestep Consumption Time: 2.35635
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61990

Cumulative Model Updates: 125,072
Cumulative Timesteps: 1,042,952,608

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1042952608...
Checkpoint 1042952608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,934.29716
Policy Entropy: 3.73378
Value Function Loss: 0.02555

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.62156

Collected Steps per Second: 22,268.21334
Overall Steps per Second: 10,707.10124

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.67223

Cumulative Model Updates: 125,078
Cumulative Timesteps: 1,043,002,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,610.18009
Policy Entropy: 3.74330
Value Function Loss: 0.02399

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.55133

Collected Steps per Second: 22,894.74152
Overall Steps per Second: 10,914.13904

Timestep Collection Time: 2.18391
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58121

Cumulative Model Updates: 125,084
Cumulative Timesteps: 1,043,052,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1043052634...
Checkpoint 1043052634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,910.87166
Policy Entropy: 3.73840
Value Function Loss: 0.02606

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.51129
Value Function Update Magnitude: 0.53688

Collected Steps per Second: 22,803.94702
Overall Steps per Second: 10,717.95557

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.47286
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.66582

Cumulative Model Updates: 125,090
Cumulative Timesteps: 1,043,102,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,780.45288
Policy Entropy: 3.73825
Value Function Loss: 0.02665

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.51550
Value Function Update Magnitude: 0.49096

Collected Steps per Second: 22,936.19726
Overall Steps per Second: 10,851.04746

Timestep Collection Time: 2.18127
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.61061

Cumulative Model Updates: 125,096
Cumulative Timesteps: 1,043,152,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1043152672...
Checkpoint 1043152672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,634.74735
Policy Entropy: 3.74041
Value Function Loss: 0.02698

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.52222
Value Function Update Magnitude: 0.50226

Collected Steps per Second: 22,887.80499
Overall Steps per Second: 10,682.91646

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.68112

Cumulative Model Updates: 125,102
Cumulative Timesteps: 1,043,202,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,399.71272
Policy Entropy: 3.74068
Value Function Loss: 0.02512

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.53236
Value Function Update Magnitude: 0.51080

Collected Steps per Second: 22,293.22075
Overall Steps per Second: 10,583.64274

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.72578

Cumulative Model Updates: 125,108
Cumulative Timesteps: 1,043,252,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1043252696...
Checkpoint 1043252696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,767.73478
Policy Entropy: 3.74877
Value Function Loss: 0.02406

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.52724
Value Function Update Magnitude: 0.55670

Collected Steps per Second: 22,802.21388
Overall Steps per Second: 10,845.41306

Timestep Collection Time: 2.19409
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61301

Cumulative Model Updates: 125,114
Cumulative Timesteps: 1,043,302,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.13317
Policy Entropy: 3.73985
Value Function Loss: 0.02353

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.49389
Value Function Update Magnitude: 0.48829

Collected Steps per Second: 22,715.01924
Overall Steps per Second: 10,682.87540

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.68245

Cumulative Model Updates: 125,120
Cumulative Timesteps: 1,043,352,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1043352748...
Checkpoint 1043352748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.13317
Policy Entropy: 3.72758
Value Function Loss: 0.02245

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.46727
Value Function Update Magnitude: 0.44845

Collected Steps per Second: 22,949.71567
Overall Steps per Second: 10,864.90226

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.60381

Cumulative Model Updates: 125,126
Cumulative Timesteps: 1,043,402,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.13317
Policy Entropy: 3.71077
Value Function Loss: 0.02219

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.43015

Collected Steps per Second: 22,907.94932
Overall Steps per Second: 10,732.76126

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.66031

Cumulative Model Updates: 125,132
Cumulative Timesteps: 1,043,452,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1043452786...
Checkpoint 1043452786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,938.78427
Policy Entropy: 3.70700
Value Function Loss: 0.02129

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.48938
Value Function Update Magnitude: 0.40627

Collected Steps per Second: 21,993.49867
Overall Steps per Second: 10,816.40227

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.35053
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62520

Cumulative Model Updates: 125,138
Cumulative Timesteps: 1,043,502,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,353.35322
Policy Entropy: 3.72283
Value Function Loss: 0.02125

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.48359
Value Function Update Magnitude: 0.40388

Collected Steps per Second: 22,176.84187
Overall Steps per Second: 10,896.16371

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.33454
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.58951

Cumulative Model Updates: 125,144
Cumulative Timesteps: 1,043,552,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1043552822...
Checkpoint 1043552822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,212.69453
Policy Entropy: 3.72992
Value Function Loss: 0.02067

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.44905
Value Function Update Magnitude: 0.41059

Collected Steps per Second: 22,013.55464
Overall Steps per Second: 10,720.88822

Timestep Collection Time: 2.27242
Timestep Consumption Time: 2.39361
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.66603

Cumulative Model Updates: 125,150
Cumulative Timesteps: 1,043,602,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,212.69453
Policy Entropy: 3.73815
Value Function Loss: 0.01868

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.44812
Value Function Update Magnitude: 0.43420

Collected Steps per Second: 22,342.28716
Overall Steps per Second: 10,668.37458

Timestep Collection Time: 2.23871
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.68844

Cumulative Model Updates: 125,156
Cumulative Timesteps: 1,043,652,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1043652864...
Checkpoint 1043652864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,212.69453
Policy Entropy: 3.72402
Value Function Loss: 0.01816

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.43964
Value Function Update Magnitude: 0.42438

Collected Steps per Second: 22,527.85503
Overall Steps per Second: 10,820.17839

Timestep Collection Time: 2.22036
Timestep Consumption Time: 2.40248
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62284

Cumulative Model Updates: 125,162
Cumulative Timesteps: 1,043,702,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,449.99650
Policy Entropy: 3.72575
Value Function Loss: 0.01908

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.45355
Value Function Update Magnitude: 0.42841

Collected Steps per Second: 22,778.89074
Overall Steps per Second: 10,662.71990

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.68961

Cumulative Model Updates: 125,168
Cumulative Timesteps: 1,043,752,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1043752888...
Checkpoint 1043752888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,825.98417
Policy Entropy: 3.71714
Value Function Loss: 0.02155

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.49692
Value Function Update Magnitude: 0.51218

Collected Steps per Second: 22,976.68725
Overall Steps per Second: 10,873.00278

Timestep Collection Time: 2.17699
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60039

Cumulative Model Updates: 125,174
Cumulative Timesteps: 1,043,802,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,037.51119
Policy Entropy: 3.73188
Value Function Loss: 0.02205

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.54818
Value Function Update Magnitude: 0.55764

Collected Steps per Second: 23,156.79065
Overall Steps per Second: 10,891.73334

Timestep Collection Time: 2.16040
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59321

Cumulative Model Updates: 125,180
Cumulative Timesteps: 1,043,852,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1043852936...
Checkpoint 1043852936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,674.69807
Policy Entropy: 3.73881
Value Function Loss: 0.02272

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.58742

Collected Steps per Second: 22,524.02179
Overall Steps per Second: 10,724.99270

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.66611

Cumulative Model Updates: 125,186
Cumulative Timesteps: 1,043,902,980

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,177.77955
Policy Entropy: 3.73686
Value Function Loss: 0.02324

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.52676
Value Function Update Magnitude: 0.55104

Collected Steps per Second: 23,290.56490
Overall Steps per Second: 10,977.35885

Timestep Collection Time: 2.14791
Timestep Consumption Time: 2.40929
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.55720

Cumulative Model Updates: 125,192
Cumulative Timesteps: 1,043,953,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1043953006...
Checkpoint 1043953006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,177.77955
Policy Entropy: 3.73729
Value Function Loss: 0.02152

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.50763
Value Function Update Magnitude: 0.50756

Collected Steps per Second: 22,775.60567
Overall Steps per Second: 10,698.29207

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.47831
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.67364

Cumulative Model Updates: 125,198
Cumulative Timesteps: 1,044,003,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,177.77955
Policy Entropy: 3.71675
Value Function Loss: 0.02407

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.47315

Collected Steps per Second: 23,166.88899
Overall Steps per Second: 10,783.42527

Timestep Collection Time: 2.15920
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.63879

Cumulative Model Updates: 125,204
Cumulative Timesteps: 1,044,053,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1044053028...
Checkpoint 1044053028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,967.50836
Policy Entropy: 3.72562
Value Function Loss: 0.02356

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.50542
Value Function Update Magnitude: 0.45212

Collected Steps per Second: 22,668.01339
Overall Steps per Second: 10,605.69056

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.50870
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.71445

Cumulative Model Updates: 125,210
Cumulative Timesteps: 1,044,103,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,368.47743
Policy Entropy: 3.71052
Value Function Loss: 0.02651

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.52752
Value Function Update Magnitude: 0.45224

Collected Steps per Second: 22,131.60276
Overall Steps per Second: 10,837.70647

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.35487
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61463

Cumulative Model Updates: 125,216
Cumulative Timesteps: 1,044,153,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1044153040...
Checkpoint 1044153040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,368.47743
Policy Entropy: 3.72210
Value Function Loss: 0.02432

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.55218
Value Function Update Magnitude: 0.45411

Collected Steps per Second: 22,085.30085
Overall Steps per Second: 10,754.62616

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.38598
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.65065

Cumulative Model Updates: 125,222
Cumulative Timesteps: 1,044,203,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,368.47743
Policy Entropy: 3.72902
Value Function Loss: 0.02100

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.47929

Collected Steps per Second: 22,349.42412
Overall Steps per Second: 10,925.33775

Timestep Collection Time: 2.23800
Timestep Consumption Time: 2.34017
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.57817

Cumulative Model Updates: 125,228
Cumulative Timesteps: 1,044,253,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1044253074...
Checkpoint 1044253074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,368.47743
Policy Entropy: 3.73981
Value Function Loss: 0.01859

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.52912
Value Function Update Magnitude: 0.41575

Collected Steps per Second: 22,000.00308
Overall Steps per Second: 10,630.74047

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70428

Cumulative Model Updates: 125,234
Cumulative Timesteps: 1,044,303,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,084.91636
Policy Entropy: 3.72052
Value Function Loss: 0.01972

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.49075
Value Function Update Magnitude: 0.35749

Collected Steps per Second: 23,071.62391
Overall Steps per Second: 10,894.70611

Timestep Collection Time: 2.16725
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.58957

Cumulative Model Updates: 125,240
Cumulative Timesteps: 1,044,353,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1044353086...
Checkpoint 1044353086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.71903
Value Function Loss: 0.02139

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.49259
Value Function Update Magnitude: 0.39157

Collected Steps per Second: 22,533.86781
Overall Steps per Second: 10,636.29250

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.70333

Cumulative Model Updates: 125,246
Cumulative Timesteps: 1,044,403,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.73000
Value Function Loss: 0.02178

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.40330

Collected Steps per Second: 22,987.90561
Overall Steps per Second: 10,876.76924

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.42267
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.59842

Cumulative Model Updates: 125,252
Cumulative Timesteps: 1,044,453,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1044453128...
Checkpoint 1044453128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.74044
Value Function Loss: 0.01990

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.38610

Collected Steps per Second: 22,822.11176
Overall Steps per Second: 10,643.43462

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.69811

Cumulative Model Updates: 125,258
Cumulative Timesteps: 1,044,503,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.73172
Value Function Loss: 0.01967

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.51862
Value Function Update Magnitude: 0.39714

Collected Steps per Second: 22,788.33732
Overall Steps per Second: 10,843.01399

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.61274

Cumulative Model Updates: 125,264
Cumulative Timesteps: 1,044,553,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1044553148...
Checkpoint 1044553148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.72155
Value Function Loss: 0.01994

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.44782
Value Function Update Magnitude: 0.35989

Collected Steps per Second: 22,510.13935
Overall Steps per Second: 10,784.81679

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.41541
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.63707

Cumulative Model Updates: 125,270
Cumulative Timesteps: 1,044,603,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,983.87234
Policy Entropy: 3.70671
Value Function Loss: 0.01988

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.41555
Value Function Update Magnitude: 0.33118

Collected Steps per Second: 23,038.47458
Overall Steps per Second: 10,891.30370

Timestep Collection Time: 2.17046
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.59119

Cumulative Model Updates: 125,276
Cumulative Timesteps: 1,044,653,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1044653162...
Checkpoint 1044653162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,022.62807
Policy Entropy: 3.72105
Value Function Loss: 0.01971

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.44463
Value Function Update Magnitude: 0.37215

Collected Steps per Second: 23,175.35981
Overall Steps per Second: 10,968.45828

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.55944

Cumulative Model Updates: 125,282
Cumulative Timesteps: 1,044,703,172

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.51401
Policy Entropy: 3.73243
Value Function Loss: 0.01976

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.43759
Value Function Update Magnitude: 0.47382

Collected Steps per Second: 22,840.39810
Overall Steps per Second: 10,722.10044

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.66327

Cumulative Model Updates: 125,288
Cumulative Timesteps: 1,044,753,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1044753172...
Checkpoint 1044753172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.51401
Policy Entropy: 3.72248
Value Function Loss: 0.01927

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.43637
Value Function Update Magnitude: 0.51101

Collected Steps per Second: 22,474.02654
Overall Steps per Second: 10,969.29667

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.33413
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.55964

Cumulative Model Updates: 125,294
Cumulative Timesteps: 1,044,803,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.51401
Policy Entropy: 3.70162
Value Function Loss: 0.02008

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.42049
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 22,409.52646
Overall Steps per Second: 10,819.12732

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.39054
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.62200

Cumulative Model Updates: 125,300
Cumulative Timesteps: 1,044,853,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1044853194...
Checkpoint 1044853194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.51401
Policy Entropy: 3.69593
Value Function Loss: 0.02049

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.41985
Value Function Update Magnitude: 0.47683

Collected Steps per Second: 21,876.77788
Overall Steps per Second: 10,650.30191

Timestep Collection Time: 2.28626
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.69620

Cumulative Model Updates: 125,306
Cumulative Timesteps: 1,044,903,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,212.51401
Policy Entropy: 3.71538
Value Function Loss: 0.01829

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.40993
Value Function Update Magnitude: 0.41824

Collected Steps per Second: 22,964.98457
Overall Steps per Second: 10,938.40893

Timestep Collection Time: 2.17784
Timestep Consumption Time: 2.39449
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57233

Cumulative Model Updates: 125,312
Cumulative Timesteps: 1,044,953,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1044953224...
Checkpoint 1044953224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,027.31622
Policy Entropy: 3.72730
Value Function Loss: 0.01858

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.40345
Value Function Update Magnitude: 0.49293

Collected Steps per Second: 22,748.11701
Overall Steps per Second: 10,733.67414

Timestep Collection Time: 2.19834
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.65898

Cumulative Model Updates: 125,318
Cumulative Timesteps: 1,045,003,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,059.35290
Policy Entropy: 3.73481
Value Function Loss: 0.01881

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.42088
Value Function Update Magnitude: 0.59463

Collected Steps per Second: 23,221.10650
Overall Steps per Second: 10,818.44641

Timestep Collection Time: 2.15321
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.62174

Cumulative Model Updates: 125,324
Cumulative Timesteps: 1,045,053,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1045053232...
Checkpoint 1045053232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,083.08539
Policy Entropy: 3.71646
Value Function Loss: 0.02172

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.45748
Value Function Update Magnitude: 0.59881

Collected Steps per Second: 22,856.17977
Overall Steps per Second: 10,672.84300

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68610

Cumulative Model Updates: 125,330
Cumulative Timesteps: 1,045,103,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,083.08539
Policy Entropy: 3.72243
Value Function Loss: 0.02000

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.47615
Value Function Update Magnitude: 0.67595

Collected Steps per Second: 23,016.65848
Overall Steps per Second: 10,897.73544

Timestep Collection Time: 2.17312
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.58976

Cumulative Model Updates: 125,336
Cumulative Timesteps: 1,045,153,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045153264...
Checkpoint 1045153264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,911.97666
Policy Entropy: 3.72459
Value Function Loss: 0.02131

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.51347
Value Function Update Magnitude: 0.81300

Collected Steps per Second: 22,679.56508
Overall Steps per Second: 10,644.59945

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.69741

Cumulative Model Updates: 125,342
Cumulative Timesteps: 1,045,203,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,899.13288
Policy Entropy: 3.74188
Value Function Loss: 0.02239

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.54074
Value Function Update Magnitude: 0.76432

Collected Steps per Second: 23,184.32530
Overall Steps per Second: 10,929.90802

Timestep Collection Time: 2.15887
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.57936

Cumulative Model Updates: 125,348
Cumulative Timesteps: 1,045,253,318

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1045253318...
Checkpoint 1045253318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,244.66085
Policy Entropy: 3.73547
Value Function Loss: 0.02539

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.72902

Collected Steps per Second: 22,554.03315
Overall Steps per Second: 10,592.74950

Timestep Collection Time: 2.21690
Timestep Consumption Time: 2.50331
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.72021

Cumulative Model Updates: 125,354
Cumulative Timesteps: 1,045,303,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,013.06487
Policy Entropy: 3.72981
Value Function Loss: 0.02208

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.49778
Value Function Update Magnitude: 0.62684

Collected Steps per Second: 22,372.94270
Overall Steps per Second: 10,920.49860

Timestep Collection Time: 2.23565
Timestep Consumption Time: 2.34455
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.58019

Cumulative Model Updates: 125,360
Cumulative Timesteps: 1,045,353,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1045353336...
Checkpoint 1045353336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,718.55920
Policy Entropy: 3.73476
Value Function Loss: 0.01989

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.45599
Value Function Update Magnitude: 0.60594

Collected Steps per Second: 22,112.65322
Overall Steps per Second: 10,686.86733

Timestep Collection Time: 2.26187
Timestep Consumption Time: 2.41826
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.68014

Cumulative Model Updates: 125,366
Cumulative Timesteps: 1,045,403,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,521.29898
Policy Entropy: 3.75642
Value Function Loss: 0.01898

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.45131
Value Function Update Magnitude: 0.68978

Collected Steps per Second: 22,382.14737
Overall Steps per Second: 10,878.73368

Timestep Collection Time: 2.23616
Timestep Consumption Time: 2.36456
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.60072

Cumulative Model Updates: 125,372
Cumulative Timesteps: 1,045,453,402

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1045453402...
Checkpoint 1045453402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,833.53686
Policy Entropy: 3.75190
Value Function Loss: 0.02059

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.47445
Value Function Update Magnitude: 0.73949

Collected Steps per Second: 21,904.57299
Overall Steps per Second: 10,689.53754

Timestep Collection Time: 2.28473
Timestep Consumption Time: 2.39705
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.68177

Cumulative Model Updates: 125,378
Cumulative Timesteps: 1,045,503,448

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,833.53686
Policy Entropy: 3.75089
Value Function Loss: 0.01907

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.47792
Value Function Update Magnitude: 0.68919

Collected Steps per Second: 22,899.90271
Overall Steps per Second: 10,936.56049

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.38869
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.57237

Cumulative Model Updates: 125,384
Cumulative Timesteps: 1,045,553,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1045553454...
Checkpoint 1045553454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,449.61028
Policy Entropy: 3.73414
Value Function Loss: 0.01832

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.44675
Value Function Update Magnitude: 0.51685

Collected Steps per Second: 22,820.67213
Overall Steps per Second: 10,770.94026

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64286

Cumulative Model Updates: 125,390
Cumulative Timesteps: 1,045,603,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,383.09431
Policy Entropy: 3.73691
Value Function Loss: 0.01943

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.44697
Value Function Update Magnitude: 0.47950

Collected Steps per Second: 23,113.07057
Overall Steps per Second: 10,706.85009

Timestep Collection Time: 2.16432
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.67215

Cumulative Model Updates: 125,396
Cumulative Timesteps: 1,045,653,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1045653486...
Checkpoint 1045653486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,175.68625
Policy Entropy: 3.73494
Value Function Loss: 0.02053

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14124
Policy Update Magnitude: 0.46047
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 22,452.48284
Overall Steps per Second: 10,617.50364

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.71090

Cumulative Model Updates: 125,402
Cumulative Timesteps: 1,045,703,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,175.68625
Policy Entropy: 3.71918
Value Function Loss: 0.02233

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14117
Policy Update Magnitude: 0.45983
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 22,719.12238
Overall Steps per Second: 10,663.52485

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.68926

Cumulative Model Updates: 125,408
Cumulative Timesteps: 1,045,753,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1045753508...
Checkpoint 1045753508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,053.25907
Policy Entropy: 3.72203
Value Function Loss: 0.01887

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.45808
Value Function Update Magnitude: 0.58436

Collected Steps per Second: 22,968.83726
Overall Steps per Second: 10,900.05598

Timestep Collection Time: 2.17747
Timestep Consumption Time: 2.41094
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.58842

Cumulative Model Updates: 125,414
Cumulative Timesteps: 1,045,803,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,053.25907
Policy Entropy: 3.70916
Value Function Loss: 0.01849

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.47369
Value Function Update Magnitude: 0.60489

Collected Steps per Second: 23,060.60127
Overall Steps per Second: 10,865.78477

Timestep Collection Time: 2.16855
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60234

Cumulative Model Updates: 125,420
Cumulative Timesteps: 1,045,853,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1045853530...
Checkpoint 1045853530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,053.25907
Policy Entropy: 3.72225
Value Function Loss: 0.01805

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.51598
Value Function Update Magnitude: 0.52881

Collected Steps per Second: 22,741.05422
Overall Steps per Second: 10,667.04210

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68790

Cumulative Model Updates: 125,426
Cumulative Timesteps: 1,045,903,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,332.71941
Policy Entropy: 3.73874
Value Function Loss: 0.01854

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.52387
Value Function Update Magnitude: 0.63912

Collected Steps per Second: 22,822.88362
Overall Steps per Second: 10,847.76672

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.60961

Cumulative Model Updates: 125,432
Cumulative Timesteps: 1,045,953,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1045953540...
Checkpoint 1045953540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,967.20191
Policy Entropy: 3.76318
Value Function Loss: 0.02189

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.53473
Value Function Update Magnitude: 0.74739

Collected Steps per Second: 22,676.95448
Overall Steps per Second: 10,716.11535

Timestep Collection Time: 2.20515
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.66643

Cumulative Model Updates: 125,438
Cumulative Timesteps: 1,046,003,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,154.93921
Policy Entropy: 3.76273
Value Function Loss: 0.02237

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.53094
Value Function Update Magnitude: 0.76031

Collected Steps per Second: 23,122.21153
Overall Steps per Second: 10,877.43236

Timestep Collection Time: 2.16277
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.59741

Cumulative Model Updates: 125,444
Cumulative Timesteps: 1,046,053,554

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1046053554...
Checkpoint 1046053554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,127.52136
Policy Entropy: 3.73905
Value Function Loss: 0.02479

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.51978
Value Function Update Magnitude: 0.85970

Collected Steps per Second: 22,719.60567
Overall Steps per Second: 10,811.56054

Timestep Collection Time: 2.20127
Timestep Consumption Time: 2.42452
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.62579

Cumulative Model Updates: 125,450
Cumulative Timesteps: 1,046,103,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,445.27386
Policy Entropy: 3.72745
Value Function Loss: 0.02383

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.84574

Collected Steps per Second: 22,790.51815
Overall Steps per Second: 10,818.01065

Timestep Collection Time: 2.19416
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.62248

Cumulative Model Updates: 125,456
Cumulative Timesteps: 1,046,153,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1046153572...
Checkpoint 1046153572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,543.45544
Policy Entropy: 3.73288
Value Function Loss: 0.02585

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.72611

Collected Steps per Second: 22,803.70001
Overall Steps per Second: 10,711.74132

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.67020

Cumulative Model Updates: 125,462
Cumulative Timesteps: 1,046,203,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,894.63058
Policy Entropy: 3.72141
Value Function Loss: 0.02693

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.68347

Collected Steps per Second: 23,030.63703
Overall Steps per Second: 10,889.29251

Timestep Collection Time: 2.17241
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59461

Cumulative Model Updates: 125,468
Cumulative Timesteps: 1,046,253,630

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1046253630...
Checkpoint 1046253630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,284.37125
Policy Entropy: 3.72161
Value Function Loss: 0.02731

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.61689
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 22,667.54768
Overall Steps per Second: 10,643.14203

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70012

Cumulative Model Updates: 125,474
Cumulative Timesteps: 1,046,303,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,284.37125
Policy Entropy: 3.71355
Value Function Loss: 0.02453

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 23,248.45574
Overall Steps per Second: 10,982.69446

Timestep Collection Time: 2.15137
Timestep Consumption Time: 2.40270
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.55407

Cumulative Model Updates: 125,480
Cumulative Timesteps: 1,046,353,670

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1046353670...
Checkpoint 1046353670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,284.37125
Policy Entropy: 3.71620
Value Function Loss: 0.02118

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.53856
Value Function Update Magnitude: 0.72208

Collected Steps per Second: 21,899.07266
Overall Steps per Second: 10,645.07870

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.41448
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.69832

Cumulative Model Updates: 125,486
Cumulative Timesteps: 1,046,403,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,929.29827
Policy Entropy: 3.72439
Value Function Loss: 0.02033

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.52123
Value Function Update Magnitude: 0.67426

Collected Steps per Second: 22,006.88962
Overall Steps per Second: 10,809.11428

Timestep Collection Time: 2.27229
Timestep Consumption Time: 2.35399
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.62628

Cumulative Model Updates: 125,492
Cumulative Timesteps: 1,046,453,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1046453690...
Checkpoint 1046453690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,765.89169
Policy Entropy: 3.72090
Value Function Loss: 0.02054

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.50042
Value Function Update Magnitude: 0.66072

Collected Steps per Second: 22,251.49536
Overall Steps per Second: 10,691.88497

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.43096
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.67944

Cumulative Model Updates: 125,498
Cumulative Timesteps: 1,046,503,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,435.39903
Policy Entropy: 3.74282
Value Function Loss: 0.02017

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.69299

Collected Steps per Second: 22,258.89403
Overall Steps per Second: 10,662.92158

Timestep Collection Time: 2.24647
Timestep Consumption Time: 2.44305
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.68952

Cumulative Model Updates: 125,504
Cumulative Timesteps: 1,046,553,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1046553726...
Checkpoint 1046553726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,622.72473
Policy Entropy: 3.73349
Value Function Loss: 0.02038

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.49203
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 22,916.21584
Overall Steps per Second: 10,943.72232

Timestep Collection Time: 2.18256
Timestep Consumption Time: 2.38773
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.57029

Cumulative Model Updates: 125,510
Cumulative Timesteps: 1,046,603,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,622.72473
Policy Entropy: 3.74141
Value Function Loss: 0.01904

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.48052
Value Function Update Magnitude: 0.55561

Collected Steps per Second: 23,231.44310
Overall Steps per Second: 10,832.85272

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.61651

Cumulative Model Updates: 125,516
Cumulative Timesteps: 1,046,653,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1046653752...
Checkpoint 1046653752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,568.53177
Policy Entropy: 3.72950
Value Function Loss: 0.01858

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.50630
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 22,821.34126
Overall Steps per Second: 10,667.37282

Timestep Collection Time: 2.19093
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68719

Cumulative Model Updates: 125,522
Cumulative Timesteps: 1,046,703,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,362.12595
Policy Entropy: 3.72193
Value Function Loss: 0.02101

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.48723
Value Function Update Magnitude: 0.50413

Collected Steps per Second: 23,066.54627
Overall Steps per Second: 10,900.57922

Timestep Collection Time: 2.16807
Timestep Consumption Time: 2.41975
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.58783

Cumulative Model Updates: 125,528
Cumulative Timesteps: 1,046,753,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1046753762...
Checkpoint 1046753762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,074.61309
Policy Entropy: 3.72931
Value Function Loss: 0.02115

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.52221

Collected Steps per Second: 22,723.00835
Overall Steps per Second: 10,633.17962

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.50325
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70490

Cumulative Model Updates: 125,534
Cumulative Timesteps: 1,046,803,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,699.37122
Policy Entropy: 3.72850
Value Function Loss: 0.02025

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.49122
Value Function Update Magnitude: 0.62040

Collected Steps per Second: 22,861.59723
Overall Steps per Second: 10,829.11995

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61810

Cumulative Model Updates: 125,540
Cumulative Timesteps: 1,046,853,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1046853800...
Checkpoint 1046853800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,699.37122
Policy Entropy: 3.72453
Value Function Loss: 0.01892

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.46951
Value Function Update Magnitude: 0.59368

Collected Steps per Second: 22,569.35398
Overall Steps per Second: 10,697.18370

Timestep Collection Time: 2.21655
Timestep Consumption Time: 2.46001
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67656

Cumulative Model Updates: 125,546
Cumulative Timesteps: 1,046,903,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,981.12988
Policy Entropy: 3.72097
Value Function Loss: 0.01628

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.42744
Value Function Update Magnitude: 0.48289

Collected Steps per Second: 22,990.16599
Overall Steps per Second: 10,860.32351

Timestep Collection Time: 2.17528
Timestep Consumption Time: 2.42956
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60484

Cumulative Model Updates: 125,552
Cumulative Timesteps: 1,046,953,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1046953836...
Checkpoint 1046953836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 607,990.61734
Policy Entropy: 3.72061
Value Function Loss: 0.01776

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.38769
Value Function Update Magnitude: 0.47789

Collected Steps per Second: 22,953.30892
Overall Steps per Second: 10,706.60122

Timestep Collection Time: 2.17921
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.67188

Cumulative Model Updates: 125,558
Cumulative Timesteps: 1,047,003,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,478.03948
Policy Entropy: 3.73490
Value Function Loss: 0.01640

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.38484
Value Function Update Magnitude: 0.50041

Collected Steps per Second: 22,978.76114
Overall Steps per Second: 10,865.03192

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60266

Cumulative Model Updates: 125,564
Cumulative Timesteps: 1,047,053,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1047053864...
Checkpoint 1047053864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492,478.03948
Policy Entropy: 3.72652
Value Function Loss: 0.01761

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.40120
Value Function Update Magnitude: 0.48513

Collected Steps per Second: 22,678.51751
Overall Steps per Second: 10,648.69379

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.69804

Cumulative Model Updates: 125,570
Cumulative Timesteps: 1,047,103,892

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 492,478.03948
Policy Entropy: 3.71501
Value Function Loss: 0.01730

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.42668
Value Function Update Magnitude: 0.40309

Collected Steps per Second: 22,755.37863
Overall Steps per Second: 10,834.42382

Timestep Collection Time: 2.19939
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61935

Cumulative Model Updates: 125,576
Cumulative Timesteps: 1,047,153,940

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1047153940...
Checkpoint 1047153940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,391.27967
Policy Entropy: 3.71946
Value Function Loss: 0.01893

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.46218
Value Function Update Magnitude: 0.40871

Collected Steps per Second: 22,393.41147
Overall Steps per Second: 10,777.02645

Timestep Collection Time: 2.23360
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.64117

Cumulative Model Updates: 125,582
Cumulative Timesteps: 1,047,203,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,791.99808
Policy Entropy: 3.72637
Value Function Loss: 0.01749

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.48289
Value Function Update Magnitude: 0.55444

Collected Steps per Second: 22,846.39321
Overall Steps per Second: 10,846.44271

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.60999

Cumulative Model Updates: 125,588
Cumulative Timesteps: 1,047,253,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047253960...
Checkpoint 1047253960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,529.80700
Policy Entropy: 3.75095
Value Function Loss: 0.01676

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.46339
Value Function Update Magnitude: 0.62076

Collected Steps per Second: 22,841.22789
Overall Steps per Second: 10,639.23092

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.70090

Cumulative Model Updates: 125,594
Cumulative Timesteps: 1,047,303,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,594.80781
Policy Entropy: 3.74758
Value Function Loss: 0.01809

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.44796
Value Function Update Magnitude: 0.64229

Collected Steps per Second: 21,989.84286
Overall Steps per Second: 10,815.47051

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.34932
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.62319

Cumulative Model Updates: 125,600
Cumulative Timesteps: 1,047,353,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047353976...
Checkpoint 1047353976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,162.03026
Policy Entropy: 3.76111
Value Function Loss: 0.01725

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.48530
Value Function Update Magnitude: 0.61183

Collected Steps per Second: 22,161.26243
Overall Steps per Second: 10,716.01913

Timestep Collection Time: 2.25646
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.66647

Cumulative Model Updates: 125,606
Cumulative Timesteps: 1,047,403,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,133.02853
Policy Entropy: 3.73547
Value Function Loss: 0.01895

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.49310
Value Function Update Magnitude: 0.56565

Collected Steps per Second: 22,453.27361
Overall Steps per Second: 10,951.79884

Timestep Collection Time: 2.22711
Timestep Consumption Time: 2.33889
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.56601

Cumulative Model Updates: 125,612
Cumulative Timesteps: 1,047,453,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1047453988...
Checkpoint 1047453988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,870.46871
Policy Entropy: 3.74366
Value Function Loss: 0.01810

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.46434
Value Function Update Magnitude: 0.52265

Collected Steps per Second: 22,325.58339
Overall Steps per Second: 10,598.02291

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.72050

Cumulative Model Updates: 125,618
Cumulative Timesteps: 1,047,504,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,870.46871
Policy Entropy: 3.72781
Value Function Loss: 0.01646

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.44260
Value Function Update Magnitude: 0.56595

Collected Steps per Second: 22,988.35042
Overall Steps per Second: 10,915.44065

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.40633
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.58195

Cumulative Model Updates: 125,624
Cumulative Timesteps: 1,047,554,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1047554030...
Checkpoint 1047554030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,653.70756
Policy Entropy: 3.74152
Value Function Loss: 0.01855

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.42429
Value Function Update Magnitude: 0.59465

Collected Steps per Second: 22,769.28582
Overall Steps per Second: 10,725.51801

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.46653
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66308

Cumulative Model Updates: 125,630
Cumulative Timesteps: 1,047,604,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,502.21656
Policy Entropy: 3.74790
Value Function Loss: 0.01769

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.43342
Value Function Update Magnitude: 0.62952

Collected Steps per Second: 22,996.77447
Overall Steps per Second: 10,883.60889

Timestep Collection Time: 2.17604
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.59792

Cumulative Model Updates: 125,636
Cumulative Timesteps: 1,047,654,086

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1047654086...
Checkpoint 1047654086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.74612
Value Function Loss: 0.01973

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.43902
Value Function Update Magnitude: 0.60716

Collected Steps per Second: 22,919.96569
Overall Steps per Second: 10,698.35615

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.67567

Cumulative Model Updates: 125,642
Cumulative Timesteps: 1,047,704,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.72644
Value Function Loss: 0.01674

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.43238
Value Function Update Magnitude: 0.58663

Collected Steps per Second: 22,761.44401
Overall Steps per Second: 10,855.10655

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.41059
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.60834

Cumulative Model Updates: 125,648
Cumulative Timesteps: 1,047,754,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1047754132...
Checkpoint 1047754132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.71330
Value Function Loss: 0.02044

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.42571
Value Function Update Magnitude: 0.48951

Collected Steps per Second: 23,047.65005
Overall Steps per Second: 10,757.06566

Timestep Collection Time: 2.16968
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.64867

Cumulative Model Updates: 125,654
Cumulative Timesteps: 1,047,804,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.71016
Value Function Loss: 0.01911

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14506
Policy Update Magnitude: 0.42061
Value Function Update Magnitude: 0.43118

Collected Steps per Second: 23,047.68878
Overall Steps per Second: 10,732.12302

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.48960
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.65910

Cumulative Model Updates: 125,660
Cumulative Timesteps: 1,047,854,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1047854140...
Checkpoint 1047854140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.70209
Value Function Loss: 0.02294

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.41373
Value Function Update Magnitude: 0.44440

Collected Steps per Second: 23,073.72257
Overall Steps per Second: 10,731.59724

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.65914

Cumulative Model Updates: 125,666
Cumulative Timesteps: 1,047,904,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.70883
Value Function Loss: 0.02265

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.46787
Value Function Update Magnitude: 0.38116

Collected Steps per Second: 22,264.48277
Overall Steps per Second: 10,879.03739

Timestep Collection Time: 2.24806
Timestep Consumption Time: 2.35271
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.60077

Cumulative Model Updates: 125,672
Cumulative Timesteps: 1,047,954,192

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1047954192...
Checkpoint 1047954192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.71365
Value Function Loss: 0.02211

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.45748
Value Function Update Magnitude: 0.47103

Collected Steps per Second: 22,347.53957
Overall Steps per Second: 10,791.49152

Timestep Collection Time: 2.23873
Timestep Consumption Time: 2.39733
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.63606

Cumulative Model Updates: 125,678
Cumulative Timesteps: 1,048,004,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.71486
Value Function Loss: 0.01788

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.44612
Value Function Update Magnitude: 0.50320

Collected Steps per Second: 22,292.36309
Overall Steps per Second: 10,781.53728

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.39531
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.63886

Cumulative Model Updates: 125,684
Cumulative Timesteps: 1,048,054,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1048054236...
Checkpoint 1048054236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.70746
Value Function Loss: 0.01754

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14944
Policy Update Magnitude: 0.45489
Value Function Update Magnitude: 0.51057

Collected Steps per Second: 23,161.03104
Overall Steps per Second: 10,990.56916

Timestep Collection Time: 2.15923
Timestep Consumption Time: 2.39103
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.55026

Cumulative Model Updates: 125,690
Cumulative Timesteps: 1,048,104,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,094.67884
Policy Entropy: 3.71276
Value Function Loss: 0.01730

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.45063
Value Function Update Magnitude: 0.56958

Collected Steps per Second: 22,604.15713
Overall Steps per Second: 10,872.12489

Timestep Collection Time: 2.21198
Timestep Consumption Time: 2.38693
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.59892

Cumulative Model Updates: 125,696
Cumulative Timesteps: 1,048,154,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1048154246...
Checkpoint 1048154246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,829.02554
Policy Entropy: 3.73242
Value Function Loss: 0.01617

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.45208
Value Function Update Magnitude: 0.67944

Collected Steps per Second: 22,909.46233
Overall Steps per Second: 10,717.63572

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.66726

Cumulative Model Updates: 125,702
Cumulative Timesteps: 1,048,204,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,905.66111
Policy Entropy: 3.74093
Value Function Loss: 0.01753

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.44393
Value Function Update Magnitude: 0.69131

Collected Steps per Second: 22,814.45629
Overall Steps per Second: 10,656.91336

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69273

Cumulative Model Updates: 125,708
Cumulative Timesteps: 1,048,254,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1048254278...
Checkpoint 1048254278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.73814
Value Function Loss: 0.01613

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.47432
Value Function Update Magnitude: 0.68769

Collected Steps per Second: 23,163.99545
Overall Steps per Second: 10,824.07294

Timestep Collection Time: 2.15964
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.62174

Cumulative Model Updates: 125,714
Cumulative Timesteps: 1,048,304,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.73155
Value Function Loss: 0.01639

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.45742
Value Function Update Magnitude: 0.62504

Collected Steps per Second: 22,552.84052
Overall Steps per Second: 10,617.58500

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.71143

Cumulative Model Updates: 125,720
Cumulative Timesteps: 1,048,354,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048354328...
Checkpoint 1048354328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.73413
Value Function Loss: 0.01443

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.43406
Value Function Update Magnitude: 0.49387

Collected Steps per Second: 22,975.19757
Overall Steps per Second: 10,882.79225

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.59459

Cumulative Model Updates: 125,726
Cumulative Timesteps: 1,048,404,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.73045
Value Function Loss: 0.01485

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.45790

Collected Steps per Second: 22,950.78688
Overall Steps per Second: 10,653.65745

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69566

Cumulative Model Updates: 125,732
Cumulative Timesteps: 1,048,454,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1048454356...
Checkpoint 1048454356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.72501
Value Function Loss: 0.01604

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.46439
Value Function Update Magnitude: 0.41168

Collected Steps per Second: 22,804.61563
Overall Steps per Second: 10,686.21111

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.67911

Cumulative Model Updates: 125,738
Cumulative Timesteps: 1,048,504,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.72361
Value Function Loss: 0.01565

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.50266
Value Function Update Magnitude: 0.37643

Collected Steps per Second: 22,923.51783
Overall Steps per Second: 10,796.23542

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.63402

Cumulative Model Updates: 125,744
Cumulative Timesteps: 1,048,554,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1048554388...
Checkpoint 1048554388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.72570
Value Function Loss: 0.01688

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.46103
Value Function Update Magnitude: 0.34927

Collected Steps per Second: 22,779.17293
Overall Steps per Second: 10,675.98153

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68585

Cumulative Model Updates: 125,750
Cumulative Timesteps: 1,048,604,414

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.71974
Value Function Loss: 0.01653

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.48622
Value Function Update Magnitude: 0.38172

Collected Steps per Second: 23,170.79457
Overall Steps per Second: 10,839.09427

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.61551

Cumulative Model Updates: 125,756
Cumulative Timesteps: 1,048,654,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1048654442...
Checkpoint 1048654442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.71075
Value Function Loss: 0.02025

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.50182
Value Function Update Magnitude: 0.41443

Collected Steps per Second: 22,312.33964
Overall Steps per Second: 10,714.98239

Timestep Collection Time: 2.24100
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.66655

Cumulative Model Updates: 125,762
Cumulative Timesteps: 1,048,704,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.71732
Value Function Loss: 0.01777

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.51264
Value Function Update Magnitude: 0.44993

Collected Steps per Second: 22,297.70235
Overall Steps per Second: 10,921.71544

Timestep Collection Time: 2.24445
Timestep Consumption Time: 2.33780
PPO Batch Consumption Time: 0.27591
Total Iteration Time: 4.58225

Cumulative Model Updates: 125,768
Cumulative Timesteps: 1,048,754,490

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1048754490...
Checkpoint 1048754490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.70865
Value Function Loss: 0.01755

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15795
Policy Update Magnitude: 0.47469
Value Function Update Magnitude: 0.46697

Collected Steps per Second: 22,245.62286
Overall Steps per Second: 10,582.66264

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.47935
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72906

Cumulative Model Updates: 125,774
Cumulative Timesteps: 1,048,804,536

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.03838
Policy Entropy: 3.72046
Value Function Loss: 0.01557

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.45733
Value Function Update Magnitude: 0.48123

Collected Steps per Second: 22,801.14199
Overall Steps per Second: 10,872.80801

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.40691
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.60084

Cumulative Model Updates: 125,780
Cumulative Timesteps: 1,048,854,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1048854560...
Checkpoint 1048854560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 398,604.78383
Policy Entropy: 3.70184
Value Function Loss: 0.01856

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14758
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.52837

Collected Steps per Second: 23,048.71187
Overall Steps per Second: 10,792.68337

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.63499

Cumulative Model Updates: 125,786
Cumulative Timesteps: 1,048,904,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,595.41733
Policy Entropy: 3.72533
Value Function Loss: 0.01899

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.50403
Value Function Update Magnitude: 0.57738

Collected Steps per Second: 22,401.68392
Overall Steps per Second: 10,727.88079

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.66224

Cumulative Model Updates: 125,792
Cumulative Timesteps: 1,048,954,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1048954600...
Checkpoint 1048954600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,834.55629
Policy Entropy: 3.71864
Value Function Loss: 0.02113

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.50692
Value Function Update Magnitude: 0.46451

Collected Steps per Second: 22,892.89743
Overall Steps per Second: 10,699.01798

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.48984
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.67445

Cumulative Model Updates: 125,798
Cumulative Timesteps: 1,049,004,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,834.55629
Policy Entropy: 3.73930
Value Function Loss: 0.01798

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.51498
Value Function Update Magnitude: 0.44097

Collected Steps per Second: 22,986.60779
Overall Steps per Second: 10,890.20358

Timestep Collection Time: 2.17535
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.59165

Cumulative Model Updates: 125,804
Cumulative Timesteps: 1,049,054,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1049054616...
Checkpoint 1049054616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,834.55629
Policy Entropy: 3.72029
Value Function Loss: 0.01946

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.50339
Value Function Update Magnitude: 0.47264

Collected Steps per Second: 23,071.39024
Overall Steps per Second: 10,722.90268

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.66385

Cumulative Model Updates: 125,810
Cumulative Timesteps: 1,049,104,626

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,811.61921
Policy Entropy: 3.72333
Value Function Loss: 0.02002

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.49529
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 22,685.83958
Overall Steps per Second: 10,758.25756

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.44445
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.64927

Cumulative Model Updates: 125,816
Cumulative Timesteps: 1,049,154,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1049154644...
Checkpoint 1049154644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,703.16083
Policy Entropy: 3.71702
Value Function Loss: 0.02105

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.51568
Value Function Update Magnitude: 0.69176

Collected Steps per Second: 22,937.20598
Overall Steps per Second: 10,682.94472

Timestep Collection Time: 2.18074
Timestep Consumption Time: 2.50149
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68223

Cumulative Model Updates: 125,822
Cumulative Timesteps: 1,049,204,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,703.16083
Policy Entropy: 3.71263
Value Function Loss: 0.01953

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.49969
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 22,964.64153
Overall Steps per Second: 10,833.57232

Timestep Collection Time: 2.17726
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.61528

Cumulative Model Updates: 125,828
Cumulative Timesteps: 1,049,254,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1049254664...
Checkpoint 1049254664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,703.16083
Policy Entropy: 3.72520
Value Function Loss: 0.01647

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.45138
Value Function Update Magnitude: 0.48132

Collected Steps per Second: 22,824.31680
Overall Steps per Second: 10,744.30148

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.46308
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.65382

Cumulative Model Updates: 125,834
Cumulative Timesteps: 1,049,304,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,703.16083
Policy Entropy: 3.73227
Value Function Loss: 0.02014

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.42858
Value Function Update Magnitude: 0.38443

Collected Steps per Second: 22,842.10048
Overall Steps per Second: 10,848.17901

Timestep Collection Time: 2.19008
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61147

Cumulative Model Updates: 125,840
Cumulative Timesteps: 1,049,354,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1049354692...
Checkpoint 1049354692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,194.07340
Policy Entropy: 3.74157
Value Function Loss: 0.01961

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13805
Policy Update Magnitude: 0.47825
Value Function Update Magnitude: 0.51365

Collected Steps per Second: 22,985.90543
Overall Steps per Second: 10,725.42199

Timestep Collection Time: 2.17568
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.66275

Cumulative Model Updates: 125,846
Cumulative Timesteps: 1,049,404,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311,203.68104
Policy Entropy: 3.73846
Value Function Loss: 0.01901

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.48229
Value Function Update Magnitude: 0.74862

Collected Steps per Second: 22,825.17973
Overall Steps per Second: 10,817.64327

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.62245

Cumulative Model Updates: 125,852
Cumulative Timesteps: 1,049,454,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1049454706...
Checkpoint 1049454706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598,622.03531
Policy Entropy: 3.73440
Value Function Loss: 0.01721

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.47649
Value Function Update Magnitude: 0.71944

Collected Steps per Second: 22,924.79591
Overall Steps per Second: 10,705.42351

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.49068
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.67277

Cumulative Model Updates: 125,858
Cumulative Timesteps: 1,049,504,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,622.03531
Policy Entropy: 3.73485
Value Function Loss: 0.01518

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.44328
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 22,142.20476
Overall Steps per Second: 10,846.18545

Timestep Collection Time: 2.25940
Timestep Consumption Time: 2.35310
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.61250

Cumulative Model Updates: 125,864
Cumulative Timesteps: 1,049,554,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1049554758...
Checkpoint 1049554758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389,396.13724
Policy Entropy: 3.73444
Value Function Loss: 0.01569

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.43079
Value Function Update Magnitude: 0.64143

Collected Steps per Second: 22,067.26686
Overall Steps per Second: 10,729.46730

Timestep Collection Time: 2.26580
Timestep Consumption Time: 2.39426
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.66006

Cumulative Model Updates: 125,870
Cumulative Timesteps: 1,049,604,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.72465
Value Function Loss: 0.01623

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.49385
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 22,026.91472
Overall Steps per Second: 10,817.96524

Timestep Collection Time: 2.27104
Timestep Consumption Time: 2.35312
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.62416

Cumulative Model Updates: 125,876
Cumulative Timesteps: 1,049,654,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1049654782...
Checkpoint 1049654782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.74067
Value Function Loss: 0.01515

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.52594
Value Function Update Magnitude: 0.54954

Collected Steps per Second: 22,338.63010
Overall Steps per Second: 10,711.05420

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66976

Cumulative Model Updates: 125,882
Cumulative Timesteps: 1,049,704,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.75149
Value Function Loss: 0.01132

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.45252
Value Function Update Magnitude: 0.52924

Collected Steps per Second: 22,828.88009
Overall Steps per Second: 10,900.40925

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.39697
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.58735

Cumulative Model Updates: 125,888
Cumulative Timesteps: 1,049,754,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1049754804...
Checkpoint 1049754804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.74612
Value Function Loss: 0.01113

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.37337
Value Function Update Magnitude: 0.46595

Collected Steps per Second: 23,024.00361
Overall Steps per Second: 10,722.42327

Timestep Collection Time: 2.17199
Timestep Consumption Time: 2.49188
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.66387

Cumulative Model Updates: 125,894
Cumulative Timesteps: 1,049,804,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.73693
Value Function Loss: 0.01169

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.36009
Value Function Update Magnitude: 0.46148

Collected Steps per Second: 23,036.43721
Overall Steps per Second: 10,903.23117

Timestep Collection Time: 2.17221
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27477
Total Iteration Time: 4.58947

Cumulative Model Updates: 125,900
Cumulative Timesteps: 1,049,854,852

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1049854852...
Checkpoint 1049854852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738,384.33772
Policy Entropy: 3.71351
Value Function Loss: 0.01571

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.42147
Value Function Update Magnitude: 0.47254

Collected Steps per Second: 22,863.19441
Overall Steps per Second: 10,723.30292

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66517

Cumulative Model Updates: 125,906
Cumulative Timesteps: 1,049,904,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117,214.52889
Policy Entropy: 3.71358
Value Function Loss: 0.01726

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.55385

Collected Steps per Second: 22,768.64025
Overall Steps per Second: 10,778.27299

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.63989

Cumulative Model Updates: 125,912
Cumulative Timesteps: 1,049,954,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1049954888...
Checkpoint 1049954888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755,777.39592
Policy Entropy: 3.69658
Value Function Loss: 0.02137

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14855
Policy Update Magnitude: 0.59168
Value Function Update Magnitude: 0.58805

Collected Steps per Second: 22,815.67309
Overall Steps per Second: 10,680.99892

Timestep Collection Time: 2.19148
Timestep Consumption Time: 2.48973
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68121

Cumulative Model Updates: 125,918
Cumulative Timesteps: 1,050,004,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898,235.12419
Policy Entropy: 3.70785
Value Function Loss: 0.02256

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.63978
Value Function Update Magnitude: 0.56630

Collected Steps per Second: 23,139.72226
Overall Steps per Second: 10,835.21898

Timestep Collection Time: 2.16182
Timestep Consumption Time: 2.45497
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.61680

Cumulative Model Updates: 125,924
Cumulative Timesteps: 1,050,054,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1050054912...
Checkpoint 1050054912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,495.38999
Policy Entropy: 3.71000
Value Function Loss: 0.02703

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.68892
Value Function Update Magnitude: 0.56719

Collected Steps per Second: 22,091.36958
Overall Steps per Second: 10,679.38611

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.68641

Cumulative Model Updates: 125,930
Cumulative Timesteps: 1,050,104,960

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,654.93418
Policy Entropy: 3.72341
Value Function Loss: 0.02418

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.67898
Value Function Update Magnitude: 0.60906

Collected Steps per Second: 22,088.51453
Overall Steps per Second: 10,828.17202

Timestep Collection Time: 2.26453
Timestep Consumption Time: 2.35491
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.61943

Cumulative Model Updates: 125,936
Cumulative Timesteps: 1,050,154,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1050154980...
Checkpoint 1050154980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,035.82305
Policy Entropy: 3.72829
Value Function Loss: 0.02523

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.67511
Value Function Update Magnitude: 0.60379

Collected Steps per Second: 21,947.10070
Overall Steps per Second: 10,706.24428

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.39350
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.67316

Cumulative Model Updates: 125,942
Cumulative Timesteps: 1,050,205,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,732.24579
Policy Entropy: 3.71450
Value Function Loss: 0.02711

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.66800
Value Function Update Magnitude: 0.57638

Collected Steps per Second: 22,177.46835
Overall Steps per Second: 10,617.03761

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.45526
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71017

Cumulative Model Updates: 125,948
Cumulative Timesteps: 1,050,255,020

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1050255020...
Checkpoint 1050255020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,074.79078
Policy Entropy: 3.70320
Value Function Loss: 0.02855

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.67539
Value Function Update Magnitude: 0.59676

Collected Steps per Second: 23,098.81711
Overall Steps per Second: 10,920.26688

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.57992

Cumulative Model Updates: 125,954
Cumulative Timesteps: 1,050,305,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,074.79078
Policy Entropy: 3.70585
Value Function Loss: 0.02510

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.64474
Value Function Update Magnitude: 0.58652

Collected Steps per Second: 22,633.51710
Overall Steps per Second: 10,806.48432

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.41948
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.63018

Cumulative Model Updates: 125,960
Cumulative Timesteps: 1,050,355,070

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1050355070...
Checkpoint 1050355070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,074.79078
Policy Entropy: 3.72261
Value Function Loss: 0.02104

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.61968
Value Function Update Magnitude: 0.55145

Collected Steps per Second: 22,547.06992
Overall Steps per Second: 10,733.16976

Timestep Collection Time: 2.21900
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.66144

Cumulative Model Updates: 125,966
Cumulative Timesteps: 1,050,405,102

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,219.74614
Policy Entropy: 3.73692
Value Function Loss: 0.01837

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.60158

Collected Steps per Second: 22,817.76861
Overall Steps per Second: 10,828.15631

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.61925

Cumulative Model Updates: 125,972
Cumulative Timesteps: 1,050,455,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1050455120...
Checkpoint 1050455120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,922.79749
Policy Entropy: 3.74120
Value Function Loss: 0.01967

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.67397

Collected Steps per Second: 22,580.84537
Overall Steps per Second: 10,713.01650

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.45423
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.66965

Cumulative Model Updates: 125,978
Cumulative Timesteps: 1,050,505,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,163.06861
Policy Entropy: 3.75249
Value Function Loss: 0.02215

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15073
Policy Update Magnitude: 0.61327
Value Function Update Magnitude: 0.75836

Collected Steps per Second: 23,043.70141
Overall Steps per Second: 10,897.69911

Timestep Collection Time: 2.17092
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.59051

Cumulative Model Updates: 125,984
Cumulative Timesteps: 1,050,555,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1050555172...
Checkpoint 1050555172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,635.03175
Policy Entropy: 3.77423
Value Function Loss: 0.02240

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15749
Policy Update Magnitude: 0.68259
Value Function Update Magnitude: 0.75676

Collected Steps per Second: 22,776.53366
Overall Steps per Second: 10,646.20484

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.69933

Cumulative Model Updates: 125,990
Cumulative Timesteps: 1,050,605,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,349.85871
Policy Entropy: 3.76798
Value Function Loss: 0.02339

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.80747
Value Function Update Magnitude: 0.79288

Collected Steps per Second: 22,884.98889
Overall Steps per Second: 10,841.15468

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.42858
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.61464

Cumulative Model Updates: 125,996
Cumulative Timesteps: 1,050,655,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1050655230...
Checkpoint 1050655230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,226.03951
Policy Entropy: 3.75963
Value Function Loss: 0.02319

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.78534
Value Function Update Magnitude: 0.88296

Collected Steps per Second: 22,677.21175
Overall Steps per Second: 10,703.59481

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.67133

Cumulative Model Updates: 126,002
Cumulative Timesteps: 1,050,705,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,001.48082
Policy Entropy: 3.75198
Value Function Loss: 0.02594

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.84591
Value Function Update Magnitude: 0.89216

Collected Steps per Second: 21,984.33762
Overall Steps per Second: 10,840.60147

Timestep Collection Time: 2.27553
Timestep Consumption Time: 2.33916
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61469

Cumulative Model Updates: 126,008
Cumulative Timesteps: 1,050,755,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1050755256...
Checkpoint 1050755256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,853.42495
Policy Entropy: 3.77299
Value Function Loss: 0.02704

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.17577
Policy Update Magnitude: 0.78780
Value Function Update Magnitude: 0.73404

Collected Steps per Second: 22,184.67397
Overall Steps per Second: 10,707.81267

Timestep Collection Time: 2.25399
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.66986

Cumulative Model Updates: 126,014
Cumulative Timesteps: 1,050,805,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,853.42495
Policy Entropy: 3.78281
Value Function Loss: 0.02061

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.69729
Value Function Update Magnitude: 0.72004

Collected Steps per Second: 22,157.35977
Overall Steps per Second: 10,569.79408

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.73330

Cumulative Model Updates: 126,020
Cumulative Timesteps: 1,050,855,290

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1050855290...
Checkpoint 1050855290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,853.42495
Policy Entropy: 3.76886
Value Function Loss: 0.01862

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.61135
Value Function Update Magnitude: 0.53774

Collected Steps per Second: 22,752.21687
Overall Steps per Second: 10,897.94197

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.39168
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.59041

Cumulative Model Updates: 126,026
Cumulative Timesteps: 1,050,905,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,853.42495
Policy Entropy: 3.76291
Value Function Loss: 0.02156

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.59735
Value Function Update Magnitude: 0.38954

Collected Steps per Second: 22,537.49778
Overall Steps per Second: 10,670.73350

Timestep Collection Time: 2.21852
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68571

Cumulative Model Updates: 126,032
Cumulative Timesteps: 1,050,955,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1050955316...
Checkpoint 1050955316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669,329.84945
Policy Entropy: 3.76665
Value Function Loss: 0.02560

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.72187
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 22,637.07949
Overall Steps per Second: 10,694.57809

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.46788
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67788

Cumulative Model Updates: 126,038
Cumulative Timesteps: 1,051,005,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,507.59051
Policy Entropy: 3.78010
Value Function Loss: 0.02560

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.81876
Value Function Update Magnitude: 0.39590

Collected Steps per Second: 23,106.97536
Overall Steps per Second: 10,707.55993

Timestep Collection Time: 2.16471
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.67147

Cumulative Model Updates: 126,044
Cumulative Timesteps: 1,051,055,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1051055364...
Checkpoint 1051055364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,685.65130
Policy Entropy: 3.77633
Value Function Loss: 0.02752

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.74148
Value Function Update Magnitude: 0.51288

Collected Steps per Second: 22,286.83133
Overall Steps per Second: 10,634.36339

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.70418

Cumulative Model Updates: 126,050
Cumulative Timesteps: 1,051,105,390

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,813.30189
Policy Entropy: 3.75005
Value Function Loss: 0.02710

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.66918
Value Function Update Magnitude: 0.67159

Collected Steps per Second: 22,628.12450
Overall Steps per Second: 10,685.88676

Timestep Collection Time: 2.21026
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68038

Cumulative Model Updates: 126,056
Cumulative Timesteps: 1,051,155,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1051155404...
Checkpoint 1051155404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,105.43407
Policy Entropy: 3.75536
Value Function Loss: 0.02856

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.63149
Value Function Update Magnitude: 0.59695

Collected Steps per Second: 22,241.34672
Overall Steps per Second: 10,605.16812

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.46701
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.71544

Cumulative Model Updates: 126,062
Cumulative Timesteps: 1,051,205,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,105.43407
Policy Entropy: 3.74230
Value Function Loss: 0.02512

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.60849
Value Function Update Magnitude: 0.52579

Collected Steps per Second: 22,794.17778
Overall Steps per Second: 10,703.59275

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.67133

Cumulative Model Updates: 126,068
Cumulative Timesteps: 1,051,255,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1051255412...
Checkpoint 1051255412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,308.52961
Policy Entropy: 3.74668
Value Function Loss: 0.02548

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.59193
Value Function Update Magnitude: 0.48193

Collected Steps per Second: 22,470.93176
Overall Steps per Second: 10,649.40957

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.69641

Cumulative Model Updates: 126,074
Cumulative Timesteps: 1,051,305,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,564.58232
Policy Entropy: 3.73734
Value Function Loss: 0.02426

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.17270
Policy Update Magnitude: 0.62024
Value Function Update Magnitude: 0.50666

Collected Steps per Second: 21,910.49359
Overall Steps per Second: 10,820.57389

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.33966
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62249

Cumulative Model Updates: 126,080
Cumulative Timesteps: 1,051,355,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1051355444...
Checkpoint 1051355444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,108.59413
Policy Entropy: 3.77244
Value Function Loss: 0.02827

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16258
Policy Update Magnitude: 0.63886
Value Function Update Magnitude: 0.45283

Collected Steps per Second: 21,382.71529
Overall Steps per Second: 10,643.65715

Timestep Collection Time: 2.33899
Timestep Consumption Time: 2.35996
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69895

Cumulative Model Updates: 126,086
Cumulative Timesteps: 1,051,405,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,210.99991
Policy Entropy: 3.76367
Value Function Loss: 0.02517

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.15624
Policy Update Magnitude: 0.70947
Value Function Update Magnitude: 0.61852

Collected Steps per Second: 21,839.33830
Overall Steps per Second: 10,670.13557

Timestep Collection Time: 2.29091
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.68898

Cumulative Model Updates: 126,092
Cumulative Timesteps: 1,051,455,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1051455490...
Checkpoint 1051455490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,169.25120
Policy Entropy: 3.78472
Value Function Loss: 0.02811

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11859
Policy Update Magnitude: 0.79864
Value Function Update Magnitude: 0.61351

Collected Steps per Second: 21,485.70133
Overall Steps per Second: 10,492.33469

Timestep Collection Time: 2.32815
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.76748

Cumulative Model Updates: 126,098
Cumulative Timesteps: 1,051,505,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,633.23753
Policy Entropy: 3.79167
Value Function Loss: 0.02865

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.90385
Value Function Update Magnitude: 0.75966

Collected Steps per Second: 22,594.64609
Overall Steps per Second: 10,849.56168

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.39605
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.60940

Cumulative Model Updates: 126,104
Cumulative Timesteps: 1,051,555,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1051555522...
Checkpoint 1051555522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,135.03118
Policy Entropy: 3.78806
Value Function Loss: 0.03007

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.94500
Value Function Update Magnitude: 0.78570

Collected Steps per Second: 22,243.71429
Overall Steps per Second: 10,808.56123

Timestep Collection Time: 2.24899
Timestep Consumption Time: 2.37937
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.62837

Cumulative Model Updates: 126,110
Cumulative Timesteps: 1,051,605,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,016.87197
Policy Entropy: 3.78901
Value Function Loss: 0.02728

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08520
Policy Update Magnitude: 0.90589
Value Function Update Magnitude: 0.69671

Collected Steps per Second: 23,300.86308
Overall Steps per Second: 10,863.86180

Timestep Collection Time: 2.14722
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.60536

Cumulative Model Updates: 126,116
Cumulative Timesteps: 1,051,655,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1051655580...
Checkpoint 1051655580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,202.04739
Policy Entropy: 3.77786
Value Function Loss: 0.02492

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.81166
Value Function Update Magnitude: 0.67943

Collected Steps per Second: 22,745.98312
Overall Steps per Second: 10,591.79595

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.72252

Cumulative Model Updates: 126,122
Cumulative Timesteps: 1,051,705,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,196.39172
Policy Entropy: 3.76222
Value Function Loss: 0.02533

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.69311
Value Function Update Magnitude: 0.67426

Collected Steps per Second: 22,428.24515
Overall Steps per Second: 10,573.37621

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.50063
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.73094

Cumulative Model Updates: 126,128
Cumulative Timesteps: 1,051,755,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1051755622...
Checkpoint 1051755622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,557.04047
Policy Entropy: 3.72689
Value Function Loss: 0.02692

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.61536
Value Function Update Magnitude: 0.68131

Collected Steps per Second: 22,761.32823
Overall Steps per Second: 10,679.73819

Timestep Collection Time: 2.19882
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68626

Cumulative Model Updates: 126,134
Cumulative Timesteps: 1,051,805,670

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724,120.41818
Policy Entropy: 3.72344
Value Function Loss: 0.03248

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.61318
Value Function Update Magnitude: 0.70035

Collected Steps per Second: 22,904.34539
Overall Steps per Second: 10,841.67683

Timestep Collection Time: 2.18308
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.61202

Cumulative Model Updates: 126,140
Cumulative Timesteps: 1,051,855,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1051855672...
Checkpoint 1051855672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,604.83295
Policy Entropy: 3.77611
Value Function Loss: 0.03285

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.76173
Value Function Update Magnitude: 0.76302

Collected Steps per Second: 22,821.80090
Overall Steps per Second: 10,771.07843

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.64429

Cumulative Model Updates: 126,146
Cumulative Timesteps: 1,051,905,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,002.98472
Policy Entropy: 3.80071
Value Function Loss: 0.03470

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.90761
Value Function Update Magnitude: 0.79489

Collected Steps per Second: 23,219.35277
Overall Steps per Second: 10,720.75372

Timestep Collection Time: 2.15355
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.66422

Cumulative Model Updates: 126,152
Cumulative Timesteps: 1,051,955,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1051955700...
Checkpoint 1051955700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,493.56958
Policy Entropy: 3.82020
Value Function Loss: 0.03111

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.92230
Value Function Update Magnitude: 0.71155

Collected Steps per Second: 22,730.14143
Overall Steps per Second: 10,619.26509

Timestep Collection Time: 2.20007
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.70918

Cumulative Model Updates: 126,158
Cumulative Timesteps: 1,052,005,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,942.95496
Policy Entropy: 3.80112
Value Function Loss: 0.02712

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.89399
Value Function Update Magnitude: 0.78757

Collected Steps per Second: 23,109.84572
Overall Steps per Second: 10,858.38439

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.60474

Cumulative Model Updates: 126,164
Cumulative Timesteps: 1,052,055,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1052055708...
Checkpoint 1052055708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,262.46851
Policy Entropy: 3.79331
Value Function Loss: 0.02195

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.78002
Value Function Update Magnitude: 0.67699

Collected Steps per Second: 22,827.06065
Overall Steps per Second: 10,669.50550

Timestep Collection Time: 2.19178
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.68925

Cumulative Model Updates: 126,170
Cumulative Timesteps: 1,052,105,740

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,262.46851
Policy Entropy: 3.76279
Value Function Loss: 0.01964

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.69100
Value Function Update Magnitude: 0.63383

Collected Steps per Second: 23,207.42037
Overall Steps per Second: 10,928.47827

Timestep Collection Time: 2.15664
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.57978

Cumulative Model Updates: 126,176
Cumulative Timesteps: 1,052,155,790

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1052155790...
Checkpoint 1052155790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,648.11019
Policy Entropy: 3.77115
Value Function Loss: 0.01768

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07190
Policy Update Magnitude: 0.61631
Value Function Update Magnitude: 0.53536

Collected Steps per Second: 22,695.33366
Overall Steps per Second: 10,644.39187

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.49441
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.69769

Cumulative Model Updates: 126,182
Cumulative Timesteps: 1,052,205,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.74061
Policy Entropy: 3.78632
Value Function Loss: 0.01769

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07107
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.47559

Collected Steps per Second: 23,260.12710
Overall Steps per Second: 10,959.84499

Timestep Collection Time: 2.15081
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.56466

Cumulative Model Updates: 126,188
Cumulative Timesteps: 1,052,255,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1052255822...
Checkpoint 1052255822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.29354
Policy Entropy: 3.80268
Value Function Loss: 0.01655

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06961
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.55120

Collected Steps per Second: 22,951.82178
Overall Steps per Second: 10,717.72458

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.66704

Cumulative Model Updates: 126,194
Cumulative Timesteps: 1,052,305,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.86294
Policy Entropy: 3.77609
Value Function Loss: 0.01676

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.19856
Policy Update Magnitude: 0.41338
Value Function Update Magnitude: 0.62823

Collected Steps per Second: 23,221.12052
Overall Steps per Second: 10,785.52976

Timestep Collection Time: 2.15321
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.63584

Cumulative Model Updates: 126,200
Cumulative Timesteps: 1,052,355,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1052355842...
Checkpoint 1052355842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193.86294
Policy Entropy: 3.76223
Value Function Loss: 0.01544

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.17027
Policy Update Magnitude: 0.32506
Value Function Update Magnitude: 0.53910

Collected Steps per Second: 22,706.18440
Overall Steps per Second: 10,634.14804

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.70334

Cumulative Model Updates: 126,206
Cumulative Timesteps: 1,052,405,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,384.52410
Policy Entropy: 3.75804
Value Function Loss: 0.01704

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.17768
Policy Update Magnitude: 0.32448
Value Function Update Magnitude: 0.49549

Collected Steps per Second: 22,992.30728
Overall Steps per Second: 10,869.24214

Timestep Collection Time: 2.17577
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60253

Cumulative Model Updates: 126,212
Cumulative Timesteps: 1,052,455,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1052455884...
Checkpoint 1052455884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,356.55025
Policy Entropy: 3.78184
Value Function Loss: 0.01892

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.38541
Value Function Update Magnitude: 0.54037

Collected Steps per Second: 22,791.13044
Overall Steps per Second: 10,711.84086

Timestep Collection Time: 2.19401
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66811

Cumulative Model Updates: 126,218
Cumulative Timesteps: 1,052,505,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,645.47067
Policy Entropy: 3.78937
Value Function Loss: 0.02081

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.40100
Value Function Update Magnitude: 0.58232

Collected Steps per Second: 22,185.79062
Overall Steps per Second: 10,871.53367

Timestep Collection Time: 2.25397
Timestep Consumption Time: 2.34575
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59972

Cumulative Model Updates: 126,224
Cumulative Timesteps: 1,052,555,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1052555894...
Checkpoint 1052555894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,645.47067
Policy Entropy: 3.78543
Value Function Loss: 0.02357

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15153
Policy Update Magnitude: 0.38643
Value Function Update Magnitude: 0.49172

Collected Steps per Second: 22,072.61775
Overall Steps per Second: 10,667.26794

Timestep Collection Time: 2.26598
Timestep Consumption Time: 2.42276
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.68874

Cumulative Model Updates: 126,230
Cumulative Timesteps: 1,052,605,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,645.47067
Policy Entropy: 3.75436
Value Function Loss: 0.03719

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.35527
Value Function Update Magnitude: 0.34663

Collected Steps per Second: 22,253.83293
Overall Steps per Second: 10,608.97232

Timestep Collection Time: 2.24797
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.71544

Cumulative Model Updates: 126,236
Cumulative Timesteps: 1,052,655,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1052655936...
Checkpoint 1052655936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,645.47067
Policy Entropy: 3.74599
Value Function Loss: 0.02591

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.35431
Value Function Update Magnitude: 0.28939

Collected Steps per Second: 23,146.03469
Overall Steps per Second: 10,998.79857

Timestep Collection Time: 2.16097
Timestep Consumption Time: 2.38661
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.54759

Cumulative Model Updates: 126,242
Cumulative Timesteps: 1,052,705,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,951.99890
Policy Entropy: 3.72228
Value Function Loss: 0.02647

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.16072
Policy Update Magnitude: 0.35219
Value Function Update Magnitude: 0.39372

Collected Steps per Second: 23,218.52639
Overall Steps per Second: 10,881.88765

Timestep Collection Time: 2.15397
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.59589

Cumulative Model Updates: 126,248
Cumulative Timesteps: 1,052,755,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1052755966...
Checkpoint 1052755966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,642.49637
Policy Entropy: 3.73384
Value Function Loss: 0.02496

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14478
Policy Update Magnitude: 0.40112
Value Function Update Magnitude: 0.42011

Collected Steps per Second: 22,715.24988
Overall Steps per Second: 10,633.12142

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70379

Cumulative Model Updates: 126,254
Cumulative Timesteps: 1,052,805,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,604.01401
Policy Entropy: 3.73651
Value Function Loss: 0.02879

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.44688
Value Function Update Magnitude: 0.50919

Collected Steps per Second: 22,911.51899
Overall Steps per Second: 10,836.63351

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61601

Cumulative Model Updates: 126,260
Cumulative Timesteps: 1,052,856,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1052856004...
Checkpoint 1052856004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,090.91447
Policy Entropy: 3.78662
Value Function Loss: 0.02635

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.69531

Collected Steps per Second: 22,847.70683
Overall Steps per Second: 10,695.27474

Timestep Collection Time: 2.18954
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.67739

Cumulative Model Updates: 126,266
Cumulative Timesteps: 1,052,906,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,480.05174
Policy Entropy: 3.79635
Value Function Loss: 0.02928

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.51290
Value Function Update Magnitude: 0.59914

Collected Steps per Second: 23,090.37996
Overall Steps per Second: 10,897.31047

Timestep Collection Time: 2.16566
Timestep Consumption Time: 2.42317
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58884

Cumulative Model Updates: 126,272
Cumulative Timesteps: 1,052,956,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1052956036...
Checkpoint 1052956036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,430.58282
Policy Entropy: 3.82064
Value Function Loss: 0.02592

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.74371

Collected Steps per Second: 22,376.78127
Overall Steps per Second: 10,667.01660

Timestep Collection Time: 2.23482
Timestep Consumption Time: 2.45328
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.68810

Cumulative Model Updates: 126,278
Cumulative Timesteps: 1,053,006,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,222.70146
Policy Entropy: 3.78016
Value Function Loss: 0.02693

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.51822
Value Function Update Magnitude: 0.79549

Collected Steps per Second: 22,954.82347
Overall Steps per Second: 10,847.78852

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61163

Cumulative Model Updates: 126,284
Cumulative Timesteps: 1,053,056,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1053056070...
Checkpoint 1053056070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.87525
Policy Entropy: 3.77783
Value Function Loss: 0.02440

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.47668
Value Function Update Magnitude: 0.62187

Collected Steps per Second: 22,637.71772
Overall Steps per Second: 10,672.22333

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.47735
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.68693

Cumulative Model Updates: 126,290
Cumulative Timesteps: 1,053,106,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352.39723
Policy Entropy: 3.74850
Value Function Loss: 0.02489

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.41147
Value Function Update Magnitude: 0.47947

Collected Steps per Second: 22,919.18222
Overall Steps per Second: 10,868.53732

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60099

Cumulative Model Updates: 126,296
Cumulative Timesteps: 1,053,156,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1053156096...
Checkpoint 1053156096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225.48897
Policy Entropy: 3.75192
Value Function Loss: 0.02041

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.38723
Value Function Update Magnitude: 0.49066

Collected Steps per Second: 22,453.01576
Overall Steps per Second: 10,682.24227

Timestep Collection Time: 2.22776
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.68254

Cumulative Model Updates: 126,302
Cumulative Timesteps: 1,053,206,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.48897
Policy Entropy: 3.74945
Value Function Loss: 0.02052

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.40002
Value Function Update Magnitude: 0.47427

Collected Steps per Second: 22,981.50554
Overall Steps per Second: 10,845.06756

Timestep Collection Time: 2.17662
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.61242

Cumulative Model Updates: 126,308
Cumulative Timesteps: 1,053,256,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1053256138...
Checkpoint 1053256138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,429.44309
Policy Entropy: 3.74203
Value Function Loss: 0.02068

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.42583
Value Function Update Magnitude: 0.44661

Collected Steps per Second: 22,472.45121
Overall Steps per Second: 10,772.13285

Timestep Collection Time: 2.22601
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.64383

Cumulative Model Updates: 126,314
Cumulative Timesteps: 1,053,306,162

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,779.82947
Policy Entropy: 3.75939
Value Function Loss: 0.01982

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.45383
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 22,899.18479
Overall Steps per Second: 10,865.64051

Timestep Collection Time: 2.18383
Timestep Consumption Time: 2.41856
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.60240

Cumulative Model Updates: 126,320
Cumulative Timesteps: 1,053,356,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1053356170...
Checkpoint 1053356170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.23289
Policy Entropy: 3.73981
Value Function Loss: 0.01998

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.64858

Collected Steps per Second: 22,606.47964
Overall Steps per Second: 10,613.90612

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.71174

Cumulative Model Updates: 126,326
Cumulative Timesteps: 1,053,406,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 639.23289
Policy Entropy: 3.74018
Value Function Loss: 0.01967

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.45971
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 22,927.36379
Overall Steps per Second: 10,828.87870

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.43794
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.62005

Cumulative Model Updates: 126,332
Cumulative Timesteps: 1,053,456,210

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1053456210...
Checkpoint 1053456210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318,816.73206
Policy Entropy: 3.71940
Value Function Loss: 0.01997

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.48793
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,734.77100
Overall Steps per Second: 10,669.92398

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.68869

Cumulative Model Updates: 126,338
Cumulative Timesteps: 1,053,506,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,050.40892
Policy Entropy: 3.72373
Value Function Loss: 0.01958

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.48306
Value Function Update Magnitude: 0.57327

Collected Steps per Second: 23,237.29977
Overall Steps per Second: 10,922.47511

Timestep Collection Time: 2.15171
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57772

Cumulative Model Updates: 126,344
Cumulative Timesteps: 1,053,556,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1053556238...
Checkpoint 1053556238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,939.78106
Policy Entropy: 3.72923
Value Function Loss: 0.01892

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.46652
Value Function Update Magnitude: 0.54588

Collected Steps per Second: 22,070.19662
Overall Steps per Second: 10,668.42394

Timestep Collection Time: 2.26722
Timestep Consumption Time: 2.42307
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69029

Cumulative Model Updates: 126,350
Cumulative Timesteps: 1,053,606,276

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,939.78106
Policy Entropy: 3.71006
Value Function Loss: 0.01982

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15768
Policy Update Magnitude: 0.42766
Value Function Update Magnitude: 0.48780

Collected Steps per Second: 22,417.44847
Overall Steps per Second: 10,881.27560

Timestep Collection Time: 2.23049
Timestep Consumption Time: 2.36474
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.59523

Cumulative Model Updates: 126,356
Cumulative Timesteps: 1,053,656,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1053656278...
Checkpoint 1053656278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,939.78106
Policy Entropy: 3.70547
Value Function Loss: 0.01870

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.16004
Policy Update Magnitude: 0.41352
Value Function Update Magnitude: 0.43089

Collected Steps per Second: 22,228.49431
Overall Steps per Second: 10,627.63485

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.70716

Cumulative Model Updates: 126,362
Cumulative Timesteps: 1,053,706,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,939.78106
Policy Entropy: 3.69707
Value Function Loss: 0.02088

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.39737
Value Function Update Magnitude: 0.35437

Collected Steps per Second: 23,215.46811
Overall Steps per Second: 10,971.84026

Timestep Collection Time: 2.15468
Timestep Consumption Time: 2.40444
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.55913

Cumulative Model Updates: 126,368
Cumulative Timesteps: 1,053,756,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1053756326...
Checkpoint 1053756326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404,302.02080
Policy Entropy: 3.72592
Value Function Loss: 0.02108

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.37801
Value Function Update Magnitude: 0.34752

Collected Steps per Second: 22,768.55339
Overall Steps per Second: 10,710.73808

Timestep Collection Time: 2.19671
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.66971

Cumulative Model Updates: 126,374
Cumulative Timesteps: 1,053,806,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,732.15976
Policy Entropy: 3.73418
Value Function Loss: 0.02270

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.40545
Value Function Update Magnitude: 0.41809

Collected Steps per Second: 22,987.97312
Overall Steps per Second: 10,890.92046

Timestep Collection Time: 2.17531
Timestep Consumption Time: 2.41622
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.59153

Cumulative Model Updates: 126,380
Cumulative Timesteps: 1,053,856,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1053856348...
Checkpoint 1053856348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,636.30399
Policy Entropy: 3.75226
Value Function Loss: 0.02106

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.41667
Value Function Update Magnitude: 0.47150

Collected Steps per Second: 22,934.73353
Overall Steps per Second: 10,695.75886

Timestep Collection Time: 2.18115
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67699

Cumulative Model Updates: 126,386
Cumulative Timesteps: 1,053,906,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595,064.51514
Policy Entropy: 3.75638
Value Function Loss: 0.01917

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.41703
Value Function Update Magnitude: 0.51465

Collected Steps per Second: 22,854.00061
Overall Steps per Second: 10,867.64211

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.41330
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.60137

Cumulative Model Updates: 126,392
Cumulative Timesteps: 1,053,956,378

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1053956378...
Checkpoint 1053956378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481,997.62835
Policy Entropy: 3.74314
Value Function Loss: 0.01850

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.38785
Value Function Update Magnitude: 0.50075

Collected Steps per Second: 22,770.67835
Overall Steps per Second: 10,678.34745

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.68443

Cumulative Model Updates: 126,398
Cumulative Timesteps: 1,054,006,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 490,072.57330
Policy Entropy: 3.74092
Value Function Loss: 0.01662

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.36638
Value Function Update Magnitude: 0.45810

Collected Steps per Second: 22,960.10440
Overall Steps per Second: 10,812.88373

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.44711
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.62541

Cumulative Model Updates: 126,404
Cumulative Timesteps: 1,054,056,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1054056414...
Checkpoint 1054056414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260,450.40249
Policy Entropy: 3.74175
Value Function Loss: 0.01530

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.36087
Value Function Update Magnitude: 0.51308

Collected Steps per Second: 22,976.04847
Overall Steps per Second: 10,741.61690

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.65498

Cumulative Model Updates: 126,410
Cumulative Timesteps: 1,054,106,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,450.40249
Policy Entropy: 3.72051
Value Function Loss: 0.01816

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.37990
Value Function Update Magnitude: 0.53958

Collected Steps per Second: 22,389.44529
Overall Steps per Second: 10,811.63287

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.39241
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.62650

Cumulative Model Updates: 126,416
Cumulative Timesteps: 1,054,156,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1054156436...
Checkpoint 1054156436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,650.92090
Policy Entropy: 3.74098
Value Function Loss: 0.01954

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.41374
Value Function Update Magnitude: 0.54467

Collected Steps per Second: 22,121.49290
Overall Steps per Second: 10,690.23286

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.41905
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.68128

Cumulative Model Updates: 126,422
Cumulative Timesteps: 1,054,206,480

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,890.27015
Policy Entropy: 3.73626
Value Function Loss: 0.02203

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.42510
Value Function Update Magnitude: 0.46740

Collected Steps per Second: 22,544.60104
Overall Steps per Second: 10,852.17027

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.39031
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.60885

Cumulative Model Updates: 126,428
Cumulative Timesteps: 1,054,256,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1054256496...
Checkpoint 1054256496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.76058
Value Function Loss: 0.01952

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.42733
Value Function Update Magnitude: 0.44078

Collected Steps per Second: 22,288.52738
Overall Steps per Second: 10,604.45365

Timestep Collection Time: 2.24393
Timestep Consumption Time: 2.47239
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.71632

Cumulative Model Updates: 126,434
Cumulative Timesteps: 1,054,306,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.74076
Value Function Loss: 0.02016

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.44250
Value Function Update Magnitude: 0.43626

Collected Steps per Second: 23,186.46379
Overall Steps per Second: 10,990.92958

Timestep Collection Time: 2.15764
Timestep Consumption Time: 2.39412
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.55175

Cumulative Model Updates: 126,440
Cumulative Timesteps: 1,054,356,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1054356538...
Checkpoint 1054356538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.73360
Value Function Loss: 0.01843

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.41692
Value Function Update Magnitude: 0.42641

Collected Steps per Second: 22,810.93451
Overall Steps per Second: 10,768.27870

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.45281
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.64605

Cumulative Model Updates: 126,446
Cumulative Timesteps: 1,054,406,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.71726
Value Function Loss: 0.01788

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.38560
Value Function Update Magnitude: 0.37132

Collected Steps per Second: 23,223.85577
Overall Steps per Second: 10,722.57365

Timestep Collection Time: 2.15296
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66306

Cumulative Model Updates: 126,452
Cumulative Timesteps: 1,054,456,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1054456568...
Checkpoint 1054456568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.73533
Value Function Loss: 0.01515

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.35486
Value Function Update Magnitude: 0.32209

Collected Steps per Second: 22,970.33714
Overall Steps per Second: 10,718.58322

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.66741

Cumulative Model Updates: 126,458
Cumulative Timesteps: 1,054,506,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.72474
Value Function Loss: 0.01658

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.35028
Value Function Update Magnitude: 0.31589

Collected Steps per Second: 22,934.92382
Overall Steps per Second: 10,863.38124

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60464

Cumulative Model Updates: 126,464
Cumulative Timesteps: 1,054,556,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1054556618...
Checkpoint 1054556618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,348.28422
Policy Entropy: 3.73505
Value Function Loss: 0.01457

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.37434
Value Function Update Magnitude: 0.34650

Collected Steps per Second: 23,031.70369
Overall Steps per Second: 10,759.89777

Timestep Collection Time: 2.17092
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.64688

Cumulative Model Updates: 126,470
Cumulative Timesteps: 1,054,606,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,333.73615
Policy Entropy: 3.71466
Value Function Loss: 0.01796

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.39974
Value Function Update Magnitude: 0.44078

Collected Steps per Second: 22,906.54387
Overall Steps per Second: 10,778.89845

Timestep Collection Time: 2.18383
Timestep Consumption Time: 2.45709
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.64092

Cumulative Model Updates: 126,476
Cumulative Timesteps: 1,054,656,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1054656642...
Checkpoint 1054656642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,609.39857
Policy Entropy: 3.74463
Value Function Loss: 0.01727

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.43721
Value Function Update Magnitude: 0.59120

Collected Steps per Second: 22,776.63000
Overall Steps per Second: 10,655.94693

Timestep Collection Time: 2.19646
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.69484

Cumulative Model Updates: 126,482
Cumulative Timesteps: 1,054,706,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,005.26448
Policy Entropy: 3.73644
Value Function Loss: 0.02090

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.47051
Value Function Update Magnitude: 0.74540

Collected Steps per Second: 22,758.79793
Overall Steps per Second: 10,798.88771

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.63085

Cumulative Model Updates: 126,488
Cumulative Timesteps: 1,054,756,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1054756678...
Checkpoint 1054756678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,592.90739
Policy Entropy: 3.74234
Value Function Loss: 0.02030

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.51788
Value Function Update Magnitude: 0.86480

Collected Steps per Second: 22,533.04277
Overall Steps per Second: 10,730.93445

Timestep Collection Time: 2.21923
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.65999

Cumulative Model Updates: 126,494
Cumulative Timesteps: 1,054,806,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,212.96583
Policy Entropy: 3.73866
Value Function Loss: 0.02090

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.53566
Value Function Update Magnitude: 0.86892

Collected Steps per Second: 22,918.54212
Overall Steps per Second: 10,839.50649

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61405

Cumulative Model Updates: 126,500
Cumulative Timesteps: 1,054,856,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1054856698...
Checkpoint 1054856698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,707.06831
Policy Entropy: 3.76687
Value Function Loss: 0.02034

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.53919
Value Function Update Magnitude: 0.72327

Collected Steps per Second: 23,123.59968
Overall Steps per Second: 10,762.55988

Timestep Collection Time: 2.16437
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.65019

Cumulative Model Updates: 126,506
Cumulative Timesteps: 1,054,906,746

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,669.76041
Policy Entropy: 3.77208
Value Function Loss: 0.02168

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.50425
Value Function Update Magnitude: 0.55736

Collected Steps per Second: 22,318.92617
Overall Steps per Second: 10,814.21932

Timestep Collection Time: 2.24249
Timestep Consumption Time: 2.38567
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.62817

Cumulative Model Updates: 126,512
Cumulative Timesteps: 1,054,956,796

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1054956796...
Checkpoint 1054956796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,265.39346
Policy Entropy: 3.76868
Value Function Loss: 0.01931

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.46361
Value Function Update Magnitude: 0.50927

Collected Steps per Second: 22,292.14975
Overall Steps per Second: 10,735.54914

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.41477
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.65798

Cumulative Model Updates: 126,518
Cumulative Timesteps: 1,055,006,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,504.71026
Policy Entropy: 3.75565
Value Function Loss: 0.02434

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.49350
Value Function Update Magnitude: 0.50466

Collected Steps per Second: 22,037.26221
Overall Steps per Second: 10,817.77641

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.35436
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.62443

Cumulative Model Updates: 126,524
Cumulative Timesteps: 1,055,056,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1055056828...
Checkpoint 1055056828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,560.19003
Policy Entropy: 3.75638
Value Function Loss: 0.02325

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.52046
Value Function Update Magnitude: 0.56434

Collected Steps per Second: 22,310.67350
Overall Steps per Second: 10,673.24792

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.44373
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.68498

Cumulative Model Updates: 126,530
Cumulative Timesteps: 1,055,106,832

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,711.84589
Policy Entropy: 3.74810
Value Function Loss: 0.02643

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.50963
Value Function Update Magnitude: 0.60052

Collected Steps per Second: 23,146.96141
Overall Steps per Second: 10,905.10996

Timestep Collection Time: 2.16123
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.58739

Cumulative Model Updates: 126,536
Cumulative Timesteps: 1,055,156,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1055156858...
Checkpoint 1055156858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,837.04517
Policy Entropy: 3.74912
Value Function Loss: 0.02173

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.49436
Value Function Update Magnitude: 0.71116

Collected Steps per Second: 22,827.11162
Overall Steps per Second: 10,770.09657

Timestep Collection Time: 2.19117
Timestep Consumption Time: 2.45299
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.64416

Cumulative Model Updates: 126,542
Cumulative Timesteps: 1,055,206,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,113.42006
Policy Entropy: 3.72689
Value Function Loss: 0.02196

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.50408
Value Function Update Magnitude: 0.76093

Collected Steps per Second: 22,795.95353
Overall Steps per Second: 10,768.32343

Timestep Collection Time: 2.19557
Timestep Consumption Time: 2.45233
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64789

Cumulative Model Updates: 126,548
Cumulative Timesteps: 1,055,256,926

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1055256926...
Checkpoint 1055256926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,113.09977
Policy Entropy: 3.73581
Value Function Loss: 0.01975

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.51389
Value Function Update Magnitude: 0.79164

Collected Steps per Second: 22,750.77249
Overall Steps per Second: 10,651.17246

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.49799
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.69695

Cumulative Model Updates: 126,554
Cumulative Timesteps: 1,055,306,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,134.48788
Policy Entropy: 3.72488
Value Function Loss: 0.02608

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.52516
Value Function Update Magnitude: 0.81202

Collected Steps per Second: 22,336.39275
Overall Steps per Second: 10,588.99283

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.72415

Cumulative Model Updates: 126,560
Cumulative Timesteps: 1,055,356,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1055356978...
Checkpoint 1055356978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,886.58620
Policy Entropy: 3.74089
Value Function Loss: 0.02596

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.59400
Value Function Update Magnitude: 0.77440

Collected Steps per Second: 23,121.82864
Overall Steps per Second: 10,913.89362

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.58370

Cumulative Model Updates: 126,566
Cumulative Timesteps: 1,055,407,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,343.87815
Policy Entropy: 3.74555
Value Function Loss: 0.02795

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.63114
Value Function Update Magnitude: 0.73792

Collected Steps per Second: 22,538.36588
Overall Steps per Second: 10,603.06344

Timestep Collection Time: 2.21879
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71637

Cumulative Model Updates: 126,572
Cumulative Timesteps: 1,055,457,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1055457012...
Checkpoint 1055457012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,376.02715
Policy Entropy: 3.75193
Value Function Loss: 0.02413

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.61446
Value Function Update Magnitude: 0.82390

Collected Steps per Second: 22,903.18972
Overall Steps per Second: 10,729.95050

Timestep Collection Time: 2.18371
Timestep Consumption Time: 2.47745
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.66116

Cumulative Model Updates: 126,578
Cumulative Timesteps: 1,055,507,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,643.32862
Policy Entropy: 3.76802
Value Function Loss: 0.02370

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.58575
Value Function Update Magnitude: 0.85536

Collected Steps per Second: 22,659.19363
Overall Steps per Second: 10,686.78808

Timestep Collection Time: 2.20749
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68055

Cumulative Model Updates: 126,584
Cumulative Timesteps: 1,055,557,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1055557046...
Checkpoint 1055557046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,081.51005
Policy Entropy: 3.77152
Value Function Loss: 0.02378

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.84419

Collected Steps per Second: 22,754.35006
Overall Steps per Second: 10,632.15443

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.70403

Cumulative Model Updates: 126,590
Cumulative Timesteps: 1,055,607,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.14069
Policy Entropy: 3.79487
Value Function Loss: 0.02234

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.87864

Collected Steps per Second: 22,918.12415
Overall Steps per Second: 10,848.85172

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.61063

Cumulative Model Updates: 126,596
Cumulative Timesteps: 1,055,657,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1055657080...
Checkpoint 1055657080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,982.94660
Policy Entropy: 3.78265
Value Function Loss: 0.02312

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.89619

Collected Steps per Second: 22,903.26159
Overall Steps per Second: 10,723.88497

Timestep Collection Time: 2.18353
Timestep Consumption Time: 2.47989
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.66342

Cumulative Model Updates: 126,602
Cumulative Timesteps: 1,055,707,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.89755
Policy Entropy: 3.79024
Value Function Loss: 0.02222

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.56191
Value Function Update Magnitude: 0.86108

Collected Steps per Second: 23,073.25137
Overall Steps per Second: 10,865.34976

Timestep Collection Time: 2.16814
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.60418

Cumulative Model Updates: 126,608
Cumulative Timesteps: 1,055,757,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1055757116...
Checkpoint 1055757116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.70169
Policy Entropy: 3.77279
Value Function Loss: 0.02419

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.75312

Collected Steps per Second: 22,999.11029
Overall Steps per Second: 10,721.89881

Timestep Collection Time: 2.17452
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66447

Cumulative Model Updates: 126,614
Cumulative Timesteps: 1,055,807,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.11190
Policy Entropy: 3.76619
Value Function Loss: 0.02352

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.52944
Value Function Update Magnitude: 0.60716

Collected Steps per Second: 22,721.81123
Overall Steps per Second: 10,794.57740

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63196

Cumulative Model Updates: 126,620
Cumulative Timesteps: 1,055,857,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1055857128...
Checkpoint 1055857128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.77362
Policy Entropy: 3.75207
Value Function Loss: 0.01971

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.48281
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 22,968.85570
Overall Steps per Second: 10,674.77179

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.50798
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.68563

Cumulative Model Updates: 126,626
Cumulative Timesteps: 1,055,907,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,815.10146
Policy Entropy: 3.75798
Value Function Loss: 0.01904

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.43490
Value Function Update Magnitude: 0.54198

Collected Steps per Second: 22,798.72314
Overall Steps per Second: 10,840.46868

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.61253

Cumulative Model Updates: 126,632
Cumulative Timesteps: 1,055,957,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1055957148...
Checkpoint 1055957148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,624.65250
Policy Entropy: 3.74082
Value Function Loss: 0.02072

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.41522
Value Function Update Magnitude: 0.62114

Collected Steps per Second: 22,706.77795
Overall Steps per Second: 10,731.99879

Timestep Collection Time: 2.20278
Timestep Consumption Time: 2.45786
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.66064

Cumulative Model Updates: 126,638
Cumulative Timesteps: 1,056,007,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.55787
Policy Entropy: 3.73062
Value Function Loss: 0.02431

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.43884
Value Function Update Magnitude: 0.53241

Collected Steps per Second: 22,930.23283
Overall Steps per Second: 10,844.00206

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.61121

Cumulative Model Updates: 126,644
Cumulative Timesteps: 1,056,057,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1056057170...
Checkpoint 1056057170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.00031
Policy Entropy: 3.74059
Value Function Loss: 0.02395

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.46603
Value Function Update Magnitude: 0.47681

Collected Steps per Second: 23,040.43997
Overall Steps per Second: 10,705.82036

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.67279

Cumulative Model Updates: 126,650
Cumulative Timesteps: 1,056,107,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189.54347
Policy Entropy: 3.74457
Value Function Loss: 0.02423

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.50083
Value Function Update Magnitude: 0.51655

Collected Steps per Second: 23,095.46025
Overall Steps per Second: 10,866.89492

Timestep Collection Time: 2.16579
Timestep Consumption Time: 2.43718
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.60297

Cumulative Model Updates: 126,656
Cumulative Timesteps: 1,056,157,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1056157216...
Checkpoint 1056157216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.26431
Policy Entropy: 3.76156
Value Function Loss: 0.02150

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.57597

Collected Steps per Second: 22,912.62848
Overall Steps per Second: 10,677.25010

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.68304

Cumulative Model Updates: 126,662
Cumulative Timesteps: 1,056,207,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.45703
Policy Entropy: 3.74296
Value Function Loss: 0.02116

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.52172
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 22,749.80904
Overall Steps per Second: 10,807.55048

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.62862

Cumulative Model Updates: 126,668
Cumulative Timesteps: 1,056,257,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1056257242...
Checkpoint 1056257242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.71413
Policy Entropy: 3.74845
Value Function Loss: 0.01884

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15766
Policy Update Magnitude: 0.48452
Value Function Update Magnitude: 0.56698

Collected Steps per Second: 22,815.42843
Overall Steps per Second: 10,732.20184

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.65981

Cumulative Model Updates: 126,674
Cumulative Timesteps: 1,056,307,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.71413
Policy Entropy: 3.71477
Value Function Loss: 0.01952

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15508
Policy Update Magnitude: 0.45673
Value Function Update Magnitude: 0.57699

Collected Steps per Second: 22,930.13557
Overall Steps per Second: 10,841.00494

Timestep Collection Time: 2.18254
Timestep Consumption Time: 2.43382
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.61636

Cumulative Model Updates: 126,680
Cumulative Timesteps: 1,056,357,298

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1056357298...
Checkpoint 1056357298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,634.26157
Policy Entropy: 3.70866
Value Function Loss: 0.02252

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,729.15738
Overall Steps per Second: 10,720.24271

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.66613

Cumulative Model Updates: 126,686
Cumulative Timesteps: 1,056,407,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,634.26157
Policy Entropy: 3.73638
Value Function Loss: 0.02050

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.52660
Value Function Update Magnitude: 0.65321

Collected Steps per Second: 22,680.97856
Overall Steps per Second: 10,824.30976

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.41532
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.62034

Cumulative Model Updates: 126,692
Cumulative Timesteps: 1,056,457,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1056457332...
Checkpoint 1056457332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,634.26157
Policy Entropy: 3.73336
Value Function Loss: 0.01935

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.50407
Value Function Update Magnitude: 0.71044

Collected Steps per Second: 22,726.19345
Overall Steps per Second: 10,688.40853

Timestep Collection Time: 2.20054
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.67890

Cumulative Model Updates: 126,698
Cumulative Timesteps: 1,056,507,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,958.91777
Policy Entropy: 3.72543
Value Function Loss: 0.01834

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.44850
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 22,852.38899
Overall Steps per Second: 10,855.99720

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.60722

Cumulative Model Updates: 126,704
Cumulative Timesteps: 1,056,557,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1056557358...
Checkpoint 1056557358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,227.04254
Policy Entropy: 3.70246
Value Function Loss: 0.02108

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14183
Policy Update Magnitude: 0.45376
Value Function Update Magnitude: 0.66876

Collected Steps per Second: 22,845.74231
Overall Steps per Second: 10,709.37211

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.66918

Cumulative Model Updates: 126,710
Cumulative Timesteps: 1,056,607,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,462.43423
Policy Entropy: 3.71094
Value Function Loss: 0.02190

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.65912

Collected Steps per Second: 23,001.54107
Overall Steps per Second: 10,857.17171

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.60672

Cumulative Model Updates: 126,716
Cumulative Timesteps: 1,056,657,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1056657378...
Checkpoint 1056657378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,233.05881
Policy Entropy: 3.71642
Value Function Loss: 0.02714

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.58349

Collected Steps per Second: 22,106.95723
Overall Steps per Second: 10,712.08332

Timestep Collection Time: 2.26300
Timestep Consumption Time: 2.40724
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.67024

Cumulative Model Updates: 126,722
Cumulative Timesteps: 1,056,707,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,244.46951
Policy Entropy: 3.73732
Value Function Loss: 0.02346

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.52401
Value Function Update Magnitude: 0.42078

Collected Steps per Second: 22,158.25891
Overall Steps per Second: 10,857.85855

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.34865
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.60533

Cumulative Model Updates: 126,728
Cumulative Timesteps: 1,056,757,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1056757410...
Checkpoint 1056757410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,499.66581
Policy Entropy: 3.76530
Value Function Loss: 0.02167

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.49203
Value Function Update Magnitude: 0.45706

Collected Steps per Second: 22,137.94678
Overall Steps per Second: 10,661.99960

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.43128
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.69011

Cumulative Model Updates: 126,734
Cumulative Timesteps: 1,056,807,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,203.12328
Policy Entropy: 3.78577
Value Function Loss: 0.02078

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.58156

Collected Steps per Second: 21,991.06811
Overall Steps per Second: 10,500.20005

Timestep Collection Time: 2.27511
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.76486

Cumulative Model Updates: 126,740
Cumulative Timesteps: 1,056,857,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1056857448...
Checkpoint 1056857448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,801.43956
Policy Entropy: 3.77721
Value Function Loss: 0.02051

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.56420

Collected Steps per Second: 22,612.78318
Overall Steps per Second: 10,677.77337

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.68262

Cumulative Model Updates: 126,746
Cumulative Timesteps: 1,056,907,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,510.76437
Policy Entropy: 3.76110
Value Function Loss: 0.02167

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.50851
Value Function Update Magnitude: 0.58118

Collected Steps per Second: 22,707.06873
Overall Steps per Second: 10,905.30995

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.38335
PPO Batch Consumption Time: 0.27511
Total Iteration Time: 4.58566

Cumulative Model Updates: 126,752
Cumulative Timesteps: 1,056,957,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1056957456...
Checkpoint 1056957456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,332.31204
Policy Entropy: 3.76982
Value Function Loss: 0.02208

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.53373
Value Function Update Magnitude: 0.68170

Collected Steps per Second: 23,072.54814
Overall Steps per Second: 10,964.10142

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.39441
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.56253

Cumulative Model Updates: 126,758
Cumulative Timesteps: 1,057,007,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.11280
Policy Entropy: 3.78624
Value Function Loss: 0.02252

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.72232

Collected Steps per Second: 22,640.98377
Overall Steps per Second: 10,644.36607

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69995

Cumulative Model Updates: 126,764
Cumulative Timesteps: 1,057,057,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1057057508...
Checkpoint 1057057508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,790.79949
Policy Entropy: 3.77755
Value Function Loss: 0.02376

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.68680

Collected Steps per Second: 22,910.58855
Overall Steps per Second: 10,845.13547

Timestep Collection Time: 2.18266
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.61092

Cumulative Model Updates: 126,770
Cumulative Timesteps: 1,057,107,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,361.28296
Policy Entropy: 3.75618
Value Function Loss: 0.02517

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 22,516.50232
Overall Steps per Second: 10,582.99697

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.72569

Cumulative Model Updates: 126,776
Cumulative Timesteps: 1,057,157,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1057157526...
Checkpoint 1057157526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,147.31482
Policy Entropy: 3.73145
Value Function Loss: 0.02516

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.56883

Collected Steps per Second: 22,702.00293
Overall Steps per Second: 10,654.07363

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.69661

Cumulative Model Updates: 126,782
Cumulative Timesteps: 1,057,207,564

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347,634.72427
Policy Entropy: 3.72416
Value Function Loss: 0.02871

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.60536
Value Function Update Magnitude: 0.55818

Collected Steps per Second: 22,266.48492
Overall Steps per Second: 10,612.61511

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.46673
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.71307

Cumulative Model Updates: 126,788
Cumulative Timesteps: 1,057,257,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1057257582...
Checkpoint 1057257582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,984.92073
Policy Entropy: 3.72317
Value Function Loss: 0.02735

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.63385
Value Function Update Magnitude: 0.54419

Collected Steps per Second: 23,083.59201
Overall Steps per Second: 10,951.46927

Timestep Collection Time: 2.16665
Timestep Consumption Time: 2.40023
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.56688

Cumulative Model Updates: 126,794
Cumulative Timesteps: 1,057,307,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,571.00978
Policy Entropy: 3.70663
Value Function Loss: 0.03243

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.66019
Value Function Update Magnitude: 0.54479

Collected Steps per Second: 22,079.09556
Overall Steps per Second: 10,834.62101

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.35147
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.61724

Cumulative Model Updates: 126,800
Cumulative Timesteps: 1,057,357,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1057357622...
Checkpoint 1057357622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,776.85410
Policy Entropy: 3.74486
Value Function Loss: 0.02955

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.73686
Value Function Update Magnitude: 0.73576

Collected Steps per Second: 22,088.38712
Overall Steps per Second: 10,690.87709

Timestep Collection Time: 2.26381
Timestep Consumption Time: 2.41344
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.67726

Cumulative Model Updates: 126,806
Cumulative Timesteps: 1,057,407,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,196.94965
Policy Entropy: 3.78365
Value Function Loss: 0.03191

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.74209
Value Function Update Magnitude: 0.73459

Collected Steps per Second: 21,947.84732
Overall Steps per Second: 10,798.36813

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.35314
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63218

Cumulative Model Updates: 126,812
Cumulative Timesteps: 1,057,457,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1057457646...
Checkpoint 1057457646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,061.45381
Policy Entropy: 3.83018
Value Function Loss: 0.02470

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.73479
Value Function Update Magnitude: 0.76634

Collected Steps per Second: 22,178.88424
Overall Steps per Second: 10,724.60981

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.40836
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.66329

Cumulative Model Updates: 126,818
Cumulative Timesteps: 1,057,507,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.25608
Policy Entropy: 3.81397
Value Function Loss: 0.02160

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.74740
Value Function Update Magnitude: 0.82724

Collected Steps per Second: 22,391.13962
Overall Steps per Second: 10,889.66370

Timestep Collection Time: 2.23329
Timestep Consumption Time: 2.35877
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.59206

Cumulative Model Updates: 126,824
Cumulative Timesteps: 1,057,557,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1057557664...
Checkpoint 1057557664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.01089
Policy Entropy: 3.79873
Value Function Loss: 0.01613

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08011
Policy Update Magnitude: 0.68095
Value Function Update Magnitude: 0.73690

Collected Steps per Second: 22,358.70682
Overall Steps per Second: 10,663.15752

Timestep Collection Time: 2.23770
Timestep Consumption Time: 2.45435
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.69204

Cumulative Model Updates: 126,830
Cumulative Timesteps: 1,057,607,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.01089
Policy Entropy: 3.78261
Value Function Loss: 0.01368

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07673
Policy Update Magnitude: 0.60516
Value Function Update Magnitude: 0.62312

Collected Steps per Second: 23,133.53547
Overall Steps per Second: 10,956.97426

Timestep Collection Time: 2.16327
Timestep Consumption Time: 2.40405
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.56732

Cumulative Model Updates: 126,836
Cumulative Timesteps: 1,057,657,740

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1057657740...
Checkpoint 1057657740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329,161.36678
Policy Entropy: 3.78955
Value Function Loss: 0.01250

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07926
Policy Update Magnitude: 0.52563
Value Function Update Magnitude: 0.60894

Collected Steps per Second: 22,955.25630
Overall Steps per Second: 10,957.73016

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.38532
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.56390

Cumulative Model Updates: 126,842
Cumulative Timesteps: 1,057,707,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,777.52013
Policy Entropy: 3.78937
Value Function Loss: 0.01195

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.49846
Value Function Update Magnitude: 0.65778

Collected Steps per Second: 22,906.88709
Overall Steps per Second: 10,727.28495

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.66176

Cumulative Model Updates: 126,848
Cumulative Timesteps: 1,057,757,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1057757758...
Checkpoint 1057757758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,225.98683
Policy Entropy: 3.79707
Value Function Loss: 0.01255

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05781
Policy Update Magnitude: 0.52113
Value Function Update Magnitude: 0.63496

Collected Steps per Second: 22,848.09221
Overall Steps per Second: 10,847.81031

Timestep Collection Time: 2.18933
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.61125

Cumulative Model Updates: 126,854
Cumulative Timesteps: 1,057,807,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,643.76550
Policy Entropy: 3.80362
Value Function Loss: 0.01338

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.65795

Collected Steps per Second: 22,606.04129
Overall Steps per Second: 10,654.61223

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.69506

Cumulative Model Updates: 126,860
Cumulative Timesteps: 1,057,857,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1057857804...
Checkpoint 1057857804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,285.99409
Policy Entropy: 3.80063
Value Function Loss: 0.01531

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07403
Policy Update Magnitude: 0.65365
Value Function Update Magnitude: 0.77691

Collected Steps per Second: 22,976.26207
Overall Steps per Second: 10,853.86792

Timestep Collection Time: 2.17668
Timestep Consumption Time: 2.43108
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60776

Cumulative Model Updates: 126,866
Cumulative Timesteps: 1,057,907,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,379.37589
Policy Entropy: 3.79125
Value Function Loss: 0.01776

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.65811
Value Function Update Magnitude: 0.93880

Collected Steps per Second: 22,750.39176
Overall Steps per Second: 10,686.62871

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.68136

Cumulative Model Updates: 126,872
Cumulative Timesteps: 1,057,957,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1057957844...
Checkpoint 1057957844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,345.09925
Policy Entropy: 3.76773
Value Function Loss: 0.01750

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.72101
Value Function Update Magnitude: 0.94421

Collected Steps per Second: 22,716.95138
Overall Steps per Second: 10,719.72833

Timestep Collection Time: 2.20197
Timestep Consumption Time: 2.46438
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.66635

Cumulative Model Updates: 126,878
Cumulative Timesteps: 1,058,007,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,345.09925
Policy Entropy: 3.76599
Value Function Loss: 0.01638

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.75379
Value Function Update Magnitude: 0.80859

Collected Steps per Second: 22,467.48801
Overall Steps per Second: 10,662.17210

Timestep Collection Time: 2.22579
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.69023

Cumulative Model Updates: 126,884
Cumulative Timesteps: 1,058,057,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1058057874...
Checkpoint 1058057874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,787.43562
Policy Entropy: 3.76055
Value Function Loss: 0.01597

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.66837
Value Function Update Magnitude: 0.70835

Collected Steps per Second: 22,831.14403
Overall Steps per Second: 10,675.64992

Timestep Collection Time: 2.19060
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.68487

Cumulative Model Updates: 126,890
Cumulative Timesteps: 1,058,107,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,346.50127
Policy Entropy: 3.77361
Value Function Loss: 0.01604

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.52948
Value Function Update Magnitude: 0.62693

Collected Steps per Second: 22,720.00365
Overall Steps per Second: 10,842.94661

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.41069
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.61148

Cumulative Model Updates: 126,896
Cumulative Timesteps: 1,058,157,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1058157890...
Checkpoint 1058157890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,897.50050
Policy Entropy: 3.77686
Value Function Loss: 0.01727

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.47427
Value Function Update Magnitude: 0.55376

Collected Steps per Second: 21,418.81694
Overall Steps per Second: 10,717.77592

Timestep Collection Time: 2.33468
Timestep Consumption Time: 2.33103
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.66571

Cumulative Model Updates: 126,902
Cumulative Timesteps: 1,058,207,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,146.88376
Policy Entropy: 3.78517
Value Function Loss: 0.02294

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.57120
Value Function Update Magnitude: 0.47760

Collected Steps per Second: 21,447.04700
Overall Steps per Second: 10,532.86366

Timestep Collection Time: 2.33188
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.74819

Cumulative Model Updates: 126,908
Cumulative Timesteps: 1,058,257,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1058257908...
Checkpoint 1058257908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.98283
Policy Entropy: 3.79696
Value Function Loss: 0.02697

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.16782
Policy Update Magnitude: 0.66179
Value Function Update Magnitude: 0.47305

Collected Steps per Second: 22,049.64953
Overall Steps per Second: 10,870.57278

Timestep Collection Time: 2.26888
Timestep Consumption Time: 2.33327
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60215

Cumulative Model Updates: 126,914
Cumulative Timesteps: 1,058,307,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,053.22436
Policy Entropy: 3.81667
Value Function Loss: 0.02882

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.18125
Policy Update Magnitude: 0.63830
Value Function Update Magnitude: 0.57276

Collected Steps per Second: 21,844.32209
Overall Steps per Second: 10,618.81875

Timestep Collection Time: 2.29002
Timestep Consumption Time: 2.42086
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71088

Cumulative Model Updates: 126,920
Cumulative Timesteps: 1,058,357,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1058357960...
Checkpoint 1058357960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.07839
Policy Entropy: 3.81430
Value Function Loss: 0.03193

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.62558
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 22,138.63539
Overall Steps per Second: 10,736.32225

Timestep Collection Time: 2.25868
Timestep Consumption Time: 2.39879
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.65746

Cumulative Model Updates: 126,926
Cumulative Timesteps: 1,058,407,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.03819
Policy Entropy: 3.81858
Value Function Loss: 0.03083

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.65243
Value Function Update Magnitude: 0.66782

Collected Steps per Second: 22,118.90629
Overall Steps per Second: 10,717.20891

Timestep Collection Time: 2.26051
Timestep Consumption Time: 2.40488
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.66539

Cumulative Model Updates: 126,932
Cumulative Timesteps: 1,058,457,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1058457964...
Checkpoint 1058457964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242.10564
Policy Entropy: 3.80306
Value Function Loss: 0.02690

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14587
Policy Update Magnitude: 0.62016
Value Function Update Magnitude: 0.67621

Collected Steps per Second: 22,188.01197
Overall Steps per Second: 10,624.22246

Timestep Collection Time: 2.25410
Timestep Consumption Time: 2.45344
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.70754

Cumulative Model Updates: 126,938
Cumulative Timesteps: 1,058,507,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,396.35486
Policy Entropy: 3.78807
Value Function Loss: 0.02656

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.70351

Collected Steps per Second: 22,588.05167
Overall Steps per Second: 10,861.95838

Timestep Collection Time: 2.21427
Timestep Consumption Time: 2.39043
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60469

Cumulative Model Updates: 126,944
Cumulative Timesteps: 1,058,557,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1058557994...
Checkpoint 1058557994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,873.49732
Policy Entropy: 3.78560
Value Function Loss: 0.02840

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.59937
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 22,998.32238
Overall Steps per Second: 10,764.35552

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.64756

Cumulative Model Updates: 126,950
Cumulative Timesteps: 1,058,608,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,311.30751
Policy Entropy: 3.78360
Value Function Loss: 0.03039

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.60120
Value Function Update Magnitude: 0.74646

Collected Steps per Second: 22,768.28591
Overall Steps per Second: 10,884.11767

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.39810
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.59440

Cumulative Model Updates: 126,956
Cumulative Timesteps: 1,058,658,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1058658028...
Checkpoint 1058658028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,210.34515
Policy Entropy: 3.77685
Value Function Loss: 0.03056

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.62321
Value Function Update Magnitude: 0.90817

Collected Steps per Second: 23,034.59486
Overall Steps per Second: 10,799.33661

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.63121

Cumulative Model Updates: 126,962
Cumulative Timesteps: 1,058,708,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,041.13442
Policy Entropy: 3.74840
Value Function Loss: 0.02932

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14298
Policy Update Magnitude: 0.62436
Value Function Update Magnitude: 0.85651

Collected Steps per Second: 22,915.69192
Overall Steps per Second: 10,711.35235

Timestep Collection Time: 2.18261
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.66944

Cumulative Model Updates: 126,968
Cumulative Timesteps: 1,058,758,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1058758058...
Checkpoint 1058758058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,739.38073
Policy Entropy: 3.75406
Value Function Loss: 0.02766

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.57756
Value Function Update Magnitude: 0.64005

Collected Steps per Second: 22,892.36163
Overall Steps per Second: 10,691.93619

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.67717

Cumulative Model Updates: 126,974
Cumulative Timesteps: 1,058,808,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,818.10191
Policy Entropy: 3.76487
Value Function Loss: 0.02640

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.53758
Value Function Update Magnitude: 0.59688

Collected Steps per Second: 22,791.56362
Overall Steps per Second: 10,822.05010

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.42660
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.62057

Cumulative Model Updates: 126,980
Cumulative Timesteps: 1,058,858,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1058858070...
Checkpoint 1058858070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,043.23921
Policy Entropy: 3.79924
Value Function Loss: 0.02943

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.60908

Collected Steps per Second: 22,471.14706
Overall Steps per Second: 10,657.07344

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.46812
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.69453

Cumulative Model Updates: 126,986
Cumulative Timesteps: 1,058,908,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,921.03552
Policy Entropy: 3.80878
Value Function Loss: 0.02900

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.58015
Value Function Update Magnitude: 0.74020

Collected Steps per Second: 22,853.82060
Overall Steps per Second: 10,860.27194

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.60688

Cumulative Model Updates: 126,992
Cumulative Timesteps: 1,058,958,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1058958132...
Checkpoint 1058958132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,270.78828
Policy Entropy: 3.78978
Value Function Loss: 0.03180

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.58535
Value Function Update Magnitude: 0.85110

Collected Steps per Second: 22,833.41954
Overall Steps per Second: 10,725.92844

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.47242
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.66272

Cumulative Model Updates: 126,998
Cumulative Timesteps: 1,059,008,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,925.43706
Policy Entropy: 3.79266
Value Function Loss: 0.03017

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.63728
Value Function Update Magnitude: 0.90632

Collected Steps per Second: 22,578.28383
Overall Steps per Second: 10,636.22170

Timestep Collection Time: 2.21540
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.70280

Cumulative Model Updates: 127,004
Cumulative Timesteps: 1,059,058,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1059058164...
Checkpoint 1059058164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,504.16619
Policy Entropy: 3.78314
Value Function Loss: 0.02994

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.64877
Value Function Update Magnitude: 0.87116

Collected Steps per Second: 23,119.23429
Overall Steps per Second: 10,867.22021

Timestep Collection Time: 2.16287
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.60136

Cumulative Model Updates: 127,010
Cumulative Timesteps: 1,059,108,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,737.53705
Policy Entropy: 3.80023
Value Function Loss: 0.02885

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.63149
Value Function Update Magnitude: 0.75353

Collected Steps per Second: 22,461.85950
Overall Steps per Second: 10,507.88577

Timestep Collection Time: 2.22671
Timestep Consumption Time: 2.53315
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.75985

Cumulative Model Updates: 127,016
Cumulative Timesteps: 1,059,158,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1059158184...
Checkpoint 1059158184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184.27685
Policy Entropy: 3.80271
Value Function Loss: 0.02612

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.62603
Value Function Update Magnitude: 0.75862

Collected Steps per Second: 22,328.39444
Overall Steps per Second: 10,607.48957

Timestep Collection Time: 2.24020
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.71554

Cumulative Model Updates: 127,022
Cumulative Timesteps: 1,059,208,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,173.19496
Policy Entropy: 3.80213
Value Function Loss: 0.02720

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.62054
Value Function Update Magnitude: 0.73059

Collected Steps per Second: 22,161.43844
Overall Steps per Second: 10,435.35328

Timestep Collection Time: 2.25725
Timestep Consumption Time: 2.53645
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.79370

Cumulative Model Updates: 127,028
Cumulative Timesteps: 1,059,258,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1059258228...
Checkpoint 1059258228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,054.92883
Policy Entropy: 3.78052
Value Function Loss: 0.02539

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.78964

Collected Steps per Second: 22,306.39167
Overall Steps per Second: 10,710.27915

Timestep Collection Time: 2.24151
Timestep Consumption Time: 2.42690
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.66841

Cumulative Model Updates: 127,034
Cumulative Timesteps: 1,059,308,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,860.94612
Policy Entropy: 3.75878
Value Function Loss: 0.02583

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.57390
Value Function Update Magnitude: 0.84403

Collected Steps per Second: 22,262.11581
Overall Steps per Second: 10,530.89412

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.50297
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.74983

Cumulative Model Updates: 127,040
Cumulative Timesteps: 1,059,358,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1059358248...
Checkpoint 1059358248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,161.71718
Policy Entropy: 3.76622
Value Function Loss: 0.02438

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.60234
Value Function Update Magnitude: 0.83513

Collected Steps per Second: 22,180.22110
Overall Steps per Second: 10,529.15697

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.75043

Cumulative Model Updates: 127,046
Cumulative Timesteps: 1,059,408,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,895.17104
Policy Entropy: 3.77715
Value Function Loss: 0.02233

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.60882
Value Function Update Magnitude: 0.82268

Collected Steps per Second: 22,142.95002
Overall Steps per Second: 10,313.25667

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.59080
PPO Batch Consumption Time: 0.29714
Total Iteration Time: 4.84949

Cumulative Model Updates: 127,052
Cumulative Timesteps: 1,059,458,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1059458280...
Checkpoint 1059458280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,328.96674
Policy Entropy: 3.77684
Value Function Loss: 0.02154

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.79833

Collected Steps per Second: 19,370.15625
Overall Steps per Second: 9,620.25366

Timestep Collection Time: 2.58232
Timestep Consumption Time: 2.61712
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 5.19945

Cumulative Model Updates: 127,058
Cumulative Timesteps: 1,059,508,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,207.04343
Policy Entropy: 3.76205
Value Function Loss: 0.02038

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.67730

Collected Steps per Second: 19,195.69331
Overall Steps per Second: 9,588.23547

Timestep Collection Time: 2.60506
Timestep Consumption Time: 2.61029
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 5.21535

Cumulative Model Updates: 127,064
Cumulative Timesteps: 1,059,558,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1059558306...
Checkpoint 1059558306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,025.61222
Policy Entropy: 3.75712
Value Function Loss: 0.02303

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.50179
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 20,866.63991
Overall Steps per Second: 10,335.38899

Timestep Collection Time: 2.39636
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.83813

Cumulative Model Updates: 127,070
Cumulative Timesteps: 1,059,608,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,563.06745
Policy Entropy: 3.77735
Value Function Loss: 0.02256

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.49276
Value Function Update Magnitude: 0.81141

Collected Steps per Second: 12,486.35343
Overall Steps per Second: 7,414.72529

Timestep Collection Time: 4.00549
Timestep Consumption Time: 2.73973
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 6.74523

Cumulative Model Updates: 127,076
Cumulative Timesteps: 1,059,658,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1059658324...
Checkpoint 1059658324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.12197
Policy Entropy: 3.76444
Value Function Loss: 0.02388

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.49666
Value Function Update Magnitude: 0.90358

Collected Steps per Second: 9,566.32049
Overall Steps per Second: 6,387.80862

Timestep Collection Time: 5.23022
Timestep Consumption Time: 2.60251
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 7.83273

Cumulative Model Updates: 127,082
Cumulative Timesteps: 1,059,708,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.12197
Policy Entropy: 3.73954
Value Function Loss: 0.02131

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.50904
Value Function Update Magnitude: 0.81467

Collected Steps per Second: 21,326.76609
Overall Steps per Second: 10,603.73649

Timestep Collection Time: 2.34457
Timestep Consumption Time: 2.37094
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.71551

Cumulative Model Updates: 127,088
Cumulative Timesteps: 1,059,758,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1059758360...
Checkpoint 1059758360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.12197
Policy Entropy: 3.70553
Value Function Loss: 0.02018

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.49534
Value Function Update Magnitude: 0.63808

Collected Steps per Second: 21,423.58887
Overall Steps per Second: 10,571.85675

Timestep Collection Time: 2.33472
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.73124

Cumulative Model Updates: 127,094
Cumulative Timesteps: 1,059,808,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,309.12197
Policy Entropy: 3.71733
Value Function Loss: 0.01746

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.47205
Value Function Update Magnitude: 0.52154

Collected Steps per Second: 21,653.30123
Overall Steps per Second: 10,506.95446

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.45081
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.76104

Cumulative Model Updates: 127,100
Cumulative Timesteps: 1,059,858,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1059858402...
Checkpoint 1059858402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,191.41356
Policy Entropy: 3.73123
Value Function Loss: 0.01650

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.41818
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 22,774.43280
Overall Steps per Second: 10,736.74770

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.46225
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.65839

Cumulative Model Updates: 127,106
Cumulative Timesteps: 1,059,908,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,127.64961
Policy Entropy: 3.75977
Value Function Loss: 0.01591

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.42322
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 22,742.07336
Overall Steps per Second: 10,848.79788

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.41197
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.61212

Cumulative Model Updates: 127,112
Cumulative Timesteps: 1,059,958,454

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1059958454...
Checkpoint 1059958454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,833.83601
Policy Entropy: 3.77066
Value Function Loss: 0.02218

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.48892
Value Function Update Magnitude: 0.67504

Collected Steps per Second: 22,939.64195
Overall Steps per Second: 10,697.21729

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.67505

Cumulative Model Updates: 127,118
Cumulative Timesteps: 1,060,008,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.88371
Policy Entropy: 3.77609
Value Function Loss: 0.02619

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.59523
Value Function Update Magnitude: 0.71554

Collected Steps per Second: 22,425.17102
Overall Steps per Second: 10,740.85545

Timestep Collection Time: 2.22964
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.65512

Cumulative Model Updates: 127,124
Cumulative Timesteps: 1,060,058,464

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1060058464...
Checkpoint 1060058464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,286.54679
Policy Entropy: 3.76885
Value Function Loss: 0.02962

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.62550
Value Function Update Magnitude: 0.83947

Collected Steps per Second: 22,715.63964
Overall Steps per Second: 10,693.75958

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.47569
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.67787

Cumulative Model Updates: 127,130
Cumulative Timesteps: 1,060,108,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,959.02595
Policy Entropy: 3.76257
Value Function Loss: 0.03248

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.68522
Value Function Update Magnitude: 0.91900

Collected Steps per Second: 22,822.06988
Overall Steps per Second: 10,844.13104

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.42119
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.61319

Cumulative Model Updates: 127,136
Cumulative Timesteps: 1,060,158,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1060158514...
Checkpoint 1060158514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.64602
Policy Entropy: 3.76238
Value Function Loss: 0.03062

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.73763
Value Function Update Magnitude: 0.95235

Collected Steps per Second: 22,814.69814
Overall Steps per Second: 10,729.17059

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.66094

Cumulative Model Updates: 127,142
Cumulative Timesteps: 1,060,208,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,680.55358
Policy Entropy: 3.75481
Value Function Loss: 0.02897

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.70423
Value Function Update Magnitude: 0.96432

Collected Steps per Second: 22,844.71468
Overall Steps per Second: 10,834.36400

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61975

Cumulative Model Updates: 127,148
Cumulative Timesteps: 1,060,258,574

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1060258574...
Checkpoint 1060258574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,678.89890
Policy Entropy: 3.75286
Value Function Loss: 0.02874

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.66520
Value Function Update Magnitude: 0.93001

Collected Steps per Second: 22,656.52437
Overall Steps per Second: 10,717.08185

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.66638

Cumulative Model Updates: 127,154
Cumulative Timesteps: 1,060,308,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,515.55167
Policy Entropy: 3.73830
Value Function Loss: 0.03009

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.63193
Value Function Update Magnitude: 0.92492

Collected Steps per Second: 22,634.85474
Overall Steps per Second: 10,801.69459

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.42108
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.63113

Cumulative Model Updates: 127,160
Cumulative Timesteps: 1,060,358,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1060358608...
Checkpoint 1060358608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,371.03475
Policy Entropy: 3.73814
Value Function Loss: 0.03178

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.65162
Value Function Update Magnitude: 0.90641

Collected Steps per Second: 22,683.37043
Overall Steps per Second: 10,746.28846

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.65444

Cumulative Model Updates: 127,166
Cumulative Timesteps: 1,060,408,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,350.38177
Policy Entropy: 3.75604
Value Function Loss: 0.02991

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.62951
Value Function Update Magnitude: 0.89996

Collected Steps per Second: 22,616.32311
Overall Steps per Second: 10,676.60702

Timestep Collection Time: 2.21132
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68426

Cumulative Model Updates: 127,172
Cumulative Timesteps: 1,060,458,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1060458638...
Checkpoint 1060458638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,186.93297
Policy Entropy: 3.75668
Value Function Loss: 0.02838

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.71625

Collected Steps per Second: 22,663.89749
Overall Steps per Second: 10,808.35888

Timestep Collection Time: 2.20677
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.62734

Cumulative Model Updates: 127,178
Cumulative Timesteps: 1,060,508,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,163.39887
Policy Entropy: 3.75640
Value Function Loss: 0.02382

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.63820

Collected Steps per Second: 22,705.54944
Overall Steps per Second: 10,673.24862

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.68611

Cumulative Model Updates: 127,184
Cumulative Timesteps: 1,060,558,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1060558668...
Checkpoint 1060558668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,218.72877
Policy Entropy: 3.74340
Value Function Loss: 0.02465

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 22,867.02022
Overall Steps per Second: 10,859.30016

Timestep Collection Time: 2.18682
Timestep Consumption Time: 2.41808
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.60490

Cumulative Model Updates: 127,190
Cumulative Timesteps: 1,060,608,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,573.42784
Policy Entropy: 3.74447
Value Function Loss: 0.02535

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.63438

Collected Steps per Second: 22,580.89263
Overall Steps per Second: 10,605.20362

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.71561

Cumulative Model Updates: 127,196
Cumulative Timesteps: 1,060,658,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1060658684...
Checkpoint 1060658684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,573.42784
Policy Entropy: 3.72595
Value Function Loss: 0.02291

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.56352
Value Function Update Magnitude: 0.76182

Collected Steps per Second: 22,764.13096
Overall Steps per Second: 10,668.85096

Timestep Collection Time: 2.19644
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.68654

Cumulative Model Updates: 127,202
Cumulative Timesteps: 1,060,708,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,573.42784
Policy Entropy: 3.73101
Value Function Loss: 0.01816

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.50526
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 23,108.27344
Overall Steps per Second: 10,830.38479

Timestep Collection Time: 2.16459
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.61849

Cumulative Model Updates: 127,208
Cumulative Timesteps: 1,060,758,704

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1060758704...
Checkpoint 1060758704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,573.42784
Policy Entropy: 3.69889
Value Function Loss: 0.01824

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.46798
Value Function Update Magnitude: 0.56100

Collected Steps per Second: 23,131.32296
Overall Steps per Second: 10,779.95326

Timestep Collection Time: 2.16235
Timestep Consumption Time: 2.47756
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.63991

Cumulative Model Updates: 127,214
Cumulative Timesteps: 1,060,808,722

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,905.28801
Policy Entropy: 3.71732
Value Function Loss: 0.01860

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.62484

Collected Steps per Second: 22,873.97039
Overall Steps per Second: 10,763.14312

Timestep Collection Time: 2.18703
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.64790

Cumulative Model Updates: 127,220
Cumulative Timesteps: 1,060,858,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1060858748...
Checkpoint 1060858748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,628.96182
Policy Entropy: 3.70572
Value Function Loss: 0.02704

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.76226

Collected Steps per Second: 22,949.58024
Overall Steps per Second: 10,674.94865

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.68667

Cumulative Model Updates: 127,226
Cumulative Timesteps: 1,060,908,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,453.05506
Policy Entropy: 3.74856
Value Function Loss: 0.02928

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.60599
Value Function Update Magnitude: 0.64058

Collected Steps per Second: 22,680.67046
Overall Steps per Second: 10,808.19377

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.42296
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.62871

Cumulative Model Updates: 127,232
Cumulative Timesteps: 1,060,958,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1060958806...
Checkpoint 1060958806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,114.70846
Policy Entropy: 3.74505
Value Function Loss: 0.03191

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15300
Policy Update Magnitude: 0.58580
Value Function Update Magnitude: 0.53970

Collected Steps per Second: 22,879.80553
Overall Steps per Second: 10,679.99527

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.49811
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.68502

Cumulative Model Updates: 127,238
Cumulative Timesteps: 1,061,008,842

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,570.65282
Policy Entropy: 3.77225
Value Function Loss: 0.02292

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 22,463.66261
Overall Steps per Second: 10,590.96205

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.72271

Cumulative Model Updates: 127,244
Cumulative Timesteps: 1,061,058,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1061058860...
Checkpoint 1061058860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.44814
Policy Entropy: 3.75975
Value Function Loss: 0.01993

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.49290
Value Function Update Magnitude: 0.68828

Collected Steps per Second: 23,050.89170
Overall Steps per Second: 10,887.74383

Timestep Collection Time: 2.16981
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.59379

Cumulative Model Updates: 127,250
Cumulative Timesteps: 1,061,108,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436.08763
Policy Entropy: 3.75020
Value Function Loss: 0.01905

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.46040
Value Function Update Magnitude: 0.62482

Collected Steps per Second: 22,840.61339
Overall Steps per Second: 10,739.20351

Timestep Collection Time: 2.18996
Timestep Consumption Time: 2.46774
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.65770

Cumulative Model Updates: 127,256
Cumulative Timesteps: 1,061,158,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1061158896...
Checkpoint 1061158896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.07125
Policy Entropy: 3.73565
Value Function Loss: 0.01776

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.47718
Value Function Update Magnitude: 0.56394

Collected Steps per Second: 22,988.46454
Overall Steps per Second: 10,863.31283

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.42871
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.60467

Cumulative Model Updates: 127,262
Cumulative Timesteps: 1,061,208,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.07125
Policy Entropy: 3.71969
Value Function Loss: 0.01883

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.45378
Value Function Update Magnitude: 0.52676

Collected Steps per Second: 22,720.98881
Overall Steps per Second: 10,818.82733

Timestep Collection Time: 2.20078
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.62194

Cumulative Model Updates: 127,268
Cumulative Timesteps: 1,061,258,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1061258922...
Checkpoint 1061258922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,204.91750
Policy Entropy: 3.71086
Value Function Loss: 0.02041

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.47113
Value Function Update Magnitude: 0.60020

Collected Steps per Second: 22,715.66713
Overall Steps per Second: 10,733.93178

Timestep Collection Time: 2.20192
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.65980

Cumulative Model Updates: 127,274
Cumulative Timesteps: 1,061,308,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,831.53492
Policy Entropy: 3.71597
Value Function Loss: 0.02169

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.49211
Value Function Update Magnitude: 0.57263

Collected Steps per Second: 22,684.11797
Overall Steps per Second: 10,602.92154

Timestep Collection Time: 2.20480
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71700

Cumulative Model Updates: 127,280
Cumulative Timesteps: 1,061,358,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1061358954...
Checkpoint 1061358954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,518.43149
Policy Entropy: 3.73780
Value Function Loss: 0.02262

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.51626
Value Function Update Magnitude: 0.53596

Collected Steps per Second: 23,015.04126
Overall Steps per Second: 10,871.94243

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.60120

Cumulative Model Updates: 127,286
Cumulative Timesteps: 1,061,408,978

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,253.17117
Policy Entropy: 3.74131
Value Function Loss: 0.02053

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.51184
Value Function Update Magnitude: 0.54401

Collected Steps per Second: 22,828.23311
Overall Steps per Second: 10,713.40529

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.47718
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66780

Cumulative Model Updates: 127,292
Cumulative Timesteps: 1,061,458,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1061458986...
Checkpoint 1061458986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,281.73039
Policy Entropy: 3.74657
Value Function Loss: 0.01935

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.47529
Value Function Update Magnitude: 0.53205

Collected Steps per Second: 23,030.58608
Overall Steps per Second: 10,883.82196

Timestep Collection Time: 2.17198
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.59600

Cumulative Model Updates: 127,298
Cumulative Timesteps: 1,061,509,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,881.19809
Policy Entropy: 3.75023
Value Function Loss: 0.01948

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.46615
Value Function Update Magnitude: 0.49597

Collected Steps per Second: 22,917.93766
Overall Steps per Second: 10,848.88221

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.61154

Cumulative Model Updates: 127,304
Cumulative Timesteps: 1,061,559,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1061559038...
Checkpoint 1061559038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,937.36360
Policy Entropy: 3.74414
Value Function Loss: 0.02018

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.48493
Value Function Update Magnitude: 0.47419

Collected Steps per Second: 22,807.75584
Overall Steps per Second: 10,738.17090

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.65852

Cumulative Model Updates: 127,310
Cumulative Timesteps: 1,061,609,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,409.44755
Policy Entropy: 3.72664
Value Function Loss: 0.02223

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.50860
Value Function Update Magnitude: 0.45985

Collected Steps per Second: 22,290.80291
Overall Steps per Second: 10,529.20540

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.75060

Cumulative Model Updates: 127,316
Cumulative Timesteps: 1,061,659,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1061659082...
Checkpoint 1061659082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,409.44755
Policy Entropy: 3.71892
Value Function Loss: 0.02060

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.47370
Value Function Update Magnitude: 0.48195

Collected Steps per Second: 22,993.29191
Overall Steps per Second: 10,764.88815

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.47107
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.64640

Cumulative Model Updates: 127,322
Cumulative Timesteps: 1,061,709,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,409.44755
Policy Entropy: 3.72221
Value Function Loss: 0.01884

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.44668
Value Function Update Magnitude: 0.44610

Collected Steps per Second: 22,920.35000
Overall Steps per Second: 10,733.38160

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.66135

Cumulative Model Updates: 127,328
Cumulative Timesteps: 1,061,759,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1061759132...
Checkpoint 1061759132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,409.44755
Policy Entropy: 3.73316
Value Function Loss: 0.01692

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.42677
Value Function Update Magnitude: 0.39782

Collected Steps per Second: 22,980.05775
Overall Steps per Second: 10,761.69361

Timestep Collection Time: 2.17667
Timestep Consumption Time: 2.47130
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.64797

Cumulative Model Updates: 127,334
Cumulative Timesteps: 1,061,809,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,704.46902
Policy Entropy: 3.74768
Value Function Loss: 0.01678

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.44505
Value Function Update Magnitude: 0.45478

Collected Steps per Second: 23,104.99216
Overall Steps per Second: 10,758.82711

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.64828

Cumulative Model Updates: 127,340
Cumulative Timesteps: 1,061,859,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1061859162...
Checkpoint 1061859162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,380.58440
Policy Entropy: 3.76367
Value Function Loss: 0.01714

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.47294
Value Function Update Magnitude: 0.51100

Collected Steps per Second: 22,873.97988
Overall Steps per Second: 10,717.04695

Timestep Collection Time: 2.18729
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.66845

Cumulative Model Updates: 127,346
Cumulative Timesteps: 1,061,909,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,653.75154
Policy Entropy: 3.75549
Value Function Loss: 0.01670

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.44795
Value Function Update Magnitude: 0.50796

Collected Steps per Second: 22,405.63417
Overall Steps per Second: 10,863.43382

Timestep Collection Time: 2.23221
Timestep Consumption Time: 2.37168
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60389

Cumulative Model Updates: 127,352
Cumulative Timesteps: 1,061,959,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1061959208...
Checkpoint 1061959208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,476.42578
Policy Entropy: 3.75275
Value Function Loss: 0.01775

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.44897
Value Function Update Magnitude: 0.47172

Collected Steps per Second: 22,080.17963
Overall Steps per Second: 10,706.43256

Timestep Collection Time: 2.26547
Timestep Consumption Time: 2.40667
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.67214

Cumulative Model Updates: 127,358
Cumulative Timesteps: 1,062,009,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,800.73423
Policy Entropy: 3.74367
Value Function Loss: 0.01776

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.45798
Value Function Update Magnitude: 0.45272

Collected Steps per Second: 22,184.19929
Overall Steps per Second: 10,881.68615

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.34168
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.59616

Cumulative Model Updates: 127,364
Cumulative Timesteps: 1,062,059,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1062059244...
Checkpoint 1062059244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,609.10704
Policy Entropy: 3.74261
Value Function Loss: 0.01884

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.43666
Value Function Update Magnitude: 0.43460

Collected Steps per Second: 22,041.68171
Overall Steps per Second: 10,557.28623

Timestep Collection Time: 2.26952
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.73834

Cumulative Model Updates: 127,370
Cumulative Timesteps: 1,062,109,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,609.10704
Policy Entropy: 3.73394
Value Function Loss: 0.01900

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.45090
Value Function Update Magnitude: 0.38666

Collected Steps per Second: 22,856.47031
Overall Steps per Second: 10,896.94519

Timestep Collection Time: 2.18870
Timestep Consumption Time: 2.40213
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.59083

Cumulative Model Updates: 127,376
Cumulative Timesteps: 1,062,159,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1062159294...
Checkpoint 1062159294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,742.67265
Policy Entropy: 3.72452
Value Function Loss: 0.02136

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.46441
Value Function Update Magnitude: 0.44710

Collected Steps per Second: 22,572.25212
Overall Steps per Second: 10,663.28184

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.69105

Cumulative Model Updates: 127,382
Cumulative Timesteps: 1,062,209,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,366.12401
Policy Entropy: 3.73506
Value Function Loss: 0.02143

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,793.83445
Overall Steps per Second: 10,813.20110

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.62638

Cumulative Model Updates: 127,388
Cumulative Timesteps: 1,062,259,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1062259342...
Checkpoint 1062259342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,598.97463
Policy Entropy: 3.74238
Value Function Loss: 0.02370

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.67739

Collected Steps per Second: 22,161.29650
Overall Steps per Second: 10,682.15385

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.68351

Cumulative Model Updates: 127,394
Cumulative Timesteps: 1,062,309,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,509.21933
Policy Entropy: 3.75521
Value Function Loss: 0.02196

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.79024

Collected Steps per Second: 23,101.24919
Overall Steps per Second: 10,900.06147

Timestep Collection Time: 2.16551
Timestep Consumption Time: 2.42400
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58952

Cumulative Model Updates: 127,400
Cumulative Timesteps: 1,062,359,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1062359398...
Checkpoint 1062359398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,894.03369
Policy Entropy: 3.74204
Value Function Loss: 0.02316

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.56996
Value Function Update Magnitude: 0.80074

Collected Steps per Second: 22,729.95956
Overall Steps per Second: 10,723.57785

Timestep Collection Time: 2.20097
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.66523

Cumulative Model Updates: 127,406
Cumulative Timesteps: 1,062,409,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,173.55882
Policy Entropy: 3.74467
Value Function Loss: 0.02135

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.54340
Value Function Update Magnitude: 0.69551

Collected Steps per Second: 22,792.96197
Overall Steps per Second: 10,826.10471

Timestep Collection Time: 2.19384
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61884

Cumulative Model Updates: 127,412
Cumulative Timesteps: 1,062,459,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1062459430...
Checkpoint 1062459430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,173.55882
Policy Entropy: 3.73901
Value Function Loss: 0.01991

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.50531
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,748.32163
Overall Steps per Second: 10,731.23810

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.46212
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.66079

Cumulative Model Updates: 127,418
Cumulative Timesteps: 1,062,509,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,573.07994
Policy Entropy: 3.74030
Value Function Loss: 0.01661

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.46139
Value Function Update Magnitude: 0.52273

Collected Steps per Second: 23,224.32717
Overall Steps per Second: 10,931.23664

Timestep Collection Time: 2.15291
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.57405

Cumulative Model Updates: 127,424
Cumulative Timesteps: 1,062,559,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1062559446...
Checkpoint 1062559446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,573.07994
Policy Entropy: 3.72997
Value Function Loss: 0.01700

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.45425
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,099.78153
Overall Steps per Second: 10,698.15781

Timestep Collection Time: 2.26274
Timestep Consumption Time: 2.41153
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67426

Cumulative Model Updates: 127,430
Cumulative Timesteps: 1,062,609,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,943.90353
Policy Entropy: 3.74444
Value Function Loss: 0.01908

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.51963
Value Function Update Magnitude: 0.66056

Collected Steps per Second: 22,256.97727
Overall Steps per Second: 10,807.46255

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.38099
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.62847

Cumulative Model Updates: 127,436
Cumulative Timesteps: 1,062,659,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1062659474...
Checkpoint 1062659474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,933.77133
Policy Entropy: 3.74119
Value Function Loss: 0.02051

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.53312
Value Function Update Magnitude: 0.72253

Collected Steps per Second: 21,925.49364
Overall Steps per Second: 10,606.90175

Timestep Collection Time: 2.28164
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.71636

Cumulative Model Updates: 127,442
Cumulative Timesteps: 1,062,709,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,251.87602
Policy Entropy: 3.74922
Value Function Loss: 0.01923

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.51508
Value Function Update Magnitude: 0.73261

Collected Steps per Second: 22,651.44662
Overall Steps per Second: 10,862.03238

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.39650
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.60448

Cumulative Model Updates: 127,448
Cumulative Timesteps: 1,062,759,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1062759514...
Checkpoint 1062759514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,251.87602
Policy Entropy: 3.72126
Value Function Loss: 0.01825

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.49707
Value Function Update Magnitude: 0.74553

Collected Steps per Second: 22,775.74989
Overall Steps per Second: 10,730.44542

Timestep Collection Time: 2.19602
Timestep Consumption Time: 2.46511
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66113

Cumulative Model Updates: 127,454
Cumulative Timesteps: 1,062,809,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,251.87602
Policy Entropy: 3.72709
Value Function Loss: 0.01552

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.45978
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,693.91916
Overall Steps per Second: 10,785.75202

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.63593

Cumulative Model Updates: 127,460
Cumulative Timesteps: 1,062,859,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1062859532...
Checkpoint 1062859532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,251.87602
Policy Entropy: 3.71550
Value Function Loss: 0.01617

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.48159
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 22,678.92269
Overall Steps per Second: 10,764.54949

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64581

Cumulative Model Updates: 127,466
Cumulative Timesteps: 1,062,909,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,251.87602
Policy Entropy: 3.72068
Value Function Loss: 0.01811

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.50561
Value Function Update Magnitude: 0.70803

Collected Steps per Second: 22,189.10560
Overall Steps per Second: 10,503.36552

Timestep Collection Time: 2.25372
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.76114

Cumulative Model Updates: 127,472
Cumulative Timesteps: 1,062,959,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1062959550...
Checkpoint 1062959550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,872.09423
Policy Entropy: 3.71013
Value Function Loss: 0.01881

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14462
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.74594

Collected Steps per Second: 22,761.57005
Overall Steps per Second: 10,679.35804

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.68493

Cumulative Model Updates: 127,478
Cumulative Timesteps: 1,063,009,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,377.97895
Policy Entropy: 3.71993
Value Function Loss: 0.01888

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.76100

Collected Steps per Second: 22,977.57159
Overall Steps per Second: 10,778.87528

Timestep Collection Time: 2.17604
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.63870

Cumulative Model Updates: 127,484
Cumulative Timesteps: 1,063,059,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1063059582...
Checkpoint 1063059582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,377.97895
Policy Entropy: 3.71360
Value Function Loss: 0.01795

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.51418
Value Function Update Magnitude: 0.76609

Collected Steps per Second: 22,528.74408
Overall Steps per Second: 10,599.53883

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.71813

Cumulative Model Updates: 127,490
Cumulative Timesteps: 1,063,109,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285,199.54903
Policy Entropy: 3.72929
Value Function Loss: 0.01861

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.51246
Value Function Update Magnitude: 0.72965

Collected Steps per Second: 22,917.02795
Overall Steps per Second: 10,866.74138

Timestep Collection Time: 2.18205
Timestep Consumption Time: 2.41970
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60175

Cumulative Model Updates: 127,496
Cumulative Timesteps: 1,063,159,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1063159598...
Checkpoint 1063159598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,499.88819
Policy Entropy: 3.73048
Value Function Loss: 0.01799

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.51666
Value Function Update Magnitude: 0.73652

Collected Steps per Second: 22,659.13380
Overall Steps per Second: 10,733.41021

Timestep Collection Time: 2.20732
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.65984

Cumulative Model Updates: 127,502
Cumulative Timesteps: 1,063,209,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,499.88819
Policy Entropy: 3.74491
Value Function Loss: 0.01815

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.47998
Value Function Update Magnitude: 0.66958

Collected Steps per Second: 23,057.93054
Overall Steps per Second: 10,843.75961

Timestep Collection Time: 2.16862
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.61132

Cumulative Model Updates: 127,508
Cumulative Timesteps: 1,063,259,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1063259618...
Checkpoint 1063259618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,499.88819
Policy Entropy: 3.73003
Value Function Loss: 0.01817

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.49970
Value Function Update Magnitude: 0.59438

Collected Steps per Second: 22,743.44745
Overall Steps per Second: 10,635.84439

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.70108

Cumulative Model Updates: 127,514
Cumulative Timesteps: 1,063,309,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,499.88819
Policy Entropy: 3.73464
Value Function Loss: 0.01683

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.48487
Value Function Update Magnitude: 0.54567

Collected Steps per Second: 22,854.41517
Overall Steps per Second: 10,880.42135

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.59578

Cumulative Model Updates: 127,520
Cumulative Timesteps: 1,063,359,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1063359622...
Checkpoint 1063359622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362,499.88819
Policy Entropy: 3.73416
Value Function Loss: 0.01619

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.43611
Value Function Update Magnitude: 0.50936

Collected Steps per Second: 22,893.28088
Overall Steps per Second: 10,714.33630

Timestep Collection Time: 2.18413
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.66683

Cumulative Model Updates: 127,526
Cumulative Timesteps: 1,063,409,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 523,051.05936
Policy Entropy: 3.73553
Value Function Loss: 0.01640

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.44370
Value Function Update Magnitude: 0.52069

Collected Steps per Second: 23,151.96777
Overall Steps per Second: 10,919.51674

Timestep Collection Time: 2.16051
Timestep Consumption Time: 2.42028
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.58079

Cumulative Model Updates: 127,532
Cumulative Timesteps: 1,063,459,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1063459644...
Checkpoint 1063459644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,403.76944
Policy Entropy: 3.73502
Value Function Loss: 0.01799

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.47472
Value Function Update Magnitude: 0.68897

Collected Steps per Second: 21,761.26087
Overall Steps per Second: 10,628.86238

Timestep Collection Time: 2.29794
Timestep Consumption Time: 2.40680
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.70474

Cumulative Model Updates: 127,538
Cumulative Timesteps: 1,063,509,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,748.60769
Policy Entropy: 3.73080
Value Function Loss: 0.02138

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.53984
Value Function Update Magnitude: 0.78953

Collected Steps per Second: 22,307.06246
Overall Steps per Second: 10,899.92747

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.34640
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58847

Cumulative Model Updates: 127,544
Cumulative Timesteps: 1,063,559,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1063559664...
Checkpoint 1063559664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,748.60769
Policy Entropy: 3.72128
Value Function Loss: 0.02341

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.59361
Value Function Update Magnitude: 0.77733

Collected Steps per Second: 21,727.33343
Overall Steps per Second: 10,632.10902

Timestep Collection Time: 2.30199
Timestep Consumption Time: 2.40226
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.70424

Cumulative Model Updates: 127,550
Cumulative Timesteps: 1,063,609,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 480,482.98526
Policy Entropy: 3.69784
Value Function Loss: 0.02672

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.61976
Value Function Update Magnitude: 0.73159

Collected Steps per Second: 22,883.74442
Overall Steps per Second: 10,885.53885

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.40868
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59398

Cumulative Model Updates: 127,556
Cumulative Timesteps: 1,063,659,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1063659688...
Checkpoint 1063659688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,197.92977
Policy Entropy: 3.68790
Value Function Loss: 0.02617

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.59010
Value Function Update Magnitude: 0.70052

Collected Steps per Second: 22,405.63196
Overall Steps per Second: 10,658.86377

Timestep Collection Time: 2.23274
Timestep Consumption Time: 2.46063
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.69337

Cumulative Model Updates: 127,562
Cumulative Timesteps: 1,063,709,714

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389,197.92977
Policy Entropy: 3.69589
Value Function Loss: 0.02399

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.72854

Collected Steps per Second: 22,952.93716
Overall Steps per Second: 10,850.71883

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61039

Cumulative Model Updates: 127,568
Cumulative Timesteps: 1,063,759,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1063759740...
Checkpoint 1063759740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 613,891.65203
Policy Entropy: 3.70955
Value Function Loss: 0.02427

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.67793

Collected Steps per Second: 22,603.23694
Overall Steps per Second: 10,725.11364

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.45018
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66251

Cumulative Model Updates: 127,574
Cumulative Timesteps: 1,063,809,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,070.78995
Policy Entropy: 3.73932
Value Function Loss: 0.02476

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15837
Policy Update Magnitude: 0.59335
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 22,596.34416
Overall Steps per Second: 10,787.73012

Timestep Collection Time: 2.21346
Timestep Consumption Time: 2.42292
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.63638

Cumulative Model Updates: 127,580
Cumulative Timesteps: 1,063,859,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1063859762...
Checkpoint 1063859762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,386.27505
Policy Entropy: 3.75113
Value Function Loss: 0.02569

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14475
Policy Update Magnitude: 0.58859
Value Function Update Magnitude: 0.60568

Collected Steps per Second: 22,240.01336
Overall Steps per Second: 10,679.59699

Timestep Collection Time: 2.24856
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.68257

Cumulative Model Updates: 127,586
Cumulative Timesteps: 1,063,909,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.75337
Value Function Loss: 0.02308

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14413
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.63952

Collected Steps per Second: 23,303.69050
Overall Steps per Second: 10,931.44201

Timestep Collection Time: 2.14593
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.57469

Cumulative Model Updates: 127,592
Cumulative Timesteps: 1,063,959,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1063959778...
Checkpoint 1063959778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.73306
Value Function Loss: 0.02143

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.15110
Policy Update Magnitude: 0.51732
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 22,957.26085
Overall Steps per Second: 10,683.34204

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.50232
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.68037

Cumulative Model Updates: 127,598
Cumulative Timesteps: 1,064,009,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.72587
Value Function Loss: 0.01930

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.46730
Value Function Update Magnitude: 0.49881

Collected Steps per Second: 23,043.18024
Overall Steps per Second: 10,854.02279

Timestep Collection Time: 2.17097
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.60898

Cumulative Model Updates: 127,604
Cumulative Timesteps: 1,064,059,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1064059806...
Checkpoint 1064059806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.72217
Value Function Loss: 0.01819

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.43523
Value Function Update Magnitude: 0.44146

Collected Steps per Second: 22,770.54363
Overall Steps per Second: 10,683.34918

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68112

Cumulative Model Updates: 127,610
Cumulative Timesteps: 1,064,109,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.73323
Value Function Loss: 0.01684

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.42534
Value Function Update Magnitude: 0.39506

Collected Steps per Second: 22,950.91144
Overall Steps per Second: 10,868.77539

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60199

Cumulative Model Updates: 127,616
Cumulative Timesteps: 1,064,159,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1064159834...
Checkpoint 1064159834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.71388
Value Function Loss: 0.01563

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14610
Policy Update Magnitude: 0.43832
Value Function Update Magnitude: 0.38951

Collected Steps per Second: 23,008.15902
Overall Steps per Second: 10,722.85942

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.49079
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.66480

Cumulative Model Updates: 127,622
Cumulative Timesteps: 1,064,209,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.71292
Value Function Loss: 0.01850

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.41596
Value Function Update Magnitude: 0.32765

Collected Steps per Second: 22,932.95956
Overall Steps per Second: 10,859.02485

Timestep Collection Time: 2.18114
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60631

Cumulative Model Updates: 127,628
Cumulative Timesteps: 1,064,259,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1064259874...
Checkpoint 1064259874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,782.19227
Policy Entropy: 3.71536
Value Function Loss: 0.01766

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.41619
Value Function Update Magnitude: 0.29997

Collected Steps per Second: 22,743.66332
Overall Steps per Second: 10,636.71499

Timestep Collection Time: 2.19929
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70258

Cumulative Model Updates: 127,634
Cumulative Timesteps: 1,064,309,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,548.86077
Policy Entropy: 3.70691
Value Function Loss: 0.01896

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.42386
Value Function Update Magnitude: 0.52591

Collected Steps per Second: 23,013.04832
Overall Steps per Second: 10,904.70814

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.41327
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.58664

Cumulative Model Updates: 127,640
Cumulative Timesteps: 1,064,359,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1064359910...
Checkpoint 1064359910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,990.78746
Policy Entropy: 3.72604
Value Function Loss: 0.01800

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.45724
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 22,852.95175
Overall Steps per Second: 10,702.84680

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.67427

Cumulative Model Updates: 127,646
Cumulative Timesteps: 1,064,409,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,498.62454
Policy Entropy: 3.72827
Value Function Loss: 0.01868

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.48405
Value Function Update Magnitude: 0.63442

Collected Steps per Second: 22,389.57457
Overall Steps per Second: 10,944.09419

Timestep Collection Time: 2.23408
Timestep Consumption Time: 2.33643
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.57050

Cumulative Model Updates: 127,652
Cumulative Timesteps: 1,064,459,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1064459958...
Checkpoint 1064459958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,967.04514
Policy Entropy: 3.74213
Value Function Loss: 0.01867

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.70379

Collected Steps per Second: 21,744.11521
Overall Steps per Second: 10,599.76596

Timestep Collection Time: 2.30048
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71916

Cumulative Model Updates: 127,658
Cumulative Timesteps: 1,064,509,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,569.30858
Policy Entropy: 3.72954
Value Function Loss: 0.01995

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.74002

Collected Steps per Second: 22,035.81997
Overall Steps per Second: 10,818.46640

Timestep Collection Time: 2.26921
Timestep Consumption Time: 2.35288
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.62210

Cumulative Model Updates: 127,664
Cumulative Timesteps: 1,064,559,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1064559984...
Checkpoint 1064559984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,910.12438
Policy Entropy: 3.73107
Value Function Loss: 0.02107

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.70011

Collected Steps per Second: 22,140.83661
Overall Steps per Second: 10,763.38814

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.38902
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.64909

Cumulative Model Updates: 127,670
Cumulative Timesteps: 1,064,610,024

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,603.68572
Policy Entropy: 3.74108
Value Function Loss: 0.02010

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.69779

Collected Steps per Second: 23,210.02970
Overall Steps per Second: 10,859.48551

Timestep Collection Time: 2.15510
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.60611

Cumulative Model Updates: 127,676
Cumulative Timesteps: 1,064,660,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1064660044...
Checkpoint 1064660044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,315.94224
Policy Entropy: 3.74544
Value Function Loss: 0.01941

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.59941

Collected Steps per Second: 22,726.70999
Overall Steps per Second: 10,721.71957

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.66567

Cumulative Model Updates: 127,682
Cumulative Timesteps: 1,064,710,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.20025
Policy Entropy: 3.74969
Value Function Loss: 0.01661

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14675
Policy Update Magnitude: 0.48662
Value Function Update Magnitude: 0.59485

Collected Steps per Second: 23,176.89439
Overall Steps per Second: 10,826.01738

Timestep Collection Time: 2.15801
Timestep Consumption Time: 2.46197
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.61998

Cumulative Model Updates: 127,688
Cumulative Timesteps: 1,064,760,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1064760084...
Checkpoint 1064760084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.20025
Policy Entropy: 3.73765
Value Function Loss: 0.01612

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.42970
Value Function Update Magnitude: 0.47097

Collected Steps per Second: 22,836.29527
Overall Steps per Second: 10,687.47772

Timestep Collection Time: 2.18993
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.67931

Cumulative Model Updates: 127,694
Cumulative Timesteps: 1,064,810,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.20025
Policy Entropy: 3.73316
Value Function Loss: 0.01572

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.43928
Value Function Update Magnitude: 0.39246

Collected Steps per Second: 22,933.25010
Overall Steps per Second: 10,870.64175

Timestep Collection Time: 2.18050
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.60010

Cumulative Model Updates: 127,700
Cumulative Timesteps: 1,064,860,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1064860100...
Checkpoint 1064860100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.20025
Policy Entropy: 3.72633
Value Function Loss: 0.01812

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.44897
Value Function Update Magnitude: 0.39353

Collected Steps per Second: 22,789.00671
Overall Steps per Second: 10,669.79293

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.49219
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.68631

Cumulative Model Updates: 127,706
Cumulative Timesteps: 1,064,910,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,450.89751
Policy Entropy: 3.73438
Value Function Loss: 0.01772

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.46853
Value Function Update Magnitude: 0.40850

Collected Steps per Second: 23,223.83371
Overall Steps per Second: 10,876.19015

Timestep Collection Time: 2.15322
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.59775

Cumulative Model Updates: 127,712
Cumulative Timesteps: 1,064,960,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1064960108...
Checkpoint 1064960108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,546.82619
Policy Entropy: 3.73102
Value Function Loss: 0.02127

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.49874
Value Function Update Magnitude: 0.57696

Collected Steps per Second: 22,699.20328
Overall Steps per Second: 10,660.91080

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.48751
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.69041

Cumulative Model Updates: 127,718
Cumulative Timesteps: 1,065,010,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,061.94348
Policy Entropy: 3.73363
Value Function Loss: 0.02028

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.52080
Value Function Update Magnitude: 0.78338

Collected Steps per Second: 22,912.25483
Overall Steps per Second: 10,836.76887

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61743

Cumulative Model Updates: 127,724
Cumulative Timesteps: 1,065,060,150

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1065060150...
Checkpoint 1065060150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,061.94348
Policy Entropy: 3.73457
Value Function Loss: 0.02204

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14787
Policy Update Magnitude: 0.53092
Value Function Update Magnitude: 0.66585

Collected Steps per Second: 22,422.28359
Overall Steps per Second: 10,649.87308

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.46566
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.69621

Cumulative Model Updates: 127,730
Cumulative Timesteps: 1,065,110,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,821.34977
Policy Entropy: 3.74751
Value Function Loss: 0.02149

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.56070
Value Function Update Magnitude: 0.66712

Collected Steps per Second: 22,854.33485
Overall Steps per Second: 10,854.40108

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.60698

Cumulative Model Updates: 127,736
Cumulative Timesteps: 1,065,160,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1065160170...
Checkpoint 1065160170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230,249.10367
Policy Entropy: 3.74345
Value Function Loss: 0.02185

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.62896
Value Function Update Magnitude: 0.77763

Collected Steps per Second: 22,476.27892
Overall Steps per Second: 10,776.37950

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.41531
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.63996

Cumulative Model Updates: 127,742
Cumulative Timesteps: 1,065,210,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.72079
Value Function Loss: 0.02428

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.60171
Value Function Update Magnitude: 0.73413

Collected Steps per Second: 22,847.73880
Overall Steps per Second: 10,844.41001

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61288

Cumulative Model Updates: 127,748
Cumulative Timesteps: 1,065,260,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1065260196...
Checkpoint 1065260196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.71319
Value Function Loss: 0.02374

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.59118
Value Function Update Magnitude: 0.63567

Collected Steps per Second: 22,592.06232
Overall Steps per Second: 10,621.19459

Timestep Collection Time: 2.21317
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.70757

Cumulative Model Updates: 127,754
Cumulative Timesteps: 1,065,310,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.71396
Value Function Loss: 0.02315

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.58324
Value Function Update Magnitude: 0.48830

Collected Steps per Second: 22,866.45864
Overall Steps per Second: 10,859.09649

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.41841
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.60554

Cumulative Model Updates: 127,760
Cumulative Timesteps: 1,065,360,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1065360208...
Checkpoint 1065360208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.71447
Value Function Loss: 0.02052

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14558
Policy Update Magnitude: 0.53397
Value Function Update Magnitude: 0.40762

Collected Steps per Second: 22,599.33669
Overall Steps per Second: 10,725.53651

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.45020
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.66345

Cumulative Model Updates: 127,766
Cumulative Timesteps: 1,065,410,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.73018
Value Function Loss: 0.01823

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14953
Policy Update Magnitude: 0.46730
Value Function Update Magnitude: 0.42034

Collected Steps per Second: 22,300.44903
Overall Steps per Second: 10,901.40580

Timestep Collection Time: 2.24336
Timestep Consumption Time: 2.34577
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58913

Cumulative Model Updates: 127,772
Cumulative Timesteps: 1,065,460,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1065460254...
Checkpoint 1065460254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,366.63341
Policy Entropy: 3.73535
Value Function Loss: 0.01783

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14767
Policy Update Magnitude: 0.42578
Value Function Update Magnitude: 0.35514

Collected Steps per Second: 21,815.35980
Overall Steps per Second: 10,621.04151

Timestep Collection Time: 2.29288
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.70952

Cumulative Model Updates: 127,778
Cumulative Timesteps: 1,065,510,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324,776.37410
Policy Entropy: 3.75901
Value Function Loss: 0.01795

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.45287
Value Function Update Magnitude: 0.41560

Collected Steps per Second: 22,391.89369
Overall Steps per Second: 10,947.37111

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.33520
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.56895

Cumulative Model Updates: 127,784
Cumulative Timesteps: 1,065,560,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1065560292...
Checkpoint 1065560292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386,094.11917
Policy Entropy: 3.76334
Value Function Loss: 0.02091

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.54187

Collected Steps per Second: 22,588.65906
Overall Steps per Second: 10,696.74830

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67507

Cumulative Model Updates: 127,790
Cumulative Timesteps: 1,065,610,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,851.64084
Policy Entropy: 3.77326
Value Function Loss: 0.02264

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.70332

Collected Steps per Second: 23,190.00581
Overall Steps per Second: 10,795.50083

Timestep Collection Time: 2.15722
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.63397

Cumulative Model Updates: 127,796
Cumulative Timesteps: 1,065,660,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1065660326...
Checkpoint 1065660326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,532.91193
Policy Entropy: 3.76843
Value Function Loss: 0.02208

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.76121

Collected Steps per Second: 22,861.08692
Overall Steps per Second: 10,760.24414

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.46030
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.64804

Cumulative Model Updates: 127,802
Cumulative Timesteps: 1,065,710,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,301.85833
Policy Entropy: 3.76321
Value Function Loss: 0.01985

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.53350
Value Function Update Magnitude: 0.71330

Collected Steps per Second: 23,067.39853
Overall Steps per Second: 10,832.28497

Timestep Collection Time: 2.16808
Timestep Consumption Time: 2.44886
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61694

Cumulative Model Updates: 127,808
Cumulative Timesteps: 1,065,760,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1065760352...
Checkpoint 1065760352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,183.85312
Policy Entropy: 3.75012
Value Function Loss: 0.01826

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.51823
Value Function Update Magnitude: 0.68575

Collected Steps per Second: 23,091.63568
Overall Steps per Second: 10,796.80475

Timestep Collection Time: 2.16607
Timestep Consumption Time: 2.46660
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.63267

Cumulative Model Updates: 127,814
Cumulative Timesteps: 1,065,810,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903,802.65201
Policy Entropy: 3.75264
Value Function Loss: 0.02057

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.79211

Collected Steps per Second: 22,966.76704
Overall Steps per Second: 10,721.07277

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.48665
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.66371

Cumulative Model Updates: 127,820
Cumulative Timesteps: 1,065,860,370

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1065860370...
Checkpoint 1065860370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,698.66287
Policy Entropy: 3.75806
Value Function Loss: 0.02213

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.59293
Value Function Update Magnitude: 0.88780

Collected Steps per Second: 22,722.70401
Overall Steps per Second: 10,606.21569

Timestep Collection Time: 2.20123
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71591

Cumulative Model Updates: 127,826
Cumulative Timesteps: 1,065,910,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 481,119.47847
Policy Entropy: 3.76361
Value Function Loss: 0.02291

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.62694
Value Function Update Magnitude: 0.89550

Collected Steps per Second: 22,680.03536
Overall Steps per Second: 10,698.52900

Timestep Collection Time: 2.20564
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67578

Cumulative Model Updates: 127,832
Cumulative Timesteps: 1,065,960,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1065960412...
Checkpoint 1065960412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770,099.18542
Policy Entropy: 3.75880
Value Function Loss: 0.02265

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.60126
Value Function Update Magnitude: 0.85057

Collected Steps per Second: 22,809.47577
Overall Steps per Second: 10,854.64312

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.41551
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60872

Cumulative Model Updates: 127,838
Cumulative Timesteps: 1,066,010,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,514.32160
Policy Entropy: 3.73921
Value Function Loss: 0.02251

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.62550
Value Function Update Magnitude: 0.73309

Collected Steps per Second: 22,723.53472
Overall Steps per Second: 10,830.44812

Timestep Collection Time: 2.20098
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.61791

Cumulative Model Updates: 127,844
Cumulative Timesteps: 1,066,060,452

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1066060452...
Checkpoint 1066060452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,608.92423
Policy Entropy: 3.74758
Value Function Loss: 0.02299

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.59848
Value Function Update Magnitude: 0.62779

Collected Steps per Second: 22,710.33926
Overall Steps per Second: 10,710.88179

Timestep Collection Time: 2.20287
Timestep Consumption Time: 2.46789
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.67076

Cumulative Model Updates: 127,850
Cumulative Timesteps: 1,066,110,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,608.92423
Policy Entropy: 3.73909
Value Function Loss: 0.02056

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.55150
Value Function Update Magnitude: 0.62806

Collected Steps per Second: 22,614.09454
Overall Steps per Second: 10,634.91366

Timestep Collection Time: 2.21128
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70206

Cumulative Model Updates: 127,856
Cumulative Timesteps: 1,066,160,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1066160486...
Checkpoint 1066160486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,608.92423
Policy Entropy: 3.74112
Value Function Loss: 0.02077

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.49811
Value Function Update Magnitude: 0.54164

Collected Steps per Second: 22,204.47317
Overall Steps per Second: 10,861.32581

Timestep Collection Time: 2.25189
Timestep Consumption Time: 2.35179
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.60367

Cumulative Model Updates: 127,862
Cumulative Timesteps: 1,066,210,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,608.92423
Policy Entropy: 3.73130
Value Function Loss: 0.01878

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.48424
Value Function Update Magnitude: 0.55246

Collected Steps per Second: 20,810.12904
Overall Steps per Second: 10,412.74706

Timestep Collection Time: 2.40383
Timestep Consumption Time: 2.40028
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.80411

Cumulative Model Updates: 127,868
Cumulative Timesteps: 1,066,260,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1066260512...
Checkpoint 1066260512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,755.85052
Policy Entropy: 3.72431
Value Function Loss: 0.02236

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.50018
Value Function Update Magnitude: 0.60472

Collected Steps per Second: 21,816.95536
Overall Steps per Second: 10,809.94650

Timestep Collection Time: 2.29308
Timestep Consumption Time: 2.33488
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.62796

Cumulative Model Updates: 127,874
Cumulative Timesteps: 1,066,310,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205,371.34209
Policy Entropy: 3.73276
Value Function Loss: 0.02354

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.65016

Collected Steps per Second: 22,267.91857
Overall Steps per Second: 10,599.38445

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.72046

Cumulative Model Updates: 127,880
Cumulative Timesteps: 1,066,360,574

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1066360574...
Checkpoint 1066360574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,739.58460
Policy Entropy: 3.73764
Value Function Loss: 0.02751

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.60123
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 22,917.94291
Overall Steps per Second: 10,954.21624

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.38419
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.56719

Cumulative Model Updates: 127,886
Cumulative Timesteps: 1,066,410,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,258.65933
Policy Entropy: 3.75173
Value Function Loss: 0.02680

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.60429
Value Function Update Magnitude: 0.57531

Collected Steps per Second: 23,030.92562
Overall Steps per Second: 10,892.83720

Timestep Collection Time: 2.17178
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59182

Cumulative Model Updates: 127,892
Cumulative Timesteps: 1,066,460,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1066460622...
Checkpoint 1066460622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,204.81267
Policy Entropy: 3.75512
Value Function Loss: 0.02617

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.57129

Collected Steps per Second: 22,846.54291
Overall Steps per Second: 10,649.29590

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.69552

Cumulative Model Updates: 127,898
Cumulative Timesteps: 1,066,510,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,299.67256
Policy Entropy: 3.76006
Value Function Loss: 0.02393

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.60763

Collected Steps per Second: 22,818.16263
Overall Steps per Second: 10,853.50601

Timestep Collection Time: 2.19159
Timestep Consumption Time: 2.41596
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60754

Cumulative Model Updates: 127,904
Cumulative Timesteps: 1,066,560,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1066560634...
Checkpoint 1066560634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600,681.28507
Policy Entropy: 3.75191
Value Function Loss: 0.02322

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.52696
Value Function Update Magnitude: 0.58078

Collected Steps per Second: 22,722.01591
Overall Steps per Second: 10,711.00450

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.66922

Cumulative Model Updates: 127,910
Cumulative Timesteps: 1,066,610,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,091.67413
Policy Entropy: 3.74715
Value Function Loss: 0.02252

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.63508

Collected Steps per Second: 22,829.01567
Overall Steps per Second: 10,826.83682

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61871

Cumulative Model Updates: 127,916
Cumulative Timesteps: 1,066,660,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1066660652...
Checkpoint 1066660652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,632.80364
Policy Entropy: 3.74658
Value Function Loss: 0.02240

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.68188

Collected Steps per Second: 22,900.59274
Overall Steps per Second: 10,680.33111

Timestep Collection Time: 2.18335
Timestep Consumption Time: 2.49815
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68150

Cumulative Model Updates: 127,922
Cumulative Timesteps: 1,066,710,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,104.70107
Policy Entropy: 3.74822
Value Function Loss: 0.02272

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13743
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.63902

Collected Steps per Second: 22,436.82011
Overall Steps per Second: 10,601.62606

Timestep Collection Time: 2.22875
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.71682

Cumulative Model Updates: 127,928
Cumulative Timesteps: 1,066,760,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1066760658...
Checkpoint 1066760658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,134.05944
Policy Entropy: 3.75699
Value Function Loss: 0.02151

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.56990

Collected Steps per Second: 22,920.14067
Overall Steps per Second: 10,878.33496

Timestep Collection Time: 2.18210
Timestep Consumption Time: 2.41548
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.59758

Cumulative Model Updates: 127,934
Cumulative Timesteps: 1,066,810,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,490.55526
Policy Entropy: 3.75716
Value Function Loss: 0.02167

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.49481
Value Function Update Magnitude: 0.66659

Collected Steps per Second: 22,232.96609
Overall Steps per Second: 10,772.93110

Timestep Collection Time: 2.25017
Timestep Consumption Time: 2.39369
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.64386

Cumulative Model Updates: 127,940
Cumulative Timesteps: 1,066,860,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1066860700...
Checkpoint 1066860700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.17154
Policy Entropy: 3.76637
Value Function Loss: 0.02016

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.74004

Collected Steps per Second: 22,087.61275
Overall Steps per Second: 10,842.97886

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.34879
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61368

Cumulative Model Updates: 127,946
Cumulative Timesteps: 1,066,910,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,866.24841
Policy Entropy: 3.75613
Value Function Loss: 0.02119

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.71736

Collected Steps per Second: 22,033.08909
Overall Steps per Second: 10,534.95060

Timestep Collection Time: 2.27068
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.74895

Cumulative Model Updates: 127,952
Cumulative Timesteps: 1,066,960,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1066960756...
Checkpoint 1066960756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,162.87538
Policy Entropy: 3.74788
Value Function Loss: 0.02112

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.73082

Collected Steps per Second: 22,955.26707
Overall Steps per Second: 10,934.20999

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.39485
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.57317

Cumulative Model Updates: 127,958
Cumulative Timesteps: 1,067,010,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,005.53877
Policy Entropy: 3.73958
Value Function Loss: 0.02254

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.53281
Value Function Update Magnitude: 0.63822

Collected Steps per Second: 22,657.21957
Overall Steps per Second: 10,718.21561

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66570

Cumulative Model Updates: 127,964
Cumulative Timesteps: 1,067,060,768

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1067060768...
Checkpoint 1067060768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674,156.50064
Policy Entropy: 3.74564
Value Function Loss: 0.02468

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.57726

Collected Steps per Second: 23,376.38623
Overall Steps per Second: 10,962.41348

Timestep Collection Time: 2.13908
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.56140

Cumulative Model Updates: 127,970
Cumulative Timesteps: 1,067,110,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,233.00939
Policy Entropy: 3.75708
Value Function Loss: 0.02278

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.58439
Value Function Update Magnitude: 0.76827

Collected Steps per Second: 22,500.21905
Overall Steps per Second: 10,646.30232

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.70097

Cumulative Model Updates: 127,976
Cumulative Timesteps: 1,067,160,820

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1067160820...
Checkpoint 1067160820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,989.46898
Policy Entropy: 3.75605
Value Function Loss: 0.02476

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.59887
Value Function Update Magnitude: 0.87579

Collected Steps per Second: 22,794.49911
Overall Steps per Second: 10,838.72943

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61364

Cumulative Model Updates: 127,982
Cumulative Timesteps: 1,067,210,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,772.57209
Policy Entropy: 3.77359
Value Function Loss: 0.02500

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.78907

Collected Steps per Second: 22,583.53939
Overall Steps per Second: 10,650.78394

Timestep Collection Time: 2.21453
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69562

Cumulative Model Updates: 127,988
Cumulative Timesteps: 1,067,260,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1067260838...
Checkpoint 1067260838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,165.06875
Policy Entropy: 3.75218
Value Function Loss: 0.02896

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.70253

Collected Steps per Second: 23,094.70955
Overall Steps per Second: 10,902.86305

Timestep Collection Time: 2.16569
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58742

Cumulative Model Updates: 127,994
Cumulative Timesteps: 1,067,310,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,278.35911
Policy Entropy: 3.76879
Value Function Loss: 0.02746

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.59110
Value Function Update Magnitude: 0.68143

Collected Steps per Second: 22,470.55434
Overall Steps per Second: 10,666.51540

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68944

Cumulative Model Updates: 128,000
Cumulative Timesteps: 1,067,360,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1067360874...
Checkpoint 1067360874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,658.18733
Policy Entropy: 3.76218
Value Function Loss: 0.03029

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.63126
Value Function Update Magnitude: 0.72040

Collected Steps per Second: 23,150.25340
Overall Steps per Second: 10,973.67172

Timestep Collection Time: 2.16170
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.56037

Cumulative Model Updates: 128,006
Cumulative Timesteps: 1,067,410,918

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,940.70371
Policy Entropy: 3.78425
Value Function Loss: 0.02456

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.66831
Value Function Update Magnitude: 0.74498

Collected Steps per Second: 22,134.10389
Overall Steps per Second: 10,814.13693

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.36576
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.62580

Cumulative Model Updates: 128,012
Cumulative Timesteps: 1,067,460,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1067460942...
Checkpoint 1067460942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,318.39681
Policy Entropy: 3.77855
Value Function Loss: 0.02459

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.67659
Value Function Update Magnitude: 0.76755

Collected Steps per Second: 22,272.82451
Overall Steps per Second: 10,743.71987

Timestep Collection Time: 2.24606
Timestep Consumption Time: 2.41025
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.65630

Cumulative Model Updates: 128,018
Cumulative Timesteps: 1,067,510,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,225.51866
Policy Entropy: 3.77098
Value Function Loss: 0.02244

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.64525
Value Function Update Magnitude: 0.81041

Collected Steps per Second: 22,200.62115
Overall Steps per Second: 10,907.30662

Timestep Collection Time: 2.25318
Timestep Consumption Time: 2.33292
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.58610

Cumulative Model Updates: 128,024
Cumulative Timesteps: 1,067,560,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1067560990...
Checkpoint 1067560990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,576.97651
Policy Entropy: 3.75617
Value Function Loss: 0.02307

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.63799
Value Function Update Magnitude: 0.78146

Collected Steps per Second: 22,459.81185
Overall Steps per Second: 10,571.27822

Timestep Collection Time: 2.22727
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.73207

Cumulative Model Updates: 128,030
Cumulative Timesteps: 1,067,611,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,598.33793
Policy Entropy: 3.73560
Value Function Loss: 0.02301

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.62059
Value Function Update Magnitude: 0.80082

Collected Steps per Second: 22,567.87342
Overall Steps per Second: 10,816.47329

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.40733
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62313

Cumulative Model Updates: 128,036
Cumulative Timesteps: 1,067,661,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1067661020...
Checkpoint 1067661020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,044.41185
Policy Entropy: 3.74013
Value Function Loss: 0.02024

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.59200
Value Function Update Magnitude: 0.84500

Collected Steps per Second: 23,050.54898
Overall Steps per Second: 10,789.21295

Timestep Collection Time: 2.16923
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.63444

Cumulative Model Updates: 128,042
Cumulative Timesteps: 1,067,711,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,044.41185
Policy Entropy: 3.73184
Value Function Loss: 0.02195

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.75009

Collected Steps per Second: 23,089.90012
Overall Steps per Second: 10,918.72485

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.58387

Cumulative Model Updates: 128,048
Cumulative Timesteps: 1,067,761,072

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1067761072...
Checkpoint 1067761072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,390.83599
Policy Entropy: 3.72513
Value Function Loss: 0.02140

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.50459
Value Function Update Magnitude: 0.60032

Collected Steps per Second: 23,042.30815
Overall Steps per Second: 10,773.95379

Timestep Collection Time: 2.17010
Timestep Consumption Time: 2.47110
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.64119

Cumulative Model Updates: 128,054
Cumulative Timesteps: 1,067,811,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,146.39813
Policy Entropy: 3.73332
Value Function Loss: 0.02280

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,889.08867
Overall Steps per Second: 10,736.71291

Timestep Collection Time: 2.18663
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.66158

Cumulative Model Updates: 128,060
Cumulative Timesteps: 1,067,861,126

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1067861126...
Checkpoint 1067861126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,724.22264
Policy Entropy: 3.74477
Value Function Loss: 0.02225

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.51366
Value Function Update Magnitude: 0.64518

Collected Steps per Second: 23,119.45008
Overall Steps per Second: 10,751.95283

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.48903
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.65292

Cumulative Model Updates: 128,066
Cumulative Timesteps: 1,067,911,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,304.94721
Policy Entropy: 3.75962
Value Function Loss: 0.02209

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14042
Policy Update Magnitude: 0.54077
Value Function Update Magnitude: 0.69071

Collected Steps per Second: 22,698.92857
Overall Steps per Second: 10,837.45377

Timestep Collection Time: 2.20328
Timestep Consumption Time: 2.41146
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.61474

Cumulative Model Updates: 128,072
Cumulative Timesteps: 1,067,961,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1067961166...
Checkpoint 1067961166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,502.07221
Policy Entropy: 3.74898
Value Function Loss: 0.02320

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14907
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.72807

Collected Steps per Second: 22,672.30249
Overall Steps per Second: 10,664.04923

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.68978

Cumulative Model Updates: 128,078
Cumulative Timesteps: 1,068,011,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,919.70079
Policy Entropy: 3.73677
Value Function Loss: 0.02145

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.71702

Collected Steps per Second: 22,735.45220
Overall Steps per Second: 10,770.27975

Timestep Collection Time: 2.20035
Timestep Consumption Time: 2.44447
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.64482

Cumulative Model Updates: 128,084
Cumulative Timesteps: 1,068,061,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1068061204...
Checkpoint 1068061204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,103.96804
Policy Entropy: 3.74798
Value Function Loss: 0.02066

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.57585
Value Function Update Magnitude: 0.70736

Collected Steps per Second: 22,537.51856
Overall Steps per Second: 10,673.10245

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.46674
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.68580

Cumulative Model Updates: 128,090
Cumulative Timesteps: 1,068,111,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,476.34542
Policy Entropy: 3.73930
Value Function Loss: 0.02029

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.55307
Value Function Update Magnitude: 0.60263

Collected Steps per Second: 22,816.49550
Overall Steps per Second: 10,822.41879

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.62133

Cumulative Model Updates: 128,096
Cumulative Timesteps: 1,068,161,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1068161230...
Checkpoint 1068161230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,533.39044
Policy Entropy: 3.75116
Value Function Loss: 0.02146

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.16722
Policy Update Magnitude: 0.51476
Value Function Update Magnitude: 0.57211

Collected Steps per Second: 21,380.38871
Overall Steps per Second: 10,279.21185

Timestep Collection Time: 2.33962
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.86633

Cumulative Model Updates: 128,102
Cumulative Timesteps: 1,068,211,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,402.16090
Policy Entropy: 3.75519
Value Function Loss: 0.02119

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.16000
Policy Update Magnitude: 0.50872
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 22,557.47467
Overall Steps per Second: 10,668.98691

Timestep Collection Time: 2.21674
Timestep Consumption Time: 2.47012
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.68686

Cumulative Model Updates: 128,108
Cumulative Timesteps: 1,068,261,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1068261256...
Checkpoint 1068261256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,009.96495
Policy Entropy: 3.75831
Value Function Loss: 0.02255

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.53636
Value Function Update Magnitude: 0.62634

Collected Steps per Second: 22,961.81306
Overall Steps per Second: 10,858.65668

Timestep Collection Time: 2.17770
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60499

Cumulative Model Updates: 128,114
Cumulative Timesteps: 1,068,311,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,681.05666
Policy Entropy: 3.76187
Value Function Loss: 0.02203

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15340
Policy Update Magnitude: 0.61301
Value Function Update Magnitude: 0.61243

Collected Steps per Second: 22,103.11267
Overall Steps per Second: 10,858.29474

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.34284
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.60514

Cumulative Model Updates: 128,120
Cumulative Timesteps: 1,068,361,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1068361264...
Checkpoint 1068361264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,200.41558
Policy Entropy: 3.75998
Value Function Loss: 0.02322

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.64596
Value Function Update Magnitude: 0.76189

Collected Steps per Second: 22,216.23069
Overall Steps per Second: 10,711.64117

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.66931

Cumulative Model Updates: 128,126
Cumulative Timesteps: 1,068,411,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,882.19896
Policy Entropy: 3.78346
Value Function Loss: 0.02127

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.19498
Policy Update Magnitude: 0.62554
Value Function Update Magnitude: 0.87288

Collected Steps per Second: 22,305.86550
Overall Steps per Second: 10,896.15399

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.34815
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.59061

Cumulative Model Updates: 128,132
Cumulative Timesteps: 1,068,461,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1068461300...
Checkpoint 1068461300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,846.87460
Policy Entropy: 3.80386
Value Function Loss: 0.02614

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.71889
Value Function Update Magnitude: 0.89939

Collected Steps per Second: 22,173.11313
Overall Steps per Second: 10,682.56682

Timestep Collection Time: 2.25616
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.68296

Cumulative Model Updates: 128,138
Cumulative Timesteps: 1,068,511,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,441.44566
Policy Entropy: 3.79141
Value Function Loss: 0.02738

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15170
Policy Update Magnitude: 0.77151
Value Function Update Magnitude: 0.78657

Collected Steps per Second: 21,999.35751
Overall Steps per Second: 10,542.47199

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.74519

Cumulative Model Updates: 128,144
Cumulative Timesteps: 1,068,561,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1068561352...
Checkpoint 1068561352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,015.07239
Policy Entropy: 3.78729
Value Function Loss: 0.02566

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.14952
Policy Update Magnitude: 0.73605
Value Function Update Magnitude: 0.67923

Collected Steps per Second: 22,860.63844
Overall Steps per Second: 10,904.74631

Timestep Collection Time: 2.18725
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.58534

Cumulative Model Updates: 128,150
Cumulative Timesteps: 1,068,611,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,495.62115
Policy Entropy: 3.78580
Value Function Loss: 0.02506

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.16723
Policy Update Magnitude: 0.71627
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 22,913.44971
Overall Steps per Second: 10,894.15759

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.40749
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.58962

Cumulative Model Updates: 128,156
Cumulative Timesteps: 1,068,661,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1068661354...
Checkpoint 1068661354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,269.52368
Policy Entropy: 3.79926
Value Function Loss: 0.02447

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.70447
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 22,701.53845
Overall Steps per Second: 10,721.52263

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.66482

Cumulative Model Updates: 128,162
Cumulative Timesteps: 1,068,711,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,601.88659
Policy Entropy: 3.78414
Value Function Loss: 0.02483

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.76611
Value Function Update Magnitude: 0.67655

Collected Steps per Second: 22,164.51186
Overall Steps per Second: 10,521.00490

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75468

Cumulative Model Updates: 128,168
Cumulative Timesteps: 1,068,761,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1068761392...
Checkpoint 1068761392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,601.88659
Policy Entropy: 3.75929
Value Function Loss: 0.02489

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.72172
Value Function Update Magnitude: 0.57978

Collected Steps per Second: 22,509.93822
Overall Steps per Second: 10,577.65398

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.72846

Cumulative Model Updates: 128,174
Cumulative Timesteps: 1,068,811,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,601.88659
Policy Entropy: 3.77666
Value Function Loss: 0.02061

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.64961
Value Function Update Magnitude: 0.38077

Collected Steps per Second: 22,575.50989
Overall Steps per Second: 10,645.49967

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.69682

Cumulative Model Updates: 128,180
Cumulative Timesteps: 1,068,861,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1068861408...
Checkpoint 1068861408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,603.39413
Policy Entropy: 3.77408
Value Function Loss: 0.01628

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07839
Policy Update Magnitude: 0.60437
Value Function Update Magnitude: 0.39021

Collected Steps per Second: 23,083.42167
Overall Steps per Second: 10,932.75855

Timestep Collection Time: 2.16710
Timestep Consumption Time: 2.40851
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.57561

Cumulative Model Updates: 128,186
Cumulative Timesteps: 1,068,911,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,697.27948
Policy Entropy: 3.77324
Value Function Loss: 0.01786

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.56403
Value Function Update Magnitude: 0.48770

Collected Steps per Second: 22,545.36464
Overall Steps per Second: 10,782.69302

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.63929

Cumulative Model Updates: 128,192
Cumulative Timesteps: 1,068,961,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1068961456...
Checkpoint 1068961456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,105.69867
Policy Entropy: 3.79170
Value Function Loss: 0.01850

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.57975

Collected Steps per Second: 22,206.91864
Overall Steps per Second: 10,760.35211

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.39629
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.64892

Cumulative Model Updates: 128,198
Cumulative Timesteps: 1,069,011,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,795.17728
Policy Entropy: 3.75958
Value Function Loss: 0.02650

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.64997

Collected Steps per Second: 21,210.82733
Overall Steps per Second: 10,431.72940

Timestep Collection Time: 2.35889
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.79633

Cumulative Model Updates: 128,204
Cumulative Timesteps: 1,069,061,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1069061514...
Checkpoint 1069061514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,866.35529
Policy Entropy: 3.75428
Value Function Loss: 0.02565

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.17683
Policy Update Magnitude: 0.55857
Value Function Update Magnitude: 0.56911

Collected Steps per Second: 21,651.45239
Overall Steps per Second: 10,651.52487

Timestep Collection Time: 2.31033
Timestep Consumption Time: 2.38590
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.69623

Cumulative Model Updates: 128,210
Cumulative Timesteps: 1,069,111,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,908.68773
Policy Entropy: 3.72890
Value Function Loss: 0.02704

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16719
Policy Update Magnitude: 0.64044
Value Function Update Magnitude: 0.52823

Collected Steps per Second: 21,512.62170
Overall Steps per Second: 10,477.69214

Timestep Collection Time: 2.32496
Timestep Consumption Time: 2.44861
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.77357

Cumulative Model Updates: 128,216
Cumulative Timesteps: 1,069,161,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1069161552...
Checkpoint 1069161552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,192.07724
Policy Entropy: 3.77149
Value Function Loss: 0.01983

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16383
Policy Update Magnitude: 0.59585
Value Function Update Magnitude: 0.62504

Collected Steps per Second: 22,020.29784
Overall Steps per Second: 10,560.44770

Timestep Collection Time: 2.27163
Timestep Consumption Time: 2.46510
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.73673

Cumulative Model Updates: 128,222
Cumulative Timesteps: 1,069,211,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,850.61693
Policy Entropy: 3.74565
Value Function Loss: 0.02741

Mean KL Divergence: 0.02861
SB3 Clip Fraction: 0.28407
Policy Update Magnitude: 0.48141
Value Function Update Magnitude: 0.55748

Collected Steps per Second: 22,673.50135
Overall Steps per Second: 10,780.81671

Timestep Collection Time: 2.20610
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.63972

Cumulative Model Updates: 128,228
Cumulative Timesteps: 1,069,261,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1069261594...
Checkpoint 1069261594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,099.93139
Policy Entropy: 3.77162
Value Function Loss: 0.03719

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.17281
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.56877

Collected Steps per Second: 22,428.96974
Overall Steps per Second: 10,610.96751

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.48443
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71512

Cumulative Model Updates: 128,234
Cumulative Timesteps: 1,069,311,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650,405.51067
Policy Entropy: 3.73258
Value Function Loss: 0.05721

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.16841
Policy Update Magnitude: 0.72970
Value Function Update Magnitude: 0.58746

Collected Steps per Second: 18,281.83827
Overall Steps per Second: 8,239.71290

Timestep Collection Time: 2.73660
Timestep Consumption Time: 3.33522
PPO Batch Consumption Time: 0.42571
Total Iteration Time: 6.07181

Cumulative Model Updates: 128,240
Cumulative Timesteps: 1,069,361,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1069361656...
Checkpoint 1069361656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,123.90277
Policy Entropy: 3.73598
Value Function Loss: 0.04950

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.83238
Value Function Update Magnitude: 0.54971

Collected Steps per Second: 14,862.27495
Overall Steps per Second: 8,493.02155

Timestep Collection Time: 3.36732
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 5.89260

Cumulative Model Updates: 128,246
Cumulative Timesteps: 1,069,411,702

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.22152
Policy Entropy: 3.77077
Value Function Loss: 0.04067

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09550
Policy Update Magnitude: 1.08207
Value Function Update Magnitude: 0.56972

Collected Steps per Second: 21,987.45682
Overall Steps per Second: 10,461.36896

Timestep Collection Time: 2.27448
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.78045

Cumulative Model Updates: 128,252
Cumulative Timesteps: 1,069,461,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1069461712...
Checkpoint 1069461712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.80790
Policy Entropy: 3.80875
Value Function Loss: 0.02784

Mean KL Divergence: 0.00647
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 1.01145
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 16,707.16763
Overall Steps per Second: 9,163.68152

Timestep Collection Time: 2.99404
Timestep Consumption Time: 2.46468
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 5.45872

Cumulative Model Updates: 128,258
Cumulative Timesteps: 1,069,511,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.68976
Policy Entropy: 3.83543
Value Function Loss: 0.02408

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.83522
Value Function Update Magnitude: 0.59116

Collected Steps per Second: 22,531.51863
Overall Steps per Second: 10,822.55952

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.40202
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.62220

Cumulative Model Updates: 128,264
Cumulative Timesteps: 1,069,561,758

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1069561758...
Checkpoint 1069561758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.92006
Policy Entropy: 3.80399
Value Function Loss: 0.02030

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06312
Policy Update Magnitude: 0.69928
Value Function Update Magnitude: 0.65654

Collected Steps per Second: 16,428.17161
Overall Steps per Second: 8,950.94601

Timestep Collection Time: 3.04404
Timestep Consumption Time: 2.54286
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 5.58690

Cumulative Model Updates: 128,270
Cumulative Timesteps: 1,069,611,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.92006
Policy Entropy: 3.78162
Value Function Loss: 0.01792

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06769
Policy Update Magnitude: 0.64044
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,449.70398
Overall Steps per Second: 10,513.60108

Timestep Collection Time: 2.22765
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.75670

Cumulative Model Updates: 128,276
Cumulative Timesteps: 1,069,661,776

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1069661776...
Checkpoint 1069661776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,665.32767
Policy Entropy: 3.74748
Value Function Loss: 0.01598

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.60607
Value Function Update Magnitude: 0.58672

Collected Steps per Second: 19,756.14318
Overall Steps per Second: 10,062.15583

Timestep Collection Time: 2.53217
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.97170

Cumulative Model Updates: 128,282
Cumulative Timesteps: 1,069,711,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,665.32767
Policy Entropy: 3.74236
Value Function Loss: 0.01700

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.18209
Policy Update Magnitude: 0.50195
Value Function Update Magnitude: 0.55909

Collected Steps per Second: 22,282.59387
Overall Steps per Second: 10,578.98927

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.72692

Cumulative Model Updates: 128,288
Cumulative Timesteps: 1,069,761,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1069761808...
Checkpoint 1069761808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,891.74594
Policy Entropy: 3.72728
Value Function Loss: 0.02539

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.22674
Policy Update Magnitude: 0.53732
Value Function Update Magnitude: 0.67433

Collected Steps per Second: 22,216.20973
Overall Steps per Second: 10,719.70952

Timestep Collection Time: 2.25124
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27547
Total Iteration Time: 4.66561

Cumulative Model Updates: 128,294
Cumulative Timesteps: 1,069,811,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,187.31525
Policy Entropy: 3.70793
Value Function Loss: 0.02990

Mean KL Divergence: 0.01914
SB3 Clip Fraction: 0.22499
Policy Update Magnitude: 0.64804
Value Function Update Magnitude: 0.74043

Collected Steps per Second: 22,497.71499
Overall Steps per Second: 10,738.67043

Timestep Collection Time: 2.22351
Timestep Consumption Time: 2.43479
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.65830

Cumulative Model Updates: 128,300
Cumulative Timesteps: 1,069,861,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1069861846...
Checkpoint 1069861846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,095.54554
Policy Entropy: 3.71635
Value Function Loss: 0.04019

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.17025
Policy Update Magnitude: 0.68182
Value Function Update Magnitude: 0.73757

Collected Steps per Second: 22,034.19645
Overall Steps per Second: 10,607.02072

Timestep Collection Time: 2.26938
Timestep Consumption Time: 2.44485
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.71424

Cumulative Model Updates: 128,306
Cumulative Timesteps: 1,069,911,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,085.47478
Policy Entropy: 3.74681
Value Function Loss: 0.04079

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.75132
Value Function Update Magnitude: 0.73648

Collected Steps per Second: 21,158.39191
Overall Steps per Second: 10,234.41129

Timestep Collection Time: 2.36332
Timestep Consumption Time: 2.52255
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.88587

Cumulative Model Updates: 128,312
Cumulative Timesteps: 1,069,961,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1069961854...
Checkpoint 1069961854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,517.30252
Policy Entropy: 3.75785
Value Function Loss: 0.03940

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.79152
Value Function Update Magnitude: 0.84116

Collected Steps per Second: 22,500.41990
Overall Steps per Second: 10,599.17424

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.71810

Cumulative Model Updates: 128,318
Cumulative Timesteps: 1,070,011,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,281.28277
Policy Entropy: 3.77114
Value Function Loss: 0.03346

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.77546
Value Function Update Magnitude: 0.87325

Collected Steps per Second: 22,891.87156
Overall Steps per Second: 10,787.52886

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.63609

Cumulative Model Updates: 128,324
Cumulative Timesteps: 1,070,061,874

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1070061874...
Checkpoint 1070061874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,413.53004
Policy Entropy: 3.77003
Value Function Loss: 0.03640

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.75108
Value Function Update Magnitude: 0.78490

Collected Steps per Second: 22,788.30417
Overall Steps per Second: 10,673.62118

Timestep Collection Time: 2.19455
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68538

Cumulative Model Updates: 128,330
Cumulative Timesteps: 1,070,111,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,499.66761
Policy Entropy: 3.81547
Value Function Loss: 0.03683

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.77350
Value Function Update Magnitude: 0.75719

Collected Steps per Second: 22,591.95855
Overall Steps per Second: 10,685.15632

Timestep Collection Time: 2.21362
Timestep Consumption Time: 2.46671
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68032

Cumulative Model Updates: 128,336
Cumulative Timesteps: 1,070,161,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1070161894...
Checkpoint 1070161894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,269.97235
Policy Entropy: 3.80314
Value Function Loss: 0.04205

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.74227
Value Function Update Magnitude: 0.72887

Collected Steps per Second: 21,153.75976
Overall Steps per Second: 10,335.47064

Timestep Collection Time: 2.36402
Timestep Consumption Time: 2.47446
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.83848

Cumulative Model Updates: 128,342
Cumulative Timesteps: 1,070,211,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,174.52472
Policy Entropy: 3.81163
Value Function Loss: 0.03641

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.68901
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 22,749.49098
Overall Steps per Second: 10,600.72484

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.71836

Cumulative Model Updates: 128,348
Cumulative Timesteps: 1,070,261,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1070261920...
Checkpoint 1070261920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,943.77333
Policy Entropy: 3.77871
Value Function Loss: 0.03391

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.65393
Value Function Update Magnitude: 0.63657

Collected Steps per Second: 15,983.92824
Overall Steps per Second: 8,921.86846

Timestep Collection Time: 3.12877
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 5.60533

Cumulative Model Updates: 128,354
Cumulative Timesteps: 1,070,311,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,707.52667
Policy Entropy: 3.79948
Value Function Loss: 0.02761

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.63769
Value Function Update Magnitude: 0.67632

Collected Steps per Second: 22,610.98459
Overall Steps per Second: 10,573.40087

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.72998

Cumulative Model Updates: 128,360
Cumulative Timesteps: 1,070,361,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1070361942...
Checkpoint 1070361942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601.26384
Policy Entropy: 3.77369
Value Function Loss: 0.02960

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.60998
Value Function Update Magnitude: 0.66679

Collected Steps per Second: 19,745.88994
Overall Steps per Second: 10,053.37776

Timestep Collection Time: 2.53238
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.97385

Cumulative Model Updates: 128,366
Cumulative Timesteps: 1,070,411,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.26384
Policy Entropy: 3.76980
Value Function Loss: 0.02581

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.66692

Collected Steps per Second: 22,383.91666
Overall Steps per Second: 10,522.63810

Timestep Collection Time: 2.23464
Timestep Consumption Time: 2.51892
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75356

Cumulative Model Updates: 128,372
Cumulative Timesteps: 1,070,461,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1070461966...
Checkpoint 1070461966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,074.88187
Policy Entropy: 3.74412
Value Function Loss: 0.02404

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 15,123.62901
Overall Steps per Second: 8,769.26766

Timestep Collection Time: 3.30608
Timestep Consumption Time: 2.39565
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 5.70173

Cumulative Model Updates: 128,378
Cumulative Timesteps: 1,070,511,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,587.47081
Policy Entropy: 3.75561
Value Function Loss: 0.02370

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.50948
Value Function Update Magnitude: 0.52798

Collected Steps per Second: 22,300.66539
Overall Steps per Second: 10,251.95815

Timestep Collection Time: 2.24244
Timestep Consumption Time: 2.63545
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.87790

Cumulative Model Updates: 128,384
Cumulative Timesteps: 1,070,561,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1070561974...
Checkpoint 1070561974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,713.86483
Policy Entropy: 3.75988
Value Function Loss: 0.02604

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.54853

Collected Steps per Second: 20,316.64335
Overall Steps per Second: 10,117.15562

Timestep Collection Time: 2.46113
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.94230

Cumulative Model Updates: 128,390
Cumulative Timesteps: 1,070,611,976

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.30539
Policy Entropy: 3.76841
Value Function Loss: 0.02858

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 21,549.54445
Overall Steps per Second: 10,490.42704

Timestep Collection Time: 2.32061
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.76701

Cumulative Model Updates: 128,396
Cumulative Timesteps: 1,070,661,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1070661984...
Checkpoint 1070661984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,536.93767
Policy Entropy: 3.76837
Value Function Loss: 0.02593

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.64855

Collected Steps per Second: 20,492.03418
Overall Steps per Second: 10,258.87179

Timestep Collection Time: 2.44056
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.87500

Cumulative Model Updates: 128,402
Cumulative Timesteps: 1,070,711,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.43034
Policy Entropy: 3.76179
Value Function Loss: 0.02272

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.50270
Value Function Update Magnitude: 0.65991

Collected Steps per Second: 21,917.63108
Overall Steps per Second: 10,780.59046

Timestep Collection Time: 2.28282
Timestep Consumption Time: 2.35830
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.64112

Cumulative Model Updates: 128,408
Cumulative Timesteps: 1,070,762,030

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1070762030...
Checkpoint 1070762030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,382.09692
Policy Entropy: 3.76284
Value Function Loss: 0.02166

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.48685
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 21,327.52998
Overall Steps per Second: 10,327.66950

Timestep Collection Time: 2.34458
Timestep Consumption Time: 2.49718
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.84175

Cumulative Model Updates: 128,414
Cumulative Timesteps: 1,070,812,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,400.58246
Policy Entropy: 3.76808
Value Function Loss: 0.02182

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14003
Policy Update Magnitude: 0.49569
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,387.29173
Overall Steps per Second: 10,612.12554

Timestep Collection Time: 2.23404
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.71291

Cumulative Model Updates: 128,420
Cumulative Timesteps: 1,070,862,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1070862048...
Checkpoint 1070862048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,980.30356
Policy Entropy: 3.78170
Value Function Loss: 0.02449

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.49315
Value Function Update Magnitude: 0.55712

Collected Steps per Second: 22,567.05990
Overall Steps per Second: 10,802.38241

Timestep Collection Time: 2.21704
Timestep Consumption Time: 2.41453
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63157

Cumulative Model Updates: 128,426
Cumulative Timesteps: 1,070,912,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.09971
Policy Entropy: 3.77262
Value Function Loss: 0.02100

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.44321
Value Function Update Magnitude: 0.42386

Collected Steps per Second: 22,275.16881
Overall Steps per Second: 10,537.92748

Timestep Collection Time: 2.24465
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74477

Cumulative Model Updates: 128,432
Cumulative Timesteps: 1,070,962,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1070962080...
Checkpoint 1070962080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.57258
Policy Entropy: 3.76232
Value Function Loss: 0.01848

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.40586
Value Function Update Magnitude: 0.46764

Collected Steps per Second: 22,491.91528
Overall Steps per Second: 10,708.01640

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.66940

Cumulative Model Updates: 128,438
Cumulative Timesteps: 1,071,012,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.43601
Policy Entropy: 3.75179
Value Function Loss: 0.01718

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.36649
Value Function Update Magnitude: 0.48085

Collected Steps per Second: 22,714.92968
Overall Steps per Second: 10,611.17873

Timestep Collection Time: 2.20146
Timestep Consumption Time: 2.51112
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71258

Cumulative Model Updates: 128,444
Cumulative Timesteps: 1,071,062,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1071062086...
Checkpoint 1071062086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.43601
Policy Entropy: 3.74978
Value Function Loss: 0.01593

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.34085
Value Function Update Magnitude: 0.49108

Collected Steps per Second: 22,485.88138
Overall Steps per Second: 10,688.89330

Timestep Collection Time: 2.22495
Timestep Consumption Time: 2.45561
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.68056

Cumulative Model Updates: 128,450
Cumulative Timesteps: 1,071,112,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255.43601
Policy Entropy: 3.73832
Value Function Loss: 0.01660

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.34531
Value Function Update Magnitude: 0.57409

Collected Steps per Second: 21,222.58903
Overall Steps per Second: 10,082.86952

Timestep Collection Time: 2.35617
Timestep Consumption Time: 2.60313
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.95930

Cumulative Model Updates: 128,456
Cumulative Timesteps: 1,071,162,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1071162120...
Checkpoint 1071162120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,554.58870
Policy Entropy: 3.75456
Value Function Loss: 0.01554

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.39450
Value Function Update Magnitude: 0.64003

Collected Steps per Second: 21,931.73713
Overall Steps per Second: 10,586.97000

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.72449

Cumulative Model Updates: 128,462
Cumulative Timesteps: 1,071,212,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,648.27384
Policy Entropy: 3.72989
Value Function Loss: 0.01777

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.42164
Value Function Update Magnitude: 0.55568

Collected Steps per Second: 22,531.68016
Overall Steps per Second: 10,523.91182

Timestep Collection Time: 2.21963
Timestep Consumption Time: 2.53260
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.75223

Cumulative Model Updates: 128,468
Cumulative Timesteps: 1,071,262,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1071262150...
Checkpoint 1071262150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,648.27384
Policy Entropy: 3.72629
Value Function Loss: 0.01699

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.44129
Value Function Update Magnitude: 0.55317

Collected Steps per Second: 22,300.32689
Overall Steps per Second: 10,628.07977

Timestep Collection Time: 2.24212
Timestep Consumption Time: 2.46240
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.70452

Cumulative Model Updates: 128,474
Cumulative Timesteps: 1,071,312,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,171.66796
Policy Entropy: 3.70304
Value Function Loss: 0.01917

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.45093
Value Function Update Magnitude: 0.64445

Collected Steps per Second: 22,582.97734
Overall Steps per Second: 10,550.89377

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.52659
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.74216

Cumulative Model Updates: 128,480
Cumulative Timesteps: 1,071,362,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1071362184...
Checkpoint 1071362184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,186.25068
Policy Entropy: 3.72542
Value Function Loss: 0.01789

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.45947
Value Function Update Magnitude: 0.57074

Collected Steps per Second: 22,157.45848
Overall Steps per Second: 10,668.41539

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.68823

Cumulative Model Updates: 128,486
Cumulative Timesteps: 1,071,412,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,186.25068
Policy Entropy: 3.73943
Value Function Loss: 0.01677

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.44378
Value Function Update Magnitude: 0.47545

Collected Steps per Second: 22,212.95572
Overall Steps per Second: 10,484.46757

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.51822
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.76934

Cumulative Model Updates: 128,492
Cumulative Timesteps: 1,071,462,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1071462204...
Checkpoint 1071462204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,186.25068
Policy Entropy: 3.73822
Value Function Loss: 0.01649

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.41585
Value Function Update Magnitude: 0.45867

Collected Steps per Second: 22,398.55784
Overall Steps per Second: 10,704.39925

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.67266

Cumulative Model Updates: 128,498
Cumulative Timesteps: 1,071,512,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,869.45673
Policy Entropy: 3.72303
Value Function Loss: 0.01549

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.44551
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,043.34881
Overall Steps per Second: 10,603.66661

Timestep Collection Time: 2.26917
Timestep Consumption Time: 2.44807
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.71724

Cumulative Model Updates: 128,504
Cumulative Timesteps: 1,071,562,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1071562242...
Checkpoint 1071562242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,049.33144
Policy Entropy: 3.71114
Value Function Loss: 0.01992

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.48594
Value Function Update Magnitude: 0.72188

Collected Steps per Second: 21,046.06370
Overall Steps per Second: 10,364.46725

Timestep Collection Time: 2.37584
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.82437

Cumulative Model Updates: 128,510
Cumulative Timesteps: 1,071,612,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,049.33144
Policy Entropy: 3.71852
Value Function Loss: 0.01960

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.50686
Value Function Update Magnitude: 0.61452

Collected Steps per Second: 21,718.08061
Overall Steps per Second: 10,421.17231

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.80023

Cumulative Model Updates: 128,516
Cumulative Timesteps: 1,071,662,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1071662268...
Checkpoint 1071662268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,049.33144
Policy Entropy: 3.72734
Value Function Loss: 0.02035

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.49036
Value Function Update Magnitude: 0.51361

Collected Steps per Second: 22,208.67329
Overall Steps per Second: 10,681.62171

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.68412

Cumulative Model Updates: 128,522
Cumulative Timesteps: 1,071,712,302

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,784.92360
Policy Entropy: 3.73841
Value Function Loss: 0.01824

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.46925
Value Function Update Magnitude: 0.46748

Collected Steps per Second: 22,383.26311
Overall Steps per Second: 10,546.85358

Timestep Collection Time: 2.23479
Timestep Consumption Time: 2.50804
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.74284

Cumulative Model Updates: 128,528
Cumulative Timesteps: 1,071,762,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1071762324...
Checkpoint 1071762324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,784.92360
Policy Entropy: 3.70956
Value Function Loss: 0.02173

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.44527
Value Function Update Magnitude: 0.48403

Collected Steps per Second: 21,944.88159
Overall Steps per Second: 10,369.81548

Timestep Collection Time: 2.27862
Timestep Consumption Time: 2.54345
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.82207

Cumulative Model Updates: 128,534
Cumulative Timesteps: 1,071,812,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,399.99581
Policy Entropy: 3.72935
Value Function Loss: 0.01976

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.44447
Value Function Update Magnitude: 0.49223

Collected Steps per Second: 22,480.15928
Overall Steps per Second: 10,499.32792

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.53874
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76354

Cumulative Model Updates: 128,540
Cumulative Timesteps: 1,071,862,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1071862342...
Checkpoint 1071862342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,399.99581
Policy Entropy: 3.70760
Value Function Loss: 0.02241

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.44005
Value Function Update Magnitude: 0.46289

Collected Steps per Second: 21,905.54690
Overall Steps per Second: 10,384.32037

Timestep Collection Time: 2.28271
Timestep Consumption Time: 2.53263
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.81534

Cumulative Model Updates: 128,546
Cumulative Timesteps: 1,071,912,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,335.77274
Policy Entropy: 3.72483
Value Function Loss: 0.01933

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14215
Policy Update Magnitude: 0.43941
Value Function Update Magnitude: 0.43893

Collected Steps per Second: 22,542.98338
Overall Steps per Second: 10,561.20931

Timestep Collection Time: 2.21869
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.73582

Cumulative Model Updates: 128,552
Cumulative Timesteps: 1,071,962,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1071962362...
Checkpoint 1071962362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,824.91942
Policy Entropy: 3.71573
Value Function Loss: 0.02104

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.42365
Value Function Update Magnitude: 0.43995

Collected Steps per Second: 22,315.63248
Overall Steps per Second: 10,670.56088

Timestep Collection Time: 2.24058
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.68579

Cumulative Model Updates: 128,558
Cumulative Timesteps: 1,072,012,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,765.75748
Policy Entropy: 3.73628
Value Function Loss: 0.01901

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.43613
Value Function Update Magnitude: 0.49081

Collected Steps per Second: 22,076.12278
Overall Steps per Second: 10,496.10756

Timestep Collection Time: 2.26625
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.76653

Cumulative Model Updates: 128,564
Cumulative Timesteps: 1,072,062,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1072062392...
Checkpoint 1072062392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,726.37698
Policy Entropy: 3.74509
Value Function Loss: 0.02186

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.43250
Value Function Update Magnitude: 0.51961

Collected Steps per Second: 21,652.44331
Overall Steps per Second: 10,599.16854

Timestep Collection Time: 2.31013
Timestep Consumption Time: 2.40911
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.71924

Cumulative Model Updates: 128,570
Cumulative Timesteps: 1,072,112,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,254.70842
Policy Entropy: 3.75105
Value Function Loss: 0.02032

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.41896
Value Function Update Magnitude: 0.55425

Collected Steps per Second: 21,835.30121
Overall Steps per Second: 10,582.11192

Timestep Collection Time: 2.29243
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.73025

Cumulative Model Updates: 128,576
Cumulative Timesteps: 1,072,162,468

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1072162468...
Checkpoint 1072162468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,839.74786
Policy Entropy: 3.74330
Value Function Loss: 0.02168

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.41448
Value Function Update Magnitude: 0.59419

Collected Steps per Second: 21,595.07537
Overall Steps per Second: 10,510.88953

Timestep Collection Time: 2.31673
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75983

Cumulative Model Updates: 128,582
Cumulative Timesteps: 1,072,212,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,078.89551
Policy Entropy: 3.75178
Value Function Loss: 0.01824

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.42542
Value Function Update Magnitude: 0.59960

Collected Steps per Second: 21,820.73687
Overall Steps per Second: 10,456.41224

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.78405

Cumulative Model Updates: 128,588
Cumulative Timesteps: 1,072,262,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1072262522...
Checkpoint 1072262522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,313.30225
Policy Entropy: 3.75024
Value Function Loss: 0.01888

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.41538
Value Function Update Magnitude: 0.65330

Collected Steps per Second: 22,065.08937
Overall Steps per Second: 10,646.18058

Timestep Collection Time: 2.26602
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.69652

Cumulative Model Updates: 128,594
Cumulative Timesteps: 1,072,312,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.24743
Policy Entropy: 3.75590
Value Function Loss: 0.01621

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.40762
Value Function Update Magnitude: 0.69442

Collected Steps per Second: 22,433.52733
Overall Steps per Second: 10,588.39804

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.49434
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.72404

Cumulative Model Updates: 128,600
Cumulative Timesteps: 1,072,362,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1072362542...
Checkpoint 1072362542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350,119.56029
Policy Entropy: 3.73771
Value Function Loss: 0.01893

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.41575
Value Function Update Magnitude: 0.68917

Collected Steps per Second: 21,924.48522
Overall Steps per Second: 10,471.95482

Timestep Collection Time: 2.28074
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.77504

Cumulative Model Updates: 128,606
Cumulative Timesteps: 1,072,412,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,278.99680
Policy Entropy: 3.76758
Value Function Loss: 0.01993

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.46718
Value Function Update Magnitude: 0.72464

Collected Steps per Second: 22,104.05541
Overall Steps per Second: 10,463.74018

Timestep Collection Time: 2.26275
Timestep Consumption Time: 2.51718
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.77994

Cumulative Model Updates: 128,612
Cumulative Timesteps: 1,072,462,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1072462562...
Checkpoint 1072462562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,372.16418
Policy Entropy: 3.77565
Value Function Loss: 0.02403

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.51241
Value Function Update Magnitude: 0.73172

Collected Steps per Second: 18,391.35353
Overall Steps per Second: 9,493.77297

Timestep Collection Time: 2.71878
Timestep Consumption Time: 2.54804
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 5.26682

Cumulative Model Updates: 128,618
Cumulative Timesteps: 1,072,512,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,851.63314
Policy Entropy: 3.81145
Value Function Loss: 0.02421

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.82871

Collected Steps per Second: 22,555.85216
Overall Steps per Second: 10,517.03727

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.53818
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.75552

Cumulative Model Updates: 128,624
Cumulative Timesteps: 1,072,562,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1072562578...
Checkpoint 1072562578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,225.24676
Policy Entropy: 3.81193
Value Function Loss: 0.02869

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.61506
Value Function Update Magnitude: 0.87680

Collected Steps per Second: 22,229.39825
Overall Steps per Second: 10,714.02928

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.66846

Cumulative Model Updates: 128,630
Cumulative Timesteps: 1,072,612,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.81597
Policy Entropy: 3.81489
Value Function Loss: 0.03054

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.63447
Value Function Update Magnitude: 0.80766

Collected Steps per Second: 22,547.69478
Overall Steps per Second: 10,501.37395

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.54488
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76338

Cumulative Model Updates: 128,636
Cumulative Timesteps: 1,072,662,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1072662618...
Checkpoint 1072662618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,518.12185
Policy Entropy: 3.79807
Value Function Loss: 0.03428

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.63164
Value Function Update Magnitude: 0.71878

Collected Steps per Second: 22,548.94424
Overall Steps per Second: 10,628.25058

Timestep Collection Time: 2.21775
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.70520

Cumulative Model Updates: 128,642
Cumulative Timesteps: 1,072,712,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,368.07150
Policy Entropy: 3.79059
Value Function Loss: 0.03023

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.63838
Value Function Update Magnitude: 0.77001

Collected Steps per Second: 22,980.13260
Overall Steps per Second: 10,707.96670

Timestep Collection Time: 2.17719
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67241

Cumulative Model Updates: 128,648
Cumulative Timesteps: 1,072,762,658

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1072762658...
Checkpoint 1072762658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.25479
Policy Entropy: 3.78180
Value Function Loss: 0.02959

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.59478
Value Function Update Magnitude: 0.89319

Collected Steps per Second: 22,687.05757
Overall Steps per Second: 10,616.86210

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.50679
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71175

Cumulative Model Updates: 128,654
Cumulative Timesteps: 1,072,812,682

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,326.78127
Policy Entropy: 3.77931
Value Function Loss: 0.02837

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.76000

Collected Steps per Second: 22,857.64227
Overall Steps per Second: 10,760.52622

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.45946
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.64717

Cumulative Model Updates: 128,660
Cumulative Timesteps: 1,072,862,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1072862688...
Checkpoint 1072862688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.23728
Policy Entropy: 3.76766
Value Function Loss: 0.02875

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.75374

Collected Steps per Second: 22,432.34608
Overall Steps per Second: 10,512.29295

Timestep Collection Time: 2.22901
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.75653

Cumulative Model Updates: 128,666
Cumulative Timesteps: 1,072,912,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713.24312
Policy Entropy: 3.78013
Value Function Loss: 0.02580

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.80205

Collected Steps per Second: 23,015.08678
Overall Steps per Second: 10,837.59713

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61615

Cumulative Model Updates: 128,672
Cumulative Timesteps: 1,072,962,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1072962718...
Checkpoint 1072962718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,526.97662
Policy Entropy: 3.78425
Value Function Loss: 0.02775

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.77966

Collected Steps per Second: 22,295.24774
Overall Steps per Second: 10,584.20444

Timestep Collection Time: 2.24290
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.72459

Cumulative Model Updates: 128,678
Cumulative Timesteps: 1,073,012,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.58841
Policy Entropy: 3.79666
Value Function Loss: 0.02644

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.76613

Collected Steps per Second: 23,269.10246
Overall Steps per Second: 10,694.93096

Timestep Collection Time: 2.15084
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.67960

Cumulative Model Updates: 128,684
Cumulative Timesteps: 1,073,062,772

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1073062772...
Checkpoint 1073062772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,900.13660
Policy Entropy: 3.78852
Value Function Loss: 0.02952

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.71925

Collected Steps per Second: 22,205.91769
Overall Steps per Second: 10,549.16205

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.74388

Cumulative Model Updates: 128,690
Cumulative Timesteps: 1,073,112,816

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,328.23200
Policy Entropy: 3.78164
Value Function Loss: 0.02608

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.58206
Value Function Update Magnitude: 0.80975

Collected Steps per Second: 22,899.62546
Overall Steps per Second: 10,697.49238

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.67437

Cumulative Model Updates: 128,696
Cumulative Timesteps: 1,073,162,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1073162820...
Checkpoint 1073162820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,283.66364
Policy Entropy: 3.76925
Value Function Loss: 0.02686

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.81498

Collected Steps per Second: 22,503.13995
Overall Steps per Second: 10,727.38947

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.43925
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.66134

Cumulative Model Updates: 128,702
Cumulative Timesteps: 1,073,212,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,588.26763
Policy Entropy: 3.76672
Value Function Loss: 0.02216

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14341
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.76698

Collected Steps per Second: 23,011.21210
Overall Steps per Second: 10,808.95866

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.62690

Cumulative Model Updates: 128,708
Cumulative Timesteps: 1,073,262,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1073262836...
Checkpoint 1073262836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,680.59084
Policy Entropy: 3.75622
Value Function Loss: 0.02595

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14098
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.68622

Collected Steps per Second: 22,162.70142
Overall Steps per Second: 10,501.12932

Timestep Collection Time: 2.25676
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.76292

Cumulative Model Updates: 128,714
Cumulative Timesteps: 1,073,312,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,094.93317
Policy Entropy: 3.76511
Value Function Loss: 0.02297

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.52236
Value Function Update Magnitude: 0.59850

Collected Steps per Second: 21,889.82539
Overall Steps per Second: 10,561.37169

Timestep Collection Time: 2.28426
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.73442

Cumulative Model Updates: 128,720
Cumulative Timesteps: 1,073,362,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1073362854...
Checkpoint 1073362854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.73662
Policy Entropy: 3.77296
Value Function Loss: 0.02679

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.56804
Value Function Update Magnitude: 0.64988

Collected Steps per Second: 22,738.21577
Overall Steps per Second: 10,646.75707

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.69814

Cumulative Model Updates: 128,726
Cumulative Timesteps: 1,073,412,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,766.64270
Policy Entropy: 3.78355
Value Function Loss: 0.02825

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.59886
Value Function Update Magnitude: 0.66891

Collected Steps per Second: 22,744.42173
Overall Steps per Second: 10,552.57429

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.54157
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.74140

Cumulative Model Updates: 128,732
Cumulative Timesteps: 1,073,462,908

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1073462908...
Checkpoint 1073462908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,508.19374
Policy Entropy: 3.77360
Value Function Loss: 0.03196

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.62667
Value Function Update Magnitude: 0.74981

Collected Steps per Second: 22,429.17743
Overall Steps per Second: 10,587.26143

Timestep Collection Time: 2.22933
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.72285

Cumulative Model Updates: 128,738
Cumulative Timesteps: 1,073,512,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,533.00884
Policy Entropy: 3.78977
Value Function Loss: 0.02916

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.60879
Value Function Update Magnitude: 0.78451

Collected Steps per Second: 22,605.65506
Overall Steps per Second: 10,776.83961

Timestep Collection Time: 2.21192
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.63976

Cumulative Model Updates: 128,744
Cumulative Timesteps: 1,073,562,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1073562912...
Checkpoint 1073562912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.26420
Policy Entropy: 3.78960
Value Function Loss: 0.02487

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.81897

Collected Steps per Second: 22,587.60364
Overall Steps per Second: 10,621.84819

Timestep Collection Time: 2.21387
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.70784

Cumulative Model Updates: 128,750
Cumulative Timesteps: 1,073,612,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.52729
Policy Entropy: 3.80765
Value Function Loss: 0.02045

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.52291
Value Function Update Magnitude: 0.86440

Collected Steps per Second: 22,550.88700
Overall Steps per Second: 10,578.85171

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.51081
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72944

Cumulative Model Updates: 128,756
Cumulative Timesteps: 1,073,662,950

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1073662950...
Checkpoint 1073662950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.18292
Policy Entropy: 3.78943
Value Function Loss: 0.02131

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.49346
Value Function Update Magnitude: 0.79700

Collected Steps per Second: 22,150.83932
Overall Steps per Second: 10,496.52033

Timestep Collection Time: 2.25824
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.76558

Cumulative Model Updates: 128,762
Cumulative Timesteps: 1,073,712,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14777
Policy Entropy: 3.78974
Value Function Loss: 0.02131

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.48982
Value Function Update Magnitude: 0.72710

Collected Steps per Second: 22,612.41027
Overall Steps per Second: 10,761.89226

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.64695

Cumulative Model Updates: 128,768
Cumulative Timesteps: 1,073,762,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1073762982...
Checkpoint 1073762982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,961.66716
Policy Entropy: 3.77751
Value Function Loss: 0.02696

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.59304

Collected Steps per Second: 22,414.94908
Overall Steps per Second: 10,700.45315

Timestep Collection Time: 2.23172
Timestep Consumption Time: 2.44322
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.67494

Cumulative Model Updates: 128,774
Cumulative Timesteps: 1,073,813,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,300.49761
Policy Entropy: 3.79267
Value Function Loss: 0.02620

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.55303

Collected Steps per Second: 22,542.11756
Overall Steps per Second: 10,535.01636

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.52962
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.74911

Cumulative Model Updates: 128,780
Cumulative Timesteps: 1,073,863,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1073863038...
Checkpoint 1073863038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,361.68529
Policy Entropy: 3.78378
Value Function Loss: 0.03182

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.58210
Value Function Update Magnitude: 0.61428

Collected Steps per Second: 22,240.59716
Overall Steps per Second: 10,490.88408

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.51800
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.76623

Cumulative Model Updates: 128,786
Cumulative Timesteps: 1,073,913,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,904.14071
Policy Entropy: 3.79412
Value Function Loss: 0.03052

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.64068
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 22,677.11188
Overall Steps per Second: 10,769.44617

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.43809
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.64314

Cumulative Model Updates: 128,792
Cumulative Timesteps: 1,073,963,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1073963044...
Checkpoint 1073963044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.18230
Policy Entropy: 3.78835
Value Function Loss: 0.03130

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.63513
Value Function Update Magnitude: 0.76332

Collected Steps per Second: 22,348.92422
Overall Steps per Second: 10,716.73576

Timestep Collection Time: 2.23769
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.66653

Cumulative Model Updates: 128,798
Cumulative Timesteps: 1,074,013,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,757.67004
Policy Entropy: 3.81354
Value Function Loss: 0.02623

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.61219
Value Function Update Magnitude: 0.82800

Collected Steps per Second: 22,703.08665
Overall Steps per Second: 10,583.00366

Timestep Collection Time: 2.20243
Timestep Consumption Time: 2.52231
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72475

Cumulative Model Updates: 128,804
Cumulative Timesteps: 1,074,063,056

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1074063056...
Checkpoint 1074063056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401.62167
Policy Entropy: 3.79694
Value Function Loss: 0.02317

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.80652

Collected Steps per Second: 21,725.42197
Overall Steps per Second: 10,698.85241

Timestep Collection Time: 2.30292
Timestep Consumption Time: 2.37347
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.67639

Cumulative Model Updates: 128,810
Cumulative Timesteps: 1,074,113,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.46392
Policy Entropy: 3.79929
Value Function Loss: 0.01883

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.48393
Value Function Update Magnitude: 0.80734

Collected Steps per Second: 21,986.76731
Overall Steps per Second: 10,648.29179

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.69615

Cumulative Model Updates: 128,816
Cumulative Timesteps: 1,074,163,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1074163094...
Checkpoint 1074163094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.06558
Policy Entropy: 3.78440
Value Function Loss: 0.01825

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.44771
Value Function Update Magnitude: 0.74378

Collected Steps per Second: 21,997.67115
Overall Steps per Second: 10,626.14621

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.43406
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.70857

Cumulative Model Updates: 128,822
Cumulative Timesteps: 1,074,213,128

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,675.17415
Policy Entropy: 3.77198
Value Function Loss: 0.01961

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.48181
Value Function Update Magnitude: 0.68340

Collected Steps per Second: 21,980.14966
Overall Steps per Second: 10,448.17049

Timestep Collection Time: 2.27560
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.78725

Cumulative Model Updates: 128,828
Cumulative Timesteps: 1,074,263,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1074263146...
Checkpoint 1074263146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,633.18953
Policy Entropy: 3.76068
Value Function Loss: 0.02254

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.50742
Value Function Update Magnitude: 0.60853

Collected Steps per Second: 22,385.81045
Overall Steps per Second: 10,555.13447

Timestep Collection Time: 2.23392
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.73779

Cumulative Model Updates: 128,834
Cumulative Timesteps: 1,074,313,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,633.18953
Policy Entropy: 3.74848
Value Function Loss: 0.02029

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.53671

Collected Steps per Second: 22,789.20518
Overall Steps per Second: 10,837.15612

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.61579

Cumulative Model Updates: 128,840
Cumulative Timesteps: 1,074,363,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074363176...
Checkpoint 1074363176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,436.01933
Policy Entropy: 3.74715
Value Function Loss: 0.01890

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14605
Policy Update Magnitude: 0.49884
Value Function Update Magnitude: 0.53042

Collected Steps per Second: 22,172.30223
Overall Steps per Second: 10,620.33266

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.70946

Cumulative Model Updates: 128,846
Cumulative Timesteps: 1,074,413,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,436.01933
Policy Entropy: 3.74794
Value Function Loss: 0.01598

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.44706
Value Function Update Magnitude: 0.49686

Collected Steps per Second: 22,482.91520
Overall Steps per Second: 10,537.52479

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.52194
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74666

Cumulative Model Updates: 128,852
Cumulative Timesteps: 1,074,463,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1074463210...
Checkpoint 1074463210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,436.01933
Policy Entropy: 3.74539
Value Function Loss: 0.01637

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.43789
Value Function Update Magnitude: 0.43504

Collected Steps per Second: 22,287.90517
Overall Steps per Second: 10,476.85599

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.77242

Cumulative Model Updates: 128,858
Cumulative Timesteps: 1,074,513,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,436.01933
Policy Entropy: 3.73885
Value Function Loss: 0.01549

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.42228
Value Function Update Magnitude: 0.39866

Collected Steps per Second: 22,366.08012
Overall Steps per Second: 10,503.74347

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.52529
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.76135

Cumulative Model Updates: 128,864
Cumulative Timesteps: 1,074,563,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1074563222...
Checkpoint 1074563222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,665.84167
Policy Entropy: 3.71583
Value Function Loss: 0.02088

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.44552
Value Function Update Magnitude: 0.35802

Collected Steps per Second: 22,469.87618
Overall Steps per Second: 10,738.28223

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.65847

Cumulative Model Updates: 128,870
Cumulative Timesteps: 1,074,613,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,328.03201
Policy Entropy: 3.72797
Value Function Loss: 0.02146

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.41945

Collected Steps per Second: 22,831.29829
Overall Steps per Second: 10,645.44083

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.69797

Cumulative Model Updates: 128,876
Cumulative Timesteps: 1,074,663,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1074663258...
Checkpoint 1074663258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,644.15804
Policy Entropy: 3.71888
Value Function Loss: 0.02488

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.54231

Collected Steps per Second: 21,887.31364
Overall Steps per Second: 10,538.96633

Timestep Collection Time: 2.28507
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.74563

Cumulative Model Updates: 128,882
Cumulative Timesteps: 1,074,713,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,496.40052
Policy Entropy: 3.74959
Value Function Loss: 0.02101

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.66532

Collected Steps per Second: 22,104.57645
Overall Steps per Second: 10,714.75367

Timestep Collection Time: 2.26297
Timestep Consumption Time: 2.40555
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.66852

Cumulative Model Updates: 128,888
Cumulative Timesteps: 1,074,763,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074763294...
Checkpoint 1074763294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,496.40052
Policy Entropy: 3.72481
Value Function Loss: 0.02307

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.67589

Collected Steps per Second: 21,785.43870
Overall Steps per Second: 10,607.95371

Timestep Collection Time: 2.29511
Timestep Consumption Time: 2.41833
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.71344

Cumulative Model Updates: 128,894
Cumulative Timesteps: 1,074,813,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,496.40052
Policy Entropy: 3.73765
Value Function Loss: 0.01985

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.51771
Value Function Update Magnitude: 0.54062

Collected Steps per Second: 22,444.85115
Overall Steps per Second: 10,627.82406

Timestep Collection Time: 2.22884
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70708

Cumulative Model Updates: 128,900
Cumulative Timesteps: 1,074,863,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1074863320...
Checkpoint 1074863320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,496.40052
Policy Entropy: 3.72791
Value Function Loss: 0.02046

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.48307
Value Function Update Magnitude: 0.50297

Collected Steps per Second: 22,629.43257
Overall Steps per Second: 10,821.33495

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.62217

Cumulative Model Updates: 128,906
Cumulative Timesteps: 1,074,913,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,623.87352
Policy Entropy: 3.73822
Value Function Loss: 0.02156

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.49256

Collected Steps per Second: 22,785.71827
Overall Steps per Second: 10,559.86450

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.54167
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.73699

Cumulative Model Updates: 128,912
Cumulative Timesteps: 1,074,963,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1074963360...
Checkpoint 1074963360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,345.10980
Policy Entropy: 3.71596
Value Function Loss: 0.02713

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.51369

Collected Steps per Second: 22,433.21235
Overall Steps per Second: 10,540.36726

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.74519

Cumulative Model Updates: 128,918
Cumulative Timesteps: 1,075,013,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.71714
Value Function Loss: 0.02669

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.17366
Policy Update Magnitude: 0.60654
Value Function Update Magnitude: 0.57205

Collected Steps per Second: 22,675.87474
Overall Steps per Second: 10,706.27755

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.46557
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.67090

Cumulative Model Updates: 128,924
Cumulative Timesteps: 1,075,063,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1075063384...
Checkpoint 1075063384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.70263
Value Function Loss: 0.02626

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.17473
Policy Update Magnitude: 0.61880
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 22,132.33492
Overall Steps per Second: 10,478.86323

Timestep Collection Time: 2.26058
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.77456

Cumulative Model Updates: 128,930
Cumulative Timesteps: 1,075,113,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.71293
Value Function Loss: 0.01668

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.60206
Value Function Update Magnitude: 0.45321

Collected Steps per Second: 22,742.83872
Overall Steps per Second: 10,805.79366

Timestep Collection Time: 2.19973
Timestep Consumption Time: 2.43001
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.62974

Cumulative Model Updates: 128,936
Cumulative Timesteps: 1,075,163,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1075163444...
Checkpoint 1075163444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.71978
Value Function Loss: 0.01330

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.58614
Value Function Update Magnitude: 0.47056

Collected Steps per Second: 22,386.15841
Overall Steps per Second: 10,484.52536

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.53612
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.77027

Cumulative Model Updates: 128,942
Cumulative Timesteps: 1,075,213,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.72742
Value Function Loss: 0.01266

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.44364
Value Function Update Magnitude: 0.40317

Collected Steps per Second: 22,704.88777
Overall Steps per Second: 10,745.27047

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.65321

Cumulative Model Updates: 128,948
Cumulative Timesteps: 1,075,263,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1075263458...
Checkpoint 1075263458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,488.47773
Policy Entropy: 3.73371
Value Function Loss: 0.01285

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15460
Policy Update Magnitude: 0.37901
Value Function Update Magnitude: 0.39414

Collected Steps per Second: 22,178.66802
Overall Steps per Second: 10,436.16347

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.53672
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.79122

Cumulative Model Updates: 128,954
Cumulative Timesteps: 1,075,313,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,621.89786
Policy Entropy: 3.73194
Value Function Loss: 0.02017

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.41810
Value Function Update Magnitude: 0.43109

Collected Steps per Second: 22,354.00793
Overall Steps per Second: 10,524.06670

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.51448
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.75140

Cumulative Model Updates: 128,960
Cumulative Timesteps: 1,075,363,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1075363464...
Checkpoint 1075363464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,118.96279
Policy Entropy: 3.73387
Value Function Loss: 0.02216

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.56606

Collected Steps per Second: 21,986.04747
Overall Steps per Second: 10,619.27476

Timestep Collection Time: 2.27599
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.71219

Cumulative Model Updates: 128,966
Cumulative Timesteps: 1,075,413,504

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,863.40111
Policy Entropy: 3.71420
Value Function Loss: 0.02612

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.56726
Value Function Update Magnitude: 0.69574

Collected Steps per Second: 22,371.68092
Overall Steps per Second: 10,510.13213

Timestep Collection Time: 2.23524
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.75789

Cumulative Model Updates: 128,972
Cumulative Timesteps: 1,075,463,510

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1075463510...
Checkpoint 1075463510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,629.59475
Policy Entropy: 3.72235
Value Function Loss: 0.02220

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.69995

Collected Steps per Second: 21,820.48940
Overall Steps per Second: 10,765.43296

Timestep Collection Time: 2.29252
Timestep Consumption Time: 2.35420
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.64672

Cumulative Model Updates: 128,978
Cumulative Timesteps: 1,075,513,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,629.59475
Policy Entropy: 3.71718
Value Function Loss: 0.02162

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.61560

Collected Steps per Second: 21,715.08167
Overall Steps per Second: 10,549.77278

Timestep Collection Time: 2.30365
Timestep Consumption Time: 2.43806
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.74171

Cumulative Model Updates: 128,984
Cumulative Timesteps: 1,075,563,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1075563558...
Checkpoint 1075563558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,128.73428
Policy Entropy: 3.73119
Value Function Loss: 0.02104

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.51470
Value Function Update Magnitude: 0.55456

Collected Steps per Second: 21,732.83598
Overall Steps per Second: 10,719.06136

Timestep Collection Time: 2.30085
Timestep Consumption Time: 2.36411
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.66496

Cumulative Model Updates: 128,990
Cumulative Timesteps: 1,075,613,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,334.48210
Policy Entropy: 3.74987
Value Function Loss: 0.02383

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.56325
Value Function Update Magnitude: 0.59087

Collected Steps per Second: 22,057.60125
Overall Steps per Second: 10,479.39151

Timestep Collection Time: 2.26734
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.77241

Cumulative Model Updates: 128,996
Cumulative Timesteps: 1,075,663,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1075663574...
Checkpoint 1075663574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,504.66978
Policy Entropy: 3.75782
Value Function Loss: 0.02490

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.60370

Collected Steps per Second: 22,431.08439
Overall Steps per Second: 10,619.63712

Timestep Collection Time: 2.22932
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70882

Cumulative Model Updates: 129,002
Cumulative Timesteps: 1,075,713,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,095.03042
Policy Entropy: 3.77519
Value Function Loss: 0.02415

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 22,632.43658
Overall Steps per Second: 10,631.17643

Timestep Collection Time: 2.21037
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70559

Cumulative Model Updates: 129,008
Cumulative Timesteps: 1,075,763,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1075763606...
Checkpoint 1075763606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,440.12504
Policy Entropy: 3.75857
Value Function Loss: 0.02367

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.48599
Value Function Update Magnitude: 0.55777

Collected Steps per Second: 22,662.75708
Overall Steps per Second: 10,577.86325

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.72950

Cumulative Model Updates: 129,014
Cumulative Timesteps: 1,075,813,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,440.12504
Policy Entropy: 3.75082
Value Function Loss: 0.02123

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.51791
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 22,680.17319
Overall Steps per Second: 10,725.23010

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.66302

Cumulative Model Updates: 129,020
Cumulative Timesteps: 1,075,863,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1075863646...
Checkpoint 1075863646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,472.49446
Policy Entropy: 3.73924
Value Function Loss: 0.02035

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.65697

Collected Steps per Second: 22,211.29239
Overall Steps per Second: 10,660.08393

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.69171

Cumulative Model Updates: 129,026
Cumulative Timesteps: 1,075,913,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,170.47220
Policy Entropy: 3.73472
Value Function Loss: 0.02064

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.53604
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,066.70447
Overall Steps per Second: 10,473.45175

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.51033
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.77818

Cumulative Model Updates: 129,032
Cumulative Timesteps: 1,075,963,704

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1075963704...
Checkpoint 1075963704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,238.41512
Policy Entropy: 3.73871
Value Function Loss: 0.02176

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.68190

Collected Steps per Second: 22,429.76742
Overall Steps per Second: 10,743.92141

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.42578
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.65603

Cumulative Model Updates: 129,038
Cumulative Timesteps: 1,076,013,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,238.41512
Policy Entropy: 3.72209
Value Function Loss: 0.02370

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.58597
Value Function Update Magnitude: 0.57168

Collected Steps per Second: 22,284.54713
Overall Steps per Second: 10,491.17529

Timestep Collection Time: 2.24380
Timestep Consumption Time: 2.52230
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76610

Cumulative Model Updates: 129,044
Cumulative Timesteps: 1,076,063,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1076063730...
Checkpoint 1076063730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,284.97600
Policy Entropy: 3.74928
Value Function Loss: 0.02282

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.50057

Collected Steps per Second: 21,724.55617
Overall Steps per Second: 10,707.06677

Timestep Collection Time: 2.30200
Timestep Consumption Time: 2.36874
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.67075

Cumulative Model Updates: 129,050
Cumulative Timesteps: 1,076,113,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,456.77080
Policy Entropy: 3.74489
Value Function Loss: 0.02232

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.59769
Value Function Update Magnitude: 0.70382

Collected Steps per Second: 22,006.78295
Overall Steps per Second: 10,639.51170

Timestep Collection Time: 2.27284
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70116

Cumulative Model Updates: 129,056
Cumulative Timesteps: 1,076,163,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1076163758...
Checkpoint 1076163758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,503.19641
Policy Entropy: 3.76332
Value Function Loss: 0.02173

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.61284
Value Function Update Magnitude: 0.86449

Collected Steps per Second: 21,895.63498
Overall Steps per Second: 10,792.15837

Timestep Collection Time: 2.28383
Timestep Consumption Time: 2.34972
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.63355

Cumulative Model Updates: 129,062
Cumulative Timesteps: 1,076,213,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,678.23320
Policy Entropy: 3.74398
Value Function Loss: 0.02176

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.63029
Value Function Update Magnitude: 0.86683

Collected Steps per Second: 21,861.68173
Overall Steps per Second: 10,411.20687

Timestep Collection Time: 2.28802
Timestep Consumption Time: 2.51642
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.80444

Cumulative Model Updates: 129,068
Cumulative Timesteps: 1,076,263,784

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1076263784...
Checkpoint 1076263784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.16425
Policy Entropy: 3.76608
Value Function Loss: 0.02058

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14604
Policy Update Magnitude: 0.58905
Value Function Update Magnitude: 0.79179

Collected Steps per Second: 22,424.96748
Overall Steps per Second: 10,780.91430

Timestep Collection Time: 2.23055
Timestep Consumption Time: 2.40913
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.63968

Cumulative Model Updates: 129,074
Cumulative Timesteps: 1,076,313,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,409.81500
Policy Entropy: 3.75314
Value Function Loss: 0.02712

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.82206

Collected Steps per Second: 22,507.14680
Overall Steps per Second: 10,459.23221

Timestep Collection Time: 2.22285
Timestep Consumption Time: 2.56048
PPO Batch Consumption Time: 0.30229
Total Iteration Time: 4.78333

Cumulative Model Updates: 129,080
Cumulative Timesteps: 1,076,363,834

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1076363834...
Checkpoint 1076363834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,406.81773
Policy Entropy: 3.76753
Value Function Loss: 0.02788

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.62598
Value Function Update Magnitude: 0.85231

Collected Steps per Second: 22,361.01769
Overall Steps per Second: 10,624.37128

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.70804

Cumulative Model Updates: 129,086
Cumulative Timesteps: 1,076,413,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,313.50508
Policy Entropy: 3.76840
Value Function Loss: 0.02788

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.62535
Value Function Update Magnitude: 0.73773

Collected Steps per Second: 22,496.19649
Overall Steps per Second: 10,512.16340

Timestep Collection Time: 2.22393
Timestep Consumption Time: 2.53532
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.75925

Cumulative Model Updates: 129,092
Cumulative Timesteps: 1,076,463,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1076463884...
Checkpoint 1076463884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,765.41498
Policy Entropy: 3.79131
Value Function Loss: 0.02237

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 22,190.72175
Overall Steps per Second: 10,634.33902

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.70344

Cumulative Model Updates: 129,098
Cumulative Timesteps: 1,076,513,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,522.16800
Policy Entropy: 3.77344
Value Function Loss: 0.01983

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.49948
Value Function Update Magnitude: 0.50856

Collected Steps per Second: 22,716.58230
Overall Steps per Second: 10,618.98282

Timestep Collection Time: 2.20227
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.71119

Cumulative Model Updates: 129,104
Cumulative Timesteps: 1,076,563,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1076563930...
Checkpoint 1076563930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.36285
Policy Entropy: 3.76440
Value Function Loss: 0.01820

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.46659
Value Function Update Magnitude: 0.51116

Collected Steps per Second: 22,448.50911
Overall Steps per Second: 10,536.32157

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.51827
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.74568

Cumulative Model Updates: 129,110
Cumulative Timesteps: 1,076,613,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.36285
Policy Entropy: 3.75294
Value Function Loss: 0.01622

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.46373
Value Function Update Magnitude: 0.52397

Collected Steps per Second: 22,683.96491
Overall Steps per Second: 10,554.56336

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73729

Cumulative Model Updates: 129,116
Cumulative Timesteps: 1,076,663,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1076663932...
Checkpoint 1076663932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.36285
Policy Entropy: 3.74651
Value Function Loss: 0.01556

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.42294
Value Function Update Magnitude: 0.44464

Collected Steps per Second: 22,112.35999
Overall Steps per Second: 10,606.67298

Timestep Collection Time: 2.26172
Timestep Consumption Time: 2.45342
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.71514

Cumulative Model Updates: 129,122
Cumulative Timesteps: 1,076,713,944

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.36285
Policy Entropy: 3.73243
Value Function Loss: 0.01322

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.37996
Value Function Update Magnitude: 0.43412

Collected Steps per Second: 22,631.54671
Overall Steps per Second: 10,571.36502

Timestep Collection Time: 2.21081
Timestep Consumption Time: 2.52217
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.73297

Cumulative Model Updates: 129,128
Cumulative Timesteps: 1,076,763,978

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1076763978...
Checkpoint 1076763978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,039.36285
Policy Entropy: 3.73101
Value Function Loss: 0.01373

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.34779
Value Function Update Magnitude: 0.41775

Collected Steps per Second: 22,441.76511
Overall Steps per Second: 10,697.06756

Timestep Collection Time: 2.22826
Timestep Consumption Time: 2.44648
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.67474

Cumulative Model Updates: 129,134
Cumulative Timesteps: 1,076,813,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,639.29083
Policy Entropy: 3.73795
Value Function Loss: 0.01444

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.35457
Value Function Update Magnitude: 0.46043

Collected Steps per Second: 22,438.45238
Overall Steps per Second: 10,566.14267

Timestep Collection Time: 2.22921
Timestep Consumption Time: 2.50478
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73399

Cumulative Model Updates: 129,140
Cumulative Timesteps: 1,076,864,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1076864004...
Checkpoint 1076864004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,994.24463
Policy Entropy: 3.74380
Value Function Loss: 0.01634

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.42302
Value Function Update Magnitude: 0.59472

Collected Steps per Second: 22,282.71909
Overall Steps per Second: 10,542.91679

Timestep Collection Time: 2.24434
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.74347

Cumulative Model Updates: 129,146
Cumulative Timesteps: 1,076,914,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,807.29880
Policy Entropy: 3.74811
Value Function Loss: 0.01808

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.70499

Collected Steps per Second: 22,375.68002
Overall Steps per Second: 10,488.10703

Timestep Collection Time: 2.23591
Timestep Consumption Time: 2.53426
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.77016

Cumulative Model Updates: 129,152
Cumulative Timesteps: 1,076,964,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1076964044...
Checkpoint 1076964044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,036.13635
Policy Entropy: 3.74424
Value Function Loss: 0.01671

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.77287

Collected Steps per Second: 22,145.21507
Overall Steps per Second: 10,500.90837

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.76168

Cumulative Model Updates: 129,158
Cumulative Timesteps: 1,077,014,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,513.47352
Policy Entropy: 3.73754
Value Function Loss: 0.01867

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.74646

Collected Steps per Second: 22,944.61627
Overall Steps per Second: 10,642.72770

Timestep Collection Time: 2.18029
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.70049

Cumulative Model Updates: 129,164
Cumulative Timesteps: 1,077,064,072

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1077064072...
Checkpoint 1077064072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,459.83253
Policy Entropy: 3.73991
Value Function Loss: 0.01820

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.75249

Collected Steps per Second: 21,430.39906
Overall Steps per Second: 10,492.55461

Timestep Collection Time: 2.33519
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.76948

Cumulative Model Updates: 129,170
Cumulative Timesteps: 1,077,114,116

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286,192.93089
Policy Entropy: 3.74157
Value Function Loss: 0.01791

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.54715
Value Function Update Magnitude: 0.75459

Collected Steps per Second: 21,768.15595
Overall Steps per Second: 10,541.59538

Timestep Collection Time: 2.29813
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.74558

Cumulative Model Updates: 129,176
Cumulative Timesteps: 1,077,164,142

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1077164142...
Checkpoint 1077164142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,192.93089
Policy Entropy: 3.73896
Value Function Loss: 0.01643

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.50318
Value Function Update Magnitude: 0.67782

Collected Steps per Second: 20,475.73550
Overall Steps per Second: 10,075.28496

Timestep Collection Time: 2.44201
Timestep Consumption Time: 2.52082
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.96284

Cumulative Model Updates: 129,182
Cumulative Timesteps: 1,077,214,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286,192.93089
Policy Entropy: 3.74004
Value Function Loss: 0.01520

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.46238
Value Function Update Magnitude: 0.58599

Collected Steps per Second: 22,224.52852
Overall Steps per Second: 10,360.22149

Timestep Collection Time: 2.25085
Timestep Consumption Time: 2.57762
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.82847

Cumulative Model Updates: 129,188
Cumulative Timesteps: 1,077,264,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1077264168...
Checkpoint 1077264168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316,708.86550
Policy Entropy: 3.74098
Value Function Loss: 0.01522

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.41531
Value Function Update Magnitude: 0.49324

Collected Steps per Second: 21,718.46084
Overall Steps per Second: 10,575.43979

Timestep Collection Time: 2.30237
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.72831

Cumulative Model Updates: 129,194
Cumulative Timesteps: 1,077,314,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,451.09790
Policy Entropy: 3.74523
Value Function Loss: 0.01481

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.41716
Value Function Update Magnitude: 0.47128

Collected Steps per Second: 22,684.94071
Overall Steps per Second: 10,557.91430

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.53249
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73730

Cumulative Model Updates: 129,200
Cumulative Timesteps: 1,077,364,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1077364188...
Checkpoint 1077364188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,476.05002
Policy Entropy: 3.74083
Value Function Loss: 0.01551

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.40890
Value Function Update Magnitude: 0.50613

Collected Steps per Second: 21,873.50056
Overall Steps per Second: 10,514.91123

Timestep Collection Time: 2.28752
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.75858

Cumulative Model Updates: 129,206
Cumulative Timesteps: 1,077,414,224

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,476.05002
Policy Entropy: 3.73200
Value Function Loss: 0.01598

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.43013
Value Function Update Magnitude: 0.53983

Collected Steps per Second: 22,359.03908
Overall Steps per Second: 10,464.69864

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.54306
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78045

Cumulative Model Updates: 129,212
Cumulative Timesteps: 1,077,464,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1077464250...
Checkpoint 1077464250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,476.05002
Policy Entropy: 3.73279
Value Function Loss: 0.01480

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14700
Policy Update Magnitude: 0.43586
Value Function Update Magnitude: 0.52914

Collected Steps per Second: 22,131.19624
Overall Steps per Second: 10,615.24564

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.71266

Cumulative Model Updates: 129,218
Cumulative Timesteps: 1,077,514,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 457,319.79929
Policy Entropy: 3.71753
Value Function Loss: 0.01868

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.43104
Value Function Update Magnitude: 0.44413

Collected Steps per Second: 22,463.15643
Overall Steps per Second: 10,542.68429

Timestep Collection Time: 2.22622
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.74338

Cumulative Model Updates: 129,224
Cumulative Timesteps: 1,077,564,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1077564284...
Checkpoint 1077564284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,048.55243
Policy Entropy: 3.72542
Value Function Loss: 0.01888

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.50068
Value Function Update Magnitude: 0.45953

Collected Steps per Second: 21,241.48633
Overall Steps per Second: 10,576.12445

Timestep Collection Time: 2.35398
Timestep Consumption Time: 2.37384
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.72782

Cumulative Model Updates: 129,230
Cumulative Timesteps: 1,077,614,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,821.73562
Policy Entropy: 3.70565
Value Function Loss: 0.02451

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.60264

Collected Steps per Second: 21,677.83778
Overall Steps per Second: 10,500.46545

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.76455

Cumulative Model Updates: 129,236
Cumulative Timesteps: 1,077,664,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1077664316...
Checkpoint 1077664316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 554,370.81121
Policy Entropy: 3.72960
Value Function Loss: 0.02275

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.71740

Collected Steps per Second: 21,530.43060
Overall Steps per Second: 10,642.76373

Timestep Collection Time: 2.32313
Timestep Consumption Time: 2.37659
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.69972

Cumulative Model Updates: 129,242
Cumulative Timesteps: 1,077,714,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,356.77351
Policy Entropy: 3.72218
Value Function Loss: 0.02613

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.62401
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 21,497.51031
Overall Steps per Second: 10,525.26626

Timestep Collection Time: 2.32660
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.75199

Cumulative Model Updates: 129,248
Cumulative Timesteps: 1,077,764,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1077764350...
Checkpoint 1077764350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,404.29753
Policy Entropy: 3.75590
Value Function Loss: 0.02494

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.62834
Value Function Update Magnitude: 0.63893

Collected Steps per Second: 22,516.15258
Overall Steps per Second: 10,659.35454

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.47029
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.69109

Cumulative Model Updates: 129,254
Cumulative Timesteps: 1,077,814,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,556.67308
Policy Entropy: 3.73443
Value Function Loss: 0.03009

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.68669
Value Function Update Magnitude: 0.67871

Collected Steps per Second: 22,235.00123
Overall Steps per Second: 10,354.11885

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.58142
PPO Batch Consumption Time: 0.30735
Total Iteration Time: 4.83112

Cumulative Model Updates: 129,260
Cumulative Timesteps: 1,077,864,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1077864376...
Checkpoint 1077864376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,291.52639
Policy Entropy: 3.74220
Value Function Loss: 0.02956

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.74749
Value Function Update Magnitude: 0.91767

Collected Steps per Second: 22,324.89209
Overall Steps per Second: 10,626.66605

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.46608
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.70627

Cumulative Model Updates: 129,266
Cumulative Timesteps: 1,077,914,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,444.98094
Policy Entropy: 3.73668
Value Function Loss: 0.03197

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.70571
Value Function Update Magnitude: 0.91770

Collected Steps per Second: 22,086.03160
Overall Steps per Second: 10,562.45985

Timestep Collection Time: 2.26514
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.73640

Cumulative Model Updates: 129,272
Cumulative Timesteps: 1,077,964,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1077964416...
Checkpoint 1077964416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,129.96054
Policy Entropy: 3.75480
Value Function Loss: 0.02855

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.67670
Value Function Update Magnitude: 0.78808

Collected Steps per Second: 22,348.40348
Overall Steps per Second: 10,651.53992

Timestep Collection Time: 2.23819
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.69603

Cumulative Model Updates: 129,278
Cumulative Timesteps: 1,078,014,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,234.93149
Policy Entropy: 3.74757
Value Function Loss: 0.02901

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14231
Policy Update Magnitude: 0.64567
Value Function Update Magnitude: 0.80746

Collected Steps per Second: 22,445.48502
Overall Steps per Second: 10,496.47782

Timestep Collection Time: 2.22771
Timestep Consumption Time: 2.53598
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.76369

Cumulative Model Updates: 129,284
Cumulative Timesteps: 1,078,064,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1078064438...
Checkpoint 1078064438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,293.87634
Policy Entropy: 3.74513
Value Function Loss: 0.02729

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.62522
Value Function Update Magnitude: 0.70875

Collected Steps per Second: 22,138.84041
Overall Steps per Second: 10,443.33971

Timestep Collection Time: 2.25893
Timestep Consumption Time: 2.52977
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.78870

Cumulative Model Updates: 129,290
Cumulative Timesteps: 1,078,114,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,767.10933
Policy Entropy: 3.74374
Value Function Loss: 0.02615

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.61582
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 22,502.09717
Overall Steps per Second: 10,502.99304

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.53965
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.76264

Cumulative Model Updates: 129,296
Cumulative Timesteps: 1,078,164,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1078164470...
Checkpoint 1078164470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,679.01978
Policy Entropy: 3.72952
Value Function Loss: 0.02474

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.59191
Value Function Update Magnitude: 0.55524

Collected Steps per Second: 22,367.43516
Overall Steps per Second: 10,567.55927

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.73335

Cumulative Model Updates: 129,302
Cumulative Timesteps: 1,078,214,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,908.31412
Policy Entropy: 3.74999
Value Function Loss: 0.02350

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.58872

Collected Steps per Second: 22,774.48593
Overall Steps per Second: 10,779.12475

Timestep Collection Time: 2.19676
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64138

Cumulative Model Updates: 129,308
Cumulative Timesteps: 1,078,264,520

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1078264520...
Checkpoint 1078264520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,020.33626
Policy Entropy: 3.73399
Value Function Loss: 0.02202

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14798
Policy Update Magnitude: 0.54035
Value Function Update Magnitude: 0.56455

Collected Steps per Second: 22,034.00694
Overall Steps per Second: 10,417.90465

Timestep Collection Time: 2.27004
Timestep Consumption Time: 2.53112
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.80116

Cumulative Model Updates: 129,314
Cumulative Timesteps: 1,078,314,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,841.70447
Policy Entropy: 3.75670
Value Function Loss: 0.01861

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.52856
Value Function Update Magnitude: 0.49498

Collected Steps per Second: 22,778.94477
Overall Steps per Second: 10,646.71903

Timestep Collection Time: 2.19677
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.70004

Cumulative Model Updates: 129,320
Cumulative Timesteps: 1,078,364,578

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1078364578...
Checkpoint 1078364578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,363.77458
Policy Entropy: 3.73406
Value Function Loss: 0.01782

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.49905
Value Function Update Magnitude: 0.43300

Collected Steps per Second: 22,445.68488
Overall Steps per Second: 10,552.62796

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.74005

Cumulative Model Updates: 129,326
Cumulative Timesteps: 1,078,414,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,183.21176
Policy Entropy: 3.74307
Value Function Loss: 0.01969

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.44329

Collected Steps per Second: 22,354.51067
Overall Steps per Second: 10,480.25559

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.53531
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.77298

Cumulative Model Updates: 129,332
Cumulative Timesteps: 1,078,464,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1078464620...
Checkpoint 1078464620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,913.92574
Policy Entropy: 3.73508
Value Function Loss: 0.02129

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14883
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.43504

Collected Steps per Second: 22,233.47576
Overall Steps per Second: 10,481.98809

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.52223
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.77200

Cumulative Model Updates: 129,338
Cumulative Timesteps: 1,078,514,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,432.47606
Policy Entropy: 3.74220
Value Function Loss: 0.03051

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.46162

Collected Steps per Second: 22,259.87798
Overall Steps per Second: 10,514.63574

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.50928
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.75566

Cumulative Model Updates: 129,344
Cumulative Timesteps: 1,078,564,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1078564644...
Checkpoint 1078564644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,961.84748
Policy Entropy: 3.76810
Value Function Loss: 0.02965

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.63751
Value Function Update Magnitude: 0.53324

Collected Steps per Second: 22,170.97680
Overall Steps per Second: 10,494.75788

Timestep Collection Time: 2.25529
Timestep Consumption Time: 2.50918
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.76447

Cumulative Model Updates: 129,350
Cumulative Timesteps: 1,078,614,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.13308
Policy Entropy: 3.76739
Value Function Loss: 0.03248

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.66754
Value Function Update Magnitude: 0.71126

Collected Steps per Second: 22,364.56477
Overall Steps per Second: 10,659.91581

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.45499
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.69084

Cumulative Model Updates: 129,356
Cumulative Timesteps: 1,078,664,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1078664650...
Checkpoint 1078664650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,372.77285
Policy Entropy: 3.77935
Value Function Loss: 0.03010

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.73692
Value Function Update Magnitude: 0.78990

Collected Steps per Second: 21,795.34896
Overall Steps per Second: 10,529.81062

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.75108

Cumulative Model Updates: 129,362
Cumulative Timesteps: 1,078,714,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,054.21754
Policy Entropy: 3.76711
Value Function Loss: 0.03084

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.79260
Value Function Update Magnitude: 0.80873

Collected Steps per Second: 22,202.82858
Overall Steps per Second: 10,473.71646

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.77405

Cumulative Model Updates: 129,368
Cumulative Timesteps: 1,078,764,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1078764680...
Checkpoint 1078764680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.94407
Policy Entropy: 3.77345
Value Function Loss: 0.02544

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.74216
Value Function Update Magnitude: 0.77097

Collected Steps per Second: 22,532.79931
Overall Steps per Second: 10,755.74303

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.64868

Cumulative Model Updates: 129,374
Cumulative Timesteps: 1,078,814,680

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,073.50786
Policy Entropy: 3.75823
Value Function Loss: 0.02425

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.65983
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 22,017.27348
Overall Steps per Second: 10,398.27968

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.53856
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.81041

Cumulative Model Updates: 129,380
Cumulative Timesteps: 1,078,864,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1078864700...
Checkpoint 1078864700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,710.68528
Policy Entropy: 3.74782
Value Function Loss: 0.02352

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.64025
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 21,590.76854
Overall Steps per Second: 10,645.60165

Timestep Collection Time: 2.31710
Timestep Consumption Time: 2.38230
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.69941

Cumulative Model Updates: 129,386
Cumulative Timesteps: 1,078,914,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,854.29536
Policy Entropy: 3.75120
Value Function Loss: 0.02723

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.67865
Value Function Update Magnitude: 0.72181

Collected Steps per Second: 21,576.66086
Overall Steps per Second: 10,487.61957

Timestep Collection Time: 2.31750
Timestep Consumption Time: 2.45040
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.76791

Cumulative Model Updates: 129,392
Cumulative Timesteps: 1,078,964,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1078964732...
Checkpoint 1078964732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,172.97723
Policy Entropy: 3.77573
Value Function Loss: 0.03032

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.70899
Value Function Update Magnitude: 0.77068

Collected Steps per Second: 21,691.26159
Overall Steps per Second: 10,717.14964

Timestep Collection Time: 2.30508
Timestep Consumption Time: 2.36034
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.66542

Cumulative Model Updates: 129,398
Cumulative Timesteps: 1,079,014,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,887.57451
Policy Entropy: 3.78606
Value Function Loss: 0.02875

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.75666
Value Function Update Magnitude: 0.82565

Collected Steps per Second: 21,519.26585
Overall Steps per Second: 10,465.57209

Timestep Collection Time: 2.32387
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.77833

Cumulative Model Updates: 129,404
Cumulative Timesteps: 1,079,064,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1079064740...
Checkpoint 1079064740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 538.74210
Policy Entropy: 3.78442
Value Function Loss: 0.02607

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.83212
Value Function Update Magnitude: 0.75070

Collected Steps per Second: 20,922.75594
Overall Steps per Second: 10,343.20490

Timestep Collection Time: 2.39108
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.83680

Cumulative Model Updates: 129,410
Cumulative Timesteps: 1,079,114,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199.82129
Policy Entropy: 3.77867
Value Function Loss: 0.02274

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16804
Policy Update Magnitude: 0.71062
Value Function Update Magnitude: 0.53977

Collected Steps per Second: 22,094.26912
Overall Steps per Second: 10,546.75169

Timestep Collection Time: 2.26312
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.74099

Cumulative Model Updates: 129,416
Cumulative Timesteps: 1,079,164,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1079164770...
Checkpoint 1079164770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,904.93224
Policy Entropy: 3.78618
Value Function Loss: 0.02333

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.57658
Value Function Update Magnitude: 0.39500

Collected Steps per Second: 21,996.33638
Overall Steps per Second: 10,415.52520

Timestep Collection Time: 2.27420
Timestep Consumption Time: 2.52863
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.80283

Cumulative Model Updates: 129,422
Cumulative Timesteps: 1,079,214,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,308.35891
Policy Entropy: 3.79221
Value Function Loss: 0.02136

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.50432
Value Function Update Magnitude: 0.35933

Collected Steps per Second: 21,963.87438
Overall Steps per Second: 10,488.69159

Timestep Collection Time: 2.27756
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.76933

Cumulative Model Updates: 129,428
Cumulative Timesteps: 1,079,264,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1079264818...
Checkpoint 1079264818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,021.42611
Policy Entropy: 3.79887
Value Function Loss: 0.02271

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.47167

Collected Steps per Second: 21,388.04083
Overall Steps per Second: 10,201.93774

Timestep Collection Time: 2.33841
Timestep Consumption Time: 2.56399
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.90240

Cumulative Model Updates: 129,434
Cumulative Timesteps: 1,079,314,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,482.05238
Policy Entropy: 3.79300
Value Function Loss: 0.02171

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.63394
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 22,614.67052
Overall Steps per Second: 10,776.03755

Timestep Collection Time: 2.21219
Timestep Consumption Time: 2.43033
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.64252

Cumulative Model Updates: 129,440
Cumulative Timesteps: 1,079,364,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1079364860...
Checkpoint 1079364860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,129.46731
Policy Entropy: 3.77459
Value Function Loss: 0.02547

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.61955
Value Function Update Magnitude: 0.68621

Collected Steps per Second: 22,206.75696
Overall Steps per Second: 10,632.50277

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.70482

Cumulative Model Updates: 129,446
Cumulative Timesteps: 1,079,414,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.69534
Policy Entropy: 3.74007
Value Function Loss: 0.02673

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.62643
Value Function Update Magnitude: 0.72523

Collected Steps per Second: 22,481.66819
Overall Steps per Second: 10,487.15539

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.54462
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.76945

Cumulative Model Updates: 129,452
Cumulative Timesteps: 1,079,464,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1079464902...
Checkpoint 1079464902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,685.22044
Policy Entropy: 3.71575
Value Function Loss: 0.03163

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17920
Policy Update Magnitude: 0.62039
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 22,147.21063
Overall Steps per Second: 10,589.03278

Timestep Collection Time: 2.25861
Timestep Consumption Time: 2.46533
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.72394

Cumulative Model Updates: 129,458
Cumulative Timesteps: 1,079,514,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,817.04263
Policy Entropy: 3.72852
Value Function Loss: 0.02608

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.18167
Policy Update Magnitude: 0.60565
Value Function Update Magnitude: 0.48251

Collected Steps per Second: 22,193.07836
Overall Steps per Second: 10,515.46987

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.50365
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.75813

Cumulative Model Updates: 129,464
Cumulative Timesteps: 1,079,564,958

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1079564958...
Checkpoint 1079564958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,786.86346
Policy Entropy: 3.73506
Value Function Loss: 0.02244

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.57071
Value Function Update Magnitude: 0.44069

Collected Steps per Second: 21,840.27792
Overall Steps per Second: 10,574.07645

Timestep Collection Time: 2.28990
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.72968

Cumulative Model Updates: 129,470
Cumulative Timesteps: 1,079,614,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,854.44775
Policy Entropy: 3.74295
Value Function Loss: 0.02674

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.26226
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.48855

Collected Steps per Second: 22,169.69089
Overall Steps per Second: 10,467.94827

Timestep Collection Time: 2.25533
Timestep Consumption Time: 2.52115
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.77649

Cumulative Model Updates: 129,476
Cumulative Timesteps: 1,079,664,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1079664970...
Checkpoint 1079664970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,534.50430
Policy Entropy: 3.74908
Value Function Loss: 0.03821

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.21613
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.67285

Collected Steps per Second: 22,224.88483
Overall Steps per Second: 10,670.12995

Timestep Collection Time: 2.25009
Timestep Consumption Time: 2.43664
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68673

Cumulative Model Updates: 129,482
Cumulative Timesteps: 1,079,714,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,882.48157
Policy Entropy: 3.79403
Value Function Loss: 0.04639

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.19095
Policy Update Magnitude: 0.70608
Value Function Update Magnitude: 0.84889

Collected Steps per Second: 22,223.69450
Overall Steps per Second: 10,549.04139

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.49061
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.74109

Cumulative Model Updates: 129,488
Cumulative Timesteps: 1,079,764,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1079764992...
Checkpoint 1079764992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,275.16506
Policy Entropy: 3.85429
Value Function Loss: 0.05157

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.17199
Policy Update Magnitude: 0.90556
Value Function Update Magnitude: 0.71703

Collected Steps per Second: 21,975.14810
Overall Steps per Second: 10,283.51843

Timestep Collection Time: 2.27666
Timestep Consumption Time: 2.58840
PPO Batch Consumption Time: 0.30706
Total Iteration Time: 4.86507

Cumulative Model Updates: 129,494
Cumulative Timesteps: 1,079,815,022

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,748.01674
Policy Entropy: 3.92983
Value Function Loss: 0.04702

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 1.05320
Value Function Update Magnitude: 0.53315

Collected Steps per Second: 21,803.05673
Overall Steps per Second: 10,492.81843

Timestep Collection Time: 2.29408
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.76688

Cumulative Model Updates: 129,500
Cumulative Timesteps: 1,079,865,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1079865040...
Checkpoint 1079865040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108.93330
Policy Entropy: 3.96324
Value Function Loss: 0.04506

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 1.10985
Value Function Update Magnitude: 0.42392

Collected Steps per Second: 22,096.23392
Overall Steps per Second: 10,809.00492

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.36474
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.62929

Cumulative Model Updates: 129,506
Cumulative Timesteps: 1,079,915,078

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,743.16083
Policy Entropy: 3.96010
Value Function Loss: 0.03983

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 1.08440
Value Function Update Magnitude: 0.43074

Collected Steps per Second: 22,027.43217
Overall Steps per Second: 10,766.46972

Timestep Collection Time: 2.26990
Timestep Consumption Time: 2.37415
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64405

Cumulative Model Updates: 129,512
Cumulative Timesteps: 1,079,965,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1079965078...
Checkpoint 1079965078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.66575
Policy Entropy: 3.93450
Value Function Loss: 0.04210

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.99806
Value Function Update Magnitude: 0.48086

Collected Steps per Second: 22,057.87765
Overall Steps per Second: 10,804.44374

Timestep Collection Time: 2.26758
Timestep Consumption Time: 2.36181
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.62939

Cumulative Model Updates: 129,518
Cumulative Timesteps: 1,080,015,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.22826
Policy Entropy: 3.86952
Value Function Loss: 0.03712

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.83043
Value Function Update Magnitude: 0.51186

Collected Steps per Second: 21,586.03279
Overall Steps per Second: 10,533.46095

Timestep Collection Time: 2.31770
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.74963

Cumulative Model Updates: 129,524
Cumulative Timesteps: 1,080,065,126

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1080065126...
Checkpoint 1080065126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,788.15329
Policy Entropy: 3.86911
Value Function Loss: 0.03491

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.71837
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 21,482.30112
Overall Steps per Second: 10,481.25310

Timestep Collection Time: 2.32768
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.77080

Cumulative Model Updates: 129,530
Cumulative Timesteps: 1,080,115,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.63393
Policy Entropy: 3.88761
Value Function Loss: 0.03217

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.75917
Value Function Update Magnitude: 0.76739

Collected Steps per Second: 21,996.97863
Overall Steps per Second: 10,766.94719

Timestep Collection Time: 2.27413
Timestep Consumption Time: 2.37194
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.64607

Cumulative Model Updates: 129,536
Cumulative Timesteps: 1,080,165,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1080165154...
Checkpoint 1080165154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.08516
Policy Entropy: 3.93441
Value Function Loss: 0.03204

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.21945
Policy Update Magnitude: 0.65098
Value Function Update Magnitude: 0.82552

Collected Steps per Second: 21,684.20623
Overall Steps per Second: 10,570.84397

Timestep Collection Time: 2.30583
Timestep Consumption Time: 2.42417
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.72999

Cumulative Model Updates: 129,542
Cumulative Timesteps: 1,080,215,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,802.49577
Policy Entropy: 3.98204
Value Function Loss: 0.03521

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16295
Policy Update Magnitude: 0.59653
Value Function Update Magnitude: 0.83789

Collected Steps per Second: 22,052.81518
Overall Steps per Second: 10,593.78273

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.72032

Cumulative Model Updates: 129,548
Cumulative Timesteps: 1,080,265,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1080265160...
Checkpoint 1080265160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.30387
Policy Entropy: 4.02341
Value Function Loss: 0.03443

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11114
Policy Update Magnitude: 0.82148
Value Function Update Magnitude: 0.76540

Collected Steps per Second: 22,441.13833
Overall Steps per Second: 10,716.34699

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.66857

Cumulative Model Updates: 129,554
Cumulative Timesteps: 1,080,315,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,943.38863
Policy Entropy: 4.03176
Value Function Loss: 0.03834

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.99858
Value Function Update Magnitude: 0.71072

Collected Steps per Second: 22,478.47090
Overall Steps per Second: 10,533.20680

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.52406
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74974

Cumulative Model Updates: 129,560
Cumulative Timesteps: 1,080,365,220

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1080365220...
Checkpoint 1080365220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,262.42290
Policy Entropy: 4.06045
Value Function Loss: 0.03558

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.97158
Value Function Update Magnitude: 0.75538

Collected Steps per Second: 22,474.38262
Overall Steps per Second: 10,755.79268

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.65089

Cumulative Model Updates: 129,566
Cumulative Timesteps: 1,080,415,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.38960
Policy Entropy: 4.08320
Value Function Loss: 0.03349

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.85812
Value Function Update Magnitude: 0.81688

Collected Steps per Second: 21,990.81060
Overall Steps per Second: 10,354.56981

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.55644
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.83130

Cumulative Model Updates: 129,572
Cumulative Timesteps: 1,080,465,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1080465270...
Checkpoint 1080465270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.48290
Policy Entropy: 4.13798
Value Function Loss: 0.02784

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.80112
Value Function Update Magnitude: 0.88063

Collected Steps per Second: 22,720.80041
Overall Steps per Second: 10,735.65897

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.65961

Cumulative Model Updates: 129,578
Cumulative Timesteps: 1,080,515,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.56809
Policy Entropy: 4.12546
Value Function Loss: 0.02867

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.05010
Policy Update Magnitude: 0.79733
Value Function Update Magnitude: 0.89244

Collected Steps per Second: 22,403.19583
Overall Steps per Second: 10,877.04051

Timestep Collection Time: 2.23361
Timestep Consumption Time: 2.36691
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60052

Cumulative Model Updates: 129,584
Cumulative Timesteps: 1,080,565,334

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1080565334...
Checkpoint 1080565334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32285
Policy Entropy: 4.07756
Value Function Loss: 0.03354

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.83207
Value Function Update Magnitude: 0.90539

Collected Steps per Second: 22,157.83005
Overall Steps per Second: 10,691.71949

Timestep Collection Time: 2.25690
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.67726

Cumulative Model Updates: 129,590
Cumulative Timesteps: 1,080,615,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,339.21771
Policy Entropy: 4.03159
Value Function Loss: 0.03370

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.85113
Value Function Update Magnitude: 0.89414

Collected Steps per Second: 22,847.88722
Overall Steps per Second: 10,773.19506

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.45345
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.64245

Cumulative Model Updates: 129,596
Cumulative Timesteps: 1,080,665,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1080665356...
Checkpoint 1080665356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.67293
Policy Entropy: 4.02841
Value Function Loss: 0.03015

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.77227
Value Function Update Magnitude: 0.87417

Collected Steps per Second: 22,587.43951
Overall Steps per Second: 10,711.05219

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.45544
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.66994

Cumulative Model Updates: 129,602
Cumulative Timesteps: 1,080,715,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.90544
Policy Entropy: 4.03163
Value Function Loss: 0.02767

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.71418
Value Function Update Magnitude: 0.87531

Collected Steps per Second: 22,292.67235
Overall Steps per Second: 10,512.84508

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.51470
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.75894

Cumulative Model Updates: 129,608
Cumulative Timesteps: 1,080,765,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1080765406...
Checkpoint 1080765406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.53848
Policy Entropy: 4.01993
Value Function Loss: 0.02757

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05186
Policy Update Magnitude: 0.67310
Value Function Update Magnitude: 0.84326

Collected Steps per Second: 22,612.48947
Overall Steps per Second: 10,604.78464

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.50429
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.71598

Cumulative Model Updates: 129,614
Cumulative Timesteps: 1,080,815,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184.55869
Policy Entropy: 4.00623
Value Function Loss: 0.02751

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.04603
Policy Update Magnitude: 0.66328
Value Function Update Magnitude: 0.79295

Collected Steps per Second: 22,435.89873
Overall Steps per Second: 10,684.42736

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.68102

Cumulative Model Updates: 129,620
Cumulative Timesteps: 1,080,865,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1080865432...
Checkpoint 1080865432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,774.00794
Policy Entropy: 3.98045
Value Function Loss: 0.02713

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04976
Policy Update Magnitude: 0.67762
Value Function Update Magnitude: 0.76575

Collected Steps per Second: 22,405.81309
Overall Steps per Second: 10,698.91894

Timestep Collection Time: 2.23165
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.67356

Cumulative Model Updates: 129,626
Cumulative Timesteps: 1,080,915,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,088.14293
Policy Entropy: 3.97316
Value Function Loss: 0.02706

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.70378
Value Function Update Magnitude: 0.82866

Collected Steps per Second: 22,644.39355
Overall Steps per Second: 10,796.15490

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.63239

Cumulative Model Updates: 129,632
Cumulative Timesteps: 1,080,965,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1080965446...
Checkpoint 1080965446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,713.26229
Policy Entropy: 3.98157
Value Function Loss: 0.03169

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06789
Policy Update Magnitude: 0.75403
Value Function Update Magnitude: 0.85169

Collected Steps per Second: 22,347.85984
Overall Steps per Second: 10,727.02255

Timestep Collection Time: 2.23744
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.66131

Cumulative Model Updates: 129,638
Cumulative Timesteps: 1,081,015,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,293.53492
Policy Entropy: 3.99462
Value Function Loss: 0.03773

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.70773
Value Function Update Magnitude: 0.79787

Collected Steps per Second: 22,149.04261
Overall Steps per Second: 10,483.64611

Timestep Collection Time: 2.25798
Timestep Consumption Time: 2.51250
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.77048

Cumulative Model Updates: 129,644
Cumulative Timesteps: 1,081,065,460

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1081065460...
Checkpoint 1081065460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.05937
Policy Entropy: 3.99873
Value Function Loss: 0.04011

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.76479
Value Function Update Magnitude: 0.65781

Collected Steps per Second: 22,388.38981
Overall Steps per Second: 10,700.98102

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.67303

Cumulative Model Updates: 129,650
Cumulative Timesteps: 1,081,115,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.63005
Policy Entropy: 3.99006
Value Function Loss: 0.03888

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.75049
Value Function Update Magnitude: 0.64471

Collected Steps per Second: 21,687.47788
Overall Steps per Second: 10,486.79446

Timestep Collection Time: 2.30714
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.77133

Cumulative Model Updates: 129,656
Cumulative Timesteps: 1,081,165,502

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1081165502...
Checkpoint 1081165502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,637.87188
Policy Entropy: 3.95734
Value Function Loss: 0.03647

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.69137
Value Function Update Magnitude: 0.69724

Collected Steps per Second: 21,684.26823
Overall Steps per Second: 10,666.26660

Timestep Collection Time: 2.30693
Timestep Consumption Time: 2.38300
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.68993

Cumulative Model Updates: 129,662
Cumulative Timesteps: 1,081,215,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.22410
Policy Entropy: 3.95688
Value Function Loss: 0.03190

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.70194
Value Function Update Magnitude: 0.68103

Collected Steps per Second: 22,814.61291
Overall Steps per Second: 10,638.03533

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.70030

Cumulative Model Updates: 129,668
Cumulative Timesteps: 1,081,265,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1081265528...
Checkpoint 1081265528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.68127
Policy Entropy: 3.91822
Value Function Loss: 0.02866

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.64451
Value Function Update Magnitude: 0.66331

Collected Steps per Second: 21,559.87158
Overall Steps per Second: 10,572.37319

Timestep Collection Time: 2.31959
Timestep Consumption Time: 2.41067
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.73025

Cumulative Model Updates: 129,674
Cumulative Timesteps: 1,081,315,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.09491
Policy Entropy: 3.86894
Value Function Loss: 0.02424

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15589
Policy Update Magnitude: 0.54671
Value Function Update Magnitude: 0.63796

Collected Steps per Second: 21,843.05491
Overall Steps per Second: 10,608.01737

Timestep Collection Time: 2.29052
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71643

Cumulative Model Updates: 129,680
Cumulative Timesteps: 1,081,365,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1081365570...
Checkpoint 1081365570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,728.06696
Policy Entropy: 3.79989
Value Function Loss: 0.02674

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17652
Policy Update Magnitude: 0.47866
Value Function Update Magnitude: 0.69116

Collected Steps per Second: 21,746.25326
Overall Steps per Second: 10,567.02000

Timestep Collection Time: 2.30063
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.73454

Cumulative Model Updates: 129,686
Cumulative Timesteps: 1,081,415,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,706.23209
Policy Entropy: 3.78441
Value Function Loss: 0.02798

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16669
Policy Update Magnitude: 0.43568
Value Function Update Magnitude: 0.76208

Collected Steps per Second: 21,665.67009
Overall Steps per Second: 10,558.65510

Timestep Collection Time: 2.30891
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73772

Cumulative Model Updates: 129,692
Cumulative Timesteps: 1,081,465,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1081465624...
Checkpoint 1081465624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,753.52300
Policy Entropy: 3.76550
Value Function Loss: 0.02604

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.49858
Value Function Update Magnitude: 0.78337

Collected Steps per Second: 21,779.56464
Overall Steps per Second: 10,461.01344

Timestep Collection Time: 2.29729
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.78290

Cumulative Model Updates: 129,698
Cumulative Timesteps: 1,081,515,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.17037
Policy Entropy: 3.76931
Value Function Loss: 0.02073

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.50518
Value Function Update Magnitude: 0.71749

Collected Steps per Second: 22,919.71184
Overall Steps per Second: 10,864.09766

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.60563

Cumulative Model Updates: 129,704
Cumulative Timesteps: 1,081,565,694

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1081565694...
Checkpoint 1081565694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,212.04655
Policy Entropy: 3.76308
Value Function Loss: 0.02130

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.45692
Value Function Update Magnitude: 0.66716

Collected Steps per Second: 22,202.65140
Overall Steps per Second: 10,688.97627

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.68127

Cumulative Model Updates: 129,710
Cumulative Timesteps: 1,081,615,732

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,048.16008
Policy Entropy: 3.78703
Value Function Loss: 0.02341

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.47758
Value Function Update Magnitude: 0.76293

Collected Steps per Second: 22,060.91873
Overall Steps per Second: 10,481.24406

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.77176

Cumulative Model Updates: 129,716
Cumulative Timesteps: 1,081,665,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1081665746...
Checkpoint 1081665746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,259.24291
Policy Entropy: 3.79496
Value Function Loss: 0.02714

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.55261
Value Function Update Magnitude: 0.85740

Collected Steps per Second: 22,231.34060
Overall Steps per Second: 10,742.41734

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.40652
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.65668

Cumulative Model Updates: 129,722
Cumulative Timesteps: 1,081,715,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.71517
Policy Entropy: 3.82139
Value Function Loss: 0.02700

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.56111
Value Function Update Magnitude: 0.78015

Collected Steps per Second: 22,496.46527
Overall Steps per Second: 10,787.53026

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.63591

Cumulative Model Updates: 129,728
Cumulative Timesteps: 1,081,765,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1081765780...
Checkpoint 1081765780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.87698
Policy Entropy: 3.81809
Value Function Loss: 0.02941

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.70936

Collected Steps per Second: 22,342.47962
Overall Steps per Second: 10,477.09559

Timestep Collection Time: 2.23861
Timestep Consumption Time: 2.53524
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.77384

Cumulative Model Updates: 129,734
Cumulative Timesteps: 1,081,815,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.40693
Policy Entropy: 3.82121
Value Function Loss: 0.02951

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.57320
Value Function Update Magnitude: 0.72682

Collected Steps per Second: 22,347.53096
Overall Steps per Second: 10,471.43767

Timestep Collection Time: 2.23801
Timestep Consumption Time: 2.53822
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.77623

Cumulative Model Updates: 129,740
Cumulative Timesteps: 1,081,865,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1081865810...
Checkpoint 1081865810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.95307
Policy Entropy: 3.79626
Value Function Loss: 0.02979

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.74541

Collected Steps per Second: 22,529.72234
Overall Steps per Second: 10,813.39154

Timestep Collection Time: 2.22009
Timestep Consumption Time: 2.40547
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62556

Cumulative Model Updates: 129,746
Cumulative Timesteps: 1,081,915,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,316.64935
Policy Entropy: 3.78231
Value Function Loss: 0.02775

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.72977

Collected Steps per Second: 22,671.09263
Overall Steps per Second: 10,611.28874

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.50701
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.71291

Cumulative Model Updates: 129,752
Cumulative Timesteps: 1,081,965,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1081965838...
Checkpoint 1081965838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,052.34913
Policy Entropy: 3.76581
Value Function Loss: 0.03040

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.69980

Collected Steps per Second: 22,574.76022
Overall Steps per Second: 10,794.18651

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63379

Cumulative Model Updates: 129,758
Cumulative Timesteps: 1,082,015,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,463.52684
Policy Entropy: 3.75764
Value Function Loss: 0.03057

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.69507

Collected Steps per Second: 22,195.44927
Overall Steps per Second: 10,593.34105

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.46802
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.72146

Cumulative Model Updates: 129,764
Cumulative Timesteps: 1,082,065,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1082065872...
Checkpoint 1082065872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,939.65772
Policy Entropy: 3.74869
Value Function Loss: 0.03062

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.69500

Collected Steps per Second: 22,635.11855
Overall Steps per Second: 10,635.11623

Timestep Collection Time: 2.21011
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.70385

Cumulative Model Updates: 129,770
Cumulative Timesteps: 1,082,115,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,939.65772
Policy Entropy: 3.72741
Value Function Loss: 0.02625

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.72290

Collected Steps per Second: 22,717.69252
Overall Steps per Second: 10,777.47513

Timestep Collection Time: 2.20198
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.64153

Cumulative Model Updates: 129,776
Cumulative Timesteps: 1,082,165,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1082165922...
Checkpoint 1082165922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,842.55983
Policy Entropy: 3.71605
Value Function Loss: 0.02531

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.50727
Value Function Update Magnitude: 0.58076

Collected Steps per Second: 22,452.00332
Overall Steps per Second: 10,546.10105

Timestep Collection Time: 2.22769
Timestep Consumption Time: 2.51492
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.74261

Cumulative Model Updates: 129,782
Cumulative Timesteps: 1,082,215,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,060.62472
Policy Entropy: 3.72289
Value Function Loss: 0.02336

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.45944
Value Function Update Magnitude: 0.46768

Collected Steps per Second: 22,744.79531
Overall Steps per Second: 10,540.41626

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.54717
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.74706

Cumulative Model Updates: 129,788
Cumulative Timesteps: 1,082,265,974

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1082265974...
Checkpoint 1082265974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,564.08883
Policy Entropy: 3.72888
Value Function Loss: 0.02543

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.51286

Collected Steps per Second: 22,206.36589
Overall Steps per Second: 10,636.92978

Timestep Collection Time: 2.25161
Timestep Consumption Time: 2.44900
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.70060

Cumulative Model Updates: 129,794
Cumulative Timesteps: 1,082,315,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,737.15984
Policy Entropy: 3.74010
Value Function Loss: 0.02492

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.47113
Value Function Update Magnitude: 0.52015

Collected Steps per Second: 22,488.22441
Overall Steps per Second: 10,516.37363

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.53181
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.75582

Cumulative Model Updates: 129,800
Cumulative Timesteps: 1,082,365,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1082365988...
Checkpoint 1082365988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,246.58966
Policy Entropy: 3.73449
Value Function Loss: 0.02599

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.48317
Value Function Update Magnitude: 0.60938

Collected Steps per Second: 22,107.16866
Overall Steps per Second: 10,588.02077

Timestep Collection Time: 2.26171
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.72232

Cumulative Model Updates: 129,806
Cumulative Timesteps: 1,082,415,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,287.52479
Policy Entropy: 3.72327
Value Function Loss: 0.02246

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.51493
Value Function Update Magnitude: 0.70729

Collected Steps per Second: 22,365.66866
Overall Steps per Second: 10,509.46502

Timestep Collection Time: 2.23557
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.75762

Cumulative Model Updates: 129,812
Cumulative Timesteps: 1,082,465,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1082465988...
Checkpoint 1082465988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,287.52479
Policy Entropy: 3.70522
Value Function Loss: 0.02148

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.50177
Value Function Update Magnitude: 0.70447

Collected Steps per Second: 22,222.75134
Overall Steps per Second: 10,614.46296

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.71300

Cumulative Model Updates: 129,818
Cumulative Timesteps: 1,082,516,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,135.59688
Policy Entropy: 3.70923
Value Function Loss: 0.02418

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14428
Policy Update Magnitude: 0.48782
Value Function Update Magnitude: 0.55675

Collected Steps per Second: 22,189.28413
Overall Steps per Second: 10,641.16838

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.69967

Cumulative Model Updates: 129,824
Cumulative Timesteps: 1,082,566,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1082566024...
Checkpoint 1082566024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,962.41570
Policy Entropy: 3.71946
Value Function Loss: 0.02565

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.49646
Value Function Update Magnitude: 0.41519

Collected Steps per Second: 22,641.01301
Overall Steps per Second: 10,756.18214

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64979

Cumulative Model Updates: 129,830
Cumulative Timesteps: 1,082,616,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,009.46933
Policy Entropy: 3.73519
Value Function Loss: 0.02813

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.39062

Collected Steps per Second: 22,169.35855
Overall Steps per Second: 10,519.65577

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.49894
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.75548

Cumulative Model Updates: 129,836
Cumulative Timesteps: 1,082,666,064

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1082666064...
Checkpoint 1082666064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,877.00317
Policy Entropy: 3.75450
Value Function Loss: 0.02532

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.51765
Value Function Update Magnitude: 0.45900

Collected Steps per Second: 22,693.82109
Overall Steps per Second: 10,748.68292

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.65304

Cumulative Model Updates: 129,842
Cumulative Timesteps: 1,082,716,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.61694
Policy Entropy: 3.77164
Value Function Loss: 0.02507

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.56633

Collected Steps per Second: 22,169.20635
Overall Steps per Second: 10,448.06781

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.53090
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.78691

Cumulative Model Updates: 129,848
Cumulative Timesteps: 1,082,766,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1082766092...
Checkpoint 1082766092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210.59000
Policy Entropy: 3.76923
Value Function Loss: 0.02376

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.53613
Value Function Update Magnitude: 0.49510

Collected Steps per Second: 22,748.81655
Overall Steps per Second: 10,806.66061

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.42983
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62863

Cumulative Model Updates: 129,854
Cumulative Timesteps: 1,082,816,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,776.22523
Policy Entropy: 3.74992
Value Function Loss: 0.02792

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.52711
Value Function Update Magnitude: 0.49837

Collected Steps per Second: 22,456.35620
Overall Steps per Second: 10,517.70792

Timestep Collection Time: 2.22770
Timestep Consumption Time: 2.52866
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.75636

Cumulative Model Updates: 129,860
Cumulative Timesteps: 1,082,866,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1082866138...
Checkpoint 1082866138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,716.71260
Policy Entropy: 3.76283
Value Function Loss: 0.03084

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.52310

Collected Steps per Second: 22,638.06585
Overall Steps per Second: 10,691.05018

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.46824
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.67700

Cumulative Model Updates: 129,866
Cumulative Timesteps: 1,082,916,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.76794
Policy Entropy: 3.77943
Value Function Loss: 0.03218

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.52987
Value Function Update Magnitude: 0.58994

Collected Steps per Second: 22,168.20369
Overall Steps per Second: 10,477.88149

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.51698
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.77291

Cumulative Model Updates: 129,872
Cumulative Timesteps: 1,082,966,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1082966150...
Checkpoint 1082966150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388.79748
Policy Entropy: 3.78195
Value Function Loss: 0.02951

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.57045

Collected Steps per Second: 22,574.64279
Overall Steps per Second: 10,637.56701

Timestep Collection Time: 2.21611
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70296

Cumulative Model Updates: 129,878
Cumulative Timesteps: 1,083,016,178

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209.80253
Policy Entropy: 3.75472
Value Function Loss: 0.02709

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.54245
Value Function Update Magnitude: 0.56684

Collected Steps per Second: 22,444.29160
Overall Steps per Second: 10,528.98220

Timestep Collection Time: 2.22827
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.74994

Cumulative Model Updates: 129,884
Cumulative Timesteps: 1,083,066,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1083066190...
Checkpoint 1083066190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,570.92870
Policy Entropy: 3.72986
Value Function Loss: 0.02800

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.55481

Collected Steps per Second: 20,989.96556
Overall Steps per Second: 10,123.75041

Timestep Collection Time: 2.38219
Timestep Consumption Time: 2.55689
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.93908

Cumulative Model Updates: 129,890
Cumulative Timesteps: 1,083,116,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,248.44842
Policy Entropy: 3.71966
Value Function Loss: 0.02722

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.52376
Value Function Update Magnitude: 0.52698

Collected Steps per Second: 22,515.44224
Overall Steps per Second: 10,612.36539

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.71412

Cumulative Model Updates: 129,896
Cumulative Timesteps: 1,083,166,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1083166220...
Checkpoint 1083166220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,248.44842
Policy Entropy: 3.70354
Value Function Loss: 0.02849

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.50839
Value Function Update Magnitude: 0.46101

Collected Steps per Second: 22,153.77474
Overall Steps per Second: 10,634.77080

Timestep Collection Time: 2.25785
Timestep Consumption Time: 2.44558
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.70344

Cumulative Model Updates: 129,902
Cumulative Timesteps: 1,083,216,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,781.57682
Policy Entropy: 3.71428
Value Function Loss: 0.02453

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.43069

Collected Steps per Second: 22,299.37879
Overall Steps per Second: 10,474.63712

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.53325
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.77725

Cumulative Model Updates: 129,908
Cumulative Timesteps: 1,083,266,280

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1083266280...
Checkpoint 1083266280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 196,371.61588
Policy Entropy: 3.71984
Value Function Loss: 0.02278

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.44214
Value Function Update Magnitude: 0.39921

Collected Steps per Second: 22,531.76487
Overall Steps per Second: 10,702.90161

Timestep Collection Time: 2.22024
Timestep Consumption Time: 2.45382
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.67406

Cumulative Model Updates: 129,914
Cumulative Timesteps: 1,083,316,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,471.11912
Policy Entropy: 3.73475
Value Function Loss: 0.02310

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.40825
Value Function Update Magnitude: 0.36764

Collected Steps per Second: 22,586.36039
Overall Steps per Second: 10,539.59468

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.53171
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.74667

Cumulative Model Updates: 129,920
Cumulative Timesteps: 1,083,366,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1083366334...
Checkpoint 1083366334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,749.65499
Policy Entropy: 3.75598
Value Function Loss: 0.02673

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.41651
Value Function Update Magnitude: 0.42062

Collected Steps per Second: 22,470.57124
Overall Steps per Second: 10,645.80144

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.47205
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.69763

Cumulative Model Updates: 129,926
Cumulative Timesteps: 1,083,416,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,891.02399
Policy Entropy: 3.78058
Value Function Loss: 0.02798

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.45120
Value Function Update Magnitude: 0.52015

Collected Steps per Second: 22,523.52176
Overall Steps per Second: 10,540.28232

Timestep Collection Time: 2.22017
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.74428

Cumulative Model Updates: 129,932
Cumulative Timesteps: 1,083,466,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1083466350...
Checkpoint 1083466350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,634.34351
Policy Entropy: 3.77261
Value Function Loss: 0.02861

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.46192
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 22,523.24773
Overall Steps per Second: 10,804.05485

Timestep Collection Time: 2.22055
Timestep Consumption Time: 2.40864
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.62919

Cumulative Model Updates: 129,938
Cumulative Timesteps: 1,083,516,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,514.17963
Policy Entropy: 3.76658
Value Function Loss: 0.02445

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.45223
Value Function Update Magnitude: 0.54237

Collected Steps per Second: 22,521.48026
Overall Steps per Second: 10,571.68181

Timestep Collection Time: 2.22143
Timestep Consumption Time: 2.51102
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.73245

Cumulative Model Updates: 129,944
Cumulative Timesteps: 1,083,566,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1083566394...
Checkpoint 1083566394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,947.46709
Policy Entropy: 3.74747
Value Function Loss: 0.02542

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.42577
Value Function Update Magnitude: 0.50198

Collected Steps per Second: 22,806.66246
Overall Steps per Second: 10,781.95708

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.63812

Cumulative Model Updates: 129,950
Cumulative Timesteps: 1,083,616,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,947.46709
Policy Entropy: 3.76059
Value Function Loss: 0.02262

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.42084
Value Function Update Magnitude: 0.39360

Collected Steps per Second: 22,217.66202
Overall Steps per Second: 10,487.09495

Timestep Collection Time: 2.25136
Timestep Consumption Time: 2.51831
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.76967

Cumulative Model Updates: 129,956
Cumulative Timesteps: 1,083,666,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1083666422...
Checkpoint 1083666422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,947.46709
Policy Entropy: 3.74614
Value Function Loss: 0.01966

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.40263
Value Function Update Magnitude: 0.36091

Collected Steps per Second: 22,687.98049
Overall Steps per Second: 10,739.80348

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.45275
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.65744

Cumulative Model Updates: 129,962
Cumulative Timesteps: 1,083,716,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,947.46709
Policy Entropy: 3.75001
Value Function Loss: 0.01504

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.41369
Value Function Update Magnitude: 0.47369

Collected Steps per Second: 22,847.69611
Overall Steps per Second: 10,618.74941

Timestep Collection Time: 2.18972
Timestep Consumption Time: 2.52176
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.71148

Cumulative Model Updates: 129,968
Cumulative Timesteps: 1,083,766,472

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1083766472...
Checkpoint 1083766472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,492.42048
Policy Entropy: 3.74444
Value Function Loss: 0.01649

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.40596
Value Function Update Magnitude: 0.49004

Collected Steps per Second: 22,812.31575
Overall Steps per Second: 10,679.96595

Timestep Collection Time: 2.19250
Timestep Consumption Time: 2.49066
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.68316

Cumulative Model Updates: 129,974
Cumulative Timesteps: 1,083,816,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,858.12860
Policy Entropy: 3.72961
Value Function Loss: 0.01743

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.38383
Value Function Update Magnitude: 0.44474

Collected Steps per Second: 22,674.27220
Overall Steps per Second: 10,779.12772

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.64045

Cumulative Model Updates: 129,980
Cumulative Timesteps: 1,083,866,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1083866508...
Checkpoint 1083866508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,927.98422
Policy Entropy: 3.74253
Value Function Loss: 0.01869

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14337
Policy Update Magnitude: 0.39582
Value Function Update Magnitude: 0.41504

Collected Steps per Second: 22,378.85982
Overall Steps per Second: 10,672.13426

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.68604

Cumulative Model Updates: 129,986
Cumulative Timesteps: 1,083,916,518

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,609.61303
Policy Entropy: 3.73214
Value Function Loss: 0.01978

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.39908
Value Function Update Magnitude: 0.43849

Collected Steps per Second: 21,729.45731
Overall Steps per Second: 10,535.05332

Timestep Collection Time: 2.30176
Timestep Consumption Time: 2.44582
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.74758

Cumulative Model Updates: 129,992
Cumulative Timesteps: 1,083,966,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1083966534...
Checkpoint 1083966534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,622.38471
Policy Entropy: 3.74463
Value Function Loss: 0.01979

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.40483
Value Function Update Magnitude: 0.47006

Collected Steps per Second: 22,044.65595
Overall Steps per Second: 10,637.42506

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.43265
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70114

Cumulative Model Updates: 129,998
Cumulative Timesteps: 1,084,016,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,886.26662
Policy Entropy: 3.74316
Value Function Loss: 0.02178

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.42179
Value Function Update Magnitude: 0.50616

Collected Steps per Second: 21,823.52165
Overall Steps per Second: 10,615.38172

Timestep Collection Time: 2.29248
Timestep Consumption Time: 2.42049
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.71297

Cumulative Model Updates: 130,004
Cumulative Timesteps: 1,084,066,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1084066572...
Checkpoint 1084066572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,127.58664
Policy Entropy: 3.75242
Value Function Loss: 0.01888

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.42614
Value Function Update Magnitude: 0.55327

Collected Steps per Second: 21,978.30790
Overall Steps per Second: 10,495.93955

Timestep Collection Time: 2.27524
Timestep Consumption Time: 2.48908
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.76432

Cumulative Model Updates: 130,010
Cumulative Timesteps: 1,084,116,578

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226,443.76720
Policy Entropy: 3.74876
Value Function Loss: 0.02081

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.41540
Value Function Update Magnitude: 0.63398

Collected Steps per Second: 22,584.90924
Overall Steps per Second: 10,779.55282

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.64027

Cumulative Model Updates: 130,016
Cumulative Timesteps: 1,084,166,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1084166598...
Checkpoint 1084166598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,005.91353
Policy Entropy: 3.76236
Value Function Loss: 0.01942

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.43911
Value Function Update Magnitude: 0.69716

Collected Steps per Second: 22,198.51015
Overall Steps per Second: 10,757.37991

Timestep Collection Time: 2.25267
Timestep Consumption Time: 2.39586
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.64853

Cumulative Model Updates: 130,022
Cumulative Timesteps: 1,084,216,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,860.70546
Policy Entropy: 3.75147
Value Function Loss: 0.02124

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.44163
Value Function Update Magnitude: 0.54194

Collected Steps per Second: 22,658.37723
Overall Steps per Second: 10,738.72093

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65698

Cumulative Model Updates: 130,028
Cumulative Timesteps: 1,084,266,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1084266614...
Checkpoint 1084266614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,252.23270
Policy Entropy: 3.75270
Value Function Loss: 0.01959

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.46001
Value Function Update Magnitude: 0.46585

Collected Steps per Second: 21,918.68198
Overall Steps per Second: 10,381.16798

Timestep Collection Time: 2.28143
Timestep Consumption Time: 2.53556
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.81699

Cumulative Model Updates: 130,034
Cumulative Timesteps: 1,084,316,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,229.59903
Policy Entropy: 3.72824
Value Function Loss: 0.02444

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.45984
Value Function Update Magnitude: 0.48843

Collected Steps per Second: 22,592.79090
Overall Steps per Second: 10,745.05825

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.44050
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.65386

Cumulative Model Updates: 130,040
Cumulative Timesteps: 1,084,366,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1084366626...
Checkpoint 1084366626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,089.35900
Policy Entropy: 3.74893
Value Function Loss: 0.02394

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.48570
Value Function Update Magnitude: 0.45991

Collected Steps per Second: 22,246.36230
Overall Steps per Second: 10,492.61029

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.76774

Cumulative Model Updates: 130,046
Cumulative Timesteps: 1,084,416,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,421.28226
Policy Entropy: 3.75522
Value Function Loss: 0.02473

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.50300
Value Function Update Magnitude: 0.47610

Collected Steps per Second: 21,925.81781
Overall Steps per Second: 10,487.56062

Timestep Collection Time: 2.28069
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.76813

Cumulative Model Updates: 130,052
Cumulative Timesteps: 1,084,466,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1084466658...
Checkpoint 1084466658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,996.31194
Policy Entropy: 3.75745
Value Function Loss: 0.02191

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.48617
Value Function Update Magnitude: 0.47797

Collected Steps per Second: 22,604.62488
Overall Steps per Second: 10,745.07720

Timestep Collection Time: 2.21362
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.65683

Cumulative Model Updates: 130,058
Cumulative Timesteps: 1,084,516,696

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,466.48623
Policy Entropy: 3.73870
Value Function Loss: 0.02122

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.45989
Value Function Update Magnitude: 0.48197

Collected Steps per Second: 21,604.57196
Overall Steps per Second: 10,547.38645

Timestep Collection Time: 2.31451
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.74089

Cumulative Model Updates: 130,064
Cumulative Timesteps: 1,084,566,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1084566700...
Checkpoint 1084566700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,322.85356
Policy Entropy: 3.72639
Value Function Loss: 0.02320

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.42958
Value Function Update Magnitude: 0.39480

Collected Steps per Second: 21,562.69945
Overall Steps per Second: 10,682.78467

Timestep Collection Time: 2.31947
Timestep Consumption Time: 2.36227
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.68174

Cumulative Model Updates: 130,070
Cumulative Timesteps: 1,084,616,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,023.48128
Policy Entropy: 3.73386
Value Function Loss: 0.02064

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.47580
Value Function Update Magnitude: 0.45401

Collected Steps per Second: 21,573.53839
Overall Steps per Second: 10,477.34256

Timestep Collection Time: 2.31895
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.77487

Cumulative Model Updates: 130,076
Cumulative Timesteps: 1,084,666,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1084666742...
Checkpoint 1084666742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,023.48128
Policy Entropy: 3.72560
Value Function Loss: 0.02217

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.48287
Value Function Update Magnitude: 0.46454

Collected Steps per Second: 21,578.16783
Overall Steps per Second: 10,406.20303

Timestep Collection Time: 2.31836
Timestep Consumption Time: 2.48896
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.80732

Cumulative Model Updates: 130,082
Cumulative Timesteps: 1,084,716,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,496.80102
Policy Entropy: 3.73837
Value Function Loss: 0.01987

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.46734
Value Function Update Magnitude: 0.42078

Collected Steps per Second: 22,492.70640
Overall Steps per Second: 10,754.82437

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.65001

Cumulative Model Updates: 130,088
Cumulative Timesteps: 1,084,766,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1084766778...
Checkpoint 1084766778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,292.83654
Policy Entropy: 3.73747
Value Function Loss: 0.02102

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.45721
Value Function Update Magnitude: 0.48868

Collected Steps per Second: 22,501.47905
Overall Steps per Second: 10,804.08527

Timestep Collection Time: 2.22288
Timestep Consumption Time: 2.40667
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.62955

Cumulative Model Updates: 130,094
Cumulative Timesteps: 1,084,816,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,292.83654
Policy Entropy: 3.74363
Value Function Loss: 0.01993

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.43989
Value Function Update Magnitude: 0.45809

Collected Steps per Second: 22,256.70074
Overall Steps per Second: 10,425.97427

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.79648

Cumulative Model Updates: 130,100
Cumulative Timesteps: 1,084,866,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1084866804...
Checkpoint 1084866804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,292.83654
Policy Entropy: 3.73821
Value Function Loss: 0.01806

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.41865
Value Function Update Magnitude: 0.48628

Collected Steps per Second: 22,491.02007
Overall Steps per Second: 10,519.51685

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.53128
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.75554

Cumulative Model Updates: 130,106
Cumulative Timesteps: 1,084,916,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,292.83654
Policy Entropy: 3.72387
Value Function Loss: 0.01662

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.38733
Value Function Update Magnitude: 0.52207

Collected Steps per Second: 22,104.61618
Overall Steps per Second: 10,405.80887

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.54528
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.80924

Cumulative Model Updates: 130,112
Cumulative Timesteps: 1,084,966,874

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1084966874...
Checkpoint 1084966874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,022.65716
Policy Entropy: 3.73295
Value Function Loss: 0.01645

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.39713
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 22,589.76778
Overall Steps per Second: 10,714.21699

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.45331
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.66670

Cumulative Model Updates: 130,118
Cumulative Timesteps: 1,085,016,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,911.14048
Policy Entropy: 3.72182
Value Function Loss: 0.02090

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.40403
Value Function Update Magnitude: 0.44478

Collected Steps per Second: 21,786.27220
Overall Steps per Second: 10,466.12269

Timestep Collection Time: 2.29567
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.77866

Cumulative Model Updates: 130,124
Cumulative Timesteps: 1,085,066,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1085066888...
Checkpoint 1085066888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,869.29245
Policy Entropy: 3.75228
Value Function Loss: 0.02029

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.44815
Value Function Update Magnitude: 0.44368

Collected Steps per Second: 22,283.13083
Overall Steps per Second: 10,621.97368

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.70911

Cumulative Model Updates: 130,130
Cumulative Timesteps: 1,085,116,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,901.61775
Policy Entropy: 3.73383
Value Function Loss: 0.02037

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.46504
Value Function Update Magnitude: 0.47332

Collected Steps per Second: 21,523.01684
Overall Steps per Second: 10,490.87753

Timestep Collection Time: 2.32347
Timestep Consumption Time: 2.44334
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.76681

Cumulative Model Updates: 130,136
Cumulative Timesteps: 1,085,166,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1085166916...
Checkpoint 1085166916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,901.61775
Policy Entropy: 3.75195
Value Function Loss: 0.01673

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.44778
Value Function Update Magnitude: 0.49642

Collected Steps per Second: 21,727.49674
Overall Steps per Second: 10,631.60315

Timestep Collection Time: 2.30178
Timestep Consumption Time: 2.40230
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.70409

Cumulative Model Updates: 130,142
Cumulative Timesteps: 1,085,216,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,710.47112
Policy Entropy: 3.72873
Value Function Loss: 0.01845

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.44220
Value Function Update Magnitude: 0.55119

Collected Steps per Second: 21,728.18111
Overall Steps per Second: 10,494.15902

Timestep Collection Time: 2.30171
Timestep Consumption Time: 2.46399
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.76570

Cumulative Model Updates: 130,148
Cumulative Timesteps: 1,085,266,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1085266940...
Checkpoint 1085266940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,886.72634
Policy Entropy: 3.74058
Value Function Loss: 0.01713

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.48967
Value Function Update Magnitude: 0.55349

Collected Steps per Second: 21,649.98288
Overall Steps per Second: 10,555.56830

Timestep Collection Time: 2.31012
Timestep Consumption Time: 2.42805
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.73816

Cumulative Model Updates: 130,154
Cumulative Timesteps: 1,085,316,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,847.25890
Policy Entropy: 3.74476
Value Function Loss: 0.01934

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.46749
Value Function Update Magnitude: 0.49247

Collected Steps per Second: 22,268.38912
Overall Steps per Second: 10,542.79723

Timestep Collection Time: 2.24605
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74409

Cumulative Model Updates: 130,160
Cumulative Timesteps: 1,085,366,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1085366970...
Checkpoint 1085366970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,733.93249
Policy Entropy: 3.74681
Value Function Loss: 0.01986

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.42738
Value Function Update Magnitude: 0.46267

Collected Steps per Second: 22,717.36184
Overall Steps per Second: 10,682.54582

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.48037
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.68203

Cumulative Model Updates: 130,166
Cumulative Timesteps: 1,085,416,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,220.54444
Policy Entropy: 3.74171
Value Function Loss: 0.02267

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.43851
Value Function Update Magnitude: 0.47608

Collected Steps per Second: 22,515.21044
Overall Steps per Second: 10,678.51656

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.46168
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.68249

Cumulative Model Updates: 130,172
Cumulative Timesteps: 1,085,466,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1085466988...
Checkpoint 1085466988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,966.62225
Policy Entropy: 3.73948
Value Function Loss: 0.02343

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.46724
Value Function Update Magnitude: 0.46394

Collected Steps per Second: 22,453.09890
Overall Steps per Second: 10,554.46470

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.51167
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.73961

Cumulative Model Updates: 130,178
Cumulative Timesteps: 1,085,517,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,963.01603
Policy Entropy: 3.74097
Value Function Loss: 0.02309

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.49544
Value Function Update Magnitude: 0.47959

Collected Steps per Second: 22,560.47908
Overall Steps per Second: 10,727.14560

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.44598
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.66331

Cumulative Model Updates: 130,184
Cumulative Timesteps: 1,085,567,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1085567036...
Checkpoint 1085567036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,595.84563
Policy Entropy: 3.75076
Value Function Loss: 0.02377

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.47795
Value Function Update Magnitude: 0.52210

Collected Steps per Second: 22,750.67830
Overall Steps per Second: 10,670.26078

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.48848
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68648

Cumulative Model Updates: 130,190
Cumulative Timesteps: 1,085,617,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,896.84316
Policy Entropy: 3.77328
Value Function Loss: 0.02087

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.45734
Value Function Update Magnitude: 0.58846

Collected Steps per Second: 22,246.66795
Overall Steps per Second: 10,444.12854

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.54077
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.78910

Cumulative Model Updates: 130,196
Cumulative Timesteps: 1,085,667,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1085667060...
Checkpoint 1085667060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.69902
Policy Entropy: 3.76786
Value Function Loss: 0.01988

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.42558
Value Function Update Magnitude: 0.55915

Collected Steps per Second: 22,427.23077
Overall Steps per Second: 10,523.28984

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.52294
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.75327

Cumulative Model Updates: 130,202
Cumulative Timesteps: 1,085,717,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.69902
Policy Entropy: 3.76482
Value Function Loss: 0.01790

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.38668
Value Function Update Magnitude: 0.47682

Collected Steps per Second: 22,397.69005
Overall Steps per Second: 10,605.11750

Timestep Collection Time: 2.23353
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.71716

Cumulative Model Updates: 130,208
Cumulative Timesteps: 1,085,767,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1085767106...
Checkpoint 1085767106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,745.87215
Policy Entropy: 3.75391
Value Function Loss: 0.01872

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.37435
Value Function Update Magnitude: 0.42241

Collected Steps per Second: 22,713.15183
Overall Steps per Second: 10,603.69291

Timestep Collection Time: 2.20225
Timestep Consumption Time: 2.51498
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.71722

Cumulative Model Updates: 130,214
Cumulative Timesteps: 1,085,817,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296,610.27642
Policy Entropy: 3.76216
Value Function Loss: 0.01926

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.42500
Value Function Update Magnitude: 0.45601

Collected Steps per Second: 22,353.67075
Overall Steps per Second: 10,513.16128

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.75594

Cumulative Model Updates: 130,220
Cumulative Timesteps: 1,085,867,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1085867126...
Checkpoint 1085867126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 458,513.03455
Policy Entropy: 3.74666
Value Function Loss: 0.01961

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.46229
Value Function Update Magnitude: 0.59243

Collected Steps per Second: 21,863.04720
Overall Steps per Second: 10,666.80883

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.40143
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.68931

Cumulative Model Updates: 130,226
Cumulative Timesteps: 1,085,917,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,764.09725
Policy Entropy: 3.74340
Value Function Loss: 0.01926

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.50807
Value Function Update Magnitude: 0.72062

Collected Steps per Second: 22,122.94967
Overall Steps per Second: 10,649.86781

Timestep Collection Time: 2.26127
Timestep Consumption Time: 2.43606
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69734

Cumulative Model Updates: 130,232
Cumulative Timesteps: 1,085,967,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1085967172...
Checkpoint 1085967172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,875.44288
Policy Entropy: 3.74458
Value Function Loss: 0.01990

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.54593
Value Function Update Magnitude: 0.74820

Collected Steps per Second: 22,021.20179
Overall Steps per Second: 10,637.58482

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70107

Cumulative Model Updates: 130,238
Cumulative Timesteps: 1,086,017,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,219.61511
Policy Entropy: 3.74477
Value Function Loss: 0.02363

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.78069

Collected Steps per Second: 21,814.02417
Overall Steps per Second: 10,438.54671

Timestep Collection Time: 2.29238
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.79051

Cumulative Model Updates: 130,244
Cumulative Timesteps: 1,086,067,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1086067186...
Checkpoint 1086067186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,325.14836
Policy Entropy: 3.76463
Value Function Loss: 0.02397

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.71139

Collected Steps per Second: 22,262.55522
Overall Steps per Second: 10,512.77849

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.75878

Cumulative Model Updates: 130,250
Cumulative Timesteps: 1,086,117,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,954.92894
Policy Entropy: 3.76297
Value Function Loss: 0.02439

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.53003
Value Function Update Magnitude: 0.57388

Collected Steps per Second: 22,498.43123
Overall Steps per Second: 10,638.79285

Timestep Collection Time: 2.22371
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70260

Cumulative Model Updates: 130,256
Cumulative Timesteps: 1,086,167,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1086167244...
Checkpoint 1086167244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.33600
Policy Entropy: 3.76896
Value Function Loss: 0.02117

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.50898
Value Function Update Magnitude: 0.47201

Collected Steps per Second: 22,675.69276
Overall Steps per Second: 10,580.47568

Timestep Collection Time: 2.20580
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.72739

Cumulative Model Updates: 130,262
Cumulative Timesteps: 1,086,217,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.15542
Policy Entropy: 3.74524
Value Function Loss: 0.02270

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.49711
Value Function Update Magnitude: 0.58238

Collected Steps per Second: 22,393.68472
Overall Steps per Second: 10,447.74327

Timestep Collection Time: 2.23402
Timestep Consumption Time: 2.55438
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.78840

Cumulative Model Updates: 130,268
Cumulative Timesteps: 1,086,267,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1086267290...
Checkpoint 1086267290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,354.83005
Policy Entropy: 3.74114
Value Function Loss: 0.02417

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.53277
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,312.48325
Overall Steps per Second: 10,629.89457

Timestep Collection Time: 2.24179
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.70560

Cumulative Model Updates: 130,274
Cumulative Timesteps: 1,086,317,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,784.73754
Policy Entropy: 3.74266
Value Function Loss: 0.02472

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.52133
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 22,526.69152
Overall Steps per Second: 10,359.69147

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.60837
PPO Batch Consumption Time: 0.30723
Total Iteration Time: 4.82929

Cumulative Model Updates: 130,280
Cumulative Timesteps: 1,086,367,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1086367340...
Checkpoint 1086367340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,775.74503
Policy Entropy: 3.74466
Value Function Loss: 0.02356

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.47705
Value Function Update Magnitude: 0.54972

Collected Steps per Second: 22,117.91407
Overall Steps per Second: 10,454.89450

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.78474

Cumulative Model Updates: 130,286
Cumulative Timesteps: 1,086,417,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,661.86471
Policy Entropy: 3.73897
Value Function Loss: 0.02080

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.44829
Value Function Update Magnitude: 0.49274

Collected Steps per Second: 22,616.95110
Overall Steps per Second: 10,583.65900

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.51414
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.72540

Cumulative Model Updates: 130,292
Cumulative Timesteps: 1,086,467,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1086467376...
Checkpoint 1086467376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,661.86471
Policy Entropy: 3.70878
Value Function Loss: 0.02318

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.42367
Value Function Update Magnitude: 0.44892

Collected Steps per Second: 21,632.39303
Overall Steps per Second: 10,652.28468

Timestep Collection Time: 2.31163
Timestep Consumption Time: 2.38277
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.69439

Cumulative Model Updates: 130,298
Cumulative Timesteps: 1,086,517,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,848.56282
Policy Entropy: 3.70259
Value Function Loss: 0.02144

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.44493
Value Function Update Magnitude: 0.47598

Collected Steps per Second: 21,705.78280
Overall Steps per Second: 10,512.08508

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.45290
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75643

Cumulative Model Updates: 130,304
Cumulative Timesteps: 1,086,567,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1086567382...
Checkpoint 1086567382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.68836
Value Function Loss: 0.02307

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.49724
Value Function Update Magnitude: 0.45170

Collected Steps per Second: 21,740.47335
Overall Steps per Second: 10,658.58459

Timestep Collection Time: 2.30032
Timestep Consumption Time: 2.39167
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.69199

Cumulative Model Updates: 130,310
Cumulative Timesteps: 1,086,617,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.71915
Value Function Loss: 0.02055

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.48688
Value Function Update Magnitude: 0.38904

Collected Steps per Second: 21,500.98393
Overall Steps per Second: 10,399.86033

Timestep Collection Time: 2.32659
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.81006

Cumulative Model Updates: 130,316
Cumulative Timesteps: 1,086,667,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1086667416...
Checkpoint 1086667416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.72779
Value Function Loss: 0.02052

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.44504
Value Function Update Magnitude: 0.32198

Collected Steps per Second: 22,261.26745
Overall Steps per Second: 10,561.63223

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.73544

Cumulative Model Updates: 130,322
Cumulative Timesteps: 1,086,717,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.72895
Value Function Loss: 0.01739

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.39344
Value Function Update Magnitude: 0.32276

Collected Steps per Second: 22,555.22773
Overall Steps per Second: 10,723.14332

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.66468

Cumulative Model Updates: 130,328
Cumulative Timesteps: 1,086,767,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1086767450...
Checkpoint 1086767450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.72440
Value Function Loss: 0.01751

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.37745
Value Function Update Magnitude: 0.37151

Collected Steps per Second: 22,367.73778
Overall Steps per Second: 10,665.34360

Timestep Collection Time: 2.23536
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.68808

Cumulative Model Updates: 130,334
Cumulative Timesteps: 1,086,817,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,571.02292
Policy Entropy: 3.72517
Value Function Loss: 0.01747

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.39157
Value Function Update Magnitude: 0.40180

Collected Steps per Second: 22,305.24577
Overall Steps per Second: 10,477.40951

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.77465

Cumulative Model Updates: 130,340
Cumulative Timesteps: 1,086,867,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1086867476...
Checkpoint 1086867476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.73005
Value Function Loss: 0.01910

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.41073
Value Function Update Magnitude: 0.43974

Collected Steps per Second: 22,347.71774
Overall Steps per Second: 10,695.59133

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.43804
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.67595

Cumulative Model Updates: 130,346
Cumulative Timesteps: 1,086,917,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.72875
Value Function Loss: 0.01769

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.42735
Value Function Update Magnitude: 0.52846

Collected Steps per Second: 22,398.72490
Overall Steps per Second: 10,568.19977

Timestep Collection Time: 2.23254
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.73174

Cumulative Model Updates: 130,352
Cumulative Timesteps: 1,086,967,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1086967494...
Checkpoint 1086967494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.72754
Value Function Loss: 0.01661

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14120
Policy Update Magnitude: 0.43679
Value Function Update Magnitude: 0.51713

Collected Steps per Second: 22,662.75601
Overall Steps per Second: 10,463.22316

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.57300
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.77979

Cumulative Model Updates: 130,358
Cumulative Timesteps: 1,087,017,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.73187
Value Function Loss: 0.01555

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14529
Policy Update Magnitude: 0.42876
Value Function Update Magnitude: 0.39505

Collected Steps per Second: 21,807.28329
Overall Steps per Second: 10,502.23628

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.76146

Cumulative Model Updates: 130,364
Cumulative Timesteps: 1,087,067,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1087067512...
Checkpoint 1087067512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.74293
Value Function Loss: 0.01637

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.42402
Value Function Update Magnitude: 0.37501

Collected Steps per Second: 21,084.64820
Overall Steps per Second: 10,525.99633

Timestep Collection Time: 2.37206
Timestep Consumption Time: 2.37942
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.75147

Cumulative Model Updates: 130,370
Cumulative Timesteps: 1,087,117,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,610.95100
Policy Entropy: 3.72309
Value Function Loss: 0.01713

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.46171
Value Function Update Magnitude: 0.51504

Collected Steps per Second: 21,723.99513
Overall Steps per Second: 10,407.59062

Timestep Collection Time: 2.30271
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.80649

Cumulative Model Updates: 130,376
Cumulative Timesteps: 1,087,167,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1087167550...
Checkpoint 1087167550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,431.27436
Policy Entropy: 3.70636
Value Function Loss: 0.02255

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.51523
Value Function Update Magnitude: 0.44336

Collected Steps per Second: 22,366.47842
Overall Steps per Second: 10,749.15535

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.65283

Cumulative Model Updates: 130,382
Cumulative Timesteps: 1,087,217,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325,342.22572
Policy Entropy: 3.71348
Value Function Loss: 0.02352

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.50523

Collected Steps per Second: 22,189.43216
Overall Steps per Second: 10,502.11119

Timestep Collection Time: 2.25332
Timestep Consumption Time: 2.50762
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.76095

Cumulative Model Updates: 130,388
Cumulative Timesteps: 1,087,267,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1087267564...
Checkpoint 1087267564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,043.52394
Policy Entropy: 3.73282
Value Function Loss: 0.02614

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.57464
Value Function Update Magnitude: 0.48619

Collected Steps per Second: 22,335.50909
Overall Steps per Second: 10,683.73444

Timestep Collection Time: 2.23904
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.68095

Cumulative Model Updates: 130,394
Cumulative Timesteps: 1,087,317,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,541.87419
Policy Entropy: 3.73444
Value Function Loss: 0.02410

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.58747
Value Function Update Magnitude: 0.47126

Collected Steps per Second: 22,187.50012
Overall Steps per Second: 10,472.19718

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.52173
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.77588

Cumulative Model Updates: 130,400
Cumulative Timesteps: 1,087,367,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1087367588...
Checkpoint 1087367588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,541.87419
Policy Entropy: 3.73308
Value Function Loss: 0.02116

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.56762
Value Function Update Magnitude: 0.49562

Collected Steps per Second: 22,409.59750
Overall Steps per Second: 10,689.76873

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.44745
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.67980

Cumulative Model Updates: 130,406
Cumulative Timesteps: 1,087,417,614

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,541.87419
Policy Entropy: 3.72112
Value Function Loss: 0.02008

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.51354
Value Function Update Magnitude: 0.51737

Collected Steps per Second: 22,297.33730
Overall Steps per Second: 10,470.74183

Timestep Collection Time: 2.24296
Timestep Consumption Time: 2.53340
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.77636

Cumulative Model Updates: 130,412
Cumulative Timesteps: 1,087,467,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1087467626...
Checkpoint 1087467626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,541.87419
Policy Entropy: 3.71122
Value Function Loss: 0.01973

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.52406
Value Function Update Magnitude: 0.54448

Collected Steps per Second: 22,554.27350
Overall Steps per Second: 10,729.33802

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.66217

Cumulative Model Updates: 130,418
Cumulative Timesteps: 1,087,517,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,541.87419
Policy Entropy: 3.69567
Value Function Loss: 0.01929

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.51003
Value Function Update Magnitude: 0.52627

Collected Steps per Second: 22,224.21023
Overall Steps per Second: 10,579.74139

Timestep Collection Time: 2.25016
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.72677

Cumulative Model Updates: 130,424
Cumulative Timesteps: 1,087,567,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1087567656...
Checkpoint 1087567656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,435.53200
Policy Entropy: 3.70895
Value Function Loss: 0.02113

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.50316
Value Function Update Magnitude: 0.47418

Collected Steps per Second: 21,772.36790
Overall Steps per Second: 10,633.24297

Timestep Collection Time: 2.29750
Timestep Consumption Time: 2.40680
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.70430

Cumulative Model Updates: 130,430
Cumulative Timesteps: 1,087,617,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,241.61050
Policy Entropy: 3.70327
Value Function Loss: 0.02147

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.48937

Collected Steps per Second: 21,620.14911
Overall Steps per Second: 10,336.38547

Timestep Collection Time: 2.31266
Timestep Consumption Time: 2.52462
PPO Batch Consumption Time: 0.30553
Total Iteration Time: 4.83728

Cumulative Model Updates: 130,436
Cumulative Timesteps: 1,087,667,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1087667678...
Checkpoint 1087667678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,241.61050
Policy Entropy: 3.72315
Value Function Loss: 0.02362

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.52701
Value Function Update Magnitude: 0.49534

Collected Steps per Second: 21,892.93289
Overall Steps per Second: 10,431.41768

Timestep Collection Time: 2.28466
Timestep Consumption Time: 2.51027
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.79494

Cumulative Model Updates: 130,442
Cumulative Timesteps: 1,087,717,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,834.61203
Policy Entropy: 3.71324
Value Function Loss: 0.02567

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.50961
Value Function Update Magnitude: 0.40825

Collected Steps per Second: 22,174.99244
Overall Steps per Second: 10,694.67840

Timestep Collection Time: 2.25479
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.67522

Cumulative Model Updates: 130,448
Cumulative Timesteps: 1,087,767,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1087767696...
Checkpoint 1087767696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,472.42903
Policy Entropy: 3.71035
Value Function Loss: 0.02896

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.54606
Value Function Update Magnitude: 0.40236

Collected Steps per Second: 22,405.21251
Overall Steps per Second: 10,754.13472

Timestep Collection Time: 2.23278
Timestep Consumption Time: 2.41901
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.65179

Cumulative Model Updates: 130,454
Cumulative Timesteps: 1,087,817,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,006.57013
Policy Entropy: 3.71447
Value Function Loss: 0.02900

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.58708
Value Function Update Magnitude: 0.45838

Collected Steps per Second: 22,275.19336
Overall Steps per Second: 10,473.15007

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.53037
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.77583

Cumulative Model Updates: 130,460
Cumulative Timesteps: 1,087,867,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1087867740...
Checkpoint 1087867740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,860.68860
Policy Entropy: 3.73238
Value Function Loss: 0.02789

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.61836
Value Function Update Magnitude: 0.48192

Collected Steps per Second: 22,576.04380
Overall Steps per Second: 10,563.16026

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.73381

Cumulative Model Updates: 130,466
Cumulative Timesteps: 1,087,917,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,635.24291
Policy Entropy: 3.73861
Value Function Loss: 0.02558

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.62464
Value Function Update Magnitude: 0.47454

Collected Steps per Second: 22,564.65578
Overall Steps per Second: 10,517.81720

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.53839
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.75460

Cumulative Model Updates: 130,472
Cumulative Timesteps: 1,087,967,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1087967752...
Checkpoint 1087967752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,628.29171
Policy Entropy: 3.74050
Value Function Loss: 0.02296

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.58807
Value Function Update Magnitude: 0.50506

Collected Steps per Second: 22,152.02891
Overall Steps per Second: 10,495.08936

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.76661

Cumulative Model Updates: 130,478
Cumulative Timesteps: 1,088,017,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,153.48334
Policy Entropy: 3.71775
Value Function Loss: 0.02174

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.61539
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,127.37614
Overall Steps per Second: 10,488.58988

Timestep Collection Time: 2.26046
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.76880

Cumulative Model Updates: 130,484
Cumulative Timesteps: 1,088,067,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1088067796...
Checkpoint 1088067796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,650.82154
Policy Entropy: 3.74436
Value Function Loss: 0.02073

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.64690
Value Function Update Magnitude: 0.64501

Collected Steps per Second: 22,312.66598
Overall Steps per Second: 10,466.51982

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.53687
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.77828

Cumulative Model Updates: 130,490
Cumulative Timesteps: 1,088,117,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,476.96772
Policy Entropy: 3.74163
Value Function Loss: 0.02652

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.64375
Value Function Update Magnitude: 0.57679

Collected Steps per Second: 22,681.89097
Overall Steps per Second: 10,585.36215

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.72464

Cumulative Model Updates: 130,496
Cumulative Timesteps: 1,088,167,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1088167820...
Checkpoint 1088167820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,840.43206
Policy Entropy: 3.75377
Value Function Loss: 0.02805

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.83384
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 22,248.92144
Overall Steps per Second: 10,508.80370

Timestep Collection Time: 2.24784
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.75906

Cumulative Model Updates: 130,502
Cumulative Timesteps: 1,088,217,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,084.31969
Policy Entropy: 3.76969
Value Function Loss: 0.02634

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16149
Policy Update Magnitude: 0.86121
Value Function Update Magnitude: 0.57528

Collected Steps per Second: 21,345.65185
Overall Steps per Second: 10,454.29989

Timestep Collection Time: 2.34305
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.78406

Cumulative Model Updates: 130,508
Cumulative Timesteps: 1,088,267,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1088267846...
Checkpoint 1088267846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,135.38512
Policy Entropy: 3.77516
Value Function Loss: 0.02424

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15597
Policy Update Magnitude: 0.75072
Value Function Update Magnitude: 0.61698

Collected Steps per Second: 21,764.20077
Overall Steps per Second: 10,509.43542

Timestep Collection Time: 2.29910
Timestep Consumption Time: 2.46215
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.76125

Cumulative Model Updates: 130,514
Cumulative Timesteps: 1,088,317,884

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,133.50643
Policy Entropy: 3.79140
Value Function Loss: 0.02295

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.23611
Policy Update Magnitude: 0.66768
Value Function Update Magnitude: 0.66686

Collected Steps per Second: 21,697.62928
Overall Steps per Second: 10,576.13478

Timestep Collection Time: 2.30486
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.72857

Cumulative Model Updates: 130,520
Cumulative Timesteps: 1,088,367,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1088367894...
Checkpoint 1088367894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552,677.28262
Policy Entropy: 3.76315
Value Function Loss: 0.03227

Mean KL Divergence: 0.02355
SB3 Clip Fraction: 0.24433
Policy Update Magnitude: 0.64384
Value Function Update Magnitude: 0.76159

Collected Steps per Second: 21,824.48105
Overall Steps per Second: 10,675.21162

Timestep Collection Time: 2.29119
Timestep Consumption Time: 2.39293
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.68412

Cumulative Model Updates: 130,526
Cumulative Timesteps: 1,088,417,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,237.42266
Policy Entropy: 3.79375
Value Function Loss: 0.04183

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.20976
Policy Update Magnitude: 0.74704
Value Function Update Magnitude: 0.68019

Collected Steps per Second: 21,699.37222
Overall Steps per Second: 10,603.54883

Timestep Collection Time: 2.30458
Timestep Consumption Time: 2.41157
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.71616

Cumulative Model Updates: 130,532
Cumulative Timesteps: 1,088,467,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1088467906...
Checkpoint 1088467906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,339.29216
Policy Entropy: 3.81418
Value Function Loss: 0.05016

Mean KL Divergence: 0.01893
SB3 Clip Fraction: 0.20435
Policy Update Magnitude: 0.83010
Value Function Update Magnitude: 0.79121

Collected Steps per Second: 21,872.47463
Overall Steps per Second: 10,646.58227

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.41162
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.69878

Cumulative Model Updates: 130,538
Cumulative Timesteps: 1,088,517,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,447.82335
Policy Entropy: 3.89674
Value Function Loss: 0.04838

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.17877
Policy Update Magnitude: 0.92559
Value Function Update Magnitude: 0.81793

Collected Steps per Second: 22,951.34486
Overall Steps per Second: 10,792.96384

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.45442
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.63320

Cumulative Model Updates: 130,544
Cumulative Timesteps: 1,088,567,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1088567938...
Checkpoint 1088567938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.06041
Policy Entropy: 4.01879
Value Function Loss: 0.04181

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 1.18334
Value Function Update Magnitude: 0.83457

Collected Steps per Second: 22,775.47798
Overall Steps per Second: 10,642.66118

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.70070

Cumulative Model Updates: 130,550
Cumulative Timesteps: 1,088,617,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92247
Policy Entropy: 4.10360
Value Function Loss: 0.03229

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 1.34027
Value Function Update Magnitude: 0.95723

Collected Steps per Second: 22,823.12811
Overall Steps per Second: 10,811.18106

Timestep Collection Time: 2.19085
Timestep Consumption Time: 2.43418
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62503

Cumulative Model Updates: 130,556
Cumulative Timesteps: 1,088,667,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1088667968...
Checkpoint 1088667968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.19122
Policy Entropy: 4.05403
Value Function Loss: 0.03355

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08459
Policy Update Magnitude: 1.26632
Value Function Update Magnitude: 1.07154

Collected Steps per Second: 22,375.50671
Overall Steps per Second: 10,700.84913

Timestep Collection Time: 2.23494
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.67327

Cumulative Model Updates: 130,562
Cumulative Timesteps: 1,088,717,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,681.22451
Policy Entropy: 3.97253
Value Function Loss: 0.03858

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 1.21301
Value Function Update Magnitude: 1.07636

Collected Steps per Second: 22,816.16094
Overall Steps per Second: 10,892.66109

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.40026
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.59300

Cumulative Model Updates: 130,568
Cumulative Timesteps: 1,088,768,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1088768006...
Checkpoint 1088768006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.62905
Policy Entropy: 3.93080
Value Function Loss: 0.04076

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 1.16800
Value Function Update Magnitude: 0.92808

Collected Steps per Second: 22,518.81609
Overall Steps per Second: 10,660.28181

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.69293

Cumulative Model Updates: 130,574
Cumulative Timesteps: 1,088,818,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.47113
Policy Entropy: 3.96349
Value Function Loss: 0.03856

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 1.03925
Value Function Update Magnitude: 0.89974

Collected Steps per Second: 22,512.47405
Overall Steps per Second: 10,933.32791

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.35218
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.57317

Cumulative Model Updates: 130,580
Cumulative Timesteps: 1,088,868,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1088868034...
Checkpoint 1088868034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,901.27585
Policy Entropy: 3.96766
Value Function Loss: 0.03804

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.94083
Value Function Update Magnitude: 0.73855

Collected Steps per Second: 22,148.24023
Overall Steps per Second: 10,677.07672

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.68368

Cumulative Model Updates: 130,586
Cumulative Timesteps: 1,088,918,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.85825
Policy Entropy: 3.96385
Value Function Loss: 0.03524

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.87216
Value Function Update Magnitude: 0.64438

Collected Steps per Second: 21,969.06086
Overall Steps per Second: 10,781.37439

Timestep Collection Time: 2.27675
Timestep Consumption Time: 2.36255
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.63930

Cumulative Model Updates: 130,592
Cumulative Timesteps: 1,088,968,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1088968060...
Checkpoint 1088968060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,021.72865
Policy Entropy: 3.92836
Value Function Loss: 0.03630

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.80459
Value Function Update Magnitude: 0.77094

Collected Steps per Second: 22,380.91427
Overall Steps per Second: 10,582.17489

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.72719

Cumulative Model Updates: 130,598
Cumulative Timesteps: 1,089,018,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,877.46551
Policy Entropy: 3.90199
Value Function Loss: 0.03715

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05770
Policy Update Magnitude: 0.85666
Value Function Update Magnitude: 0.67937

Collected Steps per Second: 22,890.89652
Overall Steps per Second: 10,697.22871

Timestep Collection Time: 2.18497
Timestep Consumption Time: 2.49063
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.67560

Cumulative Model Updates: 130,604
Cumulative Timesteps: 1,089,068,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1089068100...
Checkpoint 1089068100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,051.17774
Policy Entropy: 3.86497
Value Function Loss: 0.03364

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07499
Policy Update Magnitude: 0.86598
Value Function Update Magnitude: 0.73843

Collected Steps per Second: 22,411.17993
Overall Steps per Second: 10,915.72247

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.35102
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.58348

Cumulative Model Updates: 130,610
Cumulative Timesteps: 1,089,118,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.66782
Policy Entropy: 3.85645
Value Function Loss: 0.02722

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05838
Policy Update Magnitude: 0.82323
Value Function Update Magnitude: 0.73912

Collected Steps per Second: 21,981.84415
Overall Steps per Second: 10,663.72885

Timestep Collection Time: 2.27533
Timestep Consumption Time: 2.41496
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.69029

Cumulative Model Updates: 130,616
Cumulative Timesteps: 1,089,168,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1089168148...
Checkpoint 1089168148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.26125
Policy Entropy: 3.84782
Value Function Loss: 0.02439

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.76292
Value Function Update Magnitude: 0.59719

Collected Steps per Second: 22,579.87232
Overall Steps per Second: 11,044.34718

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.31321
PPO Batch Consumption Time: 0.27513
Total Iteration Time: 4.52793

Cumulative Model Updates: 130,622
Cumulative Timesteps: 1,089,218,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,493.02262
Policy Entropy: 3.84767
Value Function Loss: 0.02209

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06702
Policy Update Magnitude: 0.69590
Value Function Update Magnitude: 0.55613

Collected Steps per Second: 22,115.06121
Overall Steps per Second: 10,782.20680

Timestep Collection Time: 2.26108
Timestep Consumption Time: 2.37656
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63764

Cumulative Model Updates: 130,628
Cumulative Timesteps: 1,089,268,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1089268160...
Checkpoint 1089268160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,608.74335
Policy Entropy: 3.83188
Value Function Loss: 0.02201

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.62348
Value Function Update Magnitude: 0.56853

Collected Steps per Second: 22,128.39673
Overall Steps per Second: 10,636.39894

Timestep Collection Time: 2.26008
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.70197

Cumulative Model Updates: 130,634
Cumulative Timesteps: 1,089,318,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,583.66698
Policy Entropy: 3.82993
Value Function Loss: 0.02105

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.56525
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,039.18573
Overall Steps per Second: 10,703.11522

Timestep Collection Time: 2.26896
Timestep Consumption Time: 2.40314
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.67210

Cumulative Model Updates: 130,640
Cumulative Timesteps: 1,089,368,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1089368178...
Checkpoint 1089368178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.09455
Policy Entropy: 3.79389
Value Function Loss: 0.02362

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.18998
Policy Update Magnitude: 0.46676
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 22,245.31251
Overall Steps per Second: 10,652.11073

Timestep Collection Time: 2.24991
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.69860

Cumulative Model Updates: 130,646
Cumulative Timesteps: 1,089,418,228

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.83768
Policy Entropy: 3.79931
Value Function Loss: 0.02211

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.17063
Policy Update Magnitude: 0.40637
Value Function Update Magnitude: 0.68412

Collected Steps per Second: 22,786.32469
Overall Steps per Second: 10,671.44007

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68597

Cumulative Model Updates: 130,652
Cumulative Timesteps: 1,089,468,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1089468234...
Checkpoint 1089468234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,774.54547
Policy Entropy: 3.76063
Value Function Loss: 0.02275

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15236
Policy Update Magnitude: 0.38734
Value Function Update Magnitude: 0.67905

Collected Steps per Second: 22,606.86528
Overall Steps per Second: 10,648.07052

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.69700

Cumulative Model Updates: 130,658
Cumulative Timesteps: 1,089,518,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,031.91264
Policy Entropy: 3.78651
Value Function Loss: 0.02223

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.39453
Value Function Update Magnitude: 0.54201

Collected Steps per Second: 22,618.34201
Overall Steps per Second: 10,631.41410

Timestep Collection Time: 2.21254
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.70718

Cumulative Model Updates: 130,664
Cumulative Timesteps: 1,089,568,292

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1089568292...
Checkpoint 1089568292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,946.25927
Policy Entropy: 3.76218
Value Function Loss: 0.02418

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.38674
Value Function Update Magnitude: 0.48711

Collected Steps per Second: 22,828.33682
Overall Steps per Second: 10,829.39509

Timestep Collection Time: 2.19105
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.61873

Cumulative Model Updates: 130,670
Cumulative Timesteps: 1,089,618,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.97690
Policy Entropy: 3.79973
Value Function Loss: 0.02176

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.42287
Value Function Update Magnitude: 0.52923

Collected Steps per Second: 22,259.03969
Overall Steps per Second: 10,549.15121

Timestep Collection Time: 2.24646
Timestep Consumption Time: 2.49364
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.74010

Cumulative Model Updates: 130,676
Cumulative Timesteps: 1,089,668,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1089668314...
Checkpoint 1089668314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.99612
Policy Entropy: 3.77247
Value Function Loss: 0.02686

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.41898
Value Function Update Magnitude: 0.52301

Collected Steps per Second: 22,538.74847
Overall Steps per Second: 10,643.02666

Timestep Collection Time: 2.21867
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69848

Cumulative Model Updates: 130,682
Cumulative Timesteps: 1,089,718,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,822.65595
Policy Entropy: 3.77707
Value Function Loss: 0.02519

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.42160
Value Function Update Magnitude: 0.44007

Collected Steps per Second: 22,848.91725
Overall Steps per Second: 10,807.89256

Timestep Collection Time: 2.18829
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.62625

Cumulative Model Updates: 130,688
Cumulative Timesteps: 1,089,768,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1089768320...
Checkpoint 1089768320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,588.15829
Policy Entropy: 3.73910
Value Function Loss: 0.02769

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.45158
Value Function Update Magnitude: 0.42070

Collected Steps per Second: 22,516.03446
Overall Steps per Second: 10,770.62671

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.64226

Cumulative Model Updates: 130,694
Cumulative Timesteps: 1,089,818,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,046.06985
Policy Entropy: 3.75444
Value Function Loss: 0.02424

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.48492
Value Function Update Magnitude: 0.48373

Collected Steps per Second: 22,596.05695
Overall Steps per Second: 10,752.61815

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.65263

Cumulative Model Updates: 130,700
Cumulative Timesteps: 1,089,868,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1089868348...
Checkpoint 1089868348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,610.78880
Policy Entropy: 3.75122
Value Function Loss: 0.02935

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.42293

Collected Steps per Second: 22,442.22155
Overall Steps per Second: 10,726.20401

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.43558
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66540

Cumulative Model Updates: 130,706
Cumulative Timesteps: 1,089,918,390

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,816.61577
Policy Entropy: 3.78771
Value Function Loss: 0.02855

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.49381
Value Function Update Magnitude: 0.39292

Collected Steps per Second: 22,735.00657
Overall Steps per Second: 10,694.75641

Timestep Collection Time: 2.20048
Timestep Consumption Time: 2.47732
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.67781

Cumulative Model Updates: 130,712
Cumulative Timesteps: 1,089,968,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1089968418...
Checkpoint 1089968418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,388.27899
Policy Entropy: 3.78268
Value Function Loss: 0.02821

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.47515
Value Function Update Magnitude: 0.58398

Collected Steps per Second: 22,911.59329
Overall Steps per Second: 10,856.48368

Timestep Collection Time: 2.18239
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.60573

Cumulative Model Updates: 130,718
Cumulative Timesteps: 1,090,018,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,380.55107
Policy Entropy: 3.76958
Value Function Loss: 0.02697

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13633
Policy Update Magnitude: 0.46587
Value Function Update Magnitude: 0.79227

Collected Steps per Second: 22,786.01137
Overall Steps per Second: 10,692.85805

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.67920

Cumulative Model Updates: 130,724
Cumulative Timesteps: 1,090,068,454

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1090068454...
Checkpoint 1090068454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,221.32471
Policy Entropy: 3.75747
Value Function Loss: 0.02525

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.47287
Value Function Update Magnitude: 0.91768

Collected Steps per Second: 22,864.72965
Overall Steps per Second: 10,836.45058

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.61572

Cumulative Model Updates: 130,730
Cumulative Timesteps: 1,090,118,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,983.56794
Policy Entropy: 3.75067
Value Function Loss: 0.02342

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.46978
Value Function Update Magnitude: 0.86604

Collected Steps per Second: 22,634.78775
Overall Steps per Second: 10,686.76420

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.68112

Cumulative Model Updates: 130,736
Cumulative Timesteps: 1,090,168,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1090168498...
Checkpoint 1090168498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,983.56794
Policy Entropy: 3.74663
Value Function Loss: 0.02170

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.45769
Value Function Update Magnitude: 0.75396

Collected Steps per Second: 22,276.16214
Overall Steps per Second: 10,885.45559

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.34930
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.59439

Cumulative Model Updates: 130,742
Cumulative Timesteps: 1,090,218,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,354.15802
Policy Entropy: 3.74755
Value Function Loss: 0.02157

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.42785
Value Function Update Magnitude: 0.73978

Collected Steps per Second: 22,039.48931
Overall Steps per Second: 10,813.43622

Timestep Collection Time: 2.26884
Timestep Consumption Time: 2.35541
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.62425

Cumulative Model Updates: 130,748
Cumulative Timesteps: 1,090,268,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1090268514...
Checkpoint 1090268514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,752.79241
Policy Entropy: 3.75252
Value Function Loss: 0.02191

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.43974
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 22,002.29026
Overall Steps per Second: 10,564.28390

Timestep Collection Time: 2.27267
Timestep Consumption Time: 2.46063
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.73331

Cumulative Model Updates: 130,754
Cumulative Timesteps: 1,090,318,518

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,152.80975
Policy Entropy: 3.75167
Value Function Loss: 0.02043

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.42961
Value Function Update Magnitude: 0.66868

Collected Steps per Second: 22,165.79885
Overall Steps per Second: 10,604.37788

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.71692

Cumulative Model Updates: 130,760
Cumulative Timesteps: 1,090,368,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1090368538...
Checkpoint 1090368538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,230.85347
Policy Entropy: 3.74329
Value Function Loss: 0.01871

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.37587
Value Function Update Magnitude: 0.65807

Collected Steps per Second: 22,679.88885
Overall Steps per Second: 10,665.02996

Timestep Collection Time: 2.20592
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.69103

Cumulative Model Updates: 130,766
Cumulative Timesteps: 1,090,418,568

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,482.14768
Policy Entropy: 3.74224
Value Function Loss: 0.01808

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.34196
Value Function Update Magnitude: 0.53303

Collected Steps per Second: 22,720.71008
Overall Steps per Second: 10,858.83714

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.40449
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.60565

Cumulative Model Updates: 130,772
Cumulative Timesteps: 1,090,468,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1090468580...
Checkpoint 1090468580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,482.14768
Policy Entropy: 3.74272
Value Function Loss: 0.01683

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.34091
Value Function Update Magnitude: 0.42915

Collected Steps per Second: 22,782.28107
Overall Steps per Second: 10,659.65092

Timestep Collection Time: 2.19574
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.69284

Cumulative Model Updates: 130,778
Cumulative Timesteps: 1,090,518,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,482.14768
Policy Entropy: 3.74361
Value Function Loss: 0.01518

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.33293
Value Function Update Magnitude: 0.37314

Collected Steps per Second: 22,584.09771
Overall Steps per Second: 10,591.33904

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.50809
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.72310

Cumulative Model Updates: 130,784
Cumulative Timesteps: 1,090,568,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1090568628...
Checkpoint 1090568628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,482.14768
Policy Entropy: 3.73513
Value Function Loss: 0.01501

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.32667
Value Function Update Magnitude: 0.48481

Collected Steps per Second: 22,624.58481
Overall Steps per Second: 10,652.82816

Timestep Collection Time: 2.21105
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69584

Cumulative Model Updates: 130,790
Cumulative Timesteps: 1,090,618,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,995.42973
Policy Entropy: 3.74406
Value Function Loss: 0.01483

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.37311
Value Function Update Magnitude: 0.66928

Collected Steps per Second: 22,755.82515
Overall Steps per Second: 10,823.70241

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.62115

Cumulative Model Updates: 130,796
Cumulative Timesteps: 1,090,668,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1090668670...
Checkpoint 1090668670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,995.42973
Policy Entropy: 3.71543
Value Function Loss: 0.01919

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.42401
Value Function Update Magnitude: 0.69011

Collected Steps per Second: 23,005.63687
Overall Steps per Second: 10,766.03207

Timestep Collection Time: 2.17390
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.64535

Cumulative Model Updates: 130,802
Cumulative Timesteps: 1,090,718,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,558.96674
Policy Entropy: 3.73314
Value Function Loss: 0.02011

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.45422
Value Function Update Magnitude: 0.57122

Collected Steps per Second: 23,056.22332
Overall Steps per Second: 10,755.61288

Timestep Collection Time: 2.16922
Timestep Consumption Time: 2.48082
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.65004

Cumulative Model Updates: 130,808
Cumulative Timesteps: 1,090,768,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1090768696...
Checkpoint 1090768696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,558.96674
Policy Entropy: 3.71914
Value Function Loss: 0.02178

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.45162
Value Function Update Magnitude: 0.49191

Collected Steps per Second: 22,270.56041
Overall Steps per Second: 10,767.86171

Timestep Collection Time: 2.24548
Timestep Consumption Time: 2.39871
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.64419

Cumulative Model Updates: 130,814
Cumulative Timesteps: 1,090,818,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,558.96674
Policy Entropy: 3.73429
Value Function Loss: 0.01889

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.44277
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,113.19062
Overall Steps per Second: 10,743.19401

Timestep Collection Time: 2.26155
Timestep Consumption Time: 2.39349
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.65504

Cumulative Model Updates: 130,820
Cumulative Timesteps: 1,090,868,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1090868714...
Checkpoint 1090868714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,835.96292
Policy Entropy: 3.71849
Value Function Loss: 0.02209

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.45206
Value Function Update Magnitude: 0.66111

Collected Steps per Second: 21,925.72636
Overall Steps per Second: 10,646.97845

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.69880

Cumulative Model Updates: 130,826
Cumulative Timesteps: 1,090,918,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,587.80270
Policy Entropy: 3.72081
Value Function Loss: 0.02337

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.50184
Value Function Update Magnitude: 0.55136

Collected Steps per Second: 22,571.71476
Overall Steps per Second: 10,848.68082

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.39388
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60922

Cumulative Model Updates: 130,832
Cumulative Timesteps: 1,090,968,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1090968746...
Checkpoint 1090968746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,149.13260
Policy Entropy: 3.73357
Value Function Loss: 0.02299

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14639
Policy Update Magnitude: 0.48274
Value Function Update Magnitude: 0.52423

Collected Steps per Second: 22,525.70326
Overall Steps per Second: 10,609.79151

Timestep Collection Time: 2.22057
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.71451

Cumulative Model Updates: 130,838
Cumulative Timesteps: 1,091,018,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,985.96651
Policy Entropy: 3.73604
Value Function Loss: 0.02375

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16403
Policy Update Magnitude: 0.49083
Value Function Update Magnitude: 0.45920

Collected Steps per Second: 22,359.75609
Overall Steps per Second: 10,537.72830

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.51010
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74751

Cumulative Model Updates: 130,844
Cumulative Timesteps: 1,091,068,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1091068794...
Checkpoint 1091068794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,494.62651
Policy Entropy: 3.73612
Value Function Loss: 0.02725

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15704
Policy Update Magnitude: 0.51039
Value Function Update Magnitude: 0.45387

Collected Steps per Second: 22,749.03959
Overall Steps per Second: 10,621.47842

Timestep Collection Time: 2.19798
Timestep Consumption Time: 2.50965
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.70763

Cumulative Model Updates: 130,850
Cumulative Timesteps: 1,091,118,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,877.52678
Policy Entropy: 3.73991
Value Function Loss: 0.03431

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.59790
Value Function Update Magnitude: 0.58517

Collected Steps per Second: 22,622.59936
Overall Steps per Second: 10,642.21886

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69921

Cumulative Model Updates: 130,856
Cumulative Timesteps: 1,091,168,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1091168806...
Checkpoint 1091168806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,467.31087
Policy Entropy: 3.80267
Value Function Loss: 0.03198

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.63949
Value Function Update Magnitude: 0.71256

Collected Steps per Second: 22,665.05081
Overall Steps per Second: 10,715.62590

Timestep Collection Time: 2.20622
Timestep Consumption Time: 2.46024
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.66646

Cumulative Model Updates: 130,862
Cumulative Timesteps: 1,091,218,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,808.15545
Policy Entropy: 3.82420
Value Function Loss: 0.03140

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.68713
Value Function Update Magnitude: 0.74252

Collected Steps per Second: 22,777.98792
Overall Steps per Second: 10,659.96664

Timestep Collection Time: 2.19510
Timestep Consumption Time: 2.49534
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69045

Cumulative Model Updates: 130,868
Cumulative Timesteps: 1,091,268,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1091268810...
Checkpoint 1091268810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,930.87331
Policy Entropy: 3.82702
Value Function Loss: 0.02680

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.68412
Value Function Update Magnitude: 0.70207

Collected Steps per Second: 22,799.49947
Overall Steps per Second: 10,658.37871

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.49811
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.69115

Cumulative Model Updates: 130,874
Cumulative Timesteps: 1,091,318,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,773.93515
Policy Entropy: 3.79465
Value Function Loss: 0.02360

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.17382
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.71978

Collected Steps per Second: 22,692.79721
Overall Steps per Second: 10,697.47929

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.47066
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.67400

Cumulative Model Updates: 130,880
Cumulative Timesteps: 1,091,368,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1091368810...
Checkpoint 1091368810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,773.93515
Policy Entropy: 3.77964
Value Function Loss: 0.02004

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.47968
Value Function Update Magnitude: 0.55501

Collected Steps per Second: 22,596.72257
Overall Steps per Second: 10,786.80972

Timestep Collection Time: 2.21413
Timestep Consumption Time: 2.42413
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.63826

Cumulative Model Updates: 130,886
Cumulative Timesteps: 1,091,418,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,669.23291
Policy Entropy: 3.76344
Value Function Loss: 0.01902

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17586
Policy Update Magnitude: 0.43896
Value Function Update Magnitude: 0.45626

Collected Steps per Second: 22,594.07526
Overall Steps per Second: 10,596.69514

Timestep Collection Time: 2.21332
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.71921

Cumulative Model Updates: 130,892
Cumulative Timesteps: 1,091,468,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1091468850...
Checkpoint 1091468850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,037.99703
Policy Entropy: 3.76054
Value Function Loss: 0.01928

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.18010
Policy Update Magnitude: 0.41287
Value Function Update Magnitude: 0.49279

Collected Steps per Second: 22,640.55855
Overall Steps per Second: 10,606.94595

Timestep Collection Time: 2.20966
Timestep Consumption Time: 2.50687
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.71653

Cumulative Model Updates: 130,898
Cumulative Timesteps: 1,091,518,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,037.99703
Policy Entropy: 3.78344
Value Function Loss: 0.01815

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.19632
Policy Update Magnitude: 0.43165
Value Function Update Magnitude: 0.50008

Collected Steps per Second: 22,223.91386
Overall Steps per Second: 10,864.19206

Timestep Collection Time: 2.25028
Timestep Consumption Time: 2.35292
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60320

Cumulative Model Updates: 130,904
Cumulative Timesteps: 1,091,568,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1091568888...
Checkpoint 1091568888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,037.99703
Policy Entropy: 3.76135
Value Function Loss: 0.01693

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16969
Policy Update Magnitude: 0.40540
Value Function Update Magnitude: 0.51154

Collected Steps per Second: 22,124.51211
Overall Steps per Second: 10,666.37059

Timestep Collection Time: 2.26138
Timestep Consumption Time: 2.42925
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.69063

Cumulative Model Updates: 130,910
Cumulative Timesteps: 1,091,618,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,037.99703
Policy Entropy: 3.74269
Value Function Loss: 0.01526

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.42520
Value Function Update Magnitude: 0.58142

Collected Steps per Second: 21,598.70209
Overall Steps per Second: 10,459.07384

Timestep Collection Time: 2.31579
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.78226

Cumulative Model Updates: 130,916
Cumulative Timesteps: 1,091,668,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1091668938...
Checkpoint 1091668938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,126.07346
Policy Entropy: 3.73412
Value Function Loss: 0.01950

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.15832
Policy Update Magnitude: 0.48077
Value Function Update Magnitude: 0.53846

Collected Steps per Second: 22,352.79727
Overall Steps per Second: 10,619.31187

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.70991

Cumulative Model Updates: 130,922
Cumulative Timesteps: 1,091,718,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,501.52753
Policy Entropy: 3.72189
Value Function Loss: 0.02509

Mean KL Divergence: 0.02900
SB3 Clip Fraction: 0.28586
Policy Update Magnitude: 0.42816
Value Function Update Magnitude: 0.41747

Collected Steps per Second: 22,821.07035
Overall Steps per Second: 10,880.61771

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.59625

Cumulative Model Updates: 130,928
Cumulative Timesteps: 1,091,768,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1091768964...
Checkpoint 1091768964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,600.69085
Policy Entropy: 3.73920
Value Function Loss: 0.03326

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.51827
Value Function Update Magnitude: 0.37881

Collected Steps per Second: 22,594.77128
Overall Steps per Second: 10,650.31911

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.69639

Cumulative Model Updates: 130,934
Cumulative Timesteps: 1,091,818,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,450.18616
Policy Entropy: 3.75455
Value Function Loss: 0.03060

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.74671
Value Function Update Magnitude: 0.37627

Collected Steps per Second: 22,880.53735
Overall Steps per Second: 10,816.22055

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.43869
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.62509

Cumulative Model Updates: 130,940
Cumulative Timesteps: 1,091,869,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1091869008...
Checkpoint 1091869008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,643.09573
Policy Entropy: 3.76532
Value Function Loss: 0.02542

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.76221
Value Function Update Magnitude: 0.47171

Collected Steps per Second: 22,698.15256
Overall Steps per Second: 10,808.17334

Timestep Collection Time: 2.20317
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.62687

Cumulative Model Updates: 130,946
Cumulative Timesteps: 1,091,919,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,160.42055
Policy Entropy: 3.76739
Value Function Loss: 0.02000

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.70472
Value Function Update Magnitude: 0.57075

Collected Steps per Second: 22,560.37931
Overall Steps per Second: 10,765.57854

Timestep Collection Time: 2.21681
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.64555

Cumulative Model Updates: 130,952
Cumulative Timesteps: 1,091,969,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1091969028...
Checkpoint 1091969028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,626.08610
Policy Entropy: 3.75435
Value Function Loss: 0.01754

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07663
Policy Update Magnitude: 0.70010
Value Function Update Magnitude: 0.75253

Collected Steps per Second: 22,758.32915
Overall Steps per Second: 10,718.80985

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.66600

Cumulative Model Updates: 130,958
Cumulative Timesteps: 1,092,019,042

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,626.08610
Policy Entropy: 3.74538
Value Function Loss: 0.01562

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.66323
Value Function Update Magnitude: 0.76242

Collected Steps per Second: 22,855.68218
Overall Steps per Second: 10,811.98645

Timestep Collection Time: 2.18764
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.62450

Cumulative Model Updates: 130,964
Cumulative Timesteps: 1,092,069,042

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1092069042...
Checkpoint 1092069042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,626.08610
Policy Entropy: 3.74401
Value Function Loss: 0.01257

Mean KL Divergence: 0.02274
SB3 Clip Fraction: 0.27223
Policy Update Magnitude: 0.49543
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,756.04152
Overall Steps per Second: 10,698.40422

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.67528

Cumulative Model Updates: 130,970
Cumulative Timesteps: 1,092,119,060

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,626.08610
Policy Entropy: 3.75674
Value Function Loss: 0.01346

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.28456
Policy Update Magnitude: 0.31845
Value Function Update Magnitude: 0.50191

Collected Steps per Second: 22,617.78112
Overall Steps per Second: 10,631.75700

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.70364

Cumulative Model Updates: 130,976
Cumulative Timesteps: 1,092,169,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1092169068...
Checkpoint 1092169068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,488.87906
Policy Entropy: 3.75890
Value Function Loss: 0.01290

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.29081
Value Function Update Magnitude: 0.50872

Collected Steps per Second: 23,075.15247
Overall Steps per Second: 10,907.68755

Timestep Collection Time: 2.16787
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.58612

Cumulative Model Updates: 130,982
Cumulative Timesteps: 1,092,219,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,314.56824
Policy Entropy: 3.74921
Value Function Loss: 0.01492

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.34710
Value Function Update Magnitude: 0.56611

Collected Steps per Second: 22,840.81572
Overall Steps per Second: 10,683.40688

Timestep Collection Time: 2.18924
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68053

Cumulative Model Updates: 130,988
Cumulative Timesteps: 1,092,269,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1092269096...
Checkpoint 1092269096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,291.57155
Policy Entropy: 3.74656
Value Function Loss: 0.01626

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14567
Policy Update Magnitude: 0.33972
Value Function Update Magnitude: 0.61659

Collected Steps per Second: 23,012.67739
Overall Steps per Second: 10,709.71788

Timestep Collection Time: 2.17411
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.67165

Cumulative Model Updates: 130,994
Cumulative Timesteps: 1,092,319,128

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337,459.34205
Policy Entropy: 3.74167
Value Function Loss: 0.01903

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15386
Policy Update Magnitude: 0.36685
Value Function Update Magnitude: 0.67058

Collected Steps per Second: 22,845.15947
Overall Steps per Second: 10,600.48245

Timestep Collection Time: 2.18970
Timestep Consumption Time: 2.52933
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.71903

Cumulative Model Updates: 131,000
Cumulative Timesteps: 1,092,369,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1092369152...
Checkpoint 1092369152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,851.47793
Policy Entropy: 3.74319
Value Function Loss: 0.02205

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15063
Policy Update Magnitude: 0.39994
Value Function Update Magnitude: 0.70713

Collected Steps per Second: 22,912.43704
Overall Steps per Second: 10,657.81056

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.50958
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.69215

Cumulative Model Updates: 131,006
Cumulative Timesteps: 1,092,419,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,225.00723
Policy Entropy: 3.74458
Value Function Loss: 0.02841

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.42703
Value Function Update Magnitude: 0.54815

Collected Steps per Second: 22,527.93735
Overall Steps per Second: 10,666.47689

Timestep Collection Time: 2.21947
Timestep Consumption Time: 2.46812
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.68758

Cumulative Model Updates: 131,012
Cumulative Timesteps: 1,092,469,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1092469160...
Checkpoint 1092469160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,268.87855
Policy Entropy: 3.76869
Value Function Loss: 0.02525

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.47114
Value Function Update Magnitude: 0.52665

Collected Steps per Second: 22,340.31892
Overall Steps per Second: 10,943.79112

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.33293
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.57319

Cumulative Model Updates: 131,018
Cumulative Timesteps: 1,092,519,208

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,610.28594
Policy Entropy: 3.76988
Value Function Loss: 0.02319

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.47553
Value Function Update Magnitude: 0.54821

Collected Steps per Second: 22,071.01987
Overall Steps per Second: 10,832.26565

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.35090
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.61676

Cumulative Model Updates: 131,024
Cumulative Timesteps: 1,092,569,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1092569218...
Checkpoint 1092569218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,610.28594
Policy Entropy: 3.76959
Value Function Loss: 0.01902

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.43992
Value Function Update Magnitude: 0.51826

Collected Steps per Second: 22,138.26375
Overall Steps per Second: 10,614.02567

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.45261
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.71150

Cumulative Model Updates: 131,030
Cumulative Timesteps: 1,092,619,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,515.67232
Policy Entropy: 3.75088
Value Function Loss: 0.02167

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.45532
Value Function Update Magnitude: 0.52083

Collected Steps per Second: 22,443.14986
Overall Steps per Second: 10,647.32219

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.46905
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.69771

Cumulative Model Updates: 131,036
Cumulative Timesteps: 1,092,669,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1092669244...
Checkpoint 1092669244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,564.17021
Policy Entropy: 3.75132
Value Function Loss: 0.02227

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.54054
Value Function Update Magnitude: 0.73673

Collected Steps per Second: 22,819.17300
Overall Steps per Second: 10,883.96422

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.40345
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.59520

Cumulative Model Updates: 131,042
Cumulative Timesteps: 1,092,719,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337,814.82470
Policy Entropy: 3.74944
Value Function Loss: 0.02676

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14451
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.89979

Collected Steps per Second: 22,567.60385
Overall Steps per Second: 10,577.94865

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.51125
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72681

Cumulative Model Updates: 131,048
Cumulative Timesteps: 1,092,769,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1092769258...
Checkpoint 1092769258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,619.79798
Policy Entropy: 3.76886
Value Function Loss: 0.02357

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.63038
Value Function Update Magnitude: 0.94420

Collected Steps per Second: 22,794.37594
Overall Steps per Second: 10,687.50430

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.68004

Cumulative Model Updates: 131,054
Cumulative Timesteps: 1,092,819,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,097.60951
Policy Entropy: 3.79359
Value Function Loss: 0.01906

Mean KL Divergence: 0.03277
SB3 Clip Fraction: 0.32074
Policy Update Magnitude: 0.48893
Value Function Update Magnitude: 0.91133

Collected Steps per Second: 22,312.67653
Overall Steps per Second: 10,682.03321

Timestep Collection Time: 2.24106
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.68113

Cumulative Model Updates: 131,060
Cumulative Timesteps: 1,092,869,280

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1092869280...
Checkpoint 1092869280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,209.91866
Policy Entropy: 3.80681
Value Function Loss: 0.01669

Mean KL Divergence: 0.02418
SB3 Clip Fraction: 0.25486
Policy Update Magnitude: 0.40389
Value Function Update Magnitude: 0.74246

Collected Steps per Second: 22,825.83218
Overall Steps per Second: 10,752.17616

Timestep Collection Time: 2.19120
Timestep Consumption Time: 2.46051
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.65171

Cumulative Model Updates: 131,066
Cumulative Timesteps: 1,092,919,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.08292
Policy Entropy: 3.80800
Value Function Loss: 0.01798

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.17409
Policy Update Magnitude: 0.44369
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 22,815.52337
Overall Steps per Second: 10,801.66644

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62929

Cumulative Model Updates: 131,072
Cumulative Timesteps: 1,092,969,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1092969300...
Checkpoint 1092969300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,173.48744
Policy Entropy: 3.80605
Value Function Loss: 0.01972

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.16950
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.53638

Collected Steps per Second: 22,333.42057
Overall Steps per Second: 10,584.60151

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.48634
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.72630

Cumulative Model Updates: 131,078
Cumulative Timesteps: 1,093,019,326

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,062.02970
Policy Entropy: 3.81361
Value Function Loss: 0.02952

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.60721
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 22,419.75987
Overall Steps per Second: 10,588.12910

Timestep Collection Time: 2.23098
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.72397

Cumulative Model Updates: 131,084
Cumulative Timesteps: 1,093,069,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1093069344...
Checkpoint 1093069344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,931.60703
Policy Entropy: 3.79852
Value Function Loss: 0.03166

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.68557
Value Function Update Magnitude: 0.49295

Collected Steps per Second: 22,714.07745
Overall Steps per Second: 10,635.59878

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.70213

Cumulative Model Updates: 131,090
Cumulative Timesteps: 1,093,119,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,615.69436
Policy Entropy: 3.75813
Value Function Loss: 0.02751

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.70656
Value Function Update Magnitude: 0.45840

Collected Steps per Second: 22,782.98981
Overall Steps per Second: 10,855.40199

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.41186
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.60692

Cumulative Model Updates: 131,096
Cumulative Timesteps: 1,093,169,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1093169364...
Checkpoint 1093169364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,737.62752
Policy Entropy: 3.74565
Value Function Loss: 0.02448

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.69126
Value Function Update Magnitude: 0.73550

Collected Steps per Second: 22,659.16489
Overall Steps per Second: 10,732.72360

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.45302
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.66051

Cumulative Model Updates: 131,102
Cumulative Timesteps: 1,093,219,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,924.08840
Policy Entropy: 3.75431
Value Function Loss: 0.02655

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.67996
Value Function Update Magnitude: 0.82316

Collected Steps per Second: 22,307.36730
Overall Steps per Second: 10,546.82881

Timestep Collection Time: 2.24258
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.74323

Cumulative Model Updates: 131,108
Cumulative Timesteps: 1,093,269,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1093269410...
Checkpoint 1093269410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,688.02671
Policy Entropy: 3.79996
Value Function Loss: 0.03498

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.66152
Value Function Update Magnitude: 0.82900

Collected Steps per Second: 22,578.35332
Overall Steps per Second: 10,635.32295

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70207

Cumulative Model Updates: 131,114
Cumulative Timesteps: 1,093,319,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,953.26587
Policy Entropy: 3.77279
Value Function Loss: 0.04700

Mean KL Divergence: 0.02869
SB3 Clip Fraction: 0.24770
Policy Update Magnitude: 0.66671
Value Function Update Magnitude: 0.70894

Collected Steps per Second: 22,176.76122
Overall Steps per Second: 10,673.88709

Timestep Collection Time: 2.25497
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.68508

Cumulative Model Updates: 131,120
Cumulative Timesteps: 1,093,369,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1093369426...
Checkpoint 1093369426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,278.28601
Policy Entropy: 3.82799
Value Function Loss: 0.05575

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.17086
Policy Update Magnitude: 0.70832
Value Function Update Magnitude: 0.60076

Collected Steps per Second: 22,042.79646
Overall Steps per Second: 10,660.62397

Timestep Collection Time: 2.26850
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.69053

Cumulative Model Updates: 131,126
Cumulative Timesteps: 1,093,419,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,605.45815
Policy Entropy: 3.90602
Value Function Loss: 0.04717

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.98700
Value Function Update Magnitude: 0.67390

Collected Steps per Second: 22,498.01384
Overall Steps per Second: 10,621.93803

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70743

Cumulative Model Updates: 131,132
Cumulative Timesteps: 1,093,469,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1093469432...
Checkpoint 1093469432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.35767
Policy Entropy: 3.98986
Value Function Loss: 0.04428

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.98955
Value Function Update Magnitude: 0.77750

Collected Steps per Second: 22,648.90074
Overall Steps per Second: 10,959.76160

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.35538
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.56379

Cumulative Model Updates: 131,138
Cumulative Timesteps: 1,093,519,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.97691
Policy Entropy: 4.04873
Value Function Loss: 0.04377

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.99439
Value Function Update Magnitude: 0.61378

Collected Steps per Second: 22,625.61365
Overall Steps per Second: 10,678.56851

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.47269
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.68284

Cumulative Model Updates: 131,144
Cumulative Timesteps: 1,093,569,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1093569456...
Checkpoint 1093569456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,450.69462
Policy Entropy: 4.04591
Value Function Loss: 0.04116

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 1.00800
Value Function Update Magnitude: 0.62183

Collected Steps per Second: 22,761.98887
Overall Steps per Second: 10,847.83748

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.60977

Cumulative Model Updates: 131,150
Cumulative Timesteps: 1,093,619,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.65956
Policy Entropy: 4.02002
Value Function Loss: 0.03670

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06626
Policy Update Magnitude: 1.03626
Value Function Update Magnitude: 0.64324

Collected Steps per Second: 22,312.04058
Overall Steps per Second: 10,533.79789

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.50568
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.74663

Cumulative Model Updates: 131,156
Cumulative Timesteps: 1,093,669,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1093669462...
Checkpoint 1093669462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.66746
Policy Entropy: 3.98603
Value Function Loss: 0.03351

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05831
Policy Update Magnitude: 1.00283
Value Function Update Magnitude: 0.88120

Collected Steps per Second: 22,478.32619
Overall Steps per Second: 10,642.92039

Timestep Collection Time: 2.22650
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70247

Cumulative Model Updates: 131,162
Cumulative Timesteps: 1,093,719,510

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.82901
Policy Entropy: 3.94797
Value Function Loss: 0.03089

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07634
Policy Update Magnitude: 0.89175
Value Function Update Magnitude: 0.95251

Collected Steps per Second: 22,605.47084
Overall Steps per Second: 10,806.74523

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.62711

Cumulative Model Updates: 131,168
Cumulative Timesteps: 1,093,769,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1093769514...
Checkpoint 1093769514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,682.89000
Policy Entropy: 3.89963
Value Function Loss: 0.03202

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.67092
Value Function Update Magnitude: 0.71484

Collected Steps per Second: 22,694.53087
Overall Steps per Second: 10,747.90238

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.44968
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.65356

Cumulative Model Updates: 131,174
Cumulative Timesteps: 1,093,819,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,708.10084
Policy Entropy: 3.88370
Value Function Loss: 0.02906

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.64167

Collected Steps per Second: 22,746.93037
Overall Steps per Second: 10,806.10688

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.62868

Cumulative Model Updates: 131,180
Cumulative Timesteps: 1,093,869,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1093869548...
Checkpoint 1093869548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.51126
Policy Entropy: 3.88836
Value Function Loss: 0.02885

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,549.50035
Overall Steps per Second: 10,770.38327

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.64329

Cumulative Model Updates: 131,186
Cumulative Timesteps: 1,093,919,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,764.59378
Policy Entropy: 3.90232
Value Function Loss: 0.02587

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07419
Policy Update Magnitude: 0.58542
Value Function Update Magnitude: 0.57382

Collected Steps per Second: 22,655.79119
Overall Steps per Second: 10,798.32055

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.63072

Cumulative Model Updates: 131,192
Cumulative Timesteps: 1,093,969,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1093969562...
Checkpoint 1093969562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 475.51354
Policy Entropy: 3.88908
Value Function Loss: 0.02463

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.68564
Value Function Update Magnitude: 0.68062

Collected Steps per Second: 22,653.55782
Overall Steps per Second: 10,669.29668

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.68803

Cumulative Model Updates: 131,198
Cumulative Timesteps: 1,094,019,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,917.12309
Policy Entropy: 3.90275
Value Function Loss: 0.02908

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11264
Policy Update Magnitude: 0.60090
Value Function Update Magnitude: 0.66968

Collected Steps per Second: 22,781.83677
Overall Steps per Second: 10,699.15336

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.67588

Cumulative Model Updates: 131,204
Cumulative Timesteps: 1,094,069,608

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1094069608...
Checkpoint 1094069608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.51318
Policy Entropy: 3.92327
Value Function Loss: 0.02988

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.61921

Collected Steps per Second: 22,858.73064
Overall Steps per Second: 10,809.60875

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.43904
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.62718

Cumulative Model Updates: 131,210
Cumulative Timesteps: 1,094,119,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,904.64891
Policy Entropy: 3.90468
Value Function Loss: 0.03222

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11529
Policy Update Magnitude: 0.60434
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,682.41816
Overall Steps per Second: 10,670.36181

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.48232
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68738

Cumulative Model Updates: 131,216
Cumulative Timesteps: 1,094,169,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1094169642...
Checkpoint 1094169642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138.39171
Policy Entropy: 3.87116
Value Function Loss: 0.02752

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.58885
Value Function Update Magnitude: 0.64348

Collected Steps per Second: 22,862.77942
Overall Steps per Second: 10,868.28653

Timestep Collection Time: 2.18897
Timestep Consumption Time: 2.41580
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60477

Cumulative Model Updates: 131,222
Cumulative Timesteps: 1,094,219,688

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,022.07291
Policy Entropy: 3.81494
Value Function Loss: 0.02879

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.17034
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.70645

Collected Steps per Second: 22,638.28158
Overall Steps per Second: 10,576.62669

Timestep Collection Time: 2.21095
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.73232

Cumulative Model Updates: 131,228
Cumulative Timesteps: 1,094,269,740

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1094269740...
Checkpoint 1094269740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,027.73684
Policy Entropy: 3.81121
Value Function Loss: 0.02734

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.17580
Policy Update Magnitude: 0.43853
Value Function Update Magnitude: 0.71920

Collected Steps per Second: 22,627.24614
Overall Steps per Second: 10,429.48678

Timestep Collection Time: 2.21034
Timestep Consumption Time: 2.58510
PPO Batch Consumption Time: 0.30684
Total Iteration Time: 4.79544

Cumulative Model Updates: 131,234
Cumulative Timesteps: 1,094,319,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.95678
Policy Entropy: 3.81248
Value Function Loss: 0.02874

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.47608
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 22,893.70711
Overall Steps per Second: 10,620.33145

Timestep Collection Time: 2.18549
Timestep Consumption Time: 2.52566
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.71115

Cumulative Model Updates: 131,240
Cumulative Timesteps: 1,094,369,788

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1094369788...
Checkpoint 1094369788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.78046
Policy Entropy: 3.82374
Value Function Loss: 0.02329

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.25944
Policy Update Magnitude: 0.41481
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 22,762.82710
Overall Steps per Second: 10,637.22047

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.70104

Cumulative Model Updates: 131,246
Cumulative Timesteps: 1,094,419,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,941.36589
Policy Entropy: 3.81798
Value Function Loss: 0.02429

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.23784
Policy Update Magnitude: 0.38788
Value Function Update Magnitude: 0.57030

Collected Steps per Second: 22,478.06512
Overall Steps per Second: 10,571.67081

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.50623
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.73151

Cumulative Model Updates: 131,252
Cumulative Timesteps: 1,094,469,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1094469814...
Checkpoint 1094469814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,434.10579
Policy Entropy: 3.75677
Value Function Loss: 0.03261

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.25251
Policy Update Magnitude: 0.35431
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 22,850.99123
Overall Steps per Second: 10,689.56271

Timestep Collection Time: 2.18888
Timestep Consumption Time: 2.49027
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67914

Cumulative Model Updates: 131,258
Cumulative Timesteps: 1,094,519,832

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,431.90801
Policy Entropy: 3.71743
Value Function Loss: 0.04654

Mean KL Divergence: 0.01896
SB3 Clip Fraction: 0.22404
Policy Update Magnitude: 0.39448
Value Function Update Magnitude: 0.53718

Collected Steps per Second: 22,616.30405
Overall Steps per Second: 10,790.28107

Timestep Collection Time: 2.21115
Timestep Consumption Time: 2.42339
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.63454

Cumulative Model Updates: 131,264
Cumulative Timesteps: 1,094,569,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1094569840...
Checkpoint 1094569840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,190.55196
Policy Entropy: 3.71383
Value Function Loss: 0.05003

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.21747
Policy Update Magnitude: 0.44623
Value Function Update Magnitude: 0.56740

Collected Steps per Second: 22,800.72526
Overall Steps per Second: 10,690.06302

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.67724

Cumulative Model Updates: 131,270
Cumulative Timesteps: 1,094,619,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,133.21099
Policy Entropy: 3.72353
Value Function Loss: 0.05049

Mean KL Divergence: 0.01860
SB3 Clip Fraction: 0.20630
Policy Update Magnitude: 0.47361
Value Function Update Magnitude: 0.68309

Collected Steps per Second: 22,800.70793
Overall Steps per Second: 10,817.09171

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.62268

Cumulative Model Updates: 131,276
Cumulative Timesteps: 1,094,669,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1094669844...
Checkpoint 1094669844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,201.00737
Policy Entropy: 3.75372
Value Function Loss: 0.04802

Mean KL Divergence: 0.01776
SB3 Clip Fraction: 0.20091
Policy Update Magnitude: 0.46380
Value Function Update Magnitude: 0.68700

Collected Steps per Second: 22,934.33186
Overall Steps per Second: 10,685.01352

Timestep Collection Time: 2.18118
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.68170

Cumulative Model Updates: 131,282
Cumulative Timesteps: 1,094,719,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,212.27662
Policy Entropy: 3.75759
Value Function Loss: 0.04567

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.19683
Policy Update Magnitude: 0.46376
Value Function Update Magnitude: 0.64508

Collected Steps per Second: 22,918.87092
Overall Steps per Second: 10,891.92869

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.40933
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.59129

Cumulative Model Updates: 131,288
Cumulative Timesteps: 1,094,769,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1094769876...
Checkpoint 1094769876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,208.38535
Policy Entropy: 3.78050
Value Function Loss: 0.04496

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18371
Policy Update Magnitude: 0.48699
Value Function Update Magnitude: 0.65513

Collected Steps per Second: 22,742.40079
Overall Steps per Second: 10,649.46903

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.69789

Cumulative Model Updates: 131,294
Cumulative Timesteps: 1,094,819,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,412.69785
Policy Entropy: 3.79655
Value Function Loss: 0.04881

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.18307
Policy Update Magnitude: 0.50961
Value Function Update Magnitude: 0.61180

Collected Steps per Second: 22,877.63393
Overall Steps per Second: 10,832.22977

Timestep Collection Time: 2.18676
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61844

Cumulative Model Updates: 131,300
Cumulative Timesteps: 1,094,869,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1094869934...
Checkpoint 1094869934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,137.83745
Policy Entropy: 3.78879
Value Function Loss: 0.04529

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.17246
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.59782

Collected Steps per Second: 22,905.18528
Overall Steps per Second: 10,676.88113

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.68376

Cumulative Model Updates: 131,306
Cumulative Timesteps: 1,094,919,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,904.32619
Policy Entropy: 3.80233
Value Function Loss: 0.04470

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17162
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.75442

Collected Steps per Second: 23,013.83265
Overall Steps per Second: 10,853.48171

Timestep Collection Time: 2.17269
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.60700

Cumulative Model Updates: 131,312
Cumulative Timesteps: 1,094,969,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1094969944...
Checkpoint 1094969944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,634.93448
Policy Entropy: 3.79550
Value Function Loss: 0.04327

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.17973
Policy Update Magnitude: 0.60961
Value Function Update Magnitude: 0.84764

Collected Steps per Second: 22,489.03868
Overall Steps per Second: 10,589.71244

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.72421

Cumulative Model Updates: 131,318
Cumulative Timesteps: 1,095,019,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,576.19349
Policy Entropy: 3.81213
Value Function Loss: 0.04443

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.17556
Policy Update Magnitude: 0.61541
Value Function Update Magnitude: 0.78696

Collected Steps per Second: 22,216.53949
Overall Steps per Second: 10,550.58848

Timestep Collection Time: 2.25166
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.74135

Cumulative Model Updates: 131,324
Cumulative Timesteps: 1,095,069,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1095069996...
Checkpoint 1095069996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,299.13667
Policy Entropy: 3.78477
Value Function Loss: 0.04478

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.16846
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.82107

Collected Steps per Second: 22,527.11568
Overall Steps per Second: 10,660.84541

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.69269

Cumulative Model Updates: 131,330
Cumulative Timesteps: 1,095,120,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,132.50989
Policy Entropy: 3.77535
Value Function Loss: 0.04813

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.79045

Collected Steps per Second: 21,901.00073
Overall Steps per Second: 10,622.02434

Timestep Collection Time: 2.28346
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.70814

Cumulative Model Updates: 131,336
Cumulative Timesteps: 1,095,170,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1095170034...
Checkpoint 1095170034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,059.55670
Policy Entropy: 3.79085
Value Function Loss: 0.04832

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.60421
Value Function Update Magnitude: 0.61910

Collected Steps per Second: 22,002.78207
Overall Steps per Second: 10,817.73922

Timestep Collection Time: 2.27262
Timestep Consumption Time: 2.34979
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62241

Cumulative Model Updates: 131,342
Cumulative Timesteps: 1,095,220,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.45615
Policy Entropy: 3.84161
Value Function Loss: 0.04477

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.65625
Value Function Update Magnitude: 0.59727

Collected Steps per Second: 22,460.62845
Overall Steps per Second: 10,562.32390

Timestep Collection Time: 2.22674
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.73513

Cumulative Model Updates: 131,348
Cumulative Timesteps: 1,095,270,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1095270052...
Checkpoint 1095270052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,887.76316
Policy Entropy: 3.86922
Value Function Loss: 0.04323

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.68070
Value Function Update Magnitude: 0.72503

Collected Steps per Second: 22,978.42856
Overall Steps per Second: 10,693.38950

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.50233
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.68046

Cumulative Model Updates: 131,354
Cumulative Timesteps: 1,095,320,102

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.51512
Policy Entropy: 3.86980
Value Function Loss: 0.04168

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.67147
Value Function Update Magnitude: 0.69835

Collected Steps per Second: 22,750.06161
Overall Steps per Second: 10,814.49354

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.42689
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62583

Cumulative Model Updates: 131,360
Cumulative Timesteps: 1,095,370,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1095370128...
Checkpoint 1095370128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,165.14579
Policy Entropy: 3.82761
Value Function Loss: 0.04472

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.64980
Value Function Update Magnitude: 0.69838

Collected Steps per Second: 22,444.37676
Overall Steps per Second: 10,652.77552

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.69587

Cumulative Model Updates: 131,366
Cumulative Timesteps: 1,095,420,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,348.20601
Policy Entropy: 3.79405
Value Function Loss: 0.04739

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.64923
Value Function Update Magnitude: 0.63416

Collected Steps per Second: 22,610.91081
Overall Steps per Second: 10,651.44152

Timestep Collection Time: 2.21132
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69420

Cumulative Model Updates: 131,372
Cumulative Timesteps: 1,095,470,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1095470152...
Checkpoint 1095470152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,353.33543
Policy Entropy: 3.77073
Value Function Loss: 0.04789

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.62792
Value Function Update Magnitude: 0.70294

Collected Steps per Second: 22,907.00206
Overall Steps per Second: 10,852.19073

Timestep Collection Time: 2.18361
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.60921

Cumulative Model Updates: 131,378
Cumulative Timesteps: 1,095,520,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,405.34424
Policy Entropy: 3.77733
Value Function Loss: 0.04616

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15965
Policy Update Magnitude: 0.60529
Value Function Update Magnitude: 0.82760

Collected Steps per Second: 22,734.83695
Overall Steps per Second: 10,671.40329

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68879

Cumulative Model Updates: 131,384
Cumulative Timesteps: 1,095,570,208

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1095570208...
Checkpoint 1095570208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,935.97806
Policy Entropy: 3.86137
Value Function Loss: 0.04397

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.60999
Value Function Update Magnitude: 0.72849

Collected Steps per Second: 22,916.01950
Overall Steps per Second: 10,868.98212

Timestep Collection Time: 2.18293
Timestep Consumption Time: 2.41953
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.60245

Cumulative Model Updates: 131,390
Cumulative Timesteps: 1,095,620,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,806.68335
Policy Entropy: 3.93517
Value Function Loss: 0.03830

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11386
Policy Update Magnitude: 0.74240
Value Function Update Magnitude: 0.80141

Collected Steps per Second: 22,312.96791
Overall Steps per Second: 10,547.47718

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.74066

Cumulative Model Updates: 131,396
Cumulative Timesteps: 1,095,670,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1095670234...
Checkpoint 1095670234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,786.57827
Policy Entropy: 3.98721
Value Function Loss: 0.03194

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.89850
Value Function Update Magnitude: 1.05059

Collected Steps per Second: 22,288.63398
Overall Steps per Second: 10,651.26855

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.45176
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.69578

Cumulative Model Updates: 131,402
Cumulative Timesteps: 1,095,720,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,477.32245
Policy Entropy: 4.00467
Value Function Loss: 0.02865

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 1.02632
Value Function Update Magnitude: 1.20434

Collected Steps per Second: 22,814.72795
Overall Steps per Second: 10,828.74934

Timestep Collection Time: 2.19271
Timestep Consumption Time: 2.42703
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.61974

Cumulative Model Updates: 131,408
Cumulative Timesteps: 1,095,770,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1095770276...
Checkpoint 1095770276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545.55047
Policy Entropy: 4.02801
Value Function Loss: 0.02869

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 1.04378
Value Function Update Magnitude: 1.16551

Collected Steps per Second: 22,621.04170
Overall Steps per Second: 10,679.03478

Timestep Collection Time: 2.21130
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.68413

Cumulative Model Updates: 131,414
Cumulative Timesteps: 1,095,820,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.13421
Policy Entropy: 4.02417
Value Function Loss: 0.02900

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06881
Policy Update Magnitude: 0.97085
Value Function Update Magnitude: 1.10651

Collected Steps per Second: 22,703.19399
Overall Steps per Second: 10,853.34760

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.40589
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60945

Cumulative Model Updates: 131,420
Cumulative Timesteps: 1,095,870,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1095870326...
Checkpoint 1095870326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.98104
Policy Entropy: 3.96248
Value Function Loss: 0.03122

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05358
Policy Update Magnitude: 0.88336
Value Function Update Magnitude: 0.96220

Collected Steps per Second: 22,825.36456
Overall Steps per Second: 10,691.30670

Timestep Collection Time: 2.19168
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.67913

Cumulative Model Updates: 131,426
Cumulative Timesteps: 1,095,920,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.90143
Policy Entropy: 3.89617
Value Function Loss: 0.02671

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05685
Policy Update Magnitude: 0.80266
Value Function Update Magnitude: 0.86214

Collected Steps per Second: 22,639.69252
Overall Steps per Second: 10,865.52104

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.39330
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.60190

Cumulative Model Updates: 131,432
Cumulative Timesteps: 1,095,970,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1095970354...
Checkpoint 1095970354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.47904
Policy Entropy: 3.85158
Value Function Loss: 0.02434

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06732
Policy Update Magnitude: 0.72266
Value Function Update Magnitude: 0.81764

Collected Steps per Second: 22,408.49082
Overall Steps per Second: 10,724.26380

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.66494

Cumulative Model Updates: 131,438
Cumulative Timesteps: 1,096,020,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,629.48278
Policy Entropy: 3.83864
Value Function Loss: 0.02257

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06062
Policy Update Magnitude: 0.67849
Value Function Update Magnitude: 0.70934

Collected Steps per Second: 22,512.15407
Overall Steps per Second: 10,614.05420

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.71318

Cumulative Model Updates: 131,444
Cumulative Timesteps: 1,096,070,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1096070408...
Checkpoint 1096070408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.91761
Policy Entropy: 3.82816
Value Function Loss: 0.02312

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06364
Policy Update Magnitude: 0.68137
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 23,042.35795
Overall Steps per Second: 10,952.30428

Timestep Collection Time: 2.17035
Timestep Consumption Time: 2.39581
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.56616

Cumulative Model Updates: 131,450
Cumulative Timesteps: 1,096,120,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,078.63193
Policy Entropy: 3.83279
Value Function Loss: 0.02584

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.61548
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 22,452.37087
Overall Steps per Second: 10,609.04128

Timestep Collection Time: 2.22738
Timestep Consumption Time: 2.48652
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.71390

Cumulative Model Updates: 131,456
Cumulative Timesteps: 1,096,170,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1096170428...
Checkpoint 1096170428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,969.98612
Policy Entropy: 3.82667
Value Function Loss: 0.02473

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07912
Policy Update Magnitude: 0.60083
Value Function Update Magnitude: 0.55057

Collected Steps per Second: 22,663.33874
Overall Steps per Second: 10,823.14892

Timestep Collection Time: 2.20718
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.62176

Cumulative Model Updates: 131,462
Cumulative Timesteps: 1,096,220,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.98670
Policy Entropy: 3.82545
Value Function Loss: 0.02412

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.58693
Value Function Update Magnitude: 0.52973

Collected Steps per Second: 22,377.00566
Overall Steps per Second: 10,533.07209

Timestep Collection Time: 2.23515
Timestep Consumption Time: 2.51332
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.74847

Cumulative Model Updates: 131,468
Cumulative Timesteps: 1,096,270,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1096270466...
Checkpoint 1096270466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,959.58532
Policy Entropy: 3.81460
Value Function Loss: 0.02912

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.49364
Value Function Update Magnitude: 0.50753

Collected Steps per Second: 22,144.58649
Overall Steps per Second: 10,514.59720

Timestep Collection Time: 2.25861
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.75682

Cumulative Model Updates: 131,474
Cumulative Timesteps: 1,096,320,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,912.37425
Policy Entropy: 3.81013
Value Function Loss: 0.03016

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.52165
Value Function Update Magnitude: 0.61672

Collected Steps per Second: 22,055.59251
Overall Steps per Second: 10,585.77650

Timestep Collection Time: 2.26709
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.72351

Cumulative Model Updates: 131,480
Cumulative Timesteps: 1,096,370,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1096370484...
Checkpoint 1096370484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,123.24135
Policy Entropy: 3.79685
Value Function Loss: 0.03479

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.62823
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,142.31649
Overall Steps per Second: 10,711.12057

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.41050
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.66917

Cumulative Model Updates: 131,486
Cumulative Timesteps: 1,096,420,496

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,933.00709
Policy Entropy: 3.81613
Value Function Loss: 0.03582

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.63416
Value Function Update Magnitude: 0.57127

Collected Steps per Second: 22,332.15511
Overall Steps per Second: 10,737.21668

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.65838

Cumulative Model Updates: 131,492
Cumulative Timesteps: 1,096,470,514

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1096470514...
Checkpoint 1096470514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,213.29368
Policy Entropy: 3.80068
Value Function Loss: 0.03983

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.60207
Value Function Update Magnitude: 0.43331

Collected Steps per Second: 22,436.10097
Overall Steps per Second: 10,735.06737

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.66024

Cumulative Model Updates: 131,498
Cumulative Timesteps: 1,096,520,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,906.02863
Policy Entropy: 3.79480
Value Function Loss: 0.03895

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.39124

Collected Steps per Second: 22,465.98230
Overall Steps per Second: 10,594.87209

Timestep Collection Time: 2.22603
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.72021

Cumulative Model Updates: 131,504
Cumulative Timesteps: 1,096,570,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1096570552...
Checkpoint 1096570552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.33280
Policy Entropy: 3.78809
Value Function Loss: 0.03565

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12997
Policy Update Magnitude: 0.53927
Value Function Update Magnitude: 0.40110

Collected Steps per Second: 22,714.86352
Overall Steps per Second: 10,725.77018

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.46135
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.66335

Cumulative Model Updates: 131,510
Cumulative Timesteps: 1,096,620,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,592.28889
Policy Entropy: 3.77716
Value Function Loss: 0.03025

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.46067
Value Function Update Magnitude: 0.43547

Collected Steps per Second: 22,722.43924
Overall Steps per Second: 10,678.17312

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.68264

Cumulative Model Updates: 131,516
Cumulative Timesteps: 1,096,670,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1096670572...
Checkpoint 1096670572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,038.18623
Policy Entropy: 3.76069
Value Function Loss: 0.02812

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14399
Policy Update Magnitude: 0.41175
Value Function Update Magnitude: 0.42506

Collected Steps per Second: 22,704.55109
Overall Steps per Second: 10,593.83455

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72218

Cumulative Model Updates: 131,522
Cumulative Timesteps: 1,096,720,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,306.24198
Policy Entropy: 3.75485
Value Function Loss: 0.02567

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.39445
Value Function Update Magnitude: 0.44477

Collected Steps per Second: 22,789.39185
Overall Steps per Second: 10,707.29031

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.67046

Cumulative Model Updates: 131,528
Cumulative Timesteps: 1,096,770,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1096770606...
Checkpoint 1096770606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,850.60530
Policy Entropy: 3.76803
Value Function Loss: 0.02147

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.39995
Value Function Update Magnitude: 0.43883

Collected Steps per Second: 22,482.38238
Overall Steps per Second: 10,745.49930

Timestep Collection Time: 2.22503
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.65534

Cumulative Model Updates: 131,534
Cumulative Timesteps: 1,096,820,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,042.77187
Policy Entropy: 3.79188
Value Function Loss: 0.01819

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.37071
Value Function Update Magnitude: 0.54605

Collected Steps per Second: 22,387.77102
Overall Steps per Second: 10,572.22764

Timestep Collection Time: 2.23354
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.72975

Cumulative Model Updates: 131,540
Cumulative Timesteps: 1,096,870,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1096870634...
Checkpoint 1096870634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,647.98660
Policy Entropy: 3.79269
Value Function Loss: 0.01862

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.36954
Value Function Update Magnitude: 0.66613

Collected Steps per Second: 22,693.28470
Overall Steps per Second: 10,611.00655

Timestep Collection Time: 2.20338
Timestep Consumption Time: 2.50889
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71228

Cumulative Model Updates: 131,546
Cumulative Timesteps: 1,096,920,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,705.70518
Policy Entropy: 3.78751
Value Function Loss: 0.01985

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.36579
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 22,890.10798
Overall Steps per Second: 10,650.42589

Timestep Collection Time: 2.18461
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69521

Cumulative Model Updates: 131,552
Cumulative Timesteps: 1,096,970,642

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1096970642...
Checkpoint 1096970642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,585.88358
Policy Entropy: 3.76912
Value Function Loss: 0.01886

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.34652
Value Function Update Magnitude: 0.53013

Collected Steps per Second: 22,074.44037
Overall Steps per Second: 10,666.38821

Timestep Collection Time: 2.26561
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68875

Cumulative Model Updates: 131,558
Cumulative Timesteps: 1,097,020,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,947.70271
Policy Entropy: 3.75716
Value Function Loss: 0.01863

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.33392
Value Function Update Magnitude: 0.51440

Collected Steps per Second: 22,154.65858
Overall Steps per Second: 10,713.86806

Timestep Collection Time: 2.25785
Timestep Consumption Time: 2.41105
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.66890

Cumulative Model Updates: 131,564
Cumulative Timesteps: 1,097,070,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1097070676...
Checkpoint 1097070676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,947.70271
Policy Entropy: 3.73507
Value Function Loss: 0.02141

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.36364
Value Function Update Magnitude: 0.52601

Collected Steps per Second: 22,185.25370
Overall Steps per Second: 10,619.47444

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.70984

Cumulative Model Updates: 131,570
Cumulative Timesteps: 1,097,120,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,182.63438
Policy Entropy: 3.74146
Value Function Loss: 0.02361

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.39979
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,834.43650
Overall Steps per Second: 10,869.95591

Timestep Collection Time: 2.19055
Timestep Consumption Time: 2.41112
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.60167

Cumulative Model Updates: 131,576
Cumulative Timesteps: 1,097,170,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1097170712...
Checkpoint 1097170712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,966.61226
Policy Entropy: 3.74125
Value Function Loss: 0.02173

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.39929
Value Function Update Magnitude: 0.54494

Collected Steps per Second: 22,662.10048
Overall Steps per Second: 10,694.28718

Timestep Collection Time: 2.20730
Timestep Consumption Time: 2.47015
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.67745

Cumulative Model Updates: 131,582
Cumulative Timesteps: 1,097,220,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,966.61226
Policy Entropy: 3.74347
Value Function Loss: 0.01876

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.36590
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 22,866.57498
Overall Steps per Second: 10,791.21603

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.63488

Cumulative Model Updates: 131,588
Cumulative Timesteps: 1,097,270,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1097270750...
Checkpoint 1097270750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,966.61226
Policy Entropy: 3.73947
Value Function Loss: 0.01616

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14694
Policy Update Magnitude: 0.33233
Value Function Update Magnitude: 0.46640

Collected Steps per Second: 22,562.17198
Overall Steps per Second: 10,757.81954

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.64778

Cumulative Model Updates: 131,594
Cumulative Timesteps: 1,097,320,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,966.61226
Policy Entropy: 3.74225
Value Function Loss: 0.01541

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.30621
Value Function Update Magnitude: 0.45661

Collected Steps per Second: 22,797.81786
Overall Steps per Second: 10,690.26674

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.67809

Cumulative Model Updates: 131,600
Cumulative Timesteps: 1,097,370,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1097370760...
Checkpoint 1097370760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,966.61226
Policy Entropy: 3.73483
Value Function Loss: 0.01622

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.14578
Policy Update Magnitude: 0.29351
Value Function Update Magnitude: 0.38562

Collected Steps per Second: 22,920.99998
Overall Steps per Second: 10,855.09302

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.42473
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.60613

Cumulative Model Updates: 131,606
Cumulative Timesteps: 1,097,420,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.73917
Value Function Loss: 0.01748

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.32705
Value Function Update Magnitude: 0.34297

Collected Steps per Second: 22,906.08377
Overall Steps per Second: 10,851.35631

Timestep Collection Time: 2.18344
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.60901

Cumulative Model Updates: 131,612
Cumulative Timesteps: 1,097,470,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097470774...
Checkpoint 1097470774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.72990
Value Function Loss: 0.01706

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14429
Policy Update Magnitude: 0.34474
Value Function Update Magnitude: 0.42956

Collected Steps per Second: 22,684.49315
Overall Steps per Second: 10,656.29059

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.69357

Cumulative Model Updates: 131,618
Cumulative Timesteps: 1,097,520,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.73194
Value Function Loss: 0.01547

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.36077
Value Function Update Magnitude: 0.45486

Collected Steps per Second: 22,809.17051
Overall Steps per Second: 10,668.86192

Timestep Collection Time: 2.19298
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.68841

Cumulative Model Updates: 131,624
Cumulative Timesteps: 1,097,570,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1097570810...
Checkpoint 1097570810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.73357
Value Function Loss: 0.01363

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.33117
Value Function Update Magnitude: 0.44801

Collected Steps per Second: 22,605.74122
Overall Steps per Second: 10,653.68432

Timestep Collection Time: 2.21280
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.69528

Cumulative Model Updates: 131,630
Cumulative Timesteps: 1,097,620,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.74309
Value Function Loss: 0.01225

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.29451
Value Function Update Magnitude: 0.38703

Collected Steps per Second: 22,347.79558
Overall Steps per Second: 10,749.28565

Timestep Collection Time: 2.23798
Timestep Consumption Time: 2.41479
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.65277

Cumulative Model Updates: 131,636
Cumulative Timesteps: 1,097,670,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1097670846...
Checkpoint 1097670846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.74747
Value Function Loss: 0.01171

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.27818
Value Function Update Magnitude: 0.32512

Collected Steps per Second: 22,189.80071
Overall Steps per Second: 10,641.81545

Timestep Collection Time: 2.25365
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.69920

Cumulative Model Updates: 131,642
Cumulative Timesteps: 1,097,720,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.73501
Value Function Loss: 0.01427

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.29597
Value Function Update Magnitude: 0.33729

Collected Steps per Second: 22,477.34976
Overall Steps per Second: 10,643.36302

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.69983

Cumulative Model Updates: 131,648
Cumulative Timesteps: 1,097,770,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1097770876...
Checkpoint 1097770876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.72558
Value Function Loss: 0.01358

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.34824
Value Function Update Magnitude: 0.36179

Collected Steps per Second: 22,296.90781
Overall Steps per Second: 10,896.86459

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.34686
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.59013

Cumulative Model Updates: 131,654
Cumulative Timesteps: 1,097,820,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.71797
Value Function Loss: 0.01549

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.37204
Value Function Update Magnitude: 0.42166

Collected Steps per Second: 21,632.36366
Overall Steps per Second: 10,575.63115

Timestep Collection Time: 2.31191
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.72898

Cumulative Model Updates: 131,660
Cumulative Timesteps: 1,097,870,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1097870906...
Checkpoint 1097870906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.71538
Value Function Loss: 0.01440

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.38626
Value Function Update Magnitude: 0.44987

Collected Steps per Second: 22,082.64373
Overall Steps per Second: 10,515.67932

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.49138
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.75633

Cumulative Model Updates: 131,666
Cumulative Timesteps: 1,097,920,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.71186
Value Function Loss: 0.01849

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.41282
Value Function Update Magnitude: 0.45287

Collected Steps per Second: 22,789.80226
Overall Steps per Second: 10,853.47149

Timestep Collection Time: 2.19449
Timestep Consumption Time: 2.41344
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60793

Cumulative Model Updates: 131,672
Cumulative Timesteps: 1,097,970,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1097970934...
Checkpoint 1097970934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.71819
Value Function Loss: 0.02094

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.46901
Value Function Update Magnitude: 0.37903

Collected Steps per Second: 22,577.12686
Overall Steps per Second: 10,719.94811

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.66644

Cumulative Model Updates: 131,678
Cumulative Timesteps: 1,098,020,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.71612
Value Function Loss: 0.02407

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.44342
Value Function Update Magnitude: 0.30662

Collected Steps per Second: 22,657.55230
Overall Steps per Second: 10,626.19125

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.49928
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.70667

Cumulative Model Updates: 131,684
Cumulative Timesteps: 1,098,070,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1098070972...
Checkpoint 1098070972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,968.80879
Policy Entropy: 3.72524
Value Function Loss: 0.02138

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.44862
Value Function Update Magnitude: 0.28440

Collected Steps per Second: 22,934.84510
Overall Steps per Second: 10,861.10241

Timestep Collection Time: 2.18140
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60635

Cumulative Model Updates: 131,690
Cumulative Timesteps: 1,098,121,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,885.45597
Policy Entropy: 3.73047
Value Function Loss: 0.01958

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.42558
Value Function Update Magnitude: 0.30388

Collected Steps per Second: 22,922.69126
Overall Steps per Second: 10,877.28247

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.59839

Cumulative Model Updates: 131,696
Cumulative Timesteps: 1,098,171,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1098171020...
Checkpoint 1098171020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,486.65820
Policy Entropy: 3.73310
Value Function Loss: 0.01887

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.40310
Value Function Update Magnitude: 0.42835

Collected Steps per Second: 22,367.67751
Overall Steps per Second: 10,740.70153

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.65742

Cumulative Model Updates: 131,702
Cumulative Timesteps: 1,098,221,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,064.83482
Policy Entropy: 3.75400
Value Function Loss: 0.01871

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.42638
Value Function Update Magnitude: 0.59676

Collected Steps per Second: 22,642.17441
Overall Steps per Second: 10,635.45414

Timestep Collection Time: 2.20862
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.70201

Cumulative Model Updates: 131,708
Cumulative Timesteps: 1,098,271,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1098271052...
Checkpoint 1098271052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,695.85544
Policy Entropy: 3.74576
Value Function Loss: 0.02377

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.42017
Value Function Update Magnitude: 0.52946

Collected Steps per Second: 22,917.40835
Overall Steps per Second: 10,662.39506

Timestep Collection Time: 2.18253
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69107

Cumulative Model Updates: 131,714
Cumulative Timesteps: 1,098,321,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,473.34550
Policy Entropy: 3.75175
Value Function Loss: 0.02104

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.44212
Value Function Update Magnitude: 0.44952

Collected Steps per Second: 22,793.59550
Overall Steps per Second: 10,776.56145

Timestep Collection Time: 2.19413
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.64081

Cumulative Model Updates: 131,720
Cumulative Timesteps: 1,098,371,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1098371082...
Checkpoint 1098371082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,500.06107
Policy Entropy: 3.72675
Value Function Loss: 0.02362

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.43248
Value Function Update Magnitude: 0.38228

Collected Steps per Second: 22,712.48336
Overall Steps per Second: 10,654.06185

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.69323

Cumulative Model Updates: 131,726
Cumulative Timesteps: 1,098,421,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,498.49349
Policy Entropy: 3.73809
Value Function Loss: 0.02059

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.45751
Value Function Update Magnitude: 0.41759

Collected Steps per Second: 23,079.09971
Overall Steps per Second: 10,780.15433

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.63871

Cumulative Model Updates: 131,732
Cumulative Timesteps: 1,098,471,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1098471090...
Checkpoint 1098471090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,948.98769
Policy Entropy: 3.72502
Value Function Loss: 0.02405

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.44204
Value Function Update Magnitude: 0.47697

Collected Steps per Second: 22,452.91698
Overall Steps per Second: 10,650.10963

Timestep Collection Time: 2.22742
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.69591

Cumulative Model Updates: 131,738
Cumulative Timesteps: 1,098,521,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,948.98769
Policy Entropy: 3.72782
Value Function Loss: 0.01999

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.45030
Value Function Update Magnitude: 0.42229

Collected Steps per Second: 22,651.87655
Overall Steps per Second: 10,671.38462

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.68655

Cumulative Model Updates: 131,744
Cumulative Timesteps: 1,098,571,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1098571114...
Checkpoint 1098571114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,948.98769
Policy Entropy: 3.70960
Value Function Loss: 0.02043

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.43388
Value Function Update Magnitude: 0.37743

Collected Steps per Second: 22,681.36616
Overall Steps per Second: 10,816.10883

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.62569

Cumulative Model Updates: 131,750
Cumulative Timesteps: 1,098,621,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,948.98769
Policy Entropy: 3.71516
Value Function Loss: 0.01844

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.41865
Value Function Update Magnitude: 0.31689

Collected Steps per Second: 22,805.85861
Overall Steps per Second: 10,652.61567

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.50126
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.69368

Cumulative Model Updates: 131,756
Cumulative Timesteps: 1,098,671,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1098671146...
Checkpoint 1098671146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,948.98769
Policy Entropy: 3.70823
Value Function Loss: 0.01938

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14617
Policy Update Magnitude: 0.41243
Value Function Update Magnitude: 0.31077

Collected Steps per Second: 22,461.23468
Overall Steps per Second: 10,585.30869

Timestep Collection Time: 2.22668
Timestep Consumption Time: 2.49817
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.72485

Cumulative Model Updates: 131,762
Cumulative Timesteps: 1,098,721,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,833.53224
Policy Entropy: 3.71362
Value Function Loss: 0.01959

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.42358
Value Function Update Magnitude: 0.31402

Collected Steps per Second: 22,829.11692
Overall Steps per Second: 10,845.24537

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.61124

Cumulative Model Updates: 131,768
Cumulative Timesteps: 1,098,771,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1098771170...
Checkpoint 1098771170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,224.23443
Policy Entropy: 3.72516
Value Function Loss: 0.02006

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13561
Policy Update Magnitude: 0.42012
Value Function Update Magnitude: 0.33725

Collected Steps per Second: 22,581.24291
Overall Steps per Second: 10,623.44020

Timestep Collection Time: 2.21423
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.70657

Cumulative Model Updates: 131,774
Cumulative Timesteps: 1,098,821,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,224.23443
Policy Entropy: 3.73566
Value Function Loss: 0.01941

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.43192
Value Function Update Magnitude: 0.41726

Collected Steps per Second: 22,748.86155
Overall Steps per Second: 10,815.12246

Timestep Collection Time: 2.19906
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.62556

Cumulative Model Updates: 131,780
Cumulative Timesteps: 1,098,871,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1098871196...
Checkpoint 1098871196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,694.74456
Policy Entropy: 3.73328
Value Function Loss: 0.02076

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.44677
Value Function Update Magnitude: 0.40334

Collected Steps per Second: 22,425.83315
Overall Steps per Second: 10,765.48594

Timestep Collection Time: 2.22993
Timestep Consumption Time: 2.41529
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.64522

Cumulative Model Updates: 131,786
Cumulative Timesteps: 1,098,921,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,317.32226
Policy Entropy: 3.73950
Value Function Loss: 0.01959

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.48779
Value Function Update Magnitude: 0.36874

Collected Steps per Second: 22,002.13343
Overall Steps per Second: 10,796.10876

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.35936
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.63241

Cumulative Model Updates: 131,792
Cumulative Timesteps: 1,098,971,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1098971216...
Checkpoint 1098971216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,688.61870
Policy Entropy: 3.74180
Value Function Loss: 0.02261

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.45974
Value Function Update Magnitude: 0.37192

Collected Steps per Second: 21,648.81904
Overall Steps per Second: 10,528.29889

Timestep Collection Time: 2.31190
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 4.75385

Cumulative Model Updates: 131,798
Cumulative Timesteps: 1,099,021,266

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,291.70023
Policy Entropy: 3.75234
Value Function Loss: 0.02058

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.47061
Value Function Update Magnitude: 0.42347

Collected Steps per Second: 21,942.12458
Overall Steps per Second: 10,620.38295

Timestep Collection Time: 2.27945
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70943

Cumulative Model Updates: 131,804
Cumulative Timesteps: 1,099,071,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099071282...
Checkpoint 1099071282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,238.09934
Policy Entropy: 3.74007
Value Function Loss: 0.02286

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.45294
Value Function Update Magnitude: 0.45053

Collected Steps per Second: 21,796.19909
Overall Steps per Second: 10,633.75948

Timestep Collection Time: 2.29453
Timestep Consumption Time: 2.40861
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70313

Cumulative Model Updates: 131,810
Cumulative Timesteps: 1,099,121,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.72502
Value Function Loss: 0.02123

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.42984
Value Function Update Magnitude: 0.41040

Collected Steps per Second: 22,656.27296
Overall Steps per Second: 10,865.43944

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.39610
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60414

Cumulative Model Updates: 131,816
Cumulative Timesteps: 1,099,171,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1099171320...
Checkpoint 1099171320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.72282
Value Function Loss: 0.01886

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.39543
Value Function Update Magnitude: 0.36609

Collected Steps per Second: 22,611.85094
Overall Steps per Second: 10,709.80492

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.67105

Cumulative Model Updates: 131,822
Cumulative Timesteps: 1,099,221,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.72203
Value Function Loss: 0.01561

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.35651
Value Function Update Magnitude: 0.29196

Collected Steps per Second: 22,839.91497
Overall Steps per Second: 10,824.45548

Timestep Collection Time: 2.18994
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62083

Cumulative Model Updates: 131,828
Cumulative Timesteps: 1,099,271,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1099271364...
Checkpoint 1099271364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.73912
Value Function Loss: 0.01274

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.32706
Value Function Update Magnitude: 0.24422

Collected Steps per Second: 22,577.13550
Overall Steps per Second: 10,795.50832

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.41712
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.63193

Cumulative Model Updates: 131,834
Cumulative Timesteps: 1,099,321,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.73744
Value Function Loss: 0.01424

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.31365
Value Function Update Magnitude: 0.22986

Collected Steps per Second: 22,621.36448
Overall Steps per Second: 10,754.30433

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.65060

Cumulative Model Updates: 131,840
Cumulative Timesteps: 1,099,371,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1099371382...
Checkpoint 1099371382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.74073
Value Function Loss: 0.01265

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.32677
Value Function Update Magnitude: 0.25995

Collected Steps per Second: 22,572.88767
Overall Steps per Second: 10,725.47033

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.66329

Cumulative Model Updates: 131,846
Cumulative Timesteps: 1,099,421,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.72378
Value Function Loss: 0.01552

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.33567
Value Function Update Magnitude: 0.31153

Collected Steps per Second: 22,654.19157
Overall Steps per Second: 10,646.28111

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.69854

Cumulative Model Updates: 131,852
Cumulative Timesteps: 1,099,471,420

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1099471420...
Checkpoint 1099471420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.71944
Value Function Loss: 0.01663

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.39088
Value Function Update Magnitude: 0.28532

Collected Steps per Second: 22,543.02398
Overall Steps per Second: 10,654.27755

Timestep Collection Time: 2.21913
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.69539

Cumulative Model Updates: 131,858
Cumulative Timesteps: 1,099,521,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.70461
Value Function Loss: 0.02223

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.43519
Value Function Update Magnitude: 0.32022

Collected Steps per Second: 22,606.73425
Overall Steps per Second: 10,729.11595

Timestep Collection Time: 2.21270
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.66227

Cumulative Model Updates: 131,864
Cumulative Timesteps: 1,099,571,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1099571468...
Checkpoint 1099571468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,236.91616
Policy Entropy: 3.71812
Value Function Loss: 0.01916

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.49550
Value Function Update Magnitude: 0.40435

Collected Steps per Second: 22,557.04778
Overall Steps per Second: 10,620.54716

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70955

Cumulative Model Updates: 131,870
Cumulative Timesteps: 1,099,621,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,100.09081
Policy Entropy: 3.70858
Value Function Loss: 0.02374

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.49153
Value Function Update Magnitude: 0.47488

Collected Steps per Second: 21,956.05708
Overall Steps per Second: 10,730.79972

Timestep Collection Time: 2.27846
Timestep Consumption Time: 2.38345
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.66191

Cumulative Model Updates: 131,876
Cumulative Timesteps: 1,099,671,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1099671512...
Checkpoint 1099671512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,100.09081
Policy Entropy: 3.72121
Value Function Loss: 0.02124

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.48551
Value Function Update Magnitude: 0.50295

Collected Steps per Second: 21,607.20186
Overall Steps per Second: 10,746.41171

Timestep Collection Time: 2.31469
Timestep Consumption Time: 2.33933
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.65402

Cumulative Model Updates: 131,882
Cumulative Timesteps: 1,099,721,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,100.09081
Policy Entropy: 3.71527
Value Function Loss: 0.02090

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14255
Policy Update Magnitude: 0.50124
Value Function Update Magnitude: 0.43186

Collected Steps per Second: 21,899.65687
Overall Steps per Second: 10,539.04510

Timestep Collection Time: 2.28387
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.74578

Cumulative Model Updates: 131,888
Cumulative Timesteps: 1,099,771,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099771542...
Checkpoint 1099771542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,100.09081
Policy Entropy: 3.71958
Value Function Loss: 0.01682

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.50357
Value Function Update Magnitude: 0.47877

Collected Steps per Second: 22,413.97147
Overall Steps per Second: 10,635.81826

Timestep Collection Time: 2.23289
Timestep Consumption Time: 2.47272
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70561

Cumulative Model Updates: 131,894
Cumulative Timesteps: 1,099,821,590

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,920.75546
Policy Entropy: 3.72574
Value Function Loss: 0.01941

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.50669
Value Function Update Magnitude: 0.64207

Collected Steps per Second: 22,377.50998
Overall Steps per Second: 10,671.57609

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.45145
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.68628

Cumulative Model Updates: 131,900
Cumulative Timesteps: 1,099,871,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1099871600...
Checkpoint 1099871600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318,297.48619
Policy Entropy: 3.71885
Value Function Loss: 0.02174

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.50653
Value Function Update Magnitude: 0.67321

Collected Steps per Second: 22,472.05756
Overall Steps per Second: 10,619.90431

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.70852

Cumulative Model Updates: 131,906
Cumulative Timesteps: 1,099,921,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,146.72137
Policy Entropy: 3.72693
Value Function Loss: 0.02029

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.52607
Value Function Update Magnitude: 0.69764

Collected Steps per Second: 23,096.71454
Overall Steps per Second: 10,722.98555

Timestep Collection Time: 2.16550
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.66437

Cumulative Model Updates: 131,912
Cumulative Timesteps: 1,099,971,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1099971620...
Checkpoint 1099971620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,814.84956
Policy Entropy: 3.72997
Value Function Loss: 0.02522

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.50420
Value Function Update Magnitude: 0.61030

Collected Steps per Second: 22,394.89683
Overall Steps per Second: 10,659.92891

Timestep Collection Time: 2.23265
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.69046

Cumulative Model Updates: 131,918
Cumulative Timesteps: 1,100,021,620

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,371.97094
Policy Entropy: 3.74606
Value Function Loss: 0.02433

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.54398
Value Function Update Magnitude: 0.55672

Collected Steps per Second: 22,879.42103
Overall Steps per Second: 10,825.50318

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.43345
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.61891

Cumulative Model Updates: 131,924
Cumulative Timesteps: 1,100,071,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1100071622...
Checkpoint 1100071622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,611.45902
Policy Entropy: 3.73717
Value Function Loss: 0.03061

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13792
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.52203

Collected Steps per Second: 22,218.94567
Overall Steps per Second: 10,742.90704

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.40390
PPO Batch Consumption Time: 0.27559
Total Iteration Time: 4.65423

Cumulative Model Updates: 131,930
Cumulative Timesteps: 1,100,121,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,911.16520
Policy Entropy: 3.73931
Value Function Loss: 0.03065

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.48679

Collected Steps per Second: 22,686.87089
Overall Steps per Second: 10,794.81596

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.42920
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.63426

Cumulative Model Updates: 131,936
Cumulative Timesteps: 1,100,171,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1100171648...
Checkpoint 1100171648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.33030
Policy Entropy: 3.73085
Value Function Loss: 0.03001

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.50729

Collected Steps per Second: 22,424.83136
Overall Steps per Second: 10,718.71437

Timestep Collection Time: 2.23083
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.66716

Cumulative Model Updates: 131,942
Cumulative Timesteps: 1,100,221,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314,183.40822
Policy Entropy: 3.73281
Value Function Loss: 0.02648

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.52518
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 22,237.89964
Overall Steps per Second: 10,864.10495

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.35446
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60342

Cumulative Model Updates: 131,948
Cumulative Timesteps: 1,100,271,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100271686...
Checkpoint 1100271686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314,183.40822
Policy Entropy: 3.73676
Value Function Loss: 0.02170

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14595
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.53689

Collected Steps per Second: 21,717.37768
Overall Steps per Second: 10,474.64936

Timestep Collection Time: 2.30286
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.77458

Cumulative Model Updates: 131,954
Cumulative Timesteps: 1,100,321,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314,183.40822
Policy Entropy: 3.73780
Value Function Loss: 0.01923

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.48073
Value Function Update Magnitude: 0.46453

Collected Steps per Second: 21,930.06491
Overall Steps per Second: 10,631.19489

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.42433
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.70540

Cumulative Model Updates: 131,960
Cumulative Timesteps: 1,100,371,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1100371722...
Checkpoint 1100371722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314,183.40822
Policy Entropy: 3.72903
Value Function Loss: 0.01771

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14247
Policy Update Magnitude: 0.44954
Value Function Update Magnitude: 0.41704

Collected Steps per Second: 22,431.05202
Overall Steps per Second: 10,651.12008

Timestep Collection Time: 2.23030
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.69697

Cumulative Model Updates: 131,966
Cumulative Timesteps: 1,100,421,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 466,749.33263
Policy Entropy: 3.70595
Value Function Loss: 0.02359

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.48100
Value Function Update Magnitude: 0.45519

Collected Steps per Second: 22,802.79490
Overall Steps per Second: 10,835.80038

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.42201
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61507

Cumulative Model Updates: 131,972
Cumulative Timesteps: 1,100,471,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1100471758...
Checkpoint 1100471758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,395.91709
Policy Entropy: 3.71959
Value Function Loss: 0.02789

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.68587

Collected Steps per Second: 22,344.60832
Overall Steps per Second: 10,722.74349

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.66355

Cumulative Model Updates: 131,978
Cumulative Timesteps: 1,100,521,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,351.05349
Policy Entropy: 3.72238
Value Function Loss: 0.02759

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.62883
Value Function Update Magnitude: 0.93002

Collected Steps per Second: 22,516.71724
Overall Steps per Second: 10,818.27164

Timestep Collection Time: 2.22111
Timestep Consumption Time: 2.40181
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62292

Cumulative Model Updates: 131,984
Cumulative Timesteps: 1,100,571,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1100571776...
Checkpoint 1100571776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,080.76167
Policy Entropy: 3.75452
Value Function Loss: 0.02518

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.62209
Value Function Update Magnitude: 0.90358

Collected Steps per Second: 22,453.72645
Overall Steps per Second: 10,539.46300

Timestep Collection Time: 2.22734
Timestep Consumption Time: 2.51788
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74521

Cumulative Model Updates: 131,990
Cumulative Timesteps: 1,100,621,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,515.73463
Policy Entropy: 3.74950
Value Function Loss: 0.01973

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.74451

Collected Steps per Second: 21,943.80973
Overall Steps per Second: 10,631.66651

Timestep Collection Time: 2.27873
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.70331

Cumulative Model Updates: 131,996
Cumulative Timesteps: 1,100,671,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1100671792...
Checkpoint 1100671792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,101.58543
Policy Entropy: 3.74972
Value Function Loss: 0.01845

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.48786
Value Function Update Magnitude: 0.63460

Collected Steps per Second: 23,123.94799
Overall Steps per Second: 10,748.14537

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.65252

Cumulative Model Updates: 132,002
Cumulative Timesteps: 1,100,721,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,373.92993
Policy Entropy: 3.75639
Value Function Loss: 0.01773

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14153
Policy Update Magnitude: 0.46093
Value Function Update Magnitude: 0.56852

Collected Steps per Second: 23,365.99046
Overall Steps per Second: 10,811.54494

Timestep Collection Time: 2.14157
Timestep Consumption Time: 2.48681
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.62839

Cumulative Model Updates: 132,008
Cumulative Timesteps: 1,100,771,838

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1100771838...
Checkpoint 1100771838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,470.45242
Policy Entropy: 3.75482
Value Function Loss: 0.01956

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.48636
Value Function Update Magnitude: 0.71105

Collected Steps per Second: 22,882.06803
Overall Steps per Second: 10,636.22369

Timestep Collection Time: 2.18547
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70167

Cumulative Model Updates: 132,014
Cumulative Timesteps: 1,100,821,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,727.14366
Policy Entropy: 3.75652
Value Function Loss: 0.02033

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.52147
Value Function Update Magnitude: 0.84044

Collected Steps per Second: 22,960.34374
Overall Steps per Second: 10,841.71046

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61329

Cumulative Model Updates: 132,020
Cumulative Timesteps: 1,100,871,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1100871862...
Checkpoint 1100871862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.72810
Value Function Loss: 0.02321

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.57425
Value Function Update Magnitude: 0.79707

Collected Steps per Second: 22,895.23166
Overall Steps per Second: 10,663.35130

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.50630
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.69121

Cumulative Model Updates: 132,026
Cumulative Timesteps: 1,100,921,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.71280
Value Function Loss: 0.02341

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.76424

Collected Steps per Second: 23,103.28327
Overall Steps per Second: 10,902.40927

Timestep Collection Time: 2.16463
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.58706

Cumulative Model Updates: 132,032
Cumulative Timesteps: 1,100,971,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1100971896...
Checkpoint 1100971896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.70322
Value Function Loss: 0.02506

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.52231
Value Function Update Magnitude: 0.58020

Collected Steps per Second: 22,817.60404
Overall Steps per Second: 10,679.77542

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.49075
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.68231

Cumulative Model Updates: 132,038
Cumulative Timesteps: 1,101,021,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.70892
Value Function Loss: 0.02125

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.48158
Value Function Update Magnitude: 0.51014

Collected Steps per Second: 23,209.78073
Overall Steps per Second: 10,915.71760

Timestep Collection Time: 2.15547
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.58312

Cumulative Model Updates: 132,044
Cumulative Timesteps: 1,101,071,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1101071930...
Checkpoint 1101071930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.73109
Value Function Loss: 0.01823

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14108
Policy Update Magnitude: 0.43920
Value Function Update Magnitude: 0.40872

Collected Steps per Second: 22,616.97467
Overall Steps per Second: 10,604.17109

Timestep Collection Time: 2.21188
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.71758

Cumulative Model Updates: 132,050
Cumulative Timesteps: 1,101,121,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,425.61536
Policy Entropy: 3.73129
Value Function Loss: 0.01405

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14622
Policy Update Magnitude: 0.39755
Value Function Update Magnitude: 0.44620

Collected Steps per Second: 22,735.71780
Overall Steps per Second: 10,730.57944

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.66312

Cumulative Model Updates: 132,056
Cumulative Timesteps: 1,101,171,994

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1101171994...
Checkpoint 1101171994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561,890.34454
Policy Entropy: 3.72029
Value Function Loss: 0.01653

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.39888
Value Function Update Magnitude: 0.53109

Collected Steps per Second: 22,786.21964
Overall Steps per Second: 10,832.07142

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.61592

Cumulative Model Updates: 132,062
Cumulative Timesteps: 1,101,221,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,877.78268
Policy Entropy: 3.72108
Value Function Loss: 0.01783

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.44123
Value Function Update Magnitude: 0.58455

Collected Steps per Second: 22,038.90793
Overall Steps per Second: 10,675.33799

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.41527
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68425

Cumulative Model Updates: 132,068
Cumulative Timesteps: 1,101,272,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1101272000...
Checkpoint 1101272000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,379.36299
Policy Entropy: 3.70766
Value Function Loss: 0.02415

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.51221
Value Function Update Magnitude: 0.58606

Collected Steps per Second: 21,957.29526
Overall Steps per Second: 10,820.80292

Timestep Collection Time: 2.27715
Timestep Consumption Time: 2.34358
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.62073

Cumulative Model Updates: 132,074
Cumulative Timesteps: 1,101,322,000

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,651.88673
Policy Entropy: 3.72310
Value Function Loss: 0.02461

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.60143
Value Function Update Magnitude: 0.66825

Collected Steps per Second: 22,420.86625
Overall Steps per Second: 10,948.28550

Timestep Collection Time: 2.23051
Timestep Consumption Time: 2.33733
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.56784

Cumulative Model Updates: 132,080
Cumulative Timesteps: 1,101,372,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1101372010...
Checkpoint 1101372010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,197.61990
Policy Entropy: 3.70791
Value Function Loss: 0.02754

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.60269
Value Function Update Magnitude: 0.64486

Collected Steps per Second: 22,091.58337
Overall Steps per Second: 10,652.61054

Timestep Collection Time: 2.26358
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.69425

Cumulative Model Updates: 132,086
Cumulative Timesteps: 1,101,422,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,197.61990
Policy Entropy: 3.72440
Value Function Loss: 0.02322

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.54452

Collected Steps per Second: 22,870.13260
Overall Steps per Second: 10,878.34159

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.41090
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.59794

Cumulative Model Updates: 132,092
Cumulative Timesteps: 1,101,472,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1101472034...
Checkpoint 1101472034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,197.61990
Policy Entropy: 3.71987
Value Function Loss: 0.02313

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.47901
Value Function Update Magnitude: 0.49277

Collected Steps per Second: 22,608.42257
Overall Steps per Second: 10,685.74908

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.68100

Cumulative Model Updates: 132,098
Cumulative Timesteps: 1,101,522,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,197.61990
Policy Entropy: 3.72564
Value Function Loss: 0.01915

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.45803
Value Function Update Magnitude: 0.48339

Collected Steps per Second: 23,181.95747
Overall Steps per Second: 10,882.62169

Timestep Collection Time: 2.15780
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59650

Cumulative Model Updates: 132,104
Cumulative Timesteps: 1,101,572,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1101572076...
Checkpoint 1101572076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309,780.02912
Policy Entropy: 3.72217
Value Function Loss: 0.02096

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.45230
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 22,846.43288
Overall Steps per Second: 10,661.62594

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.68990

Cumulative Model Updates: 132,110
Cumulative Timesteps: 1,101,622,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,023.06187
Policy Entropy: 3.72914
Value Function Loss: 0.02015

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.68347

Collected Steps per Second: 23,274.49402
Overall Steps per Second: 10,913.74960

Timestep Collection Time: 2.14879
Timestep Consumption Time: 2.43369
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.58248

Cumulative Model Updates: 132,116
Cumulative Timesteps: 1,101,672,090

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1101672090...
Checkpoint 1101672090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,673.48119
Policy Entropy: 3.73638
Value Function Loss: 0.02182

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.50336
Value Function Update Magnitude: 0.63543

Collected Steps per Second: 22,615.99512
Overall Steps per Second: 10,635.84889

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.70409

Cumulative Model Updates: 132,122
Cumulative Timesteps: 1,101,722,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,010.09973
Policy Entropy: 3.72464
Value Function Loss: 0.02550

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13795
Policy Update Magnitude: 0.50732
Value Function Update Magnitude: 0.49797

Collected Steps per Second: 23,205.73427
Overall Steps per Second: 10,957.05813

Timestep Collection Time: 2.15559
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.56528

Cumulative Model Updates: 132,128
Cumulative Timesteps: 1,101,772,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1101772144...
Checkpoint 1101772144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,715.94399
Policy Entropy: 3.73615
Value Function Loss: 0.02202

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.49634
Value Function Update Magnitude: 0.50007

Collected Steps per Second: 22,761.67046
Overall Steps per Second: 10,705.85408

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.47436
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.67165

Cumulative Model Updates: 132,134
Cumulative Timesteps: 1,101,822,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,715.94399
Policy Entropy: 3.72012
Value Function Loss: 0.01873

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14765
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.58022

Collected Steps per Second: 22,452.90512
Overall Steps per Second: 10,814.97622

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.39643
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.62340

Cumulative Model Updates: 132,140
Cumulative Timesteps: 1,101,872,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1101872160...
Checkpoint 1101872160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,157.07188
Policy Entropy: 3.74355
Value Function Loss: 0.01561

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14581
Policy Update Magnitude: 0.46027
Value Function Update Magnitude: 0.55556

Collected Steps per Second: 21,854.08364
Overall Steps per Second: 10,623.80592

Timestep Collection Time: 2.28891
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70848

Cumulative Model Updates: 132,146
Cumulative Timesteps: 1,101,922,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,157.07188
Policy Entropy: 3.72997
Value Function Loss: 0.01632

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.42877
Value Function Update Magnitude: 0.52030

Collected Steps per Second: 22,438.88258
Overall Steps per Second: 10,968.45641

Timestep Collection Time: 2.22899
Timestep Consumption Time: 2.33100
PPO Batch Consumption Time: 0.27582
Total Iteration Time: 4.55999

Cumulative Model Updates: 132,152
Cumulative Timesteps: 1,101,972,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1101972198...
Checkpoint 1101972198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 375,805.51011
Policy Entropy: 3.73924
Value Function Loss: 0.01740

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.44740
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 22,108.24641
Overall Steps per Second: 10,597.19432

Timestep Collection Time: 2.26196
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.71898

Cumulative Model Updates: 132,158
Cumulative Timesteps: 1,102,022,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,805.51011
Policy Entropy: 3.72754
Value Function Loss: 0.01779

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.47453
Value Function Update Magnitude: 0.56695

Collected Steps per Second: 23,167.66993
Overall Steps per Second: 10,909.17666

Timestep Collection Time: 2.15844
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.58385

Cumulative Model Updates: 132,164
Cumulative Timesteps: 1,102,072,212

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1102072212...
Checkpoint 1102072212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316,554.77632
Policy Entropy: 3.73729
Value Function Loss: 0.01663

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.52404
Value Function Update Magnitude: 0.63328

Collected Steps per Second: 22,557.60327
Overall Steps per Second: 10,659.71420

Timestep Collection Time: 2.21664
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69074

Cumulative Model Updates: 132,170
Cumulative Timesteps: 1,102,122,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,554.77632
Policy Entropy: 3.73028
Value Function Loss: 0.01601

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.50980
Value Function Update Magnitude: 0.64091

Collected Steps per Second: 23,072.54709
Overall Steps per Second: 10,937.06040

Timestep Collection Time: 2.16760
Timestep Consumption Time: 2.40511
PPO Batch Consumption Time: 0.27582
Total Iteration Time: 4.57271

Cumulative Model Updates: 132,176
Cumulative Timesteps: 1,102,172,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1102172226...
Checkpoint 1102172226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316,554.77632
Policy Entropy: 3.72211
Value Function Loss: 0.01548

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.48743
Value Function Update Magnitude: 0.66062

Collected Steps per Second: 23,042.92013
Overall Steps per Second: 10,787.62771

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.63753

Cumulative Model Updates: 132,182
Cumulative Timesteps: 1,102,222,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,554.77632
Policy Entropy: 3.71737
Value Function Loss: 0.01551

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.44496
Value Function Update Magnitude: 0.62135

Collected Steps per Second: 23,081.84338
Overall Steps per Second: 10,715.81237

Timestep Collection Time: 2.16638
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.66638

Cumulative Model Updates: 132,188
Cumulative Timesteps: 1,102,272,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1102272258...
Checkpoint 1102272258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255,265.54674
Policy Entropy: 3.71762
Value Function Loss: 0.01808

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.42874
Value Function Update Magnitude: 0.59029

Collected Steps per Second: 22,770.65353
Overall Steps per Second: 10,660.68696

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69107

Cumulative Model Updates: 132,194
Cumulative Timesteps: 1,102,322,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,612.88819
Policy Entropy: 3.72769
Value Function Loss: 0.01869

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.57895

Collected Steps per Second: 22,713.96463
Overall Steps per Second: 10,833.99734

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.61769

Cumulative Model Updates: 132,200
Cumulative Timesteps: 1,102,372,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1102372296...
Checkpoint 1102372296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,445.64042
Policy Entropy: 3.71908
Value Function Loss: 0.02326

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.50729
Value Function Update Magnitude: 0.58447

Collected Steps per Second: 22,611.74008
Overall Steps per Second: 10,696.88078

Timestep Collection Time: 2.21159
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.67501

Cumulative Model Updates: 132,206
Cumulative Timesteps: 1,102,422,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,335.65337
Policy Entropy: 3.72849
Value Function Loss: 0.02069

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.53220
Value Function Update Magnitude: 0.67167

Collected Steps per Second: 22,838.41366
Overall Steps per Second: 10,832.00982

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.42704
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61669

Cumulative Model Updates: 132,212
Cumulative Timesteps: 1,102,472,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1102472312...
Checkpoint 1102472312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,335.65337
Policy Entropy: 3.71687
Value Function Loss: 0.02299

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.50765
Value Function Update Magnitude: 0.64035

Collected Steps per Second: 22,753.16063
Overall Steps per Second: 10,699.11675

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.47717
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.67590

Cumulative Model Updates: 132,218
Cumulative Timesteps: 1,102,522,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,335.65337
Policy Entropy: 3.72102
Value Function Loss: 0.02077

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.46467
Value Function Update Magnitude: 0.48609

Collected Steps per Second: 23,135.70720
Overall Steps per Second: 10,941.03417

Timestep Collection Time: 2.16151
Timestep Consumption Time: 2.40918
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.57068

Cumulative Model Updates: 132,224
Cumulative Timesteps: 1,102,572,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1102572348...
Checkpoint 1102572348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,335.65337
Policy Entropy: 3.70772
Value Function Loss: 0.02306

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.44736
Value Function Update Magnitude: 0.46739

Collected Steps per Second: 22,004.99251
Overall Steps per Second: 10,700.02529

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.40096
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.67345

Cumulative Model Updates: 132,230
Cumulative Timesteps: 1,102,622,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,587.95915
Policy Entropy: 3.71926
Value Function Loss: 0.02123

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.47246
Value Function Update Magnitude: 0.53903

Collected Steps per Second: 22,236.47223
Overall Steps per Second: 10,816.90432

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.37583
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.62628

Cumulative Model Updates: 132,236
Cumulative Timesteps: 1,102,672,396

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1102672396...
Checkpoint 1102672396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,297.23157
Policy Entropy: 3.72513
Value Function Loss: 0.02390

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.53945
Value Function Update Magnitude: 0.58803

Collected Steps per Second: 22,210.14085
Overall Steps per Second: 10,736.22398

Timestep Collection Time: 2.25158
Timestep Consumption Time: 2.40629
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.65788

Cumulative Model Updates: 132,242
Cumulative Timesteps: 1,102,722,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,191.89598
Policy Entropy: 3.73709
Value Function Loss: 0.02244

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.68343

Collected Steps per Second: 22,237.74414
Overall Steps per Second: 10,720.89740

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.41613
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.66528

Cumulative Model Updates: 132,248
Cumulative Timesteps: 1,102,772,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1102772420...
Checkpoint 1102772420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,859.73648
Policy Entropy: 3.73515
Value Function Loss: 0.02088

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.55982
Value Function Update Magnitude: 0.81174

Collected Steps per Second: 22,657.79803
Overall Steps per Second: 10,728.62687

Timestep Collection Time: 2.20754
Timestep Consumption Time: 2.45457
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.66211

Cumulative Model Updates: 132,254
Cumulative Timesteps: 1,102,822,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,859.73648
Policy Entropy: 3.72629
Value Function Loss: 0.01892

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.51325
Value Function Update Magnitude: 0.69453

Collected Steps per Second: 23,050.69051
Overall Steps per Second: 10,973.72674

Timestep Collection Time: 2.17017
Timestep Consumption Time: 2.38835
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.55852

Cumulative Model Updates: 132,260
Cumulative Timesteps: 1,102,872,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1102872462...
Checkpoint 1102872462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,260.54399
Policy Entropy: 3.71004
Value Function Loss: 0.02304

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.47491
Value Function Update Magnitude: 0.57112

Collected Steps per Second: 22,773.83053
Overall Steps per Second: 10,640.50805

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70166

Cumulative Model Updates: 132,266
Cumulative Timesteps: 1,102,922,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,685.23567
Policy Entropy: 3.72548
Value Function Loss: 0.02351

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.52098

Collected Steps per Second: 23,052.74188
Overall Steps per Second: 10,926.50054

Timestep Collection Time: 2.17015
Timestep Consumption Time: 2.40844
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.57859

Cumulative Model Updates: 132,272
Cumulative Timesteps: 1,102,972,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1102972518...
Checkpoint 1102972518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,425.38647
Policy Entropy: 3.71836
Value Function Loss: 0.02829

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.48328

Collected Steps per Second: 23,046.35579
Overall Steps per Second: 10,782.50735

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.46869
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.63918

Cumulative Model Updates: 132,278
Cumulative Timesteps: 1,103,022,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,465.23005
Policy Entropy: 3.73082
Value Function Loss: 0.02548

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.52523
Value Function Update Magnitude: 0.46043

Collected Steps per Second: 22,965.13691
Overall Steps per Second: 10,677.31058

Timestep Collection Time: 2.17747
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68339

Cumulative Model Updates: 132,284
Cumulative Timesteps: 1,103,072,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1103072546...
Checkpoint 1103072546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,465.23005
Policy Entropy: 3.69529
Value Function Loss: 0.02321

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.48674
Value Function Update Magnitude: 0.53532

Collected Steps per Second: 22,835.86071
Overall Steps per Second: 10,662.53393

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.50068
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69101

Cumulative Model Updates: 132,290
Cumulative Timesteps: 1,103,122,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,465.23005
Policy Entropy: 3.71800
Value Function Loss: 0.01962

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.45981
Value Function Update Magnitude: 0.50392

Collected Steps per Second: 22,832.28186
Overall Steps per Second: 10,846.27668

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.61246

Cumulative Model Updates: 132,296
Cumulative Timesteps: 1,103,172,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1103172592...
Checkpoint 1103172592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,474.01573
Policy Entropy: 3.70836
Value Function Loss: 0.02152

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.43493
Value Function Update Magnitude: 0.42593

Collected Steps per Second: 22,664.83476
Overall Steps per Second: 10,705.08934

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.67180

Cumulative Model Updates: 132,302
Cumulative Timesteps: 1,103,222,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.73570
Value Function Loss: 0.02266

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.48383
Value Function Update Magnitude: 0.39227

Collected Steps per Second: 22,924.29137
Overall Steps per Second: 10,867.86997

Timestep Collection Time: 2.18249
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.60366

Cumulative Model Updates: 132,308
Cumulative Timesteps: 1,103,272,636

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1103272636...
Checkpoint 1103272636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.72898
Value Function Loss: 0.02318

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.55313

Collected Steps per Second: 23,017.11673
Overall Steps per Second: 10,721.64897

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.66365

Cumulative Model Updates: 132,314
Cumulative Timesteps: 1,103,322,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.73185
Value Function Loss: 0.01903

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.45934
Value Function Update Magnitude: 0.58017

Collected Steps per Second: 22,923.90525
Overall Steps per Second: 10,903.68045

Timestep Collection Time: 2.18183
Timestep Consumption Time: 2.40525
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.58708

Cumulative Model Updates: 132,320
Cumulative Timesteps: 1,103,372,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1103372654...
Checkpoint 1103372654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.72366
Value Function Loss: 0.01947

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.43246
Value Function Update Magnitude: 0.48583

Collected Steps per Second: 22,832.84313
Overall Steps per Second: 10,714.39452

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.66755

Cumulative Model Updates: 132,326
Cumulative Timesteps: 1,103,422,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.71548
Value Function Loss: 0.01608

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.46113
Value Function Update Magnitude: 0.54170

Collected Steps per Second: 23,510.96295
Overall Steps per Second: 10,829.72566

Timestep Collection Time: 2.12786
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.61951

Cumulative Model Updates: 132,332
Cumulative Timesteps: 1,103,472,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1103472692...
Checkpoint 1103472692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.71865
Value Function Loss: 0.01493

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.49446
Value Function Update Magnitude: 0.57400

Collected Steps per Second: 23,100.31456
Overall Steps per Second: 10,805.51533

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.46368
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.62893

Cumulative Model Updates: 132,338
Cumulative Timesteps: 1,103,522,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,198.54999
Policy Entropy: 3.70672
Value Function Loss: 0.01599

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.23211
Policy Update Magnitude: 0.45688
Value Function Update Magnitude: 0.53322

Collected Steps per Second: 22,085.91470
Overall Steps per Second: 10,721.65053

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.40111
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.66645

Cumulative Model Updates: 132,344
Cumulative Timesteps: 1,103,572,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1103572742...
Checkpoint 1103572742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 528,100.39756
Policy Entropy: 3.69375
Value Function Loss: 0.03598

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.23853
Policy Update Magnitude: 0.47159
Value Function Update Magnitude: 0.49346

Collected Steps per Second: 21,904.24661
Overall Steps per Second: 10,620.47945

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70807

Cumulative Model Updates: 132,350
Cumulative Timesteps: 1,103,622,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298,272.88785
Policy Entropy: 3.70485
Value Function Loss: 0.06070

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.17150
Policy Update Magnitude: 0.85981
Value Function Update Magnitude: 0.62320

Collected Steps per Second: 22,024.11769
Overall Steps per Second: 10,806.64357

Timestep Collection Time: 2.27115
Timestep Consumption Time: 2.35749
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.62863

Cumulative Model Updates: 132,356
Cumulative Timesteps: 1,103,672,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1103672764...
Checkpoint 1103672764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,206.36133
Policy Entropy: 3.75118
Value Function Loss: 0.05196

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.17457
Policy Update Magnitude: 1.04310
Value Function Update Magnitude: 0.58114

Collected Steps per Second: 22,235.94889
Overall Steps per Second: 10,715.01401

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.41832
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.66747

Cumulative Model Updates: 132,362
Cumulative Timesteps: 1,103,722,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,502.04320
Policy Entropy: 3.76581
Value Function Loss: 0.04531

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.16956
Policy Update Magnitude: 1.08448
Value Function Update Magnitude: 0.67592

Collected Steps per Second: 22,312.53280
Overall Steps per Second: 10,896.60643

Timestep Collection Time: 2.24098
Timestep Consumption Time: 2.34779
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.58877

Cumulative Model Updates: 132,368
Cumulative Timesteps: 1,103,772,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1103772778...
Checkpoint 1103772778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,059.42517
Policy Entropy: 3.74728
Value Function Loss: 0.03878

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.93300
Value Function Update Magnitude: 0.66774

Collected Steps per Second: 21,933.29321
Overall Steps per Second: 10,677.71776

Timestep Collection Time: 2.27982
Timestep Consumption Time: 2.40320
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.68302

Cumulative Model Updates: 132,374
Cumulative Timesteps: 1,103,822,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,784.92416
Policy Entropy: 3.74381
Value Function Loss: 0.03463

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17613
Policy Update Magnitude: 0.89802
Value Function Update Magnitude: 0.59855

Collected Steps per Second: 22,358.24164
Overall Steps per Second: 10,660.70409

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.69256

Cumulative Model Updates: 132,380
Cumulative Timesteps: 1,103,872,808

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1103872808...
Checkpoint 1103872808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,807.77920
Policy Entropy: 3.76013
Value Function Loss: 0.03363

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.18169
Policy Update Magnitude: 0.75439
Value Function Update Magnitude: 0.66910

Collected Steps per Second: 22,933.35519
Overall Steps per Second: 10,891.07646

Timestep Collection Time: 2.18136
Timestep Consumption Time: 2.41194
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.59330

Cumulative Model Updates: 132,386
Cumulative Timesteps: 1,103,922,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,235.13421
Policy Entropy: 3.75487
Value Function Loss: 0.03446

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16520
Policy Update Magnitude: 0.71807
Value Function Update Magnitude: 0.76402

Collected Steps per Second: 23,035.49840
Overall Steps per Second: 10,964.26647

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.38980
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.56045

Cumulative Model Updates: 132,392
Cumulative Timesteps: 1,103,972,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1103972836...
Checkpoint 1103972836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,630.47527
Policy Entropy: 3.73776
Value Function Loss: 0.03802

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.75022
Value Function Update Magnitude: 0.85451

Collected Steps per Second: 22,780.27059
Overall Steps per Second: 10,928.45480

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.38119
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.57686

Cumulative Model Updates: 132,398
Cumulative Timesteps: 1,104,022,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,585.01919
Policy Entropy: 3.76426
Value Function Loss: 0.03730

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.84490
Value Function Update Magnitude: 0.80693

Collected Steps per Second: 22,145.51421
Overall Steps per Second: 10,551.48396

Timestep Collection Time: 2.25788
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.73886

Cumulative Model Updates: 132,404
Cumulative Timesteps: 1,104,072,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1104072856...
Checkpoint 1104072856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,539.10196
Policy Entropy: 3.79955
Value Function Loss: 0.03332

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.86451
Value Function Update Magnitude: 0.63940

Collected Steps per Second: 22,966.73763
Overall Steps per Second: 10,782.85117

Timestep Collection Time: 2.17750
Timestep Consumption Time: 2.46042
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.63792

Cumulative Model Updates: 132,410
Cumulative Timesteps: 1,104,122,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.84463
Policy Entropy: 3.82561
Value Function Loss: 0.02810

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.84727
Value Function Update Magnitude: 0.66140

Collected Steps per Second: 22,932.85383
Overall Steps per Second: 10,770.52662

Timestep Collection Time: 2.18071
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.64323

Cumulative Model Updates: 132,416
Cumulative Timesteps: 1,104,172,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1104172876...
Checkpoint 1104172876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,769.55802
Policy Entropy: 3.81322
Value Function Loss: 0.03017

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.70020
Value Function Update Magnitude: 0.56941

Collected Steps per Second: 22,673.35673
Overall Steps per Second: 10,623.21149

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70912

Cumulative Model Updates: 132,422
Cumulative Timesteps: 1,104,222,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,042.89342
Policy Entropy: 3.79745
Value Function Loss: 0.02894

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.68315
Value Function Update Magnitude: 0.60998

Collected Steps per Second: 22,765.00033
Overall Steps per Second: 10,815.31246

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.62437

Cumulative Model Updates: 132,428
Cumulative Timesteps: 1,104,272,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1104272916...
Checkpoint 1104272916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,888.62778
Policy Entropy: 3.79343
Value Function Loss: 0.02954

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.68365
Value Function Update Magnitude: 0.62462

Collected Steps per Second: 22,827.29126
Overall Steps per Second: 10,732.81223

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.66085

Cumulative Model Updates: 132,434
Cumulative Timesteps: 1,104,322,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,565.22005
Policy Entropy: 3.78615
Value Function Loss: 0.03254

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.19541
Policy Update Magnitude: 0.59816
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 22,815.57604
Overall Steps per Second: 10,811.79275

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.43339
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.62513

Cumulative Model Updates: 132,440
Cumulative Timesteps: 1,104,372,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1104372946...
Checkpoint 1104372946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,180.40662
Policy Entropy: 3.81016
Value Function Loss: 0.04391

Mean KL Divergence: 0.01952
SB3 Clip Fraction: 0.21330
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.63827

Collected Steps per Second: 22,592.11504
Overall Steps per Second: 10,765.44695

Timestep Collection Time: 2.21405
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.64635

Cumulative Model Updates: 132,446
Cumulative Timesteps: 1,104,422,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,380.00892
Policy Entropy: 3.87764
Value Function Loss: 0.04750

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.68144
Value Function Update Magnitude: 0.54783

Collected Steps per Second: 23,120.34010
Overall Steps per Second: 10,891.85452

Timestep Collection Time: 2.16381
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.59316

Cumulative Model Updates: 132,452
Cumulative Timesteps: 1,104,472,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1104472994...
Checkpoint 1104472994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.97799
Policy Entropy: 3.95428
Value Function Loss: 0.04688

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.81519
Value Function Update Magnitude: 0.48716

Collected Steps per Second: 22,913.91664
Overall Steps per Second: 11,061.29209

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.33837
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.52063

Cumulative Model Updates: 132,458
Cumulative Timesteps: 1,104,522,998

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,183.63108
Policy Entropy: 3.97233
Value Function Loss: 0.03860

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.76526
Value Function Update Magnitude: 0.49061

Collected Steps per Second: 22,320.20534
Overall Steps per Second: 10,885.96938

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.35370
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.59454

Cumulative Model Updates: 132,464
Cumulative Timesteps: 1,104,573,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1104573014...
Checkpoint 1104573014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,056.02618
Policy Entropy: 3.94145
Value Function Loss: 0.03616

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.67715
Value Function Update Magnitude: 0.52077

Collected Steps per Second: 22,366.95507
Overall Steps per Second: 10,696.04022

Timestep Collection Time: 2.23633
Timestep Consumption Time: 2.44016
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.67650

Cumulative Model Updates: 132,470
Cumulative Timesteps: 1,104,623,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,237.96651
Policy Entropy: 3.88362
Value Function Loss: 0.03538

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.58294
Value Function Update Magnitude: 0.53091

Collected Steps per Second: 22,903.62918
Overall Steps per Second: 10,860.02830

Timestep Collection Time: 2.18367
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.60533

Cumulative Model Updates: 132,476
Cumulative Timesteps: 1,104,673,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1104673048...
Checkpoint 1104673048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.25794
Policy Entropy: 3.87699
Value Function Loss: 0.03465

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.59360
Value Function Update Magnitude: 0.48114

Collected Steps per Second: 22,718.93062
Overall Steps per Second: 10,666.48380

Timestep Collection Time: 2.20186
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.68983

Cumulative Model Updates: 132,482
Cumulative Timesteps: 1,104,723,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104.76742
Policy Entropy: 3.83863
Value Function Loss: 0.03365

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.59028
Value Function Update Magnitude: 0.44360

Collected Steps per Second: 22,996.93036
Overall Steps per Second: 10,924.99213

Timestep Collection Time: 2.17507
Timestep Consumption Time: 2.40342
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.57849

Cumulative Model Updates: 132,488
Cumulative Timesteps: 1,104,773,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1104773092...
Checkpoint 1104773092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.71993
Policy Entropy: 3.80357
Value Function Loss: 0.03291

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.22848
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.49629

Collected Steps per Second: 22,532.07568
Overall Steps per Second: 10,660.54928

Timestep Collection Time: 2.21968
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69150

Cumulative Model Updates: 132,494
Cumulative Timesteps: 1,104,823,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,232.25049
Policy Entropy: 3.80783
Value Function Loss: 0.03517

Mean KL Divergence: 0.01831
SB3 Clip Fraction: 0.21101
Policy Update Magnitude: 0.49598
Value Function Update Magnitude: 0.51531

Collected Steps per Second: 22,640.68578
Overall Steps per Second: 10,865.34154

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.39424
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60344

Cumulative Model Updates: 132,500
Cumulative Timesteps: 1,104,873,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1104873124...
Checkpoint 1104873124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,067.95811
Policy Entropy: 3.82826
Value Function Loss: 0.03272

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.17393
Policy Update Magnitude: 0.53786
Value Function Update Magnitude: 0.57396

Collected Steps per Second: 22,675.96308
Overall Steps per Second: 10,671.67016

Timestep Collection Time: 2.20621
Timestep Consumption Time: 2.48171
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.68793

Cumulative Model Updates: 132,506
Cumulative Timesteps: 1,104,923,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,915.62863
Policy Entropy: 3.78415
Value Function Loss: 0.03673

Mean KL Divergence: 0.01794
SB3 Clip Fraction: 0.19686
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.68296

Collected Steps per Second: 22,905.73803
Overall Steps per Second: 10,851.71346

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60812

Cumulative Model Updates: 132,512
Cumulative Timesteps: 1,104,973,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1104973158...
Checkpoint 1104973158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,129.31491
Policy Entropy: 3.79550
Value Function Loss: 0.04373

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.16855
Policy Update Magnitude: 0.55228
Value Function Update Magnitude: 0.53432

Collected Steps per Second: 22,679.76876
Overall Steps per Second: 10,718.97018

Timestep Collection Time: 2.20470
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.66481

Cumulative Model Updates: 132,518
Cumulative Timesteps: 1,105,023,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,094.08806
Policy Entropy: 3.79236
Value Function Loss: 0.04179

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.18427
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.45028

Collected Steps per Second: 22,820.62152
Overall Steps per Second: 10,837.64324

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.42400
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.61632

Cumulative Model Updates: 132,524
Cumulative Timesteps: 1,105,073,190

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1105073190...
Checkpoint 1105073190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.27052
Policy Entropy: 3.80185
Value Function Loss: 0.03897

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16395
Policy Update Magnitude: 0.61749
Value Function Update Magnitude: 0.47234

Collected Steps per Second: 23,012.71796
Overall Steps per Second: 10,669.48501

Timestep Collection Time: 2.17341
Timestep Consumption Time: 2.51435
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.68776

Cumulative Model Updates: 132,530
Cumulative Timesteps: 1,105,123,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,340.89187
Policy Entropy: 3.80594
Value Function Loss: 0.03584

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16574
Policy Update Magnitude: 0.61357
Value Function Update Magnitude: 0.38023

Collected Steps per Second: 22,819.62479
Overall Steps per Second: 10,837.03808

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61381

Cumulative Model Updates: 132,536
Cumulative Timesteps: 1,105,173,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1105173206...
Checkpoint 1105173206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,490.08521
Policy Entropy: 3.81840
Value Function Loss: 0.03549

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.20197
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.35132

Collected Steps per Second: 22,863.26620
Overall Steps per Second: 10,758.79001

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.46143
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.64922

Cumulative Model Updates: 132,542
Cumulative Timesteps: 1,105,223,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.12778
Policy Entropy: 3.84346
Value Function Loss: 0.03901

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.19969
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.33226

Collected Steps per Second: 23,096.18979
Overall Steps per Second: 10,926.13452

Timestep Collection Time: 2.16555
Timestep Consumption Time: 2.41210
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.57765

Cumulative Model Updates: 132,548
Cumulative Timesteps: 1,105,273,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1105273242...
Checkpoint 1105273242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.86945
Policy Entropy: 3.86379
Value Function Loss: 0.03687

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16823
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.23772

Collected Steps per Second: 23,111.74121
Overall Steps per Second: 10,775.25327

Timestep Collection Time: 2.16375
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.64100

Cumulative Model Updates: 132,554
Cumulative Timesteps: 1,105,323,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,549.86945
Policy Entropy: 3.82301
Value Function Loss: 0.03473

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.17890
Policy Update Magnitude: 0.43137
Value Function Update Magnitude: 0.19046

Collected Steps per Second: 22,488.49203
Overall Steps per Second: 10,707.83793

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.67060

Cumulative Model Updates: 132,560
Cumulative Timesteps: 1,105,373,262

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1105373262...
Checkpoint 1105373262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,099.36697
Policy Entropy: 3.77766
Value Function Loss: 0.03271

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.42078
Value Function Update Magnitude: 0.19973

Collected Steps per Second: 23,013.30774
Overall Steps per Second: 10,759.43090

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.64857

Cumulative Model Updates: 132,566
Cumulative Timesteps: 1,105,423,278

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,099.36697
Policy Entropy: 3.71519
Value Function Loss: 0.02892

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14450
Policy Update Magnitude: 0.42260
Value Function Update Magnitude: 0.27410

Collected Steps per Second: 22,779.68013
Overall Steps per Second: 10,857.67870

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.41145
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.60761

Cumulative Model Updates: 132,572
Cumulative Timesteps: 1,105,473,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1105473306...
Checkpoint 1105473306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,099.36697
Policy Entropy: 3.71324
Value Function Loss: 0.02575

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.43309
Value Function Update Magnitude: 0.26860

Collected Steps per Second: 22,978.89879
Overall Steps per Second: 10,773.23940

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.64206

Cumulative Model Updates: 132,578
Cumulative Timesteps: 1,105,523,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,099.36697
Policy Entropy: 3.71482
Value Function Loss: 0.02534

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.45061
Value Function Update Magnitude: 0.32268

Collected Steps per Second: 22,247.86355
Overall Steps per Second: 10,706.46710

Timestep Collection Time: 2.24759
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.67045

Cumulative Model Updates: 132,584
Cumulative Timesteps: 1,105,573,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1105573320...
Checkpoint 1105573320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,245.58261
Policy Entropy: 3.72415
Value Function Loss: 0.02646

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.49501
Value Function Update Magnitude: 0.37456

Collected Steps per Second: 21,073.24539
Overall Steps per Second: 10,356.32630

Timestep Collection Time: 2.37296
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.82855

Cumulative Model Updates: 132,590
Cumulative Timesteps: 1,105,623,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,047.40202
Policy Entropy: 3.73434
Value Function Loss: 0.02779

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.49548
Value Function Update Magnitude: 0.54712

Collected Steps per Second: 21,485.78410
Overall Steps per Second: 10,634.70024

Timestep Collection Time: 2.32833
Timestep Consumption Time: 2.37570
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.70403

Cumulative Model Updates: 132,596
Cumulative Timesteps: 1,105,673,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1105673352...
Checkpoint 1105673352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.70726
Policy Entropy: 3.75155
Value Function Loss: 0.02519

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.47761
Value Function Update Magnitude: 0.53497

Collected Steps per Second: 22,255.88122
Overall Steps per Second: 10,773.99209

Timestep Collection Time: 2.24705
Timestep Consumption Time: 2.39469
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.64173

Cumulative Model Updates: 132,602
Cumulative Timesteps: 1,105,723,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.65198
Policy Entropy: 3.75216
Value Function Loss: 0.02358

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.42106
Value Function Update Magnitude: 0.46804

Collected Steps per Second: 22,858.50269
Overall Steps per Second: 10,930.28273

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.38832
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.57683

Cumulative Model Updates: 132,608
Cumulative Timesteps: 1,105,773,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1105773388...
Checkpoint 1105773388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.65198
Policy Entropy: 3.74515
Value Function Loss: 0.02020

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.38735
Value Function Update Magnitude: 0.40400

Collected Steps per Second: 23,093.74485
Overall Steps per Second: 10,967.47587

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.39547
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.56203

Cumulative Model Updates: 132,614
Cumulative Timesteps: 1,105,823,422

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,056.20775
Policy Entropy: 3.74481
Value Function Loss: 0.02044

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.36372
Value Function Update Magnitude: 0.34490

Collected Steps per Second: 22,886.28234
Overall Steps per Second: 10,743.07454

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.46955
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.65435

Cumulative Model Updates: 132,620
Cumulative Timesteps: 1,105,873,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1105873424...
Checkpoint 1105873424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,193.46843
Policy Entropy: 3.76250
Value Function Loss: 0.01856

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.33993
Value Function Update Magnitude: 0.28196

Collected Steps per Second: 23,008.56020
Overall Steps per Second: 10,910.73572

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.58301

Cumulative Model Updates: 132,626
Cumulative Timesteps: 1,105,923,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,252.12118
Policy Entropy: 3.76306
Value Function Loss: 0.02277

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.31741
Value Function Update Magnitude: 0.26353

Collected Steps per Second: 22,986.76156
Overall Steps per Second: 10,893.32922

Timestep Collection Time: 2.17604
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.59180

Cumulative Model Updates: 132,632
Cumulative Timesteps: 1,105,973,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1105973448...
Checkpoint 1105973448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,536.89418
Policy Entropy: 3.75437
Value Function Loss: 0.02084

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.29809
Value Function Update Magnitude: 0.21737

Collected Steps per Second: 22,915.40227
Overall Steps per Second: 10,727.52488

Timestep Collection Time: 2.18220
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.66147

Cumulative Model Updates: 132,638
Cumulative Timesteps: 1,106,023,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,691.57050
Policy Entropy: 3.74637
Value Function Loss: 0.01852

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.30592
Value Function Update Magnitude: 0.24947

Collected Steps per Second: 22,976.78330
Overall Steps per Second: 10,799.12325

Timestep Collection Time: 2.17698
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.63186

Cumulative Model Updates: 132,644
Cumulative Timesteps: 1,106,073,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1106073474...
Checkpoint 1106073474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,691.57050
Policy Entropy: 3.74455
Value Function Loss: 0.01737

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.34171
Value Function Update Magnitude: 0.33810

Collected Steps per Second: 23,119.74431
Overall Steps per Second: 10,767.01388

Timestep Collection Time: 2.16300
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.64456

Cumulative Model Updates: 132,650
Cumulative Timesteps: 1,106,123,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,691.57050
Policy Entropy: 3.74857
Value Function Loss: 0.01828

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.33695
Value Function Update Magnitude: 0.28137

Collected Steps per Second: 23,046.61161
Overall Steps per Second: 10,770.71438

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.47280
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.64240

Cumulative Model Updates: 132,656
Cumulative Timesteps: 1,106,173,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1106173484...
Checkpoint 1106173484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,955.83925
Policy Entropy: 3.74670
Value Function Loss: 0.01990

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.33926
Value Function Update Magnitude: 0.29786

Collected Steps per Second: 22,853.10127
Overall Steps per Second: 10,719.58625

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.47736
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.66604

Cumulative Model Updates: 132,662
Cumulative Timesteps: 1,106,223,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,914.62607
Policy Entropy: 3.74678
Value Function Loss: 0.01909

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13908
Policy Update Magnitude: 0.36500
Value Function Update Magnitude: 0.44032

Collected Steps per Second: 23,208.77247
Overall Steps per Second: 10,799.59908

Timestep Collection Time: 2.15436
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.62980

Cumulative Model Updates: 132,668
Cumulative Timesteps: 1,106,273,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1106273502...
Checkpoint 1106273502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,004.43457
Policy Entropy: 3.74352
Value Function Loss: 0.02052

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.39519
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 22,175.05783
Overall Steps per Second: 10,674.66089

Timestep Collection Time: 2.25533
Timestep Consumption Time: 2.42979
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.68511

Cumulative Model Updates: 132,674
Cumulative Timesteps: 1,106,323,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,428.78337
Policy Entropy: 3.75179
Value Function Loss: 0.02050

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.42392
Value Function Update Magnitude: 0.68972

Collected Steps per Second: 23,088.73883
Overall Steps per Second: 10,894.77323

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.59046

Cumulative Model Updates: 132,680
Cumulative Timesteps: 1,106,373,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1106373526...
Checkpoint 1106373526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,875.63855
Policy Entropy: 3.76284
Value Function Loss: 0.02170

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.42695
Value Function Update Magnitude: 0.63146

Collected Steps per Second: 22,915.65986
Overall Steps per Second: 10,693.76929

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.67674

Cumulative Model Updates: 132,686
Cumulative Timesteps: 1,106,423,538

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,471.89267
Policy Entropy: 3.78228
Value Function Loss: 0.02102

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.43334
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 23,165.15154
Overall Steps per Second: 10,858.38044

Timestep Collection Time: 2.15902
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.60603

Cumulative Model Updates: 132,692
Cumulative Timesteps: 1,106,473,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1106473552...
Checkpoint 1106473552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,372.89036
Policy Entropy: 3.78729
Value Function Loss: 0.02069

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.42243
Value Function Update Magnitude: 0.56852

Collected Steps per Second: 23,165.53233
Overall Steps per Second: 10,781.31385

Timestep Collection Time: 2.15847
Timestep Consumption Time: 2.47937
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.63784

Cumulative Model Updates: 132,698
Cumulative Timesteps: 1,106,523,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,163.26860
Policy Entropy: 3.78896
Value Function Loss: 0.01927

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.12207
Policy Update Magnitude: 0.42188
Value Function Update Magnitude: 0.54846

Collected Steps per Second: 22,741.46894
Overall Steps per Second: 10,766.03043

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.64479

Cumulative Model Updates: 132,704
Cumulative Timesteps: 1,106,573,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1106573560...
Checkpoint 1106573560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.76600
Value Function Loss: 0.01754

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.42271
Value Function Update Magnitude: 0.54987

Collected Steps per Second: 23,054.61903
Overall Steps per Second: 10,772.15737

Timestep Collection Time: 2.16963
Timestep Consumption Time: 2.47382
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.64345

Cumulative Model Updates: 132,710
Cumulative Timesteps: 1,106,623,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.73914
Value Function Loss: 0.01500

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.40032
Value Function Update Magnitude: 0.47120

Collected Steps per Second: 22,796.64841
Overall Steps per Second: 10,782.21164

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.44435
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.63801

Cumulative Model Updates: 132,716
Cumulative Timesteps: 1,106,673,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1106673588...
Checkpoint 1106673588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.73521
Value Function Loss: 0.01341

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05130
Policy Update Magnitude: 0.43142
Value Function Update Magnitude: 0.39747

Collected Steps per Second: 23,207.94618
Overall Steps per Second: 10,790.55822

Timestep Collection Time: 2.15521
Timestep Consumption Time: 2.48014
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.63535

Cumulative Model Updates: 132,722
Cumulative Timesteps: 1,106,723,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.74189
Value Function Loss: 0.01170

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06278
Policy Update Magnitude: 0.44144
Value Function Update Magnitude: 0.33576

Collected Steps per Second: 23,193.83857
Overall Steps per Second: 10,738.28418

Timestep Collection Time: 2.15738
Timestep Consumption Time: 2.50239
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.65978

Cumulative Model Updates: 132,728
Cumulative Timesteps: 1,106,773,644

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1106773644...
Checkpoint 1106773644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.76305
Value Function Loss: 0.01113

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06786
Policy Update Magnitude: 0.42646
Value Function Update Magnitude: 0.34348

Collected Steps per Second: 22,823.38530
Overall Steps per Second: 10,698.92373

Timestep Collection Time: 2.19258
Timestep Consumption Time: 2.48472
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.67729

Cumulative Model Updates: 132,734
Cumulative Timesteps: 1,106,823,686

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.75695
Value Function Loss: 0.01085

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.35368
Value Function Update Magnitude: 0.35089

Collected Steps per Second: 23,122.87338
Overall Steps per Second: 10,826.96692

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.45603
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.61865

Cumulative Model Updates: 132,740
Cumulative Timesteps: 1,106,873,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1106873692...
Checkpoint 1106873692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.75523
Value Function Loss: 0.01151

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.31868
Value Function Update Magnitude: 0.36110

Collected Steps per Second: 23,035.69141
Overall Steps per Second: 10,751.65021

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.65138

Cumulative Model Updates: 132,746
Cumulative Timesteps: 1,106,923,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.72625
Value Function Loss: 0.01368

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.33109
Value Function Update Magnitude: 0.32380

Collected Steps per Second: 21,925.94530
Overall Steps per Second: 10,788.13137

Timestep Collection Time: 2.28159
Timestep Consumption Time: 2.35554
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.63713

Cumulative Model Updates: 132,752
Cumulative Timesteps: 1,106,973,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1106973728...
Checkpoint 1106973728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,637.53493
Policy Entropy: 3.71900
Value Function Loss: 0.01964

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.39756
Value Function Update Magnitude: 0.44290

Collected Steps per Second: 22,156.98767
Overall Steps per Second: 10,677.14909

Timestep Collection Time: 2.25726
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68421

Cumulative Model Updates: 132,758
Cumulative Timesteps: 1,107,023,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,434.71486
Policy Entropy: 3.73170
Value Function Loss: 0.02147

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14167
Policy Update Magnitude: 0.46343
Value Function Update Magnitude: 0.51337

Collected Steps per Second: 22,304.73725
Overall Steps per Second: 10,876.48233

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.35672
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.59965

Cumulative Model Updates: 132,764
Cumulative Timesteps: 1,107,073,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1107073770...
Checkpoint 1107073770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,933.50435
Policy Entropy: 3.73974
Value Function Loss: 0.02543

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.48590
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 22,346.86301
Overall Steps per Second: 10,676.56360

Timestep Collection Time: 2.23781
Timestep Consumption Time: 2.44610
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.68390

Cumulative Model Updates: 132,770
Cumulative Timesteps: 1,107,123,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,983.88302
Policy Entropy: 3.76283
Value Function Loss: 0.02486

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.46959
Value Function Update Magnitude: 0.54204

Collected Steps per Second: 22,699.18567
Overall Steps per Second: 10,867.05267

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.39844
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.60125

Cumulative Model Updates: 132,776
Cumulative Timesteps: 1,107,173,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1107173780...
Checkpoint 1107173780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,233.61685
Policy Entropy: 3.73348
Value Function Loss: 0.02808

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.63319

Collected Steps per Second: 22,801.60624
Overall Steps per Second: 10,706.98635

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.47722
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.67022

Cumulative Model Updates: 132,782
Cumulative Timesteps: 1,107,223,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,091.15995
Policy Entropy: 3.74378
Value Function Loss: 0.02462

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.82268

Collected Steps per Second: 22,965.31914
Overall Steps per Second: 10,833.99099

Timestep Collection Time: 2.17833
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61750

Cumulative Model Updates: 132,788
Cumulative Timesteps: 1,107,273,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1107273810...
Checkpoint 1107273810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,281.86027
Policy Entropy: 3.73222
Value Function Loss: 0.02382

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.53753
Value Function Update Magnitude: 0.85376

Collected Steps per Second: 23,215.49293
Overall Steps per Second: 10,745.53931

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.65402

Cumulative Model Updates: 132,794
Cumulative Timesteps: 1,107,323,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,284.20714
Policy Entropy: 3.76782
Value Function Loss: 0.02240

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.50822
Value Function Update Magnitude: 0.80370

Collected Steps per Second: 23,087.25920
Overall Steps per Second: 10,905.57157

Timestep Collection Time: 2.16708
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.58775

Cumulative Model Updates: 132,800
Cumulative Timesteps: 1,107,373,852

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1107373852...
Checkpoint 1107373852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,834.09802
Policy Entropy: 3.76881
Value Function Loss: 0.02155

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.47319
Value Function Update Magnitude: 0.83180

Collected Steps per Second: 23,071.76216
Overall Steps per Second: 10,815.93493

Timestep Collection Time: 2.16732
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.62318

Cumulative Model Updates: 132,806
Cumulative Timesteps: 1,107,423,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,357.39516
Policy Entropy: 3.78426
Value Function Loss: 0.02043

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.43880
Value Function Update Magnitude: 0.81736

Collected Steps per Second: 22,986.77571
Overall Steps per Second: 10,713.33895

Timestep Collection Time: 2.17656
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.67007

Cumulative Model Updates: 132,812
Cumulative Timesteps: 1,107,473,888

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1107473888...
Checkpoint 1107473888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,174.75697
Policy Entropy: 3.74719
Value Function Loss: 0.02346

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.47755
Value Function Update Magnitude: 0.81311

Collected Steps per Second: 22,849.06827
Overall Steps per Second: 10,669.74135

Timestep Collection Time: 2.18959
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68896

Cumulative Model Updates: 132,818
Cumulative Timesteps: 1,107,523,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,114.14807
Policy Entropy: 3.74547
Value Function Loss: 0.02546

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.52634
Value Function Update Magnitude: 0.83328

Collected Steps per Second: 22,920.96137
Overall Steps per Second: 10,903.57942

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.40463
PPO Batch Consumption Time: 0.27647
Total Iteration Time: 4.58638

Cumulative Model Updates: 132,824
Cumulative Timesteps: 1,107,573,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1107573926...
Checkpoint 1107573926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,018.97576
Policy Entropy: 3.72489
Value Function Loss: 0.02715

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.52381
Value Function Update Magnitude: 0.79850

Collected Steps per Second: 22,726.15744
Overall Steps per Second: 10,665.32469

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.68959

Cumulative Model Updates: 132,830
Cumulative Timesteps: 1,107,623,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,336.18697
Policy Entropy: 3.73626
Value Function Loss: 0.02551

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.51297
Value Function Update Magnitude: 0.65521

Collected Steps per Second: 23,146.00633
Overall Steps per Second: 10,832.13080

Timestep Collection Time: 2.16046
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.61645

Cumulative Model Updates: 132,836
Cumulative Timesteps: 1,107,673,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1107673948...
Checkpoint 1107673948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,736.73033
Policy Entropy: 3.73901
Value Function Loss: 0.02580

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.52449
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 22,575.31912
Overall Steps per Second: 10,619.29605

Timestep Collection Time: 2.21499
Timestep Consumption Time: 2.49380
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.70879

Cumulative Model Updates: 132,842
Cumulative Timesteps: 1,107,723,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,419.19972
Policy Entropy: 3.77207
Value Function Loss: 0.02433

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.51803
Value Function Update Magnitude: 0.60104

Collected Steps per Second: 22,052.64647
Overall Steps per Second: 10,858.86813

Timestep Collection Time: 2.26812
Timestep Consumption Time: 2.33807
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.60619

Cumulative Model Updates: 132,848
Cumulative Timesteps: 1,107,773,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1107773970...
Checkpoint 1107773970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,555.11855
Policy Entropy: 3.76268
Value Function Loss: 0.02340

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.51707
Value Function Update Magnitude: 0.72930

Collected Steps per Second: 22,248.60900
Overall Steps per Second: 10,713.93016

Timestep Collection Time: 2.24877
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.66981

Cumulative Model Updates: 132,854
Cumulative Timesteps: 1,107,824,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,564.93203
Policy Entropy: 3.76059
Value Function Loss: 0.02086

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.48896
Value Function Update Magnitude: 0.75697

Collected Steps per Second: 22,114.61967
Overall Steps per Second: 10,845.91409

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.35040
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.61261

Cumulative Model Updates: 132,860
Cumulative Timesteps: 1,107,874,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1107874030...
Checkpoint 1107874030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,054.75574
Policy Entropy: 3.75084
Value Function Loss: 0.02115

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.48674
Value Function Update Magnitude: 0.81840

Collected Steps per Second: 22,016.13663
Overall Steps per Second: 10,721.35833

Timestep Collection Time: 2.27152
Timestep Consumption Time: 2.39301
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.66452

Cumulative Model Updates: 132,866
Cumulative Timesteps: 1,107,924,040

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,043.29290
Policy Entropy: 3.76624
Value Function Loss: 0.02159

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.51029
Value Function Update Magnitude: 0.81119

Collected Steps per Second: 22,958.55458
Overall Steps per Second: 10,871.88274

Timestep Collection Time: 2.17880
Timestep Consumption Time: 2.42225
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.60104

Cumulative Model Updates: 132,872
Cumulative Timesteps: 1,107,974,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1107974062...
Checkpoint 1107974062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,532.14757
Policy Entropy: 3.76622
Value Function Loss: 0.02440

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.51936
Value Function Update Magnitude: 0.84748

Collected Steps per Second: 22,993.81280
Overall Steps per Second: 10,829.79958

Timestep Collection Time: 2.17667
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.62151

Cumulative Model Updates: 132,878
Cumulative Timesteps: 1,108,024,112

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,547.05884
Policy Entropy: 3.76261
Value Function Loss: 0.02507

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.51503
Value Function Update Magnitude: 0.90151

Collected Steps per Second: 22,896.30577
Overall Steps per Second: 10,708.85256

Timestep Collection Time: 2.18446
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.67053

Cumulative Model Updates: 132,884
Cumulative Timesteps: 1,108,074,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1108074128...
Checkpoint 1108074128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,547.05884
Policy Entropy: 3.75467
Value Function Loss: 0.02356

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.89213

Collected Steps per Second: 22,525.06379
Overall Steps per Second: 10,627.73823

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.70730

Cumulative Model Updates: 132,890
Cumulative Timesteps: 1,108,124,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,499.33784
Policy Entropy: 3.75414
Value Function Loss: 0.02192

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13926
Policy Update Magnitude: 0.51012
Value Function Update Magnitude: 0.80355

Collected Steps per Second: 22,833.98399
Overall Steps per Second: 10,839.16108

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.61493

Cumulative Model Updates: 132,896
Cumulative Timesteps: 1,108,174,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1108174178...
Checkpoint 1108174178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,936.68658
Policy Entropy: 3.74050
Value Function Loss: 0.01797

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.46120
Value Function Update Magnitude: 0.70474

Collected Steps per Second: 22,853.33277
Overall Steps per Second: 10,737.10296

Timestep Collection Time: 2.18848
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.65805

Cumulative Model Updates: 132,902
Cumulative Timesteps: 1,108,224,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,266.31054
Policy Entropy: 3.75005
Value Function Loss: 0.01842

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.44362
Value Function Update Magnitude: 0.68780

Collected Steps per Second: 22,783.99333
Overall Steps per Second: 10,829.85226

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.42293
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.61798

Cumulative Model Updates: 132,908
Cumulative Timesteps: 1,108,274,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1108274204...
Checkpoint 1108274204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,407.69381
Policy Entropy: 3.74155
Value Function Loss: 0.01983

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.47411
Value Function Update Magnitude: 0.74181

Collected Steps per Second: 22,685.36191
Overall Steps per Second: 10,714.01817

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.66809

Cumulative Model Updates: 132,914
Cumulative Timesteps: 1,108,324,218

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,316.39608
Policy Entropy: 3.76014
Value Function Loss: 0.01882

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.48447
Value Function Update Magnitude: 0.76934

Collected Steps per Second: 22,734.96689
Overall Steps per Second: 10,852.11137

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60961

Cumulative Model Updates: 132,920
Cumulative Timesteps: 1,108,374,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1108374242...
Checkpoint 1108374242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,746.37354
Policy Entropy: 3.74461
Value Function Loss: 0.01975

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.47093
Value Function Update Magnitude: 0.74120

Collected Steps per Second: 22,077.83100
Overall Steps per Second: 10,696.96746

Timestep Collection Time: 2.26571
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.67628

Cumulative Model Updates: 132,926
Cumulative Timesteps: 1,108,424,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,473.10076
Policy Entropy: 3.73281
Value Function Loss: 0.01928

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.44999
Value Function Update Magnitude: 0.73793

Collected Steps per Second: 21,982.05395
Overall Steps per Second: 10,833.93947

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.34064
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61531

Cumulative Model Updates: 132,932
Cumulative Timesteps: 1,108,474,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1108474266...
Checkpoint 1108474266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,965.21891
Policy Entropy: 3.70882
Value Function Loss: 0.02592

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 22,054.23226
Overall Steps per Second: 10,703.54958

Timestep Collection Time: 2.26741
Timestep Consumption Time: 2.40450
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67191

Cumulative Model Updates: 132,938
Cumulative Timesteps: 1,108,524,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,980.06896
Policy Entropy: 3.74222
Value Function Loss: 0.02562

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 21,903.47132
Overall Steps per Second: 10,802.17759

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.34605
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.62888

Cumulative Model Updates: 132,944
Cumulative Timesteps: 1,108,574,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1108574274...
Checkpoint 1108574274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,945.09978
Policy Entropy: 3.74402
Value Function Loss: 0.02993

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.62831

Collected Steps per Second: 22,017.88524
Overall Steps per Second: 10,709.96033

Timestep Collection Time: 2.27288
Timestep Consumption Time: 2.39978
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.67266

Cumulative Model Updates: 132,950
Cumulative Timesteps: 1,108,624,318

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,650.61631
Policy Entropy: 3.76271
Value Function Loss: 0.02387

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.62927

Collected Steps per Second: 22,729.81487
Overall Steps per Second: 10,864.78498

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.40371
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60479

Cumulative Model Updates: 132,956
Cumulative Timesteps: 1,108,674,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1108674348...
Checkpoint 1108674348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,073.32132
Policy Entropy: 3.74488
Value Function Loss: 0.02415

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.65732

Collected Steps per Second: 22,812.18949
Overall Steps per Second: 10,717.63968

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.47359
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.66558

Cumulative Model Updates: 132,962
Cumulative Timesteps: 1,108,724,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,209.72231
Policy Entropy: 3.76834
Value Function Loss: 0.02189

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.78099

Collected Steps per Second: 23,017.08710
Overall Steps per Second: 10,879.92390

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.59801

Cumulative Model Updates: 132,968
Cumulative Timesteps: 1,108,774,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1108774378...
Checkpoint 1108774378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.77333
Policy Entropy: 3.75568
Value Function Loss: 0.02325

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.87790

Collected Steps per Second: 22,702.19383
Overall Steps per Second: 10,679.17699

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.48027
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.68332

Cumulative Model Updates: 132,974
Cumulative Timesteps: 1,108,824,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,122.27865
Policy Entropy: 3.76288
Value Function Loss: 0.02370

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.76767

Collected Steps per Second: 23,039.53935
Overall Steps per Second: 10,885.88973

Timestep Collection Time: 2.17044
Timestep Consumption Time: 2.42321
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.59365

Cumulative Model Updates: 132,980
Cumulative Timesteps: 1,108,874,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1108874398...
Checkpoint 1108874398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242,977.27857
Policy Entropy: 3.76839
Value Function Loss: 0.02591

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.62038

Collected Steps per Second: 22,576.37639
Overall Steps per Second: 10,648.23924

Timestep Collection Time: 2.21541
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69711

Cumulative Model Updates: 132,986
Cumulative Timesteps: 1,108,924,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,411.87274
Policy Entropy: 3.76432
Value Function Loss: 0.02747

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 22,897.67798
Overall Steps per Second: 10,862.97203

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.41975
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.60390

Cumulative Model Updates: 132,992
Cumulative Timesteps: 1,108,974,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1108974426...
Checkpoint 1108974426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,411.87274
Policy Entropy: 3.75382
Value Function Loss: 0.02672

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.57496

Collected Steps per Second: 22,529.47898
Overall Steps per Second: 10,700.50058

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.45346
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.67287

Cumulative Model Updates: 132,998
Cumulative Timesteps: 1,109,024,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,411.87274
Policy Entropy: 3.73242
Value Function Loss: 0.02344

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.52011
Value Function Update Magnitude: 0.53858

Collected Steps per Second: 23,078.21403
Overall Steps per Second: 10,907.46825

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.58530

Cumulative Model Updates: 133,004
Cumulative Timesteps: 1,109,074,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1109074442...
Checkpoint 1109074442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,215.21762
Policy Entropy: 3.73169
Value Function Loss: 0.02046

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.46990
Value Function Update Magnitude: 0.50184

Collected Steps per Second: 22,193.74519
Overall Steps per Second: 10,724.60339

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.41054
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.66460

Cumulative Model Updates: 133,010
Cumulative Timesteps: 1,109,124,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,070.30235
Policy Entropy: 3.74375
Value Function Loss: 0.01707

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.42480
Value Function Update Magnitude: 0.51205

Collected Steps per Second: 22,560.28067
Overall Steps per Second: 10,818.97294

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.62373

Cumulative Model Updates: 133,016
Cumulative Timesteps: 1,109,174,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1109174492...
Checkpoint 1109174492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,607.10667
Policy Entropy: 3.73332
Value Function Loss: 0.01766

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.39325
Value Function Update Magnitude: 0.56165

Collected Steps per Second: 22,022.60169
Overall Steps per Second: 10,674.50157

Timestep Collection Time: 2.27221
Timestep Consumption Time: 2.41560
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.68781

Cumulative Model Updates: 133,022
Cumulative Timesteps: 1,109,224,532

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,614.09932
Policy Entropy: 3.76260
Value Function Loss: 0.01727

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.40113
Value Function Update Magnitude: 0.58608

Collected Steps per Second: 22,394.10262
Overall Steps per Second: 10,792.78911

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.40018
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.63309

Cumulative Model Updates: 133,028
Cumulative Timesteps: 1,109,274,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1109274536...
Checkpoint 1109274536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,286.36306
Policy Entropy: 3.75638
Value Function Loss: 0.01651

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.41332
Value Function Update Magnitude: 0.63816

Collected Steps per Second: 22,898.32047
Overall Steps per Second: 10,703.93098

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67398

Cumulative Model Updates: 133,034
Cumulative Timesteps: 1,109,324,566

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,609.65644
Policy Entropy: 3.75631
Value Function Loss: 0.01508

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.40451
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 22,873.86409
Overall Steps per Second: 10,918.90194

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.39465
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.58178

Cumulative Model Updates: 133,040
Cumulative Timesteps: 1,109,374,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1109374594...
Checkpoint 1109374594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,699.63969
Policy Entropy: 3.73682
Value Function Loss: 0.01811

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.41823
Value Function Update Magnitude: 0.65136

Collected Steps per Second: 22,646.21359
Overall Steps per Second: 10,657.18785

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.48439
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.69280

Cumulative Model Updates: 133,046
Cumulative Timesteps: 1,109,424,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,079.13233
Policy Entropy: 3.73857
Value Function Loss: 0.02286

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.45797
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 23,011.68036
Overall Steps per Second: 10,871.09639

Timestep Collection Time: 2.17281
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59935

Cumulative Model Updates: 133,052
Cumulative Timesteps: 1,109,474,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1109474606...
Checkpoint 1109474606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,398.26419
Policy Entropy: 3.74818
Value Function Loss: 0.02726

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,792.03422
Overall Steps per Second: 10,638.84372

Timestep Collection Time: 2.19428
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70089

Cumulative Model Updates: 133,058
Cumulative Timesteps: 1,109,524,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,659.86229
Policy Entropy: 3.76511
Value Function Loss: 0.02939

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.57332
Value Function Update Magnitude: 0.75498

Collected Steps per Second: 22,996.59088
Overall Steps per Second: 10,868.79706

Timestep Collection Time: 2.17484
Timestep Consumption Time: 2.42677
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.60161

Cumulative Model Updates: 133,064
Cumulative Timesteps: 1,109,574,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1109574632...
Checkpoint 1109574632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,713.02597
Policy Entropy: 3.76287
Value Function Loss: 0.03125

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.61815
Value Function Update Magnitude: 0.67711

Collected Steps per Second: 22,494.00998
Overall Steps per Second: 10,731.45860

Timestep Collection Time: 2.22361
Timestep Consumption Time: 2.43726
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.66088

Cumulative Model Updates: 133,070
Cumulative Timesteps: 1,109,624,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,150.71927
Policy Entropy: 3.77787
Value Function Loss: 0.03077

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.70366
Value Function Update Magnitude: 0.66763

Collected Steps per Second: 22,943.70138
Overall Steps per Second: 10,848.81561

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61083

Cumulative Model Updates: 133,076
Cumulative Timesteps: 1,109,674,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1109674672...
Checkpoint 1109674672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,829.62325
Policy Entropy: 3.77732
Value Function Loss: 0.02932

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.69559
Value Function Update Magnitude: 0.70962

Collected Steps per Second: 23,048.03858
Overall Steps per Second: 10,735.63002

Timestep Collection Time: 2.16973
Timestep Consumption Time: 2.48840
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.65813

Cumulative Model Updates: 133,082
Cumulative Timesteps: 1,109,724,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,385.70234
Policy Entropy: 3.76990
Value Function Loss: 0.02600

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.61947
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 23,357.19738
Overall Steps per Second: 10,870.17753

Timestep Collection Time: 2.14135
Timestep Consumption Time: 2.45986
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.60121

Cumulative Model Updates: 133,088
Cumulative Timesteps: 1,109,774,696

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1109774696...
Checkpoint 1109774696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,071.70748
Policy Entropy: 3.76073
Value Function Loss: 0.02147

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.68305

Collected Steps per Second: 22,907.28890
Overall Steps per Second: 10,658.46451

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69392

Cumulative Model Updates: 133,094
Cumulative Timesteps: 1,109,824,726

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,739.73855
Policy Entropy: 3.75111
Value Function Loss: 0.02341

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.55014
Value Function Update Magnitude: 0.58249

Collected Steps per Second: 23,108.01883
Overall Steps per Second: 10,861.04632

Timestep Collection Time: 2.16488
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.60600

Cumulative Model Updates: 133,100
Cumulative Timesteps: 1,109,874,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1109874752...
Checkpoint 1109874752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,233.55224
Policy Entropy: 3.75540
Value Function Loss: 0.02072

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.51576
Value Function Update Magnitude: 0.52133

Collected Steps per Second: 22,804.30896
Overall Steps per Second: 10,644.04768

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.69859

Cumulative Model Updates: 133,106
Cumulative Timesteps: 1,109,924,764

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,823.32028
Policy Entropy: 3.74241
Value Function Loss: 0.02011

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.49022
Value Function Update Magnitude: 0.52717

Collected Steps per Second: 23,106.48113
Overall Steps per Second: 10,886.92775

Timestep Collection Time: 2.16398
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.59285

Cumulative Model Updates: 133,112
Cumulative Timesteps: 1,109,974,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1109974766...
Checkpoint 1109974766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,097.44372
Policy Entropy: 3.72171
Value Function Loss: 0.02039

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.48602
Value Function Update Magnitude: 0.47933

Collected Steps per Second: 22,575.43652
Overall Steps per Second: 10,668.26039

Timestep Collection Time: 2.21586
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.68905

Cumulative Model Updates: 133,118
Cumulative Timesteps: 1,110,024,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,721.18426
Policy Entropy: 3.72649
Value Function Loss: 0.02073

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.50460
Value Function Update Magnitude: 0.48225

Collected Steps per Second: 22,840.81299
Overall Steps per Second: 10,854.93332

Timestep Collection Time: 2.18985
Timestep Consumption Time: 2.41801
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.60786

Cumulative Model Updates: 133,124
Cumulative Timesteps: 1,110,074,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1110074808...
Checkpoint 1110074808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,500.46698
Policy Entropy: 3.72546
Value Function Loss: 0.02278

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.46342

Collected Steps per Second: 22,854.50649
Overall Steps per Second: 10,676.89583

Timestep Collection Time: 2.19003
Timestep Consumption Time: 2.49785
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68788

Cumulative Model Updates: 133,130
Cumulative Timesteps: 1,110,124,860

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,145.39350
Policy Entropy: 3.73740
Value Function Loss: 0.02658

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.59285
Value Function Update Magnitude: 0.52692

Collected Steps per Second: 22,928.57262
Overall Steps per Second: 10,852.05423

Timestep Collection Time: 2.18086
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60779

Cumulative Model Updates: 133,136
Cumulative Timesteps: 1,110,174,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1110174864...
Checkpoint 1110174864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,913.41670
Policy Entropy: 3.75536
Value Function Loss: 0.02768

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.64856
Value Function Update Magnitude: 0.69129

Collected Steps per Second: 22,445.78578
Overall Steps per Second: 10,784.51726

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.41013
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.63906

Cumulative Model Updates: 133,142
Cumulative Timesteps: 1,110,224,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.09979
Policy Entropy: 3.76910
Value Function Loss: 0.02485

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.64264
Value Function Update Magnitude: 0.82286

Collected Steps per Second: 23,017.74645
Overall Steps per Second: 10,800.41445

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.63260

Cumulative Model Updates: 133,148
Cumulative Timesteps: 1,110,274,928

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1110274928...
Checkpoint 1110274928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,709.39499
Policy Entropy: 3.75987
Value Function Loss: 0.02370

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12043
Policy Update Magnitude: 0.59262
Value Function Update Magnitude: 0.82009

Collected Steps per Second: 22,787.66557
Overall Steps per Second: 10,685.96232

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.67941

Cumulative Model Updates: 133,154
Cumulative Timesteps: 1,110,324,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,383.32599
Policy Entropy: 3.73433
Value Function Loss: 0.02427

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.73591

Collected Steps per Second: 23,105.37881
Overall Steps per Second: 10,867.52441

Timestep Collection Time: 2.16417
Timestep Consumption Time: 2.43706
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.60123

Cumulative Model Updates: 133,160
Cumulative Timesteps: 1,110,374,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1110374936...
Checkpoint 1110374936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,019.79426
Policy Entropy: 3.73617
Value Function Loss: 0.02755

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.61295

Collected Steps per Second: 22,302.31000
Overall Steps per Second: 10,733.02736

Timestep Collection Time: 2.24282
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.66038

Cumulative Model Updates: 133,166
Cumulative Timesteps: 1,110,424,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,841.69180
Policy Entropy: 3.75161
Value Function Loss: 0.02684

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.53592

Collected Steps per Second: 22,822.76203
Overall Steps per Second: 10,710.22438

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.47824
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.66956

Cumulative Model Updates: 133,172
Cumulative Timesteps: 1,110,474,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1110474968...
Checkpoint 1110474968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,291.72652
Policy Entropy: 3.74581
Value Function Loss: 0.02524

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.53773
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 22,614.53014
Overall Steps per Second: 10,839.18328

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.61437

Cumulative Model Updates: 133,178
Cumulative Timesteps: 1,110,524,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.99630
Policy Entropy: 3.73825
Value Function Loss: 0.02129

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.52982
Value Function Update Magnitude: 0.54435

Collected Steps per Second: 22,931.37658
Overall Steps per Second: 10,870.26530

Timestep Collection Time: 2.18147
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.60191

Cumulative Model Updates: 133,184
Cumulative Timesteps: 1,110,575,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1110575008...
Checkpoint 1110575008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427.93423
Policy Entropy: 3.72334
Value Function Loss: 0.02162

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.50153
Value Function Update Magnitude: 0.52463

Collected Steps per Second: 22,582.81241
Overall Steps per Second: 10,625.93371

Timestep Collection Time: 2.21434
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.70603

Cumulative Model Updates: 133,190
Cumulative Timesteps: 1,110,625,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.69214
Policy Entropy: 3.72933
Value Function Loss: 0.01935

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.49867

Collected Steps per Second: 22,722.67758
Overall Steps per Second: 10,824.59444

Timestep Collection Time: 2.20044
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.61911

Cumulative Model Updates: 133,196
Cumulative Timesteps: 1,110,675,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1110675014...
Checkpoint 1110675014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.69214
Policy Entropy: 3.72273
Value Function Loss: 0.01905

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.50452
Value Function Update Magnitude: 0.44611

Collected Steps per Second: 22,397.42050
Overall Steps per Second: 10,758.81851

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.64884

Cumulative Model Updates: 133,202
Cumulative Timesteps: 1,110,725,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.69214
Policy Entropy: 3.72975
Value Function Loss: 0.01896

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.48405
Value Function Update Magnitude: 0.44137

Collected Steps per Second: 22,500.18819
Overall Steps per Second: 10,885.21178

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.37147
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.59394

Cumulative Model Updates: 133,208
Cumulative Timesteps: 1,110,775,036

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1110775036...
Checkpoint 1110775036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,879.69214
Policy Entropy: 3.72675
Value Function Loss: 0.01920

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.46912
Value Function Update Magnitude: 0.52514

Collected Steps per Second: 21,581.02957
Overall Steps per Second: 10,622.57542

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.39125
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.70922

Cumulative Model Updates: 133,214
Cumulative Timesteps: 1,110,825,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,987.29403
Policy Entropy: 3.73036
Value Function Loss: 0.01988

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.45885
Value Function Update Magnitude: 0.48681

Collected Steps per Second: 22,288.65339
Overall Steps per Second: 10,650.85898

Timestep Collection Time: 2.24473
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.69746

Cumulative Model Updates: 133,220
Cumulative Timesteps: 1,110,875,092

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1110875092...
Checkpoint 1110875092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,963.83096
Policy Entropy: 3.72935
Value Function Loss: 0.02131

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.44452
Value Function Update Magnitude: 0.46792

Collected Steps per Second: 22,476.07973
Overall Steps per Second: 10,815.01458

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.39938
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.62468

Cumulative Model Updates: 133,226
Cumulative Timesteps: 1,110,925,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,444.49369
Policy Entropy: 3.73409
Value Function Loss: 0.01947

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.48464
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 22,812.08713
Overall Steps per Second: 10,909.28857

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.58453

Cumulative Model Updates: 133,232
Cumulative Timesteps: 1,110,975,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1110975122...
Checkpoint 1110975122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,444.49369
Policy Entropy: 3.71878
Value Function Loss: 0.02176

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.52154
Value Function Update Magnitude: 0.65005

Collected Steps per Second: 22,746.04687
Overall Steps per Second: 10,729.85246

Timestep Collection Time: 2.19862
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.66083

Cumulative Model Updates: 133,238
Cumulative Timesteps: 1,111,025,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,638.20374
Policy Entropy: 3.73568
Value Function Loss: 0.02239

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.72131

Collected Steps per Second: 22,942.34680
Overall Steps per Second: 10,839.94530

Timestep Collection Time: 2.17938
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.61257

Cumulative Model Updates: 133,244
Cumulative Timesteps: 1,111,075,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1111075132...
Checkpoint 1111075132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,594.27781
Policy Entropy: 3.74192
Value Function Loss: 0.02679

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.59430
Value Function Update Magnitude: 0.70892

Collected Steps per Second: 22,722.34248
Overall Steps per Second: 10,674.99988

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68628

Cumulative Model Updates: 133,250
Cumulative Timesteps: 1,111,125,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,328.32888
Policy Entropy: 3.73911
Value Function Loss: 0.02853

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.60888
Value Function Update Magnitude: 0.59566

Collected Steps per Second: 22,746.30338
Overall Steps per Second: 10,840.48372

Timestep Collection Time: 2.19825
Timestep Consumption Time: 2.41428
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.61252

Cumulative Model Updates: 133,256
Cumulative Timesteps: 1,111,175,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1111175160...
Checkpoint 1111175160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,328.32888
Policy Entropy: 3.72803
Value Function Loss: 0.02753

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.59257
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,511.67042
Overall Steps per Second: 10,675.63354

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.68450

Cumulative Model Updates: 133,262
Cumulative Timesteps: 1,111,225,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,637.00400
Policy Entropy: 3.72080
Value Function Loss: 0.02460

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14174
Policy Update Magnitude: 0.54184
Value Function Update Magnitude: 0.57907

Collected Steps per Second: 23,055.24276
Overall Steps per Second: 10,889.36489

Timestep Collection Time: 2.16975
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59384

Cumulative Model Updates: 133,268
Cumulative Timesteps: 1,111,275,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1111275194...
Checkpoint 1111275194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,637.00400
Policy Entropy: 3.72373
Value Function Loss: 0.02292

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.51191
Value Function Update Magnitude: 0.48624

Collected Steps per Second: 22,570.71704
Overall Steps per Second: 10,697.99692

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.45940
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.67545

Cumulative Model Updates: 133,274
Cumulative Timesteps: 1,111,325,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,809.34342
Policy Entropy: 3.72338
Value Function Loss: 0.02149

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.47974

Collected Steps per Second: 22,077.98983
Overall Steps per Second: 10,864.39439

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.33852
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.60421

Cumulative Model Updates: 133,280
Cumulative Timesteps: 1,111,375,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1111375234...
Checkpoint 1111375234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,115.20093
Policy Entropy: 3.73513
Value Function Loss: 0.02363

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.49701
Value Function Update Magnitude: 0.45956

Collected Steps per Second: 22,272.20573
Overall Steps per Second: 10,748.13259

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.40837
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.65458

Cumulative Model Updates: 133,286
Cumulative Timesteps: 1,111,425,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,204.58565
Policy Entropy: 3.74214
Value Function Loss: 0.02374

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.53976
Value Function Update Magnitude: 0.49294

Collected Steps per Second: 22,205.22458
Overall Steps per Second: 10,890.58633

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.34099
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.59424

Cumulative Model Updates: 133,292
Cumulative Timesteps: 1,111,475,296

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1111475296...
Checkpoint 1111475296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,003.37866
Policy Entropy: 3.76589
Value Function Loss: 0.02199

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.57306

Collected Steps per Second: 22,263.53146
Overall Steps per Second: 10,590.36229

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72127

Cumulative Model Updates: 133,298
Cumulative Timesteps: 1,111,525,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,012.06173
Policy Entropy: 3.74233
Value Function Loss: 0.01947

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.47467
Value Function Update Magnitude: 0.54902

Collected Steps per Second: 23,277.12642
Overall Steps per Second: 10,928.66567

Timestep Collection Time: 2.14898
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.57714

Cumulative Model Updates: 133,304
Cumulative Timesteps: 1,111,575,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1111575318...
Checkpoint 1111575318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,910.82027
Policy Entropy: 3.73808
Value Function Loss: 0.01975

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.43949
Value Function Update Magnitude: 0.57947

Collected Steps per Second: 22,476.63153
Overall Steps per Second: 10,665.59867

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.46354
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.68816

Cumulative Model Updates: 133,310
Cumulative Timesteps: 1,111,625,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,820.67328
Policy Entropy: 3.73355
Value Function Loss: 0.02325

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.46140
Value Function Update Magnitude: 0.58471

Collected Steps per Second: 23,042.06388
Overall Steps per Second: 10,924.86421

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.40716
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.57745

Cumulative Model Updates: 133,316
Cumulative Timesteps: 1,111,675,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1111675328...
Checkpoint 1111675328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,347.89451
Policy Entropy: 3.75072
Value Function Loss: 0.02518

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.53662
Value Function Update Magnitude: 0.53890

Collected Steps per Second: 22,940.84894
Overall Steps per Second: 10,716.67467

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.48661
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.66656

Cumulative Model Updates: 133,322
Cumulative Timesteps: 1,111,725,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,661.99781
Policy Entropy: 3.74156
Value Function Loss: 0.02575

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.55879

Collected Steps per Second: 23,013.16429
Overall Steps per Second: 10,791.60718

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.46066
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.63342

Cumulative Model Updates: 133,328
Cumulative Timesteps: 1,111,775,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1111775340...
Checkpoint 1111775340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,661.99781
Policy Entropy: 3.72895
Value Function Loss: 0.02382

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.51038
Value Function Update Magnitude: 0.53707

Collected Steps per Second: 22,827.26611
Overall Steps per Second: 10,688.64585

Timestep Collection Time: 2.19133
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67992

Cumulative Model Updates: 133,334
Cumulative Timesteps: 1,111,825,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,661.99781
Policy Entropy: 3.72510
Value Function Loss: 0.02021

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.46090
Value Function Update Magnitude: 0.40933

Collected Steps per Second: 23,285.42422
Overall Steps per Second: 10,860.16553

Timestep Collection Time: 2.14830
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.60619

Cumulative Model Updates: 133,340
Cumulative Timesteps: 1,111,875,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1111875386...
Checkpoint 1111875386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,661.99781
Policy Entropy: 3.73936
Value Function Loss: 0.01727

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.41726
Value Function Update Magnitude: 0.33635

Collected Steps per Second: 22,931.72970
Overall Steps per Second: 10,719.89439

Timestep Collection Time: 2.18082
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.66516

Cumulative Model Updates: 133,346
Cumulative Timesteps: 1,111,925,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,661.99781
Policy Entropy: 3.74825
Value Function Loss: 0.01371

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.38206
Value Function Update Magnitude: 0.32282

Collected Steps per Second: 23,005.81816
Overall Steps per Second: 10,815.16237

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.62388

Cumulative Model Updates: 133,352
Cumulative Timesteps: 1,111,975,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1111975404...
Checkpoint 1111975404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,975.35802
Policy Entropy: 3.73009
Value Function Loss: 0.01620

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.38186
Value Function Update Magnitude: 0.37492

Collected Steps per Second: 22,888.99724
Overall Steps per Second: 10,732.08938

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.66302

Cumulative Model Updates: 133,358
Cumulative Timesteps: 1,112,025,448

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,975.35802
Policy Entropy: 3.72525
Value Function Loss: 0.01724

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.40773
Value Function Update Magnitude: 0.35677

Collected Steps per Second: 22,875.94684
Overall Steps per Second: 10,874.62456

Timestep Collection Time: 2.18701
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.60062

Cumulative Model Updates: 133,364
Cumulative Timesteps: 1,112,075,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1112075478...
Checkpoint 1112075478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,975.35802
Policy Entropy: 3.70988
Value Function Loss: 0.01958

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.43666
Value Function Update Magnitude: 0.35712

Collected Steps per Second: 22,735.30727
Overall Steps per Second: 10,674.54559

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68423

Cumulative Model Updates: 133,370
Cumulative Timesteps: 1,112,125,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,686.32875
Policy Entropy: 3.73375
Value Function Loss: 0.01990

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.46647
Value Function Update Magnitude: 0.37029

Collected Steps per Second: 22,744.79375
Overall Steps per Second: 10,808.03622

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.62693

Cumulative Model Updates: 133,376
Cumulative Timesteps: 1,112,175,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1112175488...
Checkpoint 1112175488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,221.17433
Policy Entropy: 3.73390
Value Function Loss: 0.02238

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.48769
Value Function Update Magnitude: 0.42531

Collected Steps per Second: 22,663.80847
Overall Steps per Second: 10,651.58377

Timestep Collection Time: 2.20722
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.69639

Cumulative Model Updates: 133,382
Cumulative Timesteps: 1,112,225,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,184.84214
Policy Entropy: 3.75132
Value Function Loss: 0.02108

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.50180
Value Function Update Magnitude: 0.44467

Collected Steps per Second: 22,186.37397
Overall Steps per Second: 10,849.77593

Timestep Collection Time: 2.25364
Timestep Consumption Time: 2.35475
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.60839

Cumulative Model Updates: 133,388
Cumulative Timesteps: 1,112,275,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1112275512...
Checkpoint 1112275512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,551.97525
Policy Entropy: 3.74502
Value Function Loss: 0.02359

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.43682

Collected Steps per Second: 21,967.38525
Overall Steps per Second: 10,657.58556

Timestep Collection Time: 2.27637
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.69206

Cumulative Model Updates: 133,394
Cumulative Timesteps: 1,112,325,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,113.90653
Policy Entropy: 3.75114
Value Function Loss: 0.02495

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.58784
Value Function Update Magnitude: 0.48557

Collected Steps per Second: 22,287.09880
Overall Steps per Second: 10,895.39060

Timestep Collection Time: 2.24471
Timestep Consumption Time: 2.34696
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59167

Cumulative Model Updates: 133,400
Cumulative Timesteps: 1,112,375,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1112375546...
Checkpoint 1112375546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,067.95323
Policy Entropy: 3.76521
Value Function Loss: 0.03193

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.67465
Value Function Update Magnitude: 0.43770

Collected Steps per Second: 22,106.05301
Overall Steps per Second: 10,679.07521

Timestep Collection Time: 2.26264
Timestep Consumption Time: 2.42110
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.68374

Cumulative Model Updates: 133,406
Cumulative Timesteps: 1,112,425,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,399.79504
Policy Entropy: 3.80435
Value Function Loss: 0.02413

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.67614
Value Function Update Magnitude: 0.58811

Collected Steps per Second: 22,337.44215
Overall Steps per Second: 10,661.38674

Timestep Collection Time: 2.23875
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69057

Cumulative Model Updates: 133,412
Cumulative Timesteps: 1,112,475,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1112475572...
Checkpoint 1112475572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310,348.76889
Policy Entropy: 3.79346
Value Function Loss: 0.02311

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12093
Policy Update Magnitude: 0.63435
Value Function Update Magnitude: 0.69064

Collected Steps per Second: 22,624.53164
Overall Steps per Second: 10,885.74772

Timestep Collection Time: 2.21017
Timestep Consumption Time: 2.38336
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.59353

Cumulative Model Updates: 133,418
Cumulative Timesteps: 1,112,525,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,191.49482
Policy Entropy: 3.78289
Value Function Loss: 0.01804

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08322
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.67015

Collected Steps per Second: 23,101.32066
Overall Steps per Second: 10,933.57704

Timestep Collection Time: 2.16516
Timestep Consumption Time: 2.40956
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.57472

Cumulative Model Updates: 133,424
Cumulative Timesteps: 1,112,575,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1112575594...
Checkpoint 1112575594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,621.06433
Policy Entropy: 3.73306
Value Function Loss: 0.02080

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.56299
Value Function Update Magnitude: 0.67622

Collected Steps per Second: 22,715.32693
Overall Steps per Second: 10,659.33233

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.69129

Cumulative Model Updates: 133,430
Cumulative Timesteps: 1,112,625,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,925.94386
Policy Entropy: 3.75185
Value Function Loss: 0.02252

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.18282
Policy Update Magnitude: 0.51852
Value Function Update Magnitude: 0.57559

Collected Steps per Second: 23,088.90002
Overall Steps per Second: 10,910.87289

Timestep Collection Time: 2.16615
Timestep Consumption Time: 2.41772
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.58387

Cumulative Model Updates: 133,436
Cumulative Timesteps: 1,112,675,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1112675614...
Checkpoint 1112675614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,925.94386
Policy Entropy: 3.75276
Value Function Loss: 0.02113

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.48544

Collected Steps per Second: 22,893.19083
Overall Steps per Second: 10,711.44250

Timestep Collection Time: 2.18528
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67052

Cumulative Model Updates: 133,442
Cumulative Timesteps: 1,112,725,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,925.94386
Policy Entropy: 3.76058
Value Function Loss: 0.01976

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14854
Policy Update Magnitude: 0.51455
Value Function Update Magnitude: 0.49573

Collected Steps per Second: 23,182.52379
Overall Steps per Second: 10,794.35246

Timestep Collection Time: 2.15740
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.63335

Cumulative Model Updates: 133,448
Cumulative Timesteps: 1,112,775,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1112775656...
Checkpoint 1112775656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,939.20196
Policy Entropy: 3.75253
Value Function Loss: 0.01911

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05955
Policy Update Magnitude: 0.62400
Value Function Update Magnitude: 0.55048

Collected Steps per Second: 22,900.41400
Overall Steps per Second: 10,722.36600

Timestep Collection Time: 2.18503
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.66669

Cumulative Model Updates: 133,454
Cumulative Timesteps: 1,112,825,694

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,100.36318
Policy Entropy: 3.75700
Value Function Loss: 0.01921

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.71520
Value Function Update Magnitude: 0.58827

Collected Steps per Second: 23,153.86504
Overall Steps per Second: 10,841.95639

Timestep Collection Time: 2.16059
Timestep Consumption Time: 2.45352
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.61411

Cumulative Model Updates: 133,460
Cumulative Timesteps: 1,112,875,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1112875720...
Checkpoint 1112875720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,100.36318
Policy Entropy: 3.77187
Value Function Loss: 0.01490

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05629
Policy Update Magnitude: 0.65174
Value Function Update Magnitude: 0.55680

Collected Steps per Second: 23,182.50337
Overall Steps per Second: 10,825.78881

Timestep Collection Time: 2.15740
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.61989

Cumulative Model Updates: 133,466
Cumulative Timesteps: 1,112,925,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 385,100.36318
Policy Entropy: 3.76967
Value Function Loss: 0.01315

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05307
Policy Update Magnitude: 0.53971
Value Function Update Magnitude: 0.42180

Collected Steps per Second: 21,812.82428
Overall Steps per Second: 10,724.60530

Timestep Collection Time: 2.29250
Timestep Consumption Time: 2.37023
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.66274

Cumulative Model Updates: 133,472
Cumulative Timesteps: 1,112,975,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1112975740...
Checkpoint 1112975740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,077.83004
Policy Entropy: 3.76919
Value Function Loss: 0.01540

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04771
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.45756

Collected Steps per Second: 22,178.34351
Overall Steps per Second: 10,728.80394

Timestep Collection Time: 2.25490
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.66128

Cumulative Model Updates: 133,478
Cumulative Timesteps: 1,113,025,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,068.98615
Policy Entropy: 3.78443
Value Function Loss: 0.01894

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.71094
Value Function Update Magnitude: 0.75108

Collected Steps per Second: 22,281.26719
Overall Steps per Second: 10,817.34387

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.37950
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.62480

Cumulative Model Updates: 133,484
Cumulative Timesteps: 1,113,075,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1113075778...
Checkpoint 1113075778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,080.28165
Policy Entropy: 3.80789
Value Function Loss: 0.02061

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.75443
Value Function Update Magnitude: 0.72789

Collected Steps per Second: 22,326.95073
Overall Steps per Second: 10,612.56950

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.71290

Cumulative Model Updates: 133,490
Cumulative Timesteps: 1,113,125,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.18069
Policy Entropy: 3.80571
Value Function Loss: 0.01772

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.70658
Value Function Update Magnitude: 0.76354

Collected Steps per Second: 22,748.07905
Overall Steps per Second: 10,870.26104

Timestep Collection Time: 2.19983
Timestep Consumption Time: 2.40374
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60357

Cumulative Model Updates: 133,496
Cumulative Timesteps: 1,113,175,836

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1113175836...
Checkpoint 1113175836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,179.18069
Policy Entropy: 3.78079
Value Function Loss: 0.01476

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16089
Policy Update Magnitude: 0.60134
Value Function Update Magnitude: 0.75073

Collected Steps per Second: 22,885.16401
Overall Steps per Second: 10,766.68181

Timestep Collection Time: 2.18570
Timestep Consumption Time: 2.46012
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.64581

Cumulative Model Updates: 133,502
Cumulative Timesteps: 1,113,225,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 641,088.40635
Policy Entropy: 3.74983
Value Function Loss: 0.01882

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.20879
Policy Update Magnitude: 0.54337
Value Function Update Magnitude: 0.60351

Collected Steps per Second: 22,760.44446
Overall Steps per Second: 10,777.02910

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.44290
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.63987

Cumulative Model Updates: 133,508
Cumulative Timesteps: 1,113,275,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1113275860...
Checkpoint 1113275860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 641,088.40635
Policy Entropy: 3.76231
Value Function Loss: 0.01753

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15817
Policy Update Magnitude: 0.68032
Value Function Update Magnitude: 0.55527

Collected Steps per Second: 22,734.59847
Overall Steps per Second: 10,681.90198

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.48291
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68344

Cumulative Model Updates: 133,514
Cumulative Timesteps: 1,113,325,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 541,780.67230
Policy Entropy: 3.76153
Value Function Loss: 0.01715

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.66910
Value Function Update Magnitude: 0.52254

Collected Steps per Second: 23,205.05612
Overall Steps per Second: 10,930.35834

Timestep Collection Time: 2.15634
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.57789

Cumulative Model Updates: 133,520
Cumulative Timesteps: 1,113,375,926

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1113375926...
Checkpoint 1113375926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,955.37761
Policy Entropy: 3.77485
Value Function Loss: 0.01524

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.44715

Collected Steps per Second: 22,559.97089
Overall Steps per Second: 10,651.22672

Timestep Collection Time: 2.21747
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.69674

Cumulative Model Updates: 133,526
Cumulative Timesteps: 1,113,425,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,955.37761
Policy Entropy: 3.74183
Value Function Loss: 0.01742

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.59147
Value Function Update Magnitude: 0.44312

Collected Steps per Second: 22,644.52875
Overall Steps per Second: 10,816.08438

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.41567
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62459

Cumulative Model Updates: 133,532
Cumulative Timesteps: 1,113,475,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1113475972...
Checkpoint 1113475972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,983.06535
Policy Entropy: 3.75232
Value Function Loss: 0.02302

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14467
Policy Update Magnitude: 0.62838
Value Function Update Magnitude: 0.42780

Collected Steps per Second: 22,424.75058
Overall Steps per Second: 10,767.48723

Timestep Collection Time: 2.23039
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.64509

Cumulative Model Updates: 133,538
Cumulative Timesteps: 1,113,525,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,381.79476
Policy Entropy: 3.75679
Value Function Loss: 0.02908

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15486
Policy Update Magnitude: 0.52947
Value Function Update Magnitude: 0.36771

Collected Steps per Second: 22,469.79652
Overall Steps per Second: 10,785.30115

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.63612

Cumulative Model Updates: 133,544
Cumulative Timesteps: 1,113,575,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1113575990...
Checkpoint 1113575990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,797.75798
Policy Entropy: 3.76547
Value Function Loss: 0.02453

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14538
Policy Update Magnitude: 0.63242
Value Function Update Magnitude: 0.46531

Collected Steps per Second: 22,531.48950
Overall Steps per Second: 10,725.88317

Timestep Collection Time: 2.22036
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.66423

Cumulative Model Updates: 133,550
Cumulative Timesteps: 1,113,626,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,667.12378
Policy Entropy: 3.76686
Value Function Loss: 0.02912

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.60150

Collected Steps per Second: 22,507.81881
Overall Steps per Second: 10,648.87820

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.69740

Cumulative Model Updates: 133,556
Cumulative Timesteps: 1,113,676,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1113676040...
Checkpoint 1113676040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,575.37622
Policy Entropy: 3.79098
Value Function Loss: 0.02765

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17154
Policy Update Magnitude: 0.62955
Value Function Update Magnitude: 0.57987

Collected Steps per Second: 22,644.84431
Overall Steps per Second: 10,811.06780

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62748

Cumulative Model Updates: 133,562
Cumulative Timesteps: 1,113,726,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,899.62450
Policy Entropy: 3.77972
Value Function Loss: 0.02796

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.17293
Policy Update Magnitude: 0.58964
Value Function Update Magnitude: 0.57397

Collected Steps per Second: 22,843.34809
Overall Steps per Second: 10,713.47547

Timestep Collection Time: 2.18882
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.66702

Cumulative Model Updates: 133,568
Cumulative Timesteps: 1,113,776,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1113776068...
Checkpoint 1113776068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.64226
Policy Entropy: 3.77820
Value Function Loss: 0.02342

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.52841
Value Function Update Magnitude: 0.65301

Collected Steps per Second: 22,826.75256
Overall Steps per Second: 10,846.24850

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61192

Cumulative Model Updates: 133,574
Cumulative Timesteps: 1,113,826,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,742.51584
Policy Entropy: 3.76964
Value Function Loss: 0.02256

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.47218
Value Function Update Magnitude: 0.71090

Collected Steps per Second: 22,493.73280
Overall Steps per Second: 10,601.36092

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.49443
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71807

Cumulative Model Updates: 133,580
Cumulative Timesteps: 1,113,876,108

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1113876108...
Checkpoint 1113876108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,830.42353
Policy Entropy: 3.76799
Value Function Loss: 0.02562

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.47661
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 22,389.63541
Overall Steps per Second: 10,589.00426

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.49069
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.72566

Cumulative Model Updates: 133,586
Cumulative Timesteps: 1,113,926,148

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,915.11740
Policy Entropy: 3.76518
Value Function Loss: 0.02609

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.50688
Value Function Update Magnitude: 0.60524

Collected Steps per Second: 22,623.92691
Overall Steps per Second: 10,791.78965

Timestep Collection Time: 2.21129
Timestep Consumption Time: 2.42446
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.63575

Cumulative Model Updates: 133,592
Cumulative Timesteps: 1,113,976,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1113976176...
Checkpoint 1113976176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,819.37990
Policy Entropy: 3.76694
Value Function Loss: 0.02511

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.48990
Value Function Update Magnitude: 0.69789

Collected Steps per Second: 22,834.06453
Overall Steps per Second: 10,730.34713

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.46997
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.65968

Cumulative Model Updates: 133,598
Cumulative Timesteps: 1,114,026,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,190.00414
Policy Entropy: 3.76305
Value Function Loss: 0.02651

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.50227
Value Function Update Magnitude: 0.64580

Collected Steps per Second: 22,342.45430
Overall Steps per Second: 10,599.40702

Timestep Collection Time: 2.23897
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.71951

Cumulative Model Updates: 133,604
Cumulative Timesteps: 1,114,076,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1114076200...
Checkpoint 1114076200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,734.80952
Policy Entropy: 3.76061
Value Function Loss: 0.02684

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.53699

Collected Steps per Second: 22,897.39961
Overall Steps per Second: 10,835.11496

Timestep Collection Time: 2.18427
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61592

Cumulative Model Updates: 133,610
Cumulative Timesteps: 1,114,126,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,546.96901
Policy Entropy: 3.76839
Value Function Loss: 0.02647

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.52728
Value Function Update Magnitude: 0.55384

Collected Steps per Second: 22,585.88713
Overall Steps per Second: 10,628.94711

Timestep Collection Time: 2.21377
Timestep Consumption Time: 2.49036
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.70413

Cumulative Model Updates: 133,616
Cumulative Timesteps: 1,114,176,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1114176214...
Checkpoint 1114176214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,832.51430
Policy Entropy: 3.78750
Value Function Loss: 0.02592

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.52411
Value Function Update Magnitude: 0.55378

Collected Steps per Second: 22,999.19195
Overall Steps per Second: 10,929.10841

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.40124
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.57549

Cumulative Model Updates: 133,622
Cumulative Timesteps: 1,114,226,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.41312
Policy Entropy: 3.77288
Value Function Loss: 0.02485

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.48721
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 22,548.86560
Overall Steps per Second: 10,650.84439

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.47835
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69690

Cumulative Model Updates: 133,628
Cumulative Timesteps: 1,114,276,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1114276246...
Checkpoint 1114276246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,628.68997
Policy Entropy: 3.77326
Value Function Loss: 0.02262

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.50755
Value Function Update Magnitude: 0.67745

Collected Steps per Second: 23,038.59250
Overall Steps per Second: 10,921.60066

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.40897
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.58028

Cumulative Model Updates: 133,634
Cumulative Timesteps: 1,114,326,270

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,514.95427
Policy Entropy: 3.75596
Value Function Loss: 0.02773

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.61538

Collected Steps per Second: 22,986.39062
Overall Steps per Second: 10,918.99464

Timestep Collection Time: 2.17590
Timestep Consumption Time: 2.40475
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.58064

Cumulative Model Updates: 133,640
Cumulative Timesteps: 1,114,376,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1114376286...
Checkpoint 1114376286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,804.17829
Policy Entropy: 3.76864
Value Function Loss: 0.02771

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.63689
Value Function Update Magnitude: 0.70405

Collected Steps per Second: 22,349.22582
Overall Steps per Second: 10,754.64881

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.41329
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.65176

Cumulative Model Updates: 133,646
Cumulative Timesteps: 1,114,426,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,841.33650
Policy Entropy: 3.74361
Value Function Loss: 0.02988

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.61658
Value Function Update Magnitude: 0.69481

Collected Steps per Second: 22,013.91923
Overall Steps per Second: 10,848.39076

Timestep Collection Time: 2.27156
Timestep Consumption Time: 2.33797
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.60953

Cumulative Model Updates: 133,652
Cumulative Timesteps: 1,114,476,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1114476320...
Checkpoint 1114476320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,143.38557
Policy Entropy: 3.75233
Value Function Loss: 0.02794

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.58349
Value Function Update Magnitude: 0.65839

Collected Steps per Second: 22,452.17957
Overall Steps per Second: 10,836.43623

Timestep Collection Time: 2.22731
Timestep Consumption Time: 2.38749
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.61480

Cumulative Model Updates: 133,658
Cumulative Timesteps: 1,114,526,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,607.86854
Policy Entropy: 3.76579
Value Function Loss: 0.02628

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14537
Policy Update Magnitude: 0.57318
Value Function Update Magnitude: 0.63883

Collected Steps per Second: 22,404.69975
Overall Steps per Second: 10,755.87141

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.41821
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.65104

Cumulative Model Updates: 133,664
Cumulative Timesteps: 1,114,576,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1114576354...
Checkpoint 1114576354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,392.38605
Policy Entropy: 3.78471
Value Function Loss: 0.02594

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.66124

Collected Steps per Second: 22,039.72192
Overall Steps per Second: 10,589.62905

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.45326
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.72217

Cumulative Model Updates: 133,670
Cumulative Timesteps: 1,114,626,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,531.04552
Policy Entropy: 3.76836
Value Function Loss: 0.02546

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.54359
Value Function Update Magnitude: 0.73838

Collected Steps per Second: 22,717.47274
Overall Steps per Second: 10,862.47929

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.40244
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.60374

Cumulative Model Updates: 133,676
Cumulative Timesteps: 1,114,676,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1114676368...
Checkpoint 1114676368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,963.67700
Policy Entropy: 3.76419
Value Function Loss: 0.02883

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.58369
Value Function Update Magnitude: 0.81196

Collected Steps per Second: 22,851.30061
Overall Steps per Second: 10,769.76317

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.45604
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.64541

Cumulative Model Updates: 133,682
Cumulative Timesteps: 1,114,726,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,335.59569
Policy Entropy: 3.78078
Value Function Loss: 0.02852

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.62842
Value Function Update Magnitude: 0.81276

Collected Steps per Second: 22,743.14777
Overall Steps per Second: 10,842.20606

Timestep Collection Time: 2.19899
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.61271

Cumulative Model Updates: 133,688
Cumulative Timesteps: 1,114,776,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1114776410...
Checkpoint 1114776410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,287.86705
Policy Entropy: 3.79625
Value Function Loss: 0.02974

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.62577
Value Function Update Magnitude: 0.82055

Collected Steps per Second: 22,867.59808
Overall Steps per Second: 10,831.72124

Timestep Collection Time: 2.18685
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.61681

Cumulative Model Updates: 133,694
Cumulative Timesteps: 1,114,826,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,528.88866
Policy Entropy: 3.80452
Value Function Loss: 0.02569

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.65954
Value Function Update Magnitude: 0.83717

Collected Steps per Second: 22,995.63004
Overall Steps per Second: 10,688.73683

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.67894

Cumulative Model Updates: 133,700
Cumulative Timesteps: 1,114,876,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1114876430...
Checkpoint 1114876430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,676.73051
Policy Entropy: 3.77525
Value Function Loss: 0.02667

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.59824
Value Function Update Magnitude: 0.74238

Collected Steps per Second: 23,016.53985
Overall Steps per Second: 10,727.40321

Timestep Collection Time: 2.17313
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.66264

Cumulative Model Updates: 133,706
Cumulative Timesteps: 1,114,926,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,676.73051
Policy Entropy: 3.76118
Value Function Loss: 0.02513

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.66158

Collected Steps per Second: 22,965.23158
Overall Steps per Second: 10,890.13826

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.59223

Cumulative Model Updates: 133,712
Cumulative Timesteps: 1,114,976,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1114976458...
Checkpoint 1114976458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,921.35041
Policy Entropy: 3.74512
Value Function Loss: 0.02236

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15424
Policy Update Magnitude: 0.51691
Value Function Update Magnitude: 0.59210

Collected Steps per Second: 22,971.05439
Overall Steps per Second: 10,757.38915

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.47211
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.64946

Cumulative Model Updates: 133,718
Cumulative Timesteps: 1,115,026,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,378.75178
Policy Entropy: 3.74306
Value Function Loss: 0.02148

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.48055
Value Function Update Magnitude: 0.60128

Collected Steps per Second: 22,882.53417
Overall Steps per Second: 10,769.45312

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.64480

Cumulative Model Updates: 133,724
Cumulative Timesteps: 1,115,076,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1115076496...
Checkpoint 1115076496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,538.56665
Policy Entropy: 3.75838
Value Function Loss: 0.02074

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.44484
Value Function Update Magnitude: 0.58034

Collected Steps per Second: 23,082.22518
Overall Steps per Second: 10,772.36946

Timestep Collection Time: 2.16678
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.64280

Cumulative Model Updates: 133,730
Cumulative Timesteps: 1,115,126,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,754.24357
Policy Entropy: 3.75108
Value Function Loss: 0.02548

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13185
Policy Update Magnitude: 0.47198
Value Function Update Magnitude: 0.65863

Collected Steps per Second: 22,555.01500
Overall Steps per Second: 10,796.56147

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.41498
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.63240

Cumulative Model Updates: 133,736
Cumulative Timesteps: 1,115,176,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115176524...
Checkpoint 1115176524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,112.00467
Policy Entropy: 3.78200
Value Function Loss: 0.02477

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.55206
Value Function Update Magnitude: 0.72505

Collected Steps per Second: 22,433.37032
Overall Steps per Second: 10,953.28366

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.33677
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.56630

Cumulative Model Updates: 133,742
Cumulative Timesteps: 1,115,226,540

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,801.72699
Policy Entropy: 3.74831
Value Function Loss: 0.02545

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.78780

Collected Steps per Second: 22,026.39486
Overall Steps per Second: 10,696.57842

Timestep Collection Time: 2.27091
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.67626

Cumulative Model Updates: 133,748
Cumulative Timesteps: 1,115,276,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1115276560...
Checkpoint 1115276560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,801.72699
Policy Entropy: 3.74129
Value Function Loss: 0.02198

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.51987
Value Function Update Magnitude: 0.65408

Collected Steps per Second: 22,274.94605
Overall Steps per Second: 10,633.52501

Timestep Collection Time: 2.24638
Timestep Consumption Time: 2.45930
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.70568

Cumulative Model Updates: 133,754
Cumulative Timesteps: 1,115,326,598

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,654.52024
Policy Entropy: 3.72170
Value Function Loss: 0.02378

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.53002
Value Function Update Magnitude: 0.63571

Collected Steps per Second: 22,843.34004
Overall Steps per Second: 10,767.62905

Timestep Collection Time: 2.18970
Timestep Consumption Time: 2.45571
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.64541

Cumulative Model Updates: 133,760
Cumulative Timesteps: 1,115,376,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1115376618...
Checkpoint 1115376618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,975.44508
Policy Entropy: 3.74044
Value Function Loss: 0.02342

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.67128

Collected Steps per Second: 22,830.00414
Overall Steps per Second: 10,787.51187

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.63740

Cumulative Model Updates: 133,766
Cumulative Timesteps: 1,115,426,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 590,884.78928
Policy Entropy: 3.73590
Value Function Loss: 0.02266

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14592
Policy Update Magnitude: 0.51601
Value Function Update Magnitude: 0.66562

Collected Steps per Second: 22,927.43998
Overall Steps per Second: 10,768.60510

Timestep Collection Time: 2.18114
Timestep Consumption Time: 2.46273
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.64387

Cumulative Model Updates: 133,772
Cumulative Timesteps: 1,115,476,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1115476652...
Checkpoint 1115476652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.73764
Value Function Loss: 0.02020

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.48366
Value Function Update Magnitude: 0.66484

Collected Steps per Second: 22,804.85278
Overall Steps per Second: 10,676.38339

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68361

Cumulative Model Updates: 133,778
Cumulative Timesteps: 1,115,526,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.73643
Value Function Loss: 0.01750

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.48102
Value Function Update Magnitude: 0.57531

Collected Steps per Second: 23,022.91659
Overall Steps per Second: 10,910.54661

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.58437

Cumulative Model Updates: 133,784
Cumulative Timesteps: 1,115,576,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1115576674...
Checkpoint 1115576674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.73013
Value Function Loss: 0.01672

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.46493
Value Function Update Magnitude: 0.44964

Collected Steps per Second: 23,043.09108
Overall Steps per Second: 10,806.84460

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.62910

Cumulative Model Updates: 133,790
Cumulative Timesteps: 1,115,626,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.73559
Value Function Loss: 0.01468

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.43356
Value Function Update Magnitude: 0.40982

Collected Steps per Second: 22,748.54275
Overall Steps per Second: 10,673.97611

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.48754
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68654

Cumulative Model Updates: 133,796
Cumulative Timesteps: 1,115,676,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1115676724...
Checkpoint 1115676724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.74608
Value Function Loss: 0.01368

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.37532
Value Function Update Magnitude: 0.37398

Collected Steps per Second: 22,612.24181
Overall Steps per Second: 10,638.67474

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70284

Cumulative Model Updates: 133,802
Cumulative Timesteps: 1,115,726,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601,185.32198
Policy Entropy: 3.74585
Value Function Loss: 0.01373

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.14107
Policy Update Magnitude: 0.33176
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 22,196.93565
Overall Steps per Second: 10,870.93646

Timestep Collection Time: 2.25319
Timestep Consumption Time: 2.34751
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.60071

Cumulative Model Updates: 133,808
Cumulative Timesteps: 1,115,776,770

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1115776770...
Checkpoint 1115776770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709,836.90719
Policy Entropy: 3.72645
Value Function Loss: 0.01714

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.31597
Value Function Update Magnitude: 0.30227

Collected Steps per Second: 22,349.67238
Overall Steps per Second: 10,764.70137

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.40880
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.64704

Cumulative Model Updates: 133,814
Cumulative Timesteps: 1,115,826,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247,516.50060
Policy Entropy: 3.74017
Value Function Loss: 0.01649

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.34388
Value Function Update Magnitude: 0.35728

Collected Steps per Second: 22,409.68791
Overall Steps per Second: 10,763.76326

Timestep Collection Time: 2.23216
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.64726

Cumulative Model Updates: 133,820
Cumulative Timesteps: 1,115,876,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1115876816...
Checkpoint 1115876816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,557.61983
Policy Entropy: 3.73899
Value Function Loss: 0.01783

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.38578
Value Function Update Magnitude: 0.37580

Collected Steps per Second: 22,960.34100
Overall Steps per Second: 10,780.32109

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.64068

Cumulative Model Updates: 133,826
Cumulative Timesteps: 1,115,926,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,557.61983
Policy Entropy: 3.75282
Value Function Loss: 0.01584

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.47294
Value Function Update Magnitude: 0.49798

Collected Steps per Second: 23,337.29797
Overall Steps per Second: 10,864.70026

Timestep Collection Time: 2.14429
Timestep Consumption Time: 2.46163
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.60593

Cumulative Model Updates: 133,832
Cumulative Timesteps: 1,115,976,886

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1115976886...
Checkpoint 1115976886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,476.44111
Policy Entropy: 3.73358
Value Function Loss: 0.01681

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.49314
Value Function Update Magnitude: 0.56141

Collected Steps per Second: 22,841.91396
Overall Steps per Second: 10,701.07918

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.48496
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.67523

Cumulative Model Updates: 133,838
Cumulative Timesteps: 1,116,026,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,829.43193
Policy Entropy: 3.75274
Value Function Loss: 0.01785

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.52295
Value Function Update Magnitude: 0.57420

Collected Steps per Second: 22,997.36351
Overall Steps per Second: 10,815.92856

Timestep Collection Time: 2.17486
Timestep Consumption Time: 2.44943
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.62429

Cumulative Model Updates: 133,844
Cumulative Timesteps: 1,116,076,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1116076932...
Checkpoint 1116076932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,873.78412
Policy Entropy: 3.74864
Value Function Loss: 0.01971

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.51875
Value Function Update Magnitude: 0.60147

Collected Steps per Second: 22,998.63003
Overall Steps per Second: 10,700.84133

Timestep Collection Time: 2.17413
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.67272

Cumulative Model Updates: 133,850
Cumulative Timesteps: 1,116,126,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439,873.78412
Policy Entropy: 3.75281
Value Function Loss: 0.01891

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.51087
Value Function Update Magnitude: 0.62222

Collected Steps per Second: 23,374.63897
Overall Steps per Second: 10,859.75334

Timestep Collection Time: 2.13993
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.60600

Cumulative Model Updates: 133,856
Cumulative Timesteps: 1,116,176,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1116176954...
Checkpoint 1116176954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439,873.78412
Policy Entropy: 3.72351
Value Function Loss: 0.02000

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.47668
Value Function Update Magnitude: 0.59166

Collected Steps per Second: 22,854.06795
Overall Steps per Second: 10,702.24753

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67322

Cumulative Model Updates: 133,862
Cumulative Timesteps: 1,116,226,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,917.31602
Policy Entropy: 3.73377
Value Function Loss: 0.02141

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.51091
Value Function Update Magnitude: 0.61789

Collected Steps per Second: 22,927.88695
Overall Steps per Second: 10,862.58230

Timestep Collection Time: 2.18232
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.60627

Cumulative Model Updates: 133,868
Cumulative Timesteps: 1,116,277,004

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1116277004...
Checkpoint 1116277004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,973.88565
Policy Entropy: 3.73366
Value Function Loss: 0.02277

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.60578
Value Function Update Magnitude: 0.72892

Collected Steps per Second: 22,906.09549
Overall Steps per Second: 10,696.49416

Timestep Collection Time: 2.18422
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.67742

Cumulative Model Updates: 133,874
Cumulative Timesteps: 1,116,327,036

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,420.90538
Policy Entropy: 3.73473
Value Function Loss: 0.02356

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.60793
Value Function Update Magnitude: 0.67573

Collected Steps per Second: 22,985.23932
Overall Steps per Second: 10,895.89253

Timestep Collection Time: 2.17609
Timestep Consumption Time: 2.41445
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.59054

Cumulative Model Updates: 133,880
Cumulative Timesteps: 1,116,377,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1116377054...
Checkpoint 1116377054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,420.90538
Policy Entropy: 3.72106
Value Function Loss: 0.02112

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.56847

Collected Steps per Second: 23,253.24363
Overall Steps per Second: 10,958.74177

Timestep Collection Time: 2.15067
Timestep Consumption Time: 2.41281
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.56348

Cumulative Model Updates: 133,886
Cumulative Timesteps: 1,116,427,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,420.90538
Policy Entropy: 3.70902
Value Function Loss: 0.02287

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.49295
Value Function Update Magnitude: 0.45428

Collected Steps per Second: 22,885.68393
Overall Steps per Second: 10,730.92000

Timestep Collection Time: 2.18608
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.66223

Cumulative Model Updates: 133,892
Cumulative Timesteps: 1,116,477,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1116477094...
Checkpoint 1116477094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,276.33520
Policy Entropy: 3.73210
Value Function Loss: 0.02159

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.44925

Collected Steps per Second: 22,905.76201
Overall Steps per Second: 10,893.97433

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.40770
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.59135

Cumulative Model Updates: 133,898
Cumulative Timesteps: 1,116,527,112

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,276.33520
Policy Entropy: 3.71407
Value Function Loss: 0.02257

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.46071
Value Function Update Magnitude: 0.45211

Collected Steps per Second: 22,814.55260
Overall Steps per Second: 10,841.52851

Timestep Collection Time: 2.19237
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.61356

Cumulative Model Updates: 133,904
Cumulative Timesteps: 1,116,577,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1116577130...
Checkpoint 1116577130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,276.33520
Policy Entropy: 3.73068
Value Function Loss: 0.01832

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.44545
Value Function Update Magnitude: 0.43299

Collected Steps per Second: 22,994.32852
Overall Steps per Second: 10,712.56921

Timestep Collection Time: 2.17497
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66853

Cumulative Model Updates: 133,910
Cumulative Timesteps: 1,116,627,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280,895.14500
Policy Entropy: 3.70913
Value Function Loss: 0.02071

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.42580
Value Function Update Magnitude: 0.49949

Collected Steps per Second: 22,494.04968
Overall Steps per Second: 10,658.95854

Timestep Collection Time: 2.22379
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.69295

Cumulative Model Updates: 133,916
Cumulative Timesteps: 1,116,677,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1116677164...
Checkpoint 1116677164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,443.77215
Policy Entropy: 3.73129
Value Function Loss: 0.02152

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.44660
Value Function Update Magnitude: 0.44421

Collected Steps per Second: 22,439.24376
Overall Steps per Second: 10,892.21070

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.36352
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.59301

Cumulative Model Updates: 133,922
Cumulative Timesteps: 1,116,727,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,850.48203
Policy Entropy: 3.72351
Value Function Loss: 0.02312

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.47840
Value Function Update Magnitude: 0.49836

Collected Steps per Second: 22,223.83209
Overall Steps per Second: 10,874.82750

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.34812
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.59814

Cumulative Model Updates: 133,928
Cumulative Timesteps: 1,116,777,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1116777196...
Checkpoint 1116777196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,029.62705
Policy Entropy: 3.73516
Value Function Loss: 0.02179

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.49288
Value Function Update Magnitude: 0.53975

Collected Steps per Second: 22,150.19937
Overall Steps per Second: 10,719.20065

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.66770

Cumulative Model Updates: 133,934
Cumulative Timesteps: 1,116,827,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,308.21127
Policy Entropy: 3.73222
Value Function Loss: 0.02313

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.52865
Value Function Update Magnitude: 0.52616

Collected Steps per Second: 22,086.97346
Overall Steps per Second: 10,587.09636

Timestep Collection Time: 2.26450
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.72424

Cumulative Model Updates: 133,940
Cumulative Timesteps: 1,116,877,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1116877246...
Checkpoint 1116877246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,952.94924
Policy Entropy: 3.73666
Value Function Loss: 0.02092

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.51264
Value Function Update Magnitude: 0.52051

Collected Steps per Second: 23,004.84926
Overall Steps per Second: 10,959.89585

Timestep Collection Time: 2.17528
Timestep Consumption Time: 2.39064
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.56592

Cumulative Model Updates: 133,946
Cumulative Timesteps: 1,116,927,288

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,838.54561
Policy Entropy: 3.74818
Value Function Loss: 0.01972

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.46779
Value Function Update Magnitude: 0.53603

Collected Steps per Second: 23,107.34279
Overall Steps per Second: 10,964.80728

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.39795
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.56333

Cumulative Model Updates: 133,952
Cumulative Timesteps: 1,116,977,324

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1116977324...
Checkpoint 1116977324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,499.26212
Policy Entropy: 3.75563
Value Function Loss: 0.01824

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.44804
Value Function Update Magnitude: 0.46189

Collected Steps per Second: 22,791.12338
Overall Steps per Second: 10,682.85544

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.68189

Cumulative Model Updates: 133,958
Cumulative Timesteps: 1,117,027,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,030.12707
Policy Entropy: 3.74362
Value Function Loss: 0.02087

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.44633
Value Function Update Magnitude: 0.45413

Collected Steps per Second: 22,822.33052
Overall Steps per Second: 10,756.70662

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.65087

Cumulative Model Updates: 133,964
Cumulative Timesteps: 1,117,077,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1117077368...
Checkpoint 1117077368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228,687.62866
Policy Entropy: 3.74434
Value Function Loss: 0.02234

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.45730

Collected Steps per Second: 22,349.82602
Overall Steps per Second: 10,632.06507

Timestep Collection Time: 2.23832
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.70520

Cumulative Model Updates: 133,970
Cumulative Timesteps: 1,117,127,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,540.69051
Policy Entropy: 3.72452
Value Function Loss: 0.02510

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.51352
Value Function Update Magnitude: 0.48932

Collected Steps per Second: 22,858.84505
Overall Steps per Second: 10,852.11383

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.42016
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.60758

Cumulative Model Updates: 133,976
Cumulative Timesteps: 1,117,177,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1117177396...
Checkpoint 1117177396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,540.69051
Policy Entropy: 3.73184
Value Function Loss: 0.02177

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.53956
Value Function Update Magnitude: 0.53323

Collected Steps per Second: 22,883.76948
Overall Steps per Second: 10,712.62082

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.66889

Cumulative Model Updates: 133,982
Cumulative Timesteps: 1,117,227,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,787.91676
Policy Entropy: 3.71224
Value Function Loss: 0.02355

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.47653

Collected Steps per Second: 22,830.51867
Overall Steps per Second: 10,844.96527

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.61136

Cumulative Model Updates: 133,988
Cumulative Timesteps: 1,117,277,422

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1117277422...
Checkpoint 1117277422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,651.75876
Policy Entropy: 3.74492
Value Function Loss: 0.02019

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.45739
Value Function Update Magnitude: 0.53548

Collected Steps per Second: 22,276.30892
Overall Steps per Second: 10,703.64717

Timestep Collection Time: 2.24463
Timestep Consumption Time: 2.42686
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.67149

Cumulative Model Updates: 133,994
Cumulative Timesteps: 1,117,327,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,444.64874
Policy Entropy: 3.75232
Value Function Loss: 0.02065

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.43048
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 22,270.81244
Overall Steps per Second: 10,886.84656

Timestep Collection Time: 2.24572
Timestep Consumption Time: 2.34826
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59398

Cumulative Model Updates: 134,000
Cumulative Timesteps: 1,117,377,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1117377438...
Checkpoint 1117377438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,607.09224
Policy Entropy: 3.76960
Value Function Loss: 0.01714

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.40006
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 22,300.23082
Overall Steps per Second: 10,753.33836

Timestep Collection Time: 2.24249
Timestep Consumption Time: 2.40797
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.65046

Cumulative Model Updates: 134,006
Cumulative Timesteps: 1,117,427,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,107.77768
Policy Entropy: 3.74627
Value Function Loss: 0.01921

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.39567
Value Function Update Magnitude: 0.63049

Collected Steps per Second: 22,589.12789
Overall Steps per Second: 10,839.65601

Timestep Collection Time: 2.21345
Timestep Consumption Time: 2.39924
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.61269

Cumulative Model Updates: 134,012
Cumulative Timesteps: 1,117,477,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1117477446...
Checkpoint 1117477446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,274.31513
Policy Entropy: 3.75825
Value Function Loss: 0.01920

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.42619
Value Function Update Magnitude: 0.51598

Collected Steps per Second: 22,802.67523
Overall Steps per Second: 10,763.68620

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.45390
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.64785

Cumulative Model Updates: 134,018
Cumulative Timesteps: 1,117,527,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,900.12294
Policy Entropy: 3.74263
Value Function Loss: 0.01944

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.43719
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 23,274.11343
Overall Steps per Second: 10,826.15192

Timestep Collection Time: 2.14925
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.62048

Cumulative Model Updates: 134,024
Cumulative Timesteps: 1,117,577,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1117577496...
Checkpoint 1117577496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,263.46629
Policy Entropy: 3.74907
Value Function Loss: 0.02016

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.60995

Collected Steps per Second: 23,038.97140
Overall Steps per Second: 10,808.63713

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.45697
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.62834

Cumulative Model Updates: 134,030
Cumulative Timesteps: 1,117,627,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,074.99800
Policy Entropy: 3.76385
Value Function Loss: 0.02403

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.50060
Value Function Update Magnitude: 0.62407

Collected Steps per Second: 23,065.62060
Overall Steps per Second: 10,728.36981

Timestep Collection Time: 2.16808
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.66129

Cumulative Model Updates: 134,036
Cumulative Timesteps: 1,117,677,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1117677530...
Checkpoint 1117677530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,850.67323
Policy Entropy: 3.78615
Value Function Loss: 0.02489

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.49329
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 22,888.22965
Overall Steps per Second: 10,716.76499

Timestep Collection Time: 2.18470
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.66596

Cumulative Model Updates: 134,042
Cumulative Timesteps: 1,117,727,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,479.17899
Policy Entropy: 3.77882
Value Function Loss: 0.02637

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.51015
Value Function Update Magnitude: 0.53576

Collected Steps per Second: 22,853.02368
Overall Steps per Second: 10,789.29889

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.63552

Cumulative Model Updates: 134,048
Cumulative Timesteps: 1,117,777,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1117777548...
Checkpoint 1117777548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,460.22418
Policy Entropy: 3.77232
Value Function Loss: 0.02392

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.52161
Value Function Update Magnitude: 0.52134

Collected Steps per Second: 22,770.58925
Overall Steps per Second: 10,617.60604

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.71010

Cumulative Model Updates: 134,054
Cumulative Timesteps: 1,117,827,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,841.67820
Policy Entropy: 3.76561
Value Function Loss: 0.02458

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.53021
Value Function Update Magnitude: 0.51435

Collected Steps per Second: 22,563.58449
Overall Steps per Second: 10,629.41901

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70505

Cumulative Model Updates: 134,060
Cumulative Timesteps: 1,117,877,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1117877570...
Checkpoint 1117877570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,137.15483
Policy Entropy: 3.77494
Value Function Loss: 0.02165

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.53867
Value Function Update Magnitude: 0.51960

Collected Steps per Second: 22,964.31007
Overall Steps per Second: 10,860.79712

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60427

Cumulative Model Updates: 134,066
Cumulative Timesteps: 1,117,927,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,852.49924
Policy Entropy: 3.78776
Value Function Loss: 0.01738

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.52123
Value Function Update Magnitude: 0.49713

Collected Steps per Second: 23,035.68906
Overall Steps per Second: 10,911.76089

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.41205
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.58294

Cumulative Model Updates: 134,072
Cumulative Timesteps: 1,117,977,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1117977584...
Checkpoint 1117977584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,790.33490
Policy Entropy: 3.78984
Value Function Loss: 0.01469

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.48257
Value Function Update Magnitude: 0.49182

Collected Steps per Second: 23,012.72837
Overall Steps per Second: 10,715.57694

Timestep Collection Time: 2.17323
Timestep Consumption Time: 2.49399
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.66722

Cumulative Model Updates: 134,078
Cumulative Timesteps: 1,118,027,596

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.07548
Policy Entropy: 3.78405
Value Function Loss: 0.01391

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.45917
Value Function Update Magnitude: 0.51574

Collected Steps per Second: 23,218.36755
Overall Steps per Second: 10,912.12602

Timestep Collection Time: 2.15502
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.58536

Cumulative Model Updates: 134,084
Cumulative Timesteps: 1,118,077,632

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1118077632...
Checkpoint 1118077632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.64242
Policy Entropy: 3.77053
Value Function Loss: 0.01338

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06844
Policy Update Magnitude: 0.48725
Value Function Update Magnitude: 0.52948

Collected Steps per Second: 22,880.78791
Overall Steps per Second: 10,619.96932

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.52358
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.70943

Cumulative Model Updates: 134,090
Cumulative Timesteps: 1,118,127,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.64242
Policy Entropy: 3.77008
Value Function Loss: 0.01174

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.47641
Value Function Update Magnitude: 0.50494

Collected Steps per Second: 22,864.46805
Overall Steps per Second: 10,852.65387

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.42134
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.60901

Cumulative Model Updates: 134,096
Cumulative Timesteps: 1,118,177,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1118177666...
Checkpoint 1118177666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.75764
Value Function Loss: 0.01359

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.41573
Value Function Update Magnitude: 0.51095

Collected Steps per Second: 22,751.33640
Overall Steps per Second: 10,728.07013

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.66067

Cumulative Model Updates: 134,102
Cumulative Timesteps: 1,118,227,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.74975
Value Function Loss: 0.01332

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.42016
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 22,812.83496
Overall Steps per Second: 10,823.02581

Timestep Collection Time: 2.19245
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.62126

Cumulative Model Updates: 134,108
Cumulative Timesteps: 1,118,277,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1118277682...
Checkpoint 1118277682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.73696
Value Function Loss: 0.01457

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16549
Policy Update Magnitude: 0.42380
Value Function Update Magnitude: 0.55960

Collected Steps per Second: 22,436.18599
Overall Steps per Second: 10,693.93357

Timestep Collection Time: 2.22926
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.67704

Cumulative Model Updates: 134,114
Cumulative Timesteps: 1,118,327,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.74765
Value Function Loss: 0.01368

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.40547
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 22,856.80334
Overall Steps per Second: 10,873.02735

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.41148
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.59945

Cumulative Model Updates: 134,120
Cumulative Timesteps: 1,118,377,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1118377708...
Checkpoint 1118377708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.75035
Value Function Loss: 0.01494

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.39828
Value Function Update Magnitude: 0.47962

Collected Steps per Second: 22,857.42916
Overall Steps per Second: 10,675.56263

Timestep Collection Time: 2.18747
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.68359

Cumulative Model Updates: 134,126
Cumulative Timesteps: 1,118,427,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.74475
Value Function Loss: 0.01359

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.37031
Value Function Update Magnitude: 0.44414

Collected Steps per Second: 23,102.29727
Overall Steps per Second: 10,914.02218

Timestep Collection Time: 2.16437
Timestep Consumption Time: 2.41707
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.58145

Cumulative Model Updates: 134,132
Cumulative Timesteps: 1,118,477,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1118477710...
Checkpoint 1118477710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,946.01974
Policy Entropy: 3.73576
Value Function Loss: 0.01454

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14704
Policy Update Magnitude: 0.36198
Value Function Update Magnitude: 0.41960

Collected Steps per Second: 22,013.21700
Overall Steps per Second: 10,637.55302

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.42897
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.70033

Cumulative Model Updates: 134,138
Cumulative Timesteps: 1,118,527,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,616.43736
Policy Entropy: 3.73449
Value Function Loss: 0.01552

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.36894
Value Function Update Magnitude: 0.48382

Collected Steps per Second: 22,449.71856
Overall Steps per Second: 10,961.79334

Timestep Collection Time: 2.22952
Timestep Consumption Time: 2.33653
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.56604

Cumulative Model Updates: 134,144
Cumulative Timesteps: 1,118,577,762

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1118577762...
Checkpoint 1118577762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,396.36908
Policy Entropy: 3.74749
Value Function Loss: 0.01883

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14129
Policy Update Magnitude: 0.42702
Value Function Update Magnitude: 0.53008

Collected Steps per Second: 22,183.87665
Overall Steps per Second: 10,548.73084

Timestep Collection Time: 2.25389
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.73991

Cumulative Model Updates: 134,150
Cumulative Timesteps: 1,118,627,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,119.14542
Policy Entropy: 3.74065
Value Function Loss: 0.01970

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.44743
Value Function Update Magnitude: 0.45022

Collected Steps per Second: 23,153.32898
Overall Steps per Second: 10,921.84422

Timestep Collection Time: 2.16029
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.57963

Cumulative Model Updates: 134,156
Cumulative Timesteps: 1,118,677,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1118677780...
Checkpoint 1118677780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,119.14542
Policy Entropy: 3.73749
Value Function Loss: 0.01858

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.43797
Value Function Update Magnitude: 0.40588

Collected Steps per Second: 22,620.59825
Overall Steps per Second: 10,672.07865

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.68531

Cumulative Model Updates: 134,162
Cumulative Timesteps: 1,118,727,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,903.93719
Policy Entropy: 3.75041
Value Function Loss: 0.01863

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.44692
Value Function Update Magnitude: 0.40260

Collected Steps per Second: 22,807.83091
Overall Steps per Second: 10,836.88930

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.42174
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.61405

Cumulative Model Updates: 134,168
Cumulative Timesteps: 1,118,777,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1118777784...
Checkpoint 1118777784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,963.17766
Policy Entropy: 3.76454
Value Function Loss: 0.01907

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.44647
Value Function Update Magnitude: 0.47170

Collected Steps per Second: 22,872.12007
Overall Steps per Second: 10,664.69719

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69024

Cumulative Model Updates: 134,174
Cumulative Timesteps: 1,118,827,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,807.20723
Policy Entropy: 3.76213
Value Function Loss: 0.01824

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.44786
Value Function Update Magnitude: 0.50172

Collected Steps per Second: 23,171.83971
Overall Steps per Second: 10,953.57954

Timestep Collection Time: 2.15814
Timestep Consumption Time: 2.40731
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.56545

Cumulative Model Updates: 134,180
Cumulative Timesteps: 1,118,877,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1118877812...
Checkpoint 1118877812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,807.20723
Policy Entropy: 3.74350
Value Function Loss: 0.01760

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.42883
Value Function Update Magnitude: 0.49226

Collected Steps per Second: 22,496.98540
Overall Steps per Second: 10,596.08106

Timestep Collection Time: 2.22252
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.71873

Cumulative Model Updates: 134,186
Cumulative Timesteps: 1,118,927,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,807.20723
Policy Entropy: 3.72535
Value Function Loss: 0.01536

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.39410
Value Function Update Magnitude: 0.43626

Collected Steps per Second: 22,867.14466
Overall Steps per Second: 10,831.36921

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.61678

Cumulative Model Updates: 134,192
Cumulative Timesteps: 1,118,977,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1118977818...
Checkpoint 1118977818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,807.20723
Policy Entropy: 3.71960
Value Function Loss: 0.01507

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.41274
Value Function Update Magnitude: 0.44618

Collected Steps per Second: 22,811.91560
Overall Steps per Second: 10,720.98518

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66636

Cumulative Model Updates: 134,198
Cumulative Timesteps: 1,119,027,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,807.20723
Policy Entropy: 3.71891
Value Function Loss: 0.01549

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.40191
Value Function Update Magnitude: 0.41972

Collected Steps per Second: 22,190.93179
Overall Steps per Second: 10,840.33977

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.36055
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.61498

Cumulative Model Updates: 134,204
Cumulative Timesteps: 1,119,077,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1119077874...
Checkpoint 1119077874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,534.92734
Policy Entropy: 3.72408
Value Function Loss: 0.01731

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.40181
Value Function Update Magnitude: 0.37386

Collected Steps per Second: 21,913.90520
Overall Steps per Second: 10,675.21742

Timestep Collection Time: 2.28303
Timestep Consumption Time: 2.40353
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.68656

Cumulative Model Updates: 134,210
Cumulative Timesteps: 1,119,127,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,198.28336
Policy Entropy: 3.73952
Value Function Loss: 0.01905

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.45359
Value Function Update Magnitude: 0.44121

Collected Steps per Second: 22,058.69476
Overall Steps per Second: 10,851.24203

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.34137
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60832

Cumulative Model Updates: 134,216
Cumulative Timesteps: 1,119,177,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1119177910...
Checkpoint 1119177910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,061.74201
Policy Entropy: 3.74293
Value Function Loss: 0.02115

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.51827
Value Function Update Magnitude: 0.51253

Collected Steps per Second: 22,262.51548
Overall Steps per Second: 10,801.04956

Timestep Collection Time: 2.24692
Timestep Consumption Time: 2.38430
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.63122

Cumulative Model Updates: 134,222
Cumulative Timesteps: 1,119,227,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,061.74201
Policy Entropy: 3.74788
Value Function Loss: 0.01843

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13920
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.52209

Collected Steps per Second: 23,425.51240
Overall Steps per Second: 10,831.63599

Timestep Collection Time: 2.13528
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.61795

Cumulative Model Updates: 134,228
Cumulative Timesteps: 1,119,277,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1119277952...
Checkpoint 1119277952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,061.74201
Policy Entropy: 3.72814
Value Function Loss: 0.01791

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.48604
Value Function Update Magnitude: 0.47545

Collected Steps per Second: 22,613.33677
Overall Steps per Second: 10,637.85974

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70076

Cumulative Model Updates: 134,234
Cumulative Timesteps: 1,119,327,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,061.74201
Policy Entropy: 3.71498
Value Function Loss: 0.01434

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.41478
Value Function Update Magnitude: 0.40432

Collected Steps per Second: 23,004.75520
Overall Steps per Second: 10,858.66301

Timestep Collection Time: 2.17372
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.60517

Cumulative Model Updates: 134,240
Cumulative Timesteps: 1,119,377,964

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1119377964...
Checkpoint 1119377964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,061.74201
Policy Entropy: 3.70953
Value Function Loss: 0.01707

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.41490
Value Function Update Magnitude: 0.41962

Collected Steps per Second: 22,289.90236
Overall Steps per Second: 10,766.78091

Timestep Collection Time: 2.24353
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.64466

Cumulative Model Updates: 134,246
Cumulative Timesteps: 1,119,427,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,270.98875
Policy Entropy: 3.71942
Value Function Loss: 0.01703

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.45843
Value Function Update Magnitude: 0.48328

Collected Steps per Second: 22,972.10125
Overall Steps per Second: 10,905.56526

Timestep Collection Time: 2.17742
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.58665

Cumulative Model Updates: 134,252
Cumulative Timesteps: 1,119,477,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1119477992...
Checkpoint 1119477992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 434,625.31194
Policy Entropy: 3.72340
Value Function Loss: 0.02007

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.47958
Value Function Update Magnitude: 0.45590

Collected Steps per Second: 22,573.48162
Overall Steps per Second: 10,668.73247

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.68790

Cumulative Model Updates: 134,258
Cumulative Timesteps: 1,119,528,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434,625.31194
Policy Entropy: 3.72454
Value Function Loss: 0.01769

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.48151
Value Function Update Magnitude: 0.50315

Collected Steps per Second: 22,953.56778
Overall Steps per Second: 10,855.03410

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.42785
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.60616

Cumulative Model Updates: 134,264
Cumulative Timesteps: 1,119,578,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1119578006...
Checkpoint 1119578006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,306.72595
Policy Entropy: 3.71842
Value Function Loss: 0.01763

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.47706
Value Function Update Magnitude: 0.59156

Collected Steps per Second: 22,041.29054
Overall Steps per Second: 10,674.18261

Timestep Collection Time: 2.26938
Timestep Consumption Time: 2.41670
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68607

Cumulative Model Updates: 134,270
Cumulative Timesteps: 1,119,628,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554,904.51046
Policy Entropy: 3.73033
Value Function Loss: 0.01572

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.45992
Value Function Update Magnitude: 0.59485

Collected Steps per Second: 22,242.77423
Overall Steps per Second: 10,827.74659

Timestep Collection Time: 2.24882
Timestep Consumption Time: 2.37079
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.61961

Cumulative Model Updates: 134,276
Cumulative Timesteps: 1,119,678,046

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1119678046...
Checkpoint 1119678046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,077.65436
Policy Entropy: 3.73137
Value Function Loss: 0.01876

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.46446
Value Function Update Magnitude: 0.51892

Collected Steps per Second: 21,911.84988
Overall Steps per Second: 10,693.86827

Timestep Collection Time: 2.28196
Timestep Consumption Time: 2.39380
PPO Batch Consumption Time: 0.27591
Total Iteration Time: 4.67576

Cumulative Model Updates: 134,282
Cumulative Timesteps: 1,119,728,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,077.65436
Policy Entropy: 3.72046
Value Function Loss: 0.01847

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.45859
Value Function Update Magnitude: 0.48733

Collected Steps per Second: 23,099.89959
Overall Steps per Second: 10,870.22533

Timestep Collection Time: 2.16572
Timestep Consumption Time: 2.43657
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.60230

Cumulative Model Updates: 134,288
Cumulative Timesteps: 1,119,778,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1119778076...
Checkpoint 1119778076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,671.99417
Policy Entropy: 3.72133
Value Function Loss: 0.02195

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.46198
Value Function Update Magnitude: 0.42752

Collected Steps per Second: 21,926.98124
Overall Steps per Second: 10,654.72892

Timestep Collection Time: 2.28066
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.69350

Cumulative Model Updates: 134,294
Cumulative Timesteps: 1,119,828,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,163.96966
Policy Entropy: 3.73595
Value Function Loss: 0.01940

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.44385
Value Function Update Magnitude: 0.38055

Collected Steps per Second: 23,094.53256
Overall Steps per Second: 10,862.36975

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60526

Cumulative Model Updates: 134,300
Cumulative Timesteps: 1,119,878,108

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1119878108...
Checkpoint 1119878108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,163.96966
Policy Entropy: 3.74367
Value Function Loss: 0.01900

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.42191
Value Function Update Magnitude: 0.41124

Collected Steps per Second: 22,593.67227
Overall Steps per Second: 10,638.76986

Timestep Collection Time: 2.21389
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.70167

Cumulative Model Updates: 134,306
Cumulative Timesteps: 1,119,928,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,163.96966
Policy Entropy: 3.73608
Value Function Loss: 0.01598

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13636
Policy Update Magnitude: 0.42462
Value Function Update Magnitude: 0.45719

Collected Steps per Second: 22,654.20848
Overall Steps per Second: 10,712.18099

Timestep Collection Time: 2.20780
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66908

Cumulative Model Updates: 134,312
Cumulative Timesteps: 1,119,978,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1119978144...
Checkpoint 1119978144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,679.76657
Policy Entropy: 3.73731
Value Function Loss: 0.01621

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.46137
Value Function Update Magnitude: 0.51043

Collected Steps per Second: 22,652.82037
Overall Steps per Second: 10,838.06989

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.61466

Cumulative Model Updates: 134,318
Cumulative Timesteps: 1,120,028,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.73382
Value Function Loss: 0.01552

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 23,168.32843
Overall Steps per Second: 10,920.46999

Timestep Collection Time: 2.15890
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.58021

Cumulative Model Updates: 134,324
Cumulative Timesteps: 1,120,078,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1120078176...
Checkpoint 1120078176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.74181
Value Function Loss: 0.01540

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.45352
Value Function Update Magnitude: 0.61712

Collected Steps per Second: 22,952.35472
Overall Steps per Second: 10,731.61159

Timestep Collection Time: 2.17860
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.65951

Cumulative Model Updates: 134,330
Cumulative Timesteps: 1,120,128,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.72548
Value Function Loss: 0.01430

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.40078
Value Function Update Magnitude: 0.50621

Collected Steps per Second: 22,395.50035
Overall Steps per Second: 10,869.49344

Timestep Collection Time: 2.23420
Timestep Consumption Time: 2.36914
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.60334

Cumulative Model Updates: 134,336
Cumulative Timesteps: 1,120,178,216

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1120178216...
Checkpoint 1120178216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.72040
Value Function Loss: 0.01501

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13578
Policy Update Magnitude: 0.38343
Value Function Update Magnitude: 0.48909

Collected Steps per Second: 22,007.39145
Overall Steps per Second: 10,662.88255

Timestep Collection Time: 2.27260
Timestep Consumption Time: 2.41788
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69048

Cumulative Model Updates: 134,342
Cumulative Timesteps: 1,120,228,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.72662
Value Function Loss: 0.01481

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.42426
Value Function Update Magnitude: 0.43738

Collected Steps per Second: 22,654.58555
Overall Steps per Second: 10,833.31289

Timestep Collection Time: 2.20803
Timestep Consumption Time: 2.40939
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61742

Cumulative Model Updates: 134,348
Cumulative Timesteps: 1,120,278,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1120278252...
Checkpoint 1120278252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,650.26876
Policy Entropy: 3.72407
Value Function Loss: 0.01659

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.41823
Value Function Update Magnitude: 0.34499

Collected Steps per Second: 22,672.69374
Overall Steps per Second: 10,713.06817

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.46220
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.66776

Cumulative Model Updates: 134,354
Cumulative Timesteps: 1,120,328,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,241.41297
Policy Entropy: 3.73754
Value Function Loss: 0.01764

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.42721
Value Function Update Magnitude: 0.33877

Collected Steps per Second: 22,995.65562
Overall Steps per Second: 10,891.02655

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.59259

Cumulative Model Updates: 134,360
Cumulative Timesteps: 1,120,378,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1120378276...
Checkpoint 1120378276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,407.35617
Policy Entropy: 3.72568
Value Function Loss: 0.02055

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.49131
Value Function Update Magnitude: 0.42945

Collected Steps per Second: 22,917.65229
Overall Steps per Second: 10,742.91502

Timestep Collection Time: 2.18242
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.65572

Cumulative Model Updates: 134,366
Cumulative Timesteps: 1,120,428,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,407.35617
Policy Entropy: 3.73092
Value Function Loss: 0.01949

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.53492
Value Function Update Magnitude: 0.48847

Collected Steps per Second: 22,873.99543
Overall Steps per Second: 10,759.89905

Timestep Collection Time: 2.18676
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.64874

Cumulative Model Updates: 134,372
Cumulative Timesteps: 1,120,478,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1120478312...
Checkpoint 1120478312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,792.61240
Policy Entropy: 3.73623
Value Function Loss: 0.01899

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.54066
Value Function Update Magnitude: 0.54712

Collected Steps per Second: 22,812.49515
Overall Steps per Second: 10,634.30346

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.51099
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.70365

Cumulative Model Updates: 134,378
Cumulative Timesteps: 1,120,528,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,539.71458
Policy Entropy: 3.73730
Value Function Loss: 0.02013

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.59042
Value Function Update Magnitude: 0.66421

Collected Steps per Second: 22,948.30885
Overall Steps per Second: 10,860.83120

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.42528
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.60444

Cumulative Model Updates: 134,384
Cumulative Timesteps: 1,120,578,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1120578340...
Checkpoint 1120578340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,513.43585
Policy Entropy: 3.74164
Value Function Loss: 0.02564

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.61297
Value Function Update Magnitude: 0.70220

Collected Steps per Second: 22,936.04910
Overall Steps per Second: 10,716.36948

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.66669

Cumulative Model Updates: 134,390
Cumulative Timesteps: 1,120,628,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,734.54698
Policy Entropy: 3.74492
Value Function Loss: 0.02669

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.62761
Value Function Update Magnitude: 0.79283

Collected Steps per Second: 22,944.17132
Overall Steps per Second: 10,846.43843

Timestep Collection Time: 2.17946
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61036

Cumulative Model Updates: 134,396
Cumulative Timesteps: 1,120,678,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1120678356...
Checkpoint 1120678356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,935.96187
Policy Entropy: 3.75290
Value Function Loss: 0.02516

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.59877
Value Function Update Magnitude: 0.77897

Collected Steps per Second: 22,606.13746
Overall Steps per Second: 10,679.14016

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.68483

Cumulative Model Updates: 134,402
Cumulative Timesteps: 1,120,728,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,062.90820
Policy Entropy: 3.75174
Value Function Loss: 0.02094

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 22,852.03313
Overall Steps per Second: 10,832.32593

Timestep Collection Time: 2.18921
Timestep Consumption Time: 2.42918
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61840

Cumulative Model Updates: 134,408
Cumulative Timesteps: 1,120,778,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1120778414...
Checkpoint 1120778414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,651.66121
Policy Entropy: 3.75823
Value Function Loss: 0.02294

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.57564

Collected Steps per Second: 22,808.89285
Overall Steps per Second: 10,735.92805

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.65782

Cumulative Model Updates: 134,414
Cumulative Timesteps: 1,120,828,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,421.54690
Policy Entropy: 3.77729
Value Function Loss: 0.02322

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.59790
Value Function Update Magnitude: 0.65469

Collected Steps per Second: 23,106.33799
Overall Steps per Second: 10,869.98169

Timestep Collection Time: 2.16460
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.60130

Cumulative Model Updates: 134,420
Cumulative Timesteps: 1,120,878,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1120878436...
Checkpoint 1120878436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,730.58786
Policy Entropy: 3.77659
Value Function Loss: 0.02328

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.61223
Value Function Update Magnitude: 0.62649

Collected Steps per Second: 22,358.46754
Overall Steps per Second: 10,646.73862

Timestep Collection Time: 2.23781
Timestep Consumption Time: 2.46166
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.69947

Cumulative Model Updates: 134,426
Cumulative Timesteps: 1,120,928,470

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,536.54177
Policy Entropy: 3.76383
Value Function Loss: 0.02341

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.67443

Collected Steps per Second: 22,797.52851
Overall Steps per Second: 10,848.60051

Timestep Collection Time: 2.19383
Timestep Consumption Time: 2.41635
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61018

Cumulative Model Updates: 134,432
Cumulative Timesteps: 1,120,978,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1120978484...
Checkpoint 1120978484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,945.26077
Policy Entropy: 3.75647
Value Function Loss: 0.02283

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.59091
Value Function Update Magnitude: 0.76575

Collected Steps per Second: 22,566.61056
Overall Steps per Second: 10,716.30343

Timestep Collection Time: 2.21593
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.66635

Cumulative Model Updates: 134,438
Cumulative Timesteps: 1,121,028,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,842.44394
Policy Entropy: 3.76619
Value Function Loss: 0.02372

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.59555
Value Function Update Magnitude: 0.87266

Collected Steps per Second: 22,847.41271
Overall Steps per Second: 10,843.10660

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.61270

Cumulative Model Updates: 134,444
Cumulative Timesteps: 1,121,078,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1121078506...
Checkpoint 1121078506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.59123
Policy Entropy: 3.77806
Value Function Loss: 0.02292

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.78277

Collected Steps per Second: 22,829.23809
Overall Steps per Second: 10,663.26429

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.69068

Cumulative Model Updates: 134,450
Cumulative Timesteps: 1,121,128,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,862.97008
Policy Entropy: 3.76178
Value Function Loss: 0.02466

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.67962

Collected Steps per Second: 22,756.98875
Overall Steps per Second: 10,837.34001

Timestep Collection Time: 2.19739
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.61423

Cumulative Model Updates: 134,456
Cumulative Timesteps: 1,121,178,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1121178530...
Checkpoint 1121178530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,937.47584
Policy Entropy: 3.76940
Value Function Loss: 0.02498

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.65690

Collected Steps per Second: 22,061.19177
Overall Steps per Second: 10,726.94085

Timestep Collection Time: 2.26651
Timestep Consumption Time: 2.39483
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.66135

Cumulative Model Updates: 134,462
Cumulative Timesteps: 1,121,228,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,976.33479
Policy Entropy: 3.75126
Value Function Loss: 0.02746

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.61318
Value Function Update Magnitude: 0.55749

Collected Steps per Second: 22,364.39095
Overall Steps per Second: 10,933.23296

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.33845
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.57504

Cumulative Model Updates: 134,468
Cumulative Timesteps: 1,121,278,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1121278552...
Checkpoint 1121278552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,251.74350
Policy Entropy: 3.76095
Value Function Loss: 0.02617

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.59709
Value Function Update Magnitude: 0.53223

Collected Steps per Second: 21,880.27009
Overall Steps per Second: 10,605.70254

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.71595

Cumulative Model Updates: 134,474
Cumulative Timesteps: 1,121,328,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,939.83978
Policy Entropy: 3.75410
Value Function Loss: 0.02283

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.57614
Value Function Update Magnitude: 0.57301

Collected Steps per Second: 22,316.78917
Overall Steps per Second: 10,647.21570

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.69738

Cumulative Model Updates: 134,480
Cumulative Timesteps: 1,121,378,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1121378582...
Checkpoint 1121378582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,939.83978
Policy Entropy: 3.76952
Value Function Loss: 0.01915

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.56585
Value Function Update Magnitude: 0.49530

Collected Steps per Second: 22,945.90929
Overall Steps per Second: 10,976.68069

Timestep Collection Time: 2.17912
Timestep Consumption Time: 2.37617
PPO Batch Consumption Time: 0.27545
Total Iteration Time: 4.55529

Cumulative Model Updates: 134,486
Cumulative Timesteps: 1,121,428,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,442.37483
Policy Entropy: 3.76874
Value Function Loss: 0.01790

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.51342
Value Function Update Magnitude: 0.49099

Collected Steps per Second: 22,809.38652
Overall Steps per Second: 10,847.62519

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.41722
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.60930

Cumulative Model Updates: 134,492
Cumulative Timesteps: 1,121,478,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1121478584...
Checkpoint 1121478584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,434.12786
Policy Entropy: 3.76293
Value Function Loss: 0.01938

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.50238
Value Function Update Magnitude: 0.61906

Collected Steps per Second: 22,716.04575
Overall Steps per Second: 10,621.20118

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70926

Cumulative Model Updates: 134,498
Cumulative Timesteps: 1,121,528,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,616.76956
Policy Entropy: 3.75213
Value Function Loss: 0.01963

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.71315

Collected Steps per Second: 22,823.34463
Overall Steps per Second: 10,847.54900

Timestep Collection Time: 2.19197
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.61192

Cumulative Model Updates: 134,504
Cumulative Timesteps: 1,121,578,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1121578630...
Checkpoint 1121578630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,342.58344
Policy Entropy: 3.73082
Value Function Loss: 0.02596

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.56763
Value Function Update Magnitude: 0.66854

Collected Steps per Second: 23,039.64982
Overall Steps per Second: 10,727.27989

Timestep Collection Time: 2.17052
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66176

Cumulative Model Updates: 134,510
Cumulative Timesteps: 1,121,628,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,009.26783
Policy Entropy: 3.75714
Value Function Loss: 0.02486

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.59751
Value Function Update Magnitude: 0.68012

Collected Steps per Second: 23,135.40154
Overall Steps per Second: 10,906.22857

Timestep Collection Time: 2.16180
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.58582

Cumulative Model Updates: 134,516
Cumulative Timesteps: 1,121,678,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1121678652...
Checkpoint 1121678652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,351.44069
Policy Entropy: 3.74140
Value Function Loss: 0.02790

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.67134

Collected Steps per Second: 22,460.37170
Overall Steps per Second: 10,654.46572

Timestep Collection Time: 2.22686
Timestep Consumption Time: 2.46751
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.69437

Cumulative Model Updates: 134,522
Cumulative Timesteps: 1,121,728,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,351.44069
Policy Entropy: 3.74356
Value Function Loss: 0.02199

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.52476
Value Function Update Magnitude: 0.53857

Collected Steps per Second: 23,080.76029
Overall Steps per Second: 10,860.41438

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60756

Cumulative Model Updates: 134,528
Cumulative Timesteps: 1,121,778,708

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1121778708...
Checkpoint 1121778708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,601.88076
Policy Entropy: 3.71898
Value Function Loss: 0.02425

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.47334
Value Function Update Magnitude: 0.43235

Collected Steps per Second: 22,731.27931
Overall Steps per Second: 10,697.46972

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67438

Cumulative Model Updates: 134,534
Cumulative Timesteps: 1,121,828,712

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,330.98776
Policy Entropy: 3.73089
Value Function Loss: 0.02172

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.47391
Value Function Update Magnitude: 0.38588

Collected Steps per Second: 23,145.69389
Overall Steps per Second: 10,885.02875

Timestep Collection Time: 2.16083
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.59475

Cumulative Model Updates: 134,540
Cumulative Timesteps: 1,121,878,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1121878726...
Checkpoint 1121878726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,504.34771
Policy Entropy: 3.73794
Value Function Loss: 0.02386

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.51032
Value Function Update Magnitude: 0.39317

Collected Steps per Second: 22,693.82632
Overall Steps per Second: 10,631.04862

Timestep Collection Time: 2.20448
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.70584

Cumulative Model Updates: 134,546
Cumulative Timesteps: 1,121,928,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,133.64916
Policy Entropy: 3.74141
Value Function Loss: 0.02115

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.40573

Collected Steps per Second: 22,956.78867
Overall Steps per Second: 10,861.42627

Timestep Collection Time: 2.17896
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.60547

Cumulative Model Updates: 134,552
Cumulative Timesteps: 1,121,978,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1121978776...
Checkpoint 1121978776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,273.30203
Policy Entropy: 3.74815
Value Function Loss: 0.01987

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.48379
Value Function Update Magnitude: 0.40930

Collected Steps per Second: 22,790.13089
Overall Steps per Second: 10,714.72603

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.47373
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.66871

Cumulative Model Updates: 134,558
Cumulative Timesteps: 1,122,028,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,574.01988
Policy Entropy: 3.74189
Value Function Loss: 0.01892

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.45095
Value Function Update Magnitude: 0.41775

Collected Steps per Second: 22,970.78294
Overall Steps per Second: 10,861.62187

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60613

Cumulative Model Updates: 134,564
Cumulative Timesteps: 1,122,078,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1122078830...
Checkpoint 1122078830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,675.78443
Policy Entropy: 3.74378
Value Function Loss: 0.01947

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.48824
Value Function Update Magnitude: 0.49441

Collected Steps per Second: 22,936.06702
Overall Steps per Second: 10,693.28311

Timestep Collection Time: 2.18015
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.67621

Cumulative Model Updates: 134,570
Cumulative Timesteps: 1,122,128,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,061.94790
Policy Entropy: 3.75085
Value Function Loss: 0.01890

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14300
Policy Update Magnitude: 0.51579
Value Function Update Magnitude: 0.55480

Collected Steps per Second: 22,717.47135
Overall Steps per Second: 10,837.29300

Timestep Collection Time: 2.20192
Timestep Consumption Time: 2.41381
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.61573

Cumulative Model Updates: 134,576
Cumulative Timesteps: 1,122,178,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1122178856...
Checkpoint 1122178856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,016.63552
Policy Entropy: 3.76443
Value Function Loss: 0.01978

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13698
Policy Update Magnitude: 0.49017
Value Function Update Magnitude: 0.58940

Collected Steps per Second: 23,087.19868
Overall Steps per Second: 10,752.96722

Timestep Collection Time: 2.16622
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.65100

Cumulative Model Updates: 134,582
Cumulative Timesteps: 1,122,228,868

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,169.32576
Policy Entropy: 3.76372
Value Function Loss: 0.01924

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14817
Policy Update Magnitude: 0.50408
Value Function Update Magnitude: 0.58913

Collected Steps per Second: 22,961.77941
Overall Steps per Second: 10,904.73740

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.40850
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.58681

Cumulative Model Updates: 134,588
Cumulative Timesteps: 1,122,278,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1122278886...
Checkpoint 1122278886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,976.35598
Policy Entropy: 3.76281
Value Function Loss: 0.01877

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14829
Policy Update Magnitude: 0.49055
Value Function Update Magnitude: 0.57801

Collected Steps per Second: 23,090.80951
Overall Steps per Second: 10,779.92143

Timestep Collection Time: 2.16614
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.63992

Cumulative Model Updates: 134,594
Cumulative Timesteps: 1,122,328,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,616.65016
Policy Entropy: 3.76154
Value Function Loss: 0.01748

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.48305
Value Function Update Magnitude: 0.55915

Collected Steps per Second: 22,977.34192
Overall Steps per Second: 10,730.74977

Timestep Collection Time: 2.17719
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.66193

Cumulative Model Updates: 134,600
Cumulative Timesteps: 1,122,378,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1122378930...
Checkpoint 1122378930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,678.95029
Policy Entropy: 3.76811
Value Function Loss: 0.01831

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.19671
Policy Update Magnitude: 0.49593
Value Function Update Magnitude: 0.62275

Collected Steps per Second: 22,184.60523
Overall Steps per Second: 10,756.15332

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.39545
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.64999

Cumulative Model Updates: 134,606
Cumulative Timesteps: 1,122,428,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,155.90638
Policy Entropy: 3.79444
Value Function Loss: 0.03193

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.52984
Value Function Update Magnitude: 0.52150

Collected Steps per Second: 21,880.45827
Overall Steps per Second: 10,814.64734

Timestep Collection Time: 2.28524
Timestep Consumption Time: 2.33831
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.62354

Cumulative Model Updates: 134,612
Cumulative Timesteps: 1,122,478,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1122478948...
Checkpoint 1122478948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191,196.53459
Policy Entropy: 3.81885
Value Function Loss: 0.02716

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.63605
Value Function Update Magnitude: 0.43967

Collected Steps per Second: 22,174.99908
Overall Steps per Second: 10,752.56632

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.39555
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.65061

Cumulative Model Updates: 134,618
Cumulative Timesteps: 1,122,528,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,831.77018
Policy Entropy: 3.82998
Value Function Loss: 0.02757

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.65387
Value Function Update Magnitude: 0.37080

Collected Steps per Second: 22,179.61041
Overall Steps per Second: 10,765.63351

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.39056
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.64534

Cumulative Model Updates: 134,624
Cumulative Timesteps: 1,122,578,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1122578964...
Checkpoint 1122578964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,845.94779
Policy Entropy: 3.82469
Value Function Loss: 0.02417

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15142
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.40231

Collected Steps per Second: 22,440.37283
Overall Steps per Second: 10,660.29541

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.46345
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.69274

Cumulative Model Updates: 134,630
Cumulative Timesteps: 1,122,628,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 439.36069
Policy Entropy: 3.80625
Value Function Loss: 0.01997

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.64055

Collected Steps per Second: 23,035.93736
Overall Steps per Second: 10,873.23175

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.42832
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.59918

Cumulative Model Updates: 134,636
Cumulative Timesteps: 1,122,678,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1122678998...
Checkpoint 1122678998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,756.03015
Policy Entropy: 3.80058
Value Function Loss: 0.01875

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.65389
Value Function Update Magnitude: 0.68059

Collected Steps per Second: 23,102.79724
Overall Steps per Second: 11,001.47525

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.38089
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.54539

Cumulative Model Updates: 134,642
Cumulative Timesteps: 1,122,729,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.32219
Policy Entropy: 3.79048
Value Function Loss: 0.01839

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.64368
Value Function Update Magnitude: 0.72967

Collected Steps per Second: 22,854.70547
Overall Steps per Second: 10,728.82798

Timestep Collection Time: 2.18782
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.66053

Cumulative Model Updates: 134,648
Cumulative Timesteps: 1,122,779,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1122779006...
Checkpoint 1122779006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,578.86400
Policy Entropy: 3.78582
Value Function Loss: 0.01810

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06459
Policy Update Magnitude: 0.71446
Value Function Update Magnitude: 0.83746

Collected Steps per Second: 22,754.31171
Overall Steps per Second: 10,826.83572

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.42154
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.61963

Cumulative Model Updates: 134,654
Cumulative Timesteps: 1,122,829,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,616.05700
Policy Entropy: 3.75931
Value Function Loss: 0.01829

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06148
Policy Update Magnitude: 0.77138
Value Function Update Magnitude: 0.89104

Collected Steps per Second: 22,640.35540
Overall Steps per Second: 10,659.66389

Timestep Collection Time: 2.20915
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69208

Cumulative Model Updates: 134,660
Cumulative Timesteps: 1,122,879,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1122879038...
Checkpoint 1122879038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,796.21342
Policy Entropy: 3.76221
Value Function Loss: 0.01990

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.73618
Value Function Update Magnitude: 0.82540

Collected Steps per Second: 22,936.33628
Overall Steps per Second: 10,874.72377

Timestep Collection Time: 2.18038
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.59874

Cumulative Model Updates: 134,666
Cumulative Timesteps: 1,122,929,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,631.88604
Policy Entropy: 3.77467
Value Function Loss: 0.02690

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.20361
Policy Update Magnitude: 0.61034
Value Function Update Magnitude: 0.88292

Collected Steps per Second: 22,883.56212
Overall Steps per Second: 10,716.35236

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.66819

Cumulative Model Updates: 134,672
Cumulative Timesteps: 1,122,979,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1122979074...
Checkpoint 1122979074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,888.70044
Policy Entropy: 3.76484
Value Function Loss: 0.04181

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17142
Policy Update Magnitude: 0.69831
Value Function Update Magnitude: 0.71887

Collected Steps per Second: 22,781.04356
Overall Steps per Second: 10,870.17609

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.60140

Cumulative Model Updates: 134,678
Cumulative Timesteps: 1,123,029,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,389.97477
Policy Entropy: 3.78811
Value Function Loss: 0.04242

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.18390
Policy Update Magnitude: 0.70806
Value Function Update Magnitude: 0.55180

Collected Steps per Second: 22,828.49374
Overall Steps per Second: 10,737.47333

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.46684
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.65752

Cumulative Model Updates: 134,684
Cumulative Timesteps: 1,123,079,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1123079102...
Checkpoint 1123079102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,014.32076
Policy Entropy: 3.77794
Value Function Loss: 0.04068

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.66181
Value Function Update Magnitude: 0.59812

Collected Steps per Second: 22,722.42633
Overall Steps per Second: 10,837.02510

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.41421
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.61547

Cumulative Model Updates: 134,690
Cumulative Timesteps: 1,123,129,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,655.02728
Policy Entropy: 3.79512
Value Function Loss: 0.02991

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.62654
Value Function Update Magnitude: 0.66401

Collected Steps per Second: 22,794.69276
Overall Steps per Second: 10,870.14904

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.40761
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60233

Cumulative Model Updates: 134,696
Cumulative Timesteps: 1,123,179,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1123179148...
Checkpoint 1123179148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312,427.98456
Policy Entropy: 3.75879
Value Function Loss: 0.03357

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.61596

Collected Steps per Second: 22,965.98139
Overall Steps per Second: 10,754.52689

Timestep Collection Time: 2.17818
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.65144

Cumulative Model Updates: 134,702
Cumulative Timesteps: 1,123,229,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,017.53956
Policy Entropy: 3.77835
Value Function Loss: 0.02871

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.53005
Value Function Update Magnitude: 0.52194

Collected Steps per Second: 23,154.92602
Overall Steps per Second: 10,888.83151

Timestep Collection Time: 2.16049
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.59425

Cumulative Model Updates: 134,708
Cumulative Timesteps: 1,123,279,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1123279198...
Checkpoint 1123279198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,841.69748
Policy Entropy: 3.76822
Value Function Loss: 0.02823

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.52220
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 23,230.68561
Overall Steps per Second: 10,834.23783

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.46307
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.61574

Cumulative Model Updates: 134,714
Cumulative Timesteps: 1,123,329,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.29356
Policy Entropy: 3.78813
Value Function Loss: 0.02400

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.54937

Collected Steps per Second: 22,333.03776
Overall Steps per Second: 10,699.37331

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.67317

Cumulative Model Updates: 134,720
Cumulative Timesteps: 1,123,379,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1123379206...
Checkpoint 1123379206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,366.39266
Policy Entropy: 3.77541
Value Function Loss: 0.02364

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.50086
Value Function Update Magnitude: 0.52794

Collected Steps per Second: 22,444.30527
Overall Steps per Second: 10,837.19873

Timestep Collection Time: 2.22881
Timestep Consumption Time: 2.38715
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.61595

Cumulative Model Updates: 134,726
Cumulative Timesteps: 1,123,429,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,781.05538
Policy Entropy: 3.76368
Value Function Loss: 0.02176

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.49965
Value Function Update Magnitude: 0.53002

Collected Steps per Second: 22,496.81041
Overall Steps per Second: 10,795.66042

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.63297

Cumulative Model Updates: 134,732
Cumulative Timesteps: 1,123,479,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1123479246...
Checkpoint 1123479246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,212.51188
Policy Entropy: 3.75609
Value Function Loss: 0.02236

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.50894
Value Function Update Magnitude: 0.65585

Collected Steps per Second: 22,394.59900
Overall Steps per Second: 10,655.88505

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.69243

Cumulative Model Updates: 134,738
Cumulative Timesteps: 1,123,529,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,575.69929
Policy Entropy: 3.75471
Value Function Loss: 0.02189

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.49327
Value Function Update Magnitude: 0.72261

Collected Steps per Second: 22,994.50201
Overall Steps per Second: 10,819.73417

Timestep Collection Time: 2.17530
Timestep Consumption Time: 2.44773
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.62303

Cumulative Model Updates: 134,744
Cumulative Timesteps: 1,123,579,268

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1123579268...
Checkpoint 1123579268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,354.33902
Policy Entropy: 3.75620
Value Function Loss: 0.02063

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.47076
Value Function Update Magnitude: 0.70931

Collected Steps per Second: 23,087.42375
Overall Steps per Second: 10,870.19534

Timestep Collection Time: 2.16689
Timestep Consumption Time: 2.43542
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.60231

Cumulative Model Updates: 134,750
Cumulative Timesteps: 1,123,629,296

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.35993
Policy Entropy: 3.74186
Value Function Loss: 0.01823

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.44666
Value Function Update Magnitude: 0.58932

Collected Steps per Second: 22,762.92097
Overall Steps per Second: 10,692.93644

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.67823

Cumulative Model Updates: 134,756
Cumulative Timesteps: 1,123,679,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1123679320...
Checkpoint 1123679320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,375.35993
Policy Entropy: 3.72504
Value Function Loss: 0.01739

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.42446
Value Function Update Magnitude: 0.55667

Collected Steps per Second: 23,160.35830
Overall Steps per Second: 10,813.73461

Timestep Collection Time: 2.15990
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.62597

Cumulative Model Updates: 134,762
Cumulative Timesteps: 1,123,729,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,309.39028
Policy Entropy: 3.74254
Value Function Loss: 0.01876

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.42733
Value Function Update Magnitude: 0.61909

Collected Steps per Second: 22,696.08959
Overall Steps per Second: 10,726.08533

Timestep Collection Time: 2.20355
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.66265

Cumulative Model Updates: 134,768
Cumulative Timesteps: 1,123,779,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1123779356...
Checkpoint 1123779356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,314.44470
Policy Entropy: 3.77482
Value Function Loss: 0.02401

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.70816

Collected Steps per Second: 23,029.60622
Overall Steps per Second: 10,769.54966

Timestep Collection Time: 2.17147
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.64346

Cumulative Model Updates: 134,774
Cumulative Timesteps: 1,123,829,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,940.59674
Policy Entropy: 3.82888
Value Function Loss: 0.02592

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.85534

Collected Steps per Second: 23,112.22261
Overall Steps per Second: 10,756.79489

Timestep Collection Time: 2.16388
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.64934

Cumulative Model Updates: 134,780
Cumulative Timesteps: 1,123,879,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1123879376...
Checkpoint 1123879376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,537.25960
Policy Entropy: 3.82326
Value Function Loss: 0.02751

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.58516
Value Function Update Magnitude: 0.92882

Collected Steps per Second: 23,012.70674
Overall Steps per Second: 10,741.72074

Timestep Collection Time: 2.17280
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.65493

Cumulative Model Updates: 134,786
Cumulative Timesteps: 1,123,929,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,237.88331
Policy Entropy: 3.79234
Value Function Loss: 0.02566

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13255
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.84699

Collected Steps per Second: 22,838.68393
Overall Steps per Second: 10,828.67535

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.61866

Cumulative Model Updates: 134,792
Cumulative Timesteps: 1,123,979,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1123979392...
Checkpoint 1123979392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.95735
Policy Entropy: 3.76899
Value Function Loss: 0.02487

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.50818
Value Function Update Magnitude: 0.68732

Collected Steps per Second: 23,161.52768
Overall Steps per Second: 10,969.71398

Timestep Collection Time: 2.15884
Timestep Consumption Time: 2.39935
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.55819

Cumulative Model Updates: 134,798
Cumulative Timesteps: 1,124,029,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,926.67338
Policy Entropy: 3.75814
Value Function Loss: 0.02374

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.47987
Value Function Update Magnitude: 0.61624

Collected Steps per Second: 23,013.65760
Overall Steps per Second: 10,908.35612

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.58658

Cumulative Model Updates: 134,804
Cumulative Timesteps: 1,124,079,426

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1124079426...
Checkpoint 1124079426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,468.03445
Policy Entropy: 3.75991
Value Function Loss: 0.02234

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.49656
Value Function Update Magnitude: 0.56899

Collected Steps per Second: 22,367.94859
Overall Steps per Second: 10,738.84868

Timestep Collection Time: 2.23579
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.65692

Cumulative Model Updates: 134,810
Cumulative Timesteps: 1,124,129,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,852.99709
Policy Entropy: 3.76213
Value Function Loss: 0.02501

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.48905
Value Function Update Magnitude: 0.48534

Collected Steps per Second: 21,926.14209
Overall Steps per Second: 10,821.98576

Timestep Collection Time: 2.28084
Timestep Consumption Time: 2.34031
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.62115

Cumulative Model Updates: 134,816
Cumulative Timesteps: 1,124,179,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1124179446...
Checkpoint 1124179446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,079.32211
Policy Entropy: 3.74407
Value Function Loss: 0.02243

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.51499
Value Function Update Magnitude: 0.56581

Collected Steps per Second: 22,088.07989
Overall Steps per Second: 10,721.11534

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.40128
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.66612

Cumulative Model Updates: 134,822
Cumulative Timesteps: 1,124,229,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,284.55768
Policy Entropy: 3.74944
Value Function Loss: 0.02435

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.53051
Value Function Update Magnitude: 0.73424

Collected Steps per Second: 22,011.53704
Overall Steps per Second: 10,833.99537

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.34394
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.61584

Cumulative Model Updates: 134,828
Cumulative Timesteps: 1,124,279,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1124279480...
Checkpoint 1124279480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,986.12534
Policy Entropy: 3.74417
Value Function Loss: 0.02902

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.60936
Value Function Update Magnitude: 0.71214

Collected Steps per Second: 22,506.89397
Overall Steps per Second: 10,730.08974

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.66147

Cumulative Model Updates: 134,834
Cumulative Timesteps: 1,124,329,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,045.45657
Policy Entropy: 3.78555
Value Function Loss: 0.02951

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.62547
Value Function Update Magnitude: 0.70959

Collected Steps per Second: 22,790.12214
Overall Steps per Second: 10,916.30351

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.38761
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.58269

Cumulative Model Updates: 134,840
Cumulative Timesteps: 1,124,379,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1124379524...
Checkpoint 1124379524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,258.08055
Policy Entropy: 3.78719
Value Function Loss: 0.02950

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.60878
Value Function Update Magnitude: 0.74162

Collected Steps per Second: 22,595.08641
Overall Steps per Second: 10,739.70179

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.44412
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.65823

Cumulative Model Updates: 134,846
Cumulative Timesteps: 1,124,429,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,775.34856
Policy Entropy: 3.80611
Value Function Loss: 0.02498

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.69167

Collected Steps per Second: 22,989.30457
Overall Steps per Second: 10,753.65107

Timestep Collection Time: 2.17562
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.65107

Cumulative Model Updates: 134,852
Cumulative Timesteps: 1,124,479,568

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1124479568...
Checkpoint 1124479568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,208.99723
Policy Entropy: 3.77602
Value Function Loss: 0.02565

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.70440

Collected Steps per Second: 22,834.45649
Overall Steps per Second: 10,645.66551

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.50717
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.69694

Cumulative Model Updates: 134,858
Cumulative Timesteps: 1,124,529,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.89851
Policy Entropy: 3.76340
Value Function Loss: 0.02276

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 22,845.44588
Overall Steps per Second: 10,843.58465

Timestep Collection Time: 2.18880
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.61139

Cumulative Model Updates: 134,864
Cumulative Timesteps: 1,124,579,574

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1124579574...
Checkpoint 1124579574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.11449
Policy Entropy: 3.75161
Value Function Loss: 0.02648

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.50940
Value Function Update Magnitude: 0.52730

Collected Steps per Second: 22,933.94500
Overall Steps per Second: 10,696.83877

Timestep Collection Time: 2.18131
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.67671

Cumulative Model Updates: 134,870
Cumulative Timesteps: 1,124,629,600

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.25763
Policy Entropy: 3.77198
Value Function Loss: 0.02277

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14038
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.53593

Collected Steps per Second: 23,077.98508
Overall Steps per Second: 10,894.44733

Timestep Collection Time: 2.16717
Timestep Consumption Time: 2.42361
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.59078

Cumulative Model Updates: 134,876
Cumulative Timesteps: 1,124,679,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1124679614...
Checkpoint 1124679614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.87003
Policy Entropy: 3.77899
Value Function Loss: 0.02383

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.59231

Collected Steps per Second: 23,039.33750
Overall Steps per Second: 10,724.43514

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.66244

Cumulative Model Updates: 134,882
Cumulative Timesteps: 1,124,729,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,375.20360
Policy Entropy: 3.79128
Value Function Loss: 0.02059

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.47974
Value Function Update Magnitude: 0.51888

Collected Steps per Second: 22,802.58165
Overall Steps per Second: 10,854.15299

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.41409
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.60708

Cumulative Model Updates: 134,888
Cumulative Timesteps: 1,124,779,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1124779622...
Checkpoint 1124779622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,867.60121
Policy Entropy: 3.77687
Value Function Loss: 0.02123

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.44275
Value Function Update Magnitude: 0.44843

Collected Steps per Second: 23,004.63233
Overall Steps per Second: 10,763.08014

Timestep Collection Time: 2.17461
Timestep Consumption Time: 2.47332
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.64793

Cumulative Model Updates: 134,894
Cumulative Timesteps: 1,124,829,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,867.60121
Policy Entropy: 3.76489
Value Function Loss: 0.01772

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.43311
Value Function Update Magnitude: 0.47404

Collected Steps per Second: 23,006.33532
Overall Steps per Second: 10,765.30172

Timestep Collection Time: 2.17410
Timestep Consumption Time: 2.47213
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.64622

Cumulative Model Updates: 134,900
Cumulative Timesteps: 1,124,879,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1124879666...
Checkpoint 1124879666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,867.60121
Policy Entropy: 3.73413
Value Function Loss: 0.01774

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.41241
Value Function Update Magnitude: 0.46775

Collected Steps per Second: 22,255.80460
Overall Steps per Second: 10,716.22580

Timestep Collection Time: 2.24714
Timestep Consumption Time: 2.41980
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.66694

Cumulative Model Updates: 134,906
Cumulative Timesteps: 1,124,929,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,867.60121
Policy Entropy: 3.73810
Value Function Loss: 0.01523

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.36924
Value Function Update Magnitude: 0.38504

Collected Steps per Second: 22,260.79197
Overall Steps per Second: 10,902.70804

Timestep Collection Time: 2.24655
Timestep Consumption Time: 2.34038
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.58693

Cumulative Model Updates: 134,912
Cumulative Timesteps: 1,124,979,688

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1124979688...
Checkpoint 1124979688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,666.42366
Policy Entropy: 3.73585
Value Function Loss: 0.01577

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.37116
Value Function Update Magnitude: 0.40410

Collected Steps per Second: 22,326.85956
Overall Steps per Second: 10,632.09034

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.70293

Cumulative Model Updates: 134,918
Cumulative Timesteps: 1,125,029,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,315.73343
Policy Entropy: 3.73768
Value Function Loss: 0.01494

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.41410
Value Function Update Magnitude: 0.49991

Collected Steps per Second: 22,841.48973
Overall Steps per Second: 10,907.45921

Timestep Collection Time: 2.18961
Timestep Consumption Time: 2.39569
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.58530

Cumulative Model Updates: 134,924
Cumulative Timesteps: 1,125,079,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1125079704...
Checkpoint 1125079704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,315.73343
Policy Entropy: 3.73096
Value Function Loss: 0.01520

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.42901
Value Function Update Magnitude: 0.48887

Collected Steps per Second: 23,206.79677
Overall Steps per Second: 11,015.51571

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.38508
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.54014

Cumulative Model Updates: 134,930
Cumulative Timesteps: 1,125,129,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,315.73343
Policy Entropy: 3.72634
Value Function Loss: 0.01393

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.41193
Value Function Update Magnitude: 0.48089

Collected Steps per Second: 22,927.62484
Overall Steps per Second: 10,861.22548

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.60537

Cumulative Model Updates: 134,936
Cumulative Timesteps: 1,125,179,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1125179736...
Checkpoint 1125179736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,194.31784
Policy Entropy: 3.72316
Value Function Loss: 0.01754

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.46026
Value Function Update Magnitude: 0.55486

Collected Steps per Second: 23,117.37934
Overall Steps per Second: 10,750.84384

Timestep Collection Time: 2.16391
Timestep Consumption Time: 2.48912
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.65303

Cumulative Model Updates: 134,942
Cumulative Timesteps: 1,125,229,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,905.19108
Policy Entropy: 3.74023
Value Function Loss: 0.01902

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.50654
Value Function Update Magnitude: 0.65421

Collected Steps per Second: 23,002.16840
Overall Steps per Second: 10,878.87175

Timestep Collection Time: 2.17423
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.59717

Cumulative Model Updates: 134,948
Cumulative Timesteps: 1,125,279,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1125279772...
Checkpoint 1125279772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,307.51390
Policy Entropy: 3.75973
Value Function Loss: 0.02136

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.52422
Value Function Update Magnitude: 0.61598

Collected Steps per Second: 23,108.01883
Overall Steps per Second: 10,810.58912

Timestep Collection Time: 2.16505
Timestep Consumption Time: 2.46282
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.62787

Cumulative Model Updates: 134,954
Cumulative Timesteps: 1,125,329,802

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,307.51390
Policy Entropy: 3.76001
Value Function Loss: 0.01979

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 22,783.04195
Overall Steps per Second: 10,760.32356

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.64856

Cumulative Model Updates: 134,960
Cumulative Timesteps: 1,125,379,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1125379822...
Checkpoint 1125379822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,307.51390
Policy Entropy: 3.74452
Value Function Loss: 0.02011

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.48144
Value Function Update Magnitude: 0.57152

Collected Steps per Second: 23,100.29250
Overall Steps per Second: 10,858.05760

Timestep Collection Time: 2.16595
Timestep Consumption Time: 2.44206
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.60801

Cumulative Model Updates: 134,966
Cumulative Timesteps: 1,125,429,856

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,070.42814
Policy Entropy: 3.75109
Value Function Loss: 0.01834

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14559
Policy Update Magnitude: 0.47570
Value Function Update Magnitude: 0.53491

Collected Steps per Second: 22,032.55859
Overall Steps per Second: 10,667.81207

Timestep Collection Time: 2.27028
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.68887

Cumulative Model Updates: 134,972
Cumulative Timesteps: 1,125,479,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1125479876...
Checkpoint 1125479876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,456.33840
Policy Entropy: 3.75267
Value Function Loss: 0.01945

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.46609
Value Function Update Magnitude: 0.49065

Collected Steps per Second: 22,318.25883
Overall Steps per Second: 10,796.32862

Timestep Collection Time: 2.24148
Timestep Consumption Time: 2.39213
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.63361

Cumulative Model Updates: 134,978
Cumulative Timesteps: 1,125,529,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,154.51313
Policy Entropy: 3.75976
Value Function Loss: 0.01760

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.44127
Value Function Update Magnitude: 0.46330

Collected Steps per Second: 22,245.49089
Overall Steps per Second: 10,787.20857

Timestep Collection Time: 2.24900
Timestep Consumption Time: 2.38891
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.63790

Cumulative Model Updates: 134,984
Cumulative Timesteps: 1,125,579,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1125579932...
Checkpoint 1125579932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,406.28691
Policy Entropy: 3.74208
Value Function Loss: 0.02019

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.45104
Value Function Update Magnitude: 0.49944

Collected Steps per Second: 22,242.00910
Overall Steps per Second: 10,611.85260

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.46539
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.71492

Cumulative Model Updates: 134,990
Cumulative Timesteps: 1,125,629,966

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,845.23153
Policy Entropy: 3.74598
Value Function Loss: 0.01870

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13204
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.52315

Collected Steps per Second: 23,157.20590
Overall Steps per Second: 10,912.24462

Timestep Collection Time: 2.15924
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.58219

Cumulative Model Updates: 134,996
Cumulative Timesteps: 1,125,679,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1125679968...
Checkpoint 1125679968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267,977.63240
Policy Entropy: 3.75023
Value Function Loss: 0.02116

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.46981
Value Function Update Magnitude: 0.51931

Collected Steps per Second: 22,774.85561
Overall Steps per Second: 10,753.91805

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.45406
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.64947

Cumulative Model Updates: 135,002
Cumulative Timesteps: 1,125,729,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,656.08303
Policy Entropy: 3.76233
Value Function Loss: 0.01904

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.44998
Value Function Update Magnitude: 0.59478

Collected Steps per Second: 22,905.18737
Overall Steps per Second: 10,810.92603

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.44243
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62569

Cumulative Model Updates: 135,008
Cumulative Timesteps: 1,125,779,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1125779976...
Checkpoint 1125779976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,474.12228
Policy Entropy: 3.75211
Value Function Loss: 0.01954

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.47950
Value Function Update Magnitude: 0.68435

Collected Steps per Second: 22,692.29910
Overall Steps per Second: 10,653.71908

Timestep Collection Time: 2.20348
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.69338

Cumulative Model Updates: 135,014
Cumulative Timesteps: 1,125,829,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,520.05608
Policy Entropy: 3.75348
Value Function Loss: 0.01981

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.51443
Value Function Update Magnitude: 0.66975

Collected Steps per Second: 22,866.47133
Overall Steps per Second: 10,830.13646

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.43014
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.61675

Cumulative Model Updates: 135,020
Cumulative Timesteps: 1,125,879,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1125879978...
Checkpoint 1125879978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191,698.81087
Policy Entropy: 3.73465
Value Function Loss: 0.02344

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13879
Policy Update Magnitude: 0.52740
Value Function Update Magnitude: 0.59922

Collected Steps per Second: 22,226.50268
Overall Steps per Second: 10,623.77762

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.45735
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.70737

Cumulative Model Updates: 135,026
Cumulative Timesteps: 1,125,929,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,150.11050
Policy Entropy: 3.75995
Value Function Loss: 0.02239

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.56884
Value Function Update Magnitude: 0.62049

Collected Steps per Second: 23,117.49016
Overall Steps per Second: 10,913.00883

Timestep Collection Time: 2.16434
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.58480

Cumulative Model Updates: 135,032
Cumulative Timesteps: 1,125,980,022

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1125980022...
Checkpoint 1125980022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.00716
Policy Entropy: 3.75729
Value Function Loss: 0.02305

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.72360

Collected Steps per Second: 22,922.00704
Overall Steps per Second: 10,691.78330

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.49678
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.67948

Cumulative Model Updates: 135,038
Cumulative Timesteps: 1,126,030,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.00716
Policy Entropy: 3.75038
Value Function Loss: 0.02031

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.56957
Value Function Update Magnitude: 0.74300

Collected Steps per Second: 22,727.64760
Overall Steps per Second: 10,825.75527

Timestep Collection Time: 2.20076
Timestep Consumption Time: 2.41952
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.62028

Cumulative Model Updates: 135,044
Cumulative Timesteps: 1,126,080,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1126080072...
Checkpoint 1126080072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.00716
Policy Entropy: 3.70498
Value Function Loss: 0.01944

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.67892

Collected Steps per Second: 22,662.74165
Overall Steps per Second: 10,719.70072

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.66580

Cumulative Model Updates: 135,050
Cumulative Timesteps: 1,126,130,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.00716
Policy Entropy: 3.71489
Value Function Loss: 0.01659

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.69542

Collected Steps per Second: 23,074.23498
Overall Steps per Second: 10,962.61172

Timestep Collection Time: 2.16796
Timestep Consumption Time: 2.39519
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.56315

Cumulative Model Updates: 135,056
Cumulative Timesteps: 1,126,180,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1126180112...
Checkpoint 1126180112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,318.00716
Policy Entropy: 3.72287
Value Function Loss: 0.01512

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14306
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.71017

Collected Steps per Second: 22,754.09233
Overall Steps per Second: 10,680.16133

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.68270

Cumulative Model Updates: 135,062
Cumulative Timesteps: 1,126,230,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,901.89398
Policy Entropy: 3.72354
Value Function Loss: 0.01621

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.49323
Value Function Update Magnitude: 0.63250

Collected Steps per Second: 22,053.36058
Overall Steps per Second: 10,842.28677

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.34481
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.61250

Cumulative Model Updates: 135,068
Cumulative Timesteps: 1,126,280,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1126280134...
Checkpoint 1126280134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,472.32012
Policy Entropy: 3.71881
Value Function Loss: 0.01644

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.50888
Value Function Update Magnitude: 0.63344

Collected Steps per Second: 21,914.80943
Overall Steps per Second: 10,656.08493

Timestep Collection Time: 2.28220
Timestep Consumption Time: 2.41127
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.69347

Cumulative Model Updates: 135,074
Cumulative Timesteps: 1,126,330,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,551.84058
Policy Entropy: 3.73456
Value Function Loss: 0.01640

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.51016
Value Function Update Magnitude: 0.65999

Collected Steps per Second: 22,368.32089
Overall Steps per Second: 10,931.21818

Timestep Collection Time: 2.23584
Timestep Consumption Time: 2.33931
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.57515

Cumulative Model Updates: 135,080
Cumulative Timesteps: 1,126,380,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1126380160...
Checkpoint 1126380160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,522.22690
Policy Entropy: 3.73604
Value Function Loss: 0.01791

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.64610

Collected Steps per Second: 22,187.53144
Overall Steps per Second: 10,578.69197

Timestep Collection Time: 2.25433
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72818

Cumulative Model Updates: 135,086
Cumulative Timesteps: 1,126,430,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,587.71612
Policy Entropy: 3.75282
Value Function Loss: 0.01786

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.50225
Value Function Update Magnitude: 0.70840

Collected Steps per Second: 22,872.64157
Overall Steps per Second: 10,892.79198

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.40552
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.59276

Cumulative Model Updates: 135,092
Cumulative Timesteps: 1,126,480,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1126480206...
Checkpoint 1126480206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,061.09062
Policy Entropy: 3.73803
Value Function Loss: 0.01922

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.50616
Value Function Update Magnitude: 0.76625

Collected Steps per Second: 22,766.03556
Overall Steps per Second: 10,730.52269

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66389

Cumulative Model Updates: 135,098
Cumulative Timesteps: 1,126,530,252

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,803.91461
Policy Entropy: 3.74935
Value Function Loss: 0.02002

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.50967
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 22,970.49573
Overall Steps per Second: 10,912.05495

Timestep Collection Time: 2.17810
Timestep Consumption Time: 2.40692
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.58502

Cumulative Model Updates: 135,104
Cumulative Timesteps: 1,126,580,284

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1126580284...
Checkpoint 1126580284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,685.06212
Policy Entropy: 3.73778
Value Function Loss: 0.02199

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.62719

Collected Steps per Second: 22,750.71142
Overall Steps per Second: 10,706.15445

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.67077

Cumulative Model Updates: 135,110
Cumulative Timesteps: 1,126,630,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,909.71710
Policy Entropy: 3.74125
Value Function Loss: 0.02106

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.78612

Collected Steps per Second: 22,972.91052
Overall Steps per Second: 10,776.01973

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.64086

Cumulative Model Updates: 135,116
Cumulative Timesteps: 1,126,680,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1126680300...
Checkpoint 1126680300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,013.87571
Policy Entropy: 3.74930
Value Function Loss: 0.02555

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14309
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.81315

Collected Steps per Second: 22,794.14238
Overall Steps per Second: 10,654.93282

Timestep Collection Time: 2.19416
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.69398

Cumulative Model Updates: 135,122
Cumulative Timesteps: 1,126,730,314

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,511.48333
Policy Entropy: 3.76804
Value Function Loss: 0.02573

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.59804
Value Function Update Magnitude: 0.67447

Collected Steps per Second: 23,350.88462
Overall Steps per Second: 10,909.22035

Timestep Collection Time: 2.14193
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.58475

Cumulative Model Updates: 135,128
Cumulative Timesteps: 1,126,780,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1126780330...
Checkpoint 1126780330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,971.58468
Policy Entropy: 3.76584
Value Function Loss: 0.02582

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.55876
Value Function Update Magnitude: 0.69022

Collected Steps per Second: 22,714.35446
Overall Steps per Second: 10,653.43814

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69482

Cumulative Model Updates: 135,134
Cumulative Timesteps: 1,126,830,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493.73426
Policy Entropy: 3.77409
Value Function Loss: 0.02074

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.71265

Collected Steps per Second: 22,987.30426
Overall Steps per Second: 10,861.78541

Timestep Collection Time: 2.17546
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60403

Cumulative Model Updates: 135,140
Cumulative Timesteps: 1,126,880,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1126880354...
Checkpoint 1126880354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,086.15854
Policy Entropy: 3.76817
Value Function Loss: 0.02133

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.63955

Collected Steps per Second: 22,990.22433
Overall Steps per Second: 10,730.82442

Timestep Collection Time: 2.17501
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.65985

Cumulative Model Updates: 135,146
Cumulative Timesteps: 1,126,930,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,086.15854
Policy Entropy: 3.76247
Value Function Loss: 0.02021

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.58977

Collected Steps per Second: 23,290.95991
Overall Steps per Second: 10,847.39115

Timestep Collection Time: 2.14693
Timestep Consumption Time: 2.46284
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.60977

Cumulative Model Updates: 135,152
Cumulative Timesteps: 1,126,980,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1126980362...
Checkpoint 1126980362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,086.15854
Policy Entropy: 3.75357
Value Function Loss: 0.01916

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.53174
Value Function Update Magnitude: 0.54500

Collected Steps per Second: 22,886.53847
Overall Steps per Second: 10,716.88497

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66796

Cumulative Model Updates: 135,158
Cumulative Timesteps: 1,127,030,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,992.58831
Policy Entropy: 3.73520
Value Function Loss: 0.01799

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.47573
Value Function Update Magnitude: 0.48584

Collected Steps per Second: 23,351.10215
Overall Steps per Second: 10,801.59008

Timestep Collection Time: 2.14165
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.62987

Cumulative Model Updates: 135,164
Cumulative Timesteps: 1,127,080,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1127080398...
Checkpoint 1127080398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,992.58831
Policy Entropy: 3.72651
Value Function Loss: 0.01803

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.44111
Value Function Update Magnitude: 0.43172

Collected Steps per Second: 22,728.65335
Overall Steps per Second: 10,642.23519

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.49959
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.70052

Cumulative Model Updates: 135,170
Cumulative Timesteps: 1,127,130,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,992.58831
Policy Entropy: 3.71170
Value Function Loss: 0.01821

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.44546
Value Function Update Magnitude: 0.41006

Collected Steps per Second: 23,061.36482
Overall Steps per Second: 10,912.32187

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.41423
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.58271

Cumulative Model Updates: 135,176
Cumulative Timesteps: 1,127,180,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1127180430...
Checkpoint 1127180430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,992.58831
Policy Entropy: 3.71597
Value Function Loss: 0.01586

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.44435
Value Function Update Magnitude: 0.39330

Collected Steps per Second: 22,132.83338
Overall Steps per Second: 10,687.17985

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.41961
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.67888

Cumulative Model Updates: 135,182
Cumulative Timesteps: 1,127,230,434

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355,854.38644
Policy Entropy: 3.73361
Value Function Loss: 0.01700

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.45290
Value Function Update Magnitude: 0.48650

Collected Steps per Second: 22,586.54496
Overall Steps per Second: 10,864.37896

Timestep Collection Time: 2.21495
Timestep Consumption Time: 2.38983
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.60477

Cumulative Model Updates: 135,188
Cumulative Timesteps: 1,127,280,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1127280462...
Checkpoint 1127280462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,133.02090
Policy Entropy: 3.74456
Value Function Loss: 0.01694

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.50753
Value Function Update Magnitude: 0.62406

Collected Steps per Second: 22,207.20800
Overall Steps per Second: 10,633.80122

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.70255

Cumulative Model Updates: 135,194
Cumulative Timesteps: 1,127,330,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,105.78660
Policy Entropy: 3.73852
Value Function Loss: 0.02068

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.54051
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 23,227.66046
Overall Steps per Second: 11,024.96567

Timestep Collection Time: 2.15373
Timestep Consumption Time: 2.38379
PPO Batch Consumption Time: 0.27546
Total Iteration Time: 4.53752

Cumulative Model Updates: 135,200
Cumulative Timesteps: 1,127,380,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1127380494...
Checkpoint 1127380494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,418.86819
Policy Entropy: 3.74630
Value Function Loss: 0.02162

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 22,487.50458
Overall Steps per Second: 10,706.43661

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.44683
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67046

Cumulative Model Updates: 135,206
Cumulative Timesteps: 1,127,430,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,269.82067
Policy Entropy: 3.74025
Value Function Loss: 0.02276

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 23,264.19437
Overall Steps per Second: 10,748.23371

Timestep Collection Time: 2.15009
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.65379

Cumulative Model Updates: 135,212
Cumulative Timesteps: 1,127,480,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1127480518...
Checkpoint 1127480518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,674.73940
Policy Entropy: 3.74408
Value Function Loss: 0.02268

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.54855

Collected Steps per Second: 22,920.00581
Overall Steps per Second: 10,699.93004

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.49173
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.67349

Cumulative Model Updates: 135,218
Cumulative Timesteps: 1,127,530,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,951.46103
Policy Entropy: 3.75823
Value Function Loss: 0.02108

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.51804
Value Function Update Magnitude: 0.56716

Collected Steps per Second: 22,842.93300
Overall Steps per Second: 10,862.11913

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.60426

Cumulative Model Updates: 135,224
Cumulative Timesteps: 1,127,580,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1127580536...
Checkpoint 1127580536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,954.33649
Policy Entropy: 3.76235
Value Function Loss: 0.02190

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13514
Policy Update Magnitude: 0.47438
Value Function Update Magnitude: 0.49663

Collected Steps per Second: 22,560.74262
Overall Steps per Second: 10,650.85983

Timestep Collection Time: 2.21695
Timestep Consumption Time: 2.47901
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69596

Cumulative Model Updates: 135,230
Cumulative Timesteps: 1,127,630,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,544.50300
Policy Entropy: 3.75205
Value Function Loss: 0.02021

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.48089
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 23,079.09607
Overall Steps per Second: 10,904.88238

Timestep Collection Time: 2.16681
Timestep Consumption Time: 2.41903
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.58584

Cumulative Model Updates: 135,236
Cumulative Timesteps: 1,127,680,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1127680560...
Checkpoint 1127680560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,715.79237
Policy Entropy: 3.72910
Value Function Loss: 0.02515

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.51844
Value Function Update Magnitude: 0.63758

Collected Steps per Second: 23,032.14708
Overall Steps per Second: 10,775.85789

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.47051
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.64260

Cumulative Model Updates: 135,242
Cumulative Timesteps: 1,127,730,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,205.63902
Policy Entropy: 3.74138
Value Function Loss: 0.02214

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14313
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.67505

Collected Steps per Second: 23,237.20562
Overall Steps per Second: 10,757.68366

Timestep Collection Time: 2.15232
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.64914

Cumulative Model Updates: 135,248
Cumulative Timesteps: 1,127,780,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1127780602...
Checkpoint 1127780602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,769.22651
Policy Entropy: 3.72093
Value Function Loss: 0.02571

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.68175

Collected Steps per Second: 22,528.09670
Overall Steps per Second: 10,641.96958

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69838

Cumulative Model Updates: 135,254
Cumulative Timesteps: 1,127,830,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,900.17261
Policy Entropy: 3.74596
Value Function Loss: 0.02206

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.64217
Value Function Update Magnitude: 0.72134

Collected Steps per Second: 22,816.18949
Overall Steps per Second: 10,828.07377

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.61892

Cumulative Model Updates: 135,260
Cumulative Timesteps: 1,127,880,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1127880616...
Checkpoint 1127880616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,000.32386
Policy Entropy: 3.72598
Value Function Loss: 0.02735

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.61969
Value Function Update Magnitude: 0.72464

Collected Steps per Second: 22,778.35837
Overall Steps per Second: 10,707.39910

Timestep Collection Time: 2.19507
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.66967

Cumulative Model Updates: 135,266
Cumulative Timesteps: 1,127,930,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,994.67634
Policy Entropy: 3.75970
Value Function Loss: 0.02286

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.62421
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 23,157.37598
Overall Steps per Second: 10,896.44098

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.59012

Cumulative Model Updates: 135,272
Cumulative Timesteps: 1,127,980,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1127980632...
Checkpoint 1127980632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,967.32831
Policy Entropy: 3.75083
Value Function Loss: 0.02912

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.64206
Value Function Update Magnitude: 0.59005

Collected Steps per Second: 22,959.61488
Overall Steps per Second: 10,733.94928

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.66054

Cumulative Model Updates: 135,278
Cumulative Timesteps: 1,128,030,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,395.25914
Policy Entropy: 3.77789
Value Function Loss: 0.03188

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.69690
Value Function Update Magnitude: 0.63673

Collected Steps per Second: 22,769.54214
Overall Steps per Second: 10,821.75111

Timestep Collection Time: 2.19636
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62125

Cumulative Model Updates: 135,284
Cumulative Timesteps: 1,128,080,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1128080668...
Checkpoint 1128080668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,787.13393
Policy Entropy: 3.77253
Value Function Loss: 0.03318

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.70755
Value Function Update Magnitude: 0.70178

Collected Steps per Second: 22,935.42639
Overall Steps per Second: 10,711.79411

Timestep Collection Time: 2.18047
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.66869

Cumulative Model Updates: 135,290
Cumulative Timesteps: 1,128,130,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.19911
Policy Entropy: 3.77634
Value Function Loss: 0.02810

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.71531
Value Function Update Magnitude: 0.72462

Collected Steps per Second: 23,125.35362
Overall Steps per Second: 10,857.11235

Timestep Collection Time: 2.16213
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.60528

Cumulative Model Updates: 135,296
Cumulative Timesteps: 1,128,180,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1128180678...
Checkpoint 1128180678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.48956
Policy Entropy: 3.76196
Value Function Loss: 0.02596

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.61048
Value Function Update Magnitude: 0.73544

Collected Steps per Second: 22,875.96965
Overall Steps per Second: 10,721.18127

Timestep Collection Time: 2.18570
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.66367

Cumulative Model Updates: 135,302
Cumulative Timesteps: 1,128,230,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.48956
Policy Entropy: 3.74070
Value Function Loss: 0.01946

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15306
Policy Update Magnitude: 0.51729
Value Function Update Magnitude: 0.62155

Collected Steps per Second: 23,081.43157
Overall Steps per Second: 10,799.26665

Timestep Collection Time: 2.16685
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.63124

Cumulative Model Updates: 135,308
Cumulative Timesteps: 1,128,280,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1128280692...
Checkpoint 1128280692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.48956
Policy Entropy: 3.73270
Value Function Loss: 0.01725

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.46058
Value Function Update Magnitude: 0.62446

Collected Steps per Second: 23,030.25844
Overall Steps per Second: 10,770.11118

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.64452

Cumulative Model Updates: 135,314
Cumulative Timesteps: 1,128,330,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,485.30993
Policy Entropy: 3.71541
Value Function Loss: 0.01547

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15606
Policy Update Magnitude: 0.45540
Value Function Update Magnitude: 0.53918

Collected Steps per Second: 23,242.66506
Overall Steps per Second: 10,772.31515

Timestep Collection Time: 2.15139
Timestep Consumption Time: 2.49051
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.64190

Cumulative Model Updates: 135,320
Cumulative Timesteps: 1,128,380,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1128380718...
Checkpoint 1128380718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756,942.02166
Policy Entropy: 3.73844
Value Function Loss: 0.01802

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.44950
Value Function Update Magnitude: 0.50551

Collected Steps per Second: 22,183.36481
Overall Steps per Second: 10,729.81873

Timestep Collection Time: 2.25565
Timestep Consumption Time: 2.40780
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.66345

Cumulative Model Updates: 135,326
Cumulative Timesteps: 1,128,430,756

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,088.47361
Policy Entropy: 3.74481
Value Function Loss: 0.02002

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.47718
Value Function Update Magnitude: 0.53046

Collected Steps per Second: 22,372.62442
Overall Steps per Second: 10,793.08853

Timestep Collection Time: 2.23577
Timestep Consumption Time: 2.39868
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.63445

Cumulative Model Updates: 135,332
Cumulative Timesteps: 1,128,480,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1128480776...
Checkpoint 1128480776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,975.22894
Policy Entropy: 3.75145
Value Function Loss: 0.02162

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.53675
Value Function Update Magnitude: 0.55424

Collected Steps per Second: 22,098.91854
Overall Steps per Second: 10,708.09550

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.40874
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67310

Cumulative Model Updates: 135,338
Cumulative Timesteps: 1,128,530,816

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,569.57562
Policy Entropy: 3.74459
Value Function Loss: 0.02103

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.53780
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 22,445.60741
Overall Steps per Second: 10,823.92311

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.39294
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62161

Cumulative Model Updates: 135,344
Cumulative Timesteps: 1,128,580,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1128580840...
Checkpoint 1128580840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,102.78970
Policy Entropy: 3.75094
Value Function Loss: 0.02482

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.58120

Collected Steps per Second: 22,660.46813
Overall Steps per Second: 10,670.29418

Timestep Collection Time: 2.20790
Timestep Consumption Time: 2.48101
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68891

Cumulative Model Updates: 135,350
Cumulative Timesteps: 1,128,630,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,740.32783
Policy Entropy: 3.75001
Value Function Loss: 0.02332

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.54528

Collected Steps per Second: 23,101.62202
Overall Steps per Second: 10,905.55566

Timestep Collection Time: 2.16565
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.58757

Cumulative Model Updates: 135,356
Cumulative Timesteps: 1,128,680,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1128680902...
Checkpoint 1128680902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,698.59951
Policy Entropy: 3.74903
Value Function Loss: 0.02500

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.51718

Collected Steps per Second: 22,974.50134
Overall Steps per Second: 10,729.19378

Timestep Collection Time: 2.17633
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66018

Cumulative Model Updates: 135,362
Cumulative Timesteps: 1,128,730,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,401.28878
Policy Entropy: 3.76170
Value Function Loss: 0.02124

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.61362

Collected Steps per Second: 23,492.69566
Overall Steps per Second: 10,817.46837

Timestep Collection Time: 2.12934
Timestep Consumption Time: 2.49503
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.62437

Cumulative Model Updates: 135,368
Cumulative Timesteps: 1,128,780,926

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1128780926...
Checkpoint 1128780926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,856.84150
Policy Entropy: 3.76610
Value Function Loss: 0.02273

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.56832
Value Function Update Magnitude: 0.70233

Collected Steps per Second: 22,565.67155
Overall Steps per Second: 10,637.44459

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.48522
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.70151

Cumulative Model Updates: 135,374
Cumulative Timesteps: 1,128,830,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,610.19758
Policy Entropy: 3.77191
Value Function Loss: 0.02312

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.60685
Value Function Update Magnitude: 0.68138

Collected Steps per Second: 23,024.23465
Overall Steps per Second: 10,872.29174

Timestep Collection Time: 2.17223
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.60013

Cumulative Model Updates: 135,380
Cumulative Timesteps: 1,128,880,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1128880952...
Checkpoint 1128880952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,238.44727
Policy Entropy: 3.74125
Value Function Loss: 0.02289

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.61584
Value Function Update Magnitude: 0.80281

Collected Steps per Second: 22,959.00447
Overall Steps per Second: 10,688.56536

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.67827

Cumulative Model Updates: 135,386
Cumulative Timesteps: 1,128,930,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,296.30621
Policy Entropy: 3.72859
Value Function Loss: 0.02180

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.58257
Value Function Update Magnitude: 0.71430

Collected Steps per Second: 22,989.21255
Overall Steps per Second: 10,892.64629

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.59227

Cumulative Model Updates: 135,392
Cumulative Timesteps: 1,128,980,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1128980978...
Checkpoint 1128980978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,296.30621
Policy Entropy: 3.71451
Value Function Loss: 0.02086

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.68606

Collected Steps per Second: 23,205.34030
Overall Steps per Second: 10,776.82327

Timestep Collection Time: 2.15493
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.64014

Cumulative Model Updates: 135,398
Cumulative Timesteps: 1,129,030,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,967.24855
Policy Entropy: 3.72597
Value Function Loss: 0.02117

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.57450
Value Function Update Magnitude: 0.63068

Collected Steps per Second: 22,969.69745
Overall Steps per Second: 10,810.89028

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.62534

Cumulative Model Updates: 135,404
Cumulative Timesteps: 1,129,080,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1129080988...
Checkpoint 1129080988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,335.41803
Policy Entropy: 3.75581
Value Function Loss: 0.02091

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.58979
Value Function Update Magnitude: 0.58009

Collected Steps per Second: 23,254.02991
Overall Steps per Second: 10,783.80701

Timestep Collection Time: 2.15085
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.63807

Cumulative Model Updates: 135,410
Cumulative Timesteps: 1,129,131,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,062.95165
Policy Entropy: 3.77083
Value Function Loss: 0.01983

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.56440

Collected Steps per Second: 23,405.43351
Overall Steps per Second: 10,804.19290

Timestep Collection Time: 2.13779
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.63116

Cumulative Model Updates: 135,416
Cumulative Timesteps: 1,129,181,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1129181040...
Checkpoint 1129181040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,680.21741
Policy Entropy: 3.76529
Value Function Loss: 0.01677

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.67183

Collected Steps per Second: 22,956.12245
Overall Steps per Second: 10,778.74783

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.63969

Cumulative Model Updates: 135,422
Cumulative Timesteps: 1,129,231,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,925.20569
Policy Entropy: 3.73655
Value Function Loss: 0.01849

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.45812
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 22,913.15908
Overall Steps per Second: 10,717.38592

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.66905

Cumulative Model Updates: 135,428
Cumulative Timesteps: 1,129,281,090

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1129281090...
Checkpoint 1129281090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,336.32181
Policy Entropy: 3.74375
Value Function Loss: 0.02320

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.53543
Value Function Update Magnitude: 0.68752

Collected Steps per Second: 22,931.30633
Overall Steps per Second: 10,708.75538

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.48995
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67150

Cumulative Model Updates: 135,434
Cumulative Timesteps: 1,129,331,116

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,750.50501
Policy Entropy: 3.75557
Value Function Loss: 0.02617

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.63994

Collected Steps per Second: 23,213.84775
Overall Steps per Second: 10,840.89800

Timestep Collection Time: 2.15483
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.61419

Cumulative Model Updates: 135,440
Cumulative Timesteps: 1,129,381,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1129381138...
Checkpoint 1129381138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,508.32078
Policy Entropy: 3.79253
Value Function Loss: 0.02877

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.59557
Value Function Update Magnitude: 0.49398

Collected Steps per Second: 22,917.19927
Overall Steps per Second: 10,710.76410

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.66932

Cumulative Model Updates: 135,446
Cumulative Timesteps: 1,129,431,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.48659
Policy Entropy: 3.79256
Value Function Loss: 0.02350

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.57332
Value Function Update Magnitude: 0.47213

Collected Steps per Second: 22,909.71627
Overall Steps per Second: 10,868.03095

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.60212

Cumulative Model Updates: 135,452
Cumulative Timesteps: 1,129,481,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1129481166...
Checkpoint 1129481166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,906.00922
Policy Entropy: 3.79203
Value Function Loss: 0.02041

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.54938

Collected Steps per Second: 22,766.39830
Overall Steps per Second: 10,682.06340

Timestep Collection Time: 2.19648
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.68131

Cumulative Model Updates: 135,458
Cumulative Timesteps: 1,129,531,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,604.00479
Policy Entropy: 3.76814
Value Function Loss: 0.02001

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.52587
Value Function Update Magnitude: 0.50142

Collected Steps per Second: 23,106.47154
Overall Steps per Second: 10,822.60144

Timestep Collection Time: 2.16476
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.62181

Cumulative Model Updates: 135,464
Cumulative Timesteps: 1,129,581,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1129581192...
Checkpoint 1129581192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.42003
Policy Entropy: 3.75834
Value Function Loss: 0.01993

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.48964
Value Function Update Magnitude: 0.53180

Collected Steps per Second: 22,809.71535
Overall Steps per Second: 10,657.92703

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.50040
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.69341

Cumulative Model Updates: 135,470
Cumulative Timesteps: 1,129,631,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.42003
Policy Entropy: 3.74648
Value Function Loss: 0.01810

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.48099
Value Function Update Magnitude: 0.48316

Collected Steps per Second: 23,219.99026
Overall Steps per Second: 10,948.89233

Timestep Collection Time: 2.15461
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.56941

Cumulative Model Updates: 135,476
Cumulative Timesteps: 1,129,681,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1129681244...
Checkpoint 1129681244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,376.42003
Policy Entropy: 3.72130
Value Function Loss: 0.02136

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.50306
Value Function Update Magnitude: 0.45949

Collected Steps per Second: 22,885.12116
Overall Steps per Second: 10,715.86788

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66766

Cumulative Model Updates: 135,482
Cumulative Timesteps: 1,129,731,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,626.81848
Policy Entropy: 3.73094
Value Function Loss: 0.02065

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.54294
Value Function Update Magnitude: 0.47814

Collected Steps per Second: 23,189.01762
Overall Steps per Second: 10,796.89426

Timestep Collection Time: 2.15654
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.63170

Cumulative Model Updates: 135,488
Cumulative Timesteps: 1,129,781,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1129781270...
Checkpoint 1129781270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,557.37477
Policy Entropy: 3.73222
Value Function Loss: 0.02513

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.56757

Collected Steps per Second: 22,953.87435
Overall Steps per Second: 10,728.59027

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.66100

Cumulative Model Updates: 135,494
Cumulative Timesteps: 1,129,831,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,963.42058
Policy Entropy: 3.76798
Value Function Loss: 0.02186

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.58868

Collected Steps per Second: 23,307.86750
Overall Steps per Second: 10,811.53113

Timestep Collection Time: 2.14631
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.62710

Cumulative Model Updates: 135,500
Cumulative Timesteps: 1,129,881,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1129881302...
Checkpoint 1129881302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,327.74551
Policy Entropy: 3.75970
Value Function Loss: 0.02297

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.54946
Value Function Update Magnitude: 0.54170

Collected Steps per Second: 22,858.96562
Overall Steps per Second: 10,677.69302

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.49633
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.68453

Cumulative Model Updates: 135,506
Cumulative Timesteps: 1,129,931,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.64409
Policy Entropy: 3.76816
Value Function Loss: 0.01798

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.50237
Value Function Update Magnitude: 0.53092

Collected Steps per Second: 23,168.53294
Overall Steps per Second: 10,935.16859

Timestep Collection Time: 2.15836
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.27610
Total Iteration Time: 4.57295

Cumulative Model Updates: 135,512
Cumulative Timesteps: 1,129,981,328

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1129981328...
Checkpoint 1129981328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,434.03872
Policy Entropy: 3.75607
Value Function Loss: 0.01939

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.46166
Value Function Update Magnitude: 0.51956

Collected Steps per Second: 22,729.10434
Overall Steps per Second: 10,682.69889

Timestep Collection Time: 2.20000
Timestep Consumption Time: 2.48084
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.68084

Cumulative Model Updates: 135,518
Cumulative Timesteps: 1,130,031,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,807.52306
Policy Entropy: 3.76751
Value Function Loss: 0.01727

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.47826
Value Function Update Magnitude: 0.55454

Collected Steps per Second: 23,106.07159
Overall Steps per Second: 10,800.91058

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.46669
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.63183

Cumulative Model Updates: 135,524
Cumulative Timesteps: 1,130,081,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1130081360...
Checkpoint 1130081360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.92913
Policy Entropy: 3.75307
Value Function Loss: 0.01957

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.51670
Value Function Update Magnitude: 0.66281

Collected Steps per Second: 22,857.85310
Overall Steps per Second: 10,675.59835

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68564

Cumulative Model Updates: 135,530
Cumulative Timesteps: 1,130,131,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,243.47326
Policy Entropy: 3.77438
Value Function Loss: 0.01908

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.76783

Collected Steps per Second: 23,071.14614
Overall Steps per Second: 10,924.06671

Timestep Collection Time: 2.16790
Timestep Consumption Time: 2.41061
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.57851

Cumulative Model Updates: 135,536
Cumulative Timesteps: 1,130,181,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1130181398...
Checkpoint 1130181398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,243.47326
Policy Entropy: 3.76113
Value Function Loss: 0.01931

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.81342

Collected Steps per Second: 22,609.26731
Overall Steps per Second: 10,637.12897

Timestep Collection Time: 2.21201
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70164

Cumulative Model Updates: 135,542
Cumulative Timesteps: 1,130,231,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,243.47326
Policy Entropy: 3.76520
Value Function Loss: 0.01790

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.75631

Collected Steps per Second: 23,047.75332
Overall Steps per Second: 10,854.90666

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.43866
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.60971

Cumulative Model Updates: 135,548
Cumulative Timesteps: 1,130,281,448

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1130281448...
Checkpoint 1130281448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721,925.06509
Policy Entropy: 3.74623
Value Function Loss: 0.02050

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.55308
Value Function Update Magnitude: 0.62327

Collected Steps per Second: 22,846.34976
Overall Steps per Second: 10,696.12721

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.48745
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67721

Cumulative Model Updates: 135,554
Cumulative Timesteps: 1,130,331,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331,474.87016
Policy Entropy: 3.75929
Value Function Loss: 0.02257

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.59906
Value Function Update Magnitude: 0.61107

Collected Steps per Second: 23,346.38197
Overall Steps per Second: 10,862.45315

Timestep Collection Time: 2.14209
Timestep Consumption Time: 2.46184
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.60393

Cumulative Model Updates: 135,560
Cumulative Timesteps: 1,130,381,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1130381486...
Checkpoint 1130381486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,366.88066
Policy Entropy: 3.77889
Value Function Loss: 0.02562

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.62032
Value Function Update Magnitude: 0.55824

Collected Steps per Second: 22,856.94965
Overall Steps per Second: 10,737.06412

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.47043
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.65900

Cumulative Model Updates: 135,566
Cumulative Timesteps: 1,130,431,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.77637
Policy Entropy: 3.79342
Value Function Loss: 0.02236

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.59895

Collected Steps per Second: 23,291.08217
Overall Steps per Second: 10,765.00997

Timestep Collection Time: 2.14700
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.64523

Cumulative Model Updates: 135,572
Cumulative Timesteps: 1,130,481,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1130481516...
Checkpoint 1130481516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,900.00409
Policy Entropy: 3.79284
Value Function Loss: 0.02433

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.70490

Collected Steps per Second: 22,222.71681
Overall Steps per Second: 10,746.31578

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.40396
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.65499

Cumulative Model Updates: 135,578
Cumulative Timesteps: 1,130,531,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,278.57258
Policy Entropy: 3.79201
Value Function Loss: 0.02091

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.62484
Value Function Update Magnitude: 0.81955

Collected Steps per Second: 22,557.97250
Overall Steps per Second: 10,829.91313

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.61758

Cumulative Model Updates: 135,584
Cumulative Timesteps: 1,130,581,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1130581548...
Checkpoint 1130581548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,278.57258
Policy Entropy: 3.76175
Value Function Loss: 0.02224

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.60924
Value Function Update Magnitude: 0.85168

Collected Steps per Second: 22,271.43922
Overall Steps per Second: 10,727.23908

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.66252

Cumulative Model Updates: 135,590
Cumulative Timesteps: 1,130,631,564

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,494.43186
Policy Entropy: 3.75101
Value Function Loss: 0.01883

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.60144
Value Function Update Magnitude: 0.76570

Collected Steps per Second: 22,408.04873
Overall Steps per Second: 10,781.14933

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.40783
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.64051

Cumulative Model Updates: 135,596
Cumulative Timesteps: 1,130,681,594

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1130681594...
Checkpoint 1130681594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,930.61151
Policy Entropy: 3.71825
Value Function Loss: 0.01986

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11827
Policy Update Magnitude: 0.66923
Value Function Update Magnitude: 0.69756

Collected Steps per Second: 22,804.51703
Overall Steps per Second: 10,728.04735

Timestep Collection Time: 2.19351
Timestep Consumption Time: 2.46922
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.66273

Cumulative Model Updates: 135,602
Cumulative Timesteps: 1,130,731,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,369.53035
Policy Entropy: 3.73192
Value Function Loss: 0.01917

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.74888
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 23,016.06727
Overall Steps per Second: 10,874.69307

Timestep Collection Time: 2.17361
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.60041

Cumulative Model Updates: 135,608
Cumulative Timesteps: 1,130,781,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1130781644...
Checkpoint 1130781644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,948.01628
Policy Entropy: 3.73577
Value Function Loss: 0.01825

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17429
Policy Update Magnitude: 0.64199
Value Function Update Magnitude: 0.59282

Collected Steps per Second: 23,076.53658
Overall Steps per Second: 10,781.43387

Timestep Collection Time: 2.16740
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.63909

Cumulative Model Updates: 135,614
Cumulative Timesteps: 1,130,831,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,948.01628
Policy Entropy: 3.73500
Value Function Loss: 0.01798

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.56408
Value Function Update Magnitude: 0.55175

Collected Steps per Second: 22,948.26223
Overall Steps per Second: 10,765.38380

Timestep Collection Time: 2.17995
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.64693

Cumulative Model Updates: 135,620
Cumulative Timesteps: 1,130,881,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1130881686...
Checkpoint 1130881686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,948.01628
Policy Entropy: 3.73826
Value Function Loss: 0.01564

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.52465

Collected Steps per Second: 23,020.75789
Overall Steps per Second: 10,730.43085

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.48869
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.66151

Cumulative Model Updates: 135,626
Cumulative Timesteps: 1,130,931,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 539,216.93344
Policy Entropy: 3.73826
Value Function Loss: 0.01751

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.50129
Value Function Update Magnitude: 0.55497

Collected Steps per Second: 22,974.53493
Overall Steps per Second: 10,813.24640

Timestep Collection Time: 2.17728
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62599

Cumulative Model Updates: 135,632
Cumulative Timesteps: 1,130,981,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1130981728...
Checkpoint 1130981728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,257.69742
Policy Entropy: 3.75144
Value Function Loss: 0.01946

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.51733
Value Function Update Magnitude: 0.66157

Collected Steps per Second: 22,891.41310
Overall Steps per Second: 10,723.07760

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66489

Cumulative Model Updates: 135,638
Cumulative Timesteps: 1,131,031,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,633.40393
Policy Entropy: 3.77469
Value Function Loss: 0.02102

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14482
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.79399

Collected Steps per Second: 22,918.75218
Overall Steps per Second: 10,779.79803

Timestep Collection Time: 2.18371
Timestep Consumption Time: 2.45904
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.64276

Cumulative Model Updates: 135,644
Cumulative Timesteps: 1,131,081,798

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1131081798...
Checkpoint 1131081798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,389.36720
Policy Entropy: 3.76487
Value Function Loss: 0.02170

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13824
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.85977

Collected Steps per Second: 22,611.23667
Overall Steps per Second: 10,660.09998

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.69245

Cumulative Model Updates: 135,650
Cumulative Timesteps: 1,131,131,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.61678
Policy Entropy: 3.78421
Value Function Loss: 0.01843

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.72472

Collected Steps per Second: 22,961.24415
Overall Steps per Second: 10,838.35605

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61601

Cumulative Model Updates: 135,656
Cumulative Timesteps: 1,131,181,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1131181850...
Checkpoint 1131181850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,081.98265
Policy Entropy: 3.75221
Value Function Loss: 0.01832

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.51557
Value Function Update Magnitude: 0.61213

Collected Steps per Second: 23,157.00357
Overall Steps per Second: 10,729.19705

Timestep Collection Time: 2.15943
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.66074

Cumulative Model Updates: 135,662
Cumulative Timesteps: 1,131,231,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,974.33120
Policy Entropy: 3.76997
Value Function Loss: 0.01696

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.51806
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 22,710.17227
Overall Steps per Second: 10,824.66450

Timestep Collection Time: 2.20263
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62111

Cumulative Model Updates: 135,668
Cumulative Timesteps: 1,131,281,878

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1131281878...
Checkpoint 1131281878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,251.15541
Policy Entropy: 3.76866
Value Function Loss: 0.01763

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.51980
Value Function Update Magnitude: 0.74669

Collected Steps per Second: 22,953.16458
Overall Steps per Second: 10,723.97557

Timestep Collection Time: 2.17870
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.66320

Cumulative Model Updates: 135,674
Cumulative Timesteps: 1,131,331,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,311.08158
Policy Entropy: 3.78928
Value Function Loss: 0.01594

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.50142
Value Function Update Magnitude: 0.78198

Collected Steps per Second: 23,379.70411
Overall Steps per Second: 10,970.49902

Timestep Collection Time: 2.14083
Timestep Consumption Time: 2.42159
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.56242

Cumulative Model Updates: 135,680
Cumulative Timesteps: 1,131,381,938

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1131381938...
Checkpoint 1131381938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,084.14185
Policy Entropy: 3.77707
Value Function Loss: 0.01582

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.48479
Value Function Update Magnitude: 0.75982

Collected Steps per Second: 23,253.65956
Overall Steps per Second: 10,972.90076

Timestep Collection Time: 2.15029
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.55686

Cumulative Model Updates: 135,686
Cumulative Timesteps: 1,131,431,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,143.16171
Policy Entropy: 3.75662
Value Function Loss: 0.01550

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.80991

Collected Steps per Second: 22,908.38342
Overall Steps per Second: 10,713.67457

Timestep Collection Time: 2.18287
Timestep Consumption Time: 2.48462
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.66749

Cumulative Model Updates: 135,692
Cumulative Timesteps: 1,131,481,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1131481946...
Checkpoint 1131481946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,011.40588
Policy Entropy: 3.74621
Value Function Loss: 0.01741

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.64966
Value Function Update Magnitude: 0.81532

Collected Steps per Second: 22,607.45559
Overall Steps per Second: 10,812.32709

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.62583

Cumulative Model Updates: 135,698
Cumulative Timesteps: 1,131,531,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,039.13173
Policy Entropy: 3.72977
Value Function Loss: 0.02038

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.69528
Value Function Update Magnitude: 0.75194

Collected Steps per Second: 22,800.94589
Overall Steps per Second: 10,744.91159

Timestep Collection Time: 2.19412
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.65597

Cumulative Model Updates: 135,704
Cumulative Timesteps: 1,131,581,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1131581990...
Checkpoint 1131581990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,765.93948
Policy Entropy: 3.74311
Value Function Loss: 0.02360

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.84622
Value Function Update Magnitude: 0.69543

Collected Steps per Second: 23,017.43632
Overall Steps per Second: 10,922.50336

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.40592
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.57862

Cumulative Model Updates: 135,710
Cumulative Timesteps: 1,131,632,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,520.81110
Policy Entropy: 3.75379
Value Function Loss: 0.02392

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.93465
Value Function Update Magnitude: 0.72284

Collected Steps per Second: 22,670.71031
Overall Steps per Second: 10,800.17949

Timestep Collection Time: 2.20593
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.63048

Cumulative Model Updates: 135,716
Cumulative Timesteps: 1,131,682,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1131682010...
Checkpoint 1131682010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,037.94782
Policy Entropy: 3.76962
Value Function Loss: 0.02127

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14434
Policy Update Magnitude: 0.85666
Value Function Update Magnitude: 0.74857

Collected Steps per Second: 22,991.91673
Overall Steps per Second: 10,737.07010

Timestep Collection Time: 2.17485
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.65714

Cumulative Model Updates: 135,722
Cumulative Timesteps: 1,131,732,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265,536.09863
Policy Entropy: 3.76286
Value Function Loss: 0.02717

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.67640
Value Function Update Magnitude: 0.65579

Collected Steps per Second: 22,510.19103
Overall Steps per Second: 10,797.34006

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.41004
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.63170

Cumulative Model Updates: 135,728
Cumulative Timesteps: 1,131,782,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1131782024...
Checkpoint 1131782024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,305.55502
Policy Entropy: 3.74800
Value Function Loss: 0.02989

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14895
Policy Update Magnitude: 0.71743
Value Function Update Magnitude: 0.60152

Collected Steps per Second: 21,907.79874
Overall Steps per Second: 10,703.38989

Timestep Collection Time: 2.28321
Timestep Consumption Time: 2.39008
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.67329

Cumulative Model Updates: 135,734
Cumulative Timesteps: 1,131,832,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,408.00455
Policy Entropy: 3.78922
Value Function Loss: 0.03175

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15997
Policy Update Magnitude: 0.75298
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 22,163.68291
Overall Steps per Second: 10,877.04404

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.34174
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.59849

Cumulative Model Updates: 135,740
Cumulative Timesteps: 1,131,882,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1131882062...
Checkpoint 1131882062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,230.11203
Policy Entropy: 3.79984
Value Function Loss: 0.02641

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.76543
Value Function Update Magnitude: 0.76618

Collected Steps per Second: 22,456.68177
Overall Steps per Second: 10,787.38133

Timestep Collection Time: 2.22678
Timestep Consumption Time: 2.40883
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.63560

Cumulative Model Updates: 135,746
Cumulative Timesteps: 1,131,932,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,301.06448
Policy Entropy: 3.79136
Value Function Loss: 0.02336

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.67973
Value Function Update Magnitude: 0.78209

Collected Steps per Second: 22,377.75206
Overall Steps per Second: 10,814.87641

Timestep Collection Time: 2.23454
Timestep Consumption Time: 2.38909
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.62363

Cumulative Model Updates: 135,752
Cumulative Timesteps: 1,131,982,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1131982072...
Checkpoint 1131982072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,079.91612
Policy Entropy: 3.76417
Value Function Loss: 0.02551

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.77878

Collected Steps per Second: 22,347.98969
Overall Steps per Second: 10,632.77493

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70263

Cumulative Model Updates: 135,758
Cumulative Timesteps: 1,132,032,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,221.58607
Policy Entropy: 3.77379
Value Function Loss: 0.02565

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13646
Policy Update Magnitude: 0.59809
Value Function Update Magnitude: 0.82258

Collected Steps per Second: 23,078.05976
Overall Steps per Second: 10,855.68255

Timestep Collection Time: 2.16691
Timestep Consumption Time: 2.43971
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.60662

Cumulative Model Updates: 135,764
Cumulative Timesteps: 1,132,082,082

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1132082082...
Checkpoint 1132082082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,487.38040
Policy Entropy: 3.78102
Value Function Loss: 0.02758

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.65837
Value Function Update Magnitude: 0.84966

Collected Steps per Second: 22,927.31377
Overall Steps per Second: 10,756.89209

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.65004

Cumulative Model Updates: 135,770
Cumulative Timesteps: 1,132,132,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.35412
Policy Entropy: 3.81738
Value Function Loss: 0.02620

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.66850
Value Function Update Magnitude: 0.83745

Collected Steps per Second: 22,709.81165
Overall Steps per Second: 10,818.35365

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.62196

Cumulative Model Updates: 135,776
Cumulative Timesteps: 1,132,182,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1132182104...
Checkpoint 1132182104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,157.94917
Policy Entropy: 3.80130
Value Function Loss: 0.02970

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.63677
Value Function Update Magnitude: 0.87989

Collected Steps per Second: 23,169.54611
Overall Steps per Second: 11,035.18770

Timestep Collection Time: 2.15904
Timestep Consumption Time: 2.37409
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.53314

Cumulative Model Updates: 135,782
Cumulative Timesteps: 1,132,232,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,370.51977
Policy Entropy: 3.79795
Value Function Loss: 0.03029

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.65387
Value Function Update Magnitude: 0.82324

Collected Steps per Second: 23,220.68216
Overall Steps per Second: 10,980.01736

Timestep Collection Time: 2.15454
Timestep Consumption Time: 2.40191
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.55646

Cumulative Model Updates: 135,788
Cumulative Timesteps: 1,132,282,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1132282158...
Checkpoint 1132282158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,289.10497
Policy Entropy: 3.79098
Value Function Loss: 0.02959

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.69283
Value Function Update Magnitude: 0.88277

Collected Steps per Second: 23,091.56650
Overall Steps per Second: 10,858.80914

Timestep Collection Time: 2.16763
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.60953

Cumulative Model Updates: 135,794
Cumulative Timesteps: 1,132,332,212

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.89231
Policy Entropy: 3.83028
Value Function Loss: 0.02786

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.71699
Value Function Update Magnitude: 0.86569

Collected Steps per Second: 23,163.01062
Overall Steps per Second: 10,828.91779

Timestep Collection Time: 2.16008
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.62041

Cumulative Model Updates: 135,800
Cumulative Timesteps: 1,132,382,246

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1132382246...
Checkpoint 1132382246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,475.81210
Policy Entropy: 3.80962
Value Function Loss: 0.02934

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.68807
Value Function Update Magnitude: 0.79130

Collected Steps per Second: 23,184.10637
Overall Steps per Second: 10,961.60571

Timestep Collection Time: 2.15708
Timestep Consumption Time: 2.40521
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.56229

Cumulative Model Updates: 135,806
Cumulative Timesteps: 1,132,432,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,810.91092
Policy Entropy: 3.79193
Value Function Loss: 0.03002

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.68086
Value Function Update Magnitude: 0.73443

Collected Steps per Second: 22,659.01811
Overall Steps per Second: 10,678.37984

Timestep Collection Time: 2.20751
Timestep Consumption Time: 2.47672
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68423

Cumulative Model Updates: 135,812
Cumulative Timesteps: 1,132,482,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1132482276...
Checkpoint 1132482276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.91978
Policy Entropy: 3.75698
Value Function Loss: 0.03003

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.70531
Value Function Update Magnitude: 0.70728

Collected Steps per Second: 22,914.59043
Overall Steps per Second: 10,875.62026

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.41678
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.60001

Cumulative Model Updates: 135,818
Cumulative Timesteps: 1,132,532,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.91978
Policy Entropy: 3.75104
Value Function Loss: 0.02840

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13900
Policy Update Magnitude: 0.72960
Value Function Update Magnitude: 0.75133

Collected Steps per Second: 22,825.59034
Overall Steps per Second: 10,850.73431

Timestep Collection Time: 2.19158
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.61019

Cumulative Model Updates: 135,824
Cumulative Timesteps: 1,132,582,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1132582328...
Checkpoint 1132582328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,481.40772
Policy Entropy: 3.74304
Value Function Loss: 0.02480

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.71298
Value Function Update Magnitude: 0.86361

Collected Steps per Second: 22,902.81137
Overall Steps per Second: 10,735.52836

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.47509
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.65892

Cumulative Model Updates: 135,830
Cumulative Timesteps: 1,132,632,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,490.96662
Policy Entropy: 3.74323
Value Function Loss: 0.02538

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.64739
Value Function Update Magnitude: 0.80031

Collected Steps per Second: 22,685.47933
Overall Steps per Second: 10,791.07763

Timestep Collection Time: 2.20511
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.63568

Cumulative Model Updates: 135,836
Cumulative Timesteps: 1,132,682,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1132682368...
Checkpoint 1132682368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,687.98991
Policy Entropy: 3.76279
Value Function Loss: 0.02444

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14643
Policy Update Magnitude: 0.60394
Value Function Update Magnitude: 0.63947

Collected Steps per Second: 23,050.13289
Overall Steps per Second: 10,735.72486

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.65958

Cumulative Model Updates: 135,842
Cumulative Timesteps: 1,132,732,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,497.64827
Policy Entropy: 3.78590
Value Function Loss: 0.02271

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.56347
Value Function Update Magnitude: 0.66947

Collected Steps per Second: 23,085.35470
Overall Steps per Second: 10,885.19917

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.59486

Cumulative Model Updates: 135,848
Cumulative Timesteps: 1,132,782,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1132782408...
Checkpoint 1132782408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,393.48659
Policy Entropy: 3.76964
Value Function Loss: 0.02072

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14853
Policy Update Magnitude: 0.53309
Value Function Update Magnitude: 0.74389

Collected Steps per Second: 22,957.04643
Overall Steps per Second: 10,660.03224

Timestep Collection Time: 2.17833
Timestep Consumption Time: 2.51284
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.69117

Cumulative Model Updates: 135,854
Cumulative Timesteps: 1,132,832,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,310.78411
Policy Entropy: 3.75530
Value Function Loss: 0.02170

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15902
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.83079

Collected Steps per Second: 22,915.90900
Overall Steps per Second: 10,851.99202

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.60911

Cumulative Model Updates: 135,860
Cumulative Timesteps: 1,132,882,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1132882434...
Checkpoint 1132882434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,317.88642
Policy Entropy: 3.76691
Value Function Loss: 0.02015

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.71064

Collected Steps per Second: 23,093.74645
Overall Steps per Second: 10,725.87877

Timestep Collection Time: 2.16535
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66218

Cumulative Model Updates: 135,866
Cumulative Timesteps: 1,132,932,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 398,277.97582
Policy Entropy: 3.76695
Value Function Loss: 0.01959

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.68459

Collected Steps per Second: 23,097.02454
Overall Steps per Second: 10,923.28389

Timestep Collection Time: 2.16582
Timestep Consumption Time: 2.41376
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.57958

Cumulative Model Updates: 135,872
Cumulative Timesteps: 1,132,982,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1132982464...
Checkpoint 1132982464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,535.40550
Policy Entropy: 3.77467
Value Function Loss: 0.01812

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.56968

Collected Steps per Second: 23,112.11840
Overall Steps per Second: 10,800.47039

Timestep Collection Time: 2.16449
Timestep Consumption Time: 2.46734
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.63184

Cumulative Model Updates: 135,878
Cumulative Timesteps: 1,133,032,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,632.83585
Policy Entropy: 3.73392
Value Function Loss: 0.01924

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.50330
Value Function Update Magnitude: 0.53266

Collected Steps per Second: 22,934.81667
Overall Steps per Second: 10,701.18196

Timestep Collection Time: 2.18131
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.67500

Cumulative Model Updates: 135,884
Cumulative Timesteps: 1,133,082,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1133082518...
Checkpoint 1133082518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,511.12463
Policy Entropy: 3.74002
Value Function Loss: 0.02258

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.63843

Collected Steps per Second: 23,023.65279
Overall Steps per Second: 10,737.09447

Timestep Collection Time: 2.17281
Timestep Consumption Time: 2.48637
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65917

Cumulative Model Updates: 135,890
Cumulative Timesteps: 1,133,132,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,759.23376
Policy Entropy: 3.75849
Value Function Loss: 0.02423

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.60507
Value Function Update Magnitude: 0.70971

Collected Steps per Second: 22,942.50045
Overall Steps per Second: 10,893.44596

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.41133
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.59138

Cumulative Model Updates: 135,896
Cumulative Timesteps: 1,133,182,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1133182560...
Checkpoint 1133182560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,729.95113
Policy Entropy: 3.77836
Value Function Loss: 0.02767

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.61336
Value Function Update Magnitude: 0.72873

Collected Steps per Second: 22,724.05637
Overall Steps per Second: 10,684.17694

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.68150

Cumulative Model Updates: 135,902
Cumulative Timesteps: 1,133,232,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,441.43549
Policy Entropy: 3.79010
Value Function Loss: 0.02759

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.60416
Value Function Update Magnitude: 0.78594

Collected Steps per Second: 22,588.18168
Overall Steps per Second: 10,758.22620

Timestep Collection Time: 2.21541
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.65151

Cumulative Model Updates: 135,908
Cumulative Timesteps: 1,133,282,620

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1133282620...
Checkpoint 1133282620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,803.97814
Policy Entropy: 3.76852
Value Function Loss: 0.02596

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.61601
Value Function Update Magnitude: 0.77067

Collected Steps per Second: 22,852.36279
Overall Steps per Second: 10,669.57083

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.68660

Cumulative Model Updates: 135,914
Cumulative Timesteps: 1,133,332,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,803.97814
Policy Entropy: 3.74835
Value Function Loss: 0.02159

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.65380
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 23,407.75734
Overall Steps per Second: 10,981.45273

Timestep Collection Time: 2.13621
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.55350

Cumulative Model Updates: 135,920
Cumulative Timesteps: 1,133,382,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1133382628...
Checkpoint 1133382628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,021.93344
Policy Entropy: 3.73933
Value Function Loss: 0.01964

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.60497
Value Function Update Magnitude: 0.56952

Collected Steps per Second: 22,949.23759
Overall Steps per Second: 10,757.51895

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.65051

Cumulative Model Updates: 135,926
Cumulative Timesteps: 1,133,432,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,021.93344
Policy Entropy: 3.74846
Value Function Loss: 0.01807

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.67536
Value Function Update Magnitude: 0.52610

Collected Steps per Second: 22,764.90462
Overall Steps per Second: 10,758.82565

Timestep Collection Time: 2.19724
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.64921

Cumulative Model Updates: 135,932
Cumulative Timesteps: 1,133,482,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1133482676...
Checkpoint 1133482676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,021.93344
Policy Entropy: 3.76557
Value Function Loss: 0.01605

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.61536
Value Function Update Magnitude: 0.47858

Collected Steps per Second: 22,849.35234
Overall Steps per Second: 10,682.35856

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.68230

Cumulative Model Updates: 135,938
Cumulative Timesteps: 1,133,532,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,021.93344
Policy Entropy: 3.77673
Value Function Loss: 0.01396

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.21879
Policy Update Magnitude: 0.46134
Value Function Update Magnitude: 0.38113

Collected Steps per Second: 23,000.46148
Overall Steps per Second: 10,918.80607

Timestep Collection Time: 2.17430
Timestep Consumption Time: 2.40587
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.58017

Cumulative Model Updates: 135,944
Cumulative Timesteps: 1,133,582,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1133582704...
Checkpoint 1133582704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,021.93344
Policy Entropy: 3.74321
Value Function Loss: 0.01778

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.14949
Policy Update Magnitude: 0.41461
Value Function Update Magnitude: 0.35390

Collected Steps per Second: 22,961.71816
Overall Steps per Second: 10,780.71114

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.63828

Cumulative Model Updates: 135,950
Cumulative Timesteps: 1,133,632,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371,152.67954
Policy Entropy: 3.73814
Value Function Loss: 0.02151

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.51920
Value Function Update Magnitude: 0.52802

Collected Steps per Second: 22,255.33649
Overall Steps per Second: 10,743.58498

Timestep Collection Time: 2.24710
Timestep Consumption Time: 2.40777
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.65487

Cumulative Model Updates: 135,956
Cumulative Timesteps: 1,133,682,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1133682718...
Checkpoint 1133682718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,637.28000
Policy Entropy: 3.73956
Value Function Loss: 0.02434

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.59235
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 22,119.37401
Overall Steps per Second: 10,596.23061

Timestep Collection Time: 2.26046
Timestep Consumption Time: 2.45820
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.71866

Cumulative Model Updates: 135,962
Cumulative Timesteps: 1,133,732,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 562,269.40262
Policy Entropy: 3.79420
Value Function Loss: 0.02747

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.72383
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 21,739.34303
Overall Steps per Second: 10,644.56277

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.39812
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.69892

Cumulative Model Updates: 135,968
Cumulative Timesteps: 1,133,782,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1133782736...
Checkpoint 1133782736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,301.08359
Policy Entropy: 3.80969
Value Function Loss: 0.02771

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.80843
Value Function Update Magnitude: 0.63432

Collected Steps per Second: 21,972.14011
Overall Steps per Second: 10,826.56749

Timestep Collection Time: 2.27707
Timestep Consumption Time: 2.34416
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.62122

Cumulative Model Updates: 135,974
Cumulative Timesteps: 1,133,832,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,301.08359
Policy Entropy: 3.79353
Value Function Loss: 0.02657

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.80416
Value Function Update Magnitude: 0.65286

Collected Steps per Second: 21,676.42772
Overall Steps per Second: 10,581.25857

Timestep Collection Time: 2.30730
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.72666

Cumulative Model Updates: 135,980
Cumulative Timesteps: 1,133,882,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1133882782...
Checkpoint 1133882782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,177.75536
Policy Entropy: 3.78190
Value Function Loss: 0.02365

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14903
Policy Update Magnitude: 0.74118
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 21,993.42510
Overall Steps per Second: 10,691.59934

Timestep Collection Time: 2.27441
Timestep Consumption Time: 2.40422
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.67863

Cumulative Model Updates: 135,986
Cumulative Timesteps: 1,133,932,804

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,973.48983
Policy Entropy: 3.75365
Value Function Loss: 0.02075

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.69663
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 22,157.35845
Overall Steps per Second: 10,763.54816

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.38920
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.64624

Cumulative Model Updates: 135,992
Cumulative Timesteps: 1,133,982,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1133982814...
Checkpoint 1133982814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,120.60922
Policy Entropy: 3.74669
Value Function Loss: 0.02681

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.67252
Value Function Update Magnitude: 0.46465

Collected Steps per Second: 22,651.72997
Overall Steps per Second: 10,706.42058

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67084

Cumulative Model Updates: 135,998
Cumulative Timesteps: 1,134,032,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,677.10272
Policy Entropy: 3.75100
Value Function Loss: 0.03086

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.70289
Value Function Update Magnitude: 0.48292

Collected Steps per Second: 22,516.56386
Overall Steps per Second: 10,811.50367

Timestep Collection Time: 2.22139
Timestep Consumption Time: 2.40498
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.62637

Cumulative Model Updates: 136,004
Cumulative Timesteps: 1,134,082,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1134082840...
Checkpoint 1134082840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,008.18427
Policy Entropy: 3.75053
Value Function Loss: 0.03103

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.75064
Value Function Update Magnitude: 0.52931

Collected Steps per Second: 22,374.25352
Overall Steps per Second: 10,762.68057

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.64773

Cumulative Model Updates: 136,010
Cumulative Timesteps: 1,134,132,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,336.84864
Policy Entropy: 3.76350
Value Function Loss: 0.02821

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07911
Policy Update Magnitude: 0.82815
Value Function Update Magnitude: 0.52831

Collected Steps per Second: 22,711.96609
Overall Steps per Second: 10,825.75665

Timestep Collection Time: 2.20166
Timestep Consumption Time: 2.41733
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.61898

Cumulative Model Updates: 136,016
Cumulative Timesteps: 1,134,182,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1134182866...
Checkpoint 1134182866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,585.16109
Policy Entropy: 3.79381
Value Function Loss: 0.02720

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.80767
Value Function Update Magnitude: 0.54917

Collected Steps per Second: 22,907.57034
Overall Steps per Second: 10,715.43436

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.66729

Cumulative Model Updates: 136,022
Cumulative Timesteps: 1,134,232,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,074.96905
Policy Entropy: 3.79704
Value Function Loss: 0.02720

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.18954
Policy Update Magnitude: 0.65212
Value Function Update Magnitude: 0.64722

Collected Steps per Second: 22,648.13207
Overall Steps per Second: 10,791.43654

Timestep Collection Time: 2.20786
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.63367

Cumulative Model Updates: 136,028
Cumulative Timesteps: 1,134,282,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1134282882...
Checkpoint 1134282882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,888.09884
Policy Entropy: 3.80950
Value Function Loss: 0.02542

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.65094
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 23,058.35333
Overall Steps per Second: 10,710.71445

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.49991
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.66841

Cumulative Model Updates: 136,034
Cumulative Timesteps: 1,134,332,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.55835
Policy Entropy: 3.80012
Value Function Loss: 0.02213

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.67104
Value Function Update Magnitude: 0.60529

Collected Steps per Second: 23,027.83847
Overall Steps per Second: 10,882.09833

Timestep Collection Time: 2.17198
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.59617

Cumulative Model Updates: 136,040
Cumulative Timesteps: 1,134,382,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1134382900...
Checkpoint 1134382900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,184.52443
Policy Entropy: 3.80150
Value Function Loss: 0.01927

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07886
Policy Update Magnitude: 0.65164
Value Function Update Magnitude: 0.53974

Collected Steps per Second: 23,112.15389
Overall Steps per Second: 10,721.27581

Timestep Collection Time: 2.16380
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66456

Cumulative Model Updates: 136,046
Cumulative Timesteps: 1,134,432,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,086.29082
Policy Entropy: 3.81084
Value Function Loss: 0.01891

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.62768
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 22,650.51812
Overall Steps per Second: 10,790.97739

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.42731
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.63591

Cumulative Model Updates: 136,052
Cumulative Timesteps: 1,134,482,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1134482936...
Checkpoint 1134482936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.34296
Policy Entropy: 3.83269
Value Function Loss: 0.01996

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.16331
Policy Update Magnitude: 0.59655
Value Function Update Magnitude: 0.69224

Collected Steps per Second: 23,110.52661
Overall Steps per Second: 10,724.36696

Timestep Collection Time: 2.16404
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.66340

Cumulative Model Updates: 136,058
Cumulative Timesteps: 1,134,532,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,244.75338
Policy Entropy: 3.83567
Value Function Loss: 0.02088

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11324
Policy Update Magnitude: 0.64180
Value Function Update Magnitude: 0.80200

Collected Steps per Second: 22,992.91404
Overall Steps per Second: 10,905.26329

Timestep Collection Time: 2.17563
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.58714

Cumulative Model Updates: 136,064
Cumulative Timesteps: 1,134,582,972

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1134582972...
Checkpoint 1134582972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,698.70798
Policy Entropy: 3.82534
Value Function Loss: 0.02016

Mean KL Divergence: 0.00712
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.75606
Value Function Update Magnitude: 0.82832

Collected Steps per Second: 22,773.40737
Overall Steps per Second: 10,639.82524

Timestep Collection Time: 2.19589
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.70008

Cumulative Model Updates: 136,070
Cumulative Timesteps: 1,134,632,980

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.17379
Policy Entropy: 3.79752
Value Function Loss: 0.02012

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07997
Policy Update Magnitude: 0.76790
Value Function Update Magnitude: 0.79777

Collected Steps per Second: 23,092.81952
Overall Steps per Second: 10,900.95630

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.42303
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.58951

Cumulative Model Updates: 136,076
Cumulative Timesteps: 1,134,683,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1134683010...
Checkpoint 1134683010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197.67042
Policy Entropy: 3.77728
Value Function Loss: 0.01892

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06115
Policy Update Magnitude: 0.73513
Value Function Update Magnitude: 0.79065

Collected Steps per Second: 23,192.55913
Overall Steps per Second: 10,961.34387

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.40629
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.56276

Cumulative Model Updates: 136,082
Cumulative Timesteps: 1,134,733,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,674.49276
Policy Entropy: 3.79122
Value Function Loss: 0.01790

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05151
Policy Update Magnitude: 0.68570
Value Function Update Magnitude: 0.80482

Collected Steps per Second: 22,764.74902
Overall Steps per Second: 10,665.19157

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69302

Cumulative Model Updates: 136,088
Cumulative Timesteps: 1,134,783,076

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1134783076...
Checkpoint 1134783076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,632.24684
Policy Entropy: 3.78931
Value Function Loss: 0.01650

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04616
Policy Update Magnitude: 0.65866
Value Function Update Magnitude: 0.77446

Collected Steps per Second: 23,100.77619
Overall Steps per Second: 10,944.67333

Timestep Collection Time: 2.16495
Timestep Consumption Time: 2.40458
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.56953

Cumulative Model Updates: 136,094
Cumulative Timesteps: 1,134,833,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,748.33044
Policy Entropy: 3.78727
Value Function Loss: 0.01386

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05421
Policy Update Magnitude: 0.61239
Value Function Update Magnitude: 0.69006

Collected Steps per Second: 22,855.97400
Overall Steps per Second: 10,677.89268

Timestep Collection Time: 2.18822
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.68388

Cumulative Model Updates: 136,100
Cumulative Timesteps: 1,134,883,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1134883102...
Checkpoint 1134883102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,748.33044
Policy Entropy: 3.76656
Value Function Loss: 0.01460

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.15253
Policy Update Magnitude: 0.53488
Value Function Update Magnitude: 0.60752

Collected Steps per Second: 22,692.15333
Overall Steps per Second: 10,837.28998

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61462

Cumulative Model Updates: 136,106
Cumulative Timesteps: 1,134,933,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263,285.64448
Policy Entropy: 3.74116
Value Function Loss: 0.01779

Mean KL Divergence: 0.02998
SB3 Clip Fraction: 0.31789
Policy Update Magnitude: 0.46221
Value Function Update Magnitude: 0.51830

Collected Steps per Second: 22,679.87306
Overall Steps per Second: 10,669.43848

Timestep Collection Time: 2.20557
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.68834

Cumulative Model Updates: 136,112
Cumulative Timesteps: 1,134,983,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1134983134...
Checkpoint 1134983134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,875.76059
Policy Entropy: 3.76351
Value Function Loss: 0.03414

Mean KL Divergence: 0.02279
SB3 Clip Fraction: 0.23996
Policy Update Magnitude: 0.52331
Value Function Update Magnitude: 0.45624

Collected Steps per Second: 22,004.85706
Overall Steps per Second: 10,512.60807

Timestep Collection Time: 2.27323
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.75829

Cumulative Model Updates: 136,118
Cumulative Timesteps: 1,135,033,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,377.86957
Policy Entropy: 3.78543
Value Function Loss: 0.04181

Mean KL Divergence: 0.02271
SB3 Clip Fraction: 0.23899
Policy Update Magnitude: 0.69990
Value Function Update Magnitude: 0.61678

Collected Steps per Second: 22,080.48871
Overall Steps per Second: 10,504.58315

Timestep Collection Time: 2.26499
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.76097

Cumulative Model Updates: 136,124
Cumulative Timesteps: 1,135,083,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1135083168...
Checkpoint 1135083168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,493.12910
Policy Entropy: 3.81298
Value Function Loss: 0.04296

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.22228
Policy Update Magnitude: 0.65912
Value Function Update Magnitude: 0.67453

Collected Steps per Second: 22,341.05163
Overall Steps per Second: 10,584.77878

Timestep Collection Time: 2.23964
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.72717

Cumulative Model Updates: 136,130
Cumulative Timesteps: 1,135,133,204

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,671.30850
Policy Entropy: 3.79823
Value Function Loss: 0.03607

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.23485
Policy Update Magnitude: 0.65246
Value Function Update Magnitude: 0.63533

Collected Steps per Second: 22,977.57429
Overall Steps per Second: 10,884.12295

Timestep Collection Time: 2.17699
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.59587

Cumulative Model Updates: 136,136
Cumulative Timesteps: 1,135,183,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1135183226...
Checkpoint 1135183226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,295.65234
Policy Entropy: 3.80347
Value Function Loss: 0.03195

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.62560
Value Function Update Magnitude: 0.49717

Collected Steps per Second: 22,642.04710
Overall Steps per Second: 10,667.59173

Timestep Collection Time: 2.20943
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.68953

Cumulative Model Updates: 136,142
Cumulative Timesteps: 1,135,233,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,629.63520
Policy Entropy: 3.79549
Value Function Loss: 0.02638

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.59408
Value Function Update Magnitude: 0.47658

Collected Steps per Second: 22,828.65301
Overall Steps per Second: 10,848.23816

Timestep Collection Time: 2.19242
Timestep Consumption Time: 2.42123
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.61365

Cumulative Model Updates: 136,148
Cumulative Timesteps: 1,135,283,302

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1135283302...
Checkpoint 1135283302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,686.62423
Policy Entropy: 3.78828
Value Function Loss: 0.02415

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08158
Policy Update Magnitude: 0.63394
Value Function Update Magnitude: 0.42546

Collected Steps per Second: 23,073.84030
Overall Steps per Second: 10,705.73153

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.67077

Cumulative Model Updates: 136,154
Cumulative Timesteps: 1,135,333,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,686.62423
Policy Entropy: 3.77307
Value Function Loss: 0.02120

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.59218
Value Function Update Magnitude: 0.39211

Collected Steps per Second: 23,116.03783
Overall Steps per Second: 10,886.44262

Timestep Collection Time: 2.16326
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.59342

Cumulative Model Updates: 136,160
Cumulative Timesteps: 1,135,383,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1135383312...
Checkpoint 1135383312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,686.62423
Policy Entropy: 3.77143
Value Function Loss: 0.01748

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.18373
Policy Update Magnitude: 0.48971
Value Function Update Magnitude: 0.38290

Collected Steps per Second: 23,048.09090
Overall Steps per Second: 10,709.05496

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.67100

Cumulative Model Updates: 136,166
Cumulative Timesteps: 1,135,433,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,686.62423
Policy Entropy: 3.76344
Value Function Loss: 0.01581

Mean KL Divergence: 0.02149
SB3 Clip Fraction: 0.27275
Policy Update Magnitude: 0.39583
Value Function Update Magnitude: 0.37382

Collected Steps per Second: 23,380.26055
Overall Steps per Second: 10,913.28602

Timestep Collection Time: 2.13967
Timestep Consumption Time: 2.44429
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.58395

Cumulative Model Updates: 136,172
Cumulative Timesteps: 1,135,483,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1135483360...
Checkpoint 1135483360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,602.18335
Policy Entropy: 3.75134
Value Function Loss: 0.02080

Mean KL Divergence: 0.02170
SB3 Clip Fraction: 0.26608
Policy Update Magnitude: 0.31943
Value Function Update Magnitude: 0.49736

Collected Steps per Second: 22,670.85683
Overall Steps per Second: 10,659.10050

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.48615
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.69233

Cumulative Model Updates: 136,178
Cumulative Timesteps: 1,135,533,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,633.76319
Policy Entropy: 3.74174
Value Function Loss: 0.02550

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.25830
Policy Update Magnitude: 0.32572
Value Function Update Magnitude: 0.56812

Collected Steps per Second: 22,083.64874
Overall Steps per Second: 10,448.68019

Timestep Collection Time: 2.26439
Timestep Consumption Time: 2.52148
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.78587

Cumulative Model Updates: 136,184
Cumulative Timesteps: 1,135,583,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1135583382...
Checkpoint 1135583382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,664.03322
Policy Entropy: 3.72540
Value Function Loss: 0.03134

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.22417
Policy Update Magnitude: 0.34407
Value Function Update Magnitude: 0.52896

Collected Steps per Second: 22,770.47620
Overall Steps per Second: 10,668.87723

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.49240
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68972

Cumulative Model Updates: 136,190
Cumulative Timesteps: 1,135,633,416

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,520.07754
Policy Entropy: 3.74639
Value Function Loss: 0.03231

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.21131
Policy Update Magnitude: 0.36849
Value Function Update Magnitude: 0.51245

Collected Steps per Second: 22,685.25517
Overall Steps per Second: 10,767.04833

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64547

Cumulative Model Updates: 136,196
Cumulative Timesteps: 1,135,683,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1135683434...
Checkpoint 1135683434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,481.35083
Policy Entropy: 3.75058
Value Function Loss: 0.04008

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.19117
Policy Update Magnitude: 0.43101
Value Function Update Magnitude: 0.53501

Collected Steps per Second: 22,390.50528
Overall Steps per Second: 10,786.48885

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.40234
PPO Batch Consumption Time: 0.27609
Total Iteration Time: 4.63543

Cumulative Model Updates: 136,202
Cumulative Timesteps: 1,135,733,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,116.48361
Policy Entropy: 3.75021
Value Function Loss: 0.04695

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.18625
Policy Update Magnitude: 0.48510
Value Function Update Magnitude: 0.52639

Collected Steps per Second: 22,612.22351
Overall Steps per Second: 10,779.96183

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.64046

Cumulative Model Updates: 136,208
Cumulative Timesteps: 1,135,783,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1135783458...
Checkpoint 1135783458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,006.04504
Policy Entropy: 3.75054
Value Function Loss: 0.04764

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.18743
Policy Update Magnitude: 0.50133
Value Function Update Magnitude: 0.47314

Collected Steps per Second: 22,750.29578
Overall Steps per Second: 10,679.17449

Timestep Collection Time: 2.19839
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.68332

Cumulative Model Updates: 136,214
Cumulative Timesteps: 1,135,833,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,812.36330
Policy Entropy: 3.74337
Value Function Loss: 0.04421

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.20096
Policy Update Magnitude: 0.50481
Value Function Update Magnitude: 0.44074

Collected Steps per Second: 22,879.56236
Overall Steps per Second: 10,839.84826

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.61280

Cumulative Model Updates: 136,220
Cumulative Timesteps: 1,135,883,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1135883474...
Checkpoint 1135883474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,517.21505
Policy Entropy: 3.74937
Value Function Loss: 0.04050

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.19912
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 22,841.78145
Overall Steps per Second: 10,708.92799

Timestep Collection Time: 2.18923
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.66956

Cumulative Model Updates: 136,226
Cumulative Timesteps: 1,135,933,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,254.66165
Policy Entropy: 3.75291
Value Function Loss: 0.03825

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.21131
Policy Update Magnitude: 0.51150
Value Function Update Magnitude: 0.55724

Collected Steps per Second: 23,091.15895
Overall Steps per Second: 10,889.47259

Timestep Collection Time: 2.16533
Timestep Consumption Time: 2.42626
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59159

Cumulative Model Updates: 136,232
Cumulative Timesteps: 1,135,983,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1135983480...
Checkpoint 1135983480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,110.50180
Policy Entropy: 3.71053
Value Function Loss: 0.03902

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.21763
Policy Update Magnitude: 0.47530
Value Function Update Magnitude: 0.52336

Collected Steps per Second: 22,688.38236
Overall Steps per Second: 10,639.31382

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70162

Cumulative Model Updates: 136,238
Cumulative Timesteps: 1,136,033,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,504.88649
Policy Entropy: 3.68981
Value Function Loss: 0.03941

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.21177
Policy Update Magnitude: 0.47679
Value Function Update Magnitude: 0.46831

Collected Steps per Second: 23,125.64250
Overall Steps per Second: 10,914.02279

Timestep Collection Time: 2.16314
Timestep Consumption Time: 2.42032
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.58346

Cumulative Model Updates: 136,244
Cumulative Timesteps: 1,136,083,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1136083526...
Checkpoint 1136083526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,219.61393
Policy Entropy: 3.69226
Value Function Loss: 0.04047

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.19217
Policy Update Magnitude: 0.52390
Value Function Update Magnitude: 0.52834

Collected Steps per Second: 22,889.44334
Overall Steps per Second: 10,709.90145

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.67100

Cumulative Model Updates: 136,250
Cumulative Timesteps: 1,136,133,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,329.22929
Policy Entropy: 3.72480
Value Function Loss: 0.04145

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.18128
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.52409

Collected Steps per Second: 22,915.40484
Overall Steps per Second: 10,820.78214

Timestep Collection Time: 2.18203
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.62092

Cumulative Model Updates: 136,256
Cumulative Timesteps: 1,136,183,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1136183554...
Checkpoint 1136183554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,281.17487
Policy Entropy: 3.74626
Value Function Loss: 0.04312

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.58529
Value Function Update Magnitude: 0.50275

Collected Steps per Second: 22,599.59914
Overall Steps per Second: 10,684.83841

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.46789
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.68103

Cumulative Model Updates: 136,262
Cumulative Timesteps: 1,136,233,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,976.26694
Policy Entropy: 3.76889
Value Function Loss: 0.04158

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.17393
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.52630

Collected Steps per Second: 23,007.22394
Overall Steps per Second: 10,884.21636

Timestep Collection Time: 2.17393
Timestep Consumption Time: 2.42135
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.59528

Cumulative Model Updates: 136,268
Cumulative Timesteps: 1,136,283,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1136283586...
Checkpoint 1136283586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.12477
Policy Entropy: 3.77974
Value Function Loss: 0.03904

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.16676
Policy Update Magnitude: 0.56772
Value Function Update Magnitude: 0.70487

Collected Steps per Second: 22,378.75927
Overall Steps per Second: 10,686.56648

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.44480
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.67933

Cumulative Model Updates: 136,274
Cumulative Timesteps: 1,136,333,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.16897
Policy Entropy: 3.77122
Value Function Loss: 0.04075

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.17337
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.70711

Collected Steps per Second: 23,069.26364
Overall Steps per Second: 10,882.80411

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.59606

Cumulative Model Updates: 136,280
Cumulative Timesteps: 1,136,383,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1136383610...
Checkpoint 1136383610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,339.07004
Policy Entropy: 3.77199
Value Function Loss: 0.04068

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.17471
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.55820

Collected Steps per Second: 22,800.34009
Overall Steps per Second: 10,695.98143

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.48200
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.67521

Cumulative Model Updates: 136,286
Cumulative Timesteps: 1,136,433,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,418.09649
Policy Entropy: 3.80293
Value Function Loss: 0.04225

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.15980
Policy Update Magnitude: 0.54631
Value Function Update Magnitude: 0.61121

Collected Steps per Second: 23,342.27587
Overall Steps per Second: 10,874.09678

Timestep Collection Time: 2.14298
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.60011

Cumulative Model Updates: 136,292
Cumulative Timesteps: 1,136,483,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1136483638...
Checkpoint 1136483638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.63352
Policy Entropy: 3.87105
Value Function Loss: 0.03895

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.58705
Value Function Update Magnitude: 0.66101

Collected Steps per Second: 22,416.65811
Overall Steps per Second: 10,655.26696

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.46242
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.69327

Cumulative Model Updates: 136,298
Cumulative Timesteps: 1,136,533,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,694.61285
Policy Entropy: 3.89844
Value Function Loss: 0.03828

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.60944
Value Function Update Magnitude: 0.64293

Collected Steps per Second: 23,230.41563
Overall Steps per Second: 10,869.06916

Timestep Collection Time: 2.15295
Timestep Consumption Time: 2.44854
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.60150

Cumulative Model Updates: 136,304
Cumulative Timesteps: 1,136,583,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1136583660...
Checkpoint 1136583660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.93028
Policy Entropy: 3.92214
Value Function Loss: 0.03756

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.60804
Value Function Update Magnitude: 0.61780

Collected Steps per Second: 22,592.53518
Overall Steps per Second: 10,641.09367

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70196

Cumulative Model Updates: 136,310
Cumulative Timesteps: 1,136,633,694

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,030.50960
Policy Entropy: 3.93688
Value Function Loss: 0.03761

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.61208
Value Function Update Magnitude: 0.70621

Collected Steps per Second: 22,891.69314
Overall Steps per Second: 10,913.86086

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.58316

Cumulative Model Updates: 136,316
Cumulative Timesteps: 1,136,683,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1136683714...
Checkpoint 1136683714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.19275
Policy Entropy: 3.95206
Value Function Loss: 0.03769

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.63115
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,686.22361
Overall Steps per Second: 10,715.07117

Timestep Collection Time: 2.20451
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.66744

Cumulative Model Updates: 136,322
Cumulative Timesteps: 1,136,733,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,597.68806
Policy Entropy: 3.94842
Value Function Loss: 0.03858

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.66723
Value Function Update Magnitude: 0.57779

Collected Steps per Second: 23,098.63591
Overall Steps per Second: 10,844.88041

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.61158

Cumulative Model Updates: 136,328
Cumulative Timesteps: 1,136,783,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1136783738...
Checkpoint 1136783738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,282.40837
Policy Entropy: 3.89284
Value Function Loss: 0.03791

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.67355
Value Function Update Magnitude: 0.61529

Collected Steps per Second: 22,799.26750
Overall Steps per Second: 10,754.06744

Timestep Collection Time: 2.19419
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.65182

Cumulative Model Updates: 136,334
Cumulative Timesteps: 1,136,833,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,714.53087
Policy Entropy: 3.82008
Value Function Loss: 0.04213

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.17339
Policy Update Magnitude: 0.60366
Value Function Update Magnitude: 0.55900

Collected Steps per Second: 22,631.55639
Overall Steps per Second: 10,813.03412

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.62423

Cumulative Model Updates: 136,340
Cumulative Timesteps: 1,136,883,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1136883766...
Checkpoint 1136883766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,877.12401
Policy Entropy: 3.78256
Value Function Loss: 0.04202

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15474
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.51008

Collected Steps per Second: 22,688.20539
Overall Steps per Second: 10,750.69744

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.65328

Cumulative Model Updates: 136,346
Cumulative Timesteps: 1,136,933,792

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,515.62464
Policy Entropy: 3.78256
Value Function Loss: 0.04001

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.15903
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.47960

Collected Steps per Second: 23,195.60423
Overall Steps per Second: 10,808.07018

Timestep Collection Time: 2.15618
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.62747

Cumulative Model Updates: 136,352
Cumulative Timesteps: 1,136,983,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1136983806...
Checkpoint 1136983806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.51130
Policy Entropy: 3.80996
Value Function Loss: 0.03503

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.57731
Value Function Update Magnitude: 0.47643

Collected Steps per Second: 22,676.93896
Overall Steps per Second: 10,730.57100

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.66052

Cumulative Model Updates: 136,358
Cumulative Timesteps: 1,137,033,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,225.46083
Policy Entropy: 3.79162
Value Function Loss: 0.03283

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.17572
Policy Update Magnitude: 0.59816
Value Function Update Magnitude: 0.54079

Collected Steps per Second: 23,066.68475
Overall Steps per Second: 10,807.81876

Timestep Collection Time: 2.16832
Timestep Consumption Time: 2.45944
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.62776

Cumulative Model Updates: 136,364
Cumulative Timesteps: 1,137,083,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1137083832...
Checkpoint 1137083832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,993.65099
Policy Entropy: 3.76621
Value Function Loss: 0.03408

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.59212
Value Function Update Magnitude: 0.54730

Collected Steps per Second: 22,664.03903
Overall Steps per Second: 10,657.61832

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.48534
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69148

Cumulative Model Updates: 136,370
Cumulative Timesteps: 1,137,133,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,931.71398
Policy Entropy: 3.75271
Value Function Loss: 0.03467

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.69329
Value Function Update Magnitude: 0.40925

Collected Steps per Second: 22,937.11631
Overall Steps per Second: 10,857.97727

Timestep Collection Time: 2.18118
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.60767

Cumulative Model Updates: 136,376
Cumulative Timesteps: 1,137,183,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1137183862...
Checkpoint 1137183862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,931.71398
Policy Entropy: 3.76874
Value Function Loss: 0.03678

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17514
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 22,895.47406
Overall Steps per Second: 10,700.67170

Timestep Collection Time: 2.18445
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.67391

Cumulative Model Updates: 136,382
Cumulative Timesteps: 1,137,233,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,047.94825
Policy Entropy: 3.75767
Value Function Loss: 0.03507

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.45450
Value Function Update Magnitude: 0.28015

Collected Steps per Second: 23,147.34783
Overall Steps per Second: 10,937.99161

Timestep Collection Time: 2.16059
Timestep Consumption Time: 2.41173
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.57232

Cumulative Model Updates: 136,388
Cumulative Timesteps: 1,137,283,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1137283888...
Checkpoint 1137283888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,344.09001
Policy Entropy: 3.77491
Value Function Loss: 0.03082

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15896
Policy Update Magnitude: 0.43661
Value Function Update Magnitude: 0.27453

Collected Steps per Second: 22,766.71112
Overall Steps per Second: 10,701.99339

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.67408

Cumulative Model Updates: 136,394
Cumulative Timesteps: 1,137,333,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,316.61683
Policy Entropy: 3.77225
Value Function Loss: 0.02774

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.43302
Value Function Update Magnitude: 0.32279

Collected Steps per Second: 23,155.17939
Overall Steps per Second: 10,754.91710

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.64904

Cumulative Model Updates: 136,400
Cumulative Timesteps: 1,137,383,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1137383910...
Checkpoint 1137383910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,781.90220
Policy Entropy: 3.81237
Value Function Loss: 0.02522

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.57796
Value Function Update Magnitude: 0.40057

Collected Steps per Second: 22,845.05265
Overall Steps per Second: 10,707.20995

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.67143

Cumulative Model Updates: 136,406
Cumulative Timesteps: 1,137,433,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,696.71629
Policy Entropy: 3.80948
Value Function Loss: 0.02457

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.70170
Value Function Update Magnitude: 0.47961

Collected Steps per Second: 23,317.04300
Overall Steps per Second: 10,895.27527

Timestep Collection Time: 2.14581
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.59227

Cumulative Model Updates: 136,412
Cumulative Timesteps: 1,137,483,962

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1137483962...
Checkpoint 1137483962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.72186
Policy Entropy: 3.81012
Value Function Loss: 0.02704

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09200
Policy Update Magnitude: 0.70605
Value Function Update Magnitude: 0.48113

Collected Steps per Second: 22,156.62448
Overall Steps per Second: 10,747.68268

Timestep Collection Time: 2.25756
Timestep Consumption Time: 2.39646
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65403

Cumulative Model Updates: 136,418
Cumulative Timesteps: 1,137,533,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,145.67893
Policy Entropy: 3.81639
Value Function Loss: 0.02583

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07834
Policy Update Magnitude: 0.69374
Value Function Update Magnitude: 0.41215

Collected Steps per Second: 22,551.82959
Overall Steps per Second: 10,786.46050

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.41842
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.63563

Cumulative Model Updates: 136,424
Cumulative Timesteps: 1,137,583,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1137583984...
Checkpoint 1137583984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.23144
Policy Entropy: 3.81408
Value Function Loss: 0.02268

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07518
Policy Update Magnitude: 0.65781
Value Function Update Magnitude: 0.39246

Collected Steps per Second: 22,222.48381
Overall Steps per Second: 10,756.95757

Timestep Collection Time: 2.25123
Timestep Consumption Time: 2.39952
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.65076

Cumulative Model Updates: 136,430
Cumulative Timesteps: 1,137,634,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.66066
Policy Entropy: 3.82167
Value Function Loss: 0.02274

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07690
Policy Update Magnitude: 0.58689
Value Function Update Magnitude: 0.35980

Collected Steps per Second: 22,075.04934
Overall Steps per Second: 10,797.75718

Timestep Collection Time: 2.26554
Timestep Consumption Time: 2.36616
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.63170

Cumulative Model Updates: 136,436
Cumulative Timesteps: 1,137,684,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1137684024...
Checkpoint 1137684024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,429.10908
Policy Entropy: 3.80486
Value Function Loss: 0.02407

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.53100
Value Function Update Magnitude: 0.32783

Collected Steps per Second: 22,206.83634
Overall Steps per Second: 10,596.54051

Timestep Collection Time: 2.25156
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.71852

Cumulative Model Updates: 136,442
Cumulative Timesteps: 1,137,734,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,787.40562
Policy Entropy: 3.80513
Value Function Loss: 0.02122

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17483
Policy Update Magnitude: 0.50553
Value Function Update Magnitude: 0.39724

Collected Steps per Second: 23,392.10606
Overall Steps per Second: 10,945.08115

Timestep Collection Time: 2.13816
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.56972

Cumulative Model Updates: 136,448
Cumulative Timesteps: 1,137,784,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1137784040...
Checkpoint 1137784040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,947.75314
Policy Entropy: 3.79225
Value Function Loss: 0.01937

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16733
Policy Update Magnitude: 0.42463
Value Function Update Magnitude: 0.41764

Collected Steps per Second: 22,740.00870
Overall Steps per Second: 10,772.47913

Timestep Collection Time: 2.19903
Timestep Consumption Time: 2.44298
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.64201

Cumulative Model Updates: 136,454
Cumulative Timesteps: 1,137,834,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,170.21941
Policy Entropy: 3.76637
Value Function Loss: 0.01694

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.17114
Policy Update Magnitude: 0.37292
Value Function Update Magnitude: 0.46195

Collected Steps per Second: 23,197.20435
Overall Steps per Second: 10,775.85626

Timestep Collection Time: 2.15569
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.64056

Cumulative Model Updates: 136,460
Cumulative Timesteps: 1,137,884,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1137884052...
Checkpoint 1137884052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,289.91125
Policy Entropy: 3.74697
Value Function Loss: 0.02770

Mean KL Divergence: 0.02612
SB3 Clip Fraction: 0.25964
Policy Update Magnitude: 0.36218
Value Function Update Magnitude: 0.54805

Collected Steps per Second: 22,353.38169
Overall Steps per Second: 10,637.44081

Timestep Collection Time: 2.23751
Timestep Consumption Time: 2.46437
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.70188

Cumulative Model Updates: 136,466
Cumulative Timesteps: 1,137,934,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,544.07845
Policy Entropy: 3.76024
Value Function Loss: 0.04446

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.22310
Policy Update Magnitude: 0.51438
Value Function Update Magnitude: 0.55640

Collected Steps per Second: 22,825.67525
Overall Steps per Second: 10,817.71450

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62205

Cumulative Model Updates: 136,472
Cumulative Timesteps: 1,137,984,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1137984068...
Checkpoint 1137984068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,940.31367
Policy Entropy: 3.81042
Value Function Loss: 0.05773

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.64772
Value Function Update Magnitude: 0.48131

Collected Steps per Second: 22,606.35534
Overall Steps per Second: 10,705.73608

Timestep Collection Time: 2.21301
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.67301

Cumulative Model Updates: 136,478
Cumulative Timesteps: 1,138,034,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.95346
Policy Entropy: 3.88404
Value Function Loss: 0.05160

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.91226
Value Function Update Magnitude: 0.55516

Collected Steps per Second: 22,872.71408
Overall Steps per Second: 10,905.15490

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.58499

Cumulative Model Updates: 136,484
Cumulative Timesteps: 1,138,084,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1138084096...
Checkpoint 1138084096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.39824
Policy Entropy: 3.92996
Value Function Loss: 0.04139

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 1.05840
Value Function Update Magnitude: 0.80876

Collected Steps per Second: 22,506.45029
Overall Steps per Second: 10,657.43829

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.69381

Cumulative Model Updates: 136,490
Cumulative Timesteps: 1,138,134,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81457
Policy Entropy: 3.92697
Value Function Loss: 0.03702

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10311
Policy Update Magnitude: 0.96478
Value Function Update Magnitude: 0.86428

Collected Steps per Second: 23,204.01848
Overall Steps per Second: 10,871.27723

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.60112

Cumulative Model Updates: 136,496
Cumulative Timesteps: 1,138,184,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1138184140...
Checkpoint 1138184140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,315.34385
Policy Entropy: 3.90454
Value Function Loss: 0.03329

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.82190
Value Function Update Magnitude: 0.75100

Collected Steps per Second: 22,936.31623
Overall Steps per Second: 10,799.78781

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.45056
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.63120

Cumulative Model Updates: 136,502
Cumulative Timesteps: 1,138,234,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249.86044
Policy Entropy: 3.89841
Value Function Loss: 0.02829

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15971
Policy Update Magnitude: 0.62675
Value Function Update Magnitude: 0.69611

Collected Steps per Second: 23,392.69477
Overall Steps per Second: 10,871.00888

Timestep Collection Time: 2.13785
Timestep Consumption Time: 2.46246
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.60031

Cumulative Model Updates: 136,508
Cumulative Timesteps: 1,138,284,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1138284166...
Checkpoint 1138284166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,777.84725
Policy Entropy: 3.88222
Value Function Loss: 0.02651

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.57846
Value Function Update Magnitude: 0.73192

Collected Steps per Second: 22,914.94646
Overall Steps per Second: 10,959.46326

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.38152
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.56464

Cumulative Model Updates: 136,514
Cumulative Timesteps: 1,138,334,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.45935
Policy Entropy: 3.84563
Value Function Loss: 0.02289

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.79228

Collected Steps per Second: 23,171.93768
Overall Steps per Second: 11,005.10337

Timestep Collection Time: 2.15908
Timestep Consumption Time: 2.38700
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.54607

Cumulative Model Updates: 136,520
Cumulative Timesteps: 1,138,384,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1138384222...
Checkpoint 1138384222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,232.29641
Policy Entropy: 3.77592
Value Function Loss: 0.02221

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11951
Policy Update Magnitude: 0.47234
Value Function Update Magnitude: 0.78164

Collected Steps per Second: 23,061.73629
Overall Steps per Second: 10,775.07023

Timestep Collection Time: 2.16818
Timestep Consumption Time: 2.47235
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.64053

Cumulative Model Updates: 136,526
Cumulative Timesteps: 1,138,434,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,887.61052
Policy Entropy: 3.76011
Value Function Loss: 0.02223

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.45109
Value Function Update Magnitude: 0.71706

Collected Steps per Second: 23,212.29099
Overall Steps per Second: 10,767.73953

Timestep Collection Time: 2.15524
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.64610

Cumulative Model Updates: 136,532
Cumulative Timesteps: 1,138,484,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1138484252...
Checkpoint 1138484252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,810.44154
Policy Entropy: 3.76367
Value Function Loss: 0.02328

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.47686
Value Function Update Magnitude: 0.60857

Collected Steps per Second: 22,785.21978
Overall Steps per Second: 10,687.23155

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.67998

Cumulative Model Updates: 136,538
Cumulative Timesteps: 1,138,534,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,088.92810
Policy Entropy: 3.78064
Value Function Loss: 0.02106

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.45588
Value Function Update Magnitude: 0.55802

Collected Steps per Second: 23,150.73473
Overall Steps per Second: 10,829.40971

Timestep Collection Time: 2.16036
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.61835

Cumulative Model Updates: 136,544
Cumulative Timesteps: 1,138,584,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1138584282...
Checkpoint 1138584282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,791.73909
Policy Entropy: 3.77039
Value Function Loss: 0.01942

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.42189
Value Function Update Magnitude: 0.50741

Collected Steps per Second: 22,703.29018
Overall Steps per Second: 10,619.22493

Timestep Collection Time: 2.20312
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.71014

Cumulative Model Updates: 136,550
Cumulative Timesteps: 1,138,634,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.77839
Policy Entropy: 3.76335
Value Function Loss: 0.01987

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.37759
Value Function Update Magnitude: 0.47775

Collected Steps per Second: 23,168.43392
Overall Steps per Second: 10,890.47136

Timestep Collection Time: 2.15828
Timestep Consumption Time: 2.43326
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.59154

Cumulative Model Updates: 136,556
Cumulative Timesteps: 1,138,684,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1138684304...
Checkpoint 1138684304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223.46762
Policy Entropy: 3.76661
Value Function Loss: 0.01861

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.38908
Value Function Update Magnitude: 0.56756

Collected Steps per Second: 22,140.30963
Overall Steps per Second: 10,728.59207

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.40231
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.66082

Cumulative Model Updates: 136,562
Cumulative Timesteps: 1,138,734,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,794.33065
Policy Entropy: 3.76970
Value Function Loss: 0.01929

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.39438
Value Function Update Magnitude: 0.64231

Collected Steps per Second: 23,177.71752
Overall Steps per Second: 10,874.50515

Timestep Collection Time: 2.15845
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.60049

Cumulative Model Updates: 136,568
Cumulative Timesteps: 1,138,784,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1138784336...
Checkpoint 1138784336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,027.18309
Policy Entropy: 3.77636
Value Function Loss: 0.01746

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.40328
Value Function Update Magnitude: 0.67731

Collected Steps per Second: 22,990.43323
Overall Steps per Second: 10,745.23907

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.65453

Cumulative Model Updates: 136,574
Cumulative Timesteps: 1,138,834,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153.34478
Policy Entropy: 3.77145
Value Function Loss: 0.01722

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.40295
Value Function Update Magnitude: 0.70018

Collected Steps per Second: 22,757.43788
Overall Steps per Second: 10,807.39682

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.62739

Cumulative Model Updates: 136,580
Cumulative Timesteps: 1,138,884,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1138884360...
Checkpoint 1138884360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,153.34478
Policy Entropy: 3.74546
Value Function Loss: 0.01802

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.38334
Value Function Update Magnitude: 0.55288

Collected Steps per Second: 22,976.57020
Overall Steps per Second: 10,750.37816

Timestep Collection Time: 2.17683
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.65249

Cumulative Model Updates: 136,586
Cumulative Timesteps: 1,138,934,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,135.22413
Policy Entropy: 3.75067
Value Function Loss: 0.01961

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.39104
Value Function Update Magnitude: 0.49491

Collected Steps per Second: 23,159.31903
Overall Steps per Second: 10,775.03384

Timestep Collection Time: 2.15922
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.64091

Cumulative Model Updates: 136,592
Cumulative Timesteps: 1,138,984,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1138984382...
Checkpoint 1138984382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,120.97051
Policy Entropy: 3.75143
Value Function Loss: 0.01963

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.40660
Value Function Update Magnitude: 0.57952

Collected Steps per Second: 23,043.29070
Overall Steps per Second: 10,804.99479

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.45884
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.62971

Cumulative Model Updates: 136,598
Cumulative Timesteps: 1,139,034,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,157.01421
Policy Entropy: 3.74395
Value Function Loss: 0.02099

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.42197
Value Function Update Magnitude: 0.63630

Collected Steps per Second: 22,413.61128
Overall Steps per Second: 10,764.97023

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.64748

Cumulative Model Updates: 136,604
Cumulative Timesteps: 1,139,084,436

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1139084436...
Checkpoint 1139084436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,119.56714
Policy Entropy: 3.72550
Value Function Loss: 0.02248

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.39390
Value Function Update Magnitude: 0.52564

Collected Steps per Second: 22,239.82460
Overall Steps per Second: 10,774.20398

Timestep Collection Time: 2.24894
Timestep Consumption Time: 2.39326
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.64220

Cumulative Model Updates: 136,610
Cumulative Timesteps: 1,139,134,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,119.56714
Policy Entropy: 3.72175
Value Function Loss: 0.01973

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.41032
Value Function Update Magnitude: 0.48837

Collected Steps per Second: 22,409.01678
Overall Steps per Second: 10,735.20558

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66018

Cumulative Model Updates: 136,616
Cumulative Timesteps: 1,139,184,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1139184480...
Checkpoint 1139184480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,965.96404
Policy Entropy: 3.72688
Value Function Loss: 0.01990

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.38286
Value Function Update Magnitude: 0.38583

Collected Steps per Second: 22,622.14165
Overall Steps per Second: 10,697.97139

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.46376
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.67416

Cumulative Model Updates: 136,622
Cumulative Timesteps: 1,139,234,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,500.79160
Policy Entropy: 3.72386
Value Function Loss: 0.02325

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.38721
Value Function Update Magnitude: 0.36120

Collected Steps per Second: 22,802.94617
Overall Steps per Second: 10,916.07401

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.38866
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.58223

Cumulative Model Updates: 136,628
Cumulative Timesteps: 1,139,284,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1139284504...
Checkpoint 1139284504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,741.30191
Policy Entropy: 3.73628
Value Function Loss: 0.02110

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.16062
Policy Update Magnitude: 0.45985
Value Function Update Magnitude: 0.44605

Collected Steps per Second: 22,632.10954
Overall Steps per Second: 10,751.43624

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.65259

Cumulative Model Updates: 136,634
Cumulative Timesteps: 1,139,334,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,741.30191
Policy Entropy: 3.71152
Value Function Loss: 0.02649

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.46230
Value Function Update Magnitude: 0.47117

Collected Steps per Second: 23,429.58258
Overall Steps per Second: 10,789.47836

Timestep Collection Time: 2.13414
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.63433

Cumulative Model Updates: 136,640
Cumulative Timesteps: 1,139,384,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1139384528...
Checkpoint 1139384528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,367.03304
Policy Entropy: 3.72493
Value Function Loss: 0.02263

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.48689
Value Function Update Magnitude: 0.41626

Collected Steps per Second: 22,799.19962
Overall Steps per Second: 10,667.35963

Timestep Collection Time: 2.19446
Timestep Consumption Time: 2.49573
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.69020

Cumulative Model Updates: 136,646
Cumulative Timesteps: 1,139,434,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,367.03304
Policy Entropy: 3.68746
Value Function Loss: 0.02891

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.49995
Value Function Update Magnitude: 0.45854

Collected Steps per Second: 23,206.78609
Overall Steps per Second: 10,871.21810

Timestep Collection Time: 2.15549
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.60132

Cumulative Model Updates: 136,652
Cumulative Timesteps: 1,139,484,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1139484582...
Checkpoint 1139484582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,683.09443
Policy Entropy: 3.74344
Value Function Loss: 0.02403

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.55028

Collected Steps per Second: 22,814.06170
Overall Steps per Second: 10,661.88690

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.69223

Cumulative Model Updates: 136,658
Cumulative Timesteps: 1,139,534,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,103.88757
Policy Entropy: 3.73178
Value Function Loss: 0.02468

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.62523

Collected Steps per Second: 23,252.14424
Overall Steps per Second: 10,885.27316

Timestep Collection Time: 2.15086
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.59446

Cumulative Model Updates: 136,664
Cumulative Timesteps: 1,139,584,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1139584622...
Checkpoint 1139584622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,290.50650
Policy Entropy: 3.77793
Value Function Loss: 0.01851

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.66040

Collected Steps per Second: 23,074.40710
Overall Steps per Second: 10,797.26623

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.63247

Cumulative Model Updates: 136,670
Cumulative Timesteps: 1,139,634,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.15580
Policy Entropy: 3.75268
Value Function Loss: 0.01664

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14515
Policy Update Magnitude: 0.40650
Value Function Update Magnitude: 0.64874

Collected Steps per Second: 23,183.28263
Overall Steps per Second: 10,759.65974

Timestep Collection Time: 2.15673
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.64699

Cumulative Model Updates: 136,676
Cumulative Timesteps: 1,139,684,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1139684640...
Checkpoint 1139684640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,277.15580
Policy Entropy: 3.76156
Value Function Loss: 0.01393

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.36597
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 22,942.81603
Overall Steps per Second: 10,728.09183

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.66085

Cumulative Model Updates: 136,682
Cumulative Timesteps: 1,139,734,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,894.15510
Policy Entropy: 3.74488
Value Function Loss: 0.01292

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.38833
Value Function Update Magnitude: 0.61143

Collected Steps per Second: 23,207.62306
Overall Steps per Second: 10,771.31513

Timestep Collection Time: 2.15567
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.64456

Cumulative Model Updates: 136,688
Cumulative Timesteps: 1,139,784,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1139784670...
Checkpoint 1139784670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,298.90832
Policy Entropy: 3.74955
Value Function Loss: 0.01338

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.37755
Value Function Update Magnitude: 0.63781

Collected Steps per Second: 23,087.47267
Overall Steps per Second: 10,783.04735

Timestep Collection Time: 2.16654
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.63876

Cumulative Model Updates: 136,694
Cumulative Timesteps: 1,139,834,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,183.31484
Policy Entropy: 3.74605
Value Function Loss: 0.01425

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.38753
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 23,199.36720
Overall Steps per Second: 10,778.01883

Timestep Collection Time: 2.15523
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.63907

Cumulative Model Updates: 136,700
Cumulative Timesteps: 1,139,884,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1139884690...
Checkpoint 1139884690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,400.68696
Policy Entropy: 3.73787
Value Function Loss: 0.01544

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.41360
Value Function Update Magnitude: 0.64245

Collected Steps per Second: 22,851.12984
Overall Steps per Second: 10,708.13540

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.67084

Cumulative Model Updates: 136,706
Cumulative Timesteps: 1,139,934,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,400.68696
Policy Entropy: 3.74790
Value Function Loss: 0.01478

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.41468
Value Function Update Magnitude: 0.61277

Collected Steps per Second: 23,029.13922
Overall Steps per Second: 10,835.81900

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61691

Cumulative Model Updates: 136,712
Cumulative Timesteps: 1,139,984,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1139984734...
Checkpoint 1139984734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,931.53692
Policy Entropy: 3.74560
Value Function Loss: 0.01602

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.40890
Value Function Update Magnitude: 0.59694

Collected Steps per Second: 22,969.17594
Overall Steps per Second: 10,731.52077

Timestep Collection Time: 2.17709
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.65973

Cumulative Model Updates: 136,718
Cumulative Timesteps: 1,140,034,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,626.16235
Policy Entropy: 3.75475
Value Function Loss: 0.01604

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.42905
Value Function Update Magnitude: 0.60962

Collected Steps per Second: 22,948.49074
Overall Steps per Second: 10,810.65688

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.44794
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62821

Cumulative Model Updates: 136,724
Cumulative Timesteps: 1,140,084,774

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1140084774...
Checkpoint 1140084774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.73717
Value Function Loss: 0.01840

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.44319
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,928.98795
Overall Steps per Second: 10,698.77514

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.67455

Cumulative Model Updates: 136,730
Cumulative Timesteps: 1,140,134,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74934
Value Function Loss: 0.01796

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.43475
Value Function Update Magnitude: 0.56941

Collected Steps per Second: 23,381.91879
Overall Steps per Second: 10,855.58895

Timestep Collection Time: 2.13986
Timestep Consumption Time: 2.46920
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.60905

Cumulative Model Updates: 136,736
Cumulative Timesteps: 1,140,184,820

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1140184820...
Checkpoint 1140184820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74394
Value Function Loss: 0.01814

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.40954
Value Function Update Magnitude: 0.40690

Collected Steps per Second: 22,965.73270
Overall Steps per Second: 10,755.84831

Timestep Collection Time: 2.17811
Timestep Consumption Time: 2.47256
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.65068

Cumulative Model Updates: 136,742
Cumulative Timesteps: 1,140,234,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.75861
Value Function Loss: 0.01364

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.38277
Value Function Update Magnitude: 0.33428

Collected Steps per Second: 22,360.85122
Overall Steps per Second: 10,805.82463

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.39328
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.63139

Cumulative Model Updates: 136,748
Cumulative Timesteps: 1,140,284,888

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1140284888...
Checkpoint 1140284888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.75231
Value Function Loss: 0.01313

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.34162
Value Function Update Magnitude: 0.40371

Collected Steps per Second: 22,267.87129
Overall Steps per Second: 10,771.32620

Timestep Collection Time: 2.24593
Timestep Consumption Time: 2.39714
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.64307

Cumulative Model Updates: 136,754
Cumulative Timesteps: 1,140,334,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74401
Value Function Loss: 0.01442

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.35263
Value Function Update Magnitude: 0.45452

Collected Steps per Second: 22,610.12469
Overall Steps per Second: 10,762.35245

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.43550
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.64787

Cumulative Model Updates: 136,760
Cumulative Timesteps: 1,140,384,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1140384922...
Checkpoint 1140384922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74955
Value Function Loss: 0.01520

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.38007
Value Function Update Magnitude: 0.40833

Collected Steps per Second: 22,857.04781
Overall Steps per Second: 10,791.49309

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.44685
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.63532

Cumulative Model Updates: 136,766
Cumulative Timesteps: 1,140,434,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.73582
Value Function Loss: 0.01728

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.36418
Value Function Update Magnitude: 0.36135

Collected Steps per Second: 23,181.71494
Overall Steps per Second: 10,829.20092

Timestep Collection Time: 2.15774
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.61899

Cumulative Model Updates: 136,772
Cumulative Timesteps: 1,140,484,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1140484964...
Checkpoint 1140484964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74643
Value Function Loss: 0.01550

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.37164
Value Function Update Magnitude: 0.37632

Collected Steps per Second: 23,067.22291
Overall Steps per Second: 10,911.46042

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.58307

Cumulative Model Updates: 136,778
Cumulative Timesteps: 1,140,534,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.72295
Value Function Loss: 0.01727

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.37380
Value Function Update Magnitude: 0.35380

Collected Steps per Second: 23,134.81295
Overall Steps per Second: 10,928.22976

Timestep Collection Time: 2.16168
Timestep Consumption Time: 2.41454
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.57622

Cumulative Model Updates: 136,784
Cumulative Timesteps: 1,140,584,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1140584982...
Checkpoint 1140584982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74420
Value Function Loss: 0.01613

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.13013
Policy Update Magnitude: 0.38246
Value Function Update Magnitude: 0.32134

Collected Steps per Second: 23,074.55423
Overall Steps per Second: 10,709.44391

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.50229
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66952

Cumulative Model Updates: 136,790
Cumulative Timesteps: 1,140,634,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.73430
Value Function Loss: 0.01609

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.37367
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 23,203.77006
Overall Steps per Second: 10,898.94339

Timestep Collection Time: 2.15543
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.58889

Cumulative Model Updates: 136,796
Cumulative Timesteps: 1,140,685,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1140685004...
Checkpoint 1140685004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74755
Value Function Loss: 0.01334

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.33801
Value Function Update Magnitude: 0.28605

Collected Steps per Second: 23,033.95637
Overall Steps per Second: 10,744.47792

Timestep Collection Time: 2.17166
Timestep Consumption Time: 2.48394
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.65560

Cumulative Model Updates: 136,802
Cumulative Timesteps: 1,140,735,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.73924
Value Function Loss: 0.01304

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.31271
Value Function Update Magnitude: 0.29019

Collected Steps per Second: 22,988.92219
Overall Steps per Second: 10,808.69815

Timestep Collection Time: 2.17496
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.62590

Cumulative Model Updates: 136,808
Cumulative Timesteps: 1,140,785,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1140785026...
Checkpoint 1140785026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,381.30907
Policy Entropy: 3.74529
Value Function Loss: 0.01218

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12629
Policy Update Magnitude: 0.31818
Value Function Update Magnitude: 0.32403

Collected Steps per Second: 22,763.04655
Overall Steps per Second: 10,667.62172

Timestep Collection Time: 2.19777
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.68971

Cumulative Model Updates: 136,814
Cumulative Timesteps: 1,140,835,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,690.17853
Policy Entropy: 3.73286
Value Function Loss: 0.01617

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.35173
Value Function Update Magnitude: 0.48377

Collected Steps per Second: 22,342.54289
Overall Steps per Second: 10,638.73331

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.46232
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.70056

Cumulative Model Updates: 136,820
Cumulative Timesteps: 1,140,885,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1140885062...
Checkpoint 1140885062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,627.92543
Policy Entropy: 3.75059
Value Function Loss: 0.01638

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.40649
Value Function Update Magnitude: 0.63219

Collected Steps per Second: 22,967.24140
Overall Steps per Second: 10,939.73204

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.39415
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.57178

Cumulative Model Updates: 136,826
Cumulative Timesteps: 1,140,935,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,402.03097
Policy Entropy: 3.73488
Value Function Loss: 0.01758

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.42777
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 22,452.88575
Overall Steps per Second: 10,878.69754

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.37020
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.59798

Cumulative Model Updates: 136,832
Cumulative Timesteps: 1,140,985,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1140985096...
Checkpoint 1140985096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,402.03097
Policy Entropy: 3.74602
Value Function Loss: 0.01410

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.40663
Value Function Update Magnitude: 0.57093

Collected Steps per Second: 22,150.68339
Overall Steps per Second: 10,713.69608

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.40966
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.66692

Cumulative Model Updates: 136,838
Cumulative Timesteps: 1,141,035,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,458.24750
Policy Entropy: 3.73239
Value Function Loss: 0.01760

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.41352
Value Function Update Magnitude: 0.49663

Collected Steps per Second: 22,364.92736
Overall Steps per Second: 10,881.00825

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.35952
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.59516

Cumulative Model Updates: 136,844
Cumulative Timesteps: 1,141,085,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1141085096...
Checkpoint 1141085096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,291.79201
Policy Entropy: 3.73735
Value Function Loss: 0.01843

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.44160
Value Function Update Magnitude: 0.41533

Collected Steps per Second: 22,236.47751
Overall Steps per Second: 10,587.49753

Timestep Collection Time: 2.24946
Timestep Consumption Time: 2.47498
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.72444

Cumulative Model Updates: 136,850
Cumulative Timesteps: 1,141,135,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,291.79201
Policy Entropy: 3.73856
Value Function Loss: 0.01908

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.43790
Value Function Update Magnitude: 0.44038

Collected Steps per Second: 22,766.60245
Overall Steps per Second: 10,887.28049

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.39679
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.59343

Cumulative Model Updates: 136,856
Cumulative Timesteps: 1,141,185,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1141185126...
Checkpoint 1141185126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,590.82108
Policy Entropy: 3.72624
Value Function Loss: 0.01895

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.46320
Value Function Update Magnitude: 0.50175

Collected Steps per Second: 22,774.29723
Overall Steps per Second: 10,632.62096

Timestep Collection Time: 2.19581
Timestep Consumption Time: 2.50745
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70326

Cumulative Model Updates: 136,862
Cumulative Timesteps: 1,141,235,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,576.71368
Policy Entropy: 3.72986
Value Function Loss: 0.02081

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 22,863.68788
Overall Steps per Second: 10,858.81523

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.41768
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.60455

Cumulative Model Updates: 136,868
Cumulative Timesteps: 1,141,285,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1141285134...
Checkpoint 1141285134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,576.71368
Policy Entropy: 3.72677
Value Function Loss: 0.01945

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.47629
Value Function Update Magnitude: 0.62712

Collected Steps per Second: 22,755.06155
Overall Steps per Second: 10,708.90860

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.67218

Cumulative Model Updates: 136,874
Cumulative Timesteps: 1,141,335,168

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,576.71368
Policy Entropy: 3.73790
Value Function Loss: 0.01689

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.43342
Value Function Update Magnitude: 0.46298

Collected Steps per Second: 22,683.09166
Overall Steps per Second: 10,815.43758

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.41893
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.62339

Cumulative Model Updates: 136,880
Cumulative Timesteps: 1,141,385,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1141385172...
Checkpoint 1141385172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,576.71368
Policy Entropy: 3.73311
Value Function Loss: 0.01493

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.38515
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 22,844.21637
Overall Steps per Second: 10,721.57347

Timestep Collection Time: 2.18961
Timestep Consumption Time: 2.47575
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66536

Cumulative Model Updates: 136,886
Cumulative Timesteps: 1,141,435,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,598.30922
Policy Entropy: 3.74672
Value Function Loss: 0.01595

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.45707
Value Function Update Magnitude: 0.41572

Collected Steps per Second: 23,100.73230
Overall Steps per Second: 10,940.53736

Timestep Collection Time: 2.16539
Timestep Consumption Time: 2.40678
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.57217

Cumulative Model Updates: 136,892
Cumulative Timesteps: 1,141,485,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1141485214...
Checkpoint 1141485214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,024.43590
Policy Entropy: 3.75618
Value Function Loss: 0.01505

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.48041
Value Function Update Magnitude: 0.56399

Collected Steps per Second: 23,328.42999
Overall Steps per Second: 10,963.68422

Timestep Collection Time: 2.14425
Timestep Consumption Time: 2.41827
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.56252

Cumulative Model Updates: 136,898
Cumulative Timesteps: 1,141,535,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,774.32300
Policy Entropy: 3.76202
Value Function Loss: 0.01453

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.44846
Value Function Update Magnitude: 0.59402

Collected Steps per Second: 22,878.20914
Overall Steps per Second: 10,734.25446

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.66041

Cumulative Model Updates: 136,904
Cumulative Timesteps: 1,141,585,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1141585262...
Checkpoint 1141585262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,774.32300
Policy Entropy: 3.74261
Value Function Loss: 0.01385

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.42057
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 22,293.61044
Overall Steps per Second: 10,887.44263

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.34975
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.59263

Cumulative Model Updates: 136,910
Cumulative Timesteps: 1,141,635,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,357.31116
Policy Entropy: 3.74208
Value Function Loss: 0.01540

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.41282
Value Function Update Magnitude: 0.51769

Collected Steps per Second: 22,035.95853
Overall Steps per Second: 10,731.96065

Timestep Collection Time: 2.27020
Timestep Consumption Time: 2.39121
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.66140

Cumulative Model Updates: 136,916
Cumulative Timesteps: 1,141,685,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1141685290...
Checkpoint 1141685290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,562.41675
Policy Entropy: 3.73912
Value Function Loss: 0.01712

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.42327
Value Function Update Magnitude: 0.53177

Collected Steps per Second: 22,095.21555
Overall Steps per Second: 10,857.84155

Timestep Collection Time: 2.26375
Timestep Consumption Time: 2.34288
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.60662

Cumulative Model Updates: 136,922
Cumulative Timesteps: 1,141,735,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,093.48042
Policy Entropy: 3.75643
Value Function Loss: 0.01924

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.50556
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 22,102.72597
Overall Steps per Second: 10,588.21587

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.46085
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.72374

Cumulative Model Updates: 136,928
Cumulative Timesteps: 1,141,785,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1141785324...
Checkpoint 1141785324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,759.87185
Policy Entropy: 3.76332
Value Function Loss: 0.02012

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.60464

Collected Steps per Second: 22,890.72904
Overall Steps per Second: 10,923.42476

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.39341
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.57805

Cumulative Model Updates: 136,934
Cumulative Timesteps: 1,141,835,332

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,583.82017
Policy Entropy: 3.76671
Value Function Loss: 0.02049

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.52393
Value Function Update Magnitude: 0.77562

Collected Steps per Second: 22,603.19146
Overall Steps per Second: 10,862.47207

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.39150
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.60411

Cumulative Model Updates: 136,940
Cumulative Timesteps: 1,141,885,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1141885344...
Checkpoint 1141885344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,583.82017
Policy Entropy: 3.73739
Value Function Loss: 0.01887

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.75612

Collected Steps per Second: 22,808.93441
Overall Steps per Second: 10,723.66333

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.66445

Cumulative Model Updates: 136,946
Cumulative Timesteps: 1,141,935,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,940.26718
Policy Entropy: 3.71917
Value Function Loss: 0.01906

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.53640
Value Function Update Magnitude: 0.69075

Collected Steps per Second: 22,636.33177
Overall Steps per Second: 10,796.77446

Timestep Collection Time: 2.21008
Timestep Consumption Time: 2.42353
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.63361

Cumulative Model Updates: 136,952
Cumulative Timesteps: 1,141,985,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1141985392...
Checkpoint 1141985392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,682.01225
Policy Entropy: 3.73251
Value Function Loss: 0.01637

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.48358
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 22,693.67125
Overall Steps per Second: 10,728.83216

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.66071

Cumulative Model Updates: 136,958
Cumulative Timesteps: 1,142,035,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240,569.65240
Policy Entropy: 3.75696
Value Function Loss: 0.01811

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.47465
Value Function Update Magnitude: 0.58477

Collected Steps per Second: 22,631.27524
Overall Steps per Second: 10,678.07323

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.47455
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.68511

Cumulative Model Updates: 136,964
Cumulative Timesteps: 1,142,085,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1142085424...
Checkpoint 1142085424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,875.23704
Policy Entropy: 3.75328
Value Function Loss: 0.01772

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.52977
Value Function Update Magnitude: 0.64633

Collected Steps per Second: 23,050.50709
Overall Steps per Second: 10,877.39918

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.59926

Cumulative Model Updates: 136,970
Cumulative Timesteps: 1,142,135,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,875.23704
Policy Entropy: 3.73278
Value Function Loss: 0.01948

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.70721

Collected Steps per Second: 22,800.92949
Overall Steps per Second: 10,839.35949

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.61448

Cumulative Model Updates: 136,976
Cumulative Timesteps: 1,142,185,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1142185470...
Checkpoint 1142185470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,875.23704
Policy Entropy: 3.72093
Value Function Loss: 0.01866

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.69796

Collected Steps per Second: 23,009.57857
Overall Steps per Second: 10,712.64408

Timestep Collection Time: 2.17483
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.67130

Cumulative Model Updates: 136,982
Cumulative Timesteps: 1,142,235,512

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,875.23704
Policy Entropy: 3.71687
Value Function Loss: 0.02045

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.51779
Value Function Update Magnitude: 0.52759

Collected Steps per Second: 22,652.07548
Overall Steps per Second: 10,675.36967

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.68743

Cumulative Model Updates: 136,988
Cumulative Timesteps: 1,142,285,552

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1142285552...
Checkpoint 1142285552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,863.67374
Policy Entropy: 3.74735
Value Function Loss: 0.01543

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.46941
Value Function Update Magnitude: 0.52841

Collected Steps per Second: 22,990.24401
Overall Steps per Second: 10,887.17370

Timestep Collection Time: 2.17684
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59679

Cumulative Model Updates: 136,994
Cumulative Timesteps: 1,142,335,598

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,863.67374
Policy Entropy: 3.74091
Value Function Loss: 0.01480

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13456
Policy Update Magnitude: 0.44770
Value Function Update Magnitude: 0.57940

Collected Steps per Second: 22,758.98560
Overall Steps per Second: 10,864.07653

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60453

Cumulative Model Updates: 137,000
Cumulative Timesteps: 1,142,385,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1142385622...
Checkpoint 1142385622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,863.67374
Policy Entropy: 3.75366
Value Function Loss: 0.01397

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.44095
Value Function Update Magnitude: 0.51484

Collected Steps per Second: 22,811.67017
Overall Steps per Second: 10,690.29824

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.67826

Cumulative Model Updates: 137,006
Cumulative Timesteps: 1,142,435,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,863.67374
Policy Entropy: 3.73025
Value Function Loss: 0.01624

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.44740
Value Function Update Magnitude: 0.51254

Collected Steps per Second: 22,815.73788
Overall Steps per Second: 10,871.11301

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.40922
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.60192

Cumulative Model Updates: 137,012
Cumulative Timesteps: 1,142,485,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1142485662...
Checkpoint 1142485662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,863.67374
Policy Entropy: 3.73222
Value Function Loss: 0.01558

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14017
Policy Update Magnitude: 0.46995
Value Function Update Magnitude: 0.55218

Collected Steps per Second: 22,663.09904
Overall Steps per Second: 10,716.14827

Timestep Collection Time: 2.20658
Timestep Consumption Time: 2.46002
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.66660

Cumulative Model Updates: 137,018
Cumulative Timesteps: 1,142,535,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,899.47070
Policy Entropy: 3.72069
Value Function Loss: 0.02301

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.48692
Value Function Update Magnitude: 0.59079

Collected Steps per Second: 22,105.51301
Overall Steps per Second: 10,861.40114

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.34345
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.60714

Cumulative Model Updates: 137,024
Cumulative Timesteps: 1,142,585,710

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1142585710...
Checkpoint 1142585710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,422.92363
Policy Entropy: 3.73851
Value Function Loss: 0.02345

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.45836

Collected Steps per Second: 21,947.75894
Overall Steps per Second: 10,678.23419

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.40496
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.68373

Cumulative Model Updates: 137,030
Cumulative Timesteps: 1,142,635,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,484.37247
Policy Entropy: 3.71709
Value Function Loss: 0.02411

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.65295
Value Function Update Magnitude: 0.40011

Collected Steps per Second: 22,282.68709
Overall Steps per Second: 10,862.86050

Timestep Collection Time: 2.24398
Timestep Consumption Time: 2.35904
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.60302

Cumulative Model Updates: 137,036
Cumulative Timesteps: 1,142,685,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1142685726...
Checkpoint 1142685726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,088.31974
Policy Entropy: 3.73452
Value Function Loss: 0.01921

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.17869
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.44551

Collected Steps per Second: 22,053.99591
Overall Steps per Second: 10,644.78792

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.69770

Cumulative Model Updates: 137,042
Cumulative Timesteps: 1,142,735,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,088.31974
Policy Entropy: 3.71235
Value Function Loss: 0.02178

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.46006

Collected Steps per Second: 22,438.84546
Overall Steps per Second: 10,688.36431

Timestep Collection Time: 2.22846
Timestep Consumption Time: 2.44990
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67836

Cumulative Model Updates: 137,048
Cumulative Timesteps: 1,142,785,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1142785736...
Checkpoint 1142785736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230,470.80708
Policy Entropy: 3.73660
Value Function Loss: 0.02167

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.67612
Value Function Update Magnitude: 0.45399

Collected Steps per Second: 22,750.73542
Overall Steps per Second: 10,857.06769

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.40805
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.60622

Cumulative Model Updates: 137,054
Cumulative Timesteps: 1,142,835,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.73241
Value Function Loss: 0.02314

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.74041
Value Function Update Magnitude: 0.45512

Collected Steps per Second: 22,806.55661
Overall Steps per Second: 10,840.03390

Timestep Collection Time: 2.19235
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.61253

Cumulative Model Updates: 137,060
Cumulative Timesteps: 1,142,885,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1142885746...
Checkpoint 1142885746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.75219
Value Function Loss: 0.01991

Mean KL Divergence: 0.00644
SB3 Clip Fraction: 0.07863
Policy Update Magnitude: 0.72302
Value Function Update Magnitude: 0.44425

Collected Steps per Second: 22,821.42706
Overall Steps per Second: 10,738.53535

Timestep Collection Time: 2.19101
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.65631

Cumulative Model Updates: 137,066
Cumulative Timesteps: 1,142,935,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.74745
Value Function Loss: 0.01818

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06612
Policy Update Magnitude: 0.67387
Value Function Update Magnitude: 0.43641

Collected Steps per Second: 22,907.63233
Overall Steps per Second: 10,846.29676

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.61116

Cumulative Model Updates: 137,072
Cumulative Timesteps: 1,142,985,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1142985762...
Checkpoint 1142985762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.75980
Value Function Loss: 0.01425

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05982
Policy Update Magnitude: 0.67162
Value Function Update Magnitude: 0.43035

Collected Steps per Second: 22,819.86123
Overall Steps per Second: 10,684.11870

Timestep Collection Time: 2.19353
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.68508

Cumulative Model Updates: 137,078
Cumulative Timesteps: 1,143,035,818

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.75168
Value Function Loss: 0.01333

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.04206
Policy Update Magnitude: 0.65000
Value Function Update Magnitude: 0.43256

Collected Steps per Second: 23,108.39136
Overall Steps per Second: 10,968.67624

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.39596
PPO Batch Consumption Time: 0.27538
Total Iteration Time: 4.56081

Cumulative Model Updates: 137,084
Cumulative Timesteps: 1,143,085,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1143085844...
Checkpoint 1143085844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 462,317.89427
Policy Entropy: 3.75259
Value Function Loss: 0.01279

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04617
Policy Update Magnitude: 0.62683
Value Function Update Magnitude: 0.47655

Collected Steps per Second: 22,946.13527
Overall Steps per Second: 10,778.86295

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.63908

Cumulative Model Updates: 137,090
Cumulative Timesteps: 1,143,135,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.75894
Value Function Loss: 0.01243

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07036
Policy Update Magnitude: 0.59892
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 23,106.19173
Overall Steps per Second: 10,749.32761

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.65424

Cumulative Model Updates: 137,096
Cumulative Timesteps: 1,143,185,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1143185878...
Checkpoint 1143185878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.77282
Value Function Loss: 0.01226

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06704
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.49506

Collected Steps per Second: 22,186.25597
Overall Steps per Second: 10,741.34201

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.40213
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.65659

Cumulative Model Updates: 137,102
Cumulative Timesteps: 1,143,235,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.76545
Value Function Loss: 0.01173

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.53150
Value Function Update Magnitude: 0.44454

Collected Steps per Second: 21,928.27739
Overall Steps per Second: 10,771.10470

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.36236
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.64298

Cumulative Model Updates: 137,108
Cumulative Timesteps: 1,143,285,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1143285906...
Checkpoint 1143285906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.76655
Value Function Loss: 0.01038

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.50655
Value Function Update Magnitude: 0.40942

Collected Steps per Second: 22,202.72673
Overall Steps per Second: 10,665.87044

Timestep Collection Time: 2.25306
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.69010

Cumulative Model Updates: 137,114
Cumulative Timesteps: 1,143,335,930

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.76505
Value Function Loss: 0.01018

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.45152
Value Function Update Magnitude: 0.35432

Collected Steps per Second: 22,855.70255
Overall Steps per Second: 10,888.14507

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.40538
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.59380

Cumulative Model Updates: 137,120
Cumulative Timesteps: 1,143,385,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1143385948...
Checkpoint 1143385948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.77733
Value Function Loss: 0.00948

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04840
Policy Update Magnitude: 0.43181
Value Function Update Magnitude: 0.28369

Collected Steps per Second: 22,752.03535
Overall Steps per Second: 10,754.23382

Timestep Collection Time: 2.19787
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.64989

Cumulative Model Updates: 137,126
Cumulative Timesteps: 1,143,435,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740,866.35467
Policy Entropy: 3.76995
Value Function Loss: 0.01049

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04496
Policy Update Magnitude: 0.50713
Value Function Update Magnitude: 0.37554

Collected Steps per Second: 23,034.30275
Overall Steps per Second: 10,798.03420

Timestep Collection Time: 2.17085
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.63084

Cumulative Model Updates: 137,132
Cumulative Timesteps: 1,143,485,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1143485958...
Checkpoint 1143485958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047,731.91468
Policy Entropy: 3.76968
Value Function Loss: 0.01139

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.49645

Collected Steps per Second: 22,564.19383
Overall Steps per Second: 10,623.66619

Timestep Collection Time: 2.21608
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.70685

Cumulative Model Updates: 137,138
Cumulative Timesteps: 1,143,535,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047,731.91468
Policy Entropy: 3.76126
Value Function Loss: 0.01097

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08958
Policy Update Magnitude: 0.52255
Value Function Update Magnitude: 0.55990

Collected Steps per Second: 22,634.91474
Overall Steps per Second: 10,799.58741

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.42209
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.63221

Cumulative Model Updates: 137,144
Cumulative Timesteps: 1,143,585,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1143585988...
Checkpoint 1143585988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,488.64638
Policy Entropy: 3.73980
Value Function Loss: 0.01805

Mean KL Divergence: 0.01725
SB3 Clip Fraction: 0.21921
Policy Update Magnitude: 0.47819
Value Function Update Magnitude: 0.55287

Collected Steps per Second: 22,817.48476
Overall Steps per Second: 10,723.95190

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.66246

Cumulative Model Updates: 137,150
Cumulative Timesteps: 1,143,635,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,488.64638
Policy Entropy: 3.75056
Value Function Loss: 0.02003

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.23697
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.54092

Collected Steps per Second: 22,672.39460
Overall Steps per Second: 10,837.12206

Timestep Collection Time: 2.20559
Timestep Consumption Time: 2.40873
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.61432

Cumulative Model Updates: 137,156
Cumulative Timesteps: 1,143,685,994

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1143685994...
Checkpoint 1143685994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,488.64638
Policy Entropy: 3.71270
Value Function Loss: 0.02564

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.22117
Policy Update Magnitude: 0.55076
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 22,100.95100
Overall Steps per Second: 10,682.05365

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.68337

Cumulative Model Updates: 137,162
Cumulative Timesteps: 1,143,736,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 647,488.64638
Policy Entropy: 3.72426
Value Function Loss: 0.02601

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.17592
Policy Update Magnitude: 0.58565
Value Function Update Magnitude: 0.45881

Collected Steps per Second: 21,681.59314
Overall Steps per Second: 10,466.60918

Timestep Collection Time: 2.30610
Timestep Consumption Time: 2.47099
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.77710

Cumulative Model Updates: 137,168
Cumulative Timesteps: 1,143,786,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1143786022...
Checkpoint 1143786022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 647,488.64638
Policy Entropy: 3.72867
Value Function Loss: 0.02762

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.17457
Policy Update Magnitude: 0.58770
Value Function Update Magnitude: 0.38971

Collected Steps per Second: 21,531.66372
Overall Steps per Second: 10,404.32488

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.80819

Cumulative Model Updates: 137,174
Cumulative Timesteps: 1,143,836,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768,983.80465
Policy Entropy: 3.75350
Value Function Loss: 0.02321

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.16118
Policy Update Magnitude: 0.61433
Value Function Update Magnitude: 0.44162

Collected Steps per Second: 22,501.76175
Overall Steps per Second: 10,750.25603

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.42920
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.65142

Cumulative Model Updates: 137,180
Cumulative Timesteps: 1,143,886,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1143886052...
Checkpoint 1143886052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611,884.67609
Policy Entropy: 3.74971
Value Function Loss: 0.02175

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.18626
Policy Update Magnitude: 0.62330
Value Function Update Magnitude: 0.56759

Collected Steps per Second: 22,675.38547
Overall Steps per Second: 10,680.88975

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.68407

Cumulative Model Updates: 137,186
Cumulative Timesteps: 1,143,936,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,396.46648
Policy Entropy: 3.75374
Value Function Loss: 0.02384

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.72606
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 21,124.17996
Overall Steps per Second: 10,348.52413

Timestep Collection Time: 2.36733
Timestep Consumption Time: 2.46505
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.83238

Cumulative Model Updates: 137,192
Cumulative Timesteps: 1,143,986,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1143986090...
Checkpoint 1143986090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233,601.20078
Policy Entropy: 3.77409
Value Function Loss: 0.02531

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.85244
Value Function Update Magnitude: 0.69355

Collected Steps per Second: 21,813.23009
Overall Steps per Second: 10,700.73471

Timestep Collection Time: 2.29356
Timestep Consumption Time: 2.38182
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.67538

Cumulative Model Updates: 137,198
Cumulative Timesteps: 1,144,036,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,639.39892
Policy Entropy: 3.78066
Value Function Loss: 0.02722

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.85099
Value Function Update Magnitude: 0.68478

Collected Steps per Second: 22,075.74889
Overall Steps per Second: 10,839.37969

Timestep Collection Time: 2.26574
Timestep Consumption Time: 2.34873
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.61447

Cumulative Model Updates: 137,204
Cumulative Timesteps: 1,144,086,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1144086138...
Checkpoint 1144086138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,264.39855
Policy Entropy: 3.77343
Value Function Loss: 0.02708

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.80496
Value Function Update Magnitude: 0.77023

Collected Steps per Second: 21,836.61972
Overall Steps per Second: 10,709.16486

Timestep Collection Time: 2.29129
Timestep Consumption Time: 2.38078
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.67207

Cumulative Model Updates: 137,210
Cumulative Timesteps: 1,144,136,172

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,621.37369
Policy Entropy: 3.75293
Value Function Loss: 0.02581

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.83782
Value Function Update Magnitude: 0.86128

Collected Steps per Second: 21,841.11480
Overall Steps per Second: 10,503.30918

Timestep Collection Time: 2.28999
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.76193

Cumulative Model Updates: 137,216
Cumulative Timesteps: 1,144,186,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1144186188...
Checkpoint 1144186188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,410.77942
Policy Entropy: 3.73775
Value Function Loss: 0.02207

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.81378
Value Function Update Magnitude: 0.86529

Collected Steps per Second: 22,455.07638
Overall Steps per Second: 10,687.89322

Timestep Collection Time: 2.22747
Timestep Consumption Time: 2.45240
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.67987

Cumulative Model Updates: 137,222
Cumulative Timesteps: 1,144,236,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,614.36747
Policy Entropy: 3.75605
Value Function Loss: 0.02400

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15004
Policy Update Magnitude: 0.68234
Value Function Update Magnitude: 0.77729

Collected Steps per Second: 22,816.79462
Overall Steps per Second: 10,784.57270

Timestep Collection Time: 2.19172
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.63699

Cumulative Model Updates: 137,228
Cumulative Timesteps: 1,144,286,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1144286214...
Checkpoint 1144286214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,291.16205
Policy Entropy: 3.74538
Value Function Loss: 0.02800

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.76191
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,634.19567
Overall Steps per Second: 10,622.84880

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70985

Cumulative Model Updates: 137,234
Cumulative Timesteps: 1,144,336,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,811.24087
Policy Entropy: 3.75905
Value Function Loss: 0.03119

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.74060
Value Function Update Magnitude: 0.57380

Collected Steps per Second: 22,590.12368
Overall Steps per Second: 10,622.37924

Timestep Collection Time: 2.21380
Timestep Consumption Time: 2.49419
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.70798

Cumulative Model Updates: 137,240
Cumulative Timesteps: 1,144,386,256

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1144386256...
Checkpoint 1144386256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,529.94028
Policy Entropy: 3.77886
Value Function Loss: 0.03039

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.74276
Value Function Update Magnitude: 0.66698

Collected Steps per Second: 22,788.61324
Overall Steps per Second: 10,838.44467

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.41971
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.61432

Cumulative Model Updates: 137,246
Cumulative Timesteps: 1,144,436,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,550.19114
Policy Entropy: 3.79624
Value Function Loss: 0.03084

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.73036
Value Function Update Magnitude: 0.81537

Collected Steps per Second: 22,894.60700
Overall Steps per Second: 10,749.49789

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.65324

Cumulative Model Updates: 137,252
Cumulative Timesteps: 1,144,486,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1144486288...
Checkpoint 1144486288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,091.38809
Policy Entropy: 3.80878
Value Function Loss: 0.03037

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.77220
Value Function Update Magnitude: 0.71375

Collected Steps per Second: 22,982.38605
Overall Steps per Second: 10,912.10169

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.58244

Cumulative Model Updates: 137,258
Cumulative Timesteps: 1,144,536,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.86057
Policy Entropy: 3.79587
Value Function Loss: 0.02859

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.79670
Value Function Update Magnitude: 0.68862

Collected Steps per Second: 23,014.92479
Overall Steps per Second: 10,909.69308

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.41202
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.58583

Cumulative Model Updates: 137,264
Cumulative Timesteps: 1,144,586,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1144586322...
Checkpoint 1144586322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523,888.54291
Policy Entropy: 3.77465
Value Function Loss: 0.02732

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.73526
Value Function Update Magnitude: 0.69496

Collected Steps per Second: 22,845.82258
Overall Steps per Second: 10,666.76402

Timestep Collection Time: 2.18955
Timestep Consumption Time: 2.49997
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.68952

Cumulative Model Updates: 137,270
Cumulative Timesteps: 1,144,636,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,825.67777
Policy Entropy: 3.76969
Value Function Loss: 0.02611

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14393
Policy Update Magnitude: 0.61665
Value Function Update Magnitude: 0.64866

Collected Steps per Second: 22,527.96337
Overall Steps per Second: 10,791.55571

Timestep Collection Time: 2.22044
Timestep Consumption Time: 2.41485
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.63529

Cumulative Model Updates: 137,276
Cumulative Timesteps: 1,144,686,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1144686366...
Checkpoint 1144686366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,246.70020
Policy Entropy: 3.76510
Value Function Loss: 0.02751

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.59520

Collected Steps per Second: 23,111.33198
Overall Steps per Second: 10,742.70156

Timestep Collection Time: 2.16353
Timestep Consumption Time: 2.49098
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.65451

Cumulative Model Updates: 137,282
Cumulative Timesteps: 1,144,736,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,029.08091
Policy Entropy: 3.79307
Value Function Loss: 0.02608

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14532
Policy Update Magnitude: 0.55553
Value Function Update Magnitude: 0.62654

Collected Steps per Second: 22,614.89825
Overall Steps per Second: 10,790.76460

Timestep Collection Time: 2.21164
Timestep Consumption Time: 2.42344
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.63507

Cumulative Model Updates: 137,288
Cumulative Timesteps: 1,144,786,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1144786384...
Checkpoint 1144786384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,419.15831
Policy Entropy: 3.79798
Value Function Loss: 0.02631

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.59895
Value Function Update Magnitude: 0.68775

Collected Steps per Second: 22,909.29761
Overall Steps per Second: 10,723.78082

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.66477

Cumulative Model Updates: 137,294
Cumulative Timesteps: 1,144,836,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,101.48795
Policy Entropy: 3.80595
Value Function Loss: 0.02369

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08444
Policy Update Magnitude: 0.64732
Value Function Update Magnitude: 0.70073

Collected Steps per Second: 22,935.69252
Overall Steps per Second: 10,858.78019

Timestep Collection Time: 2.18079
Timestep Consumption Time: 2.42543
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.60623

Cumulative Model Updates: 137,300
Cumulative Timesteps: 1,144,886,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1144886426...
Checkpoint 1144886426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,833.13785
Policy Entropy: 3.77685
Value Function Loss: 0.02313

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.20646
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.72225

Collected Steps per Second: 23,135.41500
Overall Steps per Second: 10,755.62734

Timestep Collection Time: 2.16153
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.64947

Cumulative Model Updates: 137,306
Cumulative Timesteps: 1,144,936,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,737.86928
Policy Entropy: 3.76918
Value Function Loss: 0.02511

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.18982
Policy Update Magnitude: 0.51395
Value Function Update Magnitude: 0.62678

Collected Steps per Second: 23,158.09838
Overall Steps per Second: 10,779.35755

Timestep Collection Time: 2.15959
Timestep Consumption Time: 2.48002
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.63961

Cumulative Model Updates: 137,312
Cumulative Timesteps: 1,144,986,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1144986446...
Checkpoint 1144986446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,793.32935
Policy Entropy: 3.78579
Value Function Loss: 0.02648

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.52089
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 22,972.93642
Overall Steps per Second: 10,693.11807

Timestep Collection Time: 2.17743
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67796

Cumulative Model Updates: 137,318
Cumulative Timesteps: 1,145,036,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281,752.40194
Policy Entropy: 3.79224
Value Function Loss: 0.03063

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.55918
Value Function Update Magnitude: 0.82409

Collected Steps per Second: 23,002.45220
Overall Steps per Second: 10,840.43277

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.61513

Cumulative Model Updates: 137,324
Cumulative Timesteps: 1,145,086,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1145086498...
Checkpoint 1145086498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,485.96070
Policy Entropy: 3.81130
Value Function Loss: 0.03105

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.60738
Value Function Update Magnitude: 0.88793

Collected Steps per Second: 22,877.13521
Overall Steps per Second: 10,714.53518

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.66861

Cumulative Model Updates: 137,330
Cumulative Timesteps: 1,145,136,520

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,630.15333
Policy Entropy: 3.80554
Value Function Loss: 0.02972

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14063
Policy Update Magnitude: 0.62519
Value Function Update Magnitude: 0.89004

Collected Steps per Second: 22,858.90970
Overall Steps per Second: 10,837.22235

Timestep Collection Time: 2.18759
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.61428

Cumulative Model Updates: 137,336
Cumulative Timesteps: 1,145,186,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1145186526...
Checkpoint 1145186526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,167.81871
Policy Entropy: 3.82246
Value Function Loss: 0.02657

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.59879
Value Function Update Magnitude: 0.83064

Collected Steps per Second: 22,788.63067
Overall Steps per Second: 10,703.58848

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.47844
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.67357

Cumulative Model Updates: 137,342
Cumulative Timesteps: 1,145,236,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,418.16354
Policy Entropy: 3.79557
Value Function Loss: 0.02890

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.56364
Value Function Update Magnitude: 0.75639

Collected Steps per Second: 22,293.02854
Overall Steps per Second: 10,555.99567

Timestep Collection Time: 2.24393
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.73892

Cumulative Model Updates: 137,348
Cumulative Timesteps: 1,145,286,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1145286574...
Checkpoint 1145286574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,731.68085
Policy Entropy: 3.77154
Value Function Loss: 0.02851

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.68695

Collected Steps per Second: 23,045.15121
Overall Steps per Second: 10,928.89229

Timestep Collection Time: 2.17156
Timestep Consumption Time: 2.40749
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.57906

Cumulative Model Updates: 137,354
Cumulative Timesteps: 1,145,336,618

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,502.32391
Policy Entropy: 3.74810
Value Function Loss: 0.02724

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.51308
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 23,048.24572
Overall Steps per Second: 10,906.96705

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.41525
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.58496

Cumulative Model Updates: 137,360
Cumulative Timesteps: 1,145,386,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1145386626...
Checkpoint 1145386626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,502.32391
Policy Entropy: 3.75154
Value Function Loss: 0.02311

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.58752

Collected Steps per Second: 22,499.20285
Overall Steps per Second: 10,727.46608

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.66224

Cumulative Model Updates: 137,366
Cumulative Timesteps: 1,145,436,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,141.08941
Policy Entropy: 3.74627
Value Function Loss: 0.02132

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.51262
Value Function Update Magnitude: 0.73687

Collected Steps per Second: 22,853.84838
Overall Steps per Second: 10,883.05704

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.40696
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.59522

Cumulative Model Updates: 137,372
Cumulative Timesteps: 1,145,486,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1145486650...
Checkpoint 1145486650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,172.57755
Policy Entropy: 3.74713
Value Function Loss: 0.02171

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.49707
Value Function Update Magnitude: 0.73719

Collected Steps per Second: 22,250.59024
Overall Steps per Second: 10,720.87829

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66380

Cumulative Model Updates: 137,378
Cumulative Timesteps: 1,145,536,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,237.94643
Policy Entropy: 3.75092
Value Function Loss: 0.02141

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.47473
Value Function Update Magnitude: 0.60017

Collected Steps per Second: 22,384.50323
Overall Steps per Second: 10,876.42088

Timestep Collection Time: 2.23431
Timestep Consumption Time: 2.36407
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.59839

Cumulative Model Updates: 137,384
Cumulative Timesteps: 1,145,586,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1145586664...
Checkpoint 1145586664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,901.70480
Policy Entropy: 3.75144
Value Function Loss: 0.02456

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.49627
Value Function Update Magnitude: 0.53692

Collected Steps per Second: 22,125.55863
Overall Steps per Second: 10,681.44884

Timestep Collection Time: 2.26046
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.68232

Cumulative Model Updates: 137,390
Cumulative Timesteps: 1,145,636,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,411.36341
Policy Entropy: 3.75898
Value Function Loss: 0.02214

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.47658
Value Function Update Magnitude: 0.60983

Collected Steps per Second: 22,521.24425
Overall Steps per Second: 10,831.72063

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.39777
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.61958

Cumulative Model Updates: 137,396
Cumulative Timesteps: 1,145,686,716

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1145686716...
Checkpoint 1145686716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,488.95959
Policy Entropy: 3.75744
Value Function Loss: 0.02208

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.44126
Value Function Update Magnitude: 0.57997

Collected Steps per Second: 22,586.14523
Overall Steps per Second: 10,667.79651

Timestep Collection Time: 2.21481
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68925

Cumulative Model Updates: 137,402
Cumulative Timesteps: 1,145,736,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,488.95959
Policy Entropy: 3.76701
Value Function Loss: 0.01726

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.41597
Value Function Update Magnitude: 0.51953

Collected Steps per Second: 22,904.45571
Overall Steps per Second: 10,937.83290

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.38898
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.57257

Cumulative Model Updates: 137,408
Cumulative Timesteps: 1,145,786,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1145786754...
Checkpoint 1145786754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,174.82233
Policy Entropy: 3.74676
Value Function Loss: 0.02028

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.41186
Value Function Update Magnitude: 0.55011

Collected Steps per Second: 22,603.65073
Overall Steps per Second: 10,642.18248

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.48655
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69885

Cumulative Model Updates: 137,414
Cumulative Timesteps: 1,145,836,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,775.66435
Policy Entropy: 3.75787
Value Function Loss: 0.02034

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.44976
Value Function Update Magnitude: 0.63359

Collected Steps per Second: 23,166.77825
Overall Steps per Second: 10,938.61826

Timestep Collection Time: 2.15887
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.57224

Cumulative Model Updates: 137,420
Cumulative Timesteps: 1,145,886,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1145886774...
Checkpoint 1145886774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,532.93834
Policy Entropy: 3.74694
Value Function Loss: 0.02307

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 22,764.62396
Overall Steps per Second: 10,680.10091

Timestep Collection Time: 2.19665
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68217

Cumulative Model Updates: 137,426
Cumulative Timesteps: 1,145,936,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,532.93834
Policy Entropy: 3.75649
Value Function Loss: 0.02192

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.51113
Value Function Update Magnitude: 0.73201

Collected Steps per Second: 22,772.65417
Overall Steps per Second: 10,837.60873

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.61633

Cumulative Model Updates: 137,432
Cumulative Timesteps: 1,145,986,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1145986810...
Checkpoint 1145986810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,532.93834
Policy Entropy: 3.73960
Value Function Loss: 0.02444

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.64057

Collected Steps per Second: 22,601.87745
Overall Steps per Second: 10,600.12141

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.71863

Cumulative Model Updates: 137,438
Cumulative Timesteps: 1,146,036,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,231.99121
Policy Entropy: 3.73571
Value Function Loss: 0.02409

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.57457

Collected Steps per Second: 23,019.87491
Overall Steps per Second: 10,883.14097

Timestep Collection Time: 2.17264
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.59555

Cumulative Model Updates: 137,444
Cumulative Timesteps: 1,146,086,842

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1146086842...
Checkpoint 1146086842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,408.48841
Policy Entropy: 3.74096
Value Function Loss: 0.02553

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.67136

Collected Steps per Second: 22,615.59486
Overall Steps per Second: 10,696.88402

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.46339
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.67426

Cumulative Model Updates: 137,450
Cumulative Timesteps: 1,146,136,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,553.37806
Policy Entropy: 3.75317
Value Function Loss: 0.02405

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13899
Policy Update Magnitude: 0.60604
Value Function Update Magnitude: 0.84976

Collected Steps per Second: 23,111.24763
Overall Steps per Second: 10,868.17270

Timestep Collection Time: 2.16423
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.60225

Cumulative Model Updates: 137,456
Cumulative Timesteps: 1,146,186,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1146186860...
Checkpoint 1146186860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,553.37806
Policy Entropy: 3.73448
Value Function Loss: 0.02522

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.90026

Collected Steps per Second: 22,654.40137
Overall Steps per Second: 10,662.74293

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.48354
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.69185

Cumulative Model Updates: 137,462
Cumulative Timesteps: 1,146,236,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,553.37806
Policy Entropy: 3.73825
Value Function Loss: 0.02266

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.53283
Value Function Update Magnitude: 0.74877

Collected Steps per Second: 23,123.97027
Overall Steps per Second: 10,919.18474

Timestep Collection Time: 2.16356
Timestep Consumption Time: 2.41829
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.58184

Cumulative Model Updates: 137,468
Cumulative Timesteps: 1,146,286,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1146286918...
Checkpoint 1146286918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,284.81886
Policy Entropy: 3.74505
Value Function Loss: 0.02259

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.60266

Collected Steps per Second: 22,832.23440
Overall Steps per Second: 10,679.80363

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.68248

Cumulative Model Updates: 137,474
Cumulative Timesteps: 1,146,336,926

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,244.23421
Policy Entropy: 3.75623
Value Function Loss: 0.01865

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.49023
Value Function Update Magnitude: 0.66361

Collected Steps per Second: 22,986.91660
Overall Steps per Second: 10,848.12621

Timestep Collection Time: 2.17567
Timestep Consumption Time: 2.43452
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.61020

Cumulative Model Updates: 137,480
Cumulative Timesteps: 1,146,386,938

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1146386938...
Checkpoint 1146386938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,244.23421
Policy Entropy: 3.75011
Value Function Loss: 0.01916

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.69178

Collected Steps per Second: 22,910.92212
Overall Steps per Second: 10,690.92251

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67817

Cumulative Model Updates: 137,486
Cumulative Timesteps: 1,146,436,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,057.81620
Policy Entropy: 3.73597
Value Function Loss: 0.01980

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.48543
Value Function Update Magnitude: 0.56060

Collected Steps per Second: 22,763.88820
Overall Steps per Second: 10,838.09284

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.61613

Cumulative Model Updates: 137,492
Cumulative Timesteps: 1,146,486,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1146486982...
Checkpoint 1146486982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,145.33426
Policy Entropy: 3.73699
Value Function Loss: 0.01901

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.46011
Value Function Update Magnitude: 0.49061

Collected Steps per Second: 22,783.94084
Overall Steps per Second: 10,714.87574

Timestep Collection Time: 2.19532
Timestep Consumption Time: 2.47277
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.66809

Cumulative Model Updates: 137,498
Cumulative Timesteps: 1,146,537,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,888.46455
Policy Entropy: 3.74826
Value Function Loss: 0.01900

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.44846
Value Function Update Magnitude: 0.45669

Collected Steps per Second: 23,051.91160
Overall Steps per Second: 10,930.32384

Timestep Collection Time: 2.16971
Timestep Consumption Time: 2.40618
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.57589

Cumulative Model Updates: 137,504
Cumulative Timesteps: 1,146,587,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1146587016...
Checkpoint 1146587016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,080.36376
Policy Entropy: 3.75918
Value Function Loss: 0.01638

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13543
Policy Update Magnitude: 0.42744
Value Function Update Magnitude: 0.53022

Collected Steps per Second: 22,670.66962
Overall Steps per Second: 10,672.56018

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68529

Cumulative Model Updates: 137,510
Cumulative Timesteps: 1,146,637,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.75800
Value Function Loss: 0.01556

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.42986
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 23,161.66448
Overall Steps per Second: 10,845.16713

Timestep Collection Time: 2.15874
Timestep Consumption Time: 2.45161
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.61035

Cumulative Model Updates: 137,516
Cumulative Timesteps: 1,146,687,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1146687020...
Checkpoint 1146687020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.75812
Value Function Loss: 0.01467

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.40360
Value Function Update Magnitude: 0.51889

Collected Steps per Second: 22,760.36249
Overall Steps per Second: 10,718.98724

Timestep Collection Time: 2.19733
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.66574

Cumulative Model Updates: 137,522
Cumulative Timesteps: 1,146,737,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.75988
Value Function Loss: 0.01471

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.37459
Value Function Update Magnitude: 0.43432

Collected Steps per Second: 22,589.04382
Overall Steps per Second: 10,793.18146

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.63478

Cumulative Model Updates: 137,528
Cumulative Timesteps: 1,146,787,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1146787056...
Checkpoint 1146787056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.74057
Value Function Loss: 0.01504

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.36028
Value Function Update Magnitude: 0.38859

Collected Steps per Second: 21,945.00750
Overall Steps per Second: 10,663.56580

Timestep Collection Time: 2.27879
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.68961

Cumulative Model Updates: 137,534
Cumulative Timesteps: 1,146,837,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.74362
Value Function Loss: 0.01463

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.34514
Value Function Update Magnitude: 0.35068

Collected Steps per Second: 22,323.32606
Overall Steps per Second: 10,687.64527

Timestep Collection Time: 2.24097
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.68073

Cumulative Model Updates: 137,540
Cumulative Timesteps: 1,146,887,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1146887090...
Checkpoint 1146887090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.73616
Value Function Loss: 0.01455

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.35641
Value Function Update Magnitude: 0.35048

Collected Steps per Second: 22,553.66368
Overall Steps per Second: 10,858.96195

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.38889
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.60707

Cumulative Model Updates: 137,546
Cumulative Timesteps: 1,146,937,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.73984
Value Function Loss: 0.01489

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.35743
Value Function Update Magnitude: 0.35805

Collected Steps per Second: 23,076.88191
Overall Steps per Second: 10,948.09505

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.40158
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.56938

Cumulative Model Updates: 137,552
Cumulative Timesteps: 1,146,987,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1146987144...
Checkpoint 1146987144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.73970
Value Function Loss: 0.01459

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.36221
Value Function Update Magnitude: 0.42943

Collected Steps per Second: 22,626.54083
Overall Steps per Second: 10,613.13350

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.50205
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.71246

Cumulative Model Updates: 137,558
Cumulative Timesteps: 1,147,037,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,552.27274
Policy Entropy: 3.73697
Value Function Loss: 0.01443

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.37472
Value Function Update Magnitude: 0.49590

Collected Steps per Second: 23,166.90830
Overall Steps per Second: 10,943.91401

Timestep Collection Time: 2.15834
Timestep Consumption Time: 2.41059
PPO Batch Consumption Time: 0.27544
Total Iteration Time: 4.56893

Cumulative Model Updates: 137,564
Cumulative Timesteps: 1,147,087,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1147087160...
Checkpoint 1147087160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,611.94597
Policy Entropy: 3.74578
Value Function Loss: 0.01576

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.42759
Value Function Update Magnitude: 0.64196

Collected Steps per Second: 22,763.23811
Overall Steps per Second: 10,671.20920

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.48988
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68719

Cumulative Model Updates: 137,570
Cumulative Timesteps: 1,147,137,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,611.94597
Policy Entropy: 3.73195
Value Function Loss: 0.01503

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.45648
Value Function Update Magnitude: 0.72242

Collected Steps per Second: 23,189.81506
Overall Steps per Second: 10,857.29057

Timestep Collection Time: 2.15715
Timestep Consumption Time: 2.45026
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.60741

Cumulative Model Updates: 137,576
Cumulative Timesteps: 1,147,187,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147187202...
Checkpoint 1147187202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,090.45781
Policy Entropy: 3.72709
Value Function Loss: 0.01978

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.48930
Value Function Update Magnitude: 0.75354

Collected Steps per Second: 22,712.68113
Overall Steps per Second: 10,656.95681

Timestep Collection Time: 2.20177
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.69252

Cumulative Model Updates: 137,582
Cumulative Timesteps: 1,147,237,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,339.66193
Policy Entropy: 3.73256
Value Function Loss: 0.01908

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.74230

Collected Steps per Second: 22,844.52631
Overall Steps per Second: 10,831.27385

Timestep Collection Time: 2.18923
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.61737

Cumulative Model Updates: 137,588
Cumulative Timesteps: 1,147,287,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1147287222...
Checkpoint 1147287222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,339.66193
Policy Entropy: 3.72415
Value Function Loss: 0.02127

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.66021

Collected Steps per Second: 22,748.29131
Overall Steps per Second: 10,663.97843

Timestep Collection Time: 2.19806
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.68887

Cumulative Model Updates: 137,594
Cumulative Timesteps: 1,147,337,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,339.66193
Policy Entropy: 3.73561
Value Function Loss: 0.01868

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.51354
Value Function Update Magnitude: 0.65018

Collected Steps per Second: 22,882.94765
Overall Steps per Second: 10,838.40109

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.42926
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.61526

Cumulative Model Updates: 137,600
Cumulative Timesteps: 1,147,387,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1147387246...
Checkpoint 1147387246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527,339.66193
Policy Entropy: 3.72589
Value Function Loss: 0.01938

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13864
Policy Update Magnitude: 0.50807
Value Function Update Magnitude: 0.62119

Collected Steps per Second: 22,609.49507
Overall Steps per Second: 10,688.34315

Timestep Collection Time: 2.21181
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.67874

Cumulative Model Updates: 137,606
Cumulative Timesteps: 1,147,437,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895,881.57383
Policy Entropy: 3.74100
Value Function Loss: 0.01860

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.61139

Collected Steps per Second: 22,878.34496
Overall Steps per Second: 10,859.63436

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.41989
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60642

Cumulative Model Updates: 137,612
Cumulative Timesteps: 1,147,487,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147487278...
Checkpoint 1147487278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.72798
Value Function Loss: 0.02061

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.50700
Value Function Update Magnitude: 0.68558

Collected Steps per Second: 22,848.46513
Overall Steps per Second: 10,711.32979

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.48022
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.66907

Cumulative Model Updates: 137,618
Cumulative Timesteps: 1,147,537,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.73530
Value Function Loss: 0.01964

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.51389
Value Function Update Magnitude: 0.63009

Collected Steps per Second: 23,014.78177
Overall Steps per Second: 10,896.23671

Timestep Collection Time: 2.17278
Timestep Consumption Time: 2.41651
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58929

Cumulative Model Updates: 137,624
Cumulative Timesteps: 1,147,587,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1147587296...
Checkpoint 1147587296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.72353
Value Function Loss: 0.02202

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.51464
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 22,017.74941
Overall Steps per Second: 10,651.27684

Timestep Collection Time: 2.27208
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.69671

Cumulative Model Updates: 137,630
Cumulative Timesteps: 1,147,637,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.72785
Value Function Loss: 0.01946

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.52536
Value Function Update Magnitude: 0.61929

Collected Steps per Second: 22,171.23020
Overall Steps per Second: 10,868.77690

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.34628
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60254

Cumulative Model Updates: 137,636
Cumulative Timesteps: 1,147,687,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1147687346...
Checkpoint 1147687346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.71130
Value Function Loss: 0.01966

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.50829
Value Function Update Magnitude: 0.55885

Collected Steps per Second: 22,186.23711
Overall Steps per Second: 10,695.75540

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.67718

Cumulative Model Updates: 137,642
Cumulative Timesteps: 1,147,737,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 477,451.68021
Policy Entropy: 3.72759
Value Function Loss: 0.01734

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.48409
Value Function Update Magnitude: 0.53099

Collected Steps per Second: 23,088.95256
Overall Steps per Second: 10,892.84438

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.42589
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.59256

Cumulative Model Updates: 137,648
Cumulative Timesteps: 1,147,787,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1147787398...
Checkpoint 1147787398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,160.94404
Policy Entropy: 3.74035
Value Function Loss: 0.01716

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.50528
Value Function Update Magnitude: 0.67729

Collected Steps per Second: 22,817.03374
Overall Steps per Second: 10,784.02036

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.44602
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.63816

Cumulative Model Updates: 137,654
Cumulative Timesteps: 1,147,837,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,582.06281
Policy Entropy: 3.75830
Value Function Loss: 0.01971

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.78684

Collected Steps per Second: 23,100.19397
Overall Steps per Second: 10,806.18275

Timestep Collection Time: 2.16570
Timestep Consumption Time: 2.46388
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.62957

Cumulative Model Updates: 137,660
Cumulative Timesteps: 1,147,887,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1147887444...
Checkpoint 1147887444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,226.52434
Policy Entropy: 3.75914
Value Function Loss: 0.02027

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.88157

Collected Steps per Second: 23,187.48458
Overall Steps per Second: 10,817.10467

Timestep Collection Time: 2.15720
Timestep Consumption Time: 2.46696
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.62416

Cumulative Model Updates: 137,666
Cumulative Timesteps: 1,147,937,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,120.77234
Policy Entropy: 3.75803
Value Function Loss: 0.02010

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.88506

Collected Steps per Second: 23,039.89715
Overall Steps per Second: 10,723.77113

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.66328

Cumulative Model Updates: 137,672
Cumulative Timesteps: 1,147,987,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1147987472...
Checkpoint 1147987472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223,660.87657
Policy Entropy: 3.75651
Value Function Loss: 0.02072

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.54385
Value Function Update Magnitude: 0.68404

Collected Steps per Second: 22,568.11319
Overall Steps per Second: 10,618.80880

Timestep Collection Time: 2.21596
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70957

Cumulative Model Updates: 137,678
Cumulative Timesteps: 1,148,037,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,660.87657
Policy Entropy: 3.76439
Value Function Loss: 0.01921

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.61005

Collected Steps per Second: 23,041.43008
Overall Steps per Second: 10,892.42743

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.42160
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.59273

Cumulative Model Updates: 137,684
Cumulative Timesteps: 1,148,087,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1148087508...
Checkpoint 1148087508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223,660.87657
Policy Entropy: 3.74240
Value Function Loss: 0.01754

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.52090
Value Function Update Magnitude: 0.59211

Collected Steps per Second: 22,688.69573
Overall Steps per Second: 10,675.35381

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.68481

Cumulative Model Updates: 137,690
Cumulative Timesteps: 1,148,137,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,660.87657
Policy Entropy: 3.74289
Value Function Loss: 0.01579

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.47101
Value Function Update Magnitude: 0.56641

Collected Steps per Second: 23,345.02000
Overall Steps per Second: 10,913.22238

Timestep Collection Time: 2.14273
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.58361

Cumulative Model Updates: 137,696
Cumulative Timesteps: 1,148,187,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1148187542...
Checkpoint 1148187542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,242.43600
Policy Entropy: 3.73048
Value Function Loss: 0.01814

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.47738
Value Function Update Magnitude: 0.57327

Collected Steps per Second: 21,928.13529
Overall Steps per Second: 10,649.58894

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69652

Cumulative Model Updates: 137,702
Cumulative Timesteps: 1,148,237,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,691.25223
Policy Entropy: 3.73624
Value Function Loss: 0.01948

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.64508

Collected Steps per Second: 22,589.02977
Overall Steps per Second: 10,887.17030

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.38005
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.59440

Cumulative Model Updates: 137,708
Cumulative Timesteps: 1,148,287,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1148287578...
Checkpoint 1148287578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,783.33018
Policy Entropy: 3.74453
Value Function Loss: 0.01860

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.63927

Collected Steps per Second: 22,116.60472
Overall Steps per Second: 10,638.86372

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.70013

Cumulative Model Updates: 137,714
Cumulative Timesteps: 1,148,337,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,387.75186
Policy Entropy: 3.75089
Value Function Loss: 0.01911

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.53207
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,961.43591
Overall Steps per Second: 10,949.36257

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.39025
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.56903

Cumulative Model Updates: 137,720
Cumulative Timesteps: 1,148,387,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1148387610...
Checkpoint 1148387610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,515.50823
Policy Entropy: 3.74251
Value Function Loss: 0.01920

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.51669
Value Function Update Magnitude: 0.54929

Collected Steps per Second: 22,807.13676
Overall Steps per Second: 10,776.35854

Timestep Collection Time: 2.19265
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.64053

Cumulative Model Updates: 137,726
Cumulative Timesteps: 1,148,437,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,434.59343
Policy Entropy: 3.75987
Value Function Loss: 0.01825

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.48805
Value Function Update Magnitude: 0.50829

Collected Steps per Second: 23,239.34570
Overall Steps per Second: 10,767.39261

Timestep Collection Time: 2.15256
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.64588

Cumulative Model Updates: 137,732
Cumulative Timesteps: 1,148,487,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1148487642...
Checkpoint 1148487642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,172.47071
Policy Entropy: 3.76287
Value Function Loss: 0.01669

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.47670
Value Function Update Magnitude: 0.53500

Collected Steps per Second: 22,852.33396
Overall Steps per Second: 10,723.22482

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.66557

Cumulative Model Updates: 137,738
Cumulative Timesteps: 1,148,537,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,315.93142
Policy Entropy: 3.76748
Value Function Loss: 0.01535

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.45874
Value Function Update Magnitude: 0.62061

Collected Steps per Second: 22,990.53509
Overall Steps per Second: 10,799.24335

Timestep Collection Time: 2.17498
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.63032

Cumulative Model Updates: 137,744
Cumulative Timesteps: 1,148,587,676

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1148587676...
Checkpoint 1148587676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,224.73422
Policy Entropy: 3.74389
Value Function Loss: 0.01789

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.46908
Value Function Update Magnitude: 0.65839

Collected Steps per Second: 22,810.50788
Overall Steps per Second: 10,641.16168

Timestep Collection Time: 2.19338
Timestep Consumption Time: 2.50837
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.70174

Cumulative Model Updates: 137,750
Cumulative Timesteps: 1,148,637,708

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,900.95028
Policy Entropy: 3.74979
Value Function Loss: 0.01731

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14085
Policy Update Magnitude: 0.51438
Value Function Update Magnitude: 0.65578

Collected Steps per Second: 23,039.85781
Overall Steps per Second: 10,881.89269

Timestep Collection Time: 2.17041
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.59534

Cumulative Model Updates: 137,756
Cumulative Timesteps: 1,148,687,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1148687714...
Checkpoint 1148687714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,942.75095
Policy Entropy: 3.73364
Value Function Loss: 0.02080

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.63848

Collected Steps per Second: 22,645.31578
Overall Steps per Second: 10,643.91084

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.69809

Cumulative Model Updates: 137,762
Cumulative Timesteps: 1,148,737,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,942.75095
Policy Entropy: 3.74341
Value Function Loss: 0.01877

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14501
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.62532

Collected Steps per Second: 22,290.11395
Overall Steps per Second: 10,864.73773

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.35890
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.60204

Cumulative Model Updates: 137,768
Cumulative Timesteps: 1,148,787,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1148787720...
Checkpoint 1148787720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,706.07223
Policy Entropy: 3.73050
Value Function Loss: 0.02304

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.55974
Value Function Update Magnitude: 0.67368

Collected Steps per Second: 21,989.06967
Overall Steps per Second: 10,700.52690

Timestep Collection Time: 2.27386
Timestep Consumption Time: 2.39881
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.67267

Cumulative Model Updates: 137,774
Cumulative Timesteps: 1,148,837,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,093.93435
Policy Entropy: 3.74745
Value Function Loss: 0.02248

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.61617
Value Function Update Magnitude: 0.84527

Collected Steps per Second: 21,922.22445
Overall Steps per Second: 10,827.13510

Timestep Collection Time: 2.28125
Timestep Consumption Time: 2.33770
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.61895

Cumulative Model Updates: 137,780
Cumulative Timesteps: 1,148,887,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1148887730...
Checkpoint 1148887730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,389.34846
Policy Entropy: 3.73778
Value Function Loss: 0.02288

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15002
Policy Update Magnitude: 0.62096
Value Function Update Magnitude: 0.79120

Collected Steps per Second: 22,271.16950
Overall Steps per Second: 10,736.03922

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.41302
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.65889

Cumulative Model Updates: 137,786
Cumulative Timesteps: 1,148,937,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,389.34846
Policy Entropy: 3.74255
Value Function Loss: 0.01935

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.54352

Collected Steps per Second: 22,877.88180
Overall Steps per Second: 10,935.62604

Timestep Collection Time: 2.18587
Timestep Consumption Time: 2.38708
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.57294

Cumulative Model Updates: 137,792
Cumulative Timesteps: 1,148,987,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1148987756...
Checkpoint 1148987756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247,282.51023
Policy Entropy: 3.74115
Value Function Loss: 0.01896

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.51339
Value Function Update Magnitude: 0.37408

Collected Steps per Second: 22,803.92549
Overall Steps per Second: 10,779.08741

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.44708
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.64065

Cumulative Model Updates: 137,798
Cumulative Timesteps: 1,149,037,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,427.42837
Policy Entropy: 3.74852
Value Function Loss: 0.01846

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.49028
Value Function Update Magnitude: 0.33410

Collected Steps per Second: 22,876.39839
Overall Steps per Second: 10,739.52885

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.65756

Cumulative Model Updates: 137,804
Cumulative Timesteps: 1,149,087,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1149087798...
Checkpoint 1149087798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307,657.12609
Policy Entropy: 3.74807
Value Function Loss: 0.02101

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.51651
Value Function Update Magnitude: 0.46326

Collected Steps per Second: 23,042.84225
Overall Steps per Second: 10,767.81424

Timestep Collection Time: 2.17004
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.64384

Cumulative Model Updates: 137,810
Cumulative Timesteps: 1,149,137,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,880.27685
Policy Entropy: 3.76581
Value Function Loss: 0.02066

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.53343

Collected Steps per Second: 22,874.41240
Overall Steps per Second: 10,763.26569

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.64599

Cumulative Model Updates: 137,816
Cumulative Timesteps: 1,149,187,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1149187808...
Checkpoint 1149187808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,265.12761
Policy Entropy: 3.77196
Value Function Loss: 0.02377

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.54537

Collected Steps per Second: 22,858.53057
Overall Steps per Second: 10,699.29524

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.48584
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.67320

Cumulative Model Updates: 137,822
Cumulative Timesteps: 1,149,237,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,369.10065
Policy Entropy: 3.77710
Value Function Loss: 0.02484

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.60234
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 22,740.58161
Overall Steps per Second: 10,838.00802

Timestep Collection Time: 2.19898
Timestep Consumption Time: 2.41497
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.61395

Cumulative Model Updates: 137,828
Cumulative Timesteps: 1,149,287,814

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1149287814...
Checkpoint 1149287814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,104.14344
Policy Entropy: 3.76161
Value Function Loss: 0.02451

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.62853
Value Function Update Magnitude: 0.68955

Collected Steps per Second: 22,886.56596
Overall Steps per Second: 10,681.38847

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68160

Cumulative Model Updates: 137,834
Cumulative Timesteps: 1,149,337,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.66667
Policy Entropy: 3.75610
Value Function Loss: 0.02350

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.61778
Value Function Update Magnitude: 0.62746

Collected Steps per Second: 22,642.89661
Overall Steps per Second: 10,809.74231

Timestep Collection Time: 2.20837
Timestep Consumption Time: 2.41745
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.62583

Cumulative Model Updates: 137,840
Cumulative Timesteps: 1,149,387,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1149387824...
Checkpoint 1149387824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.66667
Policy Entropy: 3.74278
Value Function Loss: 0.02082

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.52638

Collected Steps per Second: 22,799.50057
Overall Steps per Second: 10,654.07817

Timestep Collection Time: 2.19347
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.69398

Cumulative Model Updates: 137,846
Cumulative Timesteps: 1,149,437,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.66667
Policy Entropy: 3.73577
Value Function Loss: 0.01751

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.49036
Value Function Update Magnitude: 0.41823

Collected Steps per Second: 21,960.25802
Overall Steps per Second: 10,867.01744

Timestep Collection Time: 2.27711
Timestep Consumption Time: 2.32452
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.60163

Cumulative Model Updates: 137,852
Cumulative Timesteps: 1,149,487,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1149487840...
Checkpoint 1149487840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.66667
Policy Entropy: 3.73547
Value Function Loss: 0.01823

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.44817
Value Function Update Magnitude: 0.32237

Collected Steps per Second: 22,379.10873
Overall Steps per Second: 10,765.43468

Timestep Collection Time: 2.23423
Timestep Consumption Time: 2.41027
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.64449

Cumulative Model Updates: 137,858
Cumulative Timesteps: 1,149,537,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,428.66667
Policy Entropy: 3.74041
Value Function Loss: 0.01669

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.46813
Value Function Update Magnitude: 0.31296

Collected Steps per Second: 22,252.19678
Overall Steps per Second: 10,890.80258

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.34434
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.59158

Cumulative Model Updates: 137,864
Cumulative Timesteps: 1,149,587,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1149587846...
Checkpoint 1149587846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,381.80623
Policy Entropy: 3.72653
Value Function Loss: 0.02141

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.49282
Value Function Update Magnitude: 0.35136

Collected Steps per Second: 22,405.07001
Overall Steps per Second: 10,656.20050

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.46175
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69454

Cumulative Model Updates: 137,870
Cumulative Timesteps: 1,149,637,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,205.04097
Policy Entropy: 3.73925
Value Function Loss: 0.02092

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.50684
Value Function Update Magnitude: 0.40984

Collected Steps per Second: 22,795.58515
Overall Steps per Second: 10,888.85877

Timestep Collection Time: 2.19420
Timestep Consumption Time: 2.39931
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.59350

Cumulative Model Updates: 137,876
Cumulative Timesteps: 1,149,687,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1149687890...
Checkpoint 1149687890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,205.04097
Policy Entropy: 3.72552
Value Function Loss: 0.02330

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.45641

Collected Steps per Second: 22,527.72622
Overall Steps per Second: 10,600.05895

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.71695

Cumulative Model Updates: 137,882
Cumulative Timesteps: 1,149,737,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,205.04097
Policy Entropy: 3.73459
Value Function Loss: 0.02080

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.51681

Collected Steps per Second: 22,585.93613
Overall Steps per Second: 10,787.11909

Timestep Collection Time: 2.21412
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.63590

Cumulative Model Updates: 137,888
Cumulative Timesteps: 1,149,787,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1149787898...
Checkpoint 1149787898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,205.04097
Policy Entropy: 3.71701
Value Function Loss: 0.02272

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.47386

Collected Steps per Second: 22,500.65946
Overall Steps per Second: 10,802.24575

Timestep Collection Time: 2.22340
Timestep Consumption Time: 2.40786
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.63126

Cumulative Model Updates: 137,894
Cumulative Timesteps: 1,149,837,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,674.09441
Policy Entropy: 3.71319
Value Function Loss: 0.02302

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.38053

Collected Steps per Second: 22,618.25956
Overall Steps per Second: 10,816.93436

Timestep Collection Time: 2.21158
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.62442

Cumulative Model Updates: 137,900
Cumulative Timesteps: 1,149,887,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1149887948...
Checkpoint 1149887948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,592.09191
Policy Entropy: 3.71427
Value Function Loss: 0.02492

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.35977

Collected Steps per Second: 22,557.60284
Overall Steps per Second: 10,696.70012

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.45877
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.67621

Cumulative Model Updates: 137,906
Cumulative Timesteps: 1,149,937,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,592.09191
Policy Entropy: 3.71117
Value Function Loss: 0.02407

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.39375

Collected Steps per Second: 22,940.96577
Overall Steps per Second: 10,928.62387

Timestep Collection Time: 2.18038
Timestep Consumption Time: 2.39659
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.57697

Cumulative Model Updates: 137,912
Cumulative Timesteps: 1,149,987,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1149987988...
Checkpoint 1149987988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,926.37793
Policy Entropy: 3.71238
Value Function Loss: 0.02648

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13138
Policy Update Magnitude: 0.59614
Value Function Update Magnitude: 0.50355

Collected Steps per Second: 22,161.35886
Overall Steps per Second: 10,736.41718

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.40221
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.65966

Cumulative Model Updates: 137,918
Cumulative Timesteps: 1,150,038,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,694.82963
Policy Entropy: 3.72791
Value Function Loss: 0.02554

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.59402
Value Function Update Magnitude: 0.55406

Collected Steps per Second: 22,177.54298
Overall Steps per Second: 10,800.72755

Timestep Collection Time: 2.25543
Timestep Consumption Time: 2.37573
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.63117

Cumulative Model Updates: 137,924
Cumulative Timesteps: 1,150,088,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1150088036...
Checkpoint 1150088036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,060.64603
Policy Entropy: 3.73825
Value Function Loss: 0.02413

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.56049
Value Function Update Magnitude: 0.53517

Collected Steps per Second: 22,112.14400
Overall Steps per Second: 10,737.19737

Timestep Collection Time: 2.26138
Timestep Consumption Time: 2.39570
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.65708

Cumulative Model Updates: 137,930
Cumulative Timesteps: 1,150,138,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,653.33711
Policy Entropy: 3.73767
Value Function Loss: 0.02078

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.48090

Collected Steps per Second: 22,360.82739
Overall Steps per Second: 10,772.39220

Timestep Collection Time: 2.23623
Timestep Consumption Time: 2.40563
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.64187

Cumulative Model Updates: 137,936
Cumulative Timesteps: 1,150,188,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1150188044...
Checkpoint 1150188044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.72681
Value Function Loss: 0.02265

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.52507
Value Function Update Magnitude: 0.45286

Collected Steps per Second: 22,880.19455
Overall Steps per Second: 10,809.19957

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.44283
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.63032

Cumulative Model Updates: 137,942
Cumulative Timesteps: 1,150,238,094

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.72499
Value Function Loss: 0.02118

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.54062

Collected Steps per Second: 22,813.49955
Overall Steps per Second: 10,798.24652

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.63260

Cumulative Model Updates: 137,948
Cumulative Timesteps: 1,150,288,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1150288118...
Checkpoint 1150288118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.71536
Value Function Loss: 0.02240

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14982
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.52666

Collected Steps per Second: 22,870.23351
Overall Steps per Second: 10,718.47001

Timestep Collection Time: 2.18747
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66746

Cumulative Model Updates: 137,954
Cumulative Timesteps: 1,150,338,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.72925
Value Function Loss: 0.01831

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.45988

Collected Steps per Second: 22,759.13502
Overall Steps per Second: 10,783.31389

Timestep Collection Time: 2.19824
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.63958

Cumulative Model Updates: 137,960
Cumulative Timesteps: 1,150,388,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1150388176...
Checkpoint 1150388176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.71300
Value Function Loss: 0.01951

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.15103
Policy Update Magnitude: 0.47938
Value Function Update Magnitude: 0.37558

Collected Steps per Second: 22,805.61078
Overall Steps per Second: 10,679.32296

Timestep Collection Time: 2.19341
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.68400

Cumulative Model Updates: 137,966
Cumulative Timesteps: 1,150,438,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,519.33620
Policy Entropy: 3.72203
Value Function Loss: 0.01688

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14773
Policy Update Magnitude: 0.45154
Value Function Update Magnitude: 0.34497

Collected Steps per Second: 22,906.16482
Overall Steps per Second: 10,878.67022

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.41420
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.59780

Cumulative Model Updates: 137,972
Cumulative Timesteps: 1,150,488,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1150488216...
Checkpoint 1150488216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,398.39777
Policy Entropy: 3.72280
Value Function Loss: 0.01828

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.45158
Value Function Update Magnitude: 0.37388

Collected Steps per Second: 23,057.89238
Overall Steps per Second: 10,757.39883

Timestep Collection Time: 2.17002
Timestep Consumption Time: 2.48129
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.65131

Cumulative Model Updates: 137,978
Cumulative Timesteps: 1,150,538,252

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,226.73762
Policy Entropy: 3.75757
Value Function Loss: 0.01771

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.45440
Value Function Update Magnitude: 0.43619

Collected Steps per Second: 23,187.28304
Overall Steps per Second: 10,824.10375

Timestep Collection Time: 2.15825
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.62339

Cumulative Model Updates: 137,984
Cumulative Timesteps: 1,150,588,296

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1150588296...
Checkpoint 1150588296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,504.71067
Policy Entropy: 3.77549
Value Function Loss: 0.01999

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13586
Policy Update Magnitude: 0.50393
Value Function Update Magnitude: 0.57221

Collected Steps per Second: 22,460.73829
Overall Steps per Second: 10,847.71815

Timestep Collection Time: 2.22611
Timestep Consumption Time: 2.38316
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.60926

Cumulative Model Updates: 137,990
Cumulative Timesteps: 1,150,638,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,581.11563
Policy Entropy: 3.79080
Value Function Loss: 0.02062

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.54333
Value Function Update Magnitude: 0.71848

Collected Steps per Second: 21,944.75403
Overall Steps per Second: 10,723.94863

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.38535
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.66507

Cumulative Model Updates: 137,996
Cumulative Timesteps: 1,150,688,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1150688324...
Checkpoint 1150688324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.47043
Policy Entropy: 3.77144
Value Function Loss: 0.02170

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.75715

Collected Steps per Second: 22,140.62474
Overall Steps per Second: 10,747.97687

Timestep Collection Time: 2.25974
Timestep Consumption Time: 2.39528
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.65502

Cumulative Model Updates: 138,002
Cumulative Timesteps: 1,150,738,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,648.47043
Policy Entropy: 3.74832
Value Function Loss: 0.02300

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.62850

Collected Steps per Second: 22,066.36753
Overall Steps per Second: 10,725.00935

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.39707
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.66387

Cumulative Model Updates: 138,008
Cumulative Timesteps: 1,150,788,376

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1150788376...
Checkpoint 1150788376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,475.20865
Policy Entropy: 3.74012
Value Function Loss: 0.02398

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.60387

Collected Steps per Second: 23,023.15601
Overall Steps per Second: 10,782.38803

Timestep Collection Time: 2.17225
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.63830

Cumulative Model Updates: 138,014
Cumulative Timesteps: 1,150,838,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,032.40060
Policy Entropy: 3.74215
Value Function Loss: 0.02431

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.61766
Value Function Update Magnitude: 0.83648

Collected Steps per Second: 22,705.80335
Overall Steps per Second: 10,817.11620

Timestep Collection Time: 2.20261
Timestep Consumption Time: 2.42080
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.62341

Cumulative Model Updates: 138,020
Cumulative Timesteps: 1,150,888,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1150888400...
Checkpoint 1150888400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298,162.22380
Policy Entropy: 3.76201
Value Function Loss: 0.02515

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.61412
Value Function Update Magnitude: 0.86115

Collected Steps per Second: 23,034.62878
Overall Steps per Second: 10,838.41605

Timestep Collection Time: 2.17091
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.61377

Cumulative Model Updates: 138,026
Cumulative Timesteps: 1,150,938,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,246.61437
Policy Entropy: 3.77908
Value Function Loss: 0.02438

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.94157

Collected Steps per Second: 22,734.80040
Overall Steps per Second: 10,692.59283

Timestep Collection Time: 2.20006
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.67782

Cumulative Model Updates: 138,032
Cumulative Timesteps: 1,150,988,424

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1150988424...
Checkpoint 1150988424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.11625
Policy Entropy: 3.81666
Value Function Loss: 0.02415

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.54499
Value Function Update Magnitude: 0.92394

Collected Steps per Second: 22,871.40568
Overall Steps per Second: 10,705.14266

Timestep Collection Time: 2.18622
Timestep Consumption Time: 2.48462
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.67084

Cumulative Model Updates: 138,038
Cumulative Timesteps: 1,151,038,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.64317
Policy Entropy: 3.81514
Value Function Loss: 0.02314

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.53147
Value Function Update Magnitude: 0.86689

Collected Steps per Second: 22,891.09442
Overall Steps per Second: 10,876.45194

Timestep Collection Time: 2.18469
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.59801

Cumulative Model Updates: 138,044
Cumulative Timesteps: 1,151,088,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1151088436...
Checkpoint 1151088436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.12647
Policy Entropy: 3.81090
Value Function Loss: 0.02338

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.92721

Collected Steps per Second: 23,131.01479
Overall Steps per Second: 10,813.22246

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.46355
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.62619

Cumulative Model Updates: 138,050
Cumulative Timesteps: 1,151,138,460

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,217.75714
Policy Entropy: 3.77503
Value Function Loss: 0.02363

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.57412
Value Function Update Magnitude: 0.78645

Collected Steps per Second: 22,882.12238
Overall Steps per Second: 10,700.33482

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.67312

Cumulative Model Updates: 138,056
Cumulative Timesteps: 1,151,188,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1151188464...
Checkpoint 1151188464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,724.67217
Policy Entropy: 3.77171
Value Function Loss: 0.02494

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.78431

Collected Steps per Second: 22,611.79168
Overall Steps per Second: 10,624.01800

Timestep Collection Time: 2.21203
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.70801

Cumulative Model Updates: 138,062
Cumulative Timesteps: 1,151,238,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,544.46407
Policy Entropy: 3.78311
Value Function Loss: 0.02352

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.57230
Value Function Update Magnitude: 0.83955

Collected Steps per Second: 22,609.70404
Overall Steps per Second: 10,821.87798

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.40912
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62082

Cumulative Model Updates: 138,068
Cumulative Timesteps: 1,151,288,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1151288488...
Checkpoint 1151288488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,065.34382
Policy Entropy: 3.80992
Value Function Loss: 0.02337

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.59119
Value Function Update Magnitude: 0.73774

Collected Steps per Second: 22,962.79448
Overall Steps per Second: 10,750.72924

Timestep Collection Time: 2.17848
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.65308

Cumulative Model Updates: 138,074
Cumulative Timesteps: 1,151,338,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.25825
Policy Entropy: 3.80031
Value Function Loss: 0.02345

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.53316
Value Function Update Magnitude: 0.70127

Collected Steps per Second: 22,865.20346
Overall Steps per Second: 10,845.82799

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.61154

Cumulative Model Updates: 138,080
Cumulative Timesteps: 1,151,388,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1151388528...
Checkpoint 1151388528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.10052
Policy Entropy: 3.78196
Value Function Loss: 0.02019

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.49934
Value Function Update Magnitude: 0.68261

Collected Steps per Second: 22,971.90369
Overall Steps per Second: 10,710.14543

Timestep Collection Time: 2.17727
Timestep Consumption Time: 2.49270
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.66996

Cumulative Model Updates: 138,086
Cumulative Timesteps: 1,151,438,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.10052
Policy Entropy: 3.74770
Value Function Loss: 0.01771

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.43814
Value Function Update Magnitude: 0.56516

Collected Steps per Second: 23,034.90120
Overall Steps per Second: 10,948.85206

Timestep Collection Time: 2.17114
Timestep Consumption Time: 2.39664
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.56778

Cumulative Model Updates: 138,092
Cumulative Timesteps: 1,151,488,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1151488556...
Checkpoint 1151488556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.10052
Policy Entropy: 3.73856
Value Function Loss: 0.01309

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.39561
Value Function Update Magnitude: 0.45256

Collected Steps per Second: 22,633.18382
Overall Steps per Second: 10,677.40836

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68316

Cumulative Model Updates: 138,098
Cumulative Timesteps: 1,151,538,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,423.73041
Policy Entropy: 3.72073
Value Function Loss: 0.01531

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.15173
Policy Update Magnitude: 0.41837
Value Function Update Magnitude: 0.43634

Collected Steps per Second: 22,315.62256
Overall Steps per Second: 10,824.64418

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.37974
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.62149

Cumulative Model Updates: 138,104
Cumulative Timesteps: 1,151,588,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1151588586...
Checkpoint 1151588586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,322.18760
Policy Entropy: 3.73397
Value Function Loss: 0.01907

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.49697
Value Function Update Magnitude: 0.55612

Collected Steps per Second: 22,068.36756
Overall Steps per Second: 10,696.92143

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.67705

Cumulative Model Updates: 138,110
Cumulative Timesteps: 1,151,638,616

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,949.98216
Policy Entropy: 3.74276
Value Function Loss: 0.02118

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14846
Policy Update Magnitude: 0.52471
Value Function Update Magnitude: 0.66545

Collected Steps per Second: 22,190.16739
Overall Steps per Second: 10,917.43544

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.32863
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.58386

Cumulative Model Updates: 138,116
Cumulative Timesteps: 1,151,688,660

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1151688660...
Checkpoint 1151688660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,584.46570
Policy Entropy: 3.77127
Value Function Loss: 0.02254

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.66762

Collected Steps per Second: 22,258.69721
Overall Steps per Second: 10,599.10716

Timestep Collection Time: 2.24775
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.72040

Cumulative Model Updates: 138,122
Cumulative Timesteps: 1,151,738,692

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,209.51369
Policy Entropy: 3.78008
Value Function Loss: 0.01841

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15051
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.71118

Collected Steps per Second: 22,953.95486
Overall Steps per Second: 10,922.53168

Timestep Collection Time: 2.17949
Timestep Consumption Time: 2.40076
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.58026

Cumulative Model Updates: 138,128
Cumulative Timesteps: 1,151,788,720

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1151788720...
Checkpoint 1151788720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,913.61552
Policy Entropy: 3.77156
Value Function Loss: 0.02098

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14457
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.81592

Collected Steps per Second: 22,946.56489
Overall Steps per Second: 10,788.30855

Timestep Collection Time: 2.17915
Timestep Consumption Time: 2.45587
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.63502

Cumulative Model Updates: 138,134
Cumulative Timesteps: 1,151,838,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,883.02816
Policy Entropy: 3.75057
Value Function Loss: 0.02177

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.87177

Collected Steps per Second: 22,711.20206
Overall Steps per Second: 10,740.56120

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.45536
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.65842

Cumulative Model Updates: 138,140
Cumulative Timesteps: 1,151,888,758

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1151888758...
Checkpoint 1151888758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,691.43438
Policy Entropy: 3.74011
Value Function Loss: 0.02623

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.61533
Value Function Update Magnitude: 0.83448

Collected Steps per Second: 22,711.78226
Overall Steps per Second: 10,677.58124

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68364

Cumulative Model Updates: 138,146
Cumulative Timesteps: 1,151,938,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,277.30058
Policy Entropy: 3.75300
Value Function Loss: 0.02694

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.69056

Collected Steps per Second: 22,817.75299
Overall Steps per Second: 10,837.66543

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.61520

Cumulative Model Updates: 138,152
Cumulative Timesteps: 1,151,988,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1151988786...
Checkpoint 1151988786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,459.59562
Policy Entropy: 3.76135
Value Function Loss: 0.02823

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 22,857.76014
Overall Steps per Second: 10,675.67878

Timestep Collection Time: 2.18840
Timestep Consumption Time: 2.49720
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.68560

Cumulative Model Updates: 138,158
Cumulative Timesteps: 1,152,038,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,360.08348
Policy Entropy: 3.76878
Value Function Loss: 0.02635

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.59485
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 22,582.63311
Overall Steps per Second: 10,803.52538

Timestep Collection Time: 2.21480
Timestep Consumption Time: 2.41480
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.62960

Cumulative Model Updates: 138,164
Cumulative Timesteps: 1,152,088,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1152088824...
Checkpoint 1152088824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,205.77605
Policy Entropy: 3.75518
Value Function Loss: 0.02322

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.65151

Collected Steps per Second: 22,835.54269
Overall Steps per Second: 10,732.67900

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.47058
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.66146

Cumulative Model Updates: 138,170
Cumulative Timesteps: 1,152,138,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,381.79848
Policy Entropy: 3.76607
Value Function Loss: 0.02206

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.55842
Value Function Update Magnitude: 0.72101

Collected Steps per Second: 23,167.86213
Overall Steps per Second: 10,884.54431

Timestep Collection Time: 2.15877
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.59496

Cumulative Model Updates: 138,176
Cumulative Timesteps: 1,152,188,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1152188868...
Checkpoint 1152188868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.66202
Policy Entropy: 3.77602
Value Function Loss: 0.02337

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.56654
Value Function Update Magnitude: 0.80636

Collected Steps per Second: 22,980.00507
Overall Steps per Second: 10,709.11304

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.49322
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.66911

Cumulative Model Updates: 138,182
Cumulative Timesteps: 1,152,238,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,288.24408
Policy Entropy: 3.80217
Value Function Loss: 0.02560

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.61053
Value Function Update Magnitude: 0.98337

Collected Steps per Second: 22,672.79119
Overall Steps per Second: 10,799.53011

Timestep Collection Time: 2.20617
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.63168

Cumulative Model Updates: 138,188
Cumulative Timesteps: 1,152,288,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1152288890...
Checkpoint 1152288890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.73453
Policy Entropy: 3.79090
Value Function Loss: 0.02597

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.66196
Value Function Update Magnitude: 1.15102

Collected Steps per Second: 23,035.73976
Overall Steps per Second: 10,699.67889

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.50280
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.67360

Cumulative Model Updates: 138,194
Cumulative Timesteps: 1,152,338,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,585.36356
Policy Entropy: 3.79869
Value Function Loss: 0.02568

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.65725
Value Function Update Magnitude: 1.13722

Collected Steps per Second: 22,744.03695
Overall Steps per Second: 10,820.34698

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.42332
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62240

Cumulative Model Updates: 138,200
Cumulative Timesteps: 1,152,388,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1152388912...
Checkpoint 1152388912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120.84342
Policy Entropy: 3.79246
Value Function Loss: 0.02526

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.61765
Value Function Update Magnitude: 1.16305

Collected Steps per Second: 22,806.10826
Overall Steps per Second: 10,726.93016

Timestep Collection Time: 2.19240
Timestep Consumption Time: 2.46877
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.66117

Cumulative Model Updates: 138,206
Cumulative Timesteps: 1,152,438,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,664.19866
Policy Entropy: 3.79325
Value Function Loss: 0.02341

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 1.08526

Collected Steps per Second: 22,780.63865
Overall Steps per Second: 10,826.64928

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.62064

Cumulative Model Updates: 138,212
Cumulative Timesteps: 1,152,488,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1152488938...
Checkpoint 1152488938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 457.56738
Policy Entropy: 3.78793
Value Function Loss: 0.02178

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.98090

Collected Steps per Second: 22,890.30168
Overall Steps per Second: 10,698.06397

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.49051
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.67580

Cumulative Model Updates: 138,218
Cumulative Timesteps: 1,152,538,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,248.65851
Policy Entropy: 3.78051
Value Function Loss: 0.02282

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.52325
Value Function Update Magnitude: 0.97860

Collected Steps per Second: 22,901.62153
Overall Steps per Second: 10,827.80838

Timestep Collection Time: 2.18378
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61885

Cumulative Model Updates: 138,224
Cumulative Timesteps: 1,152,588,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1152588972...
Checkpoint 1152588972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,664.54551
Policy Entropy: 3.80726
Value Function Loss: 0.02147

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.93481

Collected Steps per Second: 22,838.02190
Overall Steps per Second: 10,757.06790

Timestep Collection Time: 2.19021
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.64997

Cumulative Model Updates: 138,230
Cumulative Timesteps: 1,152,638,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,909.69830
Policy Entropy: 3.81677
Value Function Loss: 0.02501

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.55307
Value Function Update Magnitude: 0.96765

Collected Steps per Second: 23,012.24098
Overall Steps per Second: 10,905.36242

Timestep Collection Time: 2.17389
Timestep Consumption Time: 2.41340
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.58728

Cumulative Model Updates: 138,236
Cumulative Timesteps: 1,152,689,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1152689018...
Checkpoint 1152689018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,802.51793
Policy Entropy: 3.85310
Value Function Loss: 0.02506

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.62248
Value Function Update Magnitude: 1.04318

Collected Steps per Second: 22,947.14404
Overall Steps per Second: 10,768.10463

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.46531
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.64501

Cumulative Model Updates: 138,242
Cumulative Timesteps: 1,152,739,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,249.83025
Policy Entropy: 3.85194
Value Function Loss: 0.02796

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.64522
Value Function Update Magnitude: 0.96808

Collected Steps per Second: 23,204.51515
Overall Steps per Second: 10,812.77698

Timestep Collection Time: 2.15527
Timestep Consumption Time: 2.47000
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.62527

Cumulative Model Updates: 138,248
Cumulative Timesteps: 1,152,789,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1152789048...
Checkpoint 1152789048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146.75264
Policy Entropy: 3.86396
Value Function Loss: 0.02645

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.64558
Value Function Update Magnitude: 0.97877

Collected Steps per Second: 23,036.97448
Overall Steps per Second: 10,777.52887

Timestep Collection Time: 2.17042
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.63928

Cumulative Model Updates: 138,254
Cumulative Timesteps: 1,152,839,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,356.78468
Policy Entropy: 3.80680
Value Function Loss: 0.02617

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.60212
Value Function Update Magnitude: 1.00551

Collected Steps per Second: 23,288.84913
Overall Steps per Second: 10,781.35680

Timestep Collection Time: 2.14824
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.64042

Cumulative Model Updates: 138,260
Cumulative Timesteps: 1,152,889,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1152889078...
Checkpoint 1152889078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,035.37733
Policy Entropy: 3.77966
Value Function Loss: 0.02562

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.61472
Value Function Update Magnitude: 0.89391

Collected Steps per Second: 22,879.61481
Overall Steps per Second: 10,739.95122

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.65980

Cumulative Model Updates: 138,266
Cumulative Timesteps: 1,152,939,124

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,633.63413
Policy Entropy: 3.73693
Value Function Loss: 0.03323

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15381
Policy Update Magnitude: 0.59085
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 22,873.62321
Overall Steps per Second: 10,758.76462

Timestep Collection Time: 2.18636
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.64830

Cumulative Model Updates: 138,272
Cumulative Timesteps: 1,152,989,134

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1152989134...
Checkpoint 1152989134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,127.94500
Policy Entropy: 3.75908
Value Function Loss: 0.03122

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.67601
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 22,646.42175
Overall Steps per Second: 10,643.22086

Timestep Collection Time: 2.20900
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70027

Cumulative Model Updates: 138,278
Cumulative Timesteps: 1,153,039,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.17691
Policy Entropy: 3.76450
Value Function Loss: 0.03102

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15339
Policy Update Magnitude: 0.77366
Value Function Update Magnitude: 0.76932

Collected Steps per Second: 22,886.14350
Overall Steps per Second: 10,866.10779

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.41732
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.60257

Cumulative Model Updates: 138,284
Cumulative Timesteps: 1,153,089,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1153089172...
Checkpoint 1153089172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,877.92954
Policy Entropy: 3.79476
Value Function Loss: 0.02859

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.76907
Value Function Update Magnitude: 0.80816

Collected Steps per Second: 22,886.44713
Overall Steps per Second: 10,688.77706

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.68061

Cumulative Model Updates: 138,290
Cumulative Timesteps: 1,153,139,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,243.14399
Policy Entropy: 3.82398
Value Function Loss: 0.02767

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.80590
Value Function Update Magnitude: 0.94969

Collected Steps per Second: 22,987.12168
Overall Steps per Second: 10,897.52406

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.58967

Cumulative Model Updates: 138,296
Cumulative Timesteps: 1,153,189,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1153189218...
Checkpoint 1153189218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,098.29087
Policy Entropy: 3.81203
Value Function Loss: 0.03039

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.84840
Value Function Update Magnitude: 0.93613

Collected Steps per Second: 22,998.28663
Overall Steps per Second: 10,744.50687

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.47947
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.65354

Cumulative Model Updates: 138,302
Cumulative Timesteps: 1,153,239,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,460.11419
Policy Entropy: 3.81244
Value Function Loss: 0.03062

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.97699
Value Function Update Magnitude: 0.91248

Collected Steps per Second: 23,060.77219
Overall Steps per Second: 10,818.96300

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.45363
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.62207

Cumulative Model Updates: 138,308
Cumulative Timesteps: 1,153,289,224

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1153289224...
Checkpoint 1153289224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,868.12231
Policy Entropy: 3.80908
Value Function Loss: 0.03285

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.11726
Policy Update Magnitude: 0.98427
Value Function Update Magnitude: 0.93816

Collected Steps per Second: 22,748.22477
Overall Steps per Second: 10,678.34815

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68425

Cumulative Model Updates: 138,314
Cumulative Timesteps: 1,153,339,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,304.22637
Policy Entropy: 3.84554
Value Function Loss: 0.03492

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.96169
Value Function Update Magnitude: 0.90900

Collected Steps per Second: 23,200.98527
Overall Steps per Second: 10,835.38016

Timestep Collection Time: 2.15534
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.61507

Cumulative Model Updates: 138,320
Cumulative Timesteps: 1,153,389,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1153389250...
Checkpoint 1153389250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.51754
Policy Entropy: 3.87068
Value Function Loss: 0.03214

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16814
Policy Update Magnitude: 0.89778
Value Function Update Magnitude: 1.00500

Collected Steps per Second: 23,042.09023
Overall Steps per Second: 10,769.94956

Timestep Collection Time: 2.17098
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.64478

Cumulative Model Updates: 138,326
Cumulative Timesteps: 1,153,439,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.62452
Policy Entropy: 3.88831
Value Function Loss: 0.02575

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.74066
Value Function Update Magnitude: 0.91737

Collected Steps per Second: 22,741.71737
Overall Steps per Second: 10,776.64870

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.64115

Cumulative Model Updates: 138,332
Cumulative Timesteps: 1,153,489,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1153489290...
Checkpoint 1153489290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 597,354.52402
Policy Entropy: 3.83978
Value Function Loss: 0.02521

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.17402
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.81526

Collected Steps per Second: 22,896.46719
Overall Steps per Second: 10,721.51284

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.66501

Cumulative Model Updates: 138,338
Cumulative Timesteps: 1,153,539,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,036.42353
Policy Entropy: 3.84326
Value Function Loss: 0.02485

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.18097
Policy Update Magnitude: 0.54609
Value Function Update Magnitude: 0.87686

Collected Steps per Second: 23,267.79659
Overall Steps per Second: 10,821.79911

Timestep Collection Time: 2.15001
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.62271

Cumulative Model Updates: 138,344
Cumulative Timesteps: 1,153,589,332

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1153589332...
Checkpoint 1153589332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,662.71578
Policy Entropy: 3.82218
Value Function Loss: 0.02760

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15857
Policy Update Magnitude: 0.59506
Value Function Update Magnitude: 0.99387

Collected Steps per Second: 22,956.20265
Overall Steps per Second: 10,739.39449

Timestep Collection Time: 2.17815
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.65594

Cumulative Model Updates: 138,350
Cumulative Timesteps: 1,153,639,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,781.02595
Policy Entropy: 3.86047
Value Function Loss: 0.02382

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14740
Policy Update Magnitude: 0.61330
Value Function Update Magnitude: 1.01706

Collected Steps per Second: 23,179.34566
Overall Steps per Second: 10,845.48284

Timestep Collection Time: 2.15718
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.61040

Cumulative Model Updates: 138,356
Cumulative Timesteps: 1,153,689,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1153689336...
Checkpoint 1153689336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,526.93977
Policy Entropy: 3.81073
Value Function Loss: 0.02503

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.59329
Value Function Update Magnitude: 1.00315

Collected Steps per Second: 21,788.46600
Overall Steps per Second: 10,613.32018

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.41646
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71144

Cumulative Model Updates: 138,362
Cumulative Timesteps: 1,153,739,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,793.37860
Policy Entropy: 3.78055
Value Function Loss: 0.02172

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.58574
Value Function Update Magnitude: 0.93564

Collected Steps per Second: 22,214.59507
Overall Steps per Second: 10,872.96598

Timestep Collection Time: 2.25131
Timestep Consumption Time: 2.34835
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59966

Cumulative Model Updates: 138,368
Cumulative Timesteps: 1,153,789,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1153789352...
Checkpoint 1153789352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,793.37860
Policy Entropy: 3.72498
Value Function Loss: 0.02124

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.16180
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.80037

Collected Steps per Second: 22,156.97815
Overall Steps per Second: 10,651.51119

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.69586

Cumulative Model Updates: 138,374
Cumulative Timesteps: 1,153,839,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,157.67200
Policy Entropy: 3.73226
Value Function Loss: 0.01815

Mean KL Divergence: 0.01825
SB3 Clip Fraction: 0.21902
Policy Update Magnitude: 0.52192
Value Function Update Magnitude: 0.66861

Collected Steps per Second: 22,848.43417
Overall Steps per Second: 10,902.98011

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.39795
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.58664

Cumulative Model Updates: 138,380
Cumulative Timesteps: 1,153,889,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1153889378...
Checkpoint 1153889378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,535.27944
Policy Entropy: 3.71258
Value Function Loss: 0.03511

Mean KL Divergence: 0.02981
SB3 Clip Fraction: 0.28462
Policy Update Magnitude: 0.44115
Value Function Update Magnitude: 0.59907

Collected Steps per Second: 22,425.17243
Overall Steps per Second: 10,669.82468

Timestep Collection Time: 2.23062
Timestep Consumption Time: 2.45756
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68817

Cumulative Model Updates: 138,386
Cumulative Timesteps: 1,153,939,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,845.09286
Policy Entropy: 3.77258
Value Function Loss: 0.04991

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.21692
Policy Update Magnitude: 0.56449
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 23,012.78979
Overall Steps per Second: 10,964.43318

Timestep Collection Time: 2.17323
Timestep Consumption Time: 2.38807
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.56129

Cumulative Model Updates: 138,392
Cumulative Timesteps: 1,153,989,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1153989412...
Checkpoint 1153989412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,255.48578
Policy Entropy: 3.81730
Value Function Loss: 0.06041

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.70478
Value Function Update Magnitude: 0.64960

Collected Steps per Second: 22,923.25560
Overall Steps per Second: 10,797.56687

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.63086

Cumulative Model Updates: 138,398
Cumulative Timesteps: 1,154,039,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.61749
Policy Entropy: 3.89817
Value Function Loss: 0.04813

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.88549
Value Function Update Magnitude: 0.73681

Collected Steps per Second: 23,226.84769
Overall Steps per Second: 10,868.60185

Timestep Collection Time: 2.15303
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.60114

Cumulative Model Updates: 138,404
Cumulative Timesteps: 1,154,089,422

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1154089422...
Checkpoint 1154089422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,094.13783
Policy Entropy: 3.90713
Value Function Loss: 0.04171

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.95537
Value Function Update Magnitude: 0.70669

Collected Steps per Second: 22,724.17559
Overall Steps per Second: 10,874.92400

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.39868
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.60012

Cumulative Model Updates: 138,410
Cumulative Timesteps: 1,154,139,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.95295
Policy Entropy: 3.86549
Value Function Loss: 0.03830

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18099
Policy Update Magnitude: 0.78505
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 23,023.71070
Overall Steps per Second: 10,943.54153

Timestep Collection Time: 2.17237
Timestep Consumption Time: 2.39800
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.57037

Cumulative Model Updates: 138,416
Cumulative Timesteps: 1,154,189,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1154189464...
Checkpoint 1154189464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.38865
Policy Entropy: 3.80637
Value Function Loss: 0.03113

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16063
Policy Update Magnitude: 0.64673
Value Function Update Magnitude: 0.48753

Collected Steps per Second: 22,759.43163
Overall Steps per Second: 10,737.66625

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.46089
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.65893

Cumulative Model Updates: 138,422
Cumulative Timesteps: 1,154,239,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,530.40763
Policy Entropy: 3.76752
Value Function Loss: 0.02813

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.54436

Collected Steps per Second: 22,833.91925
Overall Steps per Second: 10,876.98922

Timestep Collection Time: 2.19078
Timestep Consumption Time: 2.40829
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.59907

Cumulative Model Updates: 138,428
Cumulative Timesteps: 1,154,289,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1154289514...
Checkpoint 1154289514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,359.58381
Policy Entropy: 3.77896
Value Function Loss: 0.02676

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.58055

Collected Steps per Second: 22,436.80454
Overall Steps per Second: 10,604.46354

Timestep Collection Time: 2.22955
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.71726

Cumulative Model Updates: 138,434
Cumulative Timesteps: 1,154,339,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,906.34608
Policy Entropy: 3.79673
Value Function Loss: 0.02763

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.58483
Value Function Update Magnitude: 0.56762

Collected Steps per Second: 22,926.17933
Overall Steps per Second: 10,850.43247

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.61069

Cumulative Model Updates: 138,440
Cumulative Timesteps: 1,154,389,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1154389566...
Checkpoint 1154389566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,923.77996
Policy Entropy: 3.81351
Value Function Loss: 0.02903

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.67137
Value Function Update Magnitude: 0.61214

Collected Steps per Second: 22,636.63134
Overall Steps per Second: 10,704.83092

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.67322

Cumulative Model Updates: 138,446
Cumulative Timesteps: 1,154,439,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.05748
Policy Entropy: 3.83501
Value Function Loss: 0.02880

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.66362
Value Function Update Magnitude: 0.85805

Collected Steps per Second: 22,972.09044
Overall Steps per Second: 10,954.26147

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.38864
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.56589

Cumulative Model Updates: 138,452
Cumulative Timesteps: 1,154,489,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1154489608...
Checkpoint 1154489608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.81698
Policy Entropy: 3.82827
Value Function Loss: 0.02790

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.66918
Value Function Update Magnitude: 0.89974

Collected Steps per Second: 22,666.14136
Overall Steps per Second: 10,645.62506

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.49143
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69789

Cumulative Model Updates: 138,458
Cumulative Timesteps: 1,154,539,620

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.54023
Policy Entropy: 3.81274
Value Function Loss: 0.02476

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.64312
Value Function Update Magnitude: 0.83626

Collected Steps per Second: 22,882.05437
Overall Steps per Second: 10,830.64784

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.61708

Cumulative Model Updates: 138,464
Cumulative Timesteps: 1,154,589,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1154589626...
Checkpoint 1154589626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,813.42436
Policy Entropy: 3.79020
Value Function Loss: 0.02465

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.59512
Value Function Update Magnitude: 0.75226

Collected Steps per Second: 22,539.63094
Overall Steps per Second: 10,681.90929

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.68175

Cumulative Model Updates: 138,470
Cumulative Timesteps: 1,154,639,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.85284
Policy Entropy: 3.80349
Value Function Loss: 0.02413

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.67148

Collected Steps per Second: 22,796.87593
Overall Steps per Second: 10,899.39681

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.39480
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.58869

Cumulative Model Updates: 138,476
Cumulative Timesteps: 1,154,689,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1154689650...
Checkpoint 1154689650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,657.68678
Policy Entropy: 3.80961
Value Function Loss: 0.02672

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11852
Policy Update Magnitude: 0.58421
Value Function Update Magnitude: 0.74624

Collected Steps per Second: 22,408.35108
Overall Steps per Second: 10,657.00352

Timestep Collection Time: 2.23354
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.69644

Cumulative Model Updates: 138,482
Cumulative Timesteps: 1,154,739,700

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,458.65786
Policy Entropy: 3.81790
Value Function Loss: 0.02916

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.63998
Value Function Update Magnitude: 0.69510

Collected Steps per Second: 22,814.63038
Overall Steps per Second: 10,815.02620

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.43230
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.62449

Cumulative Model Updates: 138,488
Cumulative Timesteps: 1,154,789,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1154789714...
Checkpoint 1154789714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,450.84192
Policy Entropy: 3.80224
Value Function Loss: 0.02986

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.63635
Value Function Update Magnitude: 0.61565

Collected Steps per Second: 22,811.29610
Overall Steps per Second: 10,724.93717

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.47053
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.66278

Cumulative Model Updates: 138,494
Cumulative Timesteps: 1,154,839,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,644.46537
Policy Entropy: 3.79675
Value Function Loss: 0.02666

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.61989
Value Function Update Magnitude: 0.58804

Collected Steps per Second: 22,728.39670
Overall Steps per Second: 10,850.17225

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60841

Cumulative Model Updates: 138,500
Cumulative Timesteps: 1,154,889,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1154889724...
Checkpoint 1154889724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.59361
Policy Entropy: 3.78940
Value Function Loss: 0.02600

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.58529
Value Function Update Magnitude: 0.73929

Collected Steps per Second: 22,509.87288
Overall Steps per Second: 10,674.30569

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.46378
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.68583

Cumulative Model Updates: 138,506
Cumulative Timesteps: 1,154,939,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,673.73647
Policy Entropy: 3.77897
Value Function Loss: 0.02696

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.59150
Value Function Update Magnitude: 0.81272

Collected Steps per Second: 22,561.50894
Overall Steps per Second: 10,687.86529

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.67970

Cumulative Model Updates: 138,512
Cumulative Timesteps: 1,154,989,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1154989758...
Checkpoint 1154989758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,140.24708
Policy Entropy: 3.77983
Value Function Loss: 0.02862

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.61748
Value Function Update Magnitude: 0.80433

Collected Steps per Second: 22,427.47157
Overall Steps per Second: 10,621.35252

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.70900

Cumulative Model Updates: 138,518
Cumulative Timesteps: 1,155,039,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,526.05711
Policy Entropy: 3.75518
Value Function Loss: 0.02696

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.61691
Value Function Update Magnitude: 0.75525

Collected Steps per Second: 22,980.73046
Overall Steps per Second: 10,719.38934

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.66706

Cumulative Model Updates: 138,524
Cumulative Timesteps: 1,155,089,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1155089802...
Checkpoint 1155089802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,880.92393
Policy Entropy: 3.74924
Value Function Loss: 0.02476

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.56916
Value Function Update Magnitude: 0.71404

Collected Steps per Second: 22,720.27675
Overall Steps per Second: 10,640.90979

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.49847
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.69941

Cumulative Model Updates: 138,530
Cumulative Timesteps: 1,155,139,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,880.92393
Policy Entropy: 3.72979
Value Function Loss: 0.02079

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.48587
Value Function Update Magnitude: 0.62346

Collected Steps per Second: 22,850.33778
Overall Steps per Second: 10,835.92750

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.42739
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.61668

Cumulative Model Updates: 138,536
Cumulative Timesteps: 1,155,189,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1155189834...
Checkpoint 1155189834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,880.92393
Policy Entropy: 3.72882
Value Function Loss: 0.01939

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.41303
Value Function Update Magnitude: 0.47295

Collected Steps per Second: 22,859.48219
Overall Steps per Second: 10,708.80162

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.48446
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.67410

Cumulative Model Updates: 138,542
Cumulative Timesteps: 1,155,239,888

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,880.92393
Policy Entropy: 3.71248
Value Function Loss: 0.01867

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.39962
Value Function Update Magnitude: 0.36919

Collected Steps per Second: 22,640.25937
Overall Steps per Second: 10,830.08881

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.40966
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.61935

Cumulative Model Updates: 138,548
Cumulative Timesteps: 1,155,289,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1155289916...
Checkpoint 1155289916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,222.64268
Policy Entropy: 3.71716
Value Function Loss: 0.01998

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.42659
Value Function Update Magnitude: 0.41408

Collected Steps per Second: 22,403.40905
Overall Steps per Second: 10,725.97427

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.66158

Cumulative Model Updates: 138,554
Cumulative Timesteps: 1,155,339,916

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,011.80230
Policy Entropy: 3.73796
Value Function Loss: 0.02080

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.46055
Value Function Update Magnitude: 0.47326

Collected Steps per Second: 23,057.54391
Overall Steps per Second: 10,910.44448

Timestep Collection Time: 2.16918
Timestep Consumption Time: 2.41505
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.58423

Cumulative Model Updates: 138,560
Cumulative Timesteps: 1,155,389,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1155389932...
Checkpoint 1155389932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.17507
Policy Entropy: 3.75054
Value Function Loss: 0.02201

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.48086
Value Function Update Magnitude: 0.49700

Collected Steps per Second: 22,706.44104
Overall Steps per Second: 10,670.30290

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.68646

Cumulative Model Updates: 138,566
Cumulative Timesteps: 1,155,439,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.56222
Policy Entropy: 3.76218
Value Function Loss: 0.02137

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.49466
Value Function Update Magnitude: 0.58084

Collected Steps per Second: 23,244.18709
Overall Steps per Second: 10,890.31136

Timestep Collection Time: 2.15219
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.59362

Cumulative Model Updates: 138,572
Cumulative Timesteps: 1,155,489,964

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1155489964...
Checkpoint 1155489964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,462.68017
Policy Entropy: 3.75721
Value Function Loss: 0.01943

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.47862
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,278.46612
Overall Steps per Second: 10,775.73877

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.39602
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.64061

Cumulative Model Updates: 138,578
Cumulative Timesteps: 1,155,539,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.15512
Policy Entropy: 3.75704
Value Function Loss: 0.01732

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.43969
Value Function Update Magnitude: 0.60765

Collected Steps per Second: 22,552.89198
Overall Steps per Second: 10,781.84706

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.42177
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.64002

Cumulative Model Updates: 138,584
Cumulative Timesteps: 1,155,589,998

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1155589998...
Checkpoint 1155589998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.15512
Policy Entropy: 3.73672
Value Function Loss: 0.01668

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.41259
Value Function Update Magnitude: 0.58284

Collected Steps per Second: 22,267.15095
Overall Steps per Second: 10,597.49048

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71866

Cumulative Model Updates: 138,590
Cumulative Timesteps: 1,155,640,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.15512
Policy Entropy: 3.71413
Value Function Loss: 0.01726

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.41233
Value Function Update Magnitude: 0.57915

Collected Steps per Second: 23,053.57541
Overall Steps per Second: 10,979.86346

Timestep Collection Time: 2.16938
Timestep Consumption Time: 2.38550
PPO Batch Consumption Time: 0.27525
Total Iteration Time: 4.55488

Cumulative Model Updates: 138,596
Cumulative Timesteps: 1,155,690,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1155690016...
Checkpoint 1155690016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.15512
Policy Entropy: 3.70873
Value Function Loss: 0.01826

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.43787
Value Function Update Magnitude: 0.59905

Collected Steps per Second: 22,756.90588
Overall Steps per Second: 10,806.24084

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.62881

Cumulative Model Updates: 138,602
Cumulative Timesteps: 1,155,740,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,882.15512
Policy Entropy: 3.71546
Value Function Loss: 0.01900

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.44111
Value Function Update Magnitude: 0.55403

Collected Steps per Second: 22,765.43805
Overall Steps per Second: 10,669.75545

Timestep Collection Time: 2.19666
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.68689

Cumulative Model Updates: 138,608
Cumulative Timesteps: 1,155,790,044

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1155790044...
Checkpoint 1155790044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,372.39311
Policy Entropy: 3.73167
Value Function Loss: 0.01869

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.44302
Value Function Update Magnitude: 0.52048

Collected Steps per Second: 22,938.84531
Overall Steps per Second: 10,697.65973

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.67504

Cumulative Model Updates: 138,614
Cumulative Timesteps: 1,155,840,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,585.95652
Policy Entropy: 3.74106
Value Function Loss: 0.02141

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 23,164.40852
Overall Steps per Second: 10,873.41489

Timestep Collection Time: 2.16073
Timestep Consumption Time: 2.44243
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.60315

Cumulative Model Updates: 138,620
Cumulative Timesteps: 1,155,890,108

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1155890108...
Checkpoint 1155890108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,687.60956
Policy Entropy: 3.76834
Value Function Loss: 0.02294

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.69808

Collected Steps per Second: 22,909.41300
Overall Steps per Second: 10,731.39336

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.47741
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.66053

Cumulative Model Updates: 138,626
Cumulative Timesteps: 1,155,940,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,509.71786
Policy Entropy: 3.77603
Value Function Loss: 0.02358

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.75242

Collected Steps per Second: 22,917.75868
Overall Steps per Second: 10,812.31523

Timestep Collection Time: 2.18233
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.62565

Cumulative Model Updates: 138,632
Cumulative Timesteps: 1,155,990,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1155990136...
Checkpoint 1155990136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.92213
Policy Entropy: 3.77012
Value Function Loss: 0.02251

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.50968
Value Function Update Magnitude: 0.63768

Collected Steps per Second: 22,843.55386
Overall Steps per Second: 10,694.18944

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67693

Cumulative Model Updates: 138,638
Cumulative Timesteps: 1,156,040,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,142.54494
Policy Entropy: 3.75653
Value Function Loss: 0.02026

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.49170
Value Function Update Magnitude: 0.59458

Collected Steps per Second: 23,056.32914
Overall Steps per Second: 10,875.13242

Timestep Collection Time: 2.16912
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.59875

Cumulative Model Updates: 138,644
Cumulative Timesteps: 1,156,090,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1156090164...
Checkpoint 1156090164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,524.17471
Policy Entropy: 3.75327
Value Function Loss: 0.02121

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.48386
Value Function Update Magnitude: 0.59531

Collected Steps per Second: 22,775.23862
Overall Steps per Second: 10,691.89215

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.48256
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.67925

Cumulative Model Updates: 138,650
Cumulative Timesteps: 1,156,140,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.93679
Policy Entropy: 3.76807
Value Function Loss: 0.01953

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.48625
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 23,485.74731
Overall Steps per Second: 10,799.63645

Timestep Collection Time: 2.12972
Timestep Consumption Time: 2.50174
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.63145

Cumulative Model Updates: 138,656
Cumulative Timesteps: 1,156,190,212

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1156190212...
Checkpoint 1156190212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.51615
Policy Entropy: 3.75307
Value Function Loss: 0.01982

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.44863
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 22,459.92834
Overall Steps per Second: 10,669.19248

Timestep Collection Time: 2.22717
Timestep Consumption Time: 2.46129
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.68845

Cumulative Model Updates: 138,662
Cumulative Timesteps: 1,156,240,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,168.43377
Policy Entropy: 3.76314
Value Function Loss: 0.02063

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.42123
Value Function Update Magnitude: 0.53053

Collected Steps per Second: 23,094.44182
Overall Steps per Second: 10,880.54112

Timestep Collection Time: 2.16511
Timestep Consumption Time: 2.43043
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59554

Cumulative Model Updates: 138,668
Cumulative Timesteps: 1,156,290,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1156290236...
Checkpoint 1156290236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,976.20123
Policy Entropy: 3.76560
Value Function Loss: 0.02193

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.41055
Value Function Update Magnitude: 0.60520

Collected Steps per Second: 22,597.98269
Overall Steps per Second: 10,676.18492

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.68444

Cumulative Model Updates: 138,674
Cumulative Timesteps: 1,156,340,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,969.99957
Policy Entropy: 3.77267
Value Function Loss: 0.02008

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.41724
Value Function Update Magnitude: 0.65458

Collected Steps per Second: 23,044.92779
Overall Steps per Second: 10,909.36064

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.41383
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.58377

Cumulative Model Updates: 138,680
Cumulative Timesteps: 1,156,390,254

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1156390254...
Checkpoint 1156390254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,969.99957
Policy Entropy: 3.76696
Value Function Loss: 0.01806

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.42273
Value Function Update Magnitude: 0.65188

Collected Steps per Second: 22,702.73160
Overall Steps per Second: 10,678.25537

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.48103
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.68429

Cumulative Model Updates: 138,686
Cumulative Timesteps: 1,156,440,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,858.02640
Policy Entropy: 3.75220
Value Function Loss: 0.01864

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.45411
Value Function Update Magnitude: 0.64932

Collected Steps per Second: 23,186.99433
Overall Steps per Second: 10,895.58692

Timestep Collection Time: 2.15707
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.59048

Cumulative Model Updates: 138,692
Cumulative Timesteps: 1,156,490,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1156490290...
Checkpoint 1156490290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75025
Value Function Loss: 0.02127

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.49911
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 22,215.82977
Overall Steps per Second: 10,761.25820

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.39594
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.64685

Cumulative Model Updates: 138,698
Cumulative Timesteps: 1,156,540,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.73364
Value Function Loss: 0.02175

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.51946
Value Function Update Magnitude: 0.59783

Collected Steps per Second: 22,610.31637
Overall Steps per Second: 10,823.93248

Timestep Collection Time: 2.21244
Timestep Consumption Time: 2.40917
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.62161

Cumulative Model Updates: 138,704
Cumulative Timesteps: 1,156,590,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1156590320...
Checkpoint 1156590320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75313
Value Function Loss: 0.01837

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.50461
Value Function Update Magnitude: 0.57300

Collected Steps per Second: 22,264.41618
Overall Steps per Second: 10,614.36442

Timestep Collection Time: 2.24708
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.71342

Cumulative Model Updates: 138,710
Cumulative Timesteps: 1,156,640,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.74751
Value Function Loss: 0.01689

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.42684
Value Function Update Magnitude: 0.47542

Collected Steps per Second: 23,192.82584
Overall Steps per Second: 10,876.26804

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.44142
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.59735

Cumulative Model Updates: 138,716
Cumulative Timesteps: 1,156,690,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1156690352...
Checkpoint 1156690352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75879
Value Function Loss: 0.01551

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.34960
Value Function Update Magnitude: 0.31996

Collected Steps per Second: 22,569.25695
Overall Steps per Second: 10,695.42734

Timestep Collection Time: 2.21585
Timestep Consumption Time: 2.45998
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67583

Cumulative Model Updates: 138,722
Cumulative Timesteps: 1,156,740,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75250
Value Function Loss: 0.01585

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.31535
Value Function Update Magnitude: 0.23691

Collected Steps per Second: 22,950.70236
Overall Steps per Second: 10,904.66528

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.40825
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.58831

Cumulative Model Updates: 138,728
Cumulative Timesteps: 1,156,790,396

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1156790396...
Checkpoint 1156790396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75796
Value Function Loss: 0.01336

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.31606
Value Function Update Magnitude: 0.28707

Collected Steps per Second: 22,720.34423
Overall Steps per Second: 10,664.74821

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.69266

Cumulative Model Updates: 138,734
Cumulative Timesteps: 1,156,840,442

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,716.73862
Policy Entropy: 3.75600
Value Function Loss: 0.01334

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.35126
Value Function Update Magnitude: 0.28716

Collected Steps per Second: 23,081.27230
Overall Steps per Second: 10,900.08142

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.42086
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.58712

Cumulative Model Updates: 138,740
Cumulative Timesteps: 1,156,890,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1156890442...
Checkpoint 1156890442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,493.57895
Policy Entropy: 3.75725
Value Function Loss: 0.01567

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.36285
Value Function Update Magnitude: 0.41395

Collected Steps per Second: 22,857.14286
Overall Steps per Second: 10,727.53998

Timestep Collection Time: 2.18864
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.66332

Cumulative Model Updates: 138,746
Cumulative Timesteps: 1,156,940,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,347.67176
Policy Entropy: 3.76310
Value Function Loss: 0.01733

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.41418
Value Function Update Magnitude: 0.59566

Collected Steps per Second: 23,010.18858
Overall Steps per Second: 10,786.23773

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.46387
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.63795

Cumulative Model Updates: 138,752
Cumulative Timesteps: 1,156,990,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1156990494...
Checkpoint 1156990494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,347.67176
Policy Entropy: 3.75280
Value Function Loss: 0.01902

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.46559
Value Function Update Magnitude: 0.65133

Collected Steps per Second: 23,090.02228
Overall Steps per Second: 10,720.00484

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.49934
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.66530

Cumulative Model Updates: 138,758
Cumulative Timesteps: 1,157,040,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,347.67176
Policy Entropy: 3.74264
Value Function Loss: 0.01870

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 23,045.98773
Overall Steps per Second: 10,834.67257

Timestep Collection Time: 2.16984
Timestep Consumption Time: 2.44553
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.61537

Cumulative Model Updates: 138,764
Cumulative Timesteps: 1,157,090,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1157090512...
Checkpoint 1157090512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,347.67176
Policy Entropy: 3.72087
Value Function Loss: 0.01952

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.50095
Value Function Update Magnitude: 0.51513

Collected Steps per Second: 22,714.84136
Overall Steps per Second: 10,679.68659

Timestep Collection Time: 2.20191
Timestep Consumption Time: 2.48138
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68328

Cumulative Model Updates: 138,770
Cumulative Timesteps: 1,157,140,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,347.67176
Policy Entropy: 3.73477
Value Function Loss: 0.01871

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.47613
Value Function Update Magnitude: 0.53661

Collected Steps per Second: 22,924.01314
Overall Steps per Second: 10,857.12496

Timestep Collection Time: 2.18234
Timestep Consumption Time: 2.42551
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.60785

Cumulative Model Updates: 138,776
Cumulative Timesteps: 1,157,190,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1157190556...
Checkpoint 1157190556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,521.19838
Policy Entropy: 3.74595
Value Function Loss: 0.02183

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.46338
Value Function Update Magnitude: 0.56961

Collected Steps per Second: 22,444.17748
Overall Steps per Second: 10,613.08391

Timestep Collection Time: 2.22891
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.71362

Cumulative Model Updates: 138,782
Cumulative Timesteps: 1,157,240,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,762.68173
Policy Entropy: 3.75216
Value Function Loss: 0.02196

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.50533
Value Function Update Magnitude: 0.55285

Collected Steps per Second: 23,048.01709
Overall Steps per Second: 10,914.92032

Timestep Collection Time: 2.17016
Timestep Consumption Time: 2.41237
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.58253

Cumulative Model Updates: 138,788
Cumulative Timesteps: 1,157,290,600

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1157290600...
Checkpoint 1157290600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,867.88483
Policy Entropy: 3.75547
Value Function Loss: 0.02285

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.51805
Value Function Update Magnitude: 0.44634

Collected Steps per Second: 22,557.13314
Overall Steps per Second: 10,645.25698

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.69918

Cumulative Model Updates: 138,794
Cumulative Timesteps: 1,157,340,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,344.38199
Policy Entropy: 3.76153
Value Function Loss: 0.01930

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.47501
Value Function Update Magnitude: 0.38226

Collected Steps per Second: 23,142.17488
Overall Steps per Second: 10,944.07624

Timestep Collection Time: 2.16125
Timestep Consumption Time: 2.40889
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.57014

Cumulative Model Updates: 138,800
Cumulative Timesteps: 1,157,390,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1157390640...
Checkpoint 1157390640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,801.16278
Policy Entropy: 3.75904
Value Function Loss: 0.01793

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14224
Policy Update Magnitude: 0.42331
Value Function Update Magnitude: 0.42049

Collected Steps per Second: 22,049.30872
Overall Steps per Second: 10,682.25274

Timestep Collection Time: 2.26783
Timestep Consumption Time: 2.41321
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.68104

Cumulative Model Updates: 138,806
Cumulative Timesteps: 1,157,440,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,077.16848
Policy Entropy: 3.75356
Value Function Loss: 0.01885

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.43599
Value Function Update Magnitude: 0.37976

Collected Steps per Second: 22,336.94541
Overall Steps per Second: 10,869.45372

Timestep Collection Time: 2.23907
Timestep Consumption Time: 2.36226
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.60134

Cumulative Model Updates: 138,812
Cumulative Timesteps: 1,157,490,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1157490658...
Checkpoint 1157490658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,673.81800
Policy Entropy: 3.77432
Value Function Loss: 0.02013

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.44842
Value Function Update Magnitude: 0.39233

Collected Steps per Second: 21,971.33823
Overall Steps per Second: 10,669.91126

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.41086
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68701

Cumulative Model Updates: 138,818
Cumulative Timesteps: 1,157,540,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,613.37212
Policy Entropy: 3.78053
Value Function Loss: 0.02006

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.45055
Value Function Update Magnitude: 0.46585

Collected Steps per Second: 22,322.18493
Overall Steps per Second: 10,801.56024

Timestep Collection Time: 2.23992
Timestep Consumption Time: 2.38904
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.62896

Cumulative Model Updates: 138,824
Cumulative Timesteps: 1,157,590,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1157590668...
Checkpoint 1157590668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,894.46098
Policy Entropy: 3.78639
Value Function Loss: 0.01858

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.45122
Value Function Update Magnitude: 0.44372

Collected Steps per Second: 22,692.40106
Overall Steps per Second: 10,712.42948

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.46419
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.66766

Cumulative Model Updates: 138,830
Cumulative Timesteps: 1,157,640,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,312.78894
Policy Entropy: 3.77776
Value Function Loss: 0.01822

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.43239
Value Function Update Magnitude: 0.41805

Collected Steps per Second: 22,909.99434
Overall Steps per Second: 10,877.22996

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.59841

Cumulative Model Updates: 138,836
Cumulative Timesteps: 1,157,690,688

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1157690688...
Checkpoint 1157690688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.76536
Value Function Loss: 0.01661

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.42401
Value Function Update Magnitude: 0.42298

Collected Steps per Second: 22,511.25214
Overall Steps per Second: 10,643.21149

Timestep Collection Time: 2.22200
Timestep Consumption Time: 2.47771
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.69971

Cumulative Model Updates: 138,842
Cumulative Timesteps: 1,157,740,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.75842
Value Function Loss: 0.01635

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.41777
Value Function Update Magnitude: 0.41345

Collected Steps per Second: 22,609.76248
Overall Steps per Second: 10,791.07623

Timestep Collection Time: 2.21250
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.63568

Cumulative Model Updates: 138,848
Cumulative Timesteps: 1,157,790,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1157790732...
Checkpoint 1157790732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.75353
Value Function Loss: 0.02400

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.39469
Value Function Update Magnitude: 0.31228

Collected Steps per Second: 22,515.45332
Overall Steps per Second: 10,805.62427

Timestep Collection Time: 2.22096
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.62778

Cumulative Model Updates: 138,854
Cumulative Timesteps: 1,157,840,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.73606
Value Function Loss: 0.02152

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.41687
Value Function Update Magnitude: 0.25031

Collected Steps per Second: 22,938.84377
Overall Steps per Second: 10,893.83574

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.41101
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.59159

Cumulative Model Updates: 138,860
Cumulative Timesteps: 1,157,890,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1157890758...
Checkpoint 1157890758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.72743
Value Function Loss: 0.02263

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.42536
Value Function Update Magnitude: 0.25629

Collected Steps per Second: 22,861.51729
Overall Steps per Second: 10,726.16852

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.66187

Cumulative Model Updates: 138,866
Cumulative Timesteps: 1,157,940,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,966.85476
Policy Entropy: 3.73095
Value Function Loss: 0.02012

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.45935
Value Function Update Magnitude: 0.29954

Collected Steps per Second: 22,738.78301
Overall Steps per Second: 10,771.04538

Timestep Collection Time: 2.20021
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.64486

Cumulative Model Updates: 138,872
Cumulative Timesteps: 1,157,990,792

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1157990792...
Checkpoint 1157990792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,012.42987
Policy Entropy: 3.73907
Value Function Loss: 0.02302

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.50742
Value Function Update Magnitude: 0.36297

Collected Steps per Second: 22,081.08000
Overall Steps per Second: 10,704.44316

Timestep Collection Time: 2.26583
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67395

Cumulative Model Updates: 138,878
Cumulative Timesteps: 1,158,040,824

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,012.42987
Policy Entropy: 3.73921
Value Function Loss: 0.02305

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.44790

Collected Steps per Second: 22,272.10073
Overall Steps per Second: 10,855.77564

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.36154
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.60713

Cumulative Model Updates: 138,884
Cumulative Timesteps: 1,158,090,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1158090838...
Checkpoint 1158090838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,012.42987
Policy Entropy: 3.73988
Value Function Loss: 0.02151

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.55774

Collected Steps per Second: 22,131.44011
Overall Steps per Second: 10,622.78317

Timestep Collection Time: 2.26068
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.70988

Cumulative Model Updates: 138,890
Cumulative Timesteps: 1,158,140,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 441,012.42987
Policy Entropy: 3.72844
Value Function Loss: 0.02138

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 22,775.71721
Overall Steps per Second: 10,912.87671

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.38680
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.58248

Cumulative Model Updates: 138,896
Cumulative Timesteps: 1,158,190,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1158190878...
Checkpoint 1158190878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 441,012.42987
Policy Entropy: 3.73246
Value Function Loss: 0.02036

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.61353

Collected Steps per Second: 22,894.34945
Overall Steps per Second: 10,805.27057

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.44343
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.62737

Cumulative Model Updates: 138,902
Cumulative Timesteps: 1,158,240,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,033.35708
Policy Entropy: 3.72808
Value Function Loss: 0.02281

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.50644
Value Function Update Magnitude: 0.50307

Collected Steps per Second: 22,860.12118
Overall Steps per Second: 10,782.66199

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.63874

Cumulative Model Updates: 138,908
Cumulative Timesteps: 1,158,290,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1158290896...
Checkpoint 1158290896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,068.41530
Policy Entropy: 3.73803
Value Function Loss: 0.02391

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.47847

Collected Steps per Second: 22,908.71632
Overall Steps per Second: 10,732.27294

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.66071

Cumulative Model Updates: 138,914
Cumulative Timesteps: 1,158,340,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,248.18011
Policy Entropy: 3.73063
Value Function Loss: 0.02582

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.60657

Collected Steps per Second: 22,816.02043
Overall Steps per Second: 10,762.90434

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.45493
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.64707

Cumulative Model Updates: 138,920
Cumulative Timesteps: 1,158,390,932

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1158390932...
Checkpoint 1158390932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626,072.96849
Policy Entropy: 3.72983
Value Function Loss: 0.02811

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.61609
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 22,980.41509
Overall Steps per Second: 10,712.22387

Timestep Collection Time: 2.17620
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.66850

Cumulative Model Updates: 138,926
Cumulative Timesteps: 1,158,440,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,413.91754
Policy Entropy: 3.72783
Value Function Loss: 0.02829

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13622
Policy Update Magnitude: 0.62729
Value Function Update Magnitude: 0.52707

Collected Steps per Second: 22,984.27567
Overall Steps per Second: 10,930.20177

Timestep Collection Time: 2.17653
Timestep Consumption Time: 2.40033
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.57686

Cumulative Model Updates: 138,932
Cumulative Timesteps: 1,158,490,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1158490968...
Checkpoint 1158490968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,669.92704
Policy Entropy: 3.73926
Value Function Loss: 0.03261

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.62421
Value Function Update Magnitude: 0.55563

Collected Steps per Second: 23,042.96795
Overall Steps per Second: 10,833.21114

Timestep Collection Time: 2.17099
Timestep Consumption Time: 2.44685
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.61784

Cumulative Model Updates: 138,938
Cumulative Timesteps: 1,158,540,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485,452.19453
Policy Entropy: 3.73872
Value Function Loss: 0.03329

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.62380
Value Function Update Magnitude: 0.80429

Collected Steps per Second: 22,661.35377
Overall Steps per Second: 10,628.88324

Timestep Collection Time: 2.20764
Timestep Consumption Time: 2.49916
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.70680

Cumulative Model Updates: 138,944
Cumulative Timesteps: 1,158,591,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1158591022...
Checkpoint 1158591022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,780.95391
Policy Entropy: 3.74701
Value Function Loss: 0.04089

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.65377
Value Function Update Magnitude: 0.67485

Collected Steps per Second: 23,092.42718
Overall Steps per Second: 10,728.33327

Timestep Collection Time: 2.16642
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.66317

Cumulative Model Updates: 138,950
Cumulative Timesteps: 1,158,641,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,764.49030
Policy Entropy: 3.76777
Value Function Loss: 0.02754

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.62832
Value Function Update Magnitude: 0.69800

Collected Steps per Second: 23,152.97404
Overall Steps per Second: 10,853.41943

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.44827
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.60869

Cumulative Model Updates: 138,956
Cumulative Timesteps: 1,158,691,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1158691070...
Checkpoint 1158691070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,365.89759
Policy Entropy: 3.77498
Value Function Loss: 0.02663

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.78210

Collected Steps per Second: 22,992.03549
Overall Steps per Second: 10,762.34357

Timestep Collection Time: 2.17527
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.64713

Cumulative Model Updates: 138,962
Cumulative Timesteps: 1,158,741,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,203.64125
Policy Entropy: 3.76584
Value Function Loss: 0.02296

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.69061

Collected Steps per Second: 22,800.12899
Overall Steps per Second: 10,756.98774

Timestep Collection Time: 2.19367
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.64963

Cumulative Model Updates: 138,968
Cumulative Timesteps: 1,158,791,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1158791100...
Checkpoint 1158791100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355,454.31950
Policy Entropy: 3.75577
Value Function Loss: 0.02531

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.49024
Value Function Update Magnitude: 0.70930

Collected Steps per Second: 22,914.67020
Overall Steps per Second: 10,701.31679

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67494

Cumulative Model Updates: 138,974
Cumulative Timesteps: 1,158,841,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,849.23662
Policy Entropy: 3.76751
Value Function Loss: 0.02271

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.74407

Collected Steps per Second: 22,972.67603
Overall Steps per Second: 10,906.38119

Timestep Collection Time: 2.17763
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.58686

Cumulative Model Updates: 138,980
Cumulative Timesteps: 1,158,891,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1158891154...
Checkpoint 1158891154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,305.44705
Policy Entropy: 3.78530
Value Function Loss: 0.03150

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.52328
Value Function Update Magnitude: 0.67374

Collected Steps per Second: 23,028.32991
Overall Steps per Second: 10,787.14889

Timestep Collection Time: 2.17167
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.63607

Cumulative Model Updates: 138,986
Cumulative Timesteps: 1,158,941,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,500.78532
Policy Entropy: 3.80302
Value Function Loss: 0.02786

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.55241
Value Function Update Magnitude: 0.56570

Collected Steps per Second: 23,007.72588
Overall Steps per Second: 10,701.95913

Timestep Collection Time: 2.17397
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.67372

Cumulative Model Updates: 138,992
Cumulative Timesteps: 1,158,991,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1158991182...
Checkpoint 1158991182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,736.20383
Policy Entropy: 3.79485
Value Function Loss: 0.03067

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.56398

Collected Steps per Second: 22,994.16473
Overall Steps per Second: 10,740.63950

Timestep Collection Time: 2.17455
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.65540

Cumulative Model Updates: 138,998
Cumulative Timesteps: 1,159,041,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,041.79290
Policy Entropy: 3.78013
Value Function Loss: 0.02299

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.52216
Value Function Update Magnitude: 0.55021

Collected Steps per Second: 23,031.84875
Overall Steps per Second: 10,843.72645

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.44025
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.61133

Cumulative Model Updates: 139,004
Cumulative Timesteps: 1,159,091,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1159091188...
Checkpoint 1159091188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,754.35325
Policy Entropy: 3.74999
Value Function Loss: 0.02459

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.47914
Value Function Update Magnitude: 0.48717

Collected Steps per Second: 22,966.29604
Overall Steps per Second: 10,758.13692

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.47084
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.64820

Cumulative Model Updates: 139,010
Cumulative Timesteps: 1,159,141,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314,752.85568
Policy Entropy: 3.75067
Value Function Loss: 0.02171

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13649
Policy Update Magnitude: 0.46199
Value Function Update Magnitude: 0.46917

Collected Steps per Second: 23,029.54010
Overall Steps per Second: 10,770.16548

Timestep Collection Time: 2.17121
Timestep Consumption Time: 2.47143
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.64264

Cumulative Model Updates: 139,016
Cumulative Timesteps: 1,159,191,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1159191196...
Checkpoint 1159191196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,501.76537
Policy Entropy: 3.75127
Value Function Loss: 0.02455

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.47064
Value Function Update Magnitude: 0.44948

Collected Steps per Second: 22,960.97616
Overall Steps per Second: 10,693.00329

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.67745

Cumulative Model Updates: 139,022
Cumulative Timesteps: 1,159,241,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,888.06625
Policy Entropy: 3.75848
Value Function Loss: 0.02240

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.47345
Value Function Update Magnitude: 0.50124

Collected Steps per Second: 23,251.18432
Overall Steps per Second: 10,840.35459

Timestep Collection Time: 2.15146
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.61461

Cumulative Model Updates: 139,028
Cumulative Timesteps: 1,159,291,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1159291236...
Checkpoint 1159291236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,112.77009
Policy Entropy: 3.75280
Value Function Loss: 0.02035

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14483
Policy Update Magnitude: 0.46211
Value Function Update Magnitude: 0.54163

Collected Steps per Second: 22,953.38054
Overall Steps per Second: 10,728.67213

Timestep Collection Time: 2.17946
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66283

Cumulative Model Updates: 139,034
Cumulative Timesteps: 1,159,341,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,367.54247
Policy Entropy: 3.74994
Value Function Loss: 0.01984

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.49648
Value Function Update Magnitude: 0.53537

Collected Steps per Second: 22,933.42861
Overall Steps per Second: 10,778.72261

Timestep Collection Time: 2.18022
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.63877

Cumulative Model Updates: 139,040
Cumulative Timesteps: 1,159,391,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1159391262...
Checkpoint 1159391262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,367.54247
Policy Entropy: 3.75204
Value Function Loss: 0.01717

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.53031

Collected Steps per Second: 23,100.11466
Overall Steps per Second: 10,745.91713

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.65312

Cumulative Model Updates: 139,046
Cumulative Timesteps: 1,159,441,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,367.54247
Policy Entropy: 3.73141
Value Function Loss: 0.02124

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.51925
Value Function Update Magnitude: 0.62377

Collected Steps per Second: 22,966.17726
Overall Steps per Second: 10,838.82291

Timestep Collection Time: 2.17772
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.61434

Cumulative Model Updates: 139,052
Cumulative Timesteps: 1,159,491,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1159491278...
Checkpoint 1159491278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,211.77223
Policy Entropy: 3.73528
Value Function Loss: 0.02347

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.61653
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 23,148.60462
Overall Steps per Second: 10,803.16643

Timestep Collection Time: 2.16030
Timestep Consumption Time: 2.46871
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.62901

Cumulative Model Updates: 139,058
Cumulative Timesteps: 1,159,541,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,797.18683
Policy Entropy: 3.73488
Value Function Loss: 0.02378

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.68241
Value Function Update Magnitude: 0.60454

Collected Steps per Second: 22,843.94873
Overall Steps per Second: 10,707.95112

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.48096
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.66999

Cumulative Model Updates: 139,064
Cumulative Timesteps: 1,159,591,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1159591292...
Checkpoint 1159591292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,241.10864
Policy Entropy: 3.75206
Value Function Loss: 0.02612

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.71360
Value Function Update Magnitude: 0.71734

Collected Steps per Second: 22,730.94437
Overall Steps per Second: 10,662.97551

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.69100

Cumulative Model Updates: 139,070
Cumulative Timesteps: 1,159,641,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,254.74212
Policy Entropy: 3.76626
Value Function Loss: 0.02613

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.72156
Value Function Update Magnitude: 0.67975

Collected Steps per Second: 22,956.38104
Overall Steps per Second: 10,881.32537

Timestep Collection Time: 2.17944
Timestep Consumption Time: 2.41853
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59797

Cumulative Model Updates: 139,076
Cumulative Timesteps: 1,159,691,344

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1159691344...
Checkpoint 1159691344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,083.40002
Policy Entropy: 3.76720
Value Function Loss: 0.02715

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.79639
Value Function Update Magnitude: 0.64464

Collected Steps per Second: 23,098.00223
Overall Steps per Second: 10,791.13693

Timestep Collection Time: 2.16521
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.63454

Cumulative Model Updates: 139,082
Cumulative Timesteps: 1,159,741,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,940.78148
Policy Entropy: 3.78573
Value Function Loss: 0.02173

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.77645
Value Function Update Magnitude: 0.60455

Collected Steps per Second: 22,986.58613
Overall Steps per Second: 10,761.71481

Timestep Collection Time: 2.17596
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64777

Cumulative Model Updates: 139,088
Cumulative Timesteps: 1,159,791,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1159791374...
Checkpoint 1159791374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.16424
Policy Entropy: 3.79884
Value Function Loss: 0.01589

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.64530
Value Function Update Magnitude: 0.63967

Collected Steps per Second: 22,918.81820
Overall Steps per Second: 10,702.12151

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.67440

Cumulative Model Updates: 139,094
Cumulative Timesteps: 1,159,841,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,321.21223
Policy Entropy: 3.79402
Value Function Loss: 0.01335

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 22,924.93440
Overall Steps per Second: 10,874.35387

Timestep Collection Time: 2.18225
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.60055

Cumulative Model Updates: 139,100
Cumulative Timesteps: 1,159,891,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1159891428...
Checkpoint 1159891428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,338.51507
Policy Entropy: 3.77964
Value Function Loss: 0.01396

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.09176
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.56483

Collected Steps per Second: 22,970.65241
Overall Steps per Second: 10,745.08864

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.47709
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.65422

Cumulative Model Updates: 139,106
Cumulative Timesteps: 1,159,941,438

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,887.11864
Policy Entropy: 3.76368
Value Function Loss: 0.01824

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07438
Policy Update Magnitude: 0.59643
Value Function Update Magnitude: 0.50277

Collected Steps per Second: 22,722.34494
Overall Steps per Second: 10,848.64084

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.40984
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.61164

Cumulative Model Updates: 139,112
Cumulative Timesteps: 1,159,991,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1159991468...
Checkpoint 1159991468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,890.78451
Policy Entropy: 3.77000
Value Function Loss: 0.01886

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.67764
Value Function Update Magnitude: 0.41248

Collected Steps per Second: 23,185.63056
Overall Steps per Second: 10,952.36950

Timestep Collection Time: 2.15780
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.56796

Cumulative Model Updates: 139,118
Cumulative Timesteps: 1,160,041,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,319.34736
Policy Entropy: 3.77560
Value Function Loss: 0.01905

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.70492
Value Function Update Magnitude: 0.42443

Collected Steps per Second: 22,330.74294
Overall Steps per Second: 10,885.01171

Timestep Collection Time: 2.23924
Timestep Consumption Time: 2.35460
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.59384

Cumulative Model Updates: 139,124
Cumulative Timesteps: 1,160,091,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1160091502...
Checkpoint 1160091502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,954.35366
Policy Entropy: 3.79057
Value Function Loss: 0.01795

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.68138
Value Function Update Magnitude: 0.51732

Collected Steps per Second: 22,233.46130
Overall Steps per Second: 10,737.36067

Timestep Collection Time: 2.24949
Timestep Consumption Time: 2.40845
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.65794

Cumulative Model Updates: 139,130
Cumulative Timesteps: 1,160,141,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,234.78576
Policy Entropy: 3.79171
Value Function Loss: 0.01749

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06572
Policy Update Magnitude: 0.65856
Value Function Update Magnitude: 0.49476

Collected Steps per Second: 22,209.35148
Overall Steps per Second: 10,885.49581

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.34337
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.59602

Cumulative Model Updates: 139,136
Cumulative Timesteps: 1,160,191,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1160191546...
Checkpoint 1160191546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,167.73097
Policy Entropy: 3.79425
Value Function Loss: 0.01545

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.62734
Value Function Update Magnitude: 0.43147

Collected Steps per Second: 22,175.06660
Overall Steps per Second: 10,629.76546

Timestep Collection Time: 2.25542
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.70509

Cumulative Model Updates: 139,142
Cumulative Timesteps: 1,160,241,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,167.73097
Policy Entropy: 3.79432
Value Function Loss: 0.01177

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.39542

Collected Steps per Second: 22,867.62840
Overall Steps per Second: 10,923.47119

Timestep Collection Time: 2.18728
Timestep Consumption Time: 2.39166
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.57895

Cumulative Model Updates: 139,148
Cumulative Timesteps: 1,160,291,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1160291578...
Checkpoint 1160291578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252,410.00744
Policy Entropy: 3.77863
Value Function Loss: 0.01239

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07489
Policy Update Magnitude: 0.49418
Value Function Update Magnitude: 0.41920

Collected Steps per Second: 22,983.25688
Overall Steps per Second: 10,855.12301

Timestep Collection Time: 2.17671
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.60870

Cumulative Model Updates: 139,154
Cumulative Timesteps: 1,160,341,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,012.27231
Policy Entropy: 3.77651
Value Function Loss: 0.01289

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.49674
Value Function Update Magnitude: 0.51120

Collected Steps per Second: 22,924.52291
Overall Steps per Second: 10,711.58961

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.66971

Cumulative Model Updates: 139,160
Cumulative Timesteps: 1,160,391,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1160391626...
Checkpoint 1160391626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,035.68092
Policy Entropy: 3.77919
Value Function Loss: 0.01489

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05037
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.55304

Collected Steps per Second: 22,650.11304
Overall Steps per Second: 10,659.61118

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.48390
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69210

Cumulative Model Updates: 139,166
Cumulative Timesteps: 1,160,441,642

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,071.84671
Policy Entropy: 3.78534
Value Function Loss: 0.01468

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05710
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 22,873.68190
Overall Steps per Second: 10,855.90201

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.60726

Cumulative Model Updates: 139,172
Cumulative Timesteps: 1,160,491,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1160491658...
Checkpoint 1160491658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,216.14203
Policy Entropy: 3.78037
Value Function Loss: 0.01395

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.56105

Collected Steps per Second: 22,820.07379
Overall Steps per Second: 10,701.76330

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67661

Cumulative Model Updates: 139,178
Cumulative Timesteps: 1,160,541,706

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,540.97701
Policy Entropy: 3.76755
Value Function Loss: 0.01912

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.19133
Policy Update Magnitude: 0.45935
Value Function Update Magnitude: 0.50050

Collected Steps per Second: 23,152.13649
Overall Steps per Second: 10,951.86040

Timestep Collection Time: 2.16023
Timestep Consumption Time: 2.40648
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.56671

Cumulative Model Updates: 139,184
Cumulative Timesteps: 1,160,591,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1160591720...
Checkpoint 1160591720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,772.68872
Policy Entropy: 3.77750
Value Function Loss: 0.01923

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.18265
Policy Update Magnitude: 0.42385
Value Function Update Magnitude: 0.53152

Collected Steps per Second: 22,985.17092
Overall Steps per Second: 10,795.25304

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.63222

Cumulative Model Updates: 139,190
Cumulative Timesteps: 1,160,641,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,110.17766
Policy Entropy: 3.77659
Value Function Loss: 0.02604

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.17082
Policy Update Magnitude: 0.41316
Value Function Update Magnitude: 0.50176

Collected Steps per Second: 22,906.61369
Overall Steps per Second: 10,696.32896

Timestep Collection Time: 2.18347
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.67600

Cumulative Model Updates: 139,196
Cumulative Timesteps: 1,160,691,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1160691742...
Checkpoint 1160691742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,898.92125
Policy Entropy: 3.79504
Value Function Loss: 0.02561

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14252
Policy Update Magnitude: 0.44055
Value Function Update Magnitude: 0.48149

Collected Steps per Second: 22,131.45660
Overall Steps per Second: 10,701.85513

Timestep Collection Time: 2.26013
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.67396

Cumulative Model Updates: 139,202
Cumulative Timesteps: 1,160,741,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,369.46449
Policy Entropy: 3.77625
Value Function Loss: 0.02563

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15163
Policy Update Magnitude: 0.47135
Value Function Update Magnitude: 0.50364

Collected Steps per Second: 22,036.76917
Overall Steps per Second: 10,817.21107

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.35342
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.62245

Cumulative Model Updates: 139,208
Cumulative Timesteps: 1,160,791,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1160791764...
Checkpoint 1160791764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,322.02319
Policy Entropy: 3.76954
Value Function Loss: 0.02309

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13967
Policy Update Magnitude: 0.50726
Value Function Update Magnitude: 0.51178

Collected Steps per Second: 21,881.66189
Overall Steps per Second: 10,682.94906

Timestep Collection Time: 2.28529
Timestep Consumption Time: 2.39562
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.68092

Cumulative Model Updates: 139,214
Cumulative Timesteps: 1,160,841,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,737.95152
Policy Entropy: 3.76023
Value Function Loss: 0.02152

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.55136

Collected Steps per Second: 22,073.37602
Overall Steps per Second: 10,587.75680

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.45864
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72508

Cumulative Model Updates: 139,220
Cumulative Timesteps: 1,160,891,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1160891798...
Checkpoint 1160891798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,666.48641
Policy Entropy: 3.75068
Value Function Loss: 0.02392

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.50207
Value Function Update Magnitude: 0.53703

Collected Steps per Second: 22,955.71243
Overall Steps per Second: 10,949.85160

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.39017
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.57011

Cumulative Model Updates: 139,226
Cumulative Timesteps: 1,160,941,840

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,314.84414
Policy Entropy: 3.76118
Value Function Loss: 0.02584

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.51684
Value Function Update Magnitude: 0.52076

Collected Steps per Second: 22,696.37471
Overall Steps per Second: 10,880.87092

Timestep Collection Time: 2.20299
Timestep Consumption Time: 2.39223
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.59522

Cumulative Model Updates: 139,232
Cumulative Timesteps: 1,160,991,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1160991840...
Checkpoint 1160991840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,504.61135
Policy Entropy: 3.76796
Value Function Loss: 0.02937

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.52239
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 22,806.08807
Overall Steps per Second: 10,741.47994

Timestep Collection Time: 2.19327
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.65671

Cumulative Model Updates: 139,238
Cumulative Timesteps: 1,161,041,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,916.74969
Policy Entropy: 3.77577
Value Function Loss: 0.02569

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 22,845.00278
Overall Steps per Second: 10,837.32663

Timestep Collection Time: 2.18893
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.61424

Cumulative Model Updates: 139,244
Cumulative Timesteps: 1,161,091,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1161091866...
Checkpoint 1161091866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,907.34673
Policy Entropy: 3.76487
Value Function Loss: 0.02510

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.60608

Collected Steps per Second: 22,912.43435
Overall Steps per Second: 10,704.39948

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.67266

Cumulative Model Updates: 139,250
Cumulative Timesteps: 1,161,141,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,337.24345
Policy Entropy: 3.77327
Value Function Loss: 0.02365

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.52575
Value Function Update Magnitude: 0.66889

Collected Steps per Second: 22,808.38254
Overall Steps per Second: 10,824.63907

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.42759
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.62038

Cumulative Model Updates: 139,256
Cumulative Timesteps: 1,161,191,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1161191898...
Checkpoint 1161191898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,923.61637
Policy Entropy: 3.77154
Value Function Loss: 0.02423

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.65011

Collected Steps per Second: 22,829.03330
Overall Steps per Second: 10,673.34884

Timestep Collection Time: 2.19037
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68494

Cumulative Model Updates: 139,262
Cumulative Timesteps: 1,161,241,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,063.74950
Policy Entropy: 3.77101
Value Function Loss: 0.02268

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.52302
Value Function Update Magnitude: 0.66683

Collected Steps per Second: 22,749.36326
Overall Steps per Second: 10,833.65955

Timestep Collection Time: 2.19839
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.61635

Cumulative Model Updates: 139,268
Cumulative Timesteps: 1,161,291,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1161291914...
Checkpoint 1161291914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,884.23235
Policy Entropy: 3.75319
Value Function Loss: 0.02131

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.49895
Value Function Update Magnitude: 0.72683

Collected Steps per Second: 22,924.46137
Overall Steps per Second: 10,722.22164

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.66526

Cumulative Model Updates: 139,274
Cumulative Timesteps: 1,161,341,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,170.06142
Policy Entropy: 3.74871
Value Function Loss: 0.01914

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.51724
Value Function Update Magnitude: 0.74694

Collected Steps per Second: 22,728.36312
Overall Steps per Second: 10,824.40856

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.62159

Cumulative Model Updates: 139,280
Cumulative Timesteps: 1,161,391,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1161391962...
Checkpoint 1161391962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,331.27568
Policy Entropy: 3.73478
Value Function Loss: 0.02030

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.51972
Value Function Update Magnitude: 0.78698

Collected Steps per Second: 22,917.02375
Overall Steps per Second: 10,698.09784

Timestep Collection Time: 2.18205
Timestep Consumption Time: 2.49224
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67429

Cumulative Model Updates: 139,286
Cumulative Timesteps: 1,161,441,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,508.53989
Policy Entropy: 3.73978
Value Function Loss: 0.01823

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.50531
Value Function Update Magnitude: 0.73697

Collected Steps per Second: 22,241.79211
Overall Steps per Second: 10,864.82367

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.35493
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60385

Cumulative Model Updates: 139,292
Cumulative Timesteps: 1,161,491,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1161491988...
Checkpoint 1161491988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,508.53989
Policy Entropy: 3.74712
Value Function Loss: 0.01756

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14447
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.65898

Collected Steps per Second: 22,329.00652
Overall Steps per Second: 10,744.12321

Timestep Collection Time: 2.24040
Timestep Consumption Time: 2.41572
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.65613

Cumulative Model Updates: 139,298
Cumulative Timesteps: 1,161,542,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,228.38159
Policy Entropy: 3.76399
Value Function Loss: 0.01612

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.45001
Value Function Update Magnitude: 0.56233

Collected Steps per Second: 21,954.46636
Overall Steps per Second: 10,824.91084

Timestep Collection Time: 2.27808
Timestep Consumption Time: 2.34219
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.62027

Cumulative Model Updates: 139,304
Cumulative Timesteps: 1,161,592,028

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1161592028...
Checkpoint 1161592028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,031.28200
Policy Entropy: 3.76637
Value Function Loss: 0.01771

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.43202
Value Function Update Magnitude: 0.55418

Collected Steps per Second: 22,092.72025
Overall Steps per Second: 10,646.14650

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.69766

Cumulative Model Updates: 139,310
Cumulative Timesteps: 1,161,642,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,394.89752
Policy Entropy: 3.76249
Value Function Loss: 0.01779

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.43813
Value Function Update Magnitude: 0.53965

Collected Steps per Second: 23,196.20340
Overall Steps per Second: 10,932.09226

Timestep Collection Time: 2.15570
Timestep Consumption Time: 2.41836
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.57406

Cumulative Model Updates: 139,316
Cumulative Timesteps: 1,161,692,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1161692044...
Checkpoint 1161692044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,663.53581
Policy Entropy: 3.76149
Value Function Loss: 0.02091

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.46705
Value Function Update Magnitude: 0.55701

Collected Steps per Second: 22,839.27215
Overall Steps per Second: 10,802.88266

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.43987
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.62969

Cumulative Model Updates: 139,322
Cumulative Timesteps: 1,161,742,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,980.00181
Policy Entropy: 3.75985
Value Function Loss: 0.02038

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.51662
Value Function Update Magnitude: 0.58272

Collected Steps per Second: 22,977.08136
Overall Steps per Second: 10,748.43501

Timestep Collection Time: 2.17643
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.65258

Cumulative Model Updates: 139,328
Cumulative Timesteps: 1,161,792,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1161792066...
Checkpoint 1161792066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,642.01718
Policy Entropy: 3.76254
Value Function Loss: 0.02698

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.55860
Value Function Update Magnitude: 0.67381

Collected Steps per Second: 22,981.02863
Overall Steps per Second: 10,721.86402

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.66430

Cumulative Model Updates: 139,334
Cumulative Timesteps: 1,161,842,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,937.15378
Policy Entropy: 3.77466
Value Function Loss: 0.02738

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.59644
Value Function Update Magnitude: 0.78019

Collected Steps per Second: 22,824.00650
Overall Steps per Second: 10,878.18615

Timestep Collection Time: 2.19146
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.59801

Cumulative Model Updates: 139,340
Cumulative Timesteps: 1,161,892,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1161892094...
Checkpoint 1161892094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,919.14947
Policy Entropy: 3.77088
Value Function Loss: 0.03003

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.59514
Value Function Update Magnitude: 0.83405

Collected Steps per Second: 22,958.35483
Overall Steps per Second: 10,727.42988

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.48448
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.66356

Cumulative Model Updates: 139,346
Cumulative Timesteps: 1,161,942,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,443.07341
Policy Entropy: 3.78353
Value Function Loss: 0.02680

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.72258

Collected Steps per Second: 23,022.00851
Overall Steps per Second: 10,770.83073

Timestep Collection Time: 2.17227
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.64310

Cumulative Model Updates: 139,352
Cumulative Timesteps: 1,161,992,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1161992132...
Checkpoint 1161992132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,187.01099
Policy Entropy: 3.77793
Value Function Loss: 0.02572

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.51743
Value Function Update Magnitude: 0.66113

Collected Steps per Second: 22,855.46881
Overall Steps per Second: 10,704.38875

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.67322

Cumulative Model Updates: 139,358
Cumulative Timesteps: 1,162,042,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,888.67559
Policy Entropy: 3.77827
Value Function Loss: 0.02414

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.67556

Collected Steps per Second: 22,785.56234
Overall Steps per Second: 10,862.36347

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.40868
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60305

Cumulative Model Updates: 139,364
Cumulative Timesteps: 1,162,092,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1162092156...
Checkpoint 1162092156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,336.13037
Policy Entropy: 3.77324
Value Function Loss: 0.02523

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.70467

Collected Steps per Second: 22,834.48799
Overall Steps per Second: 10,741.72544

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.46577
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.65605

Cumulative Model Updates: 139,370
Cumulative Timesteps: 1,162,142,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,556.49632
Policy Entropy: 3.77469
Value Function Loss: 0.02331

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.51474
Value Function Update Magnitude: 0.63775

Collected Steps per Second: 22,790.13949
Overall Steps per Second: 10,750.75812

Timestep Collection Time: 2.19472
Timestep Consumption Time: 2.45779
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.65251

Cumulative Model Updates: 139,376
Cumulative Timesteps: 1,162,192,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1162192188...
Checkpoint 1162192188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,556.49632
Policy Entropy: 3.76421
Value Function Loss: 0.02174

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.51112
Value Function Update Magnitude: 0.60708

Collected Steps per Second: 22,891.31649
Overall Steps per Second: 10,721.12521

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.48094
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.66649

Cumulative Model Updates: 139,382
Cumulative Timesteps: 1,162,242,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,357.02849
Policy Entropy: 3.75030
Value Function Loss: 0.01896

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.49367
Value Function Update Magnitude: 0.54991

Collected Steps per Second: 22,228.16624
Overall Steps per Second: 10,915.83041

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.33316
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.58453

Cumulative Model Updates: 139,388
Cumulative Timesteps: 1,162,292,262

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1162292262...
Checkpoint 1162292262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,642.40974
Policy Entropy: 3.74936
Value Function Loss: 0.01646

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.55447

Collected Steps per Second: 22,302.44395
Overall Steps per Second: 10,961.85704

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.32001
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.56255

Cumulative Model Updates: 139,394
Cumulative Timesteps: 1,162,342,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,781.52442
Policy Entropy: 3.74293
Value Function Loss: 0.01791

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.44332
Value Function Update Magnitude: 0.48320

Collected Steps per Second: 22,227.51075
Overall Steps per Second: 10,887.31082

Timestep Collection Time: 2.24973
Timestep Consumption Time: 2.34332
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59305

Cumulative Model Updates: 139,400
Cumulative Timesteps: 1,162,392,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1162392282...
Checkpoint 1162392282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,753.67218
Policy Entropy: 3.75657
Value Function Loss: 0.02002

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.48257
Value Function Update Magnitude: 0.49603

Collected Steps per Second: 21,984.77432
Overall Steps per Second: 10,707.64278

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.39651
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.67199

Cumulative Model Updates: 139,406
Cumulative Timesteps: 1,162,442,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,322.15618
Policy Entropy: 3.74423
Value Function Loss: 0.02225

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.57129
Value Function Update Magnitude: 0.79230

Collected Steps per Second: 22,856.81800
Overall Steps per Second: 10,913.98397

Timestep Collection Time: 2.18823
Timestep Consumption Time: 2.39451
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58274

Cumulative Model Updates: 139,412
Cumulative Timesteps: 1,162,492,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1162492324...
Checkpoint 1162492324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,017.87387
Policy Entropy: 3.76137
Value Function Loss: 0.02200

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.60422
Value Function Update Magnitude: 0.94703

Collected Steps per Second: 22,456.37396
Overall Steps per Second: 10,676.42521

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.68584

Cumulative Model Updates: 139,418
Cumulative Timesteps: 1,162,542,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.30600
Policy Entropy: 3.76854
Value Function Loss: 0.02037

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.88762

Collected Steps per Second: 23,018.19763
Overall Steps per Second: 10,858.59851

Timestep Collection Time: 2.17219
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.60465

Cumulative Model Updates: 139,424
Cumulative Timesteps: 1,162,592,352

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1162592352...
Checkpoint 1162592352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,874.61558
Policy Entropy: 3.76272
Value Function Loss: 0.02099

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.49941
Value Function Update Magnitude: 0.81383

Collected Steps per Second: 22,762.46623
Overall Steps per Second: 10,665.36389

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68826

Cumulative Model Updates: 139,430
Cumulative Timesteps: 1,162,642,354

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,401.29762
Policy Entropy: 3.76318
Value Function Loss: 0.02043

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.49574
Value Function Update Magnitude: 0.83851

Collected Steps per Second: 23,067.14219
Overall Steps per Second: 10,892.00978

Timestep Collection Time: 2.16828
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.59199

Cumulative Model Updates: 139,436
Cumulative Timesteps: 1,162,692,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1162692370...
Checkpoint 1162692370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,994.57625
Policy Entropy: 3.77012
Value Function Loss: 0.02287

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.51567
Value Function Update Magnitude: 0.84043

Collected Steps per Second: 22,968.76051
Overall Steps per Second: 10,722.27145

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.66506

Cumulative Model Updates: 139,442
Cumulative Timesteps: 1,162,742,390

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,544.09920
Policy Entropy: 3.79226
Value Function Loss: 0.02102

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.95076

Collected Steps per Second: 22,854.42699
Overall Steps per Second: 10,879.08180

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.40870
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.59690

Cumulative Model Updates: 139,448
Cumulative Timesteps: 1,162,792,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1162792400...
Checkpoint 1162792400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.31635
Policy Entropy: 3.78558
Value Function Loss: 0.02110

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13283
Policy Update Magnitude: 0.53098
Value Function Update Magnitude: 0.93374

Collected Steps per Second: 22,769.72928
Overall Steps per Second: 10,647.94096

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.69800

Cumulative Model Updates: 139,454
Cumulative Timesteps: 1,162,842,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,568.26970
Policy Entropy: 3.77035
Value Function Loss: 0.02168

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.50800
Value Function Update Magnitude: 0.78061

Collected Steps per Second: 22,842.07737
Overall Steps per Second: 10,852.26300

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60936

Cumulative Model Updates: 139,460
Cumulative Timesteps: 1,162,892,446

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1162892446...
Checkpoint 1162892446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,616.84249
Policy Entropy: 3.74550
Value Function Loss: 0.02234

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.49903
Value Function Update Magnitude: 0.66643

Collected Steps per Second: 22,881.59854
Overall Steps per Second: 10,710.30179

Timestep Collection Time: 2.18630
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67083

Cumulative Model Updates: 139,466
Cumulative Timesteps: 1,162,942,472

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,060.05811
Policy Entropy: 3.74765
Value Function Loss: 0.02125

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.48679
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 22,731.30631
Overall Steps per Second: 10,808.74744

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.42763
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.62847

Cumulative Model Updates: 139,472
Cumulative Timesteps: 1,162,992,500

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1162992500...
Checkpoint 1162992500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,125.84580
Policy Entropy: 3.74339
Value Function Loss: 0.01989

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.45588
Value Function Update Magnitude: 0.59217

Collected Steps per Second: 22,669.13109
Overall Steps per Second: 10,697.88101

Timestep Collection Time: 2.20617
Timestep Consumption Time: 2.46877
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.67494

Cumulative Model Updates: 139,478
Cumulative Timesteps: 1,163,042,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,912.20810
Policy Entropy: 3.75671
Value Function Loss: 0.01753

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.42519
Value Function Update Magnitude: 0.62788

Collected Steps per Second: 22,735.54123
Overall Steps per Second: 10,828.09690

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.41842
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.61762

Cumulative Model Updates: 139,484
Cumulative Timesteps: 1,163,092,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1163092512...
Checkpoint 1163092512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,530.89695
Policy Entropy: 3.75472
Value Function Loss: 0.01691

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.44106
Value Function Update Magnitude: 0.71288

Collected Steps per Second: 22,953.16884
Overall Steps per Second: 10,706.41743

Timestep Collection Time: 2.17922
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.67196

Cumulative Model Updates: 139,490
Cumulative Timesteps: 1,163,142,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,636.89093
Policy Entropy: 3.74583
Value Function Loss: 0.01855

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.48342
Value Function Update Magnitude: 0.80903

Collected Steps per Second: 22,933.68708
Overall Steps per Second: 10,853.00642

Timestep Collection Time: 2.18098
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60868

Cumulative Model Updates: 139,496
Cumulative Timesteps: 1,163,192,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1163192550...
Checkpoint 1163192550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,128.46994
Policy Entropy: 3.73656
Value Function Loss: 0.02110

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.51834
Value Function Update Magnitude: 0.77566

Collected Steps per Second: 22,595.67181
Overall Steps per Second: 10,717.63710

Timestep Collection Time: 2.21379
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.66726

Cumulative Model Updates: 139,502
Cumulative Timesteps: 1,163,242,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,634.96681
Policy Entropy: 3.74390
Value Function Loss: 0.02387

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13598
Policy Update Magnitude: 0.54769
Value Function Update Magnitude: 0.69018

Collected Steps per Second: 22,235.79466
Overall Steps per Second: 10,879.55001

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.34771
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.59688

Cumulative Model Updates: 139,508
Cumulative Timesteps: 1,163,292,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1163292584...
Checkpoint 1163292584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,090.40312
Policy Entropy: 3.75340
Value Function Loss: 0.02480

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.64315

Collected Steps per Second: 22,201.48679
Overall Steps per Second: 10,739.36589

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.40501
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65838

Cumulative Model Updates: 139,514
Cumulative Timesteps: 1,163,342,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.48773
Policy Entropy: 3.76064
Value Function Loss: 0.02303

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.66301

Collected Steps per Second: 22,394.05332
Overall Steps per Second: 10,847.20505

Timestep Collection Time: 2.23372
Timestep Consumption Time: 2.37779
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.61151

Cumulative Model Updates: 139,520
Cumulative Timesteps: 1,163,392,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1163392634...
Checkpoint 1163392634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247,935.93651
Policy Entropy: 3.75065
Value Function Loss: 0.02234

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.50293
Value Function Update Magnitude: 0.67508

Collected Steps per Second: 22,176.36377
Overall Steps per Second: 10,614.72277

Timestep Collection Time: 2.25510
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.71138

Cumulative Model Updates: 139,526
Cumulative Timesteps: 1,163,442,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,027.82371
Policy Entropy: 3.75717
Value Function Loss: 0.02035

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.51459
Value Function Update Magnitude: 0.61522

Collected Steps per Second: 23,356.20686
Overall Steps per Second: 10,950.21293

Timestep Collection Time: 2.14084
Timestep Consumption Time: 2.42546
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.56630

Cumulative Model Updates: 139,532
Cumulative Timesteps: 1,163,492,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1163492646...
Checkpoint 1163492646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,249.46729
Policy Entropy: 3.75350
Value Function Loss: 0.02133

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13995
Policy Update Magnitude: 0.49336
Value Function Update Magnitude: 0.55578

Collected Steps per Second: 22,769.81553
Overall Steps per Second: 10,783.89033

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.44134
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.63784

Cumulative Model Updates: 139,538
Cumulative Timesteps: 1,163,542,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,751.92860
Policy Entropy: 3.76888
Value Function Loss: 0.02201

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.48993
Value Function Update Magnitude: 0.55057

Collected Steps per Second: 23,508.72934
Overall Steps per Second: 10,961.91278

Timestep Collection Time: 2.12695
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.56143

Cumulative Model Updates: 139,544
Cumulative Timesteps: 1,163,592,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1163592662...
Checkpoint 1163592662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,960.58884
Policy Entropy: 3.78102
Value Function Loss: 0.02089

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14118
Policy Update Magnitude: 0.50466
Value Function Update Magnitude: 0.66899

Collected Steps per Second: 22,335.66827
Overall Steps per Second: 10,632.55746

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.46505
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.70461

Cumulative Model Updates: 139,550
Cumulative Timesteps: 1,163,642,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226.97645
Policy Entropy: 3.79196
Value Function Loss: 0.02042

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.48014
Value Function Update Magnitude: 0.59460

Collected Steps per Second: 23,003.64403
Overall Steps per Second: 10,692.08215

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.67692

Cumulative Model Updates: 139,556
Cumulative Timesteps: 1,163,692,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1163692690...
Checkpoint 1163692690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.36344
Policy Entropy: 3.78284
Value Function Loss: 0.01835

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.45326
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 22,936.71307
Overall Steps per Second: 10,717.94153

Timestep Collection Time: 2.17991
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.66507

Cumulative Model Updates: 139,562
Cumulative Timesteps: 1,163,742,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,397.23543
Policy Entropy: 3.75677
Value Function Loss: 0.01814

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.44017
Value Function Update Magnitude: 0.64668

Collected Steps per Second: 23,169.80874
Overall Steps per Second: 10,806.74925

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.63062

Cumulative Model Updates: 139,568
Cumulative Timesteps: 1,163,792,732

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1163792732...
Checkpoint 1163792732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,962.41106
Policy Entropy: 3.74786
Value Function Loss: 0.01689

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.45514
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 22,406.30451
Overall Steps per Second: 10,641.19157

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.70060

Cumulative Model Updates: 139,574
Cumulative Timesteps: 1,163,842,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,497.92755
Policy Entropy: 3.75304
Value Function Loss: 0.02090

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.47482
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 22,778.27862
Overall Steps per Second: 10,832.76965

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.61655

Cumulative Model Updates: 139,580
Cumulative Timesteps: 1,163,892,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1163892762...
Checkpoint 1163892762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,794.88142
Policy Entropy: 3.75817
Value Function Loss: 0.02296

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.58950
Value Function Update Magnitude: 0.57442

Collected Steps per Second: 22,931.01287
Overall Steps per Second: 10,725.89483

Timestep Collection Time: 2.18150
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.66385

Cumulative Model Updates: 139,586
Cumulative Timesteps: 1,163,942,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,105.48335
Policy Entropy: 3.75346
Value Function Loss: 0.02205

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.16084
Policy Update Magnitude: 0.61262
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 22,478.02845
Overall Steps per Second: 10,956.76080

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.33928
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.56394

Cumulative Model Updates: 139,592
Cumulative Timesteps: 1,163,992,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1163992792...
Checkpoint 1163992792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,747.64140
Policy Entropy: 3.74989
Value Function Loss: 0.01783

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.57341
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 22,159.30097
Overall Steps per Second: 10,759.30013

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.39219
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.64993

Cumulative Model Updates: 139,598
Cumulative Timesteps: 1,164,042,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 370,799.51106
Policy Entropy: 3.73648
Value Function Loss: 0.01656

Mean KL Divergence: 0.02336
SB3 Clip Fraction: 0.26272
Policy Update Magnitude: 0.49681
Value Function Update Magnitude: 0.47875

Collected Steps per Second: 22,399.53972
Overall Steps per Second: 10,758.56697

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.64783

Cumulative Model Updates: 139,604
Cumulative Timesteps: 1,164,092,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1164092826...
Checkpoint 1164092826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,437.63207
Policy Entropy: 3.74810
Value Function Loss: 0.04373

Mean KL Divergence: 0.02725
SB3 Clip Fraction: 0.25658
Policy Update Magnitude: 0.52130
Value Function Update Magnitude: 0.46989

Collected Steps per Second: 22,736.16874
Overall Steps per Second: 10,755.78685

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.64922

Cumulative Model Updates: 139,610
Cumulative Timesteps: 1,164,142,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,891.85242
Policy Entropy: 3.90424
Value Function Loss: 0.04434

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.15688
Policy Update Magnitude: 0.92912
Value Function Update Magnitude: 0.64164

Collected Steps per Second: 22,871.07817
Overall Steps per Second: 10,888.73538

Timestep Collection Time: 2.18643
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.59245

Cumulative Model Updates: 139,616
Cumulative Timesteps: 1,164,192,838

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1164192838...
Checkpoint 1164192838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.61981
Policy Entropy: 4.05170
Value Function Loss: 0.04168

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 1.31336
Value Function Update Magnitude: 0.85357

Collected Steps per Second: 23,014.65373
Overall Steps per Second: 10,904.69991

Timestep Collection Time: 2.17366
Timestep Consumption Time: 2.41390
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.58756

Cumulative Model Updates: 139,622
Cumulative Timesteps: 1,164,242,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.18380
Policy Entropy: 4.15861
Value Function Loss: 0.02977

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08298
Policy Update Magnitude: 1.35851
Value Function Update Magnitude: 1.08916

Collected Steps per Second: 22,996.55249
Overall Steps per Second: 10,917.36823

Timestep Collection Time: 2.17493
Timestep Consumption Time: 2.40639
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.58132

Cumulative Model Updates: 139,628
Cumulative Timesteps: 1,164,292,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1164292880...
Checkpoint 1164292880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206.70308
Policy Entropy: 4.15040
Value Function Loss: 0.03028

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07479
Policy Update Magnitude: 1.30554
Value Function Update Magnitude: 1.19880

Collected Steps per Second: 22,859.97166
Overall Steps per Second: 10,746.42609

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.65457

Cumulative Model Updates: 139,634
Cumulative Timesteps: 1,164,342,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14299
Policy Entropy: 4.09738
Value Function Loss: 0.02993

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 1.23240
Value Function Update Magnitude: 1.27837

Collected Steps per Second: 23,128.25913
Overall Steps per Second: 10,893.59188

Timestep Collection Time: 2.16246
Timestep Consumption Time: 2.42868
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.59114

Cumulative Model Updates: 139,640
Cumulative Timesteps: 1,164,392,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1164392914...
Checkpoint 1164392914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.85758
Policy Entropy: 4.05553
Value Function Loss: 0.03187

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06710
Policy Update Magnitude: 1.12946
Value Function Update Magnitude: 1.22287

Collected Steps per Second: 22,499.26408
Overall Steps per Second: 10,978.20959

Timestep Collection Time: 2.22238
Timestep Consumption Time: 2.33228
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.55466

Cumulative Model Updates: 139,646
Cumulative Timesteps: 1,164,442,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.48107
Policy Entropy: 3.99145
Value Function Loss: 0.03244

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.08150
Policy Update Magnitude: 0.99434
Value Function Update Magnitude: 1.11099

Collected Steps per Second: 22,289.95283
Overall Steps per Second: 10,791.27253

Timestep Collection Time: 2.24379
Timestep Consumption Time: 2.39088
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.63467

Cumulative Model Updates: 139,652
Cumulative Timesteps: 1,164,492,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1164492930...
Checkpoint 1164492930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.24141
Policy Entropy: 3.95976
Value Function Loss: 0.03325

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.85018
Value Function Update Magnitude: 1.03621

Collected Steps per Second: 22,157.55700
Overall Steps per Second: 10,921.92546

Timestep Collection Time: 2.25720
Timestep Consumption Time: 2.32203
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.57923

Cumulative Model Updates: 139,658
Cumulative Timesteps: 1,164,542,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.76158
Policy Entropy: 3.95036
Value Function Loss: 0.03417

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.76957
Value Function Update Magnitude: 0.98910

Collected Steps per Second: 22,418.44009
Overall Steps per Second: 10,874.23190

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.36905
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.60060

Cumulative Model Updates: 139,664
Cumulative Timesteps: 1,164,592,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1164592972...
Checkpoint 1164592972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.05988
Policy Entropy: 3.96440
Value Function Loss: 0.03436

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.67935
Value Function Update Magnitude: 0.79533

Collected Steps per Second: 22,629.87195
Overall Steps per Second: 10,595.68121

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.51074
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.72136

Cumulative Model Updates: 139,670
Cumulative Timesteps: 1,164,642,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,428.98403
Policy Entropy: 3.95254
Value Function Loss: 0.03629

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.66066
Value Function Update Magnitude: 0.71600

Collected Steps per Second: 22,995.70684
Overall Steps per Second: 10,917.67652

Timestep Collection Time: 2.17528
Timestep Consumption Time: 2.40647
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.58174

Cumulative Model Updates: 139,676
Cumulative Timesteps: 1,164,693,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1164693020...
Checkpoint 1164693020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.79726
Policy Entropy: 3.93378
Value Function Loss: 0.03290

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.64820
Value Function Update Magnitude: 0.74951

Collected Steps per Second: 22,632.59008
Overall Steps per Second: 10,676.56400

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.47464
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68447

Cumulative Model Updates: 139,682
Cumulative Timesteps: 1,164,743,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,591.99615
Policy Entropy: 3.88776
Value Function Loss: 0.03383

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.68743
Value Function Update Magnitude: 0.82872

Collected Steps per Second: 23,034.82773
Overall Steps per Second: 10,876.74338

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.59788

Cumulative Model Updates: 139,688
Cumulative Timesteps: 1,164,793,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1164793044...
Checkpoint 1164793044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.52784
Policy Entropy: 3.88711
Value Function Loss: 0.02926

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.77630
Value Function Update Magnitude: 0.82131

Collected Steps per Second: 22,687.64240
Overall Steps per Second: 10,651.35354

Timestep Collection Time: 2.20464
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.69593

Cumulative Model Updates: 139,694
Cumulative Timesteps: 1,164,843,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.22663
Policy Entropy: 3.86514
Value Function Loss: 0.02619

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.80132
Value Function Update Magnitude: 0.79755

Collected Steps per Second: 23,301.50143
Overall Steps per Second: 10,987.06768

Timestep Collection Time: 2.14613
Timestep Consumption Time: 2.40541
PPO Batch Consumption Time: 0.27647
Total Iteration Time: 4.55153

Cumulative Model Updates: 139,700
Cumulative Timesteps: 1,164,893,070

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1164893070...
Checkpoint 1164893070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,732.71762
Policy Entropy: 3.84615
Value Function Loss: 0.02365

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06102
Policy Update Magnitude: 0.73626
Value Function Update Magnitude: 0.76206

Collected Steps per Second: 22,340.61710
Overall Steps per Second: 10,832.56310

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.37868
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.61774

Cumulative Model Updates: 139,706
Cumulative Timesteps: 1,164,943,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,640.34799
Policy Entropy: 3.82358
Value Function Loss: 0.02255

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.66453
Value Function Update Magnitude: 0.69983

Collected Steps per Second: 22,600.83127
Overall Steps per Second: 10,839.50658

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.40054
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.61294

Cumulative Model Updates: 139,712
Cumulative Timesteps: 1,164,993,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1164993094...
Checkpoint 1164993094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,904.92278
Policy Entropy: 3.79860
Value Function Loss: 0.02124

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.61155
Value Function Update Magnitude: 0.70993

Collected Steps per Second: 22,113.18329
Overall Steps per Second: 10,881.99214

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.33487
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.59714

Cumulative Model Updates: 139,718
Cumulative Timesteps: 1,165,043,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,292.86087
Policy Entropy: 3.79963
Value Function Loss: 0.02143

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.19092
Policy Update Magnitude: 0.46607
Value Function Update Magnitude: 0.68372

Collected Steps per Second: 22,423.94450
Overall Steps per Second: 10,926.27000

Timestep Collection Time: 2.23119
Timestep Consumption Time: 2.34787
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.57906

Cumulative Model Updates: 139,724
Cumulative Timesteps: 1,165,093,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1165093152...
Checkpoint 1165093152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,140.02483
Policy Entropy: 3.78954
Value Function Loss: 0.02108

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17662
Policy Update Magnitude: 0.37527
Value Function Update Magnitude: 0.62619

Collected Steps per Second: 21,968.57224
Overall Steps per Second: 10,742.05278

Timestep Collection Time: 2.27671
Timestep Consumption Time: 2.37939
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.65609

Cumulative Model Updates: 139,730
Cumulative Timesteps: 1,165,143,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,435.08561
Policy Entropy: 3.78701
Value Function Loss: 0.02093

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17767
Policy Update Magnitude: 0.36355
Value Function Update Magnitude: 0.53864

Collected Steps per Second: 23,214.62258
Overall Steps per Second: 10,809.14819

Timestep Collection Time: 2.15381
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.62571

Cumulative Model Updates: 139,736
Cumulative Timesteps: 1,165,193,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1165193168...
Checkpoint 1165193168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,975.04714
Policy Entropy: 3.80706
Value Function Loss: 0.01740

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.33541
Value Function Update Magnitude: 0.45113

Collected Steps per Second: 22,938.74349
Overall Steps per Second: 10,768.66121

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.46378
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.64385

Cumulative Model Updates: 139,742
Cumulative Timesteps: 1,165,243,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,150.10747
Policy Entropy: 3.81024
Value Function Loss: 0.01624

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15863
Policy Update Magnitude: 0.33198
Value Function Update Magnitude: 0.48152

Collected Steps per Second: 23,131.27189
Overall Steps per Second: 10,808.66241

Timestep Collection Time: 2.16253
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.62795

Cumulative Model Updates: 139,748
Cumulative Timesteps: 1,165,293,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1165293198...
Checkpoint 1165293198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,517.72850
Policy Entropy: 3.82217
Value Function Loss: 0.01729

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15750
Policy Update Magnitude: 0.39132
Value Function Update Magnitude: 0.65869

Collected Steps per Second: 23,018.91893
Overall Steps per Second: 10,734.96938

Timestep Collection Time: 2.17291
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.65935

Cumulative Model Updates: 139,754
Cumulative Timesteps: 1,165,343,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,781.87059
Policy Entropy: 3.80313
Value Function Loss: 0.01784

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.16519
Policy Update Magnitude: 0.41897
Value Function Update Magnitude: 0.77534

Collected Steps per Second: 23,344.85156
Overall Steps per Second: 10,781.35413

Timestep Collection Time: 2.14231
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.63875

Cumulative Model Updates: 139,760
Cumulative Timesteps: 1,165,393,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1165393228...
Checkpoint 1165393228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,375.06164
Policy Entropy: 3.77700
Value Function Loss: 0.01909

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.43427
Value Function Update Magnitude: 0.82537

Collected Steps per Second: 22,717.97381
Overall Steps per Second: 10,613.42373

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71309

Cumulative Model Updates: 139,766
Cumulative Timesteps: 1,165,443,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,531.98018
Policy Entropy: 3.76752
Value Function Loss: 0.01853

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15771
Policy Update Magnitude: 0.42037
Value Function Update Magnitude: 0.83042

Collected Steps per Second: 23,256.16863
Overall Steps per Second: 10,935.90735

Timestep Collection Time: 2.15066
Timestep Consumption Time: 2.42290
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.57356

Cumulative Model Updates: 139,772
Cumulative Timesteps: 1,165,493,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1165493266...
Checkpoint 1165493266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,521.26231
Policy Entropy: 3.76783
Value Function Loss: 0.01901

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.16112
Policy Update Magnitude: 0.43194
Value Function Update Magnitude: 0.84344

Collected Steps per Second: 22,924.75334
Overall Steps per Second: 10,705.33293

Timestep Collection Time: 2.18157
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.67169

Cumulative Model Updates: 139,778
Cumulative Timesteps: 1,165,543,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,774.87775
Policy Entropy: 3.77163
Value Function Loss: 0.01888

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.44074
Value Function Update Magnitude: 0.79432

Collected Steps per Second: 23,245.41938
Overall Steps per Second: 10,877.53520

Timestep Collection Time: 2.15139
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.59755

Cumulative Model Updates: 139,784
Cumulative Timesteps: 1,165,593,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1165593288...
Checkpoint 1165593288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,929.92126
Policy Entropy: 3.77110
Value Function Loss: 0.02011

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.43156
Value Function Update Magnitude: 0.70600

Collected Steps per Second: 22,725.52617
Overall Steps per Second: 10,650.67043

Timestep Collection Time: 2.20043
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.69510

Cumulative Model Updates: 139,790
Cumulative Timesteps: 1,165,643,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.79043
Policy Entropy: 3.76231
Value Function Loss: 0.01854

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14799
Policy Update Magnitude: 0.43416
Value Function Update Magnitude: 0.61397

Collected Steps per Second: 22,861.97386
Overall Steps per Second: 10,837.89386

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.61400

Cumulative Model Updates: 139,796
Cumulative Timesteps: 1,165,693,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1165693300...
Checkpoint 1165693300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.79043
Policy Entropy: 3.75084
Value Function Loss: 0.02087

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14831
Policy Update Magnitude: 0.39264
Value Function Update Magnitude: 0.52659

Collected Steps per Second: 22,768.64729
Overall Steps per Second: 10,682.21463

Timestep Collection Time: 2.19618
Timestep Consumption Time: 2.48487
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.68105

Cumulative Model Updates: 139,802
Cumulative Timesteps: 1,165,743,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,761.09952
Policy Entropy: 3.76267
Value Function Loss: 0.01967

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.37448
Value Function Update Magnitude: 0.40498

Collected Steps per Second: 22,774.21807
Overall Steps per Second: 10,816.28533

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.62506

Cumulative Model Updates: 139,808
Cumulative Timesteps: 1,165,793,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1165793330...
Checkpoint 1165793330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,262.51145
Policy Entropy: 3.74639
Value Function Loss: 0.02532

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.38817
Value Function Update Magnitude: 0.52429

Collected Steps per Second: 22,618.08623
Overall Steps per Second: 10,716.92159

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.66571

Cumulative Model Updates: 139,814
Cumulative Timesteps: 1,165,843,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,518.51637
Policy Entropy: 3.76638
Value Function Loss: 0.02637

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.56489

Collected Steps per Second: 23,098.93425
Overall Steps per Second: 10,957.32902

Timestep Collection Time: 2.16478
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.56352

Cumulative Model Updates: 139,820
Cumulative Timesteps: 1,165,893,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1165893336...
Checkpoint 1165893336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,929.41384
Policy Entropy: 3.74544
Value Function Loss: 0.02778

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.50273
Value Function Update Magnitude: 0.55344

Collected Steps per Second: 22,847.88150
Overall Steps per Second: 10,736.27575

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.65711

Cumulative Model Updates: 139,826
Cumulative Timesteps: 1,165,943,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,362.18753
Policy Entropy: 3.75575
Value Function Loss: 0.02322

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.51404

Collected Steps per Second: 22,917.12698
Overall Steps per Second: 10,771.47096

Timestep Collection Time: 2.18195
Timestep Consumption Time: 2.46031
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.64226

Cumulative Model Updates: 139,832
Cumulative Timesteps: 1,165,993,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1165993340...
Checkpoint 1165993340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,053.93021
Policy Entropy: 3.74255
Value Function Loss: 0.02278

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.47776
Value Function Update Magnitude: 0.57549

Collected Steps per Second: 22,813.02577
Overall Steps per Second: 10,684.24973

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.48905
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68166

Cumulative Model Updates: 139,838
Cumulative Timesteps: 1,166,043,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,928.24270
Policy Entropy: 3.77272
Value Function Loss: 0.02231

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.47973
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 23,107.10309
Overall Steps per Second: 10,836.16439

Timestep Collection Time: 2.16384
Timestep Consumption Time: 2.45034
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.61418

Cumulative Model Updates: 139,844
Cumulative Timesteps: 1,166,093,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1166093360...
Checkpoint 1166093360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,014.92387
Policy Entropy: 3.76948
Value Function Loss: 0.02715

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.63066

Collected Steps per Second: 23,010.83111
Overall Steps per Second: 10,741.62116

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.48260
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65609

Cumulative Model Updates: 139,850
Cumulative Timesteps: 1,166,143,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,830.39667
Policy Entropy: 3.77876
Value Function Loss: 0.02801

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.53429
Value Function Update Magnitude: 0.55093

Collected Steps per Second: 23,127.37420
Overall Steps per Second: 10,762.49431

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.64576

Cumulative Model Updates: 139,856
Cumulative Timesteps: 1,166,193,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1166193374...
Checkpoint 1166193374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,883.97516
Policy Entropy: 3.77982
Value Function Loss: 0.02882

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.58220
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 22,519.10301
Overall Steps per Second: 10,673.02248

Timestep Collection Time: 2.22096
Timestep Consumption Time: 2.46506
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68602

Cumulative Model Updates: 139,862
Cumulative Timesteps: 1,166,243,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,201.31112
Policy Entropy: 3.78508
Value Function Loss: 0.02417

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.69149

Collected Steps per Second: 23,147.23541
Overall Steps per Second: 10,963.23972

Timestep Collection Time: 2.16078
Timestep Consumption Time: 2.40138
PPO Batch Consumption Time: 0.27590
Total Iteration Time: 4.56216

Cumulative Model Updates: 139,868
Cumulative Timesteps: 1,166,293,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1166293404...
Checkpoint 1166293404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,343.46560
Policy Entropy: 3.76319
Value Function Loss: 0.02820

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 22,289.46636
Overall Steps per Second: 10,787.72367

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.39178
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.63508

Cumulative Model Updates: 139,874
Cumulative Timesteps: 1,166,343,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,332.02683
Policy Entropy: 3.76160
Value Function Loss: 0.02797

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.52339

Collected Steps per Second: 22,444.78739
Overall Steps per Second: 10,766.21901

Timestep Collection Time: 2.22965
Timestep Consumption Time: 2.41859
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.64824

Cumulative Model Updates: 139,880
Cumulative Timesteps: 1,166,393,450

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1166393450...
Checkpoint 1166393450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,094.09661
Policy Entropy: 3.77189
Value Function Loss: 0.02858

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.53366
Value Function Update Magnitude: 0.66482

Collected Steps per Second: 22,069.60607
Overall Steps per Second: 10,699.32670

Timestep Collection Time: 2.26701
Timestep Consumption Time: 2.40917
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67618

Cumulative Model Updates: 139,886
Cumulative Timesteps: 1,166,443,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.06382
Policy Entropy: 3.78842
Value Function Loss: 0.02658

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 22,457.34622
Overall Steps per Second: 10,818.67620

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.39529
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.62182

Cumulative Model Updates: 139,892
Cumulative Timesteps: 1,166,493,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1166493484...
Checkpoint 1166493484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.79167
Policy Entropy: 3.80843
Value Function Loss: 0.02341

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.49179
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 22,043.97518
Overall Steps per Second: 10,697.99794

Timestep Collection Time: 2.26837
Timestep Consumption Time: 2.40577
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.67415

Cumulative Model Updates: 139,898
Cumulative Timesteps: 1,166,543,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.63342
Policy Entropy: 3.80038
Value Function Loss: 0.01989

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.44185
Value Function Update Magnitude: 0.48760

Collected Steps per Second: 22,596.95401
Overall Steps per Second: 10,821.93044

Timestep Collection Time: 2.21384
Timestep Consumption Time: 2.40881
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.62265

Cumulative Model Updates: 139,904
Cumulative Timesteps: 1,166,593,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1166593514...
Checkpoint 1166593514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82806
Policy Entropy: 3.78989
Value Function Loss: 0.01607

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13759
Policy Update Magnitude: 0.36927
Value Function Update Magnitude: 0.43625

Collected Steps per Second: 22,734.96337
Overall Steps per Second: 10,739.48043

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.65758

Cumulative Model Updates: 139,910
Cumulative Timesteps: 1,166,643,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.39109
Policy Entropy: 3.76199
Value Function Loss: 0.01426

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.31318
Value Function Update Magnitude: 0.40142

Collected Steps per Second: 23,235.81922
Overall Steps per Second: 10,836.65109

Timestep Collection Time: 2.15219
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.61471

Cumulative Model Updates: 139,916
Cumulative Timesteps: 1,166,693,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1166693542...
Checkpoint 1166693542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.05098
Policy Entropy: 3.76874
Value Function Loss: 0.01434

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.29143
Value Function Update Magnitude: 0.34130

Collected Steps per Second: 22,668.67320
Overall Steps per Second: 10,641.79613

Timestep Collection Time: 2.20666
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.70052

Cumulative Model Updates: 139,922
Cumulative Timesteps: 1,166,743,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.46419
Policy Entropy: 3.76603
Value Function Loss: 0.01572

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13567
Policy Update Magnitude: 0.32906
Value Function Update Magnitude: 0.34292

Collected Steps per Second: 23,196.23725
Overall Steps per Second: 10,942.12391

Timestep Collection Time: 2.15630
Timestep Consumption Time: 2.41484
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.57114

Cumulative Model Updates: 139,928
Cumulative Timesteps: 1,166,793,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1166793582...
Checkpoint 1166793582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,639.65761
Policy Entropy: 3.77745
Value Function Loss: 0.01497

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.36000
Value Function Update Magnitude: 0.39389

Collected Steps per Second: 22,715.12160
Overall Steps per Second: 10,653.28638

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.69395

Cumulative Model Updates: 139,934
Cumulative Timesteps: 1,166,843,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,639.65761
Policy Entropy: 3.75096
Value Function Loss: 0.01469

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.35183
Value Function Update Magnitude: 0.39451

Collected Steps per Second: 23,088.25624
Overall Steps per Second: 10,938.60415

Timestep Collection Time: 2.16621
Timestep Consumption Time: 2.40604
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.57225

Cumulative Model Updates: 139,940
Cumulative Timesteps: 1,166,893,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1166893602...
Checkpoint 1166893602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,639.65761
Policy Entropy: 3.74378
Value Function Loss: 0.01422

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.32851
Value Function Update Magnitude: 0.33600

Collected Steps per Second: 23,015.60997
Overall Steps per Second: 10,757.67262

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.64952

Cumulative Model Updates: 139,946
Cumulative Timesteps: 1,166,943,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,350.88262
Policy Entropy: 3.73922
Value Function Loss: 0.01469

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.31567
Value Function Update Magnitude: 0.32982

Collected Steps per Second: 23,274.90109
Overall Steps per Second: 10,782.06823

Timestep Collection Time: 2.14841
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.63770

Cumulative Model Updates: 139,952
Cumulative Timesteps: 1,166,993,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1166993624...
Checkpoint 1166993624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,374.46620
Policy Entropy: 3.74251
Value Function Loss: 0.01858

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.33443
Value Function Update Magnitude: 0.32446

Collected Steps per Second: 22,909.57459
Overall Steps per Second: 10,720.01611

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.66697

Cumulative Model Updates: 139,958
Cumulative Timesteps: 1,167,043,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,337.94322
Policy Entropy: 3.73919
Value Function Loss: 0.01827

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.36856
Value Function Update Magnitude: 0.36492

Collected Steps per Second: 23,129.17625
Overall Steps per Second: 10,777.90065

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.63949

Cumulative Model Updates: 139,964
Cumulative Timesteps: 1,167,093,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1167093658...
Checkpoint 1167093658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,717.71662
Policy Entropy: 3.73316
Value Function Loss: 0.02011

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13865
Policy Update Magnitude: 0.41362
Value Function Update Magnitude: 0.45086

Collected Steps per Second: 22,373.45701
Overall Steps per Second: 10,634.28402

Timestep Collection Time: 2.23568
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.70365

Cumulative Model Updates: 139,970
Cumulative Timesteps: 1,167,143,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,152.47654
Policy Entropy: 3.73595
Value Function Loss: 0.01956

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13828
Policy Update Magnitude: 0.44152
Value Function Update Magnitude: 0.54010

Collected Steps per Second: 22,762.45815
Overall Steps per Second: 10,852.66719

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.41114
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.60827

Cumulative Model Updates: 139,976
Cumulative Timesteps: 1,167,193,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1167193690...
Checkpoint 1167193690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233,152.47654
Policy Entropy: 3.73468
Value Function Loss: 0.01875

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.46152
Value Function Update Magnitude: 0.54867

Collected Steps per Second: 22,759.75836
Overall Steps per Second: 10,680.61352

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68269

Cumulative Model Updates: 139,982
Cumulative Timesteps: 1,167,243,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,152.47654
Policy Entropy: 3.73668
Value Function Loss: 0.01641

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.44366
Value Function Update Magnitude: 0.53424

Collected Steps per Second: 22,869.35016
Overall Steps per Second: 10,884.63202

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.40740
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.59382

Cumulative Model Updates: 139,988
Cumulative Timesteps: 1,167,293,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1167293706...
Checkpoint 1167293706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233,152.47654
Policy Entropy: 3.74623
Value Function Loss: 0.01459

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.39079
Value Function Update Magnitude: 0.43402

Collected Steps per Second: 22,386.99049
Overall Steps per Second: 10,794.34952

Timestep Collection Time: 2.23487
Timestep Consumption Time: 2.40015
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.63502

Cumulative Model Updates: 139,994
Cumulative Timesteps: 1,167,343,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,152.47654
Policy Entropy: 3.74857
Value Function Loss: 0.01322

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.33590
Value Function Update Magnitude: 0.30001

Collected Steps per Second: 22,356.48410
Overall Steps per Second: 10,785.73483

Timestep Collection Time: 2.23720
Timestep Consumption Time: 2.40003
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.63724

Cumulative Model Updates: 140,000
Cumulative Timesteps: 1,167,393,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1167393754...
Checkpoint 1167393754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,378.75390
Policy Entropy: 3.75437
Value Function Loss: 0.01622

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.33165
Value Function Update Magnitude: 0.27375

Collected Steps per Second: 22,268.65146
Overall Steps per Second: 10,657.09821

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.44845
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.69565

Cumulative Model Updates: 140,006
Cumulative Timesteps: 1,167,443,796

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,453.44079
Policy Entropy: 3.75772
Value Function Loss: 0.01672

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.37412
Value Function Update Magnitude: 0.36489

Collected Steps per Second: 22,687.75368
Overall Steps per Second: 10,879.06905

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.39339
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.59837

Cumulative Model Updates: 140,012
Cumulative Timesteps: 1,167,493,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1167493822...
Checkpoint 1167493822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411,898.26702
Policy Entropy: 3.75713
Value Function Loss: 0.02103

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.41419
Value Function Update Magnitude: 0.38271

Collected Steps per Second: 22,982.95657
Overall Steps per Second: 10,813.48987

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.44950
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.62607

Cumulative Model Updates: 140,018
Cumulative Timesteps: 1,167,543,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,512.94057
Policy Entropy: 3.77130
Value Function Loss: 0.01940

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.45642
Value Function Update Magnitude: 0.39910

Collected Steps per Second: 22,897.23636
Overall Steps per Second: 10,759.77756

Timestep Collection Time: 2.18489
Timestep Consumption Time: 2.46465
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.64954

Cumulative Model Updates: 140,024
Cumulative Timesteps: 1,167,593,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1167593874...
Checkpoint 1167593874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,585.59327
Policy Entropy: 3.76656
Value Function Loss: 0.02388

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.50922
Value Function Update Magnitude: 0.44779

Collected Steps per Second: 22,690.43863
Overall Steps per Second: 10,741.62971

Timestep Collection Time: 2.20516
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.65814

Cumulative Model Updates: 140,030
Cumulative Timesteps: 1,167,643,910

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,958.90064
Policy Entropy: 3.77179
Value Function Loss: 0.02363

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.52315
Value Function Update Magnitude: 0.47965

Collected Steps per Second: 22,750.61693
Overall Steps per Second: 10,852.48906

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.40950
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.60724

Cumulative Model Updates: 140,036
Cumulative Timesteps: 1,167,693,910

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1167693910...
Checkpoint 1167693910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,710.42610
Policy Entropy: 3.75486
Value Function Loss: 0.02602

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.47265

Collected Steps per Second: 22,790.27967
Overall Steps per Second: 10,708.66424

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.67080

Cumulative Model Updates: 140,042
Cumulative Timesteps: 1,167,743,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,677.78250
Policy Entropy: 3.74226
Value Function Loss: 0.02332

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.47000

Collected Steps per Second: 23,120.33575
Overall Steps per Second: 10,775.65710

Timestep Collection Time: 2.16364
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.64232

Cumulative Model Updates: 140,048
Cumulative Timesteps: 1,167,793,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1167793952...
Checkpoint 1167793952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,472.09117
Policy Entropy: 3.73166
Value Function Loss: 0.02573

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.53349
Value Function Update Magnitude: 0.51970

Collected Steps per Second: 22,726.35695
Overall Steps per Second: 10,639.07884

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.70229

Cumulative Model Updates: 140,054
Cumulative Timesteps: 1,167,843,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,472.09117
Policy Entropy: 3.72202
Value Function Loss: 0.02378

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.50005

Collected Steps per Second: 22,807.50691
Overall Steps per Second: 10,865.63131

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.41095
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.60461

Cumulative Model Updates: 140,060
Cumulative Timesteps: 1,167,894,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1167894012...
Checkpoint 1167894012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,480.58821
Policy Entropy: 3.72004
Value Function Loss: 0.02362

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.50104
Value Function Update Magnitude: 0.49694

Collected Steps per Second: 23,125.04505
Overall Steps per Second: 10,747.77479

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.65417

Cumulative Model Updates: 140,066
Cumulative Timesteps: 1,167,944,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,172.09550
Policy Entropy: 3.73500
Value Function Loss: 0.02066

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.46791
Value Function Update Magnitude: 0.44669

Collected Steps per Second: 22,956.75787
Overall Steps per Second: 10,915.36133

Timestep Collection Time: 2.17801
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.58070

Cumulative Model Updates: 140,072
Cumulative Timesteps: 1,167,994,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1167994034...
Checkpoint 1167994034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,128.96495
Policy Entropy: 3.73404
Value Function Loss: 0.02304

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.45034
Value Function Update Magnitude: 0.37129

Collected Steps per Second: 22,083.34926
Overall Steps per Second: 10,720.50516

Timestep Collection Time: 2.26551
Timestep Consumption Time: 2.40125
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66676

Cumulative Model Updates: 140,078
Cumulative Timesteps: 1,168,044,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,256.26031
Policy Entropy: 3.74702
Value Function Loss: 0.01913

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.44637
Value Function Update Magnitude: 0.39012

Collected Steps per Second: 22,179.85451
Overall Steps per Second: 10,812.08167

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.37092
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.62594

Cumulative Model Updates: 140,084
Cumulative Timesteps: 1,168,094,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1168094080...
Checkpoint 1168094080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,379.21722
Policy Entropy: 3.74512
Value Function Loss: 0.02400

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.47129
Value Function Update Magnitude: 0.55060

Collected Steps per Second: 22,149.56420
Overall Steps per Second: 10,748.06502

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.39577
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.65423

Cumulative Model Updates: 140,090
Cumulative Timesteps: 1,168,144,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,902.20422
Policy Entropy: 3.75511
Value Function Loss: 0.02216

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.54716
Value Function Update Magnitude: 0.58798

Collected Steps per Second: 22,519.31670
Overall Steps per Second: 10,746.53083

Timestep Collection Time: 2.22076
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.65359

Cumulative Model Updates: 140,096
Cumulative Timesteps: 1,168,194,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1168194114...
Checkpoint 1168194114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,668.23803
Policy Entropy: 3.75581
Value Function Loss: 0.02229

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.54391
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,799.19418
Overall Steps per Second: 10,773.43700

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.64216

Cumulative Model Updates: 140,102
Cumulative Timesteps: 1,168,244,126

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,410.27660
Policy Entropy: 3.76409
Value Function Loss: 0.01985

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.51492
Value Function Update Magnitude: 0.57163

Collected Steps per Second: 22,699.71488
Overall Steps per Second: 10,804.46054

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.62938

Cumulative Model Updates: 140,108
Cumulative Timesteps: 1,168,294,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1168294144...
Checkpoint 1168294144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.36710
Policy Entropy: 3.75597
Value Function Loss: 0.02216

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.58117
Value Function Update Magnitude: 0.49929

Collected Steps per Second: 22,940.11302
Overall Steps per Second: 10,725.12632

Timestep Collection Time: 2.18020
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.66326

Cumulative Model Updates: 140,114
Cumulative Timesteps: 1,168,344,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.36710
Policy Entropy: 3.73407
Value Function Loss: 0.01928

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.18993
Policy Update Magnitude: 0.57962
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 22,933.93563
Overall Steps per Second: 10,808.16264

Timestep Collection Time: 2.18018
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.62613

Cumulative Model Updates: 140,120
Cumulative Timesteps: 1,168,394,158

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1168394158...
Checkpoint 1168394158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.36710
Policy Entropy: 3.74554
Value Function Loss: 0.01659

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 23,119.36182
Overall Steps per Second: 10,779.42168

Timestep Collection Time: 2.16321
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.63958

Cumulative Model Updates: 140,126
Cumulative Timesteps: 1,168,444,170

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,673.36710
Policy Entropy: 3.75506
Value Function Loss: 0.01473

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.59126
Value Function Update Magnitude: 0.54406

Collected Steps per Second: 22,737.67147
Overall Steps per Second: 10,776.20869

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.64152

Cumulative Model Updates: 140,132
Cumulative Timesteps: 1,168,494,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1168494188...
Checkpoint 1168494188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,789.98018
Policy Entropy: 3.75004
Value Function Loss: 0.01291

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 22,935.80926
Overall Steps per Second: 10,734.34182

Timestep Collection Time: 2.18078
Timestep Consumption Time: 2.47884
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.65962

Cumulative Model Updates: 140,138
Cumulative Timesteps: 1,168,544,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,079.80090
Policy Entropy: 3.74743
Value Function Loss: 0.01350

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.46855
Value Function Update Magnitude: 0.61820

Collected Steps per Second: 22,795.95230
Overall Steps per Second: 10,830.50272

Timestep Collection Time: 2.19451
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.61899

Cumulative Model Updates: 140,144
Cumulative Timesteps: 1,168,594,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1168594232...
Checkpoint 1168594232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,079.80090
Policy Entropy: 3.73562
Value Function Loss: 0.01361

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.40256
Value Function Update Magnitude: 0.50656

Collected Steps per Second: 23,175.36740
Overall Steps per Second: 10,798.19082

Timestep Collection Time: 2.15746
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.63041

Cumulative Model Updates: 140,150
Cumulative Timesteps: 1,168,644,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,079.80090
Policy Entropy: 3.74740
Value Function Loss: 0.01270

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.38855
Value Function Update Magnitude: 0.43896

Collected Steps per Second: 23,024.85088
Overall Steps per Second: 10,710.53242

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.66942

Cumulative Model Updates: 140,156
Cumulative Timesteps: 1,168,694,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1168694244...
Checkpoint 1168694244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310,620.37465
Policy Entropy: 3.74089
Value Function Loss: 0.01301

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.38963
Value Function Update Magnitude: 0.43687

Collected Steps per Second: 23,007.42744
Overall Steps per Second: 10,740.22291

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.65707

Cumulative Model Updates: 140,162
Cumulative Timesteps: 1,168,744,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,719.78184
Policy Entropy: 3.73028
Value Function Loss: 0.01590

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.39030
Value Function Update Magnitude: 0.48579

Collected Steps per Second: 22,932.85477
Overall Steps per Second: 10,792.06826

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.45403
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.63544

Cumulative Model Updates: 140,168
Cumulative Timesteps: 1,168,794,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1168794288...
Checkpoint 1168794288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,648.02308
Policy Entropy: 3.74458
Value Function Loss: 0.01950

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.41690
Value Function Update Magnitude: 0.42871

Collected Steps per Second: 22,987.50283
Overall Steps per Second: 10,757.36181

Timestep Collection Time: 2.17527
Timestep Consumption Time: 2.47308
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.64835

Cumulative Model Updates: 140,174
Cumulative Timesteps: 1,168,844,292

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,648.02308
Policy Entropy: 3.74178
Value Function Loss: 0.02010

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.45976
Value Function Update Magnitude: 0.40842

Collected Steps per Second: 22,864.33506
Overall Steps per Second: 10,816.33030

Timestep Collection Time: 2.18681
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.62264

Cumulative Model Updates: 140,180
Cumulative Timesteps: 1,168,894,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1168894292...
Checkpoint 1168894292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,648.02308
Policy Entropy: 3.75251
Value Function Loss: 0.01860

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.45983
Value Function Update Magnitude: 0.40130

Collected Steps per Second: 23,110.42860
Overall Steps per Second: 10,807.06929

Timestep Collection Time: 2.16430
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.62827

Cumulative Model Updates: 140,186
Cumulative Timesteps: 1,168,944,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299,006.50728
Policy Entropy: 3.73583
Value Function Loss: 0.02338

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.46047
Value Function Update Magnitude: 0.32944

Collected Steps per Second: 22,067.87673
Overall Steps per Second: 10,747.79166

Timestep Collection Time: 2.26610
Timestep Consumption Time: 2.38676
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.65286

Cumulative Model Updates: 140,192
Cumulative Timesteps: 1,168,994,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1168994318...
Checkpoint 1168994318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,914.34780
Policy Entropy: 3.74145
Value Function Loss: 0.02124

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.47106
Value Function Update Magnitude: 0.36089

Collected Steps per Second: 22,302.72019
Overall Steps per Second: 10,803.86370

Timestep Collection Time: 2.24296
Timestep Consumption Time: 2.38724
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.63020

Cumulative Model Updates: 140,198
Cumulative Timesteps: 1,169,044,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,622.39971
Policy Entropy: 3.73858
Value Function Loss: 0.02630

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.52858
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,097.04969
Overall Steps per Second: 10,728.21013

Timestep Collection Time: 2.26356
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.66229

Cumulative Model Updates: 140,204
Cumulative Timesteps: 1,169,094,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1169094360...
Checkpoint 1169094360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,848.13536
Policy Entropy: 3.73358
Value Function Loss: 0.02475

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.60508
Value Function Update Magnitude: 0.65503

Collected Steps per Second: 22,392.58554
Overall Steps per Second: 10,637.11943

Timestep Collection Time: 2.23378
Timestep Consumption Time: 2.46863
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70240

Cumulative Model Updates: 140,210
Cumulative Timesteps: 1,169,144,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,241.42901
Policy Entropy: 3.71321
Value Function Loss: 0.03148

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.60396
Value Function Update Magnitude: 0.64216

Collected Steps per Second: 22,822.81499
Overall Steps per Second: 10,874.47446

Timestep Collection Time: 2.19210
Timestep Consumption Time: 2.40858
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.60068

Cumulative Model Updates: 140,216
Cumulative Timesteps: 1,169,194,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1169194410...
Checkpoint 1169194410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,905.50032
Policy Entropy: 3.72095
Value Function Loss: 0.02696

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.65021

Collected Steps per Second: 22,995.46927
Overall Steps per Second: 10,817.84182

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.44863
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.62384

Cumulative Model Updates: 140,222
Cumulative Timesteps: 1,169,244,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,247.97275
Policy Entropy: 3.72425
Value Function Loss: 0.02773

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.55918
Value Function Update Magnitude: 0.59298

Collected Steps per Second: 22,886.37563
Overall Steps per Second: 10,758.11756

Timestep Collection Time: 2.18549
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.64933

Cumulative Model Updates: 140,228
Cumulative Timesteps: 1,169,294,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1169294448...
Checkpoint 1169294448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,142.34798
Policy Entropy: 3.73902
Value Function Loss: 0.01930

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.51773
Value Function Update Magnitude: 0.56519

Collected Steps per Second: 23,009.06157
Overall Steps per Second: 10,768.51859

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.47011
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.64316

Cumulative Model Updates: 140,234
Cumulative Timesteps: 1,169,344,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,142.34798
Policy Entropy: 3.72954
Value Function Loss: 0.01888

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.47388
Value Function Update Magnitude: 0.67748

Collected Steps per Second: 23,120.42658
Overall Steps per Second: 10,773.00743

Timestep Collection Time: 2.16363
Timestep Consumption Time: 2.47983
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.64346

Cumulative Model Updates: 140,240
Cumulative Timesteps: 1,169,394,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1169394472...
Checkpoint 1169394472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,142.34798
Policy Entropy: 3.72602
Value Function Loss: 0.01875

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.45878
Value Function Update Magnitude: 0.73183

Collected Steps per Second: 22,960.74560
Overall Steps per Second: 10,731.49077

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.66161

Cumulative Model Updates: 140,246
Cumulative Timesteps: 1,169,444,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,591.39525
Policy Entropy: 3.73932
Value Function Loss: 0.01887

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.48067
Value Function Update Magnitude: 0.73232

Collected Steps per Second: 23,045.83567
Overall Steps per Second: 10,785.15999

Timestep Collection Time: 2.16994
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.63674

Cumulative Model Updates: 140,252
Cumulative Timesteps: 1,169,494,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1169494506...
Checkpoint 1169494506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,514.06934
Policy Entropy: 3.74016
Value Function Loss: 0.01709

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.46007
Value Function Update Magnitude: 0.66188

Collected Steps per Second: 23,138.27768
Overall Steps per Second: 10,832.50524

Timestep Collection Time: 2.16109
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.61611

Cumulative Model Updates: 140,258
Cumulative Timesteps: 1,169,544,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,425.24681
Policy Entropy: 3.75353
Value Function Loss: 0.01619

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.41461
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 22,556.27668
Overall Steps per Second: 10,791.28268

Timestep Collection Time: 2.21694
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.63393

Cumulative Model Updates: 140,264
Cumulative Timesteps: 1,169,594,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1169594516...
Checkpoint 1169594516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,394.14793
Policy Entropy: 3.73134
Value Function Loss: 0.01548

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14825
Policy Update Magnitude: 0.40527
Value Function Update Magnitude: 0.57029

Collected Steps per Second: 22,228.43087
Overall Steps per Second: 10,781.06026

Timestep Collection Time: 2.24955
Timestep Consumption Time: 2.38858
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.63813

Cumulative Model Updates: 140,270
Cumulative Timesteps: 1,169,644,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,432.92659
Policy Entropy: 3.75340
Value Function Loss: 0.01564

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.40692
Value Function Update Magnitude: 0.56843

Collected Steps per Second: 21,883.11457
Overall Steps per Second: 10,689.16467

Timestep Collection Time: 2.28505
Timestep Consumption Time: 2.39296
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.67801

Cumulative Model Updates: 140,276
Cumulative Timesteps: 1,169,694,524

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1169694524...
Checkpoint 1169694524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265,215.17814
Policy Entropy: 3.73869
Value Function Loss: 0.01736

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.45972
Value Function Update Magnitude: 0.63656

Collected Steps per Second: 22,653.31671
Overall Steps per Second: 10,673.59774

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.68614

Cumulative Model Updates: 140,282
Cumulative Timesteps: 1,169,744,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,358.66860
Policy Entropy: 3.75443
Value Function Loss: 0.01797

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.52001
Value Function Update Magnitude: 0.74897

Collected Steps per Second: 23,199.46199
Overall Steps per Second: 10,895.41165

Timestep Collection Time: 2.15626
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.59129

Cumulative Model Updates: 140,288
Cumulative Timesteps: 1,169,794,566

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1169794566...
Checkpoint 1169794566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,631.68676
Policy Entropy: 3.75389
Value Function Loss: 0.01793

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.52280
Value Function Update Magnitude: 0.74792

Collected Steps per Second: 23,112.97891
Overall Steps per Second: 10,768.24051

Timestep Collection Time: 2.16355
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.64384

Cumulative Model Updates: 140,294
Cumulative Timesteps: 1,169,844,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,631.68676
Policy Entropy: 3.74250
Value Function Loss: 0.01757

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.49053
Value Function Update Magnitude: 0.66182

Collected Steps per Second: 22,555.38334
Overall Steps per Second: 10,821.10090

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.40480
PPO Batch Consumption Time: 0.27540
Total Iteration Time: 4.62245

Cumulative Model Updates: 140,300
Cumulative Timesteps: 1,169,894,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1169894592...
Checkpoint 1169894592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,631.68676
Policy Entropy: 3.73909
Value Function Loss: 0.01496

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.44188
Value Function Update Magnitude: 0.59208

Collected Steps per Second: 22,991.75619
Overall Steps per Second: 10,775.23018

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.64194

Cumulative Model Updates: 140,306
Cumulative Timesteps: 1,169,944,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416,631.68676
Policy Entropy: 3.71397
Value Function Loss: 0.01526

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.40132
Value Function Update Magnitude: 0.50080

Collected Steps per Second: 22,488.61373
Overall Steps per Second: 10,711.97637

Timestep Collection Time: 2.22424
Timestep Consumption Time: 2.44530
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.66954

Cumulative Model Updates: 140,312
Cumulative Timesteps: 1,169,994,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1169994630...
Checkpoint 1169994630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416,631.68676
Policy Entropy: 3.73017
Value Function Loss: 0.01608

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.38071
Value Function Update Magnitude: 0.42885

Collected Steps per Second: 23,026.43422
Overall Steps per Second: 10,778.95388

Timestep Collection Time: 2.17203
Timestep Consumption Time: 2.46794
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.63997

Cumulative Model Updates: 140,318
Cumulative Timesteps: 1,170,044,644

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,323.47032
Policy Entropy: 3.73579
Value Function Loss: 0.01833

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.39689
Value Function Update Magnitude: 0.38569

Collected Steps per Second: 22,934.08311
Overall Steps per Second: 10,771.23169

Timestep Collection Time: 2.18042
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.64255

Cumulative Model Updates: 140,324
Cumulative Timesteps: 1,170,094,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1170094650...
Checkpoint 1170094650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,717.09104
Policy Entropy: 3.75417
Value Function Loss: 0.01912

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.42005
Value Function Update Magnitude: 0.43188

Collected Steps per Second: 22,134.99880
Overall Steps per Second: 10,735.43066

Timestep Collection Time: 2.25941
Timestep Consumption Time: 2.39918
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.65859

Cumulative Model Updates: 140,330
Cumulative Timesteps: 1,170,144,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,436.21044
Policy Entropy: 3.74571
Value Function Loss: 0.02015

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.47105
Value Function Update Magnitude: 0.48876

Collected Steps per Second: 22,378.01773
Overall Steps per Second: 10,792.17712

Timestep Collection Time: 2.23577
Timestep Consumption Time: 2.40019
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.63595

Cumulative Model Updates: 140,336
Cumulative Timesteps: 1,170,194,694

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1170194694...
Checkpoint 1170194694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,793.73101
Policy Entropy: 3.74049
Value Function Loss: 0.02056

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.49674
Value Function Update Magnitude: 0.50864

Collected Steps per Second: 22,247.80399
Overall Steps per Second: 10,730.58865

Timestep Collection Time: 2.24804
Timestep Consumption Time: 2.41284
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.66088

Cumulative Model Updates: 140,342
Cumulative Timesteps: 1,170,244,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,589.83987
Policy Entropy: 3.74126
Value Function Loss: 0.02308

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.53330
Value Function Update Magnitude: 0.52617

Collected Steps per Second: 22,191.60017
Overall Steps per Second: 10,747.54240

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.40047
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.65483

Cumulative Model Updates: 140,348
Cumulative Timesteps: 1,170,294,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1170294736...
Checkpoint 1170294736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,589.83987
Policy Entropy: 3.73632
Value Function Loss: 0.02085

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.60395
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 22,719.82230
Overall Steps per Second: 10,716.99714

Timestep Collection Time: 2.20213
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.66847

Cumulative Model Updates: 140,354
Cumulative Timesteps: 1,170,344,768

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,082.70373
Policy Entropy: 3.71408
Value Function Loss: 0.02725

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17248
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.55171

Collected Steps per Second: 22,891.66087
Overall Steps per Second: 10,841.05419

Timestep Collection Time: 2.18420
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.61210

Cumulative Model Updates: 140,360
Cumulative Timesteps: 1,170,394,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1170394768...
Checkpoint 1170394768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,872.07017
Policy Entropy: 3.71181
Value Function Loss: 0.04328

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.19565
Policy Update Magnitude: 0.61904
Value Function Update Magnitude: 0.54618

Collected Steps per Second: 22,663.80785
Overall Steps per Second: 10,705.74093

Timestep Collection Time: 2.20748
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.67319

Cumulative Model Updates: 140,366
Cumulative Timesteps: 1,170,444,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,239.14474
Policy Entropy: 3.71436
Value Function Loss: 0.04322

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.19740
Policy Update Magnitude: 0.70796
Value Function Update Magnitude: 0.52287

Collected Steps per Second: 23,057.96068
Overall Steps per Second: 10,905.16652

Timestep Collection Time: 2.17053
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.58938

Cumulative Model Updates: 140,372
Cumulative Timesteps: 1,170,494,846

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1170494846...
Checkpoint 1170494846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,661.49149
Policy Entropy: 3.73156
Value Function Loss: 0.03461

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.64251
Value Function Update Magnitude: 0.66134

Collected Steps per Second: 22,906.14067
Overall Steps per Second: 10,706.92698

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.67006

Cumulative Model Updates: 140,378
Cumulative Timesteps: 1,170,544,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.74607
Value Function Loss: 0.02455

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.58840
Value Function Update Magnitude: 0.68046

Collected Steps per Second: 23,119.02963
Overall Steps per Second: 10,826.83361

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.61963

Cumulative Model Updates: 140,384
Cumulative Timesteps: 1,170,594,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170594864...
Checkpoint 1170594864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.75293
Value Function Loss: 0.01884

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.53480
Value Function Update Magnitude: 0.64567

Collected Steps per Second: 22,820.37349
Overall Steps per Second: 10,696.58774

Timestep Collection Time: 2.19164
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67570

Cumulative Model Updates: 140,390
Cumulative Timesteps: 1,170,644,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.77069
Value Function Loss: 0.01495

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06595
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.56947

Collected Steps per Second: 22,822.43326
Overall Steps per Second: 10,847.05139

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.41940
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.61084

Cumulative Model Updates: 140,396
Cumulative Timesteps: 1,170,694,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1170694892...
Checkpoint 1170694892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.78168
Value Function Loss: 0.01283

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06253
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.42784

Collected Steps per Second: 23,110.58005
Overall Steps per Second: 10,772.79425

Timestep Collection Time: 2.16490
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.64429

Cumulative Model Updates: 140,402
Cumulative Timesteps: 1,170,744,924

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.76091
Value Function Loss: 0.01215

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.44629
Value Function Update Magnitude: 0.35145

Collected Steps per Second: 22,283.01659
Overall Steps per Second: 10,808.73339

Timestep Collection Time: 2.24458
Timestep Consumption Time: 2.38279
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.62737

Cumulative Model Updates: 140,408
Cumulative Timesteps: 1,170,794,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170794940...
Checkpoint 1170794940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.77575
Value Function Loss: 0.01055

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.42221
Value Function Update Magnitude: 0.42305

Collected Steps per Second: 22,101.76954
Overall Steps per Second: 10,727.67907

Timestep Collection Time: 2.26226
Timestep Consumption Time: 2.39858
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.66084

Cumulative Model Updates: 140,414
Cumulative Timesteps: 1,170,844,940

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,694.60850
Policy Entropy: 3.74506
Value Function Loss: 0.01215

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.43840
Value Function Update Magnitude: 0.39553

Collected Steps per Second: 22,478.63720
Overall Steps per Second: 10,810.44204

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.40130
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.62608

Cumulative Model Updates: 140,420
Cumulative Timesteps: 1,170,894,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1170894950...
Checkpoint 1170894950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101,340.53504
Policy Entropy: 3.75639
Value Function Loss: 0.01845

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.16165
Policy Update Magnitude: 0.43385
Value Function Update Magnitude: 0.40552

Collected Steps per Second: 22,600.62929
Overall Steps per Second: 10,687.49309

Timestep Collection Time: 2.21463
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.68323

Cumulative Model Updates: 140,426
Cumulative Timesteps: 1,170,945,002

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,026.23713
Policy Entropy: 3.74640
Value Function Loss: 0.02209

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.19262
Policy Update Magnitude: 0.52768
Value Function Update Magnitude: 0.42964

Collected Steps per Second: 22,945.05697
Overall Steps per Second: 10,848.23992

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61052

Cumulative Model Updates: 140,432
Cumulative Timesteps: 1,170,995,018

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1170995018...
Checkpoint 1170995018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,849.62711
Policy Entropy: 3.76775
Value Function Loss: 0.02375

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16868
Policy Update Magnitude: 0.60662
Value Function Update Magnitude: 0.44927

Collected Steps per Second: 22,394.84311
Overall Steps per Second: 10,671.34982

Timestep Collection Time: 2.23328
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.68675

Cumulative Model Updates: 140,438
Cumulative Timesteps: 1,171,045,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,244.24678
Policy Entropy: 3.77447
Value Function Loss: 0.01852

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.58538

Collected Steps per Second: 23,065.51852
Overall Steps per Second: 10,926.29184

Timestep Collection Time: 2.16904
Timestep Consumption Time: 2.40983
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.57886

Cumulative Model Updates: 140,444
Cumulative Timesteps: 1,171,095,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1171095062...
Checkpoint 1171095062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.77454
Value Function Loss: 0.01533

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05767
Policy Update Magnitude: 0.62031
Value Function Update Magnitude: 0.68491

Collected Steps per Second: 22,484.37355
Overall Steps per Second: 10,601.59752

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.71684

Cumulative Model Updates: 140,450
Cumulative Timesteps: 1,171,145,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.75981
Value Function Loss: 0.01401

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.66012
Value Function Update Magnitude: 0.65868

Collected Steps per Second: 23,062.15973
Overall Steps per Second: 10,876.32451

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.43142
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60155

Cumulative Model Updates: 140,456
Cumulative Timesteps: 1,171,195,116

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1171195116...
Checkpoint 1171195116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.75425
Value Function Loss: 0.01391

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.69318
Value Function Update Magnitude: 0.65499

Collected Steps per Second: 22,681.43824
Overall Steps per Second: 10,683.46897

Timestep Collection Time: 2.20462
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68050

Cumulative Model Updates: 140,462
Cumulative Timesteps: 1,171,245,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.74964
Value Function Loss: 0.01504

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07020
Policy Update Magnitude: 0.72302
Value Function Update Magnitude: 0.64758

Collected Steps per Second: 23,107.29498
Overall Steps per Second: 10,978.39628

Timestep Collection Time: 2.16442
Timestep Consumption Time: 2.39125
PPO Batch Consumption Time: 0.27559
Total Iteration Time: 4.55567

Cumulative Model Updates: 140,468
Cumulative Timesteps: 1,171,295,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1171295134...
Checkpoint 1171295134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.75047
Value Function Loss: 0.01484

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.66384
Value Function Update Magnitude: 0.55629

Collected Steps per Second: 22,419.54035
Overall Steps per Second: 10,955.73072

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.33512
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.56674

Cumulative Model Updates: 140,474
Cumulative Timesteps: 1,171,345,166

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.76006
Value Function Loss: 0.01418

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17782
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.50970

Collected Steps per Second: 22,301.00661
Overall Steps per Second: 10,897.83516

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.34686
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.58972

Cumulative Model Updates: 140,480
Cumulative Timesteps: 1,171,395,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1171395184...
Checkpoint 1171395184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,425.87995
Policy Entropy: 3.77050
Value Function Loss: 0.01191

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.16397
Policy Update Magnitude: 0.44464
Value Function Update Magnitude: 0.58456

Collected Steps per Second: 21,929.53899
Overall Steps per Second: 10,672.36451

Timestep Collection Time: 2.28076
Timestep Consumption Time: 2.40574
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.68650

Cumulative Model Updates: 140,486
Cumulative Timesteps: 1,171,445,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 514,846.43914
Policy Entropy: 3.72890
Value Function Loss: 0.02236

Mean KL Divergence: 0.03091
SB3 Clip Fraction: 0.31397
Policy Update Magnitude: 0.40583
Value Function Update Magnitude: 0.60763

Collected Steps per Second: 23,040.71135
Overall Steps per Second: 10,941.27810

Timestep Collection Time: 2.17042
Timestep Consumption Time: 2.40016
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.57058

Cumulative Model Updates: 140,492
Cumulative Timesteps: 1,171,495,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1171495208...
Checkpoint 1171495208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,709.88585
Policy Entropy: 3.76361
Value Function Loss: 0.03257

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.19505
Policy Update Magnitude: 0.51521
Value Function Update Magnitude: 0.65952

Collected Steps per Second: 22,220.34196
Overall Steps per Second: 10,657.34791

Timestep Collection Time: 2.25028
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.69179

Cumulative Model Updates: 140,498
Cumulative Timesteps: 1,171,545,210

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,231.78946
Policy Entropy: 3.76944
Value Function Loss: 0.04142

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.15260
Policy Update Magnitude: 0.72691
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 22,318.12150
Overall Steps per Second: 10,668.67702

Timestep Collection Time: 2.24087
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.68774

Cumulative Model Updates: 140,504
Cumulative Timesteps: 1,171,595,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1171595222...
Checkpoint 1171595222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,230.59134
Policy Entropy: 3.81040
Value Function Loss: 0.03524

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.83366
Value Function Update Magnitude: 0.70098

Collected Steps per Second: 22,588.45406
Overall Steps per Second: 10,897.10858

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.37618
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.59094

Cumulative Model Updates: 140,510
Cumulative Timesteps: 1,171,645,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,952.57224
Policy Entropy: 3.79247
Value Function Loss: 0.02772

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.17342
Policy Update Magnitude: 0.78405
Value Function Update Magnitude: 0.65883

Collected Steps per Second: 23,172.13758
Overall Steps per Second: 10,956.41057

Timestep Collection Time: 2.15845
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.56500

Cumulative Model Updates: 140,516
Cumulative Timesteps: 1,171,695,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1171695266...
Checkpoint 1171695266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,762.70681
Policy Entropy: 3.77924
Value Function Loss: 0.02225

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.75057
Value Function Update Magnitude: 0.68129

Collected Steps per Second: 22,695.72190
Overall Steps per Second: 10,666.94058

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68850

Cumulative Model Updates: 140,522
Cumulative Timesteps: 1,171,745,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,216.07227
Policy Entropy: 3.78296
Value Function Loss: 0.01975

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.73656
Value Function Update Magnitude: 0.70957

Collected Steps per Second: 22,954.71847
Overall Steps per Second: 10,874.22281

Timestep Collection Time: 2.17881
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.59932

Cumulative Model Updates: 140,528
Cumulative Timesteps: 1,171,795,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1171795292...
Checkpoint 1171795292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 570,103.53044
Policy Entropy: 3.74801
Value Function Loss: 0.01914

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.69748
Value Function Update Magnitude: 0.73774

Collected Steps per Second: 22,803.79782
Overall Steps per Second: 10,744.38486

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.65639

Cumulative Model Updates: 140,534
Cumulative Timesteps: 1,171,845,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,788.85253
Policy Entropy: 3.77290
Value Function Loss: 0.01643

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.67095
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 23,362.52309
Overall Steps per Second: 10,794.21619

Timestep Collection Time: 2.14018
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.63211

Cumulative Model Updates: 140,540
Cumulative Timesteps: 1,171,895,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1171895322...
Checkpoint 1171895322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,015.46743
Policy Entropy: 3.74804
Value Function Loss: 0.01386

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.59530
Value Function Update Magnitude: 0.59833

Collected Steps per Second: 22,960.46508
Overall Steps per Second: 10,795.03164

Timestep Collection Time: 2.17853
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.63361

Cumulative Model Updates: 140,546
Cumulative Timesteps: 1,171,945,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,015.46743
Policy Entropy: 3.75645
Value Function Loss: 0.01260

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.15311
Policy Update Magnitude: 0.47150
Value Function Update Magnitude: 0.57476

Collected Steps per Second: 22,414.20625
Overall Steps per Second: 10,783.93650

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.40609
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.63708

Cumulative Model Updates: 140,552
Cumulative Timesteps: 1,171,995,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1171995348...
Checkpoint 1171995348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,015.46743
Policy Entropy: 3.73317
Value Function Loss: 0.01333

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.19397
Policy Update Magnitude: 0.40653
Value Function Update Magnitude: 0.53196

Collected Steps per Second: 22,153.88269
Overall Steps per Second: 10,762.09966

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.38909
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.64612

Cumulative Model Updates: 140,558
Cumulative Timesteps: 1,172,045,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,657.21002
Policy Entropy: 3.73564
Value Function Loss: 0.01541

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17312
Policy Update Magnitude: 0.40345
Value Function Update Magnitude: 0.57429

Collected Steps per Second: 22,766.29409
Overall Steps per Second: 10,877.83564

Timestep Collection Time: 2.19693
Timestep Consumption Time: 2.40104
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.59797

Cumulative Model Updates: 140,564
Cumulative Timesteps: 1,172,095,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1172095366...
Checkpoint 1172095366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,310.31999
Policy Entropy: 3.73146
Value Function Loss: 0.02156

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.46484
Value Function Update Magnitude: 0.61335

Collected Steps per Second: 22,165.97172
Overall Steps per Second: 10,622.56176

Timestep Collection Time: 2.25661
Timestep Consumption Time: 2.45223
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.70885

Cumulative Model Updates: 140,570
Cumulative Timesteps: 1,172,145,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,628.24508
Policy Entropy: 3.75682
Value Function Loss: 0.02323

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.74731

Collected Steps per Second: 22,811.10758
Overall Steps per Second: 10,768.67494

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.64477

Cumulative Model Updates: 140,576
Cumulative Timesteps: 1,172,195,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1172195404...
Checkpoint 1172195404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,772.05135
Policy Entropy: 3.76828
Value Function Loss: 0.03000

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.62936
Value Function Update Magnitude: 0.76416

Collected Steps per Second: 22,756.92348
Overall Steps per Second: 10,765.63509

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.64627

Cumulative Model Updates: 140,582
Cumulative Timesteps: 1,172,245,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,547.34846
Policy Entropy: 3.77914
Value Function Loss: 0.03081

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.64160
Value Function Update Magnitude: 0.77627

Collected Steps per Second: 22,852.79395
Overall Steps per Second: 10,797.79369

Timestep Collection Time: 2.18905
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.63298

Cumulative Model Updates: 140,588
Cumulative Timesteps: 1,172,295,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1172295450...
Checkpoint 1172295450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,250.00926
Policy Entropy: 3.77374
Value Function Loss: 0.03555

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.64560
Value Function Update Magnitude: 0.66468

Collected Steps per Second: 22,659.00004
Overall Steps per Second: 10,623.90819

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.70750

Cumulative Model Updates: 140,594
Cumulative Timesteps: 1,172,345,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,850.54980
Policy Entropy: 3.77552
Value Function Loss: 0.03132

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.62836
Value Function Update Magnitude: 0.67965

Collected Steps per Second: 22,667.97385
Overall Steps per Second: 10,813.42527

Timestep Collection Time: 2.20708
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.62666

Cumulative Model Updates: 140,600
Cumulative Timesteps: 1,172,395,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1172395492...
Checkpoint 1172395492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,798.70261
Policy Entropy: 3.76823
Value Function Loss: 0.02882

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.61729
Value Function Update Magnitude: 0.68304

Collected Steps per Second: 22,425.64593
Overall Steps per Second: 10,772.09909

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.41251
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.64255

Cumulative Model Updates: 140,606
Cumulative Timesteps: 1,172,445,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.82834
Policy Entropy: 3.75212
Value Function Loss: 0.02521

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.60448

Collected Steps per Second: 23,158.56122
Overall Steps per Second: 10,876.43744

Timestep Collection Time: 2.15963
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.59838

Cumulative Model Updates: 140,612
Cumulative Timesteps: 1,172,495,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1172495516...
Checkpoint 1172495516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,266.08557
Policy Entropy: 3.75109
Value Function Loss: 0.02459

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.50481
Value Function Update Magnitude: 0.52817

Collected Steps per Second: 22,331.16648
Overall Steps per Second: 10,636.02996

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.70345

Cumulative Model Updates: 140,618
Cumulative Timesteps: 1,172,545,542

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,169.50060
Policy Entropy: 3.74635
Value Function Loss: 0.02440

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.68025

Collected Steps per Second: 23,204.95811
Overall Steps per Second: 10,885.34131

Timestep Collection Time: 2.15566
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.59535

Cumulative Model Updates: 140,624
Cumulative Timesteps: 1,172,595,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1172595564...
Checkpoint 1172595564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,000.91350
Policy Entropy: 3.75026
Value Function Loss: 0.02666

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.78243

Collected Steps per Second: 22,928.06604
Overall Steps per Second: 10,712.64819

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.48893
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.67167

Cumulative Model Updates: 140,630
Cumulative Timesteps: 1,172,645,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,282.50757
Policy Entropy: 3.74857
Value Function Loss: 0.02613

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.59702
Value Function Update Magnitude: 0.82543

Collected Steps per Second: 23,158.01700
Overall Steps per Second: 10,876.78961

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.59750

Cumulative Model Updates: 140,636
Cumulative Timesteps: 1,172,695,616

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1172695616...
Checkpoint 1172695616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,891.80298
Policy Entropy: 3.73718
Value Function Loss: 0.02716

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.58160
Value Function Update Magnitude: 0.78265

Collected Steps per Second: 22,002.07056
Overall Steps per Second: 10,684.55838

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.40849
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.68227

Cumulative Model Updates: 140,642
Cumulative Timesteps: 1,172,745,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,897.68976
Policy Entropy: 3.73727
Value Function Loss: 0.02591

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.55474

Collected Steps per Second: 22,483.76562
Overall Steps per Second: 10,843.48579

Timestep Collection Time: 2.22454
Timestep Consumption Time: 2.38800
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.61254

Cumulative Model Updates: 140,648
Cumulative Timesteps: 1,172,795,660

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1172795660...
Checkpoint 1172795660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.74538
Value Function Loss: 0.02242

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.51409
Value Function Update Magnitude: 0.55211

Collected Steps per Second: 21,810.80707
Overall Steps per Second: 10,635.49597

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.41015
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.70387

Cumulative Model Updates: 140,654
Cumulative Timesteps: 1,172,845,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.74403
Value Function Loss: 0.01787

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.46555
Value Function Update Magnitude: 0.56822

Collected Steps per Second: 22,462.92089
Overall Steps per Second: 10,812.50106

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.39973
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.62687

Cumulative Model Updates: 140,660
Cumulative Timesteps: 1,172,895,716

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1172895716...
Checkpoint 1172895716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.73558
Value Function Loss: 0.01578

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.40613
Value Function Update Magnitude: 0.42878

Collected Steps per Second: 22,205.80571
Overall Steps per Second: 10,795.16659

Timestep Collection Time: 2.25220
Timestep Consumption Time: 2.38061
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.63281

Cumulative Model Updates: 140,666
Cumulative Timesteps: 1,172,945,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.71577
Value Function Loss: 0.01470

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.41056
Value Function Update Magnitude: 0.42278

Collected Steps per Second: 23,175.65144
Overall Steps per Second: 10,852.60899

Timestep Collection Time: 2.15942
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.61143

Cumulative Model Updates: 140,672
Cumulative Timesteps: 1,172,995,774

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1172995774...
Checkpoint 1172995774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.72776
Value Function Loss: 0.01374

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.43376
Value Function Update Magnitude: 0.52550

Collected Steps per Second: 22,847.42837
Overall Steps per Second: 10,686.91003

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.49099
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.68012

Cumulative Model Updates: 140,678
Cumulative Timesteps: 1,173,045,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.56201
Policy Entropy: 3.73084
Value Function Loss: 0.01549

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.45852
Value Function Update Magnitude: 0.57494

Collected Steps per Second: 23,326.02656
Overall Steps per Second: 10,893.40368

Timestep Collection Time: 2.14481
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.59269

Cumulative Model Updates: 140,684
Cumulative Timesteps: 1,173,095,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1173095820...
Checkpoint 1173095820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,880.21329
Policy Entropy: 3.74071
Value Function Loss: 0.01590

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.49630
Value Function Update Magnitude: 0.58179

Collected Steps per Second: 22,763.34438
Overall Steps per Second: 10,673.92667

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68525

Cumulative Model Updates: 140,690
Cumulative Timesteps: 1,173,145,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,970.30301
Policy Entropy: 3.72011
Value Function Loss: 0.02030

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.49931
Value Function Update Magnitude: 0.54958

Collected Steps per Second: 23,307.85169
Overall Steps per Second: 10,836.96955

Timestep Collection Time: 2.14571
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.61494

Cumulative Model Updates: 140,696
Cumulative Timesteps: 1,173,195,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1173195842...
Checkpoint 1173195842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,970.30301
Policy Entropy: 3.71859
Value Function Loss: 0.01864

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.50287
Value Function Update Magnitude: 0.52888

Collected Steps per Second: 22,990.47226
Overall Steps per Second: 10,712.44529

Timestep Collection Time: 2.17551
Timestep Consumption Time: 2.49345
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.66896

Cumulative Model Updates: 140,702
Cumulative Timesteps: 1,173,245,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,970.30301
Policy Entropy: 3.71361
Value Function Loss: 0.02029

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.46147
Value Function Update Magnitude: 0.43811

Collected Steps per Second: 22,817.25275
Overall Steps per Second: 10,887.41440

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.40171
PPO Batch Consumption Time: 0.27558
Total Iteration Time: 4.59356

Cumulative Model Updates: 140,708
Cumulative Timesteps: 1,173,295,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1173295870...
Checkpoint 1173295870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335,535.48902
Policy Entropy: 3.72140
Value Function Loss: 0.02277

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.47401
Value Function Update Magnitude: 0.34546

Collected Steps per Second: 22,717.93254
Overall Steps per Second: 10,693.21774

Timestep Collection Time: 2.20187
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67792

Cumulative Model Updates: 140,714
Cumulative Timesteps: 1,173,345,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,535.48902
Policy Entropy: 3.72070
Value Function Loss: 0.02132

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.56558

Collected Steps per Second: 23,161.81772
Overall Steps per Second: 10,815.02949

Timestep Collection Time: 2.16028
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.62652

Cumulative Model Updates: 140,720
Cumulative Timesteps: 1,173,395,928

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1173395928...
Checkpoint 1173395928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,763.17643
Policy Entropy: 3.71465
Value Function Loss: 0.02495

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.59370
Value Function Update Magnitude: 0.59675

Collected Steps per Second: 23,040.78678
Overall Steps per Second: 10,774.48215

Timestep Collection Time: 2.17059
Timestep Consumption Time: 2.47112
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.64171

Cumulative Model Updates: 140,726
Cumulative Timesteps: 1,173,445,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,876.83906
Policy Entropy: 3.72612
Value Function Loss: 0.02184

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.62137
Value Function Update Magnitude: 0.61149

Collected Steps per Second: 23,119.82717
Overall Steps per Second: 10,777.99821

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.64149

Cumulative Model Updates: 140,732
Cumulative Timesteps: 1,173,495,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1173495966...
Checkpoint 1173495966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,921.13872
Policy Entropy: 3.72619
Value Function Loss: 0.02822

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.62998
Value Function Update Magnitude: 0.67735

Collected Steps per Second: 22,035.48606
Overall Steps per Second: 10,674.82712

Timestep Collection Time: 2.26970
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68523

Cumulative Model Updates: 140,738
Cumulative Timesteps: 1,173,545,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,169.92381
Policy Entropy: 3.74478
Value Function Loss: 0.02587

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.63050
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 22,162.50881
Overall Steps per Second: 10,883.59035

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.33829
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.59462

Cumulative Model Updates: 140,744
Cumulative Timesteps: 1,173,595,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1173595986...
Checkpoint 1173595986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288,233.33596
Policy Entropy: 3.74743
Value Function Loss: 0.02867

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.62323
Value Function Update Magnitude: 0.60281

Collected Steps per Second: 22,119.57122
Overall Steps per Second: 10,732.20827

Timestep Collection Time: 2.26071
Timestep Consumption Time: 2.39872
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.65943

Cumulative Model Updates: 140,750
Cumulative Timesteps: 1,173,645,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,479.28664
Policy Entropy: 3.74653
Value Function Loss: 0.02607

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.62374
Value Function Update Magnitude: 0.49988

Collected Steps per Second: 22,642.33629
Overall Steps per Second: 10,780.16201

Timestep Collection Time: 2.20887
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.63945

Cumulative Model Updates: 140,756
Cumulative Timesteps: 1,173,696,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1173696006...
Checkpoint 1173696006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,558.52830
Policy Entropy: 3.72863
Value Function Loss: 0.02700

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.60262
Value Function Update Magnitude: 0.52129

Collected Steps per Second: 22,854.34515
Overall Steps per Second: 10,769.68267

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64471

Cumulative Model Updates: 140,762
Cumulative Timesteps: 1,173,746,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,432.94712
Policy Entropy: 3.74602
Value Function Loss: 0.02277

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.57387
Value Function Update Magnitude: 0.58737

Collected Steps per Second: 22,955.63875
Overall Steps per Second: 10,788.29749

Timestep Collection Time: 2.17925
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.63706

Cumulative Model Updates: 140,768
Cumulative Timesteps: 1,173,796,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1173796054...
Checkpoint 1173796054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,809.32936
Policy Entropy: 3.75141
Value Function Loss: 0.02537

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.61620

Collected Steps per Second: 22,712.78751
Overall Steps per Second: 10,727.31574

Timestep Collection Time: 2.20193
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.66212

Cumulative Model Updates: 140,774
Cumulative Timesteps: 1,173,846,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,998.81952
Policy Entropy: 3.75588
Value Function Loss: 0.02408

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.50193
Value Function Update Magnitude: 0.48861

Collected Steps per Second: 22,916.16461
Overall Steps per Second: 10,876.87341

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.60040

Cumulative Model Updates: 140,780
Cumulative Timesteps: 1,173,896,104

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1173896104...
Checkpoint 1173896104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.75812
Value Function Loss: 0.01935

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.43453
Value Function Update Magnitude: 0.42629

Collected Steps per Second: 22,453.02988
Overall Steps per Second: 10,563.61486

Timestep Collection Time: 2.22741
Timestep Consumption Time: 2.50696
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.73436

Cumulative Model Updates: 140,786
Cumulative Timesteps: 1,173,946,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.74526
Value Function Loss: 0.01716

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.42482
Value Function Update Magnitude: 0.44250

Collected Steps per Second: 23,026.59474
Overall Steps per Second: 10,877.18507

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.60082

Cumulative Model Updates: 140,792
Cumulative Timesteps: 1,173,996,160

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1173996160...
Checkpoint 1173996160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.75658
Value Function Loss: 0.01755

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.42890
Value Function Update Magnitude: 0.39673

Collected Steps per Second: 22,822.50509
Overall Steps per Second: 10,686.83612

Timestep Collection Time: 2.19196
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.68109

Cumulative Model Updates: 140,798
Cumulative Timesteps: 1,174,046,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.73907
Value Function Loss: 0.01798

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.33945

Collected Steps per Second: 22,897.31855
Overall Steps per Second: 10,876.41255

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.59747

Cumulative Model Updates: 140,804
Cumulative Timesteps: 1,174,096,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1174096190...
Checkpoint 1174096190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.74229
Value Function Loss: 0.01892

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.43043
Value Function Update Magnitude: 0.31960

Collected Steps per Second: 22,358.35907
Overall Steps per Second: 10,711.43241

Timestep Collection Time: 2.23755
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.67052

Cumulative Model Updates: 140,810
Cumulative Timesteps: 1,174,146,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.72914
Value Function Loss: 0.01891

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.47067
Value Function Update Magnitude: 0.36698

Collected Steps per Second: 22,994.90956
Overall Steps per Second: 10,877.92759

Timestep Collection Time: 2.17579
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.59941

Cumulative Model Updates: 140,816
Cumulative Timesteps: 1,174,196,250

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1174196250...
Checkpoint 1174196250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.72456
Value Function Loss: 0.02030

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.50586
Value Function Update Magnitude: 0.39744

Collected Steps per Second: 22,537.50475
Overall Steps per Second: 10,650.82154

Timestep Collection Time: 2.21915
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.69579

Cumulative Model Updates: 140,822
Cumulative Timesteps: 1,174,246,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.71967
Value Function Loss: 0.02330

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.51714
Value Function Update Magnitude: 0.40277

Collected Steps per Second: 22,276.94722
Overall Steps per Second: 10,882.07308

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.35071
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.59563

Cumulative Model Updates: 140,828
Cumulative Timesteps: 1,174,296,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1174296274...
Checkpoint 1174296274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,657.41092
Policy Entropy: 3.73329
Value Function Loss: 0.02077

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.52551
Value Function Update Magnitude: 0.45630

Collected Steps per Second: 21,963.93843
Overall Steps per Second: 10,650.25511

Timestep Collection Time: 2.27746
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69679

Cumulative Model Updates: 140,834
Cumulative Timesteps: 1,174,346,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,654.33404
Policy Entropy: 3.73423
Value Function Loss: 0.01958

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.48392
Value Function Update Magnitude: 0.43748

Collected Steps per Second: 22,446.95914
Overall Steps per Second: 10,689.58763

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.67820

Cumulative Model Updates: 140,840
Cumulative Timesteps: 1,174,396,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1174396304...
Checkpoint 1174396304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,654.33404
Policy Entropy: 3.74572
Value Function Loss: 0.01659

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.46446
Value Function Update Magnitude: 0.48461

Collected Steps per Second: 22,960.31394
Overall Steps per Second: 10,874.92854

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.42045
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.59847

Cumulative Model Updates: 140,846
Cumulative Timesteps: 1,174,446,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,714.96362
Policy Entropy: 3.73907
Value Function Loss: 0.01840

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.47325
Value Function Update Magnitude: 0.51972

Collected Steps per Second: 22,909.42873
Overall Steps per Second: 10,933.18843

Timestep Collection Time: 2.18268
Timestep Consumption Time: 2.39092
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.57360

Cumulative Model Updates: 140,852
Cumulative Timesteps: 1,174,496,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1174496316...
Checkpoint 1174496316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,281.25167
Policy Entropy: 3.76599
Value Function Loss: 0.01894

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.50370
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 22,841.44529
Overall Steps per Second: 10,688.46428

Timestep Collection Time: 2.18997
Timestep Consumption Time: 2.49003
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68000

Cumulative Model Updates: 140,858
Cumulative Timesteps: 1,174,546,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,281.25167
Policy Entropy: 3.76011
Value Function Loss: 0.01994

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.48608
Value Function Update Magnitude: 0.44478

Collected Steps per Second: 23,053.68274
Overall Steps per Second: 10,821.31702

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.45225
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.62162

Cumulative Model Updates: 140,864
Cumulative Timesteps: 1,174,596,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1174596350...
Checkpoint 1174596350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 429,637.05108
Policy Entropy: 3.76040
Value Function Loss: 0.02111

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.39924

Collected Steps per Second: 22,779.63275
Overall Steps per Second: 10,666.24775

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68768

Cumulative Model Updates: 140,870
Cumulative Timesteps: 1,174,646,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,165.46002
Policy Entropy: 3.74310
Value Function Loss: 0.02175

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.50093
Value Function Update Magnitude: 0.42189

Collected Steps per Second: 23,075.27042
Overall Steps per Second: 10,929.56212

Timestep Collection Time: 2.16760
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.57640

Cumulative Model Updates: 140,876
Cumulative Timesteps: 1,174,696,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1174696368...
Checkpoint 1174696368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,202.85673
Policy Entropy: 3.75352
Value Function Loss: 0.02280

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.49289
Value Function Update Magnitude: 0.44940

Collected Steps per Second: 22,731.25069
Overall Steps per Second: 10,710.03260

Timestep Collection Time: 2.20076
Timestep Consumption Time: 2.47019
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.67095

Cumulative Model Updates: 140,882
Cumulative Timesteps: 1,174,746,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,202.85673
Policy Entropy: 3.75380
Value Function Loss: 0.02055

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.49519

Collected Steps per Second: 22,847.56217
Overall Steps per Second: 10,794.38500

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.44499
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.63463

Cumulative Model Updates: 140,888
Cumulative Timesteps: 1,174,796,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1174796422...
Checkpoint 1174796422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,731.58411
Policy Entropy: 3.73875
Value Function Loss: 0.02182

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 22,047.34324
Overall Steps per Second: 10,662.84390

Timestep Collection Time: 2.26821
Timestep Consumption Time: 2.42172
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.68993

Cumulative Model Updates: 140,894
Cumulative Timesteps: 1,174,846,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,917.59950
Policy Entropy: 3.74169
Value Function Loss: 0.02078

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 22,405.49173
Overall Steps per Second: 10,883.28637

Timestep Collection Time: 2.23195
Timestep Consumption Time: 2.36298
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.59494

Cumulative Model Updates: 140,900
Cumulative Timesteps: 1,174,896,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1174896438...
Checkpoint 1174896438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,917.59950
Policy Entropy: 3.73811
Value Function Loss: 0.02059

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.53998
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 22,190.37004
Overall Steps per Second: 10,614.47972

Timestep Collection Time: 2.25458
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.71337

Cumulative Model Updates: 140,906
Cumulative Timesteps: 1,174,946,468

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,917.59950
Policy Entropy: 3.72675
Value Function Loss: 0.01910

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.50983

Collected Steps per Second: 23,148.28960
Overall Steps per Second: 10,909.05608

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.58353

Cumulative Model Updates: 140,912
Cumulative Timesteps: 1,174,996,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1174996470...
Checkpoint 1174996470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,917.59950
Policy Entropy: 3.72589
Value Function Loss: 0.01845

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.49230
Value Function Update Magnitude: 0.45248

Collected Steps per Second: 23,108.87449
Overall Steps per Second: 11,008.10980

Timestep Collection Time: 2.16454
Timestep Consumption Time: 2.37939
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.54392

Cumulative Model Updates: 140,918
Cumulative Timesteps: 1,175,046,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,463.62971
Policy Entropy: 3.72512
Value Function Loss: 0.01950

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.46334
Value Function Update Magnitude: 0.43166

Collected Steps per Second: 22,698.77978
Overall Steps per Second: 10,625.79457

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.50297
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70591

Cumulative Model Updates: 140,924
Cumulative Timesteps: 1,175,096,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1175096494...
Checkpoint 1175096494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,271.93241
Policy Entropy: 3.75472
Value Function Loss: 0.01920

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.45185
Value Function Update Magnitude: 0.38266

Collected Steps per Second: 22,701.79904
Overall Steps per Second: 10,693.24624

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.47496
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.67884

Cumulative Model Updates: 140,930
Cumulative Timesteps: 1,175,146,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,365.10766
Policy Entropy: 3.74813
Value Function Loss: 0.02159

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13409
Policy Update Magnitude: 0.44824
Value Function Update Magnitude: 0.42316

Collected Steps per Second: 22,912.55474
Overall Steps per Second: 10,754.95754

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.64958

Cumulative Model Updates: 140,936
Cumulative Timesteps: 1,175,196,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1175196532...
Checkpoint 1175196532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,711.96735
Policy Entropy: 3.75686
Value Function Loss: 0.01995

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.47895
Value Function Update Magnitude: 0.50634

Collected Steps per Second: 22,972.32383
Overall Steps per Second: 10,737.87361

Timestep Collection Time: 2.17853
Timestep Consumption Time: 2.48216
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.66070

Cumulative Model Updates: 140,942
Cumulative Timesteps: 1,175,246,578

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,711.96735
Policy Entropy: 3.74139
Value Function Loss: 0.02029

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.46458
Value Function Update Magnitude: 0.43585

Collected Steps per Second: 22,674.99996
Overall Steps per Second: 10,806.40654

Timestep Collection Time: 2.20604
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.62892

Cumulative Model Updates: 140,948
Cumulative Timesteps: 1,175,296,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1175296600...
Checkpoint 1175296600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,711.96735
Policy Entropy: 3.74366
Value Function Loss: 0.01829

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.47738
Value Function Update Magnitude: 0.39392

Collected Steps per Second: 22,759.65272
Overall Steps per Second: 10,709.67290

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.66998

Cumulative Model Updates: 140,954
Cumulative Timesteps: 1,175,346,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,711.96735
Policy Entropy: 3.72649
Value Function Loss: 0.02063

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.45812
Value Function Update Magnitude: 0.36239

Collected Steps per Second: 23,077.72118
Overall Steps per Second: 10,876.68272

Timestep Collection Time: 2.16763
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.59920

Cumulative Model Updates: 140,960
Cumulative Timesteps: 1,175,396,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1175396638...
Checkpoint 1175396638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,780.65526
Policy Entropy: 3.75004
Value Function Loss: 0.01967

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.46718
Value Function Update Magnitude: 0.43744

Collected Steps per Second: 22,815.81382
Overall Steps per Second: 10,743.92091

Timestep Collection Time: 2.19164
Timestep Consumption Time: 2.46253
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.65417

Cumulative Model Updates: 140,966
Cumulative Timesteps: 1,175,446,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,478.61107
Policy Entropy: 3.74782
Value Function Loss: 0.02123

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.46581
Value Function Update Magnitude: 0.48377

Collected Steps per Second: 22,420.32054
Overall Steps per Second: 10,789.64175

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.40463
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.63537

Cumulative Model Updates: 140,972
Cumulative Timesteps: 1,175,496,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1175496656...
Checkpoint 1175496656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,762.10008
Policy Entropy: 3.76533
Value Function Loss: 0.02120

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.49097
Value Function Update Magnitude: 0.55364

Collected Steps per Second: 22,143.09421
Overall Steps per Second: 10,742.97564

Timestep Collection Time: 2.25912
Timestep Consumption Time: 2.39731
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.65644

Cumulative Model Updates: 140,978
Cumulative Timesteps: 1,175,546,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,721.65958
Policy Entropy: 3.76576
Value Function Loss: 0.02042

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.49735
Value Function Update Magnitude: 0.57462

Collected Steps per Second: 22,244.50577
Overall Steps per Second: 10,775.23124

Timestep Collection Time: 2.24820
Timestep Consumption Time: 2.39300
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.64120

Cumulative Model Updates: 140,984
Cumulative Timesteps: 1,175,596,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1175596690...
Checkpoint 1175596690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,721.65958
Policy Entropy: 3.75768
Value Function Loss: 0.02039

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.47517
Value Function Update Magnitude: 0.56225

Collected Steps per Second: 22,277.98103
Overall Steps per Second: 10,652.04176

Timestep Collection Time: 2.24455
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.69431

Cumulative Model Updates: 140,990
Cumulative Timesteps: 1,175,646,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,679.48124
Policy Entropy: 3.75970
Value Function Loss: 0.01911

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.44653
Value Function Update Magnitude: 0.53954

Collected Steps per Second: 22,810.82416
Overall Steps per Second: 10,940.58594

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.37924
PPO Batch Consumption Time: 0.27560
Total Iteration Time: 4.57215

Cumulative Model Updates: 140,996
Cumulative Timesteps: 1,175,696,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1175696716...
Checkpoint 1175696716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,268.79175
Policy Entropy: 3.74677
Value Function Loss: 0.02114

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.46131
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 22,798.18244
Overall Steps per Second: 10,793.73533

Timestep Collection Time: 2.19386
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.63380

Cumulative Model Updates: 141,002
Cumulative Timesteps: 1,175,746,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,268.79175
Policy Entropy: 3.74511
Value Function Loss: 0.02003

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.57793

Collected Steps per Second: 22,822.29755
Overall Steps per Second: 10,720.45582

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.66622

Cumulative Model Updates: 141,008
Cumulative Timesteps: 1,175,796,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1175796756...
Checkpoint 1175796756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,791.52622
Policy Entropy: 3.72715
Value Function Loss: 0.02123

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.51361
Value Function Update Magnitude: 0.66215

Collected Steps per Second: 22,759.82909
Overall Steps per Second: 10,664.85350

Timestep Collection Time: 2.19703
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68867

Cumulative Model Updates: 141,014
Cumulative Timesteps: 1,175,846,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,605.02028
Policy Entropy: 3.74068
Value Function Loss: 0.02235

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.84032

Collected Steps per Second: 22,955.95768
Overall Steps per Second: 10,846.61913

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.61194

Cumulative Model Updates: 141,020
Cumulative Timesteps: 1,175,896,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1175896784...
Checkpoint 1175896784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,578.98923
Policy Entropy: 3.76701
Value Function Loss: 0.02279

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.90395

Collected Steps per Second: 22,977.86092
Overall Steps per Second: 10,712.05401

Timestep Collection Time: 2.17601
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.66764

Cumulative Model Updates: 141,026
Cumulative Timesteps: 1,175,946,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,877.21025
Policy Entropy: 3.77366
Value Function Loss: 0.02051

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.56776
Value Function Update Magnitude: 0.90641

Collected Steps per Second: 22,712.25407
Overall Steps per Second: 10,818.24111

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.62256

Cumulative Model Updates: 141,032
Cumulative Timesteps: 1,175,996,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1175996792...
Checkpoint 1175996792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,621.26026
Policy Entropy: 3.75918
Value Function Loss: 0.01917

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.53654
Value Function Update Magnitude: 0.85474

Collected Steps per Second: 22,919.87833
Overall Steps per Second: 10,688.29519

Timestep Collection Time: 2.18273
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.68063

Cumulative Model Updates: 141,038
Cumulative Timesteps: 1,176,046,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,380.21411
Policy Entropy: 3.74676
Value Function Loss: 0.01872

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.93750

Collected Steps per Second: 22,891.15969
Overall Steps per Second: 10,841.30763

Timestep Collection Time: 2.18460
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.61273

Cumulative Model Updates: 141,044
Cumulative Timesteps: 1,176,096,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1176096828...
Checkpoint 1176096828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,660.52677
Policy Entropy: 3.74257
Value Function Loss: 0.01986

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.88620

Collected Steps per Second: 22,812.10520
Overall Steps per Second: 10,708.50322

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.67161

Cumulative Model Updates: 141,050
Cumulative Timesteps: 1,176,146,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,595.98622
Policy Entropy: 3.74254
Value Function Loss: 0.01977

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.53932
Value Function Update Magnitude: 0.67824

Collected Steps per Second: 23,033.22303
Overall Steps per Second: 10,901.17174

Timestep Collection Time: 2.17078
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.58666

Cumulative Model Updates: 141,056
Cumulative Timesteps: 1,176,196,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1176196854...
Checkpoint 1176196854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,734.69136
Policy Entropy: 3.74650
Value Function Loss: 0.02161

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.51066
Value Function Update Magnitude: 0.58509

Collected Steps per Second: 22,941.84403
Overall Steps per Second: 10,736.80238

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.65818

Cumulative Model Updates: 141,062
Cumulative Timesteps: 1,176,246,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,386.01011
Policy Entropy: 3.75987
Value Function Loss: 0.02001

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.52072
Value Function Update Magnitude: 0.63230

Collected Steps per Second: 22,898.47360
Overall Steps per Second: 10,785.38048

Timestep Collection Time: 2.18364
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.63609

Cumulative Model Updates: 141,068
Cumulative Timesteps: 1,176,296,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1176296870...
Checkpoint 1176296870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,711.91973
Policy Entropy: 3.77760
Value Function Loss: 0.01779

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.52175
Value Function Update Magnitude: 0.68928

Collected Steps per Second: 23,125.93921
Overall Steps per Second: 10,820.42709

Timestep Collection Time: 2.16233
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.62144

Cumulative Model Updates: 141,074
Cumulative Timesteps: 1,176,346,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,512.58826
Policy Entropy: 3.76831
Value Function Loss: 0.01602

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.50068
Value Function Update Magnitude: 0.62000

Collected Steps per Second: 22,261.96287
Overall Steps per Second: 10,708.62291

Timestep Collection Time: 2.24634
Timestep Consumption Time: 2.42354
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.66988

Cumulative Model Updates: 141,080
Cumulative Timesteps: 1,176,396,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1176396884...
Checkpoint 1176396884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,754.40160
Policy Entropy: 3.75565
Value Function Loss: 0.01631

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.48966
Value Function Update Magnitude: 0.59988

Collected Steps per Second: 22,054.82576
Overall Steps per Second: 10,703.16640

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.40463
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.67189

Cumulative Model Updates: 141,086
Cumulative Timesteps: 1,176,446,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,348.74747
Policy Entropy: 3.73201
Value Function Loss: 0.02049

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.50844
Value Function Update Magnitude: 0.51367

Collected Steps per Second: 21,922.66833
Overall Steps per Second: 10,548.03112

Timestep Collection Time: 2.28147
Timestep Consumption Time: 2.46026
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.74174

Cumulative Model Updates: 141,092
Cumulative Timesteps: 1,176,496,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1176496904...
Checkpoint 1176496904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290,257.72950
Policy Entropy: 3.73072
Value Function Loss: 0.02343

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.49191

Collected Steps per Second: 23,308.15251
Overall Steps per Second: 10,968.62548

Timestep Collection Time: 2.14560
Timestep Consumption Time: 2.41377
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.55937

Cumulative Model Updates: 141,098
Cumulative Timesteps: 1,176,546,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,587.71707
Policy Entropy: 3.72097
Value Function Loss: 0.02646

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.57134
Value Function Update Magnitude: 0.63367

Collected Steps per Second: 22,732.13591
Overall Steps per Second: 10,870.42353

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.40136
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.60203

Cumulative Model Updates: 141,104
Cumulative Timesteps: 1,176,596,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1176596940...
Checkpoint 1176596940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,898.20057
Policy Entropy: 3.72891
Value Function Loss: 0.02865

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.59547
Value Function Update Magnitude: 0.74379

Collected Steps per Second: 23,025.67352
Overall Steps per Second: 10,824.90814

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.61916

Cumulative Model Updates: 141,110
Cumulative Timesteps: 1,176,646,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,898.20057
Policy Entropy: 3.71941
Value Function Loss: 0.02735

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 23,159.34788
Overall Steps per Second: 10,742.54747

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.65811

Cumulative Model Updates: 141,116
Cumulative Timesteps: 1,176,696,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1176696982...
Checkpoint 1176696982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,001.33815
Policy Entropy: 3.72552
Value Function Loss: 0.02421

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.49179

Collected Steps per Second: 23,073.75323
Overall Steps per Second: 10,727.41378

Timestep Collection Time: 2.16705
Timestep Consumption Time: 2.49409
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66114

Cumulative Model Updates: 141,122
Cumulative Timesteps: 1,176,746,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,820.74585
Policy Entropy: 3.72991
Value Function Loss: 0.02072

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.54296
Value Function Update Magnitude: 0.46837

Collected Steps per Second: 22,855.43771
Overall Steps per Second: 10,873.13302

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27604
Total Iteration Time: 4.59849

Cumulative Model Updates: 141,128
Cumulative Timesteps: 1,176,796,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1176796984...
Checkpoint 1176796984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,908.22818
Policy Entropy: 3.75264
Value Function Loss: 0.01660

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.50604
Value Function Update Magnitude: 0.46269

Collected Steps per Second: 23,068.97633
Overall Steps per Second: 10,729.78313

Timestep Collection Time: 2.16828
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.66179

Cumulative Model Updates: 141,134
Cumulative Timesteps: 1,176,847,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,908.22818
Policy Entropy: 3.75023
Value Function Loss: 0.01479

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08608
Policy Update Magnitude: 0.48555
Value Function Update Magnitude: 0.47354

Collected Steps per Second: 22,897.71074
Overall Steps per Second: 10,794.87339

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.63387

Cumulative Model Updates: 141,140
Cumulative Timesteps: 1,176,897,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1176897026...
Checkpoint 1176897026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,896.39015
Policy Entropy: 3.75077
Value Function Loss: 0.01290

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07296
Policy Update Magnitude: 0.52926
Value Function Update Magnitude: 0.49746

Collected Steps per Second: 22,857.99748
Overall Steps per Second: 10,671.56763

Timestep Collection Time: 2.18777
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.68610

Cumulative Model Updates: 141,146
Cumulative Timesteps: 1,176,947,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,040.10868
Policy Entropy: 3.75644
Value Function Loss: 0.01303

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.07389
Policy Update Magnitude: 0.55401
Value Function Update Magnitude: 0.53105

Collected Steps per Second: 22,878.38563
Overall Steps per Second: 10,872.15737

Timestep Collection Time: 2.18599
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60001

Cumulative Model Updates: 141,152
Cumulative Timesteps: 1,176,997,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1176997046...
Checkpoint 1176997046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,632.73336
Policy Entropy: 3.77324
Value Function Loss: 0.01302

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06397
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.56340

Collected Steps per Second: 22,823.96560
Overall Steps per Second: 10,704.68256

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67235

Cumulative Model Updates: 141,158
Cumulative Timesteps: 1,177,047,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,865.81701
Policy Entropy: 3.80794
Value Function Loss: 0.01266

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05434
Policy Update Magnitude: 0.58831
Value Function Update Magnitude: 0.64039

Collected Steps per Second: 22,862.02887
Overall Steps per Second: 10,813.08379

Timestep Collection Time: 2.18747
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62495

Cumulative Model Updates: 141,164
Cumulative Timesteps: 1,177,097,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1177097072...
Checkpoint 1177097072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.79352
Value Function Loss: 0.01264

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05554
Policy Update Magnitude: 0.61361
Value Function Update Magnitude: 0.63908

Collected Steps per Second: 22,830.76994
Overall Steps per Second: 10,741.49604

Timestep Collection Time: 2.19117
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.65727

Cumulative Model Updates: 141,170
Cumulative Timesteps: 1,177,147,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.78801
Value Function Loss: 0.01178

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04823
Policy Update Magnitude: 0.61235
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 22,787.92426
Overall Steps per Second: 10,784.08944

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.64165

Cumulative Model Updates: 141,176
Cumulative Timesteps: 1,177,197,154

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1177197154...
Checkpoint 1177197154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.76784
Value Function Loss: 0.01058

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.49473

Collected Steps per Second: 22,649.36714
Overall Steps per Second: 10,638.70825

Timestep Collection Time: 2.20757
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.69982

Cumulative Model Updates: 141,182
Cumulative Timesteps: 1,177,247,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.76488
Value Function Loss: 0.01169

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.37897

Collected Steps per Second: 22,228.04521
Overall Steps per Second: 10,908.12875

Timestep Collection Time: 2.25085
Timestep Consumption Time: 2.33582
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.58667

Cumulative Model Updates: 141,188
Cumulative Timesteps: 1,177,297,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1177297186...
Checkpoint 1177297186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.74943
Value Function Loss: 0.01242

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.18830
Policy Update Magnitude: 0.49998
Value Function Update Magnitude: 0.34449

Collected Steps per Second: 22,114.09649
Overall Steps per Second: 10,718.99194

Timestep Collection Time: 2.26245
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.66760

Cumulative Model Updates: 141,194
Cumulative Timesteps: 1,177,347,218

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.76556
Value Function Loss: 0.01278

Mean KL Divergence: 0.02389
SB3 Clip Fraction: 0.24335
Policy Update Magnitude: 0.43631
Value Function Update Magnitude: 0.30833

Collected Steps per Second: 22,207.35081
Overall Steps per Second: 10,845.39569

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.35931
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.61136

Cumulative Model Updates: 141,200
Cumulative Timesteps: 1,177,397,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1177397230...
Checkpoint 1177397230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.80513
Value Function Loss: 0.02189

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16851
Policy Update Magnitude: 0.36902
Value Function Update Magnitude: 0.24983

Collected Steps per Second: 22,367.26426
Overall Steps per Second: 10,675.08171

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.45065
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68811

Cumulative Model Updates: 141,206
Cumulative Timesteps: 1,177,447,276

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.79287
Value Function Loss: 0.01737

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16882
Policy Update Magnitude: 0.36190
Value Function Update Magnitude: 0.18600

Collected Steps per Second: 23,081.86188
Overall Steps per Second: 10,928.25256

Timestep Collection Time: 2.16698
Timestep Consumption Time: 2.40996
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.57694

Cumulative Model Updates: 141,212
Cumulative Timesteps: 1,177,497,294

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1177497294...
Checkpoint 1177497294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,196.05267
Policy Entropy: 3.78234
Value Function Loss: 0.02737

Mean KL Divergence: 0.01905
SB3 Clip Fraction: 0.22442
Policy Update Magnitude: 0.33719
Value Function Update Magnitude: 0.16074

Collected Steps per Second: 22,927.04265
Overall Steps per Second: 10,732.84643

Timestep Collection Time: 2.18118
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.65934

Cumulative Model Updates: 141,218
Cumulative Timesteps: 1,177,547,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,335.38670
Policy Entropy: 3.75353
Value Function Loss: 0.02219

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17159
Policy Update Magnitude: 0.36096
Value Function Update Magnitude: 0.26537

Collected Steps per Second: 22,769.62102
Overall Steps per Second: 10,766.96593

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.64532

Cumulative Model Updates: 141,224
Cumulative Timesteps: 1,177,597,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1177597318...
Checkpoint 1177597318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,598.53254
Policy Entropy: 3.74699
Value Function Loss: 0.02303

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16423
Policy Update Magnitude: 0.44978
Value Function Update Magnitude: 0.37006

Collected Steps per Second: 22,812.81768
Overall Steps per Second: 10,681.70560

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.48915
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.68090

Cumulative Model Updates: 141,230
Cumulative Timesteps: 1,177,647,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,014.76427
Policy Entropy: 3.75935
Value Function Loss: 0.02172

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.54278

Collected Steps per Second: 23,092.53060
Overall Steps per Second: 10,923.70423

Timestep Collection Time: 2.16538
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.57757

Cumulative Model Updates: 141,236
Cumulative Timesteps: 1,177,697,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1177697322...
Checkpoint 1177697322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260,754.06587
Policy Entropy: 3.74774
Value Function Loss: 0.02278

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15268
Policy Update Magnitude: 0.58861
Value Function Update Magnitude: 0.55379

Collected Steps per Second: 23,028.37759
Overall Steps per Second: 10,936.18745

Timestep Collection Time: 2.17219
Timestep Consumption Time: 2.40180
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.57399

Cumulative Model Updates: 141,242
Cumulative Timesteps: 1,177,747,344

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,929.23348
Policy Entropy: 3.73062
Value Function Loss: 0.02099

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.51617
Value Function Update Magnitude: 0.53234

Collected Steps per Second: 22,328.21992
Overall Steps per Second: 10,548.94089

Timestep Collection Time: 2.23959
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.74038

Cumulative Model Updates: 141,248
Cumulative Timesteps: 1,177,797,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1177797350...
Checkpoint 1177797350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,929.23348
Policy Entropy: 3.72333
Value Function Loss: 0.01787

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.46959
Value Function Update Magnitude: 0.45652

Collected Steps per Second: 22,044.74755
Overall Steps per Second: 10,680.30729

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.41350
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.68170

Cumulative Model Updates: 141,254
Cumulative Timesteps: 1,177,847,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,466.17898
Policy Entropy: 3.73734
Value Function Loss: 0.01727

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.46023
Value Function Update Magnitude: 0.48543

Collected Steps per Second: 22,030.72654
Overall Steps per Second: 10,813.18232

Timestep Collection Time: 2.26992
Timestep Consumption Time: 2.35480
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.62473

Cumulative Model Updates: 141,260
Cumulative Timesteps: 1,177,897,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1177897360...
Checkpoint 1177897360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,629.95534
Policy Entropy: 3.74445
Value Function Loss: 0.01955

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14569
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.64921

Collected Steps per Second: 22,231.04809
Overall Steps per Second: 10,749.49489

Timestep Collection Time: 2.24920
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.65157

Cumulative Model Updates: 141,266
Cumulative Timesteps: 1,177,947,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,837.51032
Policy Entropy: 3.75931
Value Function Loss: 0.02224

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.51024
Value Function Update Magnitude: 0.69017

Collected Steps per Second: 22,157.40341
Overall Steps per Second: 10,905.29777

Timestep Collection Time: 2.25757
Timestep Consumption Time: 2.32937
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.58694

Cumulative Model Updates: 141,272
Cumulative Timesteps: 1,177,997,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1177997384...
Checkpoint 1177997384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,543.86827
Policy Entropy: 3.75967
Value Function Loss: 0.02216

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.54494
Value Function Update Magnitude: 0.57695

Collected Steps per Second: 22,485.67438
Overall Steps per Second: 10,612.30915

Timestep Collection Time: 2.22462
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.71358

Cumulative Model Updates: 141,278
Cumulative Timesteps: 1,178,047,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,800.59528
Policy Entropy: 3.74485
Value Function Loss: 0.01738

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.52620
Value Function Update Magnitude: 0.63258

Collected Steps per Second: 22,922.09709
Overall Steps per Second: 10,935.20397

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.39147
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.57312

Cumulative Model Updates: 141,284
Cumulative Timesteps: 1,178,097,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1178097414...
Checkpoint 1178097414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,800.59528
Policy Entropy: 3.73064
Value Function Loss: 0.01652

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.46921
Value Function Update Magnitude: 0.58649

Collected Steps per Second: 23,122.84350
Overall Steps per Second: 10,790.29573

Timestep Collection Time: 2.16254
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.63416

Cumulative Model Updates: 141,290
Cumulative Timesteps: 1,178,147,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,827.38594
Policy Entropy: 3.72715
Value Function Loss: 0.01555

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.47050
Value Function Update Magnitude: 0.63226

Collected Steps per Second: 23,134.84935
Overall Steps per Second: 10,851.87689

Timestep Collection Time: 2.16150
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.60805

Cumulative Model Updates: 141,296
Cumulative Timesteps: 1,178,197,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1178197424...
Checkpoint 1178197424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,206.36650
Policy Entropy: 3.74418
Value Function Loss: 0.01661

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.49878
Value Function Update Magnitude: 0.68663

Collected Steps per Second: 23,144.38764
Overall Steps per Second: 10,969.83609

Timestep Collection Time: 2.16061
Timestep Consumption Time: 2.39789
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.55850

Cumulative Model Updates: 141,302
Cumulative Timesteps: 1,178,247,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,001.72760
Policy Entropy: 3.74679
Value Function Loss: 0.01704

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05030
Policy Update Magnitude: 0.60810
Value Function Update Magnitude: 0.71386

Collected Steps per Second: 23,083.09809
Overall Steps per Second: 10,943.15652

Timestep Collection Time: 2.16817
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.57345

Cumulative Model Updates: 141,308
Cumulative Timesteps: 1,178,297,478

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1178297478...
Checkpoint 1178297478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,008.68970
Policy Entropy: 3.74834
Value Function Loss: 0.01620

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06348
Policy Update Magnitude: 0.70236
Value Function Update Magnitude: 0.76751

Collected Steps per Second: 22,970.55800
Overall Steps per Second: 10,775.49914

Timestep Collection Time: 2.17835
Timestep Consumption Time: 2.46533
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.64368

Cumulative Model Updates: 141,314
Cumulative Timesteps: 1,178,347,516

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,557.71044
Policy Entropy: 3.76272
Value Function Loss: 0.01519

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.70659
Value Function Update Magnitude: 0.74927

Collected Steps per Second: 22,736.25485
Overall Steps per Second: 10,732.18203

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.65982

Cumulative Model Updates: 141,320
Cumulative Timesteps: 1,178,397,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1178397526...
Checkpoint 1178397526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,776.28377
Policy Entropy: 3.77583
Value Function Loss: 0.01373

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05835
Policy Update Magnitude: 0.65939
Value Function Update Magnitude: 0.68433

Collected Steps per Second: 23,096.67211
Overall Steps per Second: 10,767.38167

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.64458

Cumulative Model Updates: 141,326
Cumulative Timesteps: 1,178,447,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.06963
Policy Entropy: 3.77858
Value Function Loss: 0.01373

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06275
Policy Update Magnitude: 0.61846
Value Function Update Magnitude: 0.66511

Collected Steps per Second: 23,411.98006
Overall Steps per Second: 10,817.49982

Timestep Collection Time: 2.13583
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.62251

Cumulative Model Updates: 141,332
Cumulative Timesteps: 1,178,497,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1178497540...
Checkpoint 1178497540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.06963
Policy Entropy: 3.75848
Value Function Loss: 0.01197

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.57007
Value Function Update Magnitude: 0.62082

Collected Steps per Second: 23,018.55938
Overall Steps per Second: 10,804.23355

Timestep Collection Time: 2.17320
Timestep Consumption Time: 2.45683
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.63004

Cumulative Model Updates: 141,338
Cumulative Timesteps: 1,178,547,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,073.06963
Policy Entropy: 3.75664
Value Function Loss: 0.01079

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.48683
Value Function Update Magnitude: 0.49173

Collected Steps per Second: 23,261.56770
Overall Steps per Second: 10,755.25088

Timestep Collection Time: 2.15067
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.65150

Cumulative Model Updates: 141,344
Cumulative Timesteps: 1,178,597,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1178597592...
Checkpoint 1178597592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,585.08060
Policy Entropy: 3.74905
Value Function Loss: 0.01244

Mean KL Divergence: 0.03146
SB3 Clip Fraction: 0.33583
Policy Update Magnitude: 0.39184
Value Function Update Magnitude: 0.44744

Collected Steps per Second: 23,150.60955
Overall Steps per Second: 10,950.57997

Timestep Collection Time: 2.16020
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.56688

Cumulative Model Updates: 141,350
Cumulative Timesteps: 1,178,647,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,650.11007
Policy Entropy: 3.74310
Value Function Loss: 0.02975

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.22455
Policy Update Magnitude: 0.43517
Value Function Update Magnitude: 0.52922

Collected Steps per Second: 22,838.61927
Overall Steps per Second: 10,671.58913

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.68665

Cumulative Model Updates: 141,356
Cumulative Timesteps: 1,178,697,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1178697616...
Checkpoint 1178697616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,623.23415
Policy Entropy: 3.76025
Value Function Loss: 0.03692

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.17802
Policy Update Magnitude: 0.80375
Value Function Update Magnitude: 0.66055

Collected Steps per Second: 23,006.36069
Overall Steps per Second: 10,873.95335

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.60035

Cumulative Model Updates: 141,362
Cumulative Timesteps: 1,178,747,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,677.70897
Policy Entropy: 3.74451
Value Function Loss: 0.03603

Mean KL Divergence: 0.02096
SB3 Clip Fraction: 0.21730
Policy Update Magnitude: 0.87832
Value Function Update Magnitude: 0.83655

Collected Steps per Second: 22,948.35057
Overall Steps per Second: 10,754.68505

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.65081

Cumulative Model Updates: 141,368
Cumulative Timesteps: 1,178,797,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1178797658...
Checkpoint 1178797658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,935.18689
Policy Entropy: 3.77295
Value Function Loss: 0.02519

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.80847
Value Function Update Magnitude: 0.72201

Collected Steps per Second: 22,468.16191
Overall Steps per Second: 10,770.23944

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.41782
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.64391

Cumulative Model Updates: 141,374
Cumulative Timesteps: 1,178,847,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,550.34856
Policy Entropy: 3.76846
Value Function Loss: 0.02295

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.19088
Policy Update Magnitude: 0.59710
Value Function Update Magnitude: 0.69015

Collected Steps per Second: 23,086.60263
Overall Steps per Second: 10,959.46178

Timestep Collection Time: 2.16706
Timestep Consumption Time: 2.39795
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.56501

Cumulative Model Updates: 141,380
Cumulative Timesteps: 1,178,897,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1178897704...
Checkpoint 1178897704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,385.77419
Policy Entropy: 3.78213
Value Function Loss: 0.02407

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15274
Policy Update Magnitude: 0.54766
Value Function Update Magnitude: 0.70835

Collected Steps per Second: 23,138.21585
Overall Steps per Second: 10,752.84403

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.64993

Cumulative Model Updates: 141,386
Cumulative Timesteps: 1,178,947,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,296.88826
Policy Entropy: 3.77899
Value Function Loss: 0.03104

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15747
Policy Update Magnitude: 0.59648
Value Function Update Magnitude: 0.74724

Collected Steps per Second: 23,196.10464
Overall Steps per Second: 10,865.02678

Timestep Collection Time: 2.15579
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.60247

Cumulative Model Updates: 141,392
Cumulative Timesteps: 1,178,997,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1178997710...
Checkpoint 1178997710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.88809
Policy Entropy: 3.80180
Value Function Loss: 0.02867

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.66382
Value Function Update Magnitude: 0.89592

Collected Steps per Second: 22,921.67068
Overall Steps per Second: 10,722.27501

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.66468

Cumulative Model Updates: 141,398
Cumulative Timesteps: 1,179,047,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,475.85634
Policy Entropy: 3.79365
Value Function Loss: 0.02936

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14979
Policy Update Magnitude: 0.65731
Value Function Update Magnitude: 0.92411

Collected Steps per Second: 23,093.00538
Overall Steps per Second: 10,824.71633

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.45439
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.61998

Cumulative Model Updates: 141,404
Cumulative Timesteps: 1,179,097,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1179097736...
Checkpoint 1179097736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,963.39484
Policy Entropy: 3.78721
Value Function Loss: 0.02581

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.66483
Value Function Update Magnitude: 0.98607

Collected Steps per Second: 22,928.73081
Overall Steps per Second: 10,737.49127

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.47591
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.65658

Cumulative Model Updates: 141,410
Cumulative Timesteps: 1,179,147,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,315.61577
Policy Entropy: 3.73946
Value Function Loss: 0.02612

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.64325
Value Function Update Magnitude: 0.98587

Collected Steps per Second: 23,021.44924
Overall Steps per Second: 10,825.38473

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.62099

Cumulative Model Updates: 141,416
Cumulative Timesteps: 1,179,197,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1179197760...
Checkpoint 1179197760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,871.56128
Policy Entropy: 3.72933
Value Function Loss: 0.02387

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14689
Policy Update Magnitude: 0.60105
Value Function Update Magnitude: 0.92617

Collected Steps per Second: 22,852.32967
Overall Steps per Second: 10,690.67401

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.67866

Cumulative Model Updates: 141,422
Cumulative Timesteps: 1,179,247,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,165.64554
Policy Entropy: 3.74998
Value Function Loss: 0.02668

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.69836

Collected Steps per Second: 22,774.82326
Overall Steps per Second: 10,812.84626

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.62505

Cumulative Model Updates: 141,428
Cumulative Timesteps: 1,179,297,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1179297788...
Checkpoint 1179297788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,076.73707
Policy Entropy: 3.76882
Value Function Loss: 0.02651

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.59924

Collected Steps per Second: 22,492.83352
Overall Steps per Second: 10,659.47798

Timestep Collection Time: 2.22320
Timestep Consumption Time: 2.46803
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.69122

Cumulative Model Updates: 141,434
Cumulative Timesteps: 1,179,347,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580,489.67237
Policy Entropy: 3.78583
Value Function Loss: 0.02725

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.75971

Collected Steps per Second: 22,966.19819
Overall Steps per Second: 10,869.90964

Timestep Collection Time: 2.17781
Timestep Consumption Time: 2.42352
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.60133

Cumulative Model Updates: 141,440
Cumulative Timesteps: 1,179,397,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1179397810...
Checkpoint 1179397810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,855.99259
Policy Entropy: 3.77620
Value Function Loss: 0.02778

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.90407

Collected Steps per Second: 22,931.46333
Overall Steps per Second: 10,699.34625

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.67374

Cumulative Model Updates: 141,446
Cumulative Timesteps: 1,179,447,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,385.86885
Policy Entropy: 3.77621
Value Function Loss: 0.02532

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.97116

Collected Steps per Second: 22,911.71165
Overall Steps per Second: 10,860.33135

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.42317
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60686

Cumulative Model Updates: 141,452
Cumulative Timesteps: 1,179,497,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1179497848...
Checkpoint 1179497848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,995.64602
Policy Entropy: 3.76569
Value Function Loss: 0.02506

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.83204

Collected Steps per Second: 22,726.63762
Overall Steps per Second: 10,651.63829

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.69562

Cumulative Model Updates: 141,458
Cumulative Timesteps: 1,179,547,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312,125.13111
Policy Entropy: 3.77572
Value Function Loss: 0.02107

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.54092
Value Function Update Magnitude: 0.76343

Collected Steps per Second: 22,709.69101
Overall Steps per Second: 10,817.44710

Timestep Collection Time: 2.20206
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.62290

Cumulative Model Updates: 141,464
Cumulative Timesteps: 1,179,597,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1179597872...
Checkpoint 1179597872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,387.01847
Policy Entropy: 3.76849
Value Function Loss: 0.02203

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.49875
Value Function Update Magnitude: 0.73124

Collected Steps per Second: 22,608.33159
Overall Steps per Second: 10,716.08036

Timestep Collection Time: 2.21175
Timestep Consumption Time: 2.45451
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.66626

Cumulative Model Updates: 141,470
Cumulative Timesteps: 1,179,647,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,640.30954
Policy Entropy: 3.77168
Value Function Loss: 0.02081

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.46361
Value Function Update Magnitude: 0.69463

Collected Steps per Second: 22,269.12407
Overall Steps per Second: 10,878.04289

Timestep Collection Time: 2.24535
Timestep Consumption Time: 2.35125
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.59660

Cumulative Model Updates: 141,476
Cumulative Timesteps: 1,179,697,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1179697878...
Checkpoint 1179697878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,255.94913
Policy Entropy: 3.76109
Value Function Loss: 0.01982

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.44397
Value Function Update Magnitude: 0.63154

Collected Steps per Second: 22,092.06162
Overall Steps per Second: 10,698.84713

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.41140
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.67583

Cumulative Model Updates: 141,482
Cumulative Timesteps: 1,179,747,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,097.52981
Policy Entropy: 3.75025
Value Function Loss: 0.01954

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.43566
Value Function Update Magnitude: 0.60026

Collected Steps per Second: 22,026.24542
Overall Steps per Second: 10,834.53409

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.34495
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.61506

Cumulative Model Updates: 141,488
Cumulative Timesteps: 1,179,797,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1179797906...
Checkpoint 1179797906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,130.90369
Policy Entropy: 3.75235
Value Function Loss: 0.01950

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.44769
Value Function Update Magnitude: 0.72406

Collected Steps per Second: 22,062.42421
Overall Steps per Second: 10,681.76435

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.41525
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.68219

Cumulative Model Updates: 141,494
Cumulative Timesteps: 1,179,847,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,975.92029
Policy Entropy: 3.75749
Value Function Loss: 0.02118

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.49393
Value Function Update Magnitude: 0.70646

Collected Steps per Second: 22,535.46316
Overall Steps per Second: 10,838.74313

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.39436
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.61308

Cumulative Model Updates: 141,500
Cumulative Timesteps: 1,179,897,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1179897920...
Checkpoint 1179897920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,642.86311
Policy Entropy: 3.76428
Value Function Loss: 0.01992

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.48770
Value Function Update Magnitude: 0.57833

Collected Steps per Second: 22,835.81493
Overall Steps per Second: 10,754.94868

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.46086
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.65163

Cumulative Model Updates: 141,506
Cumulative Timesteps: 1,179,947,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,045.93277
Policy Entropy: 3.76716
Value Function Loss: 0.01799

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.43237
Value Function Update Magnitude: 0.50186

Collected Steps per Second: 22,805.56392
Overall Steps per Second: 10,919.39098

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.38790
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.58157

Cumulative Model Updates: 141,512
Cumulative Timesteps: 1,179,997,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1179997976...
Checkpoint 1179997976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.65178
Policy Entropy: 3.77858
Value Function Loss: 0.01534

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.40261
Value Function Update Magnitude: 0.48351

Collected Steps per Second: 22,685.70765
Overall Steps per Second: 10,642.52381

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.49480
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.69945

Cumulative Model Updates: 141,518
Cumulative Timesteps: 1,180,047,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,408.65178
Policy Entropy: 3.75953
Value Function Loss: 0.01476

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.37824
Value Function Update Magnitude: 0.45954

Collected Steps per Second: 23,095.36668
Overall Steps per Second: 10,918.91945

Timestep Collection Time: 2.16494
Timestep Consumption Time: 2.41427
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.57921

Cumulative Model Updates: 141,524
Cumulative Timesteps: 1,180,097,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1180097990...
Checkpoint 1180097990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,034.99694
Policy Entropy: 3.75439
Value Function Loss: 0.01507

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.35274
Value Function Update Magnitude: 0.41111

Collected Steps per Second: 22,982.54593
Overall Steps per Second: 10,786.33820

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.63698

Cumulative Model Updates: 141,530
Cumulative Timesteps: 1,180,148,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,499.08828
Policy Entropy: 3.74526
Value Function Loss: 0.01818

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.36694
Value Function Update Magnitude: 0.37105

Collected Steps per Second: 23,291.36355
Overall Steps per Second: 10,787.07909

Timestep Collection Time: 2.14715
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.63610

Cumulative Model Updates: 141,536
Cumulative Timesteps: 1,180,198,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1180198016...
Checkpoint 1180198016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,499.08828
Policy Entropy: 3.75545
Value Function Loss: 0.01733

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.39138
Value Function Update Magnitude: 0.34173

Collected Steps per Second: 22,751.45633
Overall Steps per Second: 10,704.52856

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.67335

Cumulative Model Updates: 141,542
Cumulative Timesteps: 1,180,248,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,250.14914
Policy Entropy: 3.75347
Value Function Loss: 0.01881

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.40370
Value Function Update Magnitude: 0.36898

Collected Steps per Second: 23,261.68554
Overall Steps per Second: 10,799.86765

Timestep Collection Time: 2.14989
Timestep Consumption Time: 2.48073
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.63061

Cumulative Model Updates: 141,548
Cumulative Timesteps: 1,180,298,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1180298052...
Checkpoint 1180298052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,247.85152
Policy Entropy: 3.76889
Value Function Loss: 0.01790

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.43309
Value Function Update Magnitude: 0.43632

Collected Steps per Second: 22,842.56354
Overall Steps per Second: 10,721.20055

Timestep Collection Time: 2.18925
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.66440

Cumulative Model Updates: 141,554
Cumulative Timesteps: 1,180,348,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,790.10635
Policy Entropy: 3.79856
Value Function Loss: 0.01997

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.48504
Value Function Update Magnitude: 0.51618

Collected Steps per Second: 23,336.23338
Overall Steps per Second: 10,761.52375

Timestep Collection Time: 2.14388
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.64897

Cumulative Model Updates: 141,560
Cumulative Timesteps: 1,180,398,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1180398090...
Checkpoint 1180398090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,888.43678
Policy Entropy: 3.82212
Value Function Loss: 0.02194

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.55038
Value Function Update Magnitude: 0.58090

Collected Steps per Second: 22,640.99806
Overall Steps per Second: 10,638.53974

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.70196

Cumulative Model Updates: 141,566
Cumulative Timesteps: 1,180,448,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,364.54168
Policy Entropy: 3.81720
Value Function Loss: 0.02587

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.61127
Value Function Update Magnitude: 0.60112

Collected Steps per Second: 23,069.91855
Overall Steps per Second: 10,946.23987

Timestep Collection Time: 2.16750
Timestep Consumption Time: 2.40065
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.56814

Cumulative Model Updates: 141,572
Cumulative Timesteps: 1,180,498,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1180498116...
Checkpoint 1180498116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.32495
Policy Entropy: 3.82060
Value Function Loss: 0.02626

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.62222
Value Function Update Magnitude: 0.67979

Collected Steps per Second: 23,251.52210
Overall Steps per Second: 10,876.97951

Timestep Collection Time: 2.15281
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.60201

Cumulative Model Updates: 141,578
Cumulative Timesteps: 1,180,548,172

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,388.44726
Policy Entropy: 3.79808
Value Function Loss: 0.03205

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.61332
Value Function Update Magnitude: 0.65881

Collected Steps per Second: 22,880.88621
Overall Steps per Second: 10,681.84845

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.49621
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68196

Cumulative Model Updates: 141,584
Cumulative Timesteps: 1,180,598,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1180598184...
Checkpoint 1180598184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,536.08805
Policy Entropy: 3.79406
Value Function Loss: 0.03123

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.66792
Value Function Update Magnitude: 0.71723

Collected Steps per Second: 22,381.53317
Overall Steps per Second: 10,617.27870

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.70968

Cumulative Model Updates: 141,590
Cumulative Timesteps: 1,180,648,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,666.60954
Policy Entropy: 3.80461
Value Function Loss: 0.02914

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.65940
Value Function Update Magnitude: 0.87106

Collected Steps per Second: 22,978.73075
Overall Steps per Second: 10,873.42610

Timestep Collection Time: 2.17680
Timestep Consumption Time: 2.42341
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.60021

Cumulative Model Updates: 141,596
Cumulative Timesteps: 1,180,698,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1180698208...
Checkpoint 1180698208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.14100
Policy Entropy: 3.79713
Value Function Loss: 0.02518

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.59797
Value Function Update Magnitude: 0.73966

Collected Steps per Second: 22,867.30692
Overall Steps per Second: 10,720.10252

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.66413

Cumulative Model Updates: 141,602
Cumulative Timesteps: 1,180,748,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390.23844
Policy Entropy: 3.79707
Value Function Loss: 0.02321

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.55667
Value Function Update Magnitude: 0.61376

Collected Steps per Second: 23,224.71696
Overall Steps per Second: 10,795.89549

Timestep Collection Time: 2.15477
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.63547

Cumulative Model Updates: 141,608
Cumulative Timesteps: 1,180,798,252

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1180798252...
Checkpoint 1180798252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,826.77579
Policy Entropy: 3.78018
Value Function Loss: 0.02282

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.61864

Collected Steps per Second: 22,225.26179
Overall Steps per Second: 10,695.42251

Timestep Collection Time: 2.25032
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.67621

Cumulative Model Updates: 141,614
Cumulative Timesteps: 1,180,848,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,703.60686
Policy Entropy: 3.78122
Value Function Loss: 0.02232

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.56270
Value Function Update Magnitude: 0.67329

Collected Steps per Second: 22,490.97336
Overall Steps per Second: 10,965.27683

Timestep Collection Time: 2.22311
Timestep Consumption Time: 2.33673
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.55985

Cumulative Model Updates: 141,620
Cumulative Timesteps: 1,180,898,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1180898266...
Checkpoint 1180898266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,377.16911
Policy Entropy: 3.76806
Value Function Loss: 0.02151

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.73573

Collected Steps per Second: 22,272.24452
Overall Steps per Second: 10,791.27587

Timestep Collection Time: 2.24566
Timestep Consumption Time: 2.38919
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.63486

Cumulative Model Updates: 141,626
Cumulative Timesteps: 1,180,948,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,099.79509
Policy Entropy: 3.78856
Value Function Loss: 0.01953

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.78440

Collected Steps per Second: 22,369.52686
Overall Steps per Second: 10,753.90711

Timestep Collection Time: 2.23617
Timestep Consumption Time: 2.41535
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.65152

Cumulative Model Updates: 141,632
Cumulative Timesteps: 1,180,998,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1180998304...
Checkpoint 1180998304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,113.47556
Policy Entropy: 3.77959
Value Function Loss: 0.01865

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.64542

Collected Steps per Second: 22,115.09114
Overall Steps per Second: 10,586.70054

Timestep Collection Time: 2.26198
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.72517

Cumulative Model Updates: 141,638
Cumulative Timesteps: 1,181,048,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,113.47556
Policy Entropy: 3.78280
Value Function Loss: 0.01741

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.48451
Value Function Update Magnitude: 0.51317

Collected Steps per Second: 22,913.68342
Overall Steps per Second: 10,961.67687

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.38010
PPO Batch Consumption Time: 0.27547
Total Iteration Time: 4.56299

Cumulative Model Updates: 141,644
Cumulative Timesteps: 1,181,098,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1181098346...
Checkpoint 1181098346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,494.95956
Policy Entropy: 3.75822
Value Function Loss: 0.01820

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.45369
Value Function Update Magnitude: 0.43284

Collected Steps per Second: 22,883.53599
Overall Steps per Second: 10,727.17775

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.47697
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.66274

Cumulative Model Updates: 141,650
Cumulative Timesteps: 1,181,148,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,536.27133
Policy Entropy: 3.76554
Value Function Loss: 0.01910

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.43711
Value Function Update Magnitude: 0.48886

Collected Steps per Second: 22,903.29214
Overall Steps per Second: 10,772.03851

Timestep Collection Time: 2.18431
Timestep Consumption Time: 2.45993
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.64425

Cumulative Model Updates: 141,656
Cumulative Timesteps: 1,181,198,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1181198392...
Checkpoint 1181198392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,188.85007
Policy Entropy: 3.75945
Value Function Loss: 0.01948

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.49452
Value Function Update Magnitude: 0.60318

Collected Steps per Second: 22,742.66687
Overall Steps per Second: 10,661.68272

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69175

Cumulative Model Updates: 141,662
Cumulative Timesteps: 1,181,248,414

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,280.31632
Policy Entropy: 3.76412
Value Function Loss: 0.02374

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.59726

Collected Steps per Second: 22,698.84987
Overall Steps per Second: 10,829.15842

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.41557
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61938

Cumulative Model Updates: 141,668
Cumulative Timesteps: 1,181,298,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1181298438...
Checkpoint 1181298438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,216.46332
Policy Entropy: 3.76250
Value Function Loss: 0.02279

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.63486

Collected Steps per Second: 22,359.78090
Overall Steps per Second: 10,715.69646

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.66699

Cumulative Model Updates: 141,674
Cumulative Timesteps: 1,181,348,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,266.37126
Policy Entropy: 3.78051
Value Function Loss: 0.02492

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13542
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.57025

Collected Steps per Second: 23,156.09789
Overall Steps per Second: 10,944.69288

Timestep Collection Time: 2.15969
Timestep Consumption Time: 2.40965
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.56934

Cumulative Model Updates: 141,680
Cumulative Timesteps: 1,181,398,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1181398458...
Checkpoint 1181398458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,978.71099
Policy Entropy: 3.77644
Value Function Loss: 0.02232

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.56108

Collected Steps per Second: 22,872.96451
Overall Steps per Second: 10,737.74457

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.65852

Cumulative Model Updates: 141,686
Cumulative Timesteps: 1,181,448,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.31091
Policy Entropy: 3.77997
Value Function Loss: 0.02234

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.51026
Value Function Update Magnitude: 0.56792

Collected Steps per Second: 23,234.82143
Overall Steps per Second: 10,740.16430

Timestep Collection Time: 2.15315
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.65803

Cumulative Model Updates: 141,692
Cumulative Timesteps: 1,181,498,508

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1181498508...
Checkpoint 1181498508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.31091
Policy Entropy: 3.75558
Value Function Loss: 0.01902

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.46962
Value Function Update Magnitude: 0.53326

Collected Steps per Second: 22,864.94623
Overall Steps per Second: 10,711.56592

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.67065

Cumulative Model Updates: 141,698
Cumulative Timesteps: 1,181,548,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,877.31091
Policy Entropy: 3.74828
Value Function Loss: 0.01797

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.43150
Value Function Update Magnitude: 0.46533

Collected Steps per Second: 22,456.50932
Overall Steps per Second: 10,835.21417

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.38834
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.61514

Cumulative Model Updates: 141,704
Cumulative Timesteps: 1,181,598,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1181598544...
Checkpoint 1181598544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,928.19545
Policy Entropy: 3.74823
Value Function Loss: 0.01965

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.43688
Value Function Update Magnitude: 0.43236

Collected Steps per Second: 21,660.31204
Overall Steps per Second: 10,631.63350

Timestep Collection Time: 2.30855
Timestep Consumption Time: 2.39477
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.70332

Cumulative Model Updates: 141,710
Cumulative Timesteps: 1,181,648,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,318.45216
Policy Entropy: 3.75166
Value Function Loss: 0.02170

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.43506

Collected Steps per Second: 22,575.27469
Overall Steps per Second: 10,842.82783

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.39749
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.61319

Cumulative Model Updates: 141,716
Cumulative Timesteps: 1,181,698,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1181698568...
Checkpoint 1181698568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,896.86144
Policy Entropy: 3.76145
Value Function Loss: 0.02214

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.50726
Value Function Update Magnitude: 0.50744

Collected Steps per Second: 22,316.18332
Overall Steps per Second: 10,713.22233

Timestep Collection Time: 2.24097
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.66806

Cumulative Model Updates: 141,722
Cumulative Timesteps: 1,181,748,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,533.11617
Policy Entropy: 3.74926
Value Function Loss: 0.02297

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.49216

Collected Steps per Second: 23,103.19410
Overall Steps per Second: 10,924.80675

Timestep Collection Time: 2.16533
Timestep Consumption Time: 2.41379
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.57912

Cumulative Model Updates: 141,728
Cumulative Timesteps: 1,181,798,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1181798604...
Checkpoint 1181798604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,101.69219
Policy Entropy: 3.72968
Value Function Loss: 0.01999

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.49956
Value Function Update Magnitude: 0.40718

Collected Steps per Second: 22,802.48503
Overall Steps per Second: 10,682.57280

Timestep Collection Time: 2.19397
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.68314

Cumulative Model Updates: 141,734
Cumulative Timesteps: 1,181,848,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,101.69219
Policy Entropy: 3.73769
Value Function Loss: 0.01944

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14975
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.37515

Collected Steps per Second: 23,013.07184
Overall Steps per Second: 10,933.04377

Timestep Collection Time: 2.17363
Timestep Consumption Time: 2.40167
PPO Batch Consumption Time: 0.27578
Total Iteration Time: 4.57530

Cumulative Model Updates: 141,740
Cumulative Timesteps: 1,181,898,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1181898654...
Checkpoint 1181898654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,101.69219
Policy Entropy: 3.72418
Value Function Loss: 0.01737

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.46986
Value Function Update Magnitude: 0.47333

Collected Steps per Second: 22,613.80146
Overall Steps per Second: 10,631.60194

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.70371

Cumulative Model Updates: 141,746
Cumulative Timesteps: 1,181,948,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,758.89398
Policy Entropy: 3.74199
Value Function Loss: 0.01916

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14329
Policy Update Magnitude: 0.49959
Value Function Update Magnitude: 0.74348

Collected Steps per Second: 23,071.17531
Overall Steps per Second: 10,839.75889

Timestep Collection Time: 2.16833
Timestep Consumption Time: 2.44671
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.61505

Cumulative Model Updates: 141,752
Cumulative Timesteps: 1,181,998,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1181998688...
Checkpoint 1181998688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,100.84843
Policy Entropy: 3.74475
Value Function Loss: 0.02041

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.84978

Collected Steps per Second: 22,643.26016
Overall Steps per Second: 10,635.96983

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70535

Cumulative Model Updates: 141,758
Cumulative Timesteps: 1,182,048,734

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,563.50915
Policy Entropy: 3.75989
Value Function Loss: 0.02232

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.62688
Value Function Update Magnitude: 0.79734

Collected Steps per Second: 23,031.43210
Overall Steps per Second: 10,877.67523

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.42562
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.59657

Cumulative Model Updates: 141,764
Cumulative Timesteps: 1,182,098,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1182098734...
Checkpoint 1182098734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,445.89118
Policy Entropy: 3.75575
Value Function Loss: 0.02011

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.71733

Collected Steps per Second: 22,909.03521
Overall Steps per Second: 10,674.04781

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.68538

Cumulative Model Updates: 141,770
Cumulative Timesteps: 1,182,148,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,222.49134
Policy Entropy: 3.76031
Value Function Loss: 0.02043

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.53769
Value Function Update Magnitude: 0.70041

Collected Steps per Second: 22,836.00548
Overall Steps per Second: 10,838.45983

Timestep Collection Time: 2.19084
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.61597

Cumulative Model Updates: 141,776
Cumulative Timesteps: 1,182,198,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1182198776...
Checkpoint 1182198776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,939.23472
Policy Entropy: 3.76574
Value Function Loss: 0.01881

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.51544
Value Function Update Magnitude: 0.71513

Collected Steps per Second: 22,574.49328
Overall Steps per Second: 10,728.81512

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.66202

Cumulative Model Updates: 141,782
Cumulative Timesteps: 1,182,248,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,302.51372
Policy Entropy: 3.75898
Value Function Loss: 0.02133

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.63773

Collected Steps per Second: 20,989.44649
Overall Steps per Second: 10,349.83639

Timestep Collection Time: 2.38301
Timestep Consumption Time: 2.44973
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.83273

Cumulative Model Updates: 141,788
Cumulative Timesteps: 1,182,298,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1182298812...
Checkpoint 1182298812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,163.31636
Policy Entropy: 3.75138
Value Function Loss: 0.01960

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.49761
Value Function Update Magnitude: 0.61414

Collected Steps per Second: 21,803.13496
Overall Steps per Second: 10,508.00686

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.75828

Cumulative Model Updates: 141,794
Cumulative Timesteps: 1,182,348,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,244.97552
Policy Entropy: 3.74214
Value Function Loss: 0.02228

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.49423
Value Function Update Magnitude: 0.51879

Collected Steps per Second: 23,326.84189
Overall Steps per Second: 10,838.27284

Timestep Collection Time: 2.14354
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.61347

Cumulative Model Updates: 141,800
Cumulative Timesteps: 1,182,398,814

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1182398814...
Checkpoint 1182398814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,054.66348
Policy Entropy: 3.75176
Value Function Loss: 0.02122

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.52295
Value Function Update Magnitude: 0.54244

Collected Steps per Second: 22,819.67190
Overall Steps per Second: 10,863.11727

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.41280
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.60494

Cumulative Model Updates: 141,806
Cumulative Timesteps: 1,182,448,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,382.54947
Policy Entropy: 3.75002
Value Function Loss: 0.02487

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.59521
Value Function Update Magnitude: 0.67545

Collected Steps per Second: 22,862.66328
Overall Steps per Second: 10,752.52033

Timestep Collection Time: 2.18741
Timestep Consumption Time: 2.46359
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.65100

Cumulative Model Updates: 141,812
Cumulative Timesteps: 1,182,498,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1182498848...
Checkpoint 1182498848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,486.57801
Policy Entropy: 3.76202
Value Function Loss: 0.02384

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.63423
Value Function Update Magnitude: 0.74870

Collected Steps per Second: 22,551.32802
Overall Steps per Second: 10,813.74981

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.40677
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.62411

Cumulative Model Updates: 141,818
Cumulative Timesteps: 1,182,548,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,927.30889
Policy Entropy: 3.75876
Value Function Loss: 0.02723

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.63420
Value Function Update Magnitude: 0.72654

Collected Steps per Second: 22,727.43382
Overall Steps per Second: 10,706.53499

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.67191

Cumulative Model Updates: 141,824
Cumulative Timesteps: 1,182,598,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1182598872...
Checkpoint 1182598872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,536.95356
Policy Entropy: 3.75214
Value Function Loss: 0.02692

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.69528
Value Function Update Magnitude: 0.64948

Collected Steps per Second: 22,906.63443
Overall Steps per Second: 10,888.54179

Timestep Collection Time: 2.18408
Timestep Consumption Time: 2.41065
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59474

Cumulative Model Updates: 141,830
Cumulative Timesteps: 1,182,648,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,594.12769
Policy Entropy: 3.75857
Value Function Loss: 0.02719

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.74400
Value Function Update Magnitude: 0.58690

Collected Steps per Second: 22,300.30862
Overall Steps per Second: 10,891.95813

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.34927
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.59220

Cumulative Model Updates: 141,836
Cumulative Timesteps: 1,182,698,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1182698920...
Checkpoint 1182698920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,515.15541
Policy Entropy: 3.77386
Value Function Loss: 0.02528

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.72041
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 21,763.77310
Overall Steps per Second: 10,711.11822

Timestep Collection Time: 2.29868
Timestep Consumption Time: 2.37198
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.67066

Cumulative Model Updates: 141,842
Cumulative Timesteps: 1,182,748,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,892.49790
Policy Entropy: 3.79275
Value Function Loss: 0.02701

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12903
Policy Update Magnitude: 0.72994
Value Function Update Magnitude: 0.75801

Collected Steps per Second: 22,206.96248
Overall Steps per Second: 10,876.73147

Timestep Collection Time: 2.25299
Timestep Consumption Time: 2.34692
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.59991

Cumulative Model Updates: 141,848
Cumulative Timesteps: 1,182,798,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1182798980...
Checkpoint 1182798980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,503.35879
Policy Entropy: 3.79611
Value Function Loss: 0.02673

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.75227
Value Function Update Magnitude: 0.88122

Collected Steps per Second: 21,986.81494
Overall Steps per Second: 10,635.94160

Timestep Collection Time: 2.27555
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.70405

Cumulative Model Updates: 141,854
Cumulative Timesteps: 1,182,849,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.62451
Policy Entropy: 3.78117
Value Function Loss: 0.03058

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.74205
Value Function Update Magnitude: 0.84940

Collected Steps per Second: 22,157.30392
Overall Steps per Second: 10,870.94635

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.34395
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60162

Cumulative Model Updates: 141,860
Cumulative Timesteps: 1,182,899,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1182899036...
Checkpoint 1182899036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,161.95739
Policy Entropy: 3.78207
Value Function Loss: 0.03089

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.71391
Value Function Update Magnitude: 0.68646

Collected Steps per Second: 21,944.16512
Overall Steps per Second: 10,725.87206

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.38426
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.66386

Cumulative Model Updates: 141,866
Cumulative Timesteps: 1,182,949,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,372.13117
Policy Entropy: 3.78050
Value Function Loss: 0.03219

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.69047
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 23,196.29256
Overall Steps per Second: 10,888.14571

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.43771
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.59417

Cumulative Model Updates: 141,872
Cumulative Timesteps: 1,182,999,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1182999082...
Checkpoint 1182999082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,225.58918
Policy Entropy: 3.79278
Value Function Loss: 0.02879

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.70439
Value Function Update Magnitude: 0.55854

Collected Steps per Second: 22,894.29550
Overall Steps per Second: 10,764.27446

Timestep Collection Time: 2.18509
Timestep Consumption Time: 2.46232
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.64741

Cumulative Model Updates: 141,878
Cumulative Timesteps: 1,183,049,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,082.61652
Policy Entropy: 3.79046
Value Function Loss: 0.02844

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.65901
Value Function Update Magnitude: 0.53676

Collected Steps per Second: 22,915.41450
Overall Steps per Second: 10,799.70757

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.63142

Cumulative Model Updates: 141,884
Cumulative Timesteps: 1,183,099,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1183099126...
Checkpoint 1183099126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,389.92879
Policy Entropy: 3.78015
Value Function Loss: 0.02679

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.62729
Value Function Update Magnitude: 0.50142

Collected Steps per Second: 22,821.20689
Overall Steps per Second: 10,697.41772

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.48308
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.67403

Cumulative Model Updates: 141,890
Cumulative Timesteps: 1,183,149,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.62355
Policy Entropy: 3.80078
Value Function Loss: 0.02360

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.58206
Value Function Update Magnitude: 0.48126

Collected Steps per Second: 23,046.29951
Overall Steps per Second: 10,837.67818

Timestep Collection Time: 2.16955
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.61353

Cumulative Model Updates: 141,896
Cumulative Timesteps: 1,183,199,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1183199126...
Checkpoint 1183199126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,149.22821
Policy Entropy: 3.78007
Value Function Loss: 0.02278

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.44284

Collected Steps per Second: 22,754.01544
Overall Steps per Second: 10,668.72392

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.68922

Cumulative Model Updates: 141,902
Cumulative Timesteps: 1,183,249,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,211.74435
Policy Entropy: 3.77244
Value Function Loss: 0.02058

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15548
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.45867

Collected Steps per Second: 22,992.17501
Overall Steps per Second: 10,860.70466

Timestep Collection Time: 2.17526
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.60504

Cumulative Model Updates: 141,908
Cumulative Timesteps: 1,183,299,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1183299168...
Checkpoint 1183299168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,752.56194
Policy Entropy: 3.74202
Value Function Loss: 0.02316

Mean KL Divergence: 0.02796
SB3 Clip Fraction: 0.27054
Policy Update Magnitude: 0.47617
Value Function Update Magnitude: 0.59582

Collected Steps per Second: 22,713.99657
Overall Steps per Second: 10,671.07390

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.68781

Cumulative Model Updates: 141,914
Cumulative Timesteps: 1,183,349,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,428.29277
Policy Entropy: 3.78844
Value Function Loss: 0.02841

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.20264
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.57821

Collected Steps per Second: 22,818.72899
Overall Steps per Second: 10,818.31072

Timestep Collection Time: 2.19171
Timestep Consumption Time: 2.43119
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62290

Cumulative Model Updates: 141,920
Cumulative Timesteps: 1,183,399,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1183399204...
Checkpoint 1183399204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,347.21054
Policy Entropy: 3.81025
Value Function Loss: 0.03056

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.18821
Policy Update Magnitude: 0.73266
Value Function Update Magnitude: 0.49257

Collected Steps per Second: 22,552.01523
Overall Steps per Second: 10,679.23939

Timestep Collection Time: 2.21745
Timestep Consumption Time: 2.46528
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.68273

Cumulative Model Updates: 141,926
Cumulative Timesteps: 1,183,449,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,070.81714
Policy Entropy: 3.81994
Value Function Loss: 0.02905

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.15618
Policy Update Magnitude: 0.77513
Value Function Update Magnitude: 0.48462

Collected Steps per Second: 22,386.44117
Overall Steps per Second: 10,560.96613

Timestep Collection Time: 2.23439
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73631

Cumulative Model Updates: 141,932
Cumulative Timesteps: 1,183,499,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1183499232...
Checkpoint 1183499232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,376.48313
Policy Entropy: 3.82140
Value Function Loss: 0.02670

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.77138
Value Function Update Magnitude: 0.67450

Collected Steps per Second: 22,307.10823
Overall Steps per Second: 10,529.52961

Timestep Collection Time: 2.24207
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.74988

Cumulative Model Updates: 141,938
Cumulative Timesteps: 1,183,549,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,590.43165
Policy Entropy: 3.82112
Value Function Loss: 0.02534

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.89657
Value Function Update Magnitude: 0.73480

Collected Steps per Second: 22,821.03302
Overall Steps per Second: 10,831.49269

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.61765

Cumulative Model Updates: 141,944
Cumulative Timesteps: 1,183,599,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1183599262...
Checkpoint 1183599262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,496.77236
Policy Entropy: 3.83016
Value Function Loss: 0.02379

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.88270
Value Function Update Magnitude: 0.64463

Collected Steps per Second: 22,709.41447
Overall Steps per Second: 10,737.96516

Timestep Collection Time: 2.20270
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.65842

Cumulative Model Updates: 141,950
Cumulative Timesteps: 1,183,649,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,638.06894
Policy Entropy: 3.82488
Value Function Loss: 0.01939

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.79177
Value Function Update Magnitude: 0.60900

Collected Steps per Second: 23,017.88775
Overall Steps per Second: 10,885.26165

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.59576

Cumulative Model Updates: 141,956
Cumulative Timesteps: 1,183,699,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1183699310...
Checkpoint 1183699310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.60326
Policy Entropy: 3.78847
Value Function Loss: 0.01762

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.65774
Value Function Update Magnitude: 0.57705

Collected Steps per Second: 22,947.42466
Overall Steps per Second: 10,726.55099

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.48343
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.66320

Cumulative Model Updates: 141,962
Cumulative Timesteps: 1,183,749,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,472.11294
Policy Entropy: 3.77155
Value Function Loss: 0.02318

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.50794

Collected Steps per Second: 22,920.29965
Overall Steps per Second: 10,863.93616

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.60441

Cumulative Model Updates: 141,968
Cumulative Timesteps: 1,183,799,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1183799352...
Checkpoint 1183799352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.44218
Policy Entropy: 3.78033
Value Function Loss: 0.02602

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.64710
Value Function Update Magnitude: 0.49788

Collected Steps per Second: 22,700.38250
Overall Steps per Second: 10,735.42121

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.65934

Cumulative Model Updates: 141,974
Cumulative Timesteps: 1,183,849,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,366.72430
Policy Entropy: 3.77441
Value Function Loss: 0.03497

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.66334
Value Function Update Magnitude: 0.49644

Collected Steps per Second: 22,912.10290
Overall Steps per Second: 10,820.39137

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.62220

Cumulative Model Updates: 141,980
Cumulative Timesteps: 1,183,899,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1183899386...
Checkpoint 1183899386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,333.04120
Policy Entropy: 3.80574
Value Function Loss: 0.03147

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.70448
Value Function Update Magnitude: 0.67184

Collected Steps per Second: 22,914.27652
Overall Steps per Second: 10,811.73923

Timestep Collection Time: 2.18283
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.62627

Cumulative Model Updates: 141,986
Cumulative Timesteps: 1,183,949,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,679.01226
Policy Entropy: 3.78554
Value Function Loss: 0.03166

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.67486
Value Function Update Magnitude: 0.62963

Collected Steps per Second: 22,809.02714
Overall Steps per Second: 10,701.65528

Timestep Collection Time: 2.19290
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67386

Cumulative Model Updates: 141,992
Cumulative Timesteps: 1,183,999,422

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1183999422...
Checkpoint 1183999422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,965.08469
Policy Entropy: 3.79593
Value Function Loss: 0.02466

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.59921
Value Function Update Magnitude: 0.58334

Collected Steps per Second: 23,026.78440
Overall Steps per Second: 10,742.91287

Timestep Collection Time: 2.17330
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.65833

Cumulative Model Updates: 141,998
Cumulative Timesteps: 1,184,049,466

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,901.18036
Policy Entropy: 3.76258
Value Function Loss: 0.02472

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.54679

Collected Steps per Second: 22,979.36581
Overall Steps per Second: 10,811.18010

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.62540

Cumulative Model Updates: 142,004
Cumulative Timesteps: 1,184,099,472

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1184099472...
Checkpoint 1184099472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,479.91740
Policy Entropy: 3.76385
Value Function Loss: 0.02426

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.54755
Value Function Update Magnitude: 0.56395

Collected Steps per Second: 22,868.71877
Overall Steps per Second: 10,696.28509

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.67583

Cumulative Model Updates: 142,010
Cumulative Timesteps: 1,184,149,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,370.30066
Policy Entropy: 3.78563
Value Function Loss: 0.02216

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.66500

Collected Steps per Second: 22,896.24022
Overall Steps per Second: 10,817.76361

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.43836
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.62221

Cumulative Model Updates: 142,016
Cumulative Timesteps: 1,184,199,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1184199488...
Checkpoint 1184199488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,454.07984
Policy Entropy: 3.79482
Value Function Loss: 0.02050

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.49099
Value Function Update Magnitude: 0.71322

Collected Steps per Second: 23,117.30333
Overall Steps per Second: 10,776.44569

Timestep Collection Time: 2.16383
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.64179

Cumulative Model Updates: 142,022
Cumulative Timesteps: 1,184,249,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,098.19240
Policy Entropy: 3.80234
Value Function Loss: 0.01921

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.47758
Value Function Update Magnitude: 0.69206

Collected Steps per Second: 23,057.65312
Overall Steps per Second: 10,818.87767

Timestep Collection Time: 2.16978
Timestep Consumption Time: 2.45455
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.62432

Cumulative Model Updates: 142,028
Cumulative Timesteps: 1,184,299,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1184299540...
Checkpoint 1184299540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,048.07247
Policy Entropy: 3.78136
Value Function Loss: 0.02103

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.48324
Value Function Update Magnitude: 0.72425

Collected Steps per Second: 22,908.50725
Overall Steps per Second: 10,734.42084

Timestep Collection Time: 2.18286
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.65847

Cumulative Model Updates: 142,034
Cumulative Timesteps: 1,184,349,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,860.71547
Policy Entropy: 3.78643
Value Function Loss: 0.01786

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.49850
Value Function Update Magnitude: 0.77498

Collected Steps per Second: 23,198.15012
Overall Steps per Second: 10,781.83529

Timestep Collection Time: 2.15552
Timestep Consumption Time: 2.48228
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.63780

Cumulative Model Updates: 142,040
Cumulative Timesteps: 1,184,399,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1184399550...
Checkpoint 1184399550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.87760
Policy Entropy: 3.77175
Value Function Loss: 0.01722

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.45079
Value Function Update Magnitude: 0.68932

Collected Steps per Second: 22,796.37094
Overall Steps per Second: 10,663.75305

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.68897

Cumulative Model Updates: 142,046
Cumulative Timesteps: 1,184,449,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,163.12347
Policy Entropy: 3.77080
Value Function Loss: 0.01649

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.41065
Value Function Update Magnitude: 0.65081

Collected Steps per Second: 23,010.29187
Overall Steps per Second: 10,933.99396

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.40043
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.57381

Cumulative Model Updates: 142,052
Cumulative Timesteps: 1,184,499,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1184499562...
Checkpoint 1184499562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,943.53553
Policy Entropy: 3.75220
Value Function Loss: 0.01711

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.42882
Value Function Update Magnitude: 0.76800

Collected Steps per Second: 23,122.30211
Overall Steps per Second: 10,820.91632

Timestep Collection Time: 2.16345
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.62290

Cumulative Model Updates: 142,058
Cumulative Timesteps: 1,184,549,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,684.69532
Policy Entropy: 3.76822
Value Function Loss: 0.01885

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.46869
Value Function Update Magnitude: 0.78157

Collected Steps per Second: 23,076.88864
Overall Steps per Second: 10,763.62757

Timestep Collection Time: 2.16693
Timestep Consumption Time: 2.47890
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.64583

Cumulative Model Updates: 142,064
Cumulative Timesteps: 1,184,599,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1184599592...
Checkpoint 1184599592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,674.65727
Policy Entropy: 3.76583
Value Function Loss: 0.01791

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.87655

Collected Steps per Second: 23,031.56020
Overall Steps per Second: 10,884.27580

Timestep Collection Time: 2.17111
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.59415

Cumulative Model Updates: 142,070
Cumulative Timesteps: 1,184,649,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,331.65224
Policy Entropy: 3.75960
Value Function Loss: 0.02043

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13804
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.81739

Collected Steps per Second: 22,765.52839
Overall Steps per Second: 10,701.55995

Timestep Collection Time: 2.19736
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.67446

Cumulative Model Updates: 142,076
Cumulative Timesteps: 1,184,699,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1184699620...
Checkpoint 1184699620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,139.14508
Policy Entropy: 3.75644
Value Function Loss: 0.02103

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.52021
Value Function Update Magnitude: 0.76388

Collected Steps per Second: 22,976.54248
Overall Steps per Second: 10,898.05690

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.58852

Cumulative Model Updates: 142,082
Cumulative Timesteps: 1,184,749,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,763.14111
Policy Entropy: 3.77288
Value Function Loss: 0.02222

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.53196
Value Function Update Magnitude: 0.79536

Collected Steps per Second: 22,424.22990
Overall Steps per Second: 10,927.94257

Timestep Collection Time: 2.23036
Timestep Consumption Time: 2.34635
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.57671

Cumulative Model Updates: 142,088
Cumulative Timesteps: 1,184,799,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1184799640...
Checkpoint 1184799640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.26607
Policy Entropy: 3.77001
Value Function Loss: 0.01983

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.84274

Collected Steps per Second: 22,164.07693
Overall Steps per Second: 10,684.31627

Timestep Collection Time: 2.25626
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68051

Cumulative Model Updates: 142,094
Cumulative Timesteps: 1,184,849,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,930.11905
Policy Entropy: 3.76738
Value Function Loss: 0.01920

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.52116
Value Function Update Magnitude: 0.75395

Collected Steps per Second: 22,346.86405
Overall Steps per Second: 10,902.23471

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.34895
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.58658

Cumulative Model Updates: 142,100
Cumulative Timesteps: 1,184,899,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1184899652...
Checkpoint 1184899652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,041.05746
Policy Entropy: 3.74967
Value Function Loss: 0.01881

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.50767
Value Function Update Magnitude: 0.67122

Collected Steps per Second: 22,501.92085
Overall Steps per Second: 10,668.78962

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.46572
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.68882

Cumulative Model Updates: 142,106
Cumulative Timesteps: 1,184,949,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,164.92634
Policy Entropy: 3.74533
Value Function Loss: 0.01891

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.78251

Collected Steps per Second: 23,109.05837
Overall Steps per Second: 10,920.97055

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.57908

Cumulative Model Updates: 142,112
Cumulative Timesteps: 1,184,999,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1184999684...
Checkpoint 1184999684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,164.92634
Policy Entropy: 3.73949
Value Function Loss: 0.01644

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.52058
Value Function Update Magnitude: 0.80769

Collected Steps per Second: 23,061.80086
Overall Steps per Second: 10,801.45276

Timestep Collection Time: 2.16843
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.62975

Cumulative Model Updates: 142,118
Cumulative Timesteps: 1,185,049,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,164.92634
Policy Entropy: 3.74236
Value Function Loss: 0.01460

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13901
Policy Update Magnitude: 0.45909
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 22,780.41103
Overall Steps per Second: 10,729.83154

Timestep Collection Time: 2.19504
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.66028

Cumulative Model Updates: 142,124
Cumulative Timesteps: 1,185,099,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1185099696...
Checkpoint 1185099696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,164.92634
Policy Entropy: 3.74429
Value Function Loss: 0.01216

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.39612
Value Function Update Magnitude: 0.47361

Collected Steps per Second: 22,851.38446
Overall Steps per Second: 10,706.32120

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.48328
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.67238

Cumulative Model Updates: 142,130
Cumulative Timesteps: 1,185,149,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,164.92634
Policy Entropy: 3.73513
Value Function Loss: 0.01241

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.37837
Value Function Update Magnitude: 0.41858

Collected Steps per Second: 22,897.55915
Overall Steps per Second: 10,896.57336

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.59117

Cumulative Model Updates: 142,136
Cumulative Timesteps: 1,185,199,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1185199748...
Checkpoint 1185199748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322,541.35369
Policy Entropy: 3.73971
Value Function Loss: 0.01488

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.41601
Value Function Update Magnitude: 0.53834

Collected Steps per Second: 23,054.36069
Overall Steps per Second: 10,946.73975

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.39897
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.56794

Cumulative Model Updates: 142,142
Cumulative Timesteps: 1,185,249,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,398.24325
Policy Entropy: 3.73830
Value Function Loss: 0.01858

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.48784
Value Function Update Magnitude: 0.58734

Collected Steps per Second: 22,868.40417
Overall Steps per Second: 10,791.36629

Timestep Collection Time: 2.18721
Timestep Consumption Time: 2.44779
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.63500

Cumulative Model Updates: 142,148
Cumulative Timesteps: 1,185,299,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1185299770...
Checkpoint 1185299770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,157.47924
Policy Entropy: 3.74493
Value Function Loss: 0.02087

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.69255

Collected Steps per Second: 22,167.29485
Overall Steps per Second: 10,843.73200

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.35548
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.61114

Cumulative Model Updates: 142,154
Cumulative Timesteps: 1,185,349,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,131.87059
Policy Entropy: 3.74702
Value Function Loss: 0.02484

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.63206
Value Function Update Magnitude: 0.80496

Collected Steps per Second: 22,407.11565
Overall Steps per Second: 10,958.19116

Timestep Collection Time: 2.23188
Timestep Consumption Time: 2.33183
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.56371

Cumulative Model Updates: 142,160
Cumulative Timesteps: 1,185,399,782

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1185399782...
Checkpoint 1185399782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,010.86380
Policy Entropy: 3.75616
Value Function Loss: 0.02486

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.67705
Value Function Update Magnitude: 0.79666

Collected Steps per Second: 22,409.45668
Overall Steps per Second: 10,943.81784

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.33778
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.56916

Cumulative Model Updates: 142,166
Cumulative Timesteps: 1,185,449,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,019.60653
Policy Entropy: 3.75531
Value Function Loss: 0.02600

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.66075
Value Function Update Magnitude: 0.77639

Collected Steps per Second: 21,639.93034
Overall Steps per Second: 10,563.21401

Timestep Collection Time: 2.31147
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.73530

Cumulative Model Updates: 142,172
Cumulative Timesteps: 1,185,499,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1185499806...
Checkpoint 1185499806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,731.01944
Policy Entropy: 3.74047
Value Function Loss: 0.02345

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.59489
Value Function Update Magnitude: 0.68437

Collected Steps per Second: 22,184.14892
Overall Steps per Second: 10,656.97930

Timestep Collection Time: 2.25512
Timestep Consumption Time: 2.43926
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.69439

Cumulative Model Updates: 142,178
Cumulative Timesteps: 1,185,549,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,731.01944
Policy Entropy: 3.72614
Value Function Loss: 0.02360

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.55773

Collected Steps per Second: 23,032.62744
Overall Steps per Second: 10,895.62290

Timestep Collection Time: 2.17205
Timestep Consumption Time: 2.41952
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.59157

Cumulative Model Updates: 142,184
Cumulative Timesteps: 1,185,599,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1185599862...
Checkpoint 1185599862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,865.41814
Policy Entropy: 3.72818
Value Function Loss: 0.01947

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.49750
Value Function Update Magnitude: 0.44656

Collected Steps per Second: 22,900.77979
Overall Steps per Second: 10,806.35183

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.44397
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.62765

Cumulative Model Updates: 142,190
Cumulative Timesteps: 1,185,649,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,092.39975
Policy Entropy: 3.74220
Value Function Loss: 0.01801

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.46849
Value Function Update Magnitude: 0.40368

Collected Steps per Second: 22,718.67543
Overall Steps per Second: 10,765.29645

Timestep Collection Time: 2.20101
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.64493

Cumulative Model Updates: 142,196
Cumulative Timesteps: 1,185,699,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1185699874...
Checkpoint 1185699874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,234.58669
Policy Entropy: 3.76555
Value Function Loss: 0.01750

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.44996
Value Function Update Magnitude: 0.40308

Collected Steps per Second: 23,085.64485
Overall Steps per Second: 10,744.73225

Timestep Collection Time: 2.16611
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.65400

Cumulative Model Updates: 142,202
Cumulative Timesteps: 1,185,749,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,817.70134
Policy Entropy: 3.75573
Value Function Loss: 0.01925

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.46159
Value Function Update Magnitude: 0.49406

Collected Steps per Second: 23,043.96904
Overall Steps per Second: 10,757.20093

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.47838
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.64824

Cumulative Model Updates: 142,208
Cumulative Timesteps: 1,185,799,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1185799882...
Checkpoint 1185799882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,001.55888
Policy Entropy: 3.74983
Value Function Loss: 0.01996

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.53269
Value Function Update Magnitude: 0.64553

Collected Steps per Second: 23,141.73873
Overall Steps per Second: 10,776.50711

Timestep Collection Time: 2.16189
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.64251

Cumulative Model Updates: 142,214
Cumulative Timesteps: 1,185,849,912

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,001.55888
Policy Entropy: 3.72143
Value Function Loss: 0.01980

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.64969

Collected Steps per Second: 22,946.92519
Overall Steps per Second: 10,779.84788

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.63903

Cumulative Model Updates: 142,220
Cumulative Timesteps: 1,185,899,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1185899920...
Checkpoint 1185899920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,001.55888
Policy Entropy: 3.72177
Value Function Loss: 0.01921

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.45545
Value Function Update Magnitude: 0.51195

Collected Steps per Second: 22,721.89887
Overall Steps per Second: 10,665.35521

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.48845
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68976

Cumulative Model Updates: 142,226
Cumulative Timesteps: 1,185,949,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,001.55888
Policy Entropy: 3.73357
Value Function Loss: 0.01622

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.40311
Value Function Update Magnitude: 0.35674

Collected Steps per Second: 22,528.49162
Overall Steps per Second: 10,792.73698

Timestep Collection Time: 2.21977
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.63349

Cumulative Model Updates: 142,232
Cumulative Timesteps: 1,185,999,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1185999946...
Checkpoint 1185999946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,001.55888
Policy Entropy: 3.73629
Value Function Loss: 0.01447

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.37287
Value Function Update Magnitude: 0.25451

Collected Steps per Second: 22,992.88392
Overall Steps per Second: 10,728.99830

Timestep Collection Time: 2.17537
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.66194

Cumulative Model Updates: 142,238
Cumulative Timesteps: 1,186,049,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,265.81791
Policy Entropy: 3.74581
Value Function Loss: 0.01313

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.39368
Value Function Update Magnitude: 0.30518

Collected Steps per Second: 22,974.43694
Overall Steps per Second: 10,901.71437

Timestep Collection Time: 2.17633
Timestep Consumption Time: 2.41010
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.58643

Cumulative Model Updates: 142,244
Cumulative Timesteps: 1,186,099,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1186099964...
Checkpoint 1186099964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,780.01396
Policy Entropy: 3.74448
Value Function Loss: 0.01339

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.41985
Value Function Update Magnitude: 0.33776

Collected Steps per Second: 22,111.14433
Overall Steps per Second: 10,718.06744

Timestep Collection Time: 2.26194
Timestep Consumption Time: 2.40439
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.66633

Cumulative Model Updates: 142,250
Cumulative Timesteps: 1,186,149,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,393.63453
Policy Entropy: 3.73906
Value Function Loss: 0.01747

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.44512
Value Function Update Magnitude: 0.39930

Collected Steps per Second: 22,170.09866
Overall Steps per Second: 10,855.11733

Timestep Collection Time: 2.25592
Timestep Consumption Time: 2.35149
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.60741

Cumulative Model Updates: 142,256
Cumulative Timesteps: 1,186,199,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1186199992...
Checkpoint 1186199992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,471.63620
Policy Entropy: 3.75432
Value Function Loss: 0.01925

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.51082
Value Function Update Magnitude: 0.46224

Collected Steps per Second: 22,362.05810
Overall Steps per Second: 10,818.16200

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.38707
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.62408

Cumulative Model Updates: 142,262
Cumulative Timesteps: 1,186,250,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,648.80052
Policy Entropy: 3.74495
Value Function Loss: 0.02677

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.59839
Value Function Update Magnitude: 0.54661

Collected Steps per Second: 22,259.06800
Overall Steps per Second: 10,793.24759

Timestep Collection Time: 2.24708
Timestep Consumption Time: 2.38711
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.63419

Cumulative Model Updates: 142,268
Cumulative Timesteps: 1,186,300,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1186300034...
Checkpoint 1186300034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,725.03993
Policy Entropy: 3.78220
Value Function Loss: 0.02862

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.65260
Value Function Update Magnitude: 0.65772

Collected Steps per Second: 22,808.01886
Overall Steps per Second: 10,917.86334

Timestep Collection Time: 2.19256
Timestep Consumption Time: 2.38782
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.58038

Cumulative Model Updates: 142,274
Cumulative Timesteps: 1,186,350,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,824.12840
Policy Entropy: 3.77816
Value Function Loss: 0.03220

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.69668
Value Function Update Magnitude: 0.65739

Collected Steps per Second: 23,093.47551
Overall Steps per Second: 10,965.70651

Timestep Collection Time: 2.16529
Timestep Consumption Time: 2.39475
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.56003

Cumulative Model Updates: 142,280
Cumulative Timesteps: 1,186,400,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1186400046...
Checkpoint 1186400046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.43387
Policy Entropy: 3.80015
Value Function Loss: 0.02705

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.67006
Value Function Update Magnitude: 0.79377

Collected Steps per Second: 22,954.29823
Overall Steps per Second: 10,760.40249

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.46882
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.64741

Cumulative Model Updates: 142,286
Cumulative Timesteps: 1,186,450,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,287.36807
Policy Entropy: 3.77818
Value Function Loss: 0.02729

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.64093
Value Function Update Magnitude: 0.64913

Collected Steps per Second: 23,048.09728
Overall Steps per Second: 10,834.35371

Timestep Collection Time: 2.17103
Timestep Consumption Time: 2.44743
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.61846

Cumulative Model Updates: 142,292
Cumulative Timesteps: 1,186,500,092

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1186500092...
Checkpoint 1186500092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,277.59117
Policy Entropy: 3.77241
Value Function Loss: 0.02362

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.59805
Value Function Update Magnitude: 0.49190

Collected Steps per Second: 22,711.74100
Overall Steps per Second: 10,637.20563

Timestep Collection Time: 2.20194
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.70142

Cumulative Model Updates: 142,298
Cumulative Timesteps: 1,186,550,102

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,381.15567
Policy Entropy: 3.76572
Value Function Loss: 0.02571

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.55206
Value Function Update Magnitude: 0.46910

Collected Steps per Second: 22,973.44904
Overall Steps per Second: 10,874.83791

Timestep Collection Time: 2.17660
Timestep Consumption Time: 2.42154
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.59814

Cumulative Model Updates: 142,304
Cumulative Timesteps: 1,186,600,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1186600106...
Checkpoint 1186600106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,581.10111
Policy Entropy: 3.75066
Value Function Loss: 0.02322

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.64873

Collected Steps per Second: 22,915.07264
Overall Steps per Second: 10,712.82909

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.48652
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66954

Cumulative Model Updates: 142,310
Cumulative Timesteps: 1,186,650,130

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,301.63778
Policy Entropy: 3.76696
Value Function Loss: 0.02967

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.60957
Value Function Update Magnitude: 0.62814

Collected Steps per Second: 22,977.75177
Overall Steps per Second: 10,906.64900

Timestep Collection Time: 2.17637
Timestep Consumption Time: 2.40873
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.58509

Cumulative Model Updates: 142,316
Cumulative Timesteps: 1,186,700,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1186700138...
Checkpoint 1186700138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473.85814
Policy Entropy: 3.79224
Value Function Loss: 0.02595

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12191
Policy Update Magnitude: 0.67618
Value Function Update Magnitude: 0.61274

Collected Steps per Second: 22,893.22438
Overall Steps per Second: 10,735.44564

Timestep Collection Time: 2.18458
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.65859

Cumulative Model Updates: 142,322
Cumulative Timesteps: 1,186,750,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,203.38311
Policy Entropy: 3.79660
Value Function Loss: 0.03038

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.65494
Value Function Update Magnitude: 0.59300

Collected Steps per Second: 22,457.05111
Overall Steps per Second: 10,745.61363

Timestep Collection Time: 2.22647
Timestep Consumption Time: 2.42659
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.65306

Cumulative Model Updates: 142,328
Cumulative Timesteps: 1,186,800,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1186800150...
Checkpoint 1186800150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,476.32081
Policy Entropy: 3.79832
Value Function Loss: 0.02794

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.63746
Value Function Update Magnitude: 0.58285

Collected Steps per Second: 23,060.57524
Overall Steps per Second: 10,773.72794

Timestep Collection Time: 2.16933
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.64333

Cumulative Model Updates: 142,334
Cumulative Timesteps: 1,186,850,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,112.66993
Policy Entropy: 3.79142
Value Function Loss: 0.02836

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.65170
Value Function Update Magnitude: 0.59068

Collected Steps per Second: 22,785.71878
Overall Steps per Second: 10,723.46934

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.66509

Cumulative Model Updates: 142,340
Cumulative Timesteps: 1,186,900,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1186900202...
Checkpoint 1186900202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,008.86091
Policy Entropy: 3.80190
Value Function Loss: 0.02591

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11777
Policy Update Magnitude: 0.62162
Value Function Update Magnitude: 0.59038

Collected Steps per Second: 22,811.74901
Overall Steps per Second: 10,705.54798

Timestep Collection Time: 2.19212
Timestep Consumption Time: 2.47892
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.67104

Cumulative Model Updates: 142,346
Cumulative Timesteps: 1,186,950,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,104.22096
Policy Entropy: 3.79940
Value Function Loss: 0.02533

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.59593
Value Function Update Magnitude: 0.58482

Collected Steps per Second: 22,740.03923
Overall Steps per Second: 10,806.97239

Timestep Collection Time: 2.19929
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.62775

Cumulative Model Updates: 142,352
Cumulative Timesteps: 1,187,000,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1187000220...
Checkpoint 1187000220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.41960
Policy Entropy: 3.80538
Value Function Loss: 0.02462

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.56129

Collected Steps per Second: 22,655.63329
Overall Steps per Second: 10,708.90237

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.46353
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.67181

Cumulative Model Updates: 142,358
Cumulative Timesteps: 1,187,050,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108.22540
Policy Entropy: 3.79392
Value Function Loss: 0.02276

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.50344
Value Function Update Magnitude: 0.67220

Collected Steps per Second: 22,656.66722
Overall Steps per Second: 10,671.34040

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68845

Cumulative Model Updates: 142,364
Cumulative Timesteps: 1,187,100,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1187100282...
Checkpoint 1187100282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,516.88942
Policy Entropy: 3.78948
Value Function Loss: 0.02156

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.47333
Value Function Update Magnitude: 0.72834

Collected Steps per Second: 23,030.28439
Overall Steps per Second: 10,923.39778

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.57825

Cumulative Model Updates: 142,370
Cumulative Timesteps: 1,187,150,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,586.77285
Policy Entropy: 3.78465
Value Function Loss: 0.02196

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.49127
Value Function Update Magnitude: 0.70195

Collected Steps per Second: 22,970.23143
Overall Steps per Second: 10,872.93444

Timestep Collection Time: 2.17717
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.59949

Cumulative Model Updates: 142,376
Cumulative Timesteps: 1,187,200,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1187200302...
Checkpoint 1187200302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,306.84856
Policy Entropy: 3.78970
Value Function Loss: 0.02247

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.51369
Value Function Update Magnitude: 0.74165

Collected Steps per Second: 22,797.53489
Overall Steps per Second: 10,684.80069

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68029

Cumulative Model Updates: 142,382
Cumulative Timesteps: 1,187,250,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190.73969
Policy Entropy: 3.79615
Value Function Loss: 0.02274

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.54500
Value Function Update Magnitude: 0.71470

Collected Steps per Second: 22,740.71758
Overall Steps per Second: 10,830.22765

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.61745

Cumulative Model Updates: 142,388
Cumulative Timesteps: 1,187,300,318

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1187300318...
Checkpoint 1187300318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.16338
Policy Entropy: 3.77028
Value Function Loss: 0.02131

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.53200
Value Function Update Magnitude: 0.69895

Collected Steps per Second: 22,975.52735
Overall Steps per Second: 10,751.15866

Timestep Collection Time: 2.17745
Timestep Consumption Time: 2.47582
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.65327

Cumulative Model Updates: 142,394
Cumulative Timesteps: 1,187,350,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.22164
Policy Entropy: 3.75662
Value Function Loss: 0.02042

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.49755
Value Function Update Magnitude: 0.63839

Collected Steps per Second: 22,777.38544
Overall Steps per Second: 10,825.88689

Timestep Collection Time: 2.19569
Timestep Consumption Time: 2.42398
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61967

Cumulative Model Updates: 142,400
Cumulative Timesteps: 1,187,400,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1187400358...
Checkpoint 1187400358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.52261
Policy Entropy: 3.74749
Value Function Loss: 0.01919

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.49572
Value Function Update Magnitude: 0.59358

Collected Steps per Second: 22,997.69908
Overall Steps per Second: 10,719.86162

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.66555

Cumulative Model Updates: 142,406
Cumulative Timesteps: 1,187,450,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,949.00753
Policy Entropy: 3.75035
Value Function Loss: 0.01831

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.46078
Value Function Update Magnitude: 0.59007

Collected Steps per Second: 22,967.87624
Overall Steps per Second: 10,895.00160

Timestep Collection Time: 2.17800
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.59146

Cumulative Model Updates: 142,412
Cumulative Timesteps: 1,187,500,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1187500396...
Checkpoint 1187500396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,949.00753
Policy Entropy: 3.74654
Value Function Loss: 0.01596

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.43978
Value Function Update Magnitude: 0.59776

Collected Steps per Second: 22,848.28173
Overall Steps per Second: 10,718.43090

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.66505

Cumulative Model Updates: 142,418
Cumulative Timesteps: 1,187,550,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,933.20280
Policy Entropy: 3.74140
Value Function Loss: 0.01818

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.41882
Value Function Update Magnitude: 0.55636

Collected Steps per Second: 22,945.14103
Overall Steps per Second: 10,740.87474

Timestep Collection Time: 2.18033
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.65772

Cumulative Model Updates: 142,424
Cumulative Timesteps: 1,187,600,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1187600426...
Checkpoint 1187600426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,006.33621
Policy Entropy: 3.75879
Value Function Loss: 0.01832

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.40806
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 22,919.13320
Overall Steps per Second: 10,702.56066

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.67421

Cumulative Model Updates: 142,430
Cumulative Timesteps: 1,187,650,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,702.93727
Policy Entropy: 3.76161
Value Function Loss: 0.02026

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.41669
Value Function Update Magnitude: 0.50867

Collected Steps per Second: 23,105.20633
Overall Steps per Second: 10,950.32499

Timestep Collection Time: 2.16497
Timestep Consumption Time: 2.40312
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.56808

Cumulative Model Updates: 142,436
Cumulative Timesteps: 1,187,700,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1187700474...
Checkpoint 1187700474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,046.48434
Policy Entropy: 3.77089
Value Function Loss: 0.02037

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.42050
Value Function Update Magnitude: 0.45646

Collected Steps per Second: 22,727.81068
Overall Steps per Second: 10,682.55085

Timestep Collection Time: 2.20109
Timestep Consumption Time: 2.48187
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68296

Cumulative Model Updates: 142,442
Cumulative Timesteps: 1,187,750,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,723.62743
Policy Entropy: 3.76545
Value Function Loss: 0.02329

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.48425
Value Function Update Magnitude: 0.45931

Collected Steps per Second: 23,413.05557
Overall Steps per Second: 10,791.05436

Timestep Collection Time: 2.13616
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.63476

Cumulative Model Updates: 142,448
Cumulative Timesteps: 1,187,800,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1187800514...
Checkpoint 1187800514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,979.04806
Policy Entropy: 3.76927
Value Function Loss: 0.02466

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.62570
Value Function Update Magnitude: 0.64731

Collected Steps per Second: 22,825.24086
Overall Steps per Second: 10,767.44196

Timestep Collection Time: 2.19178
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.64623

Cumulative Model Updates: 142,454
Cumulative Timesteps: 1,187,850,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,341.15431
Policy Entropy: 3.76469
Value Function Loss: 0.02433

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.65925
Value Function Update Magnitude: 0.63969

Collected Steps per Second: 22,927.52074
Overall Steps per Second: 10,804.51639

Timestep Collection Time: 2.18192
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.63010

Cumulative Model Updates: 142,460
Cumulative Timesteps: 1,187,900,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1187900568...
Checkpoint 1187900568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,948.11219
Policy Entropy: 3.75540
Value Function Loss: 0.02221

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.61945
Value Function Update Magnitude: 0.58253

Collected Steps per Second: 22,803.17636
Overall Steps per Second: 10,614.36462

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.51812
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.71097

Cumulative Model Updates: 142,466
Cumulative Timesteps: 1,187,950,572

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,307.64641
Policy Entropy: 3.74477
Value Function Loss: 0.02123

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15714
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 22,973.32157
Overall Steps per Second: 10,876.43036

Timestep Collection Time: 2.17861
Timestep Consumption Time: 2.42308
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60169

Cumulative Model Updates: 142,472
Cumulative Timesteps: 1,188,000,622

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1188000622...
Checkpoint 1188000622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,393.04930
Policy Entropy: 3.75291
Value Function Loss: 0.01996

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16736
Policy Update Magnitude: 0.52744
Value Function Update Magnitude: 0.56131

Collected Steps per Second: 23,056.12718
Overall Steps per Second: 10,722.29534

Timestep Collection Time: 2.16914
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.66430

Cumulative Model Updates: 142,478
Cumulative Timesteps: 1,188,050,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,157.71964
Policy Entropy: 3.73474
Value Function Loss: 0.02178

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15842
Policy Update Magnitude: 0.52395
Value Function Update Magnitude: 0.62375

Collected Steps per Second: 23,190.22983
Overall Steps per Second: 10,907.95743

Timestep Collection Time: 2.15608
Timestep Consumption Time: 2.42773
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58381

Cumulative Model Updates: 142,484
Cumulative Timesteps: 1,188,100,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1188100634...
Checkpoint 1188100634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,955.25850
Policy Entropy: 3.73917
Value Function Loss: 0.01960

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.52333
Value Function Update Magnitude: 0.64252

Collected Steps per Second: 22,679.04225
Overall Steps per Second: 10,666.91331

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.48301
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.68795

Cumulative Model Updates: 142,490
Cumulative Timesteps: 1,188,150,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,760.87970
Policy Entropy: 3.74023
Value Function Loss: 0.02021

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.50887
Value Function Update Magnitude: 0.69392

Collected Steps per Second: 23,150.56269
Overall Steps per Second: 10,845.03406

Timestep Collection Time: 2.15995
Timestep Consumption Time: 2.45083
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61077

Cumulative Model Updates: 142,496
Cumulative Timesteps: 1,188,200,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1188200644...
Checkpoint 1188200644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,203.98536
Policy Entropy: 3.73970
Value Function Loss: 0.01933

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.49163
Value Function Update Magnitude: 0.65972

Collected Steps per Second: 22,858.11357
Overall Steps per Second: 10,706.39190

Timestep Collection Time: 2.18749
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67029

Cumulative Model Updates: 142,502
Cumulative Timesteps: 1,188,250,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,416.43182
Policy Entropy: 3.74314
Value Function Loss: 0.01949

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.50620
Value Function Update Magnitude: 0.58440

Collected Steps per Second: 22,216.90364
Overall Steps per Second: 10,853.45590

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.35657
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60738

Cumulative Model Updates: 142,508
Cumulative Timesteps: 1,188,300,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1188300652...
Checkpoint 1188300652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,416.43182
Policy Entropy: 3.73120
Value Function Loss: 0.01775

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.47589
Value Function Update Magnitude: 0.63649

Collected Steps per Second: 22,243.74594
Overall Steps per Second: 10,742.94050

Timestep Collection Time: 2.24899
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.65664

Cumulative Model Updates: 142,514
Cumulative Timesteps: 1,188,350,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,416.43182
Policy Entropy: 3.72977
Value Function Loss: 0.01454

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.42946
Value Function Update Magnitude: 0.58307

Collected Steps per Second: 22,233.99843
Overall Steps per Second: 10,792.35242

Timestep Collection Time: 2.24917
Timestep Consumption Time: 2.38448
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.63365

Cumulative Model Updates: 142,520
Cumulative Timesteps: 1,188,400,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1188400686...
Checkpoint 1188400686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,416.43182
Policy Entropy: 3.71823
Value Function Loss: 0.01414

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.41436
Value Function Update Magnitude: 0.53178

Collected Steps per Second: 22,204.76766
Overall Steps per Second: 10,613.19969

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.71281

Cumulative Model Updates: 142,526
Cumulative Timesteps: 1,188,450,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,746.34373
Policy Entropy: 3.72995
Value Function Loss: 0.01415

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.45860
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 22,968.01569
Overall Steps per Second: 10,909.30249

Timestep Collection Time: 2.17711
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.58361

Cumulative Model Updates: 142,532
Cumulative Timesteps: 1,188,500,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1188500708...
Checkpoint 1188500708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350,746.34373
Policy Entropy: 3.72064
Value Function Loss: 0.01508

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.46794
Value Function Update Magnitude: 0.57641

Collected Steps per Second: 22,865.33112
Overall Steps per Second: 10,779.69601

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.45301
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.64095

Cumulative Model Updates: 142,538
Cumulative Timesteps: 1,188,550,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,746.34373
Policy Entropy: 3.72570
Value Function Loss: 0.01531

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.44945
Value Function Update Magnitude: 0.55506

Collected Steps per Second: 22,833.29495
Overall Steps per Second: 10,805.53860

Timestep Collection Time: 2.19084
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.62948

Cumulative Model Updates: 142,544
Cumulative Timesteps: 1,188,600,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1188600760...
Checkpoint 1188600760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,578.04267
Policy Entropy: 3.72838
Value Function Loss: 0.01518

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.43113
Value Function Update Magnitude: 0.56326

Collected Steps per Second: 23,132.79012
Overall Steps per Second: 10,801.13739

Timestep Collection Time: 2.16273
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.63192

Cumulative Model Updates: 142,550
Cumulative Timesteps: 1,188,650,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,238.91114
Policy Entropy: 3.73149
Value Function Loss: 0.01626

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.46817
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 23,159.85902
Overall Steps per Second: 10,752.24887

Timestep Collection Time: 2.15908
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.65056

Cumulative Model Updates: 142,556
Cumulative Timesteps: 1,188,700,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1188700794...
Checkpoint 1188700794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,238.91114
Policy Entropy: 3.71935
Value Function Loss: 0.01708

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.46331
Value Function Update Magnitude: 0.53243

Collected Steps per Second: 22,889.17814
Overall Steps per Second: 10,723.51280

Timestep Collection Time: 2.18566
Timestep Consumption Time: 2.47960
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.66526

Cumulative Model Updates: 142,562
Cumulative Timesteps: 1,188,750,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,238.91114
Policy Entropy: 3.71772
Value Function Loss: 0.01649

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.45118
Value Function Update Magnitude: 0.44656

Collected Steps per Second: 22,886.60889
Overall Steps per Second: 10,862.54520

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.60500

Cumulative Model Updates: 142,568
Cumulative Timesteps: 1,188,800,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1188800844...
Checkpoint 1188800844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,115.17273
Policy Entropy: 3.73073
Value Function Loss: 0.01603

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.48179
Value Function Update Magnitude: 0.45378

Collected Steps per Second: 22,832.11834
Overall Steps per Second: 10,714.78960

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.47774
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.66869

Cumulative Model Updates: 142,574
Cumulative Timesteps: 1,188,850,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,153.53495
Policy Entropy: 3.74197
Value Function Loss: 0.01485

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.47741
Value Function Update Magnitude: 0.58202

Collected Steps per Second: 23,179.63485
Overall Steps per Second: 10,794.54145

Timestep Collection Time: 2.15758
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.63308

Cumulative Model Updates: 142,580
Cumulative Timesteps: 1,188,900,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1188900880...
Checkpoint 1188900880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,153.53495
Policy Entropy: 3.73431
Value Function Loss: 0.01410

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.46568
Value Function Update Magnitude: 0.58331

Collected Steps per Second: 22,744.34792
Overall Steps per Second: 10,658.63679

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.69234

Cumulative Model Updates: 142,586
Cumulative Timesteps: 1,188,950,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,153.53495
Policy Entropy: 3.72492
Value Function Loss: 0.01410

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.46292
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 22,981.41299
Overall Steps per Second: 10,935.43784

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.57522

Cumulative Model Updates: 142,592
Cumulative Timesteps: 1,189,000,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1189000926...
Checkpoint 1189000926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,153.53495
Policy Entropy: 3.71287
Value Function Loss: 0.01431

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.47156
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 21,648.96703
Overall Steps per Second: 10,560.18226

Timestep Collection Time: 2.31023
Timestep Consumption Time: 2.42587
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.73609

Cumulative Model Updates: 142,598
Cumulative Timesteps: 1,189,050,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,167.11527
Policy Entropy: 3.71613
Value Function Loss: 0.01544

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.51239
Value Function Update Magnitude: 0.56413

Collected Steps per Second: 22,394.39720
Overall Steps per Second: 10,991.28772

Timestep Collection Time: 2.23368
Timestep Consumption Time: 2.31738
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.55106

Cumulative Model Updates: 142,604
Cumulative Timesteps: 1,189,100,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1189100962...
Checkpoint 1189100962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,498.65919
Policy Entropy: 3.72034
Value Function Loss: 0.01680

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.53386
Value Function Update Magnitude: 0.56282

Collected Steps per Second: 22,096.88132
Overall Steps per Second: 10,598.97582

Timestep Collection Time: 2.26403
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.72008

Cumulative Model Updates: 142,610
Cumulative Timesteps: 1,189,150,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,306.95308
Policy Entropy: 3.72889
Value Function Loss: 0.01826

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 22,961.80595
Overall Steps per Second: 10,939.90837

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.39519
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.57481

Cumulative Model Updates: 142,616
Cumulative Timesteps: 1,189,201,038

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1189201038...
Checkpoint 1189201038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,329.06431
Policy Entropy: 3.72925
Value Function Loss: 0.01912

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.57243
Value Function Update Magnitude: 0.59947

Collected Steps per Second: 22,903.77101
Overall Steps per Second: 10,828.71238

Timestep Collection Time: 2.18375
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.61883

Cumulative Model Updates: 142,622
Cumulative Timesteps: 1,189,251,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,329.06431
Policy Entropy: 3.72832
Value Function Loss: 0.01822

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.49913

Collected Steps per Second: 22,833.37842
Overall Steps per Second: 10,701.84456

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67415

Cumulative Model Updates: 142,628
Cumulative Timesteps: 1,189,301,076

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1189301076...
Checkpoint 1189301076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,525.82359
Policy Entropy: 3.73185
Value Function Loss: 0.01693

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.52686
Value Function Update Magnitude: 0.59678

Collected Steps per Second: 22,578.25400
Overall Steps per Second: 10,636.55898

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.70096

Cumulative Model Updates: 142,634
Cumulative Timesteps: 1,189,351,078

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,504.37445
Policy Entropy: 3.73651
Value Function Loss: 0.01784

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.55475

Collected Steps per Second: 22,877.18857
Overall Steps per Second: 10,858.56891

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.42014
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.60668

Cumulative Model Updates: 142,640
Cumulative Timesteps: 1,189,401,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1189401100...
Checkpoint 1189401100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,504.37445
Policy Entropy: 3.72849
Value Function Loss: 0.02007

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14172
Policy Update Magnitude: 0.51677
Value Function Update Magnitude: 0.44370

Collected Steps per Second: 22,885.82438
Overall Steps per Second: 10,682.49172

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.68112

Cumulative Model Updates: 142,646
Cumulative Timesteps: 1,189,451,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,076.72178
Policy Entropy: 3.73745
Value Function Loss: 0.02062

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.47887

Collected Steps per Second: 23,182.90988
Overall Steps per Second: 10,956.82491

Timestep Collection Time: 2.15728
Timestep Consumption Time: 2.40718
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.56446

Cumulative Model Updates: 142,652
Cumulative Timesteps: 1,189,501,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1189501118...
Checkpoint 1189501118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,255.96359
Policy Entropy: 3.73273
Value Function Loss: 0.01996

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.51515

Collected Steps per Second: 22,694.73503
Overall Steps per Second: 10,676.53541

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.68485

Cumulative Model Updates: 142,658
Cumulative Timesteps: 1,189,551,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,867.00174
Policy Entropy: 3.73808
Value Function Loss: 0.02221

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.60238
Value Function Update Magnitude: 0.51496

Collected Steps per Second: 22,423.90348
Overall Steps per Second: 10,854.99276

Timestep Collection Time: 2.23101
Timestep Consumption Time: 2.37774
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.60875

Cumulative Model Updates: 142,664
Cumulative Timesteps: 1,189,601,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1189601164...
Checkpoint 1189601164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326,821.35172
Policy Entropy: 3.72825
Value Function Loss: 0.02009

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.57847
Value Function Update Magnitude: 0.47617

Collected Steps per Second: 22,000.15663
Overall Steps per Second: 10,655.67386

Timestep Collection Time: 2.27280
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.69252

Cumulative Model Updates: 142,670
Cumulative Timesteps: 1,189,651,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,437.15783
Policy Entropy: 3.71370
Value Function Loss: 0.02059

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.43205

Collected Steps per Second: 21,926.28233
Overall Steps per Second: 10,565.49074

Timestep Collection Time: 2.28137
Timestep Consumption Time: 2.45310
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.73447

Cumulative Model Updates: 142,676
Cumulative Timesteps: 1,189,701,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1189701188...
Checkpoint 1189701188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,583.73613
Policy Entropy: 3.73625
Value Function Loss: 0.01819

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.57524
Value Function Update Magnitude: 0.43571

Collected Steps per Second: 22,856.35829
Overall Steps per Second: 10,921.33713

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.39100
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.57893

Cumulative Model Updates: 142,682
Cumulative Timesteps: 1,189,751,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,242.09163
Policy Entropy: 3.73194
Value Function Loss: 0.01957

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.45624

Collected Steps per Second: 23,144.10822
Overall Steps per Second: 10,912.32377

Timestep Collection Time: 2.16072
Timestep Consumption Time: 2.42199
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.58271

Cumulative Model Updates: 142,688
Cumulative Timesteps: 1,189,801,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1189801204...
Checkpoint 1189801204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,243.14319
Policy Entropy: 3.75679
Value Function Loss: 0.01896

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.50578

Collected Steps per Second: 22,982.34486
Overall Steps per Second: 10,719.57035

Timestep Collection Time: 2.17576
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.66474

Cumulative Model Updates: 142,694
Cumulative Timesteps: 1,189,851,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,654.08319
Policy Entropy: 3.74717
Value Function Loss: 0.02139

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.57167
Value Function Update Magnitude: 0.56860

Collected Steps per Second: 22,949.46738
Overall Steps per Second: 10,879.03518

Timestep Collection Time: 2.17870
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.59600

Cumulative Model Updates: 142,700
Cumulative Timesteps: 1,189,901,208

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1189901208...
Checkpoint 1189901208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,654.08319
Policy Entropy: 3.75826
Value Function Loss: 0.02068

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.53509

Collected Steps per Second: 22,494.07534
Overall Steps per Second: 10,594.31642

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.72215

Cumulative Model Updates: 142,706
Cumulative Timesteps: 1,189,951,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,634.99772
Policy Entropy: 3.73712
Value Function Loss: 0.02350

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.59898
Value Function Update Magnitude: 0.51932

Collected Steps per Second: 22,573.10971
Overall Steps per Second: 10,796.19999

Timestep Collection Time: 2.21529
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.63181

Cumulative Model Updates: 142,712
Cumulative Timesteps: 1,190,001,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1190001242...
Checkpoint 1190001242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,434.14864
Policy Entropy: 3.73391
Value Function Loss: 0.02235

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.63871
Value Function Update Magnitude: 0.57975

Collected Steps per Second: 22,881.82914
Overall Steps per Second: 10,749.06946

Timestep Collection Time: 2.18523
Timestep Consumption Time: 2.46652
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.65175

Cumulative Model Updates: 142,718
Cumulative Timesteps: 1,190,051,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,289.45775
Policy Entropy: 3.72835
Value Function Loss: 0.02418

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.61172
Value Function Update Magnitude: 0.49677

Collected Steps per Second: 22,909.70582
Overall Steps per Second: 10,912.72247

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.58236

Cumulative Model Updates: 142,724
Cumulative Timesteps: 1,190,101,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1190101250...
Checkpoint 1190101250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,602.41437
Policy Entropy: 3.73422
Value Function Loss: 0.01892

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.56551
Value Function Update Magnitude: 0.51234

Collected Steps per Second: 22,592.37700
Overall Steps per Second: 10,636.73707

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.48805
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.70163

Cumulative Model Updates: 142,730
Cumulative Timesteps: 1,190,151,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,132.79780
Policy Entropy: 3.73912
Value Function Loss: 0.01836

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.52552
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 23,216.75836
Overall Steps per Second: 10,954.21472

Timestep Collection Time: 2.15465
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.56664

Cumulative Model Updates: 142,736
Cumulative Timesteps: 1,190,201,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1190201284...
Checkpoint 1190201284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,132.79780
Policy Entropy: 3.74540
Value Function Loss: 0.01763

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.52213
Value Function Update Magnitude: 0.46734

Collected Steps per Second: 22,689.34368
Overall Steps per Second: 10,669.30079

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.48505
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.69084

Cumulative Model Updates: 142,742
Cumulative Timesteps: 1,190,251,332

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,819.65148
Policy Entropy: 3.75353
Value Function Loss: 0.01863

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.53669

Collected Steps per Second: 22,358.94861
Overall Steps per Second: 10,866.46533

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.36715
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.60536

Cumulative Model Updates: 142,748
Cumulative Timesteps: 1,190,301,376

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1190301376...
Checkpoint 1190301376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,690.71073
Policy Entropy: 3.75978
Value Function Loss: 0.01995

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.68912

Collected Steps per Second: 21,912.22116
Overall Steps per Second: 10,663.38393

Timestep Collection Time: 2.28238
Timestep Consumption Time: 2.40769
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.69007

Cumulative Model Updates: 142,754
Cumulative Timesteps: 1,190,351,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,776.18662
Policy Entropy: 3.76663
Value Function Loss: 0.02034

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.77345

Collected Steps per Second: 22,402.44798
Overall Steps per Second: 10,862.85288

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.37151
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.60395

Cumulative Model Updates: 142,760
Cumulative Timesteps: 1,190,401,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1190401400...
Checkpoint 1190401400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,776.18662
Policy Entropy: 3.75832
Value Function Loss: 0.02013

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.56251
Value Function Update Magnitude: 0.70809

Collected Steps per Second: 22,133.17525
Overall Steps per Second: 10,645.38600

Timestep Collection Time: 2.25996
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.69875

Cumulative Model Updates: 142,766
Cumulative Timesteps: 1,190,451,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,776.18662
Policy Entropy: 3.74689
Value Function Loss: 0.01855

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.54299
Value Function Update Magnitude: 0.49878

Collected Steps per Second: 23,190.02671
Overall Steps per Second: 10,938.54811

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.57355

Cumulative Model Updates: 142,772
Cumulative Timesteps: 1,190,501,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1190501448...
Checkpoint 1190501448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,824.89617
Policy Entropy: 3.72456
Value Function Loss: 0.02019

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.51211
Value Function Update Magnitude: 0.40514

Collected Steps per Second: 22,644.93061
Overall Steps per Second: 10,718.05528

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.66689

Cumulative Model Updates: 142,778
Cumulative Timesteps: 1,190,551,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,072.56662
Policy Entropy: 3.73580
Value Function Loss: 0.01855

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.52936
Value Function Update Magnitude: 0.52774

Collected Steps per Second: 23,148.62153
Overall Steps per Second: 10,831.74026

Timestep Collection Time: 2.16134
Timestep Consumption Time: 2.45768
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.61902

Cumulative Model Updates: 142,784
Cumulative Timesteps: 1,190,601,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1190601500...
Checkpoint 1190601500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,274.30654
Policy Entropy: 3.72469
Value Function Loss: 0.02277

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.51402
Value Function Update Magnitude: 0.47125

Collected Steps per Second: 22,749.61181
Overall Steps per Second: 10,628.66898

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.70426

Cumulative Model Updates: 142,790
Cumulative Timesteps: 1,190,651,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,274.30654
Policy Entropy: 3.73838
Value Function Loss: 0.02218

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.53512
Value Function Update Magnitude: 0.40510

Collected Steps per Second: 22,877.32220
Overall Steps per Second: 10,854.64705

Timestep Collection Time: 2.18566
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.60651

Cumulative Model Updates: 142,796
Cumulative Timesteps: 1,190,701,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1190701502...
Checkpoint 1190701502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,464.59299
Policy Entropy: 3.73157
Value Function Loss: 0.02407

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.51899
Value Function Update Magnitude: 0.44429

Collected Steps per Second: 22,533.93855
Overall Steps per Second: 10,657.99695

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.69263

Cumulative Model Updates: 142,802
Cumulative Timesteps: 1,190,751,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,524.18681
Policy Entropy: 3.76082
Value Function Loss: 0.02009

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.50499
Value Function Update Magnitude: 0.48189

Collected Steps per Second: 23,038.48922
Overall Steps per Second: 10,883.41790

Timestep Collection Time: 2.17106
Timestep Consumption Time: 2.42474
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.59580

Cumulative Model Updates: 142,808
Cumulative Timesteps: 1,190,801,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1190801534...
Checkpoint 1190801534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,689.10415
Policy Entropy: 3.75841
Value Function Loss: 0.01710

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.45945
Value Function Update Magnitude: 0.51974

Collected Steps per Second: 22,819.22931
Overall Steps per Second: 10,664.63516

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.68933

Cumulative Model Updates: 142,814
Cumulative Timesteps: 1,190,851,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,694.56993
Policy Entropy: 3.77300
Value Function Loss: 0.01477

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.42895
Value Function Update Magnitude: 0.48028

Collected Steps per Second: 23,125.48271
Overall Steps per Second: 10,955.57964

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.40196
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.56425

Cumulative Model Updates: 142,820
Cumulative Timesteps: 1,190,901,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1190901548...
Checkpoint 1190901548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,405.11982
Policy Entropy: 3.75307
Value Function Loss: 0.01421

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.40003
Value Function Update Magnitude: 0.53746

Collected Steps per Second: 22,841.22463
Overall Steps per Second: 10,699.29621

Timestep Collection Time: 2.19034
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.67601

Cumulative Model Updates: 142,826
Cumulative Timesteps: 1,190,951,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,576.00696
Policy Entropy: 3.75844
Value Function Loss: 0.01537

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.41014
Value Function Update Magnitude: 0.59919

Collected Steps per Second: 23,004.39347
Overall Steps per Second: 10,814.83777

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.62531

Cumulative Model Updates: 142,832
Cumulative Timesteps: 1,191,001,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1191001600...
Checkpoint 1191001600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,734.04551
Policy Entropy: 3.74306
Value Function Loss: 0.01502

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.43357
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 22,995.34562
Overall Steps per Second: 10,743.29178

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.65518

Cumulative Model Updates: 142,838
Cumulative Timesteps: 1,191,051,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,662.08441
Policy Entropy: 3.74366
Value Function Loss: 0.01416

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.42643
Value Function Update Magnitude: 0.58916

Collected Steps per Second: 23,238.19888
Overall Steps per Second: 10,818.85331

Timestep Collection Time: 2.15249
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.62341

Cumulative Model Updates: 142,844
Cumulative Timesteps: 1,191,101,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1191101632...
Checkpoint 1191101632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,894.13932
Policy Entropy: 3.74018
Value Function Loss: 0.01448

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.43153
Value Function Update Magnitude: 0.60125

Collected Steps per Second: 22,776.45994
Overall Steps per Second: 10,694.88821

Timestep Collection Time: 2.19560
Timestep Consumption Time: 2.48028
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67588

Cumulative Model Updates: 142,850
Cumulative Timesteps: 1,191,151,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,284.67332
Policy Entropy: 3.74012
Value Function Loss: 0.01656

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13489
Policy Update Magnitude: 0.48733
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 23,257.99392
Overall Steps per Second: 10,829.22413

Timestep Collection Time: 2.15066
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.61898

Cumulative Model Updates: 142,856
Cumulative Timesteps: 1,191,201,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1191201660...
Checkpoint 1191201660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,576.07396
Policy Entropy: 3.75618
Value Function Loss: 0.01677

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.50135
Value Function Update Magnitude: 0.75149

Collected Steps per Second: 22,890.42204
Overall Steps per Second: 10,683.20106

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68305

Cumulative Model Updates: 142,862
Cumulative Timesteps: 1,191,251,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,637.84853
Policy Entropy: 3.74229
Value Function Loss: 0.01707

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.49042
Value Function Update Magnitude: 0.66900

Collected Steps per Second: 23,059.80487
Overall Steps per Second: 10,924.06104

Timestep Collection Time: 2.16836
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.57724

Cumulative Model Updates: 142,868
Cumulative Timesteps: 1,191,301,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1191301692...
Checkpoint 1191301692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,789.15346
Policy Entropy: 3.75906
Value Function Loss: 0.01593

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.47937
Value Function Update Magnitude: 0.61579

Collected Steps per Second: 22,754.29129
Overall Steps per Second: 10,690.41311

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.67746

Cumulative Model Updates: 142,874
Cumulative Timesteps: 1,191,351,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 486,834.94362
Policy Entropy: 3.74199
Value Function Loss: 0.01630

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.70525

Collected Steps per Second: 23,071.52778
Overall Steps per Second: 10,805.07788

Timestep Collection Time: 2.16813
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.62949

Cumulative Model Updates: 142,880
Cumulative Timesteps: 1,191,401,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1191401718...
Checkpoint 1191401718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,834.94362
Policy Entropy: 3.75492
Value Function Loss: 0.01394

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.71087

Collected Steps per Second: 22,696.35779
Overall Steps per Second: 10,625.80413

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.50383
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.70797

Cumulative Model Updates: 142,886
Cumulative Timesteps: 1,191,451,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016,708.57876
Policy Entropy: 3.73090
Value Function Loss: 0.01669

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.44003
Value Function Update Magnitude: 0.56619

Collected Steps per Second: 22,860.80999
Overall Steps per Second: 10,870.92952

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.59942

Cumulative Model Updates: 142,892
Cumulative Timesteps: 1,191,501,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1191501744...
Checkpoint 1191501744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,334.37457
Policy Entropy: 3.74978
Value Function Loss: 0.01509

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.47545
Value Function Update Magnitude: 0.50002

Collected Steps per Second: 22,761.70536
Overall Steps per Second: 10,680.07903

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.68424

Cumulative Model Updates: 142,898
Cumulative Timesteps: 1,191,551,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,334.37457
Policy Entropy: 3.73009
Value Function Loss: 0.01870

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.52441
Value Function Update Magnitude: 0.47065

Collected Steps per Second: 22,994.72076
Overall Steps per Second: 10,860.03994

Timestep Collection Time: 2.17493
Timestep Consumption Time: 2.43021
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.60514

Cumulative Model Updates: 142,904
Cumulative Timesteps: 1,191,601,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1191601784...
Checkpoint 1191601784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409,510.07381
Policy Entropy: 3.74541
Value Function Loss: 0.01753

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.47411

Collected Steps per Second: 22,750.19921
Overall Steps per Second: 10,673.02801

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.68714

Cumulative Model Updates: 142,910
Cumulative Timesteps: 1,191,651,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,510.07381
Policy Entropy: 3.72283
Value Function Loss: 0.02123

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.45548

Collected Steps per Second: 22,820.55091
Overall Steps per Second: 10,866.93030

Timestep Collection Time: 2.19127
Timestep Consumption Time: 2.41040
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.60167

Cumulative Model Updates: 142,916
Cumulative Timesteps: 1,191,701,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1191701816...
Checkpoint 1191701816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298,749.40170
Policy Entropy: 3.73912
Value Function Loss: 0.01960

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.55678

Collected Steps per Second: 22,919.33139
Overall Steps per Second: 10,694.28598

Timestep Collection Time: 2.18183
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.67596

Cumulative Model Updates: 142,922
Cumulative Timesteps: 1,191,751,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,826.15630
Policy Entropy: 3.72637
Value Function Loss: 0.01992

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.58644
Value Function Update Magnitude: 0.66992

Collected Steps per Second: 22,825.14112
Overall Steps per Second: 10,867.95159

Timestep Collection Time: 2.19188
Timestep Consumption Time: 2.41156
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.60344

Cumulative Model Updates: 142,928
Cumulative Timesteps: 1,191,801,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1191801852...
Checkpoint 1191801852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 428,565.72959
Policy Entropy: 3.75759
Value Function Loss: 0.01925

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.59148
Value Function Update Magnitude: 0.68939

Collected Steps per Second: 23,023.73189
Overall Steps per Second: 10,741.41102

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.48371
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.65581

Cumulative Model Updates: 142,934
Cumulative Timesteps: 1,191,851,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,696.81279
Policy Entropy: 3.75416
Value Function Loss: 0.02112

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.59330
Value Function Update Magnitude: 0.69517

Collected Steps per Second: 23,061.49799
Overall Steps per Second: 10,875.41339

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.59992

Cumulative Model Updates: 142,940
Cumulative Timesteps: 1,191,901,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1191901888...
Checkpoint 1191901888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,419.34584
Policy Entropy: 3.76963
Value Function Loss: 0.01981

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.60219
Value Function Update Magnitude: 0.64677

Collected Steps per Second: 22,963.29503
Overall Steps per Second: 10,789.41628

Timestep Collection Time: 2.17869
Timestep Consumption Time: 2.45826
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.63695

Cumulative Model Updates: 142,946
Cumulative Timesteps: 1,191,951,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,382.20926
Policy Entropy: 3.75478
Value Function Loss: 0.02201

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.69027

Collected Steps per Second: 22,323.28936
Overall Steps per Second: 10,706.40231

Timestep Collection Time: 2.24080
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.67216

Cumulative Model Updates: 142,952
Cumulative Timesteps: 1,192,001,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1192001940...
Checkpoint 1192001940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383,772.81904
Policy Entropy: 3.74552
Value Function Loss: 0.01985

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.57798
Value Function Update Magnitude: 0.74142

Collected Steps per Second: 22,171.48466
Overall Steps per Second: 10,717.51103

Timestep Collection Time: 2.25614
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.66732

Cumulative Model Updates: 142,958
Cumulative Timesteps: 1,192,051,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,122.68993
Policy Entropy: 3.74037
Value Function Loss: 0.02185

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.60200
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 22,394.45728
Overall Steps per Second: 10,870.16662

Timestep Collection Time: 2.23359
Timestep Consumption Time: 2.36800
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.60159

Cumulative Model Updates: 142,964
Cumulative Timesteps: 1,192,101,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1192101982...
Checkpoint 1192101982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,182.32282
Policy Entropy: 3.74102
Value Function Loss: 0.01695

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.59633
Value Function Update Magnitude: 0.70993

Collected Steps per Second: 22,464.45875
Overall Steps per Second: 10,667.52988

Timestep Collection Time: 2.22627
Timestep Consumption Time: 2.46197
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68825

Cumulative Model Updates: 142,970
Cumulative Timesteps: 1,192,151,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,942.10381
Policy Entropy: 3.73809
Value Function Loss: 0.02143

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.60654
Value Function Update Magnitude: 0.83809

Collected Steps per Second: 22,613.75051
Overall Steps per Second: 10,874.06385

Timestep Collection Time: 2.21228
Timestep Consumption Time: 2.38839
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.60067

Cumulative Model Updates: 142,976
Cumulative Timesteps: 1,192,202,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1192202022...
Checkpoint 1192202022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,147.11865
Policy Entropy: 3.76599
Value Function Loss: 0.01987

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.68256
Value Function Update Magnitude: 0.86755

Collected Steps per Second: 22,851.85795
Overall Steps per Second: 10,763.30237

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.45790
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.64634

Cumulative Model Updates: 142,982
Cumulative Timesteps: 1,192,252,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,918.07016
Policy Entropy: 3.76527
Value Function Loss: 0.02635

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.69472
Value Function Update Magnitude: 0.80499

Collected Steps per Second: 23,174.30654
Overall Steps per Second: 10,795.41680

Timestep Collection Time: 2.15886
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.63437

Cumulative Model Updates: 142,988
Cumulative Timesteps: 1,192,302,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1192302062...
Checkpoint 1192302062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,596.89671
Policy Entropy: 3.78449
Value Function Loss: 0.02476

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.72429
Value Function Update Magnitude: 0.89647

Collected Steps per Second: 22,849.26089
Overall Steps per Second: 10,781.81154

Timestep Collection Time: 2.18887
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.63874

Cumulative Model Updates: 142,994
Cumulative Timesteps: 1,192,352,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,135.94501
Policy Entropy: 3.74466
Value Function Loss: 0.02786

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.69228
Value Function Update Magnitude: 0.93291

Collected Steps per Second: 22,705.17646
Overall Steps per Second: 10,723.84909

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.46036
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.66250

Cumulative Model Updates: 143,000
Cumulative Timesteps: 1,192,402,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1192402076...
Checkpoint 1192402076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,063.40900
Policy Entropy: 3.75182
Value Function Loss: 0.02695

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.66486
Value Function Update Magnitude: 0.73745

Collected Steps per Second: 23,154.79443
Overall Steps per Second: 10,801.29516

Timestep Collection Time: 2.15938
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.62907

Cumulative Model Updates: 143,006
Cumulative Timesteps: 1,192,452,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,610.70636
Policy Entropy: 3.75620
Value Function Loss: 0.02604

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.62350
Value Function Update Magnitude: 0.60940

Collected Steps per Second: 22,982.54453
Overall Steps per Second: 10,762.32512

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.64788

Cumulative Model Updates: 143,012
Cumulative Timesteps: 1,192,502,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1192502098...
Checkpoint 1192502098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,136.32258
Policy Entropy: 3.78508
Value Function Loss: 0.02348

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.62999
Value Function Update Magnitude: 0.58686

Collected Steps per Second: 23,040.86017
Overall Steps per Second: 10,768.71892

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.64531

Cumulative Model Updates: 143,018
Cumulative Timesteps: 1,192,552,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,247.51956
Policy Entropy: 3.80063
Value Function Loss: 0.02087

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.61838
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 23,020.24617
Overall Steps per Second: 10,739.52913

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.65570

Cumulative Model Updates: 143,024
Cumulative Timesteps: 1,192,602,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1192602122...
Checkpoint 1192602122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,780.35329
Policy Entropy: 3.82720
Value Function Loss: 0.01886

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.64674

Collected Steps per Second: 22,913.37380
Overall Steps per Second: 10,715.70581

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.66642

Cumulative Model Updates: 143,030
Cumulative Timesteps: 1,192,652,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,386.05166
Policy Entropy: 3.84614
Value Function Loss: 0.02127

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.57071
Value Function Update Magnitude: 0.77129

Collected Steps per Second: 23,248.17990
Overall Steps per Second: 10,848.11919

Timestep Collection Time: 2.15071
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.60909

Cumulative Model Updates: 143,036
Cumulative Timesteps: 1,192,702,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1192702126...
Checkpoint 1192702126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.76724
Policy Entropy: 3.86037
Value Function Loss: 0.02221

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.58841
Value Function Update Magnitude: 0.84237

Collected Steps per Second: 23,009.07357
Overall Steps per Second: 10,975.53220

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.38396
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.55832

Cumulative Model Updates: 143,042
Cumulative Timesteps: 1,192,752,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.28097
Policy Entropy: 3.82942
Value Function Loss: 0.02347

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.62172
Value Function Update Magnitude: 0.87837

Collected Steps per Second: 22,861.10421
Overall Steps per Second: 10,668.35427

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.68863

Cumulative Model Updates: 143,048
Cumulative Timesteps: 1,192,802,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1192802176...
Checkpoint 1192802176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,807.19733
Policy Entropy: 3.80672
Value Function Loss: 0.02544

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15814
Policy Update Magnitude: 0.60949
Value Function Update Magnitude: 0.83105

Collected Steps per Second: 22,931.34996
Overall Steps per Second: 10,893.31355

Timestep Collection Time: 2.18182
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.59291

Cumulative Model Updates: 143,054
Cumulative Timesteps: 1,192,852,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,408.55286
Policy Entropy: 3.79765
Value Function Loss: 0.02522

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.75032
Value Function Update Magnitude: 0.78020

Collected Steps per Second: 22,817.58178
Overall Steps per Second: 10,733.94888

Timestep Collection Time: 2.19217
Timestep Consumption Time: 2.46781
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.65998

Cumulative Model Updates: 143,060
Cumulative Timesteps: 1,192,902,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1192902228...
Checkpoint 1192902228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.20569
Policy Entropy: 3.78407
Value Function Loss: 0.02721

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.80227
Value Function Update Magnitude: 0.67370

Collected Steps per Second: 23,214.58877
Overall Steps per Second: 10,933.52902

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.41975
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.57400

Cumulative Model Updates: 143,066
Cumulative Timesteps: 1,192,952,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,355.79649
Policy Entropy: 3.80650
Value Function Loss: 0.02916

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.85405
Value Function Update Magnitude: 0.71161

Collected Steps per Second: 22,483.75122
Overall Steps per Second: 10,753.25266

Timestep Collection Time: 2.22383
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.64976

Cumulative Model Updates: 143,072
Cumulative Timesteps: 1,193,002,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1193002238...
Checkpoint 1193002238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,409.89048
Policy Entropy: 3.79435
Value Function Loss: 0.03031

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 1.04612
Value Function Update Magnitude: 0.81428

Collected Steps per Second: 22,574.80659
Overall Steps per Second: 10,714.93152

Timestep Collection Time: 2.21486
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.66639

Cumulative Model Updates: 143,078
Cumulative Timesteps: 1,193,052,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,104.45632
Policy Entropy: 3.81620
Value Function Loss: 0.03141

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 1.01751
Value Function Update Magnitude: 0.76889

Collected Steps per Second: 22,903.02501
Overall Steps per Second: 10,853.25692

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.61115

Cumulative Model Updates: 143,084
Cumulative Timesteps: 1,193,102,284

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1193102284...
Checkpoint 1193102284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,270.97184
Policy Entropy: 3.80873
Value Function Loss: 0.02781

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.90639
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 22,728.75830
Overall Steps per Second: 10,740.64989

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65540

Cumulative Model Updates: 143,090
Cumulative Timesteps: 1,193,152,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,599.52340
Policy Entropy: 3.79272
Value Function Loss: 0.02692

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.90840
Value Function Update Magnitude: 0.66556

Collected Steps per Second: 22,704.01959
Overall Steps per Second: 10,811.22905

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.42363
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62686

Cumulative Model Updates: 143,096
Cumulative Timesteps: 1,193,202,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1193202308...
Checkpoint 1193202308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,229.55747
Policy Entropy: 3.77670
Value Function Loss: 0.02896

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.94715
Value Function Update Magnitude: 0.65794

Collected Steps per Second: 22,721.41651
Overall Steps per Second: 10,745.54824

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.45370
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.65532

Cumulative Model Updates: 143,102
Cumulative Timesteps: 1,193,252,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,150.29048
Policy Entropy: 3.79281
Value Function Loss: 0.03454

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.80335
Value Function Update Magnitude: 0.68049

Collected Steps per Second: 22,965.57047
Overall Steps per Second: 10,888.53493

Timestep Collection Time: 2.17804
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.59382

Cumulative Model Updates: 143,108
Cumulative Timesteps: 1,193,302,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1193302352...
Checkpoint 1193302352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,651.13777
Policy Entropy: 3.79588
Value Function Loss: 0.03390

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.71228
Value Function Update Magnitude: 0.88510

Collected Steps per Second: 22,825.39318
Overall Steps per Second: 10,664.06333

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.68977

Cumulative Model Updates: 143,114
Cumulative Timesteps: 1,193,352,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,021.97865
Policy Entropy: 3.78481
Value Function Loss: 0.03678

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13924
Policy Update Magnitude: 0.70026
Value Function Update Magnitude: 0.80211

Collected Steps per Second: 22,576.64053
Overall Steps per Second: 10,867.59354

Timestep Collection Time: 2.21663
Timestep Consumption Time: 2.38826
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.60488

Cumulative Model Updates: 143,120
Cumulative Timesteps: 1,193,402,408

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1193402408...
Checkpoint 1193402408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,206.00379
Policy Entropy: 3.77554
Value Function Loss: 0.03430

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.71379
Value Function Update Magnitude: 0.64461

Collected Steps per Second: 22,701.77537
Overall Steps per Second: 10,671.33394

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.48437
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68807

Cumulative Model Updates: 143,126
Cumulative Timesteps: 1,193,452,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,608.60282
Policy Entropy: 3.76316
Value Function Loss: 0.03776

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.66336
Value Function Update Magnitude: 0.49738

Collected Steps per Second: 22,936.83983
Overall Steps per Second: 10,871.79892

Timestep Collection Time: 2.18103
Timestep Consumption Time: 2.42041
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.60145

Cumulative Model Updates: 143,132
Cumulative Timesteps: 1,193,502,462

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1193502462...
Checkpoint 1193502462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,262.02932
Policy Entropy: 3.79698
Value Function Loss: 0.03533

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.60723
Value Function Update Magnitude: 0.43656

Collected Steps per Second: 22,978.53455
Overall Steps per Second: 10,719.48242

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66683

Cumulative Model Updates: 143,138
Cumulative Timesteps: 1,193,552,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,750.11556
Policy Entropy: 3.79343
Value Function Loss: 0.03665

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.43908

Collected Steps per Second: 22,764.22616
Overall Steps per Second: 10,878.41434

Timestep Collection Time: 2.19748
Timestep Consumption Time: 2.40098
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.59846

Cumulative Model Updates: 143,144
Cumulative Timesteps: 1,193,602,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1193602512...
Checkpoint 1193602512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,981.91425
Policy Entropy: 3.81251
Value Function Loss: 0.02995

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.51119
Value Function Update Magnitude: 0.47727

Collected Steps per Second: 23,264.46656
Overall Steps per Second: 10,823.93281

Timestep Collection Time: 2.14937
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.61976

Cumulative Model Updates: 143,150
Cumulative Timesteps: 1,193,652,516

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,800.83998
Policy Entropy: 3.77864
Value Function Loss: 0.03290

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.48569

Collected Steps per Second: 23,118.04372
Overall Steps per Second: 10,705.97929

Timestep Collection Time: 2.16446
Timestep Consumption Time: 2.50938
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.67384

Cumulative Model Updates: 143,156
Cumulative Timesteps: 1,193,702,554

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1193702554...
Checkpoint 1193702554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,384.13645
Policy Entropy: 3.78744
Value Function Loss: 0.03098

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.49786

Collected Steps per Second: 22,848.08477
Overall Steps per Second: 10,705.06182

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.67106

Cumulative Model Updates: 143,162
Cumulative Timesteps: 1,193,752,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,835.12157
Policy Entropy: 3.78868
Value Function Loss: 0.03186

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.48930

Collected Steps per Second: 22,561.71414
Overall Steps per Second: 10,783.06878

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.63783

Cumulative Model Updates: 143,168
Cumulative Timesteps: 1,193,802,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1193802568...
Checkpoint 1193802568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,269.24569
Policy Entropy: 3.82138
Value Function Loss: 0.02755

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.54540
Value Function Update Magnitude: 0.53237

Collected Steps per Second: 22,713.91132
Overall Steps per Second: 10,719.34165

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.66503

Cumulative Model Updates: 143,174
Cumulative Timesteps: 1,193,852,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,918.49968
Policy Entropy: 3.80285
Value Function Loss: 0.02573

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.63143
Value Function Update Magnitude: 0.66451

Collected Steps per Second: 23,221.26925
Overall Steps per Second: 10,965.76838

Timestep Collection Time: 2.15440
Timestep Consumption Time: 2.40779
PPO Batch Consumption Time: 0.27617
Total Iteration Time: 4.56220

Cumulative Model Updates: 143,180
Cumulative Timesteps: 1,193,902,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1193902602...
Checkpoint 1193902602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,570.25521
Policy Entropy: 3.77850
Value Function Loss: 0.02310

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14919
Policy Update Magnitude: 0.63893
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 22,941.69285
Overall Steps per Second: 10,781.50215

Timestep Collection Time: 2.17953
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.63776

Cumulative Model Updates: 143,186
Cumulative Timesteps: 1,193,952,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,787.69906
Policy Entropy: 3.75401
Value Function Loss: 0.02487

Mean KL Divergence: 0.02055
SB3 Clip Fraction: 0.24859
Policy Update Magnitude: 0.56672
Value Function Update Magnitude: 0.55066

Collected Steps per Second: 22,727.13847
Overall Steps per Second: 10,716.16488

Timestep Collection Time: 2.20072
Timestep Consumption Time: 2.46662
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66734

Cumulative Model Updates: 143,192
Cumulative Timesteps: 1,194,002,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1194002620...
Checkpoint 1194002620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,495.20314
Policy Entropy: 3.77501
Value Function Loss: 0.03106

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.25938
Policy Update Magnitude: 0.52489
Value Function Update Magnitude: 0.53835

Collected Steps per Second: 22,843.02660
Overall Steps per Second: 10,710.91211

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.48038
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.67019

Cumulative Model Updates: 143,198
Cumulative Timesteps: 1,194,052,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,812.65377
Policy Entropy: 3.79407
Value Function Loss: 0.03756

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.17887
Policy Update Magnitude: 0.58778
Value Function Update Magnitude: 0.46225

Collected Steps per Second: 22,818.38955
Overall Steps per Second: 10,877.92814

Timestep Collection Time: 2.19192
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.59793

Cumulative Model Updates: 143,204
Cumulative Timesteps: 1,194,102,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1194102658...
Checkpoint 1194102658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,976.04557
Policy Entropy: 3.79227
Value Function Loss: 0.03312

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17296
Policy Update Magnitude: 0.69176
Value Function Update Magnitude: 0.34847

Collected Steps per Second: 22,877.67539
Overall Steps per Second: 10,727.72349

Timestep Collection Time: 2.18580
Timestep Consumption Time: 2.47558
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66138

Cumulative Model Updates: 143,210
Cumulative Timesteps: 1,194,152,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,730.34305
Policy Entropy: 3.76110
Value Function Loss: 0.03189

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.31739

Collected Steps per Second: 22,976.48806
Overall Steps per Second: 10,739.46020

Timestep Collection Time: 2.17649
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.65647

Cumulative Model Updates: 143,216
Cumulative Timesteps: 1,194,202,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1194202672...
Checkpoint 1194202672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,633.83055
Policy Entropy: 3.73745
Value Function Loss: 0.03206

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.54113
Value Function Update Magnitude: 0.40724

Collected Steps per Second: 23,044.17570
Overall Steps per Second: 10,763.55534

Timestep Collection Time: 2.17018
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.64623

Cumulative Model Updates: 143,222
Cumulative Timesteps: 1,194,252,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,372.90427
Policy Entropy: 3.75510
Value Function Loss: 0.02998

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14086
Policy Update Magnitude: 0.53243
Value Function Update Magnitude: 0.46760

Collected Steps per Second: 22,341.34031
Overall Steps per Second: 10,836.14202

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.37714
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.61603

Cumulative Model Updates: 143,228
Cumulative Timesteps: 1,194,302,702

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1194302702...
Checkpoint 1194302702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.40954
Policy Entropy: 3.79062
Value Function Loss: 0.02580

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.56087
Value Function Update Magnitude: 0.58862

Collected Steps per Second: 22,265.25590
Overall Steps per Second: 10,807.65125

Timestep Collection Time: 2.24682
Timestep Consumption Time: 2.38194
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.62876

Cumulative Model Updates: 143,234
Cumulative Timesteps: 1,194,352,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,629.68100
Policy Entropy: 3.78698
Value Function Loss: 0.02259

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07130
Policy Update Magnitude: 0.66233
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 22,238.94018
Overall Steps per Second: 10,710.28528

Timestep Collection Time: 2.24948
Timestep Consumption Time: 2.42136
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.67084

Cumulative Model Updates: 143,240
Cumulative Timesteps: 1,194,402,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1194402754...
Checkpoint 1194402754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,964.75974
Policy Entropy: 3.76716
Value Function Loss: 0.01862

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.71378
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 22,416.89246
Overall Steps per Second: 10,636.55482

Timestep Collection Time: 2.23189
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70378

Cumulative Model Updates: 143,246
Cumulative Timesteps: 1,194,452,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,964.75974
Policy Entropy: 3.77022
Value Function Loss: 0.01460

Mean KL Divergence: 0.00530
SB3 Clip Fraction: 0.06041
Policy Update Magnitude: 0.61816
Value Function Update Magnitude: 0.46701

Collected Steps per Second: 22,855.83274
Overall Steps per Second: 10,916.37664

Timestep Collection Time: 2.18955
Timestep Consumption Time: 2.39475
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.58431

Cumulative Model Updates: 143,252
Cumulative Timesteps: 1,194,502,830

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1194502830...
Checkpoint 1194502830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,952.98368
Policy Entropy: 3.77497
Value Function Loss: 0.01285

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.04815
Policy Update Magnitude: 0.57959
Value Function Update Magnitude: 0.50380

Collected Steps per Second: 23,018.36001
Overall Steps per Second: 10,868.46210

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.60157

Cumulative Model Updates: 143,258
Cumulative Timesteps: 1,194,552,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,632.78169
Policy Entropy: 3.78208
Value Function Loss: 0.01237

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16827
Policy Update Magnitude: 0.52272
Value Function Update Magnitude: 0.61016

Collected Steps per Second: 22,572.20990
Overall Steps per Second: 10,674.16390

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.68440

Cumulative Model Updates: 143,264
Cumulative Timesteps: 1,194,602,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1194602844...
Checkpoint 1194602844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,335.79069
Policy Entropy: 3.77487
Value Function Loss: 0.01693

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14199
Policy Update Magnitude: 0.50313
Value Function Update Magnitude: 0.72448

Collected Steps per Second: 23,075.58581
Overall Steps per Second: 10,758.94593

Timestep Collection Time: 2.16688
Timestep Consumption Time: 2.48060
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.64748

Cumulative Model Updates: 143,270
Cumulative Timesteps: 1,194,652,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,458.35696
Policy Entropy: 3.81100
Value Function Loss: 0.01796

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.16430
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.80691

Collected Steps per Second: 23,298.46714
Overall Steps per Second: 10,755.40081

Timestep Collection Time: 2.14701
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.65087

Cumulative Model Updates: 143,276
Cumulative Timesteps: 1,194,702,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1194702868...
Checkpoint 1194702868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.41626
Policy Entropy: 3.85376
Value Function Loss: 0.02054

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.15345
Policy Update Magnitude: 0.65837
Value Function Update Magnitude: 0.94717

Collected Steps per Second: 23,136.09264
Overall Steps per Second: 10,760.50499

Timestep Collection Time: 2.16303
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65071

Cumulative Model Updates: 143,282
Cumulative Timesteps: 1,194,752,912

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,507.92094
Policy Entropy: 3.87395
Value Function Loss: 0.02376

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.17346
Policy Update Magnitude: 0.67907
Value Function Update Magnitude: 0.93221

Collected Steps per Second: 22,705.93911
Overall Steps per Second: 10,793.48987

Timestep Collection Time: 2.20224
Timestep Consumption Time: 2.43055
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.63279

Cumulative Model Updates: 143,288
Cumulative Timesteps: 1,194,802,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1194802916...
Checkpoint 1194802916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,361.24235
Policy Entropy: 3.81579
Value Function Loss: 0.02797

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16683
Policy Update Magnitude: 0.68974
Value Function Update Magnitude: 0.80089

Collected Steps per Second: 22,832.21957
Overall Steps per Second: 10,718.09616

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.47601
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66669

Cumulative Model Updates: 143,294
Cumulative Timesteps: 1,194,852,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,578.27371
Policy Entropy: 3.78590
Value Function Loss: 0.03414

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.65789
Value Function Update Magnitude: 0.62125

Collected Steps per Second: 22,579.29497
Overall Steps per Second: 10,796.17668

Timestep Collection Time: 2.21451
Timestep Consumption Time: 2.41695
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.63145

Cumulative Model Updates: 143,300
Cumulative Timesteps: 1,194,902,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1194902936...
Checkpoint 1194902936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,093.12048
Policy Entropy: 3.79268
Value Function Loss: 0.03227

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.63676
Value Function Update Magnitude: 0.57643

Collected Steps per Second: 22,624.58582
Overall Steps per Second: 10,675.00466

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.68627

Cumulative Model Updates: 143,306
Cumulative Timesteps: 1,194,952,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,130.68934
Policy Entropy: 3.78363
Value Function Loss: 0.03275

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13506
Policy Update Magnitude: 0.60814
Value Function Update Magnitude: 0.53931

Collected Steps per Second: 22,615.30815
Overall Steps per Second: 10,802.68352

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.63144

Cumulative Model Updates: 143,312
Cumulative Timesteps: 1,195,002,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1195002994...
Checkpoint 1195002994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,130.68934
Policy Entropy: 3.77100
Value Function Loss: 0.02956

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13685
Policy Update Magnitude: 0.58309
Value Function Update Magnitude: 0.40652

Collected Steps per Second: 22,553.62428
Overall Steps per Second: 10,700.34311

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.67349

Cumulative Model Updates: 143,318
Cumulative Timesteps: 1,195,053,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,904.30218
Policy Entropy: 3.75833
Value Function Loss: 0.03218

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.37483

Collected Steps per Second: 22,647.66637
Overall Steps per Second: 10,697.82491

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.67422

Cumulative Model Updates: 143,324
Cumulative Timesteps: 1,195,103,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1195103006...
Checkpoint 1195103006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,186.19577
Policy Entropy: 3.76195
Value Function Loss: 0.02994

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.60661
Value Function Update Magnitude: 0.41763

Collected Steps per Second: 22,843.67010
Overall Steps per Second: 10,852.00618

Timestep Collection Time: 2.18905
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60800

Cumulative Model Updates: 143,330
Cumulative Timesteps: 1,195,153,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,143.45032
Policy Entropy: 3.76204
Value Function Loss: 0.03037

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.66768
Value Function Update Magnitude: 0.49818

Collected Steps per Second: 22,800.85207
Overall Steps per Second: 10,854.59443

Timestep Collection Time: 2.19343
Timestep Consumption Time: 2.41402
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.60745

Cumulative Model Updates: 143,336
Cumulative Timesteps: 1,195,203,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1195203024...
Checkpoint 1195203024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,334.59437
Policy Entropy: 3.79016
Value Function Loss: 0.02908

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.64045
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 22,759.92255
Overall Steps per Second: 10,718.69803

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.66568

Cumulative Model Updates: 143,342
Cumulative Timesteps: 1,195,253,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.43885
Policy Entropy: 3.80539
Value Function Loss: 0.03111

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.61475
Value Function Update Magnitude: 0.52506

Collected Steps per Second: 22,572.03924
Overall Steps per Second: 10,833.91495

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.40106
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.61717

Cumulative Model Updates: 143,348
Cumulative Timesteps: 1,195,303,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1195303056...
Checkpoint 1195303056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.41622
Policy Entropy: 3.82432
Value Function Loss: 0.03162

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.61295
Value Function Update Magnitude: 0.46713

Collected Steps per Second: 22,967.07739
Overall Steps per Second: 10,734.87504

Timestep Collection Time: 2.17834
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.66051

Cumulative Model Updates: 143,354
Cumulative Timesteps: 1,195,353,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,703.88974
Policy Entropy: 3.79952
Value Function Loss: 0.03213

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.61197
Value Function Update Magnitude: 0.49115

Collected Steps per Second: 22,709.40924
Overall Steps per Second: 10,803.23182

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.62973

Cumulative Model Updates: 143,360
Cumulative Timesteps: 1,195,403,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1195403102...
Checkpoint 1195403102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,658.87126
Policy Entropy: 3.81440
Value Function Loss: 0.03134

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.59908
Value Function Update Magnitude: 0.54072

Collected Steps per Second: 22,929.08468
Overall Steps per Second: 10,724.98589

Timestep Collection Time: 2.18151
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.66388

Cumulative Model Updates: 143,366
Cumulative Timesteps: 1,195,453,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,334.62058
Policy Entropy: 3.81440
Value Function Loss: 0.03130

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.58502
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 22,730.32770
Overall Steps per Second: 10,803.91962

Timestep Collection Time: 2.20058
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.62980

Cumulative Model Updates: 143,372
Cumulative Timesteps: 1,195,503,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1195503142...
Checkpoint 1195503142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,831.58172
Policy Entropy: 3.82520
Value Function Loss: 0.02986

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.58490
Value Function Update Magnitude: 0.59762

Collected Steps per Second: 23,050.07826
Overall Steps per Second: 10,756.71010

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.64845

Cumulative Model Updates: 143,378
Cumulative Timesteps: 1,195,553,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,184.79900
Policy Entropy: 3.81533
Value Function Loss: 0.02682

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.69584

Collected Steps per Second: 22,801.94661
Overall Steps per Second: 10,824.72148

Timestep Collection Time: 2.19323
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.61998

Cumulative Model Updates: 143,384
Cumulative Timesteps: 1,195,603,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1195603154...
Checkpoint 1195603154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,591.58984
Policy Entropy: 3.81095
Value Function Loss: 0.02317

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.80728

Collected Steps per Second: 22,910.22301
Overall Steps per Second: 10,707.11592

Timestep Collection Time: 2.18348
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.67203

Cumulative Model Updates: 143,390
Cumulative Timesteps: 1,195,653,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,881.29151
Policy Entropy: 3.81434
Value Function Loss: 0.02252

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14784
Policy Update Magnitude: 0.49972
Value Function Update Magnitude: 0.79400

Collected Steps per Second: 22,970.29295
Overall Steps per Second: 10,887.05555

Timestep Collection Time: 2.17707
Timestep Consumption Time: 2.41627
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.59334

Cumulative Model Updates: 143,396
Cumulative Timesteps: 1,195,703,186

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1195703186...
Checkpoint 1195703186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,974.91643
Policy Entropy: 3.80985
Value Function Loss: 0.02256

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.49777
Value Function Update Magnitude: 0.87014

Collected Steps per Second: 23,065.40857
Overall Steps per Second: 10,762.69886

Timestep Collection Time: 2.16870
Timestep Consumption Time: 2.47902
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.64772

Cumulative Model Updates: 143,402
Cumulative Timesteps: 1,195,753,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,600.31897
Policy Entropy: 3.82659
Value Function Loss: 0.02426

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.53929
Value Function Update Magnitude: 0.93055

Collected Steps per Second: 23,153.82860
Overall Steps per Second: 10,850.64281

Timestep Collection Time: 2.16059
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.61042

Cumulative Model Updates: 143,408
Cumulative Timesteps: 1,195,803,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1195803234...
Checkpoint 1195803234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,086.73257
Policy Entropy: 3.82841
Value Function Loss: 0.02592

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.95942

Collected Steps per Second: 22,921.43051
Overall Steps per Second: 10,727.45305

Timestep Collection Time: 2.18276
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.66392

Cumulative Model Updates: 143,414
Cumulative Timesteps: 1,195,853,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,411.63344
Policy Entropy: 3.84342
Value Function Loss: 0.02441

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.92554

Collected Steps per Second: 23,103.15147
Overall Steps per Second: 10,802.20515

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.46605
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.63165

Cumulative Model Updates: 143,420
Cumulative Timesteps: 1,195,903,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1195903298...
Checkpoint 1195903298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,244.33211
Policy Entropy: 3.81008
Value Function Loss: 0.02388

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.49268
Value Function Update Magnitude: 0.83391

Collected Steps per Second: 23,016.16829
Overall Steps per Second: 10,783.87516

Timestep Collection Time: 2.17282
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.63748

Cumulative Model Updates: 143,426
Cumulative Timesteps: 1,195,953,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,597.11600
Policy Entropy: 3.79515
Value Function Loss: 0.02029

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14620
Policy Update Magnitude: 0.46315
Value Function Update Magnitude: 0.71304

Collected Steps per Second: 23,203.83641
Overall Steps per Second: 10,751.62092

Timestep Collection Time: 2.15585
Timestep Consumption Time: 2.49684
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.65269

Cumulative Model Updates: 143,432
Cumulative Timesteps: 1,196,003,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1196003332...
Checkpoint 1196003332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,472.10113
Policy Entropy: 3.77234
Value Function Loss: 0.02075

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.45342
Value Function Update Magnitude: 0.68982

Collected Steps per Second: 22,315.65318
Overall Steps per Second: 10,784.92240

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.39667
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.63833

Cumulative Model Updates: 143,438
Cumulative Timesteps: 1,196,053,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,385.71341
Policy Entropy: 3.77957
Value Function Loss: 0.02169

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.46670
Value Function Update Magnitude: 0.70337

Collected Steps per Second: 22,542.93049
Overall Steps per Second: 10,795.33904

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.63589

Cumulative Model Updates: 143,444
Cumulative Timesteps: 1,196,103,402

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1196103402...
Checkpoint 1196103402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,645.36640
Policy Entropy: 3.77123
Value Function Loss: 0.02507

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.50715
Value Function Update Magnitude: 0.81319

Collected Steps per Second: 22,294.76656
Overall Steps per Second: 10,797.25638

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.38832
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63118

Cumulative Model Updates: 143,450
Cumulative Timesteps: 1,196,153,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.70300
Policy Entropy: 3.77072
Value Function Loss: 0.02543

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14274
Policy Update Magnitude: 0.50680
Value Function Update Magnitude: 0.73818

Collected Steps per Second: 22,325.92910
Overall Steps per Second: 10,704.61548

Timestep Collection Time: 2.23982
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.67144

Cumulative Model Updates: 143,456
Cumulative Timesteps: 1,196,203,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1196203412...
Checkpoint 1196203412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,363.70300
Policy Entropy: 3.74949
Value Function Loss: 0.02312

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.48554
Value Function Update Magnitude: 0.63335

Collected Steps per Second: 22,298.68661
Overall Steps per Second: 10,647.33974

Timestep Collection Time: 2.24363
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69883

Cumulative Model Updates: 143,462
Cumulative Timesteps: 1,196,253,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,445.58665
Policy Entropy: 3.74093
Value Function Loss: 0.02081

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.43435
Value Function Update Magnitude: 0.53931

Collected Steps per Second: 22,799.76313
Overall Steps per Second: 10,867.50064

Timestep Collection Time: 2.19327
Timestep Consumption Time: 2.40816
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.60143

Cumulative Model Updates: 143,468
Cumulative Timesteps: 1,196,303,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1196303448...
Checkpoint 1196303448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,631.75626
Policy Entropy: 3.73808
Value Function Loss: 0.01963

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.41243
Value Function Update Magnitude: 0.47960

Collected Steps per Second: 22,975.70203
Overall Steps per Second: 10,712.66713

Timestep Collection Time: 2.17717
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.66943

Cumulative Model Updates: 143,474
Cumulative Timesteps: 1,196,353,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,507.07891
Policy Entropy: 3.73845
Value Function Loss: 0.02149

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.41951
Value Function Update Magnitude: 0.44671

Collected Steps per Second: 22,501.79903
Overall Steps per Second: 10,636.04081

Timestep Collection Time: 2.22231
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.70156

Cumulative Model Updates: 143,480
Cumulative Timesteps: 1,196,403,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1196403476...
Checkpoint 1196403476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,038.35261
Policy Entropy: 3.73415
Value Function Loss: 0.02082

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13711
Policy Update Magnitude: 0.44882
Value Function Update Magnitude: 0.47711

Collected Steps per Second: 23,036.90168
Overall Steps per Second: 10,949.70143

Timestep Collection Time: 2.17165
Timestep Consumption Time: 2.39725
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.56889

Cumulative Model Updates: 143,486
Cumulative Timesteps: 1,196,453,504

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,439.76447
Policy Entropy: 3.72325
Value Function Loss: 0.02269

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.47270
Value Function Update Magnitude: 0.49056

Collected Steps per Second: 22,949.52985
Overall Steps per Second: 10,912.13664

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.40423
PPO Batch Consumption Time: 0.27577
Total Iteration Time: 4.58370

Cumulative Model Updates: 143,492
Cumulative Timesteps: 1,196,503,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1196503522...
Checkpoint 1196503522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,858.15363
Policy Entropy: 3.74067
Value Function Loss: 0.02017

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.50017
Value Function Update Magnitude: 0.55942

Collected Steps per Second: 22,998.95097
Overall Steps per Second: 10,811.29025

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.45078
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.62479

Cumulative Model Updates: 143,498
Cumulative Timesteps: 1,196,553,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,690.15870
Policy Entropy: 3.74963
Value Function Loss: 0.02110

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.45433
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 22,725.48493
Overall Steps per Second: 10,690.22061

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.47740
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67792

Cumulative Model Updates: 143,504
Cumulative Timesteps: 1,196,603,530

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1196603530...
Checkpoint 1196603530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,306.58249
Policy Entropy: 3.73789
Value Function Loss: 0.01965

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.41536
Value Function Update Magnitude: 0.51808

Collected Steps per Second: 22,866.72103
Overall Steps per Second: 10,709.68360

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.67185

Cumulative Model Updates: 143,510
Cumulative Timesteps: 1,196,653,564

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,307.38131
Policy Entropy: 3.72795
Value Function Loss: 0.02107

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.39799
Value Function Update Magnitude: 0.52903

Collected Steps per Second: 22,425.30840
Overall Steps per Second: 10,869.07028

Timestep Collection Time: 2.23105
Timestep Consumption Time: 2.37210
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.60315

Cumulative Model Updates: 143,516
Cumulative Timesteps: 1,196,703,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1196703596...
Checkpoint 1196703596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,404.68025
Policy Entropy: 3.71962
Value Function Loss: 0.02086

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.46595
Value Function Update Magnitude: 0.58624

Collected Steps per Second: 22,162.07804
Overall Steps per Second: 10,749.99560

Timestep Collection Time: 2.25728
Timestep Consumption Time: 2.39630
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.65358

Cumulative Model Updates: 143,522
Cumulative Timesteps: 1,196,753,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,452.89972
Policy Entropy: 3.73868
Value Function Loss: 0.02052

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.65995

Collected Steps per Second: 22,412.02849
Overall Steps per Second: 10,751.97293

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.42072
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.65291

Cumulative Model Updates: 143,528
Cumulative Timesteps: 1,196,803,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1196803650...
Checkpoint 1196803650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,984.78178
Policy Entropy: 3.74375
Value Function Loss: 0.02147

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.47958
Value Function Update Magnitude: 0.70449

Collected Steps per Second: 22,176.10157
Overall Steps per Second: 10,635.87047

Timestep Collection Time: 2.25558
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.70295

Cumulative Model Updates: 143,534
Cumulative Timesteps: 1,196,853,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,854.25068
Policy Entropy: 3.75191
Value Function Loss: 0.01998

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.45924
Value Function Update Magnitude: 0.66803

Collected Steps per Second: 22,940.09986
Overall Steps per Second: 10,964.51801

Timestep Collection Time: 2.17994
Timestep Consumption Time: 2.38096
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.56089

Cumulative Model Updates: 143,540
Cumulative Timesteps: 1,196,903,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1196903678...
Checkpoint 1196903678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,690.19875
Policy Entropy: 3.75891
Value Function Loss: 0.01908

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.45620
Value Function Update Magnitude: 0.70790

Collected Steps per Second: 23,084.10533
Overall Steps per Second: 10,990.06276

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.38443
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.55120

Cumulative Model Updates: 143,546
Cumulative Timesteps: 1,196,953,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,093.43939
Policy Entropy: 3.77032
Value Function Loss: 0.01893

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.43994
Value Function Update Magnitude: 0.68153

Collected Steps per Second: 22,968.34776
Overall Steps per Second: 10,940.23924

Timestep Collection Time: 2.17717
Timestep Consumption Time: 2.39366
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.57083

Cumulative Model Updates: 143,552
Cumulative Timesteps: 1,197,003,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1197003702...
Checkpoint 1197003702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,029.22673
Policy Entropy: 3.76537
Value Function Loss: 0.01921

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.46930
Value Function Update Magnitude: 0.59204

Collected Steps per Second: 22,917.92633
Overall Steps per Second: 10,687.76323

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.49705
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.67918

Cumulative Model Updates: 143,558
Cumulative Timesteps: 1,197,053,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,471.00657
Policy Entropy: 3.73831
Value Function Loss: 0.02231

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 23,201.32776
Overall Steps per Second: 10,952.70227

Timestep Collection Time: 2.15600
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.56709

Cumulative Model Updates: 143,564
Cumulative Timesteps: 1,197,103,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1197103734...
Checkpoint 1197103734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,874.45543
Policy Entropy: 3.74044
Value Function Loss: 0.02098

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.52400
Value Function Update Magnitude: 0.59728

Collected Steps per Second: 22,964.38091
Overall Steps per Second: 10,763.97207

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.46794
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.64531

Cumulative Model Updates: 143,570
Cumulative Timesteps: 1,197,153,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,484.09844
Policy Entropy: 3.72901
Value Function Loss: 0.02289

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14246
Policy Update Magnitude: 0.52908
Value Function Update Magnitude: 0.61080

Collected Steps per Second: 23,093.69949
Overall Steps per Second: 10,730.27362

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.66009

Cumulative Model Updates: 143,576
Cumulative Timesteps: 1,197,203,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1197203740...
Checkpoint 1197203740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,811.64184
Policy Entropy: 3.74452
Value Function Loss: 0.02051

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.52524
Value Function Update Magnitude: 0.55154

Collected Steps per Second: 22,604.02182
Overall Steps per Second: 10,664.80452

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.47702
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68963

Cumulative Model Updates: 143,582
Cumulative Timesteps: 1,197,253,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,399.01746
Policy Entropy: 3.74106
Value Function Loss: 0.02077

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.51171
Value Function Update Magnitude: 0.55797

Collected Steps per Second: 23,041.78359
Overall Steps per Second: 10,920.70878

Timestep Collection Time: 2.17040
Timestep Consumption Time: 2.40897
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.57937

Cumulative Model Updates: 143,588
Cumulative Timesteps: 1,197,303,764

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1197303764...
Checkpoint 1197303764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,731.06659
Policy Entropy: 3.75142
Value Function Loss: 0.01849

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13420
Policy Update Magnitude: 0.47682
Value Function Update Magnitude: 0.58103

Collected Steps per Second: 22,978.82383
Overall Steps per Second: 10,728.92593

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.66123

Cumulative Model Updates: 143,594
Cumulative Timesteps: 1,197,353,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,534.41953
Policy Entropy: 3.75605
Value Function Loss: 0.02001

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.49502
Value Function Update Magnitude: 0.48683

Collected Steps per Second: 22,814.66291
Overall Steps per Second: 10,813.93719

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.62533

Cumulative Model Updates: 143,600
Cumulative Timesteps: 1,197,403,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1197403792...
Checkpoint 1197403792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,609.86852
Policy Entropy: 3.76410
Value Function Loss: 0.02289

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.48378
Value Function Update Magnitude: 0.48786

Collected Steps per Second: 22,512.20795
Overall Steps per Second: 10,609.92137

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.49265
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.71464

Cumulative Model Updates: 143,606
Cumulative Timesteps: 1,197,453,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,591.40554
Policy Entropy: 3.77959
Value Function Loss: 0.02575

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.50755
Value Function Update Magnitude: 0.62153

Collected Steps per Second: 22,871.78946
Overall Steps per Second: 10,871.72765

Timestep Collection Time: 2.18715
Timestep Consumption Time: 2.41414
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.60129

Cumulative Model Updates: 143,612
Cumulative Timesteps: 1,197,503,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1197503838...
Checkpoint 1197503838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,091.75500
Policy Entropy: 3.79735
Value Function Loss: 0.02560

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.56727
Value Function Update Magnitude: 0.66821

Collected Steps per Second: 22,871.15983
Overall Steps per Second: 10,691.16288

Timestep Collection Time: 2.18625
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67695

Cumulative Model Updates: 143,618
Cumulative Timesteps: 1,197,553,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,315.97730
Policy Entropy: 3.81915
Value Function Loss: 0.02595

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.53727
Value Function Update Magnitude: 0.56262

Collected Steps per Second: 23,058.33076
Overall Steps per Second: 10,867.01095

Timestep Collection Time: 2.17058
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60568

Cumulative Model Updates: 143,624
Cumulative Timesteps: 1,197,603,890

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1197603890...
Checkpoint 1197603890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,110.11719
Policy Entropy: 3.83005
Value Function Loss: 0.02559

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.52028
Value Function Update Magnitude: 0.54522

Collected Steps per Second: 22,736.37141
Overall Steps per Second: 10,690.75788

Timestep Collection Time: 2.19912
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.67694

Cumulative Model Updates: 143,630
Cumulative Timesteps: 1,197,653,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,350.04952
Policy Entropy: 3.80832
Value Function Loss: 0.03010

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.53344
Value Function Update Magnitude: 0.56784

Collected Steps per Second: 23,417.36334
Overall Steps per Second: 10,921.54399

Timestep Collection Time: 2.13525
Timestep Consumption Time: 2.44304
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.57829

Cumulative Model Updates: 143,636
Cumulative Timesteps: 1,197,703,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1197703892...
Checkpoint 1197703892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,697.64727
Policy Entropy: 3.79628
Value Function Loss: 0.02911

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.57223

Collected Steps per Second: 22,937.66721
Overall Steps per Second: 10,756.31689

Timestep Collection Time: 2.18008
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.64899

Cumulative Model Updates: 143,642
Cumulative Timesteps: 1,197,753,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.76104
Value Function Loss: 0.03116

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.54876

Collected Steps per Second: 23,450.17801
Overall Steps per Second: 10,841.32281

Timestep Collection Time: 2.13269
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.61309

Cumulative Model Updates: 143,648
Cumulative Timesteps: 1,197,803,910

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1197803910...
Checkpoint 1197803910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.74056
Value Function Loss: 0.02591

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.56184
Value Function Update Magnitude: 0.62872

Collected Steps per Second: 23,161.55826
Overall Steps per Second: 10,948.29442

Timestep Collection Time: 2.15909
Timestep Consumption Time: 2.40856
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.56765

Cumulative Model Updates: 143,654
Cumulative Timesteps: 1,197,853,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.71617
Value Function Loss: 0.02383

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.55795
Value Function Update Magnitude: 0.72024

Collected Steps per Second: 22,311.24969
Overall Steps per Second: 10,927.21020

Timestep Collection Time: 2.24335
Timestep Consumption Time: 2.33714
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.58049

Cumulative Model Updates: 143,660
Cumulative Timesteps: 1,197,903,970

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1197903970...
Checkpoint 1197903970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.72000
Value Function Loss: 0.02175

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.52393
Value Function Update Magnitude: 0.54079

Collected Steps per Second: 21,848.11789
Overall Steps per Second: 10,740.62241

Timestep Collection Time: 2.28953
Timestep Consumption Time: 2.36774
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.65727

Cumulative Model Updates: 143,666
Cumulative Timesteps: 1,197,953,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.73936
Value Function Loss: 0.02054

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.49988
Value Function Update Magnitude: 0.47050

Collected Steps per Second: 22,360.24412
Overall Steps per Second: 10,910.97072

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.34718
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.58401

Cumulative Model Updates: 143,672
Cumulative Timesteps: 1,198,004,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1198004008...
Checkpoint 1198004008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.75631
Value Function Loss: 0.01796

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.46482
Value Function Update Magnitude: 0.46561

Collected Steps per Second: 22,150.65537
Overall Steps per Second: 10,636.96540

Timestep Collection Time: 2.25781
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.70172

Cumulative Model Updates: 143,678
Cumulative Timesteps: 1,198,054,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,463.31101
Policy Entropy: 3.75619
Value Function Loss: 0.01592

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.43119
Value Function Update Magnitude: 0.45576

Collected Steps per Second: 23,157.20946
Overall Steps per Second: 10,904.65765

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.42633
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.58575

Cumulative Model Updates: 143,684
Cumulative Timesteps: 1,198,104,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1198104026...
Checkpoint 1198104026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,233.52496
Policy Entropy: 3.74640
Value Function Loss: 0.01504

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.39413
Value Function Update Magnitude: 0.44589

Collected Steps per Second: 22,958.53183
Overall Steps per Second: 10,771.44013

Timestep Collection Time: 2.17906
Timestep Consumption Time: 2.46545
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.64450

Cumulative Model Updates: 143,690
Cumulative Timesteps: 1,198,154,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,233.52496
Policy Entropy: 3.73440
Value Function Loss: 0.01413

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.37577
Value Function Update Magnitude: 0.40086

Collected Steps per Second: 23,153.44216
Overall Steps per Second: 10,767.80996

Timestep Collection Time: 2.16002
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.64458

Cumulative Model Updates: 143,696
Cumulative Timesteps: 1,198,204,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1198204066...
Checkpoint 1198204066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,233.52496
Policy Entropy: 3.74346
Value Function Loss: 0.01357

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.39916
Value Function Update Magnitude: 0.33187

Collected Steps per Second: 22,562.05332
Overall Steps per Second: 10,629.17230

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70422

Cumulative Model Updates: 143,702
Cumulative Timesteps: 1,198,254,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220,788.69339
Policy Entropy: 3.75540
Value Function Loss: 0.01697

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.45188
Value Function Update Magnitude: 0.42496

Collected Steps per Second: 23,091.19762
Overall Steps per Second: 10,902.74982

Timestep Collection Time: 2.16550
Timestep Consumption Time: 2.42087
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.58637

Cumulative Model Updates: 143,708
Cumulative Timesteps: 1,198,304,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1198304072...
Checkpoint 1198304072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,633.89585
Policy Entropy: 3.78635
Value Function Loss: 0.01707

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.50120
Value Function Update Magnitude: 0.49518

Collected Steps per Second: 22,771.15544
Overall Steps per Second: 10,691.39414

Timestep Collection Time: 2.19594
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.67703

Cumulative Model Updates: 143,714
Cumulative Timesteps: 1,198,354,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.50518
Policy Entropy: 3.80077
Value Function Loss: 0.01857

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.50780
Value Function Update Magnitude: 0.56168

Collected Steps per Second: 23,242.21511
Overall Steps per Second: 10,856.50368

Timestep Collection Time: 2.15169
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.60646

Cumulative Model Updates: 143,720
Cumulative Timesteps: 1,198,404,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1198404086...
Checkpoint 1198404086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,889.51708
Policy Entropy: 3.79581
Value Function Loss: 0.01768

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.53360
Value Function Update Magnitude: 0.58812

Collected Steps per Second: 22,156.68468
Overall Steps per Second: 10,724.69365

Timestep Collection Time: 2.25747
Timestep Consumption Time: 2.40635
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.66382

Cumulative Model Updates: 143,726
Cumulative Timesteps: 1,198,454,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,555.52387
Policy Entropy: 3.78008
Value Function Loss: 0.02277

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.55659
Value Function Update Magnitude: 0.70340

Collected Steps per Second: 22,464.04977
Overall Steps per Second: 10,860.29922

Timestep Collection Time: 2.22622
Timestep Consumption Time: 2.37862
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.60485

Cumulative Model Updates: 143,732
Cumulative Timesteps: 1,198,504,114

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1198504114...
Checkpoint 1198504114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,735.67368
Policy Entropy: 3.77902
Value Function Loss: 0.02557

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.66684

Collected Steps per Second: 22,452.21923
Overall Steps per Second: 10,848.83630

Timestep Collection Time: 2.22757
Timestep Consumption Time: 2.38250
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.61008

Cumulative Model Updates: 143,738
Cumulative Timesteps: 1,198,554,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,500.57659
Policy Entropy: 3.77766
Value Function Loss: 0.02540

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 22,253.74795
Overall Steps per Second: 10,745.99291

Timestep Collection Time: 2.24924
Timestep Consumption Time: 2.40868
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.65792

Cumulative Model Updates: 143,744
Cumulative Timesteps: 1,198,604,182

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1198604182...
Checkpoint 1198604182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,640.83304
Policy Entropy: 3.76713
Value Function Loss: 0.02458

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.53865
Value Function Update Magnitude: 0.59050

Collected Steps per Second: 22,210.77521
Overall Steps per Second: 10,599.50206

Timestep Collection Time: 2.25134
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.71758

Cumulative Model Updates: 143,750
Cumulative Timesteps: 1,198,654,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,640.83304
Policy Entropy: 3.75634
Value Function Loss: 0.02415

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.51616
Value Function Update Magnitude: 0.50068

Collected Steps per Second: 23,126.39722
Overall Steps per Second: 10,901.41307

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.42521
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.58785

Cumulative Model Updates: 143,756
Cumulative Timesteps: 1,198,704,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1198704200...
Checkpoint 1198704200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,394.57615
Policy Entropy: 3.73679
Value Function Loss: 0.02140

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.48536
Value Function Update Magnitude: 0.51660

Collected Steps per Second: 22,537.83302
Overall Steps per Second: 10,696.36159

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.45599
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.67449

Cumulative Model Updates: 143,762
Cumulative Timesteps: 1,198,754,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,910.96611
Policy Entropy: 3.73159
Value Function Loss: 0.02185

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.44542
Value Function Update Magnitude: 0.62372

Collected Steps per Second: 22,877.02226
Overall Steps per Second: 10,880.01657

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.59687

Cumulative Model Updates: 143,768
Cumulative Timesteps: 1,198,804,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1198804214...
Checkpoint 1198804214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,325.96602
Policy Entropy: 3.74326
Value Function Loss: 0.01981

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.44927
Value Function Update Magnitude: 0.67141

Collected Steps per Second: 22,729.36249
Overall Steps per Second: 10,666.30191

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.69066

Cumulative Model Updates: 143,774
Cumulative Timesteps: 1,198,854,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,014.14214
Policy Entropy: 3.76521
Value Function Loss: 0.02014

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.47232
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 23,068.82106
Overall Steps per Second: 10,834.73703

Timestep Collection Time: 2.16812
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.61626

Cumulative Model Updates: 143,780
Cumulative Timesteps: 1,198,904,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1198904262...
Checkpoint 1198904262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,416.83846
Policy Entropy: 3.77404
Value Function Loss: 0.02009

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.45747
Value Function Update Magnitude: 0.60101

Collected Steps per Second: 22,864.17200
Overall Steps per Second: 10,715.50674

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.48040
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66819

Cumulative Model Updates: 143,786
Cumulative Timesteps: 1,198,954,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,396.30096
Policy Entropy: 3.77804
Value Function Loss: 0.01868

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.47284
Value Function Update Magnitude: 0.61817

Collected Steps per Second: 23,351.59905
Overall Steps per Second: 10,818.89639

Timestep Collection Time: 2.14247
Timestep Consumption Time: 2.48185
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.62432

Cumulative Model Updates: 143,792
Cumulative Timesteps: 1,199,004,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1199004314...
Checkpoint 1199004314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,490.95276
Policy Entropy: 3.75764
Value Function Loss: 0.02210

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.46469
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 22,725.52631
Overall Steps per Second: 10,627.69310

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.70563

Cumulative Model Updates: 143,798
Cumulative Timesteps: 1,199,054,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,289.18048
Policy Entropy: 3.75626
Value Function Loss: 0.02014

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.48151
Value Function Update Magnitude: 0.56211

Collected Steps per Second: 23,165.74349
Overall Steps per Second: 10,907.77587

Timestep Collection Time: 2.15914
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.58554

Cumulative Model Updates: 143,804
Cumulative Timesteps: 1,199,104,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1199104342...
Checkpoint 1199104342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,289.18048
Policy Entropy: 3.74635
Value Function Loss: 0.01954

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.46673
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 22,906.79110
Overall Steps per Second: 10,700.91393

Timestep Collection Time: 2.18354
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.67418

Cumulative Model Updates: 143,810
Cumulative Timesteps: 1,199,154,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,289.18048
Policy Entropy: 3.75070
Value Function Loss: 0.01537

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.43562
Value Function Update Magnitude: 0.45250

Collected Steps per Second: 22,968.92246
Overall Steps per Second: 10,878.64696

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.41969
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.59690

Cumulative Model Updates: 143,816
Cumulative Timesteps: 1,199,204,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1199204368...
Checkpoint 1199204368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,191.26637
Policy Entropy: 3.74643
Value Function Loss: 0.01541

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.41568
Value Function Update Magnitude: 0.47493

Collected Steps per Second: 22,780.26050
Overall Steps per Second: 10,681.67550

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.68148

Cumulative Model Updates: 143,822
Cumulative Timesteps: 1,199,254,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 543,989.11100
Policy Entropy: 3.74935
Value Function Loss: 0.01865

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14197
Policy Update Magnitude: 0.47521
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 23,448.54600
Overall Steps per Second: 10,891.91269

Timestep Collection Time: 2.13327
Timestep Consumption Time: 2.45932
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.59258

Cumulative Model Updates: 143,828
Cumulative Timesteps: 1,199,304,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199304396...
Checkpoint 1199304396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,287.67268
Policy Entropy: 3.76595
Value Function Loss: 0.02159

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14113
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.82240

Collected Steps per Second: 22,876.83809
Overall Steps per Second: 10,714.94503

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.48146
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.66769

Cumulative Model Updates: 143,834
Cumulative Timesteps: 1,199,354,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,332.13354
Policy Entropy: 3.76003
Value Function Loss: 0.02361

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.61114
Value Function Update Magnitude: 0.96145

Collected Steps per Second: 22,992.69360
Overall Steps per Second: 10,829.58133

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.62105

Cumulative Model Updates: 143,840
Cumulative Timesteps: 1,199,404,454

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1199404454...
Checkpoint 1199404454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,557.84684
Policy Entropy: 3.76819
Value Function Loss: 0.02384

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.59024
Value Function Update Magnitude: 0.88348

Collected Steps per Second: 22,774.18788
Overall Steps per Second: 10,643.63042

Timestep Collection Time: 2.19608
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.69896

Cumulative Model Updates: 143,846
Cumulative Timesteps: 1,199,454,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,975.81930
Policy Entropy: 3.76224
Value Function Loss: 0.02388

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.79926

Collected Steps per Second: 23,046.89773
Overall Steps per Second: 10,900.53406

Timestep Collection Time: 2.17070
Timestep Consumption Time: 2.41880
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.58950

Cumulative Model Updates: 143,852
Cumulative Timesteps: 1,199,504,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1199504496...
Checkpoint 1199504496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,804.64044
Policy Entropy: 3.75779
Value Function Loss: 0.02212

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.72682

Collected Steps per Second: 22,703.32801
Overall Steps per Second: 10,674.20130

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.48316
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68663

Cumulative Model Updates: 143,858
Cumulative Timesteps: 1,199,554,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,804.64044
Policy Entropy: 3.73241
Value Function Loss: 0.02308

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.48378
Value Function Update Magnitude: 0.55906

Collected Steps per Second: 23,105.50886
Overall Steps per Second: 10,893.36224

Timestep Collection Time: 2.16399
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.58995

Cumulative Model Updates: 143,864
Cumulative Timesteps: 1,199,604,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1199604522...
Checkpoint 1199604522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,804.64044
Policy Entropy: 3.72579
Value Function Loss: 0.02024

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.46738
Value Function Update Magnitude: 0.43967

Collected Steps per Second: 22,556.84372
Overall Steps per Second: 10,608.55067

Timestep Collection Time: 2.21707
Timestep Consumption Time: 2.49706
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.71412

Cumulative Model Updates: 143,870
Cumulative Timesteps: 1,199,654,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,350.68829
Policy Entropy: 3.72234
Value Function Loss: 0.02095

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.44030
Value Function Update Magnitude: 0.34222

Collected Steps per Second: 22,776.66997
Overall Steps per Second: 10,828.76558

Timestep Collection Time: 2.19602
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61899

Cumulative Model Updates: 143,876
Cumulative Timesteps: 1,199,704,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1199704550...
Checkpoint 1199704550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,245.70701
Policy Entropy: 3.75533
Value Function Loss: 0.01967

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.47127
Value Function Update Magnitude: 0.41352

Collected Steps per Second: 21,933.77553
Overall Steps per Second: 10,733.04347

Timestep Collection Time: 2.27959
Timestep Consumption Time: 2.37892
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.65851

Cumulative Model Updates: 143,882
Cumulative Timesteps: 1,199,754,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,488.97147
Policy Entropy: 3.74470
Value Function Loss: 0.01984

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.51255
Value Function Update Magnitude: 0.50395

Collected Steps per Second: 22,454.67452
Overall Steps per Second: 10,903.98581

Timestep Collection Time: 2.22769
Timestep Consumption Time: 2.35981
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.58750

Cumulative Model Updates: 143,888
Cumulative Timesteps: 1,199,804,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1199804572...
Checkpoint 1199804572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,890.11217
Policy Entropy: 3.75673
Value Function Loss: 0.01730

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.47291
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 21,875.01094
Overall Steps per Second: 10,613.01337

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.71157

Cumulative Model Updates: 143,894
Cumulative Timesteps: 1,199,854,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,430.97369
Policy Entropy: 3.74118
Value Function Loss: 0.01611

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13863
Policy Update Magnitude: 0.44991
Value Function Update Magnitude: 0.56657

Collected Steps per Second: 22,578.71929
Overall Steps per Second: 10,831.70880

Timestep Collection Time: 2.21483
Timestep Consumption Time: 2.40199
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.61682

Cumulative Model Updates: 143,900
Cumulative Timesteps: 1,199,904,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1199904584...
Checkpoint 1199904584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,274.21477
Policy Entropy: 3.74905
Value Function Loss: 0.01543

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.44220
Value Function Update Magnitude: 0.55693

Collected Steps per Second: 22,768.09915
Overall Steps per Second: 10,710.36375

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.66931

Cumulative Model Updates: 143,906
Cumulative Timesteps: 1,199,954,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 388,274.21477
Policy Entropy: 3.75384
Value Function Loss: 0.01468

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.42843
Value Function Update Magnitude: 0.55470

Collected Steps per Second: 23,218.48682
Overall Steps per Second: 10,995.39154

Timestep Collection Time: 2.15449
Timestep Consumption Time: 2.39505
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.54954

Cumulative Model Updates: 143,912
Cumulative Timesteps: 1,200,004,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1200004618...
Checkpoint 1200004618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 388,274.21477
Policy Entropy: 3.73556
Value Function Loss: 0.01467

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.41657
Value Function Update Magnitude: 0.50822

Collected Steps per Second: 22,889.23311
Overall Steps per Second: 10,749.33548

Timestep Collection Time: 2.18470
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.65201

Cumulative Model Updates: 143,918
Cumulative Timesteps: 1,200,054,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,657.37309
Policy Entropy: 3.74489
Value Function Loss: 0.01763

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.44828
Value Function Update Magnitude: 0.52403

Collected Steps per Second: 23,170.81942
Overall Steps per Second: 10,749.27911

Timestep Collection Time: 2.15918
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.65427

Cumulative Model Updates: 143,924
Cumulative Timesteps: 1,200,104,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1200104654...
Checkpoint 1200104654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,983.50514
Policy Entropy: 3.75342
Value Function Loss: 0.01999

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.48968
Value Function Update Magnitude: 0.52104

Collected Steps per Second: 22,948.97546
Overall Steps per Second: 10,710.60739

Timestep Collection Time: 2.17979
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.67051

Cumulative Model Updates: 143,930
Cumulative Timesteps: 1,200,154,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,183.73251
Policy Entropy: 3.77167
Value Function Loss: 0.02097

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.51530
Value Function Update Magnitude: 0.45341

Collected Steps per Second: 23,337.13683
Overall Steps per Second: 10,843.56980

Timestep Collection Time: 2.14285
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.61177

Cumulative Model Updates: 143,936
Cumulative Timesteps: 1,200,204,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1200204686...
Checkpoint 1200204686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,649.83244
Policy Entropy: 3.76699
Value Function Loss: 0.02178

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.53078
Value Function Update Magnitude: 0.43451

Collected Steps per Second: 23,075.60744
Overall Steps per Second: 10,774.20089

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.64331

Cumulative Model Updates: 143,942
Cumulative Timesteps: 1,200,254,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,259.81950
Policy Entropy: 3.77448
Value Function Loss: 0.02303

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.45163

Collected Steps per Second: 23,138.40343
Overall Steps per Second: 10,751.00079

Timestep Collection Time: 2.16143
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.65185

Cumulative Model Updates: 143,948
Cumulative Timesteps: 1,200,304,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1200304726...
Checkpoint 1200304726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,163.95404
Policy Entropy: 3.77584
Value Function Loss: 0.02117

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.57096

Collected Steps per Second: 22,845.72045
Overall Steps per Second: 10,684.91871

Timestep Collection Time: 2.18938
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.68118

Cumulative Model Updates: 143,954
Cumulative Timesteps: 1,200,354,744

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,572.75091
Policy Entropy: 3.77494
Value Function Loss: 0.02066

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.65484

Collected Steps per Second: 23,164.56954
Overall Steps per Second: 10,885.09994

Timestep Collection Time: 2.15942
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.59546

Cumulative Model Updates: 143,960
Cumulative Timesteps: 1,200,404,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1200404766...
Checkpoint 1200404766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,352.06704
Policy Entropy: 3.78136
Value Function Loss: 0.01935

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.61228
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 22,688.54339
Overall Steps per Second: 10,662.78001

Timestep Collection Time: 2.20411
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.68996

Cumulative Model Updates: 143,966
Cumulative Timesteps: 1,200,454,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,259.78371
Policy Entropy: 3.78404
Value Function Loss: 0.02199

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14905
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.59940

Collected Steps per Second: 23,001.46493
Overall Steps per Second: 10,931.71711

Timestep Collection Time: 2.17464
Timestep Consumption Time: 2.40103
PPO Batch Consumption Time: 0.27563
Total Iteration Time: 4.57568

Cumulative Model Updates: 143,972
Cumulative Timesteps: 1,200,504,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1200504794...
Checkpoint 1200504794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,157.10763
Policy Entropy: 3.80516
Value Function Loss: 0.02068

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.50285

Collected Steps per Second: 22,915.42582
Overall Steps per Second: 10,773.03157

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.46027
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.64308

Cumulative Model Updates: 143,978
Cumulative Timesteps: 1,200,554,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,981.39058
Policy Entropy: 3.77405
Value Function Loss: 0.02075

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.49715
Value Function Update Magnitude: 0.45686

Collected Steps per Second: 23,199.53979
Overall Steps per Second: 10,779.44171

Timestep Collection Time: 2.15556
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.63920

Cumulative Model Updates: 143,984
Cumulative Timesteps: 1,200,604,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1200604822...
Checkpoint 1200604822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,635.84098
Policy Entropy: 3.77099
Value Function Loss: 0.02043

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.48808
Value Function Update Magnitude: 0.43018

Collected Steps per Second: 22,994.28789
Overall Steps per Second: 10,803.90413

Timestep Collection Time: 2.17515
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.62944

Cumulative Model Updates: 143,990
Cumulative Timesteps: 1,200,654,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,367.31735
Policy Entropy: 3.75728
Value Function Loss: 0.02105

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.52596
Value Function Update Magnitude: 0.42350

Collected Steps per Second: 22,448.56237
Overall Steps per Second: 10,787.63126

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.40791
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.63549

Cumulative Model Updates: 143,996
Cumulative Timesteps: 1,200,704,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1200704844...
Checkpoint 1200704844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,008.86461
Policy Entropy: 3.75728
Value Function Loss: 0.02174

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.41179

Collected Steps per Second: 22,125.74905
Overall Steps per Second: 10,787.74775

Timestep Collection Time: 2.26099
Timestep Consumption Time: 2.37631
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.63730

Cumulative Model Updates: 144,002
Cumulative Timesteps: 1,200,754,870

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,046.87089
Policy Entropy: 3.76978
Value Function Loss: 0.01997

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.41593

Collected Steps per Second: 22,307.04769
Overall Steps per Second: 10,716.70039

Timestep Collection Time: 2.24225
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.66729

Cumulative Model Updates: 144,008
Cumulative Timesteps: 1,200,804,888

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1200804888...
Checkpoint 1200804888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,803.10007
Policy Entropy: 3.75240
Value Function Loss: 0.02207

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.54239
Value Function Update Magnitude: 0.37045

Collected Steps per Second: 21,948.02405
Overall Steps per Second: 10,570.59419

Timestep Collection Time: 2.27884
Timestep Consumption Time: 2.45278
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.73162

Cumulative Model Updates: 144,014
Cumulative Timesteps: 1,200,854,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,187.94773
Policy Entropy: 3.78665
Value Function Loss: 0.01993

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.52650
Value Function Update Magnitude: 0.41759

Collected Steps per Second: 22,925.85245
Overall Steps per Second: 10,963.94326

Timestep Collection Time: 2.18190
Timestep Consumption Time: 2.38051
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.56241

Cumulative Model Updates: 144,020
Cumulative Timesteps: 1,200,904,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1200904926...
Checkpoint 1200904926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,187.94773
Policy Entropy: 3.75159
Value Function Loss: 0.02089

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.51878
Value Function Update Magnitude: 0.41869

Collected Steps per Second: 23,105.57904
Overall Steps per Second: 10,996.46566

Timestep Collection Time: 2.16467
Timestep Consumption Time: 2.38370
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.54837

Cumulative Model Updates: 144,026
Cumulative Timesteps: 1,200,954,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,187.94773
Policy Entropy: 3.75373
Value Function Loss: 0.02004

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.49048
Value Function Update Magnitude: 0.37692

Collected Steps per Second: 22,681.21177
Overall Steps per Second: 10,653.22993

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.69567

Cumulative Model Updates: 144,032
Cumulative Timesteps: 1,201,004,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1201004966...
Checkpoint 1201004966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,552.06723
Policy Entropy: 3.72990
Value Function Loss: 0.02208

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.47762
Value Function Update Magnitude: 0.34353

Collected Steps per Second: 22,939.25964
Overall Steps per Second: 10,855.95280

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.60577

Cumulative Model Updates: 144,038
Cumulative Timesteps: 1,201,054,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,082.39604
Policy Entropy: 3.74654
Value Function Loss: 0.02221

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13955
Policy Update Magnitude: 0.46783
Value Function Update Magnitude: 0.39706

Collected Steps per Second: 22,657.82431
Overall Steps per Second: 10,664.99896

Timestep Collection Time: 2.20736
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68955

Cumulative Model Updates: 144,044
Cumulative Timesteps: 1,201,104,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1201104980...
Checkpoint 1201104980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,107.18551
Policy Entropy: 3.76097
Value Function Loss: 0.02365

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.45225
Value Function Update Magnitude: 0.42467

Collected Steps per Second: 22,649.29478
Overall Steps per Second: 10,682.44425

Timestep Collection Time: 2.20899
Timestep Consumption Time: 2.47459
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68357

Cumulative Model Updates: 144,050
Cumulative Timesteps: 1,201,155,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,057.06383
Policy Entropy: 3.77088
Value Function Loss: 0.02273

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.47578
Value Function Update Magnitude: 0.44665

Collected Steps per Second: 23,193.11907
Overall Steps per Second: 10,759.23937

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.64940

Cumulative Model Updates: 144,056
Cumulative Timesteps: 1,201,205,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1201205036...
Checkpoint 1201205036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,425.75764
Policy Entropy: 3.77486
Value Function Loss: 0.02133

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.48656
Value Function Update Magnitude: 0.49848

Collected Steps per Second: 22,725.55116
Overall Steps per Second: 10,659.79763

Timestep Collection Time: 2.20201
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.69446

Cumulative Model Updates: 144,062
Cumulative Timesteps: 1,201,255,078

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,560.74180
Policy Entropy: 3.77151
Value Function Loss: 0.01997

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.51299
Value Function Update Magnitude: 0.53158

Collected Steps per Second: 23,016.19544
Overall Steps per Second: 10,919.53337

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.40782
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.58133

Cumulative Model Updates: 144,068
Cumulative Timesteps: 1,201,305,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1201305104...
Checkpoint 1201305104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,560.74180
Policy Entropy: 3.75931
Value Function Loss: 0.01716

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.50432

Collected Steps per Second: 22,926.63596
Overall Steps per Second: 10,753.63250

Timestep Collection Time: 2.18174
Timestep Consumption Time: 2.46971
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.65145

Cumulative Model Updates: 144,074
Cumulative Timesteps: 1,201,355,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,560.74180
Policy Entropy: 3.75578
Value Function Loss: 0.01432

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.52215
Value Function Update Magnitude: 0.43175

Collected Steps per Second: 23,201.48487
Overall Steps per Second: 10,770.95370

Timestep Collection Time: 2.15598
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.64416

Cumulative Model Updates: 144,080
Cumulative Timesteps: 1,201,405,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1201405146...
Checkpoint 1201405146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,560.74180
Policy Entropy: 3.75476
Value Function Loss: 0.01235

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.50207
Value Function Update Magnitude: 0.39605

Collected Steps per Second: 23,048.13391
Overall Steps per Second: 10,753.21515

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.65219

Cumulative Model Updates: 144,086
Cumulative Timesteps: 1,201,455,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405,021.00233
Policy Entropy: 3.75368
Value Function Loss: 0.01394

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07650
Policy Update Magnitude: 0.57009
Value Function Update Magnitude: 0.43256

Collected Steps per Second: 23,005.68274
Overall Steps per Second: 10,810.48530

Timestep Collection Time: 2.17398
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.62643

Cumulative Model Updates: 144,092
Cumulative Timesteps: 1,201,505,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1201505186...
Checkpoint 1201505186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,416.40457
Policy Entropy: 3.73630
Value Function Loss: 0.01872

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.61330
Value Function Update Magnitude: 0.45059

Collected Steps per Second: 23,057.44676
Overall Steps per Second: 10,752.81809

Timestep Collection Time: 2.16910
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.65125

Cumulative Model Updates: 144,098
Cumulative Timesteps: 1,201,555,200

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,816.38837
Policy Entropy: 3.73554
Value Function Loss: 0.02273

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.63681
Value Function Update Magnitude: 0.38257

Collected Steps per Second: 23,058.92050
Overall Steps per Second: 10,786.86922

Timestep Collection Time: 2.16879
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.63619

Cumulative Model Updates: 144,104
Cumulative Timesteps: 1,201,605,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1201605210...
Checkpoint 1201605210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 358,692.32129
Policy Entropy: 3.73420
Value Function Loss: 0.02366

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.62309
Value Function Update Magnitude: 0.34679

Collected Steps per Second: 22,945.63302
Overall Steps per Second: 10,729.36371

Timestep Collection Time: 2.17924
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.66048

Cumulative Model Updates: 144,110
Cumulative Timesteps: 1,201,655,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358,692.32129
Policy Entropy: 3.73913
Value Function Loss: 0.01911

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.47373

Collected Steps per Second: 22,930.56069
Overall Steps per Second: 10,802.12998

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.62890

Cumulative Model Updates: 144,116
Cumulative Timesteps: 1,201,705,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1201705216...
Checkpoint 1201705216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357,650.31954
Policy Entropy: 3.73060
Value Function Loss: 0.02253

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.51892
Value Function Update Magnitude: 0.53611

Collected Steps per Second: 22,788.98492
Overall Steps per Second: 10,636.36178

Timestep Collection Time: 2.19527
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.70349

Cumulative Model Updates: 144,122
Cumulative Timesteps: 1,201,755,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,711.20027
Policy Entropy: 3.73059
Value Function Loss: 0.02454

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.56278

Collected Steps per Second: 22,691.89616
Overall Steps per Second: 10,820.65971

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.41842
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.62282

Cumulative Model Updates: 144,128
Cumulative Timesteps: 1,201,805,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1201805266...
Checkpoint 1201805266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,870.16642
Policy Entropy: 3.73658
Value Function Loss: 0.02756

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.53821
Value Function Update Magnitude: 0.53211

Collected Steps per Second: 22,840.04642
Overall Steps per Second: 10,724.21058

Timestep Collection Time: 2.18966
Timestep Consumption Time: 2.47380
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.66347

Cumulative Model Updates: 144,134
Cumulative Timesteps: 1,201,855,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,415.32364
Policy Entropy: 3.73532
Value Function Loss: 0.02653

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.56349

Collected Steps per Second: 22,715.05523
Overall Steps per Second: 10,836.57422

Timestep Collection Time: 2.20250
Timestep Consumption Time: 2.41427
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.61677

Cumulative Model Updates: 144,140
Cumulative Timesteps: 1,201,905,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1201905308...
Checkpoint 1201905308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,002.19744
Policy Entropy: 3.75783
Value Function Loss: 0.02485

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.57126
Value Function Update Magnitude: 0.53555

Collected Steps per Second: 22,925.48032
Overall Steps per Second: 10,696.68331

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.67584

Cumulative Model Updates: 144,146
Cumulative Timesteps: 1,201,955,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,333.21207
Policy Entropy: 3.76154
Value Function Loss: 0.02432

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.55893
Value Function Update Magnitude: 0.52218

Collected Steps per Second: 22,915.87670
Overall Steps per Second: 10,858.09401

Timestep Collection Time: 2.18259
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.60633

Cumulative Model Updates: 144,152
Cumulative Timesteps: 1,202,005,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1202005340...
Checkpoint 1202005340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,273.63924
Policy Entropy: 3.77865
Value Function Loss: 0.02388

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.56153
Value Function Update Magnitude: 0.58113

Collected Steps per Second: 22,983.58428
Overall Steps per Second: 10,722.82398

Timestep Collection Time: 2.17625
Timestep Consumption Time: 2.48838
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.66463

Cumulative Model Updates: 144,158
Cumulative Timesteps: 1,202,055,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.55110
Policy Entropy: 3.77755
Value Function Loss: 0.02403

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.70666

Collected Steps per Second: 22,444.65958
Overall Steps per Second: 10,788.05979

Timestep Collection Time: 2.22859
Timestep Consumption Time: 2.40802
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.63661

Cumulative Model Updates: 144,164
Cumulative Timesteps: 1,202,105,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1202105378...
Checkpoint 1202105378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,787.07143
Policy Entropy: 3.79122
Value Function Loss: 0.02220

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.61472
Value Function Update Magnitude: 0.74774

Collected Steps per Second: 22,239.10899
Overall Steps per Second: 10,759.65818

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.40138
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.65219

Cumulative Model Updates: 144,170
Cumulative Timesteps: 1,202,155,434

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,179.39039
Policy Entropy: 3.78341
Value Function Loss: 0.02016

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.60868
Value Function Update Magnitude: 0.79508

Collected Steps per Second: 22,356.31842
Overall Steps per Second: 10,879.03825

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.36043
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.59783

Cumulative Model Updates: 144,176
Cumulative Timesteps: 1,202,205,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1202205454...
Checkpoint 1202205454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,331.96265
Policy Entropy: 3.78034
Value Function Loss: 0.02001

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16588
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.77062

Collected Steps per Second: 22,254.78755
Overall Steps per Second: 10,733.00470

Timestep Collection Time: 2.24752
Timestep Consumption Time: 2.41269
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.66020

Cumulative Model Updates: 144,182
Cumulative Timesteps: 1,202,255,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,483.61374
Policy Entropy: 3.76044
Value Function Loss: 0.02331

Mean KL Divergence: 0.02523
SB3 Clip Fraction: 0.26316
Policy Update Magnitude: 0.49088
Value Function Update Magnitude: 0.65811

Collected Steps per Second: 22,234.17002
Overall Steps per Second: 10,764.22280

Timestep Collection Time: 2.24960
Timestep Consumption Time: 2.39709
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.64669

Cumulative Model Updates: 144,188
Cumulative Timesteps: 1,202,305,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1202305490...
Checkpoint 1202305490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,718.01470
Policy Entropy: 3.76123
Value Function Loss: 0.03251

Mean KL Divergence: 0.02255
SB3 Clip Fraction: 0.25454
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.51798

Collected Steps per Second: 22,992.22756
Overall Steps per Second: 10,781.72531

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.63915

Cumulative Model Updates: 144,194
Cumulative Timesteps: 1,202,355,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,891.54622
Policy Entropy: 3.80597
Value Function Loss: 0.05045

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.20367
Policy Update Magnitude: 0.65456
Value Function Update Magnitude: 0.46372

Collected Steps per Second: 22,681.57881
Overall Steps per Second: 10,881.68259

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.39121
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.59635

Cumulative Model Updates: 144,200
Cumulative Timesteps: 1,202,405,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1202405524...
Checkpoint 1202405524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540.33873
Policy Entropy: 3.86522
Value Function Loss: 0.06262

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.17912
Policy Update Magnitude: 0.91773
Value Function Update Magnitude: 0.53979

Collected Steps per Second: 22,812.44536
Overall Steps per Second: 11,048.20417

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.33505
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.52798

Cumulative Model Updates: 144,206
Cumulative Timesteps: 1,202,455,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.85119
Policy Entropy: 3.86999
Value Function Loss: 0.04993

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.17102
Policy Update Magnitude: 0.99732
Value Function Update Magnitude: 0.63195

Collected Steps per Second: 22,065.51731
Overall Steps per Second: 10,571.16248

Timestep Collection Time: 2.26725
Timestep Consumption Time: 2.46525
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.73250

Cumulative Model Updates: 144,212
Cumulative Timesteps: 1,202,505,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1202505578...
Checkpoint 1202505578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,618.42743
Policy Entropy: 3.82713
Value Function Loss: 0.04174

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.16614
Policy Update Magnitude: 0.97295
Value Function Update Magnitude: 0.69963

Collected Steps per Second: 22,916.30011
Overall Steps per Second: 10,952.41681

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.38402
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.56648

Cumulative Model Updates: 144,218
Cumulative Timesteps: 1,202,555,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.85184
Policy Entropy: 3.77122
Value Function Loss: 0.03354

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.16951
Policy Update Magnitude: 0.85548
Value Function Update Magnitude: 0.73626

Collected Steps per Second: 22,817.36906
Overall Steps per Second: 10,883.86727

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.40408
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.59671

Cumulative Model Updates: 144,224
Cumulative Timesteps: 1,202,605,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1202605622...
Checkpoint 1202605622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.18166
Policy Entropy: 3.76194
Value Function Loss: 0.03701

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.17566
Policy Update Magnitude: 0.80465
Value Function Update Magnitude: 0.66275

Collected Steps per Second: 22,811.10825
Overall Steps per Second: 10,722.59767

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.47133
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.66342

Cumulative Model Updates: 144,230
Cumulative Timesteps: 1,202,655,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,668.67877
Policy Entropy: 3.78746
Value Function Loss: 0.03252

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.69554
Value Function Update Magnitude: 0.49586

Collected Steps per Second: 22,824.85555
Overall Steps per Second: 10,926.99814

Timestep Collection Time: 2.19182
Timestep Consumption Time: 2.38656
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.57838

Cumulative Model Updates: 144,236
Cumulative Timesteps: 1,202,705,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1202705654...
Checkpoint 1202705654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,286.05328
Policy Entropy: 3.81676
Value Function Loss: 0.03190

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.67419
Value Function Update Magnitude: 0.59716

Collected Steps per Second: 22,978.59920
Overall Steps per Second: 10,785.01857

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.63810

Cumulative Model Updates: 144,242
Cumulative Timesteps: 1,202,755,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.17807
Policy Entropy: 3.83647
Value Function Loss: 0.03394

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.68242
Value Function Update Magnitude: 0.64876

Collected Steps per Second: 22,778.57950
Overall Steps per Second: 10,748.39337

Timestep Collection Time: 2.19548
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.65279

Cumulative Model Updates: 144,248
Cumulative Timesteps: 1,202,805,686

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1202805686...
Checkpoint 1202805686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,589.26789
Policy Entropy: 3.84755
Value Function Loss: 0.03512

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.66312
Value Function Update Magnitude: 0.72117

Collected Steps per Second: 22,851.95526
Overall Steps per Second: 10,792.58685

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.63577

Cumulative Model Updates: 144,254
Cumulative Timesteps: 1,202,855,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 535.64473
Policy Entropy: 3.83493
Value Function Loss: 0.03120

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.61648
Value Function Update Magnitude: 0.77029

Collected Steps per Second: 23,216.24627
Overall Steps per Second: 10,871.23102

Timestep Collection Time: 2.15410
Timestep Consumption Time: 2.44612
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.60021

Cumulative Model Updates: 144,260
Cumulative Timesteps: 1,202,905,728

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1202905728...
Checkpoint 1202905728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.58448
Policy Entropy: 3.82110
Value Function Loss: 0.02847

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.59376
Value Function Update Magnitude: 0.68616

Collected Steps per Second: 22,928.07978
Overall Steps per Second: 10,884.83580

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.41407
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.59594

Cumulative Model Updates: 144,266
Cumulative Timesteps: 1,202,955,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.26052
Policy Entropy: 3.79527
Value Function Loss: 0.02385

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11427
Policy Update Magnitude: 0.52690
Value Function Update Magnitude: 0.56070

Collected Steps per Second: 22,963.81388
Overall Steps per Second: 10,756.74295

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.65029

Cumulative Model Updates: 144,272
Cumulative Timesteps: 1,203,005,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1203005776...
Checkpoint 1203005776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,394.56992
Policy Entropy: 3.80105
Value Function Loss: 0.02145

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.48243
Value Function Update Magnitude: 0.55011

Collected Steps per Second: 23,221.85016
Overall Steps per Second: 10,898.86547

Timestep Collection Time: 2.15366
Timestep Consumption Time: 2.43507
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.58873

Cumulative Model Updates: 144,278
Cumulative Timesteps: 1,203,055,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,656.65724
Policy Entropy: 3.77782
Value Function Loss: 0.02196

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.47437
Value Function Update Magnitude: 0.53793

Collected Steps per Second: 22,860.84464
Overall Steps per Second: 10,827.12929

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.61914

Cumulative Model Updates: 144,284
Cumulative Timesteps: 1,203,105,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1203105800...
Checkpoint 1203105800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,275.67001
Policy Entropy: 3.79266
Value Function Loss: 0.02258

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.48654
Value Function Update Magnitude: 0.54776

Collected Steps per Second: 23,240.28239
Overall Steps per Second: 10,762.67213

Timestep Collection Time: 2.15256
Timestep Consumption Time: 2.49555
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.64810

Cumulative Model Updates: 144,290
Cumulative Timesteps: 1,203,155,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,517.97467
Policy Entropy: 3.77843
Value Function Loss: 0.02300

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.49811
Value Function Update Magnitude: 0.53430

Collected Steps per Second: 23,082.05182
Overall Steps per Second: 10,860.92922

Timestep Collection Time: 2.16757
Timestep Consumption Time: 2.43903
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.60660

Cumulative Model Updates: 144,296
Cumulative Timesteps: 1,203,205,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1203205858...
Checkpoint 1203205858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.95090
Policy Entropy: 3.80634
Value Function Loss: 0.02324

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.47697
Value Function Update Magnitude: 0.56751

Collected Steps per Second: 23,042.34708
Overall Steps per Second: 10,712.42349

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.66972

Cumulative Model Updates: 144,302
Cumulative Timesteps: 1,203,255,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,469.54155
Policy Entropy: 3.80184
Value Function Loss: 0.02386

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,742.54068
Overall Steps per Second: 10,862.37629

Timestep Collection Time: 2.19905
Timestep Consumption Time: 2.40510
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.60415

Cumulative Model Updates: 144,308
Cumulative Timesteps: 1,203,305,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1203305894...
Checkpoint 1203305894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.34535
Policy Entropy: 3.79877
Value Function Loss: 0.02199

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.50971
Value Function Update Magnitude: 0.58252

Collected Steps per Second: 23,006.43933
Overall Steps per Second: 10,769.80674

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.64502

Cumulative Model Updates: 144,314
Cumulative Timesteps: 1,203,355,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.28684
Policy Entropy: 3.76940
Value Function Loss: 0.02030

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.48018
Value Function Update Magnitude: 0.61338

Collected Steps per Second: 22,962.04186
Overall Steps per Second: 10,731.60115

Timestep Collection Time: 2.17751
Timestep Consumption Time: 2.48163
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.65914

Cumulative Model Updates: 144,320
Cumulative Timesteps: 1,203,405,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1203405920...
Checkpoint 1203405920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,434.17128
Policy Entropy: 3.75205
Value Function Loss: 0.02076

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.47420
Value Function Update Magnitude: 0.53937

Collected Steps per Second: 23,034.64339
Overall Steps per Second: 10,712.63690

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.49734
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.66851

Cumulative Model Updates: 144,326
Cumulative Timesteps: 1,203,455,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,259.16117
Policy Entropy: 3.74357
Value Function Loss: 0.02094

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.48506
Value Function Update Magnitude: 0.46095

Collected Steps per Second: 22,997.07206
Overall Steps per Second: 10,884.76688

Timestep Collection Time: 2.17532
Timestep Consumption Time: 2.42064
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.59596

Cumulative Model Updates: 144,332
Cumulative Timesteps: 1,203,505,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1203505958...
Checkpoint 1203505958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,259.16117
Policy Entropy: 3.75733
Value Function Loss: 0.01690

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.43225
Value Function Update Magnitude: 0.41890

Collected Steps per Second: 23,080.95766
Overall Steps per Second: 10,778.51606

Timestep Collection Time: 2.16741
Timestep Consumption Time: 2.47386
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.64127

Cumulative Model Updates: 144,338
Cumulative Timesteps: 1,203,555,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,259.16117
Policy Entropy: 3.76417
Value Function Loss: 0.01422

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.39644
Value Function Update Magnitude: 0.41330

Collected Steps per Second: 23,152.90469
Overall Steps per Second: 10,715.77055

Timestep Collection Time: 2.16077
Timestep Consumption Time: 2.50787
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.66863

Cumulative Model Updates: 144,344
Cumulative Timesteps: 1,203,606,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1203606012...
Checkpoint 1203606012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,134.06915
Policy Entropy: 3.75737
Value Function Loss: 0.01885

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.43070
Value Function Update Magnitude: 0.43682

Collected Steps per Second: 22,990.89651
Overall Steps per Second: 10,750.34026

Timestep Collection Time: 2.17503
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.65157

Cumulative Model Updates: 144,350
Cumulative Timesteps: 1,203,656,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,191.23955
Policy Entropy: 3.78453
Value Function Loss: 0.01906

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.49532
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 23,090.22234
Overall Steps per Second: 10,831.33883

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.61697

Cumulative Model Updates: 144,356
Cumulative Timesteps: 1,203,706,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1203706026...
Checkpoint 1203706026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,900.12699
Policy Entropy: 3.77057
Value Function Loss: 0.02386

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.55238
Value Function Update Magnitude: 0.72746

Collected Steps per Second: 23,173.99482
Overall Steps per Second: 10,963.28007

Timestep Collection Time: 2.15794
Timestep Consumption Time: 2.40347
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.56141

Cumulative Model Updates: 144,362
Cumulative Timesteps: 1,203,756,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,686.71273
Policy Entropy: 3.80673
Value Function Loss: 0.02276

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.63870
Value Function Update Magnitude: 0.79535

Collected Steps per Second: 23,164.71306
Overall Steps per Second: 10,932.83257

Timestep Collection Time: 2.15846
Timestep Consumption Time: 2.41492
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.57338

Cumulative Model Updates: 144,368
Cumulative Timesteps: 1,203,806,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1203806034...
Checkpoint 1203806034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,452.16834
Policy Entropy: 3.78552
Value Function Loss: 0.02340

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.63405
Value Function Update Magnitude: 0.83806

Collected Steps per Second: 23,009.69834
Overall Steps per Second: 10,729.11308

Timestep Collection Time: 2.17447
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.66339

Cumulative Model Updates: 144,374
Cumulative Timesteps: 1,203,856,068

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.19418
Policy Entropy: 3.79947
Value Function Loss: 0.02250

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.59236
Value Function Update Magnitude: 0.83576

Collected Steps per Second: 22,359.99148
Overall Steps per Second: 10,897.33580

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.35233
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.58864

Cumulative Model Updates: 144,380
Cumulative Timesteps: 1,203,906,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1203906072...
Checkpoint 1203906072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,465.45971
Policy Entropy: 3.76314
Value Function Loss: 0.02293

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.59782
Value Function Update Magnitude: 0.80615

Collected Steps per Second: 22,480.10472
Overall Steps per Second: 10,824.37083

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.39569
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.62050

Cumulative Model Updates: 144,386
Cumulative Timesteps: 1,203,956,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,099.71286
Policy Entropy: 3.75831
Value Function Loss: 0.02328

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.60860
Value Function Update Magnitude: 0.88767

Collected Steps per Second: 22,500.65137
Overall Steps per Second: 10,817.15324

Timestep Collection Time: 2.22340
Timestep Consumption Time: 2.40147
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.62488

Cumulative Model Updates: 144,392
Cumulative Timesteps: 1,204,006,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1204006114...
Checkpoint 1204006114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,526.09122
Policy Entropy: 3.75933
Value Function Loss: 0.02104

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.60687
Value Function Update Magnitude: 0.91045

Collected Steps per Second: 22,332.44119
Overall Steps per Second: 10,637.87806

Timestep Collection Time: 2.24033
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70319

Cumulative Model Updates: 144,398
Cumulative Timesteps: 1,204,056,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,762.00409
Policy Entropy: 3.76132
Value Function Loss: 0.01875

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.55451
Value Function Update Magnitude: 0.81843

Collected Steps per Second: 23,180.94871
Overall Steps per Second: 10,839.33818

Timestep Collection Time: 2.15789
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.61486

Cumulative Model Updates: 144,404
Cumulative Timesteps: 1,204,106,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1204106168...
Checkpoint 1204106168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,762.00409
Policy Entropy: 3.75914
Value Function Loss: 0.01757

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.48823
Value Function Update Magnitude: 0.67639

Collected Steps per Second: 22,963.62901
Overall Steps per Second: 10,841.45638

Timestep Collection Time: 2.17736
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.61193

Cumulative Model Updates: 144,410
Cumulative Timesteps: 1,204,156,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,986.76982
Policy Entropy: 3.75600
Value Function Loss: 0.01619

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.46597
Value Function Update Magnitude: 0.64714

Collected Steps per Second: 22,888.20660
Overall Steps per Second: 10,668.18023

Timestep Collection Time: 2.18471
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.68721

Cumulative Model Updates: 144,416
Cumulative Timesteps: 1,204,206,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1204206172...
Checkpoint 1204206172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,700.58524
Policy Entropy: 3.75124
Value Function Loss: 0.01752

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.46959
Value Function Update Magnitude: 0.66716

Collected Steps per Second: 22,728.06467
Overall Steps per Second: 10,640.15116

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70181

Cumulative Model Updates: 144,422
Cumulative Timesteps: 1,204,256,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,741.38352
Policy Entropy: 3.76493
Value Function Loss: 0.01638

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.45243
Value Function Update Magnitude: 0.63416

Collected Steps per Second: 22,936.66207
Overall Steps per Second: 10,879.87830

Timestep Collection Time: 2.18114
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.59821

Cumulative Model Updates: 144,428
Cumulative Timesteps: 1,204,306,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1204306228...
Checkpoint 1204306228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,197.50962
Policy Entropy: 3.75589
Value Function Loss: 0.02093

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.48327
Value Function Update Magnitude: 0.51449

Collected Steps per Second: 23,062.00428
Overall Steps per Second: 10,744.87998

Timestep Collection Time: 2.16928
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.65599

Cumulative Model Updates: 144,434
Cumulative Timesteps: 1,204,356,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,420.80750
Policy Entropy: 3.76035
Value Function Loss: 0.01983

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.51038
Value Function Update Magnitude: 0.47900

Collected Steps per Second: 22,680.68209
Overall Steps per Second: 10,784.69505

Timestep Collection Time: 2.20470
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.63657

Cumulative Model Updates: 144,440
Cumulative Timesteps: 1,204,406,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1204406260...
Checkpoint 1204406260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,759.99894
Policy Entropy: 3.76662
Value Function Loss: 0.02155

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.51756
Value Function Update Magnitude: 0.53014

Collected Steps per Second: 23,235.37284
Overall Steps per Second: 10,770.21322

Timestep Collection Time: 2.15275
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.64429

Cumulative Model Updates: 144,446
Cumulative Timesteps: 1,204,456,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,851.86763
Policy Entropy: 3.78660
Value Function Loss: 0.02000

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.51014
Value Function Update Magnitude: 0.54012

Collected Steps per Second: 22,961.99019
Overall Steps per Second: 10,884.66983

Timestep Collection Time: 2.17751
Timestep Consumption Time: 2.41611
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.59362

Cumulative Model Updates: 144,452
Cumulative Timesteps: 1,204,506,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1204506280...
Checkpoint 1204506280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,104.00024
Policy Entropy: 3.78057
Value Function Loss: 0.01830

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.49544
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 23,135.92527
Overall Steps per Second: 10,795.28675

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.63350

Cumulative Model Updates: 144,458
Cumulative Timesteps: 1,204,556,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,104.00024
Policy Entropy: 3.76051
Value Function Loss: 0.01703

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.47745
Value Function Update Magnitude: 0.58403

Collected Steps per Second: 23,179.31040
Overall Steps per Second: 10,746.67864

Timestep Collection Time: 2.15761
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.65372

Cumulative Model Updates: 144,464
Cumulative Timesteps: 1,204,606,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1204606312...
Checkpoint 1204606312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,683.48947
Policy Entropy: 3.75442
Value Function Loss: 0.01622

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.51537
Value Function Update Magnitude: 0.62771

Collected Steps per Second: 22,886.28907
Overall Steps per Second: 10,716.84742

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.66667

Cumulative Model Updates: 144,470
Cumulative Timesteps: 1,204,656,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,551.45496
Policy Entropy: 3.76566
Value Function Loss: 0.01713

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.70298

Collected Steps per Second: 23,094.80663
Overall Steps per Second: 10,785.70844

Timestep Collection Time: 2.16499
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.63576

Cumulative Model Updates: 144,476
Cumulative Timesteps: 1,204,706,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1204706324...
Checkpoint 1204706324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,423.36066
Policy Entropy: 3.77729
Value Function Loss: 0.01817

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.54555
Value Function Update Magnitude: 0.82202

Collected Steps per Second: 22,847.78039
Overall Steps per Second: 10,687.68084

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.49048
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.67941

Cumulative Model Updates: 144,482
Cumulative Timesteps: 1,204,756,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,016.36258
Policy Entropy: 3.77289
Value Function Loss: 0.01780

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.88899

Collected Steps per Second: 22,824.36401
Overall Steps per Second: 10,889.71544

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.40181
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.59332

Cumulative Model Updates: 144,488
Cumulative Timesteps: 1,204,806,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1204806356...
Checkpoint 1204806356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,355.40967
Policy Entropy: 3.76328
Value Function Loss: 0.01910

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.57151
Value Function Update Magnitude: 0.82895

Collected Steps per Second: 22,834.87552
Overall Steps per Second: 10,656.23856

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69378

Cumulative Model Updates: 144,494
Cumulative Timesteps: 1,204,856,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,662.21428
Policy Entropy: 3.76984
Value Function Loss: 0.01705

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.80871

Collected Steps per Second: 22,705.37018
Overall Steps per Second: 10,840.88451

Timestep Collection Time: 2.20336
Timestep Consumption Time: 2.41140
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61475

Cumulative Model Updates: 144,500
Cumulative Timesteps: 1,204,906,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1204906402...
Checkpoint 1204906402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,662.21428
Policy Entropy: 3.75733
Value Function Loss: 0.02084

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.52154
Value Function Update Magnitude: 0.68261

Collected Steps per Second: 23,076.44669
Overall Steps per Second: 10,793.45329

Timestep Collection Time: 2.16697
Timestep Consumption Time: 2.46602
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.63299

Cumulative Model Updates: 144,506
Cumulative Timesteps: 1,204,956,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,135.10521
Policy Entropy: 3.74679
Value Function Loss: 0.02080

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.55316
Value Function Update Magnitude: 0.54864

Collected Steps per Second: 22,031.63764
Overall Steps per Second: 10,779.90501

Timestep Collection Time: 2.27037
Timestep Consumption Time: 2.36974
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.64012

Cumulative Model Updates: 144,512
Cumulative Timesteps: 1,205,006,428

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1205006428...
Checkpoint 1205006428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.73325
Value Function Loss: 0.02025

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.54603

Collected Steps per Second: 22,332.98903
Overall Steps per Second: 10,734.98958

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.65841

Cumulative Model Updates: 144,518
Cumulative Timesteps: 1,205,056,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.74687
Value Function Loss: 0.01604

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.48591

Collected Steps per Second: 22,285.22187
Overall Steps per Second: 10,819.53312

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.37801
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.62201

Cumulative Model Updates: 144,524
Cumulative Timesteps: 1,205,106,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1205106444...
Checkpoint 1205106444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.76181
Value Function Loss: 0.01192

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.37997

Collected Steps per Second: 22,375.52490
Overall Steps per Second: 10,640.99473

Timestep Collection Time: 2.23539
Timestep Consumption Time: 2.46511
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.70050

Cumulative Model Updates: 144,530
Cumulative Timesteps: 1,205,156,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.76160
Value Function Loss: 0.01068

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06015
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.35296

Collected Steps per Second: 22,475.05549
Overall Steps per Second: 10,818.18183

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.39802
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.62351

Cumulative Model Updates: 144,536
Cumulative Timesteps: 1,205,206,480

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1205206480...
Checkpoint 1205206480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.76371
Value Function Loss: 0.01148

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12360
Policy Update Magnitude: 0.51945
Value Function Update Magnitude: 0.47723

Collected Steps per Second: 22,698.85862
Overall Steps per Second: 10,720.56016

Timestep Collection Time: 2.20337
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.66524

Cumulative Model Updates: 144,542
Cumulative Timesteps: 1,205,256,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.76242
Value Function Loss: 0.01188

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.08447
Policy Update Magnitude: 0.52052
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 22,887.77226
Overall Steps per Second: 10,873.32015

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.41606
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.60264

Cumulative Model Updates: 144,548
Cumulative Timesteps: 1,205,306,540

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1205306540...
Checkpoint 1205306540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.76302
Value Function Loss: 0.01065

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07859
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 23,067.17840
Overall Steps per Second: 10,759.90559

Timestep Collection Time: 2.16836
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.64855

Cumulative Model Updates: 144,554
Cumulative Timesteps: 1,205,356,558

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.75254
Value Function Loss: 0.01126

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05663
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.45520

Collected Steps per Second: 22,814.12839
Overall Steps per Second: 10,852.84822

Timestep Collection Time: 2.19233
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.60856

Cumulative Model Updates: 144,560
Cumulative Timesteps: 1,205,406,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1205406574...
Checkpoint 1205406574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.74830
Value Function Loss: 0.01115

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05856
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.51818

Collected Steps per Second: 22,800.72353
Overall Steps per Second: 10,714.15991

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.66709

Cumulative Model Updates: 144,566
Cumulative Timesteps: 1,205,456,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,447.17519
Policy Entropy: 3.74063
Value Function Loss: 0.01220

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07696
Policy Update Magnitude: 0.59185
Value Function Update Magnitude: 0.58201

Collected Steps per Second: 22,727.16946
Overall Steps per Second: 10,870.30174

Timestep Collection Time: 2.20089
Timestep Consumption Time: 2.40064
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.60153

Cumulative Model Updates: 144,572
Cumulative Timesteps: 1,205,506,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1205506598...
Checkpoint 1205506598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,688.37699
Policy Entropy: 3.75667
Value Function Loss: 0.01179

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05915
Policy Update Magnitude: 0.63894
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 22,713.57524
Overall Steps per Second: 10,710.67497

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.46800
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.67029

Cumulative Model Updates: 144,578
Cumulative Timesteps: 1,205,556,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,022.80133
Policy Entropy: 3.75955
Value Function Loss: 0.01591

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.68281
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 23,042.22824
Overall Steps per Second: 10,771.48390

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.47304
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.64393

Cumulative Model Updates: 144,584
Cumulative Timesteps: 1,205,606,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1205606642...
Checkpoint 1205606642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,434.00201
Policy Entropy: 3.76407
Value Function Loss: 0.01687

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.69795
Value Function Update Magnitude: 0.55907

Collected Steps per Second: 22,595.38533
Overall Steps per Second: 10,624.26974

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.49396
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.70734

Cumulative Model Updates: 144,590
Cumulative Timesteps: 1,205,656,654

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,262.84239
Policy Entropy: 3.76619
Value Function Loss: 0.01697

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.67645
Value Function Update Magnitude: 0.71016

Collected Steps per Second: 22,245.86315
Overall Steps per Second: 10,897.96318

Timestep Collection Time: 2.24761
Timestep Consumption Time: 2.34040
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.58801

Cumulative Model Updates: 144,596
Cumulative Timesteps: 1,205,706,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1205706654...
Checkpoint 1205706654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,323.97869
Policy Entropy: 3.75853
Value Function Loss: 0.01773

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.64359
Value Function Update Magnitude: 0.78851

Collected Steps per Second: 21,738.24869
Overall Steps per Second: 10,680.02183

Timestep Collection Time: 2.30028
Timestep Consumption Time: 2.38174
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.68201

Cumulative Model Updates: 144,602
Cumulative Timesteps: 1,205,756,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,385.36416
Policy Entropy: 3.76608
Value Function Loss: 0.02196

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15720
Policy Update Magnitude: 0.63984
Value Function Update Magnitude: 0.88055

Collected Steps per Second: 22,248.21090
Overall Steps per Second: 10,915.72756

Timestep Collection Time: 2.24773
Timestep Consumption Time: 2.33355
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.58128

Cumulative Model Updates: 144,608
Cumulative Timesteps: 1,205,806,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1205806666...
Checkpoint 1205806666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,493.03008
Policy Entropy: 3.76856
Value Function Loss: 0.02189

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.67342
Value Function Update Magnitude: 0.90254

Collected Steps per Second: 21,903.11248
Overall Steps per Second: 10,679.09196

Timestep Collection Time: 2.28287
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68223

Cumulative Model Updates: 144,614
Cumulative Timesteps: 1,205,856,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,517.95223
Policy Entropy: 3.77931
Value Function Loss: 0.01859

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08263
Policy Update Magnitude: 0.76909
Value Function Update Magnitude: 0.71008

Collected Steps per Second: 22,125.19704
Overall Steps per Second: 10,746.58708

Timestep Collection Time: 2.26122
Timestep Consumption Time: 2.39421
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.65543

Cumulative Model Updates: 144,620
Cumulative Timesteps: 1,205,906,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1205906698...
Checkpoint 1205906698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314,639.60372
Policy Entropy: 3.77119
Value Function Loss: 0.01644

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.73853
Value Function Update Magnitude: 0.68509

Collected Steps per Second: 22,650.80085
Overall Steps per Second: 10,745.37793

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.44808
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.65763

Cumulative Model Updates: 144,626
Cumulative Timesteps: 1,205,956,746

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,221.86931
Policy Entropy: 3.76439
Value Function Loss: 0.01639

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06670
Policy Update Magnitude: 0.74467
Value Function Update Magnitude: 0.75569

Collected Steps per Second: 22,810.35983
Overall Steps per Second: 10,936.93061

Timestep Collection Time: 2.19269
Timestep Consumption Time: 2.38044
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.57313

Cumulative Model Updates: 144,632
Cumulative Timesteps: 1,206,006,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1206006762...
Checkpoint 1206006762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,531.82836
Policy Entropy: 3.76736
Value Function Loss: 0.01767

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07687
Policy Update Magnitude: 0.77338
Value Function Update Magnitude: 0.85636

Collected Steps per Second: 22,829.16694
Overall Steps per Second: 10,723.82541

Timestep Collection Time: 2.19062
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.66345

Cumulative Model Updates: 144,638
Cumulative Timesteps: 1,206,056,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,392.76217
Policy Entropy: 3.77268
Value Function Loss: 0.01594

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.16501
Policy Update Magnitude: 0.65729
Value Function Update Magnitude: 0.79104

Collected Steps per Second: 22,910.90572
Overall Steps per Second: 10,793.10592

Timestep Collection Time: 2.18237
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.63259

Cumulative Model Updates: 144,644
Cumulative Timesteps: 1,206,106,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1206106772...
Checkpoint 1206106772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,731.07863
Policy Entropy: 3.76500
Value Function Loss: 0.01391

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.17482
Policy Update Magnitude: 0.49586
Value Function Update Magnitude: 0.65562

Collected Steps per Second: 22,755.53838
Overall Steps per Second: 10,672.03092

Timestep Collection Time: 2.19806
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.68683

Cumulative Model Updates: 144,650
Cumulative Timesteps: 1,206,156,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,731.07863
Policy Entropy: 3.76941
Value Function Loss: 0.01107

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.19111
Policy Update Magnitude: 0.45727
Value Function Update Magnitude: 0.56633

Collected Steps per Second: 23,224.40158
Overall Steps per Second: 10,833.65556

Timestep Collection Time: 2.15342
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.61635

Cumulative Model Updates: 144,656
Cumulative Timesteps: 1,206,206,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1206206802...
Checkpoint 1206206802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683,731.07863
Policy Entropy: 3.78733
Value Function Loss: 0.00889

Mean KL Divergence: 0.01695
SB3 Clip Fraction: 0.21790
Policy Update Magnitude: 0.37024
Value Function Update Magnitude: 0.45436

Collected Steps per Second: 23,027.09104
Overall Steps per Second: 10,766.55777

Timestep Collection Time: 2.17205
Timestep Consumption Time: 2.47345
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.64550

Cumulative Model Updates: 144,662
Cumulative Timesteps: 1,206,256,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 683,731.07863
Policy Entropy: 3.76847
Value Function Loss: 0.00970

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.17399
Policy Update Magnitude: 0.34101
Value Function Update Magnitude: 0.39992

Collected Steps per Second: 23,073.58425
Overall Steps per Second: 10,834.88427

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.44911
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.61731

Cumulative Model Updates: 144,668
Cumulative Timesteps: 1,206,306,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1206306846...
Checkpoint 1206306846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,119.40936
Policy Entropy: 3.75359
Value Function Loss: 0.01115

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.44897
Value Function Update Magnitude: 0.44984

Collected Steps per Second: 23,056.62388
Overall Steps per Second: 10,807.39151

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.45809
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.62683

Cumulative Model Updates: 144,674
Cumulative Timesteps: 1,206,356,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,812.62637
Policy Entropy: 3.75287
Value Function Loss: 0.01308

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.51618
Value Function Update Magnitude: 0.54106

Collected Steps per Second: 23,137.38413
Overall Steps per Second: 10,724.51330

Timestep Collection Time: 2.16126
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.66278

Cumulative Model Updates: 144,680
Cumulative Timesteps: 1,206,406,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1206406856...
Checkpoint 1206406856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,523.96138
Policy Entropy: 3.76126
Value Function Loss: 0.01493

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.19871
Policy Update Magnitude: 0.43154
Value Function Update Magnitude: 0.56622

Collected Steps per Second: 23,111.87877
Overall Steps per Second: 10,730.40626

Timestep Collection Time: 2.16417
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.66133

Cumulative Model Updates: 144,686
Cumulative Timesteps: 1,206,456,874

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,305.02197
Policy Entropy: 3.75557
Value Function Loss: 0.02154

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.19605
Policy Update Magnitude: 0.37408
Value Function Update Magnitude: 0.46879

Collected Steps per Second: 23,060.33178
Overall Steps per Second: 10,828.27749

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.44990
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.61865

Cumulative Model Updates: 144,692
Cumulative Timesteps: 1,206,506,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1206506886...
Checkpoint 1206506886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,660.59657
Policy Entropy: 3.74157
Value Function Loss: 0.02187

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16205
Policy Update Magnitude: 0.44285
Value Function Update Magnitude: 0.44357

Collected Steps per Second: 22,859.90106
Overall Steps per Second: 10,710.24181

Timestep Collection Time: 2.18776
Timestep Consumption Time: 2.48179
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66955

Cumulative Model Updates: 144,698
Cumulative Timesteps: 1,206,556,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.13108
Policy Entropy: 3.74479
Value Function Loss: 0.02275

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07363
Policy Update Magnitude: 0.59840
Value Function Update Magnitude: 0.51220

Collected Steps per Second: 23,119.69400
Overall Steps per Second: 10,820.21028

Timestep Collection Time: 2.16292
Timestep Consumption Time: 2.45862
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.62154

Cumulative Model Updates: 144,704
Cumulative Timesteps: 1,206,606,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1206606904...
Checkpoint 1206606904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.58447
Policy Entropy: 3.76862
Value Function Loss: 0.01742

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06853
Policy Update Magnitude: 0.67257
Value Function Update Magnitude: 0.55431

Collected Steps per Second: 22,848.82798
Overall Steps per Second: 10,688.86991

Timestep Collection Time: 2.18926
Timestep Consumption Time: 2.49056
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.67982

Cumulative Model Updates: 144,710
Cumulative Timesteps: 1,206,656,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 544.58447
Policy Entropy: 3.75818
Value Function Loss: 0.01523

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07364
Policy Update Magnitude: 0.64160
Value Function Update Magnitude: 0.59792

Collected Steps per Second: 23,312.37397
Overall Steps per Second: 10,880.95639

Timestep Collection Time: 2.14590
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.59757

Cumulative Model Updates: 144,716
Cumulative Timesteps: 1,206,706,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1206706952...
Checkpoint 1206706952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,682.71917
Policy Entropy: 3.77350
Value Function Loss: 0.01426

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07549
Policy Update Magnitude: 0.60173
Value Function Update Magnitude: 0.53972

Collected Steps per Second: 22,869.44989
Overall Steps per Second: 10,702.10983

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.48695
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67441

Cumulative Model Updates: 144,722
Cumulative Timesteps: 1,206,756,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,511.09336
Policy Entropy: 3.75447
Value Function Loss: 0.01325

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.06630
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 23,216.14621
Overall Steps per Second: 10,835.08109

Timestep Collection Time: 2.15505
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.61759

Cumulative Model Updates: 144,728
Cumulative Timesteps: 1,206,807,010

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1206807010...
Checkpoint 1206807010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,511.09336
Policy Entropy: 3.75603
Value Function Loss: 0.01350

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.50746
Value Function Update Magnitude: 0.55141

Collected Steps per Second: 22,971.25281
Overall Steps per Second: 10,754.32779

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.47286
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.64966

Cumulative Model Updates: 144,734
Cumulative Timesteps: 1,206,857,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,186.04591
Policy Entropy: 3.73656
Value Function Loss: 0.01521

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.16071
Policy Update Magnitude: 0.44904
Value Function Update Magnitude: 0.58899

Collected Steps per Second: 23,061.78503
Overall Steps per Second: 10,819.46797

Timestep Collection Time: 2.16922
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.62370

Cumulative Model Updates: 144,740
Cumulative Timesteps: 1,206,907,040

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1206907040...
Checkpoint 1206907040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,036.28160
Policy Entropy: 3.74433
Value Function Loss: 0.01769

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.20249
Policy Update Magnitude: 0.44753
Value Function Update Magnitude: 0.76162

Collected Steps per Second: 22,679.44485
Overall Steps per Second: 10,642.95009

Timestep Collection Time: 2.20587
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.70058

Cumulative Model Updates: 144,746
Cumulative Timesteps: 1,206,957,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,285.60832
Policy Entropy: 3.77003
Value Function Loss: 0.01750

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.20993
Policy Update Magnitude: 0.47888
Value Function Update Magnitude: 0.78005

Collected Steps per Second: 23,002.81919
Overall Steps per Second: 10,885.25565

Timestep Collection Time: 2.17495
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.59613

Cumulative Model Updates: 144,752
Cumulative Timesteps: 1,207,007,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1207007098...
Checkpoint 1207007098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,461.19003
Policy Entropy: 3.79114
Value Function Loss: 0.02560

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.23691
Policy Update Magnitude: 0.43392
Value Function Update Magnitude: 0.58383

Collected Steps per Second: 22,731.63479
Overall Steps per Second: 10,663.46140

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.68928

Cumulative Model Updates: 144,758
Cumulative Timesteps: 1,207,057,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,586.27683
Policy Entropy: 3.81607
Value Function Loss: 0.03273

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.18314
Policy Update Magnitude: 0.40652
Value Function Update Magnitude: 0.40850

Collected Steps per Second: 23,336.11024
Overall Steps per Second: 10,909.82092

Timestep Collection Time: 2.14363
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.58523

Cumulative Model Updates: 144,764
Cumulative Timesteps: 1,207,107,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1207107126...
Checkpoint 1207107126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,646.33735
Policy Entropy: 3.79337
Value Function Loss: 0.03435

Mean KL Divergence: 0.02148
SB3 Clip Fraction: 0.24448
Policy Update Magnitude: 0.39315
Value Function Update Magnitude: 0.31807

Collected Steps per Second: 22,709.40392
Overall Steps per Second: 10,660.77976

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.48985
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.69290

Cumulative Model Updates: 144,770
Cumulative Timesteps: 1,207,157,156

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,561.72175
Policy Entropy: 3.79046
Value Function Loss: 0.05571

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.22685
Policy Update Magnitude: 0.61041
Value Function Update Magnitude: 0.36297

Collected Steps per Second: 22,909.98713
Overall Steps per Second: 10,887.03562

Timestep Collection Time: 2.18263
Timestep Consumption Time: 2.41036
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.59299

Cumulative Model Updates: 144,776
Cumulative Timesteps: 1,207,207,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1207207160...
Checkpoint 1207207160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,871.18206
Policy Entropy: 3.79588
Value Function Loss: 0.04973

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 1.18478
Value Function Update Magnitude: 0.56396

Collected Steps per Second: 22,717.42939
Overall Steps per Second: 10,772.90765

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.64202

Cumulative Model Updates: 144,782
Cumulative Timesteps: 1,207,257,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.31998
Policy Entropy: 3.82106
Value Function Loss: 0.04870

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 1.30338
Value Function Update Magnitude: 0.67491

Collected Steps per Second: 23,041.52031
Overall Steps per Second: 10,773.87479

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.64104

Cumulative Model Updates: 144,788
Cumulative Timesteps: 1,207,307,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1207307170...
Checkpoint 1207307170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,695.53660
Policy Entropy: 3.82554
Value Function Loss: 0.03624

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 1.01358
Value Function Update Magnitude: 0.68410

Collected Steps per Second: 22,600.68797
Overall Steps per Second: 10,724.26694

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66587

Cumulative Model Updates: 144,794
Cumulative Timesteps: 1,207,357,208

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,044.01295
Policy Entropy: 3.80432
Value Function Loss: 0.03487

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.92181
Value Function Update Magnitude: 0.73543

Collected Steps per Second: 23,002.75020
Overall Steps per Second: 10,764.96904

Timestep Collection Time: 2.17435
Timestep Consumption Time: 2.47183
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.64618

Cumulative Model Updates: 144,800
Cumulative Timesteps: 1,207,407,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1207407224...
Checkpoint 1207407224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,023.25832
Policy Entropy: 3.81826
Value Function Loss: 0.03972

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.95454
Value Function Update Magnitude: 0.66570

Collected Steps per Second: 22,694.33888
Overall Steps per Second: 10,702.30393

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.67376

Cumulative Model Updates: 144,806
Cumulative Timesteps: 1,207,457,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,434.20849
Policy Entropy: 3.84128
Value Function Loss: 0.03716

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.94652
Value Function Update Magnitude: 0.65690

Collected Steps per Second: 23,183.99531
Overall Steps per Second: 10,868.42785

Timestep Collection Time: 2.15718
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.60159

Cumulative Model Updates: 144,812
Cumulative Timesteps: 1,207,507,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1207507256...
Checkpoint 1207507256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,433.93172
Policy Entropy: 3.85269
Value Function Loss: 0.03586

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.17659
Policy Update Magnitude: 0.81052
Value Function Update Magnitude: 0.71234

Collected Steps per Second: 22,657.97071
Overall Steps per Second: 10,715.27239

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.66717

Cumulative Model Updates: 144,818
Cumulative Timesteps: 1,207,557,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,126.01132
Policy Entropy: 3.83742
Value Function Loss: 0.03590

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.82734
Value Function Update Magnitude: 0.71388

Collected Steps per Second: 22,964.27000
Overall Steps per Second: 10,828.61091

Timestep Collection Time: 2.17756
Timestep Consumption Time: 2.44039
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.61795

Cumulative Model Updates: 144,824
Cumulative Timesteps: 1,207,607,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1207607272...
Checkpoint 1207607272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.41855
Policy Entropy: 3.80457
Value Function Loss: 0.03398

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.81652
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 22,969.36131
Overall Steps per Second: 10,736.60354

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.48164
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.65976

Cumulative Model Updates: 144,830
Cumulative Timesteps: 1,207,657,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,209.66397
Policy Entropy: 3.78496
Value Function Loss: 0.03424

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.84852
Value Function Update Magnitude: 0.54455

Collected Steps per Second: 22,949.15810
Overall Steps per Second: 10,820.59963

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.62359

Cumulative Model Updates: 144,836
Cumulative Timesteps: 1,207,707,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1207707332...
Checkpoint 1207707332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,292.56864
Policy Entropy: 3.77244
Value Function Loss: 0.03413

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.91244
Value Function Update Magnitude: 0.48573

Collected Steps per Second: 22,797.85764
Overall Steps per Second: 10,680.12073

Timestep Collection Time: 2.19371
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.68272

Cumulative Model Updates: 144,842
Cumulative Timesteps: 1,207,757,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,882.51802
Policy Entropy: 3.77020
Value Function Loss: 0.03192

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.90903
Value Function Update Magnitude: 0.46003

Collected Steps per Second: 22,852.11772
Overall Steps per Second: 10,828.41487

Timestep Collection Time: 2.18877
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.61914

Cumulative Model Updates: 144,848
Cumulative Timesteps: 1,207,807,362

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1207807362...
Checkpoint 1207807362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,173.80098
Policy Entropy: 3.77514
Value Function Loss: 0.03057

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.86556
Value Function Update Magnitude: 0.46829

Collected Steps per Second: 22,751.51867
Overall Steps per Second: 10,630.89724

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.50732
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.70647

Cumulative Model Updates: 144,854
Cumulative Timesteps: 1,207,857,396

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,034.62907
Policy Entropy: 3.77223
Value Function Loss: 0.02812

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07976
Policy Update Magnitude: 0.81643
Value Function Update Magnitude: 0.44216

Collected Steps per Second: 23,043.96976
Overall Steps per Second: 10,911.49833

Timestep Collection Time: 2.17107
Timestep Consumption Time: 2.41400
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58507

Cumulative Model Updates: 144,860
Cumulative Timesteps: 1,207,907,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1207907426...
Checkpoint 1207907426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,773.15465
Policy Entropy: 3.77273
Value Function Loss: 0.02706

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.78160
Value Function Update Magnitude: 0.47291

Collected Steps per Second: 22,820.22008
Overall Steps per Second: 10,660.31671

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.69236

Cumulative Model Updates: 144,866
Cumulative Timesteps: 1,207,957,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.43776
Policy Entropy: 3.79116
Value Function Loss: 0.02463

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06013
Policy Update Magnitude: 0.76519
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 23,135.95777
Overall Steps per Second: 10,911.01287

Timestep Collection Time: 2.16226
Timestep Consumption Time: 2.42265
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.58491

Cumulative Model Updates: 144,872
Cumulative Timesteps: 1,208,007,474

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1208007474...
Checkpoint 1208007474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,768.31652
Policy Entropy: 3.78229
Value Function Loss: 0.02574

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.72520
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 22,777.60681
Overall Steps per Second: 10,671.22373

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.49165
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.68793

Cumulative Model Updates: 144,878
Cumulative Timesteps: 1,208,057,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,075.90431
Policy Entropy: 3.79389
Value Function Loss: 0.02513

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07340
Policy Update Magnitude: 0.68310
Value Function Update Magnitude: 0.58871

Collected Steps per Second: 23,053.24586
Overall Steps per Second: 10,903.43749

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.41720
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.58644

Cumulative Model Updates: 144,884
Cumulative Timesteps: 1,208,107,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1208107508...
Checkpoint 1208107508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,640.96885
Policy Entropy: 3.77332
Value Function Loss: 0.02216

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05525
Policy Update Magnitude: 0.67039
Value Function Update Magnitude: 0.59624

Collected Steps per Second: 22,782.77349
Overall Steps per Second: 10,684.60492

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.48509
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.67982

Cumulative Model Updates: 144,890
Cumulative Timesteps: 1,208,157,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.69439
Policy Entropy: 3.79679
Value Function Loss: 0.01788

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.67086
Value Function Update Magnitude: 0.61854

Collected Steps per Second: 22,724.04217
Overall Steps per Second: 10,817.11167

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.62434

Cumulative Model Updates: 144,896
Cumulative Timesteps: 1,208,207,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1208207532...
Checkpoint 1208207532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,141.21571
Policy Entropy: 3.79718
Value Function Loss: 0.01836

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 22,927.09169
Overall Steps per Second: 10,707.27742

Timestep Collection Time: 2.18135
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.67084

Cumulative Model Updates: 144,902
Cumulative Timesteps: 1,208,257,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,079.39089
Policy Entropy: 3.78300
Value Function Loss: 0.01949

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.25958
Policy Update Magnitude: 0.44694
Value Function Update Magnitude: 0.69977

Collected Steps per Second: 23,367.86996
Overall Steps per Second: 10,894.20927

Timestep Collection Time: 2.14037
Timestep Consumption Time: 2.45069
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.59106

Cumulative Model Updates: 144,908
Cumulative Timesteps: 1,208,307,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1208307560...
Checkpoint 1208307560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,813.01350
Policy Entropy: 3.77616
Value Function Loss: 0.04036

Mean KL Divergence: 0.02639
SB3 Clip Fraction: 0.26841
Policy Update Magnitude: 0.41808
Value Function Update Magnitude: 0.65826

Collected Steps per Second: 22,787.38693
Overall Steps per Second: 10,682.28337

Timestep Collection Time: 2.19446
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68121

Cumulative Model Updates: 144,914
Cumulative Timesteps: 1,208,357,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,625.33168
Policy Entropy: 3.86666
Value Function Loss: 0.04725

Mean KL Divergence: 0.01772
SB3 Clip Fraction: 0.18596
Policy Update Magnitude: 0.62168
Value Function Update Magnitude: 0.57296

Collected Steps per Second: 22,988.68007
Overall Steps per Second: 10,832.38122

Timestep Collection Time: 2.17585
Timestep Consumption Time: 2.44178
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.61764

Cumulative Model Updates: 144,920
Cumulative Timesteps: 1,208,407,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1208407586...
Checkpoint 1208407586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.70954
Policy Entropy: 4.03159
Value Function Loss: 0.04174

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11414
Policy Update Magnitude: 0.76215
Value Function Update Magnitude: 0.62909

Collected Steps per Second: 22,838.38833
Overall Steps per Second: 11,030.85027

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.34391
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.53365

Cumulative Model Updates: 144,926
Cumulative Timesteps: 1,208,457,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.30647
Policy Entropy: 4.18855
Value Function Loss: 0.02271

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.06886
Policy Update Magnitude: 0.99349
Value Function Update Magnitude: 0.92238

Collected Steps per Second: 23,231.24698
Overall Steps per Second: 10,967.25755

Timestep Collection Time: 2.15245
Timestep Consumption Time: 2.40694
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.55939

Cumulative Model Updates: 144,932
Cumulative Timesteps: 1,208,507,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1208507600...
Checkpoint 1208507600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124.46643
Policy Entropy: 4.27553
Value Function Loss: 0.01364

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.04875
Policy Update Magnitude: 1.11438
Value Function Update Magnitude: 1.14599

Collected Steps per Second: 22,827.21534
Overall Steps per Second: 10,703.33234

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.67256

Cumulative Model Updates: 144,938
Cumulative Timesteps: 1,208,557,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.61436
Policy Entropy: 4.29574
Value Function Loss: 0.01151

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.03890
Policy Update Magnitude: 1.05771
Value Function Update Magnitude: 1.19429

Collected Steps per Second: 23,232.39750
Overall Steps per Second: 10,864.44421

Timestep Collection Time: 2.15303
Timestep Consumption Time: 2.45098
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.60401

Cumulative Model Updates: 144,944
Cumulative Timesteps: 1,208,607,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1208607632...
Checkpoint 1208607632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 547.62561
Policy Entropy: 4.26835
Value Function Loss: 0.01203

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04341
Policy Update Magnitude: 1.01775
Value Function Update Magnitude: 1.13707

Collected Steps per Second: 23,252.50045
Overall Steps per Second: 11,175.24103

Timestep Collection Time: 2.15117
Timestep Consumption Time: 2.32480
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.47597

Cumulative Model Updates: 144,950
Cumulative Timesteps: 1,208,657,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.48446
Policy Entropy: 4.24808
Value Function Loss: 0.01246

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04473
Policy Update Magnitude: 0.99527
Value Function Update Magnitude: 1.08195

Collected Steps per Second: 23,512.35317
Overall Steps per Second: 10,860.51767

Timestep Collection Time: 2.12748
Timestep Consumption Time: 2.47838
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.60586

Cumulative Model Updates: 144,956
Cumulative Timesteps: 1,208,707,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1208707674...
Checkpoint 1208707674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.81199
Policy Entropy: 4.23121
Value Function Loss: 0.01242

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04631
Policy Update Magnitude: 0.94834
Value Function Update Magnitude: 1.01070

Collected Steps per Second: 22,921.73749
Overall Steps per Second: 10,725.56121

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.66381

Cumulative Model Updates: 144,962
Cumulative Timesteps: 1,208,757,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.11529
Policy Entropy: 4.23110
Value Function Loss: 0.01270

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 0.88850
Value Function Update Magnitude: 0.96450

Collected Steps per Second: 23,087.66494
Overall Steps per Second: 10,827.59617

Timestep Collection Time: 2.16601
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.61857

Cumulative Model Updates: 144,968
Cumulative Timesteps: 1,208,807,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1208807704...
Checkpoint 1208807704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101.19636
Policy Entropy: 4.21317
Value Function Loss: 0.01427

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.03933
Policy Update Magnitude: 0.84912
Value Function Update Magnitude: 0.92549

Collected Steps per Second: 23,064.77006
Overall Steps per Second: 11,086.52414

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.34292
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.51142

Cumulative Model Updates: 144,974
Cumulative Timesteps: 1,208,857,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.89660
Policy Entropy: 4.18858
Value Function Loss: 0.01628

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04397
Policy Update Magnitude: 0.83368
Value Function Update Magnitude: 0.90557

Collected Steps per Second: 23,331.65661
Overall Steps per Second: 10,922.02835

Timestep Collection Time: 2.14327
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.57845

Cumulative Model Updates: 144,980
Cumulative Timesteps: 1,208,907,726

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1208907726...
Checkpoint 1208907726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.04494
Policy Entropy: 4.18936
Value Function Loss: 0.01847

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04936
Policy Update Magnitude: 0.82133
Value Function Update Magnitude: 0.88249

Collected Steps per Second: 22,751.54998
Overall Steps per Second: 10,688.73315

Timestep Collection Time: 2.19809
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67876

Cumulative Model Updates: 144,986
Cumulative Timesteps: 1,208,957,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.63200
Policy Entropy: 4.18456
Value Function Loss: 0.01893

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04514
Policy Update Magnitude: 0.81725
Value Function Update Magnitude: 0.85531

Collected Steps per Second: 23,135.45353
Overall Steps per Second: 10,849.97707

Timestep Collection Time: 2.16153
Timestep Consumption Time: 2.44751
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.60904

Cumulative Model Updates: 144,992
Cumulative Timesteps: 1,209,007,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1209007744...
Checkpoint 1209007744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,109.22589
Policy Entropy: 4.19099
Value Function Loss: 0.01915

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.04501
Policy Update Magnitude: 0.78320
Value Function Update Magnitude: 0.81003

Collected Steps per Second: 22,998.71057
Overall Steps per Second: 11,080.07323

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.33960
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.51459

Cumulative Model Updates: 144,998
Cumulative Timesteps: 1,209,057,766

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.16016
Policy Entropy: 4.18182
Value Function Loss: 0.01830

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.03773
Policy Update Magnitude: 0.74300
Value Function Update Magnitude: 0.79703

Collected Steps per Second: 23,064.65000
Overall Steps per Second: 10,941.77540

Timestep Collection Time: 2.16860
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.57129

Cumulative Model Updates: 145,004
Cumulative Timesteps: 1,209,107,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1209107784...
Checkpoint 1209107784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.32530
Policy Entropy: 4.15902
Value Function Loss: 0.01960

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03505
Policy Update Magnitude: 0.71571
Value Function Update Magnitude: 0.76637

Collected Steps per Second: 22,989.66664
Overall Steps per Second: 10,760.93966

Timestep Collection Time: 2.17628
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.64941

Cumulative Model Updates: 145,010
Cumulative Timesteps: 1,209,157,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.50934
Policy Entropy: 4.14283
Value Function Loss: 0.02197

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04941
Policy Update Magnitude: 0.69376
Value Function Update Magnitude: 0.72666

Collected Steps per Second: 23,338.06792
Overall Steps per Second: 10,787.48721

Timestep Collection Time: 2.14302
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.63630

Cumulative Model Updates: 145,016
Cumulative Timesteps: 1,209,207,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1209207830...
Checkpoint 1209207830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.13189
Policy Entropy: 4.08758
Value Function Loss: 0.02558

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04952
Policy Update Magnitude: 0.70049
Value Function Update Magnitude: 0.76209

Collected Steps per Second: 23,001.96045
Overall Steps per Second: 10,849.41559

Timestep Collection Time: 2.17486
Timestep Consumption Time: 2.43608
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.61094

Cumulative Model Updates: 145,022
Cumulative Timesteps: 1,209,257,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.22710
Policy Entropy: 4.03627
Value Function Loss: 0.02922

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04766
Policy Update Magnitude: 0.73243
Value Function Update Magnitude: 0.75327

Collected Steps per Second: 23,478.54221
Overall Steps per Second: 10,971.18166

Timestep Collection Time: 2.13020
Timestep Consumption Time: 2.42847
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.55867

Cumulative Model Updates: 145,028
Cumulative Timesteps: 1,209,307,870

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1209307870...
Checkpoint 1209307870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,124.26005
Policy Entropy: 3.97321
Value Function Loss: 0.02875

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06482
Policy Update Magnitude: 0.70530
Value Function Update Magnitude: 0.70715

Collected Steps per Second: 22,645.49766
Overall Steps per Second: 10,836.33118

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.40664
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.61503

Cumulative Model Updates: 145,034
Cumulative Timesteps: 1,209,357,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,000.79188
Policy Entropy: 3.92694
Value Function Loss: 0.02999

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07878
Policy Update Magnitude: 0.62056
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,837.78413
Overall Steps per Second: 10,922.04832

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.38988
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.58046

Cumulative Model Updates: 145,040
Cumulative Timesteps: 1,209,407,908

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1209407908...
Checkpoint 1209407908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,052.11956
Policy Entropy: 3.89887
Value Function Loss: 0.02916

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06838
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.54509

Collected Steps per Second: 22,748.65483
Overall Steps per Second: 10,743.45282

Timestep Collection Time: 2.19916
Timestep Consumption Time: 2.45744
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.65660

Cumulative Model Updates: 145,046
Cumulative Timesteps: 1,209,457,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,237.16077
Policy Entropy: 3.88172
Value Function Loss: 0.03582

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16445
Policy Update Magnitude: 0.48738
Value Function Update Magnitude: 0.58472

Collected Steps per Second: 23,309.63753
Overall Steps per Second: 10,837.14895

Timestep Collection Time: 2.14504
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.61376

Cumulative Model Updates: 145,052
Cumulative Timesteps: 1,209,507,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1209507936...
Checkpoint 1209507936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.74732
Policy Entropy: 3.95575
Value Function Loss: 0.03260

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.17245
Policy Update Magnitude: 0.41689
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 22,938.92397
Overall Steps per Second: 11,102.05596

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.32471
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.50511

Cumulative Model Updates: 145,058
Cumulative Timesteps: 1,209,557,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,129.95691
Policy Entropy: 3.97840
Value Function Loss: 0.03369

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.43559
Value Function Update Magnitude: 0.63351

Collected Steps per Second: 22,336.12212
Overall Steps per Second: 10,924.39672

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.33988
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.57984

Cumulative Model Updates: 145,064
Cumulative Timesteps: 1,209,607,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1209607984...
Checkpoint 1209607984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.19649
Policy Entropy: 4.00888
Value Function Loss: 0.02715

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.45921
Value Function Update Magnitude: 0.65231

Collected Steps per Second: 23,033.88697
Overall Steps per Second: 10,801.93262

Timestep Collection Time: 2.17184
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.63121

Cumulative Model Updates: 145,070
Cumulative Timesteps: 1,209,658,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,869.98759
Policy Entropy: 3.91752
Value Function Loss: 0.02863

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.51518
Value Function Update Magnitude: 0.58933

Collected Steps per Second: 23,612.01293
Overall Steps per Second: 10,911.12187

Timestep Collection Time: 2.11824
Timestep Consumption Time: 2.46570
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.58395

Cumulative Model Updates: 145,076
Cumulative Timesteps: 1,209,708,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1209708026...
Checkpoint 1209708026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,127.23344
Policy Entropy: 3.89280
Value Function Loss: 0.02561

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05883
Policy Update Magnitude: 0.60843
Value Function Update Magnitude: 0.50998

Collected Steps per Second: 22,707.76318
Overall Steps per Second: 10,860.45619

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.40254
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60496

Cumulative Model Updates: 145,082
Cumulative Timesteps: 1,209,758,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,626.15620
Policy Entropy: 3.85205
Value Function Loss: 0.02909

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.63120
Value Function Update Magnitude: 0.60332

Collected Steps per Second: 22,396.93307
Overall Steps per Second: 10,918.04410

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.34788
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.58104

Cumulative Model Updates: 145,088
Cumulative Timesteps: 1,209,808,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1209808054...
Checkpoint 1209808054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226.18594
Policy Entropy: 3.86075
Value Function Loss: 0.02804

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.21839
Policy Update Magnitude: 0.51571
Value Function Update Magnitude: 0.52983

Collected Steps per Second: 22,307.25605
Overall Steps per Second: 10,765.60925

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.40376
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.64591

Cumulative Model Updates: 145,094
Cumulative Timesteps: 1,209,858,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,291.95640
Policy Entropy: 3.88376
Value Function Loss: 0.03168

Mean KL Divergence: 0.02322
SB3 Clip Fraction: 0.23161
Policy Update Magnitude: 0.48904
Value Function Update Magnitude: 0.51582

Collected Steps per Second: 22,316.18867
Overall Steps per Second: 10,825.55486

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.37837
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.61907

Cumulative Model Updates: 145,100
Cumulative Timesteps: 1,209,908,074

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1209908074...
Checkpoint 1209908074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,200.34255
Policy Entropy: 3.87697
Value Function Loss: 0.03185

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.20248
Policy Update Magnitude: 0.46153
Value Function Update Magnitude: 0.61117

Collected Steps per Second: 21,887.59984
Overall Steps per Second: 10,649.56809

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.41178
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.69728

Cumulative Model Updates: 145,106
Cumulative Timesteps: 1,209,958,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.38399
Policy Entropy: 3.87505
Value Function Loss: 0.03170

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.19720
Policy Update Magnitude: 0.53106
Value Function Update Magnitude: 0.75491

Collected Steps per Second: 22,237.45111
Overall Steps per Second: 10,893.98316

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.34189
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.59097

Cumulative Model Updates: 145,112
Cumulative Timesteps: 1,210,008,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1210008112...
Checkpoint 1210008112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,322.92689
Policy Entropy: 3.87543
Value Function Loss: 0.02902

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.17330
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.79408

Collected Steps per Second: 22,057.21257
Overall Steps per Second: 10,646.77724

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69776

Cumulative Model Updates: 145,118
Cumulative Timesteps: 1,210,058,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500.83166
Policy Entropy: 3.87853
Value Function Loss: 0.02605

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.54236
Value Function Update Magnitude: 0.75397

Collected Steps per Second: 22,664.87514
Overall Steps per Second: 10,937.47078

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.36557
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.57181

Cumulative Model Updates: 145,124
Cumulative Timesteps: 1,210,108,132

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1210108132...
Checkpoint 1210108132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,736.03535
Policy Entropy: 3.83116
Value Function Loss: 0.02757

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.50499
Value Function Update Magnitude: 0.69799

Collected Steps per Second: 22,235.52249
Overall Steps per Second: 10,769.13859

Timestep Collection Time: 2.24874
Timestep Consumption Time: 2.39434
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.64308

Cumulative Model Updates: 145,130
Cumulative Timesteps: 1,210,158,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,286.02185
Policy Entropy: 3.82361
Value Function Loss: 0.02641

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.17811
Policy Update Magnitude: 0.48306
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 22,413.91140
Overall Steps per Second: 10,741.08066

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.65651

Cumulative Model Updates: 145,136
Cumulative Timesteps: 1,210,208,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1210208150...
Checkpoint 1210208150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,292.82527
Policy Entropy: 3.81275
Value Function Loss: 0.02569

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.16484
Policy Update Magnitude: 0.48955
Value Function Update Magnitude: 0.61047

Collected Steps per Second: 22,287.36483
Overall Steps per Second: 10,807.04293

Timestep Collection Time: 2.24369
Timestep Consumption Time: 2.38347
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.62717

Cumulative Model Updates: 145,142
Cumulative Timesteps: 1,210,258,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,595.75057
Policy Entropy: 3.79717
Value Function Loss: 0.02365

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 22,684.63470
Overall Steps per Second: 10,746.66903

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.44994
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.65540

Cumulative Model Updates: 145,148
Cumulative Timesteps: 1,210,308,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1210308186...
Checkpoint 1210308186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,107.11965
Policy Entropy: 3.77253
Value Function Loss: 0.02233

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.64430
Value Function Update Magnitude: 0.55901

Collected Steps per Second: 23,099.17574
Overall Steps per Second: 10,983.05717

Timestep Collection Time: 2.16562
Timestep Consumption Time: 2.38903
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.55465

Cumulative Model Updates: 145,154
Cumulative Timesteps: 1,210,358,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,391.96913
Policy Entropy: 3.73610
Value Function Loss: 0.02103

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08328
Policy Update Magnitude: 0.61936
Value Function Update Magnitude: 0.47006

Collected Steps per Second: 22,841.31988
Overall Steps per Second: 10,918.21875

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.39087
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58023

Cumulative Model Updates: 145,160
Cumulative Timesteps: 1,210,408,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1210408218...
Checkpoint 1210408218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,299.90397
Policy Entropy: 3.74962
Value Function Loss: 0.02399

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.58107
Value Function Update Magnitude: 0.43508

Collected Steps per Second: 22,994.80690
Overall Steps per Second: 10,705.14491

Timestep Collection Time: 2.17475
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.67140

Cumulative Model Updates: 145,166
Cumulative Timesteps: 1,210,458,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,690.62143
Policy Entropy: 3.74282
Value Function Loss: 0.02473

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08151
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.41112

Collected Steps per Second: 22,968.18336
Overall Steps per Second: 10,881.93253

Timestep Collection Time: 2.17788
Timestep Consumption Time: 2.41891
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.59679

Cumulative Model Updates: 145,172
Cumulative Timesteps: 1,210,508,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1210508248...
Checkpoint 1210508248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,880.82151
Policy Entropy: 3.73598
Value Function Loss: 0.02477

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.59442
Value Function Update Magnitude: 0.42000

Collected Steps per Second: 22,796.56068
Overall Steps per Second: 10,680.20207

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68437

Cumulative Model Updates: 145,178
Cumulative Timesteps: 1,210,558,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,880.82151
Policy Entropy: 3.72593
Value Function Loss: 0.02179

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.38266

Collected Steps per Second: 22,702.37544
Overall Steps per Second: 10,815.13289

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.42074
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.62315

Cumulative Model Updates: 145,184
Cumulative Timesteps: 1,210,608,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1210608278...
Checkpoint 1210608278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,769.18210
Policy Entropy: 3.72551
Value Function Loss: 0.02533

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.57174
Value Function Update Magnitude: 0.36336

Collected Steps per Second: 22,743.72029
Overall Steps per Second: 10,742.30570

Timestep Collection Time: 2.19858
Timestep Consumption Time: 2.45628
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.65487

Cumulative Model Updates: 145,190
Cumulative Timesteps: 1,210,658,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,079.59408
Policy Entropy: 3.73439
Value Function Loss: 0.02916

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.31128

Collected Steps per Second: 22,747.66105
Overall Steps per Second: 10,818.21368

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62202

Cumulative Model Updates: 145,196
Cumulative Timesteps: 1,210,708,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1210708284...
Checkpoint 1210708284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,778.41011
Policy Entropy: 3.76182
Value Function Loss: 0.04151

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.19391
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.31683

Collected Steps per Second: 22,334.35251
Overall Steps per Second: 10,778.08191

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.27569
Total Iteration Time: 4.63979

Cumulative Model Updates: 145,202
Cumulative Timesteps: 1,210,758,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,164.86099
Policy Entropy: 3.77292
Value Function Loss: 0.04495

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.17241
Policy Update Magnitude: 0.64036
Value Function Update Magnitude: 0.57840

Collected Steps per Second: 22,652.71685
Overall Steps per Second: 10,799.08174

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.63113

Cumulative Model Updates: 145,208
Cumulative Timesteps: 1,210,808,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1210808304...
Checkpoint 1210808304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,184.32725
Policy Entropy: 3.80338
Value Function Loss: 0.04891

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.70647
Value Function Update Magnitude: 0.53176

Collected Steps per Second: 22,640.78517
Overall Steps per Second: 10,676.96230

Timestep Collection Time: 2.21017
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.68673

Cumulative Model Updates: 145,214
Cumulative Timesteps: 1,210,858,344

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.92048
Policy Entropy: 3.79659
Value Function Loss: 0.04039

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.75865
Value Function Update Magnitude: 0.50621

Collected Steps per Second: 22,985.26892
Overall Steps per Second: 10,862.73755

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.42768
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.60308

Cumulative Model Updates: 145,220
Cumulative Timesteps: 1,210,908,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1210908346...
Checkpoint 1210908346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,379.25264
Policy Entropy: 3.78388
Value Function Loss: 0.03451

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.65166
Value Function Update Magnitude: 0.47448

Collected Steps per Second: 22,712.05052
Overall Steps per Second: 10,701.62665

Timestep Collection Time: 2.20297
Timestep Consumption Time: 2.47239
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.67536

Cumulative Model Updates: 145,226
Cumulative Timesteps: 1,210,958,380

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,793.55752
Policy Entropy: 3.74583
Value Function Loss: 0.02798

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15498
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.49218

Collected Steps per Second: 23,031.24964
Overall Steps per Second: 10,893.68242

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.42011
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.59220

Cumulative Model Updates: 145,232
Cumulative Timesteps: 1,211,008,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1211008406...
Checkpoint 1211008406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,936.73849
Policy Entropy: 3.73029
Value Function Loss: 0.02495

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.21559
Policy Update Magnitude: 0.48646
Value Function Update Magnitude: 0.54742

Collected Steps per Second: 23,043.75858
Overall Steps per Second: 10,758.36328

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.47806
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.64810

Cumulative Model Updates: 145,238
Cumulative Timesteps: 1,211,058,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,938.29566
Policy Entropy: 3.70907
Value Function Loss: 0.03727

Mean KL Divergence: 0.02653
SB3 Clip Fraction: 0.25094
Policy Update Magnitude: 0.48075
Value Function Update Magnitude: 0.60294

Collected Steps per Second: 23,223.43765
Overall Steps per Second: 10,821.86887

Timestep Collection Time: 2.15489
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.62434

Cumulative Model Updates: 145,244
Cumulative Timesteps: 1,211,108,456

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1211108456...
Checkpoint 1211108456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,925.29560
Policy Entropy: 3.79088
Value Function Loss: 0.04672

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.69734
Value Function Update Magnitude: 0.69787

Collected Steps per Second: 22,902.28462
Overall Steps per Second: 10,708.81504

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.67036

Cumulative Model Updates: 145,250
Cumulative Timesteps: 1,211,158,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.76265
Policy Entropy: 3.84011
Value Function Loss: 0.04708

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.80077
Value Function Update Magnitude: 0.63742

Collected Steps per Second: 23,298.15367
Overall Steps per Second: 10,834.91843

Timestep Collection Time: 2.14687
Timestep Consumption Time: 2.46951
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.61637

Cumulative Model Updates: 145,256
Cumulative Timesteps: 1,211,208,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1211208488...
Checkpoint 1211208488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,703.28541
Policy Entropy: 3.86921
Value Function Loss: 0.04547

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.78326
Value Function Update Magnitude: 0.64470

Collected Steps per Second: 23,007.70453
Overall Steps per Second: 10,718.07342

Timestep Collection Time: 2.17423
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.66726

Cumulative Model Updates: 145,262
Cumulative Timesteps: 1,211,258,512

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,174.73290
Policy Entropy: 3.87655
Value Function Loss: 0.04232

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.87732
Value Function Update Magnitude: 0.68380

Collected Steps per Second: 23,219.78729
Overall Steps per Second: 10,841.08032

Timestep Collection Time: 2.15377
Timestep Consumption Time: 2.45924
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.61301

Cumulative Model Updates: 145,268
Cumulative Timesteps: 1,211,308,522

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1211308522...
Checkpoint 1211308522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,128.23562
Policy Entropy: 3.84566
Value Function Loss: 0.04150

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.94724
Value Function Update Magnitude: 0.83681

Collected Steps per Second: 22,852.58493
Overall Steps per Second: 10,690.50573

Timestep Collection Time: 2.18846
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.67817

Cumulative Model Updates: 145,274
Cumulative Timesteps: 1,211,358,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670.52736
Policy Entropy: 3.83421
Value Function Loss: 0.03303

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.81213
Value Function Update Magnitude: 0.81079

Collected Steps per Second: 23,167.53499
Overall Steps per Second: 10,768.44069

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.64394

Cumulative Model Updates: 145,280
Cumulative Timesteps: 1,211,408,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1211408542...
Checkpoint 1211408542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,307.82055
Policy Entropy: 3.78599
Value Function Loss: 0.02509

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.15887
Policy Update Magnitude: 0.58073
Value Function Update Magnitude: 0.71723

Collected Steps per Second: 22,647.17574
Overall Steps per Second: 10,716.58966

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.66716

Cumulative Model Updates: 145,286
Cumulative Timesteps: 1,211,458,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,902.24665
Policy Entropy: 3.77142
Value Function Loss: 0.02027

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.63969

Collected Steps per Second: 23,060.68835
Overall Steps per Second: 10,885.39661

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59331

Cumulative Model Updates: 145,292
Cumulative Timesteps: 1,211,508,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1211508558...
Checkpoint 1211508558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,465.60485
Policy Entropy: 3.76559
Value Function Loss: 0.01845

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.55307
Value Function Update Magnitude: 0.54418

Collected Steps per Second: 22,875.23254
Overall Steps per Second: 10,673.20566

Timestep Collection Time: 2.18682
Timestep Consumption Time: 2.50006
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.68688

Cumulative Model Updates: 145,298
Cumulative Timesteps: 1,211,558,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.62985
Policy Entropy: 3.76714
Value Function Loss: 0.01700

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.50115

Collected Steps per Second: 23,070.62626
Overall Steps per Second: 10,935.71766

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.40520
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.57272

Cumulative Model Updates: 145,304
Cumulative Timesteps: 1,211,608,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1211608588...
Checkpoint 1211608588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,729.30801
Policy Entropy: 3.77762
Value Function Loss: 0.01486

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.51341
Value Function Update Magnitude: 0.54534

Collected Steps per Second: 23,056.72696
Overall Steps per Second: 10,771.65430

Timestep Collection Time: 2.16995
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.64478

Cumulative Model Updates: 145,310
Cumulative Timesteps: 1,211,658,620

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,751.62681
Policy Entropy: 3.79105
Value Function Loss: 0.01390

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06895
Policy Update Magnitude: 0.48178
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 23,220.03803
Overall Steps per Second: 10,799.32837

Timestep Collection Time: 2.15469
Timestep Consumption Time: 2.47819
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.63288

Cumulative Model Updates: 145,316
Cumulative Timesteps: 1,211,708,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1211708652...
Checkpoint 1211708652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,184.34999
Policy Entropy: 3.79402
Value Function Loss: 0.01311

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06531
Policy Update Magnitude: 0.45464
Value Function Update Magnitude: 0.56828

Collected Steps per Second: 22,535.07120
Overall Steps per Second: 10,972.10692

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.33974
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.55993

Cumulative Model Updates: 145,322
Cumulative Timesteps: 1,211,758,684

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,515.69031
Policy Entropy: 3.79257
Value Function Loss: 0.01230

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.45820
Value Function Update Magnitude: 0.49514

Collected Steps per Second: 22,306.36381
Overall Steps per Second: 10,905.30760

Timestep Collection Time: 2.24151
Timestep Consumption Time: 2.34341
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.58492

Cumulative Model Updates: 145,328
Cumulative Timesteps: 1,211,808,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1211808684...
Checkpoint 1211808684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,515.69031
Policy Entropy: 3.74998
Value Function Loss: 0.01374

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.17412
Policy Update Magnitude: 0.37938
Value Function Update Magnitude: 0.53943

Collected Steps per Second: 22,232.68818
Overall Steps per Second: 10,782.28315

Timestep Collection Time: 2.25047
Timestep Consumption Time: 2.38992
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.64039

Cumulative Model Updates: 145,334
Cumulative Timesteps: 1,211,858,718

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,993.69993
Policy Entropy: 3.75079
Value Function Loss: 0.01504

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17713
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.60903

Collected Steps per Second: 22,923.78147
Overall Steps per Second: 10,870.81650

Timestep Collection Time: 2.18245
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.60223

Cumulative Model Updates: 145,340
Cumulative Timesteps: 1,211,908,748

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1211908748...
Checkpoint 1211908748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,354.76063
Policy Entropy: 3.71426
Value Function Loss: 0.02012

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.17487
Policy Update Magnitude: 0.31375
Value Function Update Magnitude: 0.60190

Collected Steps per Second: 22,875.54155
Overall Steps per Second: 10,804.61459

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.62950

Cumulative Model Updates: 145,346
Cumulative Timesteps: 1,211,958,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,961.38724
Policy Entropy: 3.77518
Value Function Loss: 0.02028

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15143
Policy Update Magnitude: 0.35985
Value Function Update Magnitude: 0.63243

Collected Steps per Second: 22,910.06259
Overall Steps per Second: 10,739.39629

Timestep Collection Time: 2.18306
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.65706

Cumulative Model Updates: 145,352
Cumulative Timesteps: 1,212,008,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1212008782...
Checkpoint 1212008782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,322.67841
Policy Entropy: 3.74790
Value Function Loss: 0.02244

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.38866
Value Function Update Magnitude: 0.67962

Collected Steps per Second: 23,065.88390
Overall Steps per Second: 10,770.82176

Timestep Collection Time: 2.16857
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.64403

Cumulative Model Updates: 145,358
Cumulative Timesteps: 1,212,058,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,859.21074
Policy Entropy: 3.77111
Value Function Loss: 0.02033

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14659
Policy Update Magnitude: 0.37979
Value Function Update Magnitude: 0.67044

Collected Steps per Second: 23,235.17006
Overall Steps per Second: 10,785.69223

Timestep Collection Time: 2.15200
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.63596

Cumulative Model Updates: 145,364
Cumulative Timesteps: 1,212,108,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1212108804...
Checkpoint 1212108804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,901.68079
Policy Entropy: 3.72393
Value Function Loss: 0.02322

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.40263
Value Function Update Magnitude: 0.61136

Collected Steps per Second: 23,037.01609
Overall Steps per Second: 10,758.49889

Timestep Collection Time: 2.17259
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.65214

Cumulative Model Updates: 145,370
Cumulative Timesteps: 1,212,158,854

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,899.17206
Policy Entropy: 3.73297
Value Function Loss: 0.02157

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.44239
Value Function Update Magnitude: 0.48141

Collected Steps per Second: 22,753.01155
Overall Steps per Second: 10,836.84125

Timestep Collection Time: 2.19751
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.61389

Cumulative Model Updates: 145,376
Cumulative Timesteps: 1,212,208,854

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212208854...
Checkpoint 1212208854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,333.36830
Policy Entropy: 3.71186
Value Function Loss: 0.02756

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14202
Policy Update Magnitude: 0.43866
Value Function Update Magnitude: 0.41751

Collected Steps per Second: 22,764.26376
Overall Steps per Second: 10,686.29251

Timestep Collection Time: 2.19722
Timestep Consumption Time: 2.48336
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.68058

Cumulative Model Updates: 145,382
Cumulative Timesteps: 1,212,258,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,729.18033
Policy Entropy: 3.74223
Value Function Loss: 0.02831

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.47400
Value Function Update Magnitude: 0.41218

Collected Steps per Second: 22,750.74219
Overall Steps per Second: 10,872.26485

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.40113
PPO Batch Consumption Time: 0.27597
Total Iteration Time: 4.59886

Cumulative Model Updates: 145,388
Cumulative Timesteps: 1,212,308,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212308872...
Checkpoint 1212308872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,605.57785
Policy Entropy: 3.73549
Value Function Loss: 0.02649

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.44578
Value Function Update Magnitude: 0.41159

Collected Steps per Second: 23,051.45569
Overall Steps per Second: 10,789.79803

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.63605

Cumulative Model Updates: 145,394
Cumulative Timesteps: 1,212,358,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,862.65851
Policy Entropy: 3.74548
Value Function Loss: 0.01998

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.40009
Value Function Update Magnitude: 0.46407

Collected Steps per Second: 23,024.78964
Overall Steps per Second: 10,707.77378

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.66950

Cumulative Model Updates: 145,400
Cumulative Timesteps: 1,212,408,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1212408894...
Checkpoint 1212408894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,050.10867
Policy Entropy: 3.74007
Value Function Loss: 0.01883

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14572
Policy Update Magnitude: 0.37985
Value Function Update Magnitude: 0.48027

Collected Steps per Second: 23,006.86305
Overall Steps per Second: 10,772.16380

Timestep Collection Time: 2.17396
Timestep Consumption Time: 2.46912
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.64308

Cumulative Model Updates: 145,406
Cumulative Timesteps: 1,212,458,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,050.18555
Policy Entropy: 3.73881
Value Function Loss: 0.01781

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.39953
Value Function Update Magnitude: 0.51282

Collected Steps per Second: 23,227.15764
Overall Steps per Second: 10,771.95214

Timestep Collection Time: 2.15343
Timestep Consumption Time: 2.48993
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.64336

Cumulative Model Updates: 145,412
Cumulative Timesteps: 1,212,508,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1212508928...
Checkpoint 1212508928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,323.80149
Policy Entropy: 3.74728
Value Function Loss: 0.01891

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.39184
Value Function Update Magnitude: 0.52248

Collected Steps per Second: 23,184.69830
Overall Steps per Second: 10,821.28222

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.62108

Cumulative Model Updates: 145,418
Cumulative Timesteps: 1,212,558,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,969.98361
Policy Entropy: 3.74184
Value Function Loss: 0.01707

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.36842
Value Function Update Magnitude: 0.50214

Collected Steps per Second: 23,067.13258
Overall Steps per Second: 10,749.71977

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.48439
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65259

Cumulative Model Updates: 145,424
Cumulative Timesteps: 1,212,608,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1212608948...
Checkpoint 1212608948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,991.93365
Policy Entropy: 3.73726
Value Function Loss: 0.01908

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.35379
Value Function Update Magnitude: 0.52380

Collected Steps per Second: 22,733.01373
Overall Steps per Second: 10,705.42704

Timestep Collection Time: 2.20068
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.67314

Cumulative Model Updates: 145,430
Cumulative Timesteps: 1,212,658,976

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,991.93365
Policy Entropy: 3.72470
Value Function Loss: 0.01881

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.37688
Value Function Update Magnitude: 0.53684

Collected Steps per Second: 23,096.92829
Overall Steps per Second: 10,797.49924

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.63348

Cumulative Model Updates: 145,436
Cumulative Timesteps: 1,212,709,006

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1212709006...
Checkpoint 1212709006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,888.98263
Policy Entropy: 3.73443
Value Function Loss: 0.01998

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.43071
Value Function Update Magnitude: 0.53267

Collected Steps per Second: 22,865.00193
Overall Steps per Second: 10,697.48281

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67661

Cumulative Model Updates: 145,442
Cumulative Timesteps: 1,212,759,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,924.52069
Policy Entropy: 3.71319
Value Function Loss: 0.02357

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.45667
Value Function Update Magnitude: 0.50927

Collected Steps per Second: 23,282.83398
Overall Steps per Second: 10,884.53054

Timestep Collection Time: 2.14845
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.59570

Cumulative Model Updates: 145,448
Cumulative Timesteps: 1,212,809,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1212809056...
Checkpoint 1212809056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,019.65867
Policy Entropy: 3.73362
Value Function Loss: 0.02451

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13526
Policy Update Magnitude: 0.49241
Value Function Update Magnitude: 0.53638

Collected Steps per Second: 22,851.06769
Overall Steps per Second: 10,740.10303

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.46835
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.65731

Cumulative Model Updates: 145,454
Cumulative Timesteps: 1,212,859,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,876.79966
Policy Entropy: 3.73548
Value Function Loss: 0.02699

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.51936
Value Function Update Magnitude: 0.63726

Collected Steps per Second: 22,393.00170
Overall Steps per Second: 10,797.28455

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.39901
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.63283

Cumulative Model Updates: 145,460
Cumulative Timesteps: 1,212,909,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1212909098...
Checkpoint 1212909098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,830.84314
Policy Entropy: 3.76468
Value Function Loss: 0.02460

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.51193
Value Function Update Magnitude: 0.65263

Collected Steps per Second: 22,319.88953
Overall Steps per Second: 10,783.60527

Timestep Collection Time: 2.24078
Timestep Consumption Time: 2.39718
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.63797

Cumulative Model Updates: 145,466
Cumulative Timesteps: 1,212,959,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,329.96914
Policy Entropy: 3.75150
Value Function Loss: 0.02631

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.49472
Value Function Update Magnitude: 0.55546

Collected Steps per Second: 22,506.55354
Overall Steps per Second: 10,777.22759

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.64015

Cumulative Model Updates: 145,472
Cumulative Timesteps: 1,213,009,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1213009120...
Checkpoint 1213009120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,421.78089
Policy Entropy: 3.75100
Value Function Loss: 0.02232

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.48074
Value Function Update Magnitude: 0.53982

Collected Steps per Second: 22,594.80905
Overall Steps per Second: 10,696.11894

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.67628

Cumulative Model Updates: 145,478
Cumulative Timesteps: 1,213,059,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,421.78089
Policy Entropy: 3.72158
Value Function Loss: 0.02251

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.46522
Value Function Update Magnitude: 0.50225

Collected Steps per Second: 23,169.26241
Overall Steps per Second: 10,847.35749

Timestep Collection Time: 2.15933
Timestep Consumption Time: 2.45286
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.61218

Cumulative Model Updates: 145,484
Cumulative Timesteps: 1,213,109,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1213109168...
Checkpoint 1213109168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,093.43383
Policy Entropy: 3.72526
Value Function Loss: 0.02257

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.46724
Value Function Update Magnitude: 0.48113

Collected Steps per Second: 23,072.88703
Overall Steps per Second: 10,846.29421

Timestep Collection Time: 2.16739
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.61061

Cumulative Model Updates: 145,490
Cumulative Timesteps: 1,213,159,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,371.17078
Policy Entropy: 3.71613
Value Function Loss: 0.02548

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.50729

Collected Steps per Second: 22,712.42768
Overall Steps per Second: 10,685.53054

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.68072

Cumulative Model Updates: 145,496
Cumulative Timesteps: 1,213,209,192

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1213209192...
Checkpoint 1213209192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,034.78676
Policy Entropy: 3.75943
Value Function Loss: 0.02885

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.45804
Value Function Update Magnitude: 0.60094

Collected Steps per Second: 22,910.56394
Overall Steps per Second: 10,715.81049

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.66862

Cumulative Model Updates: 145,502
Cumulative Timesteps: 1,213,259,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,199.45962
Policy Entropy: 3.76793
Value Function Loss: 0.02749

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.47661
Value Function Update Magnitude: 0.57841

Collected Steps per Second: 23,050.24654
Overall Steps per Second: 10,828.55126

Timestep Collection Time: 2.17048
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.62019

Cumulative Model Updates: 145,508
Cumulative Timesteps: 1,213,309,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1213309250...
Checkpoint 1213309250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,769.51197
Policy Entropy: 3.78259
Value Function Loss: 0.02652

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.48853
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 22,926.94772
Overall Steps per Second: 10,701.16708

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67519

Cumulative Model Updates: 145,514
Cumulative Timesteps: 1,213,359,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.08539
Policy Entropy: 3.75971
Value Function Loss: 0.02096

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.14082
Policy Update Magnitude: 0.49005
Value Function Update Magnitude: 0.51856

Collected Steps per Second: 22,809.69502
Overall Steps per Second: 10,874.79779

Timestep Collection Time: 2.19328
Timestep Consumption Time: 2.40708
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.60036

Cumulative Model Updates: 145,520
Cumulative Timesteps: 1,213,409,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1213409308...
Checkpoint 1213409308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,666.08539
Policy Entropy: 3.73237
Value Function Loss: 0.01953

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.44347
Value Function Update Magnitude: 0.55524

Collected Steps per Second: 23,162.77355
Overall Steps per Second: 10,840.09031

Timestep Collection Time: 2.15933
Timestep Consumption Time: 2.45466
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.61398

Cumulative Model Updates: 145,526
Cumulative Timesteps: 1,213,459,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,260.42952
Policy Entropy: 3.72777
Value Function Loss: 0.01763

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.41588
Value Function Update Magnitude: 0.48237

Collected Steps per Second: 22,823.73963
Overall Steps per Second: 10,685.37690

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.48869
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.67948

Cumulative Model Updates: 145,532
Cumulative Timesteps: 1,213,509,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1213509326...
Checkpoint 1213509326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,434.50451
Policy Entropy: 3.73193
Value Function Loss: 0.01866

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.39956
Value Function Update Magnitude: 0.45176

Collected Steps per Second: 23,298.97537
Overall Steps per Second: 11,011.02887

Timestep Collection Time: 2.14619
Timestep Consumption Time: 2.39508
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.54126

Cumulative Model Updates: 145,538
Cumulative Timesteps: 1,213,559,330

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,863.10789
Policy Entropy: 3.76092
Value Function Loss: 0.01729

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14819
Policy Update Magnitude: 0.35814
Value Function Update Magnitude: 0.40691

Collected Steps per Second: 22,686.05730
Overall Steps per Second: 10,678.12931

Timestep Collection Time: 2.20488
Timestep Consumption Time: 2.47946
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.68434

Cumulative Model Updates: 145,544
Cumulative Timesteps: 1,213,609,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1213609350...
Checkpoint 1213609350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,701.08174
Policy Entropy: 3.76074
Value Function Loss: 0.01798

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.33870
Value Function Update Magnitude: 0.48483

Collected Steps per Second: 23,211.72499
Overall Steps per Second: 10,982.42272

Timestep Collection Time: 2.15495
Timestep Consumption Time: 2.39961
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.55455

Cumulative Model Updates: 145,550
Cumulative Timesteps: 1,213,659,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,507.40455
Policy Entropy: 3.75554
Value Function Loss: 0.01667

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.36814
Value Function Update Magnitude: 0.50658

Collected Steps per Second: 22,421.59403
Overall Steps per Second: 10,897.67702

Timestep Collection Time: 2.23044
Timestep Consumption Time: 2.35861
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.58905

Cumulative Model Updates: 145,556
Cumulative Timesteps: 1,213,709,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1213709380...
Checkpoint 1213709380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,986.39560
Policy Entropy: 3.73087
Value Function Loss: 0.02128

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.39455
Value Function Update Magnitude: 0.50111

Collected Steps per Second: 22,055.29835
Overall Steps per Second: 10,719.80721

Timestep Collection Time: 2.26730
Timestep Consumption Time: 2.39752
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66482

Cumulative Model Updates: 145,562
Cumulative Timesteps: 1,213,759,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,704.57457
Policy Entropy: 3.74885
Value Function Loss: 0.02088

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.51093

Collected Steps per Second: 22,147.04203
Overall Steps per Second: 10,815.87302

Timestep Collection Time: 2.25872
Timestep Consumption Time: 2.36633
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62505

Cumulative Model Updates: 145,568
Cumulative Timesteps: 1,213,809,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1213809410...
Checkpoint 1213809410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,704.57457
Policy Entropy: 3.74486
Value Function Loss: 0.02107

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15021
Policy Update Magnitude: 0.46540
Value Function Update Magnitude: 0.44154

Collected Steps per Second: 22,378.12788
Overall Steps per Second: 10,641.20326

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.46449
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.69890

Cumulative Model Updates: 145,574
Cumulative Timesteps: 1,213,859,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,706.52201
Policy Entropy: 3.74443
Value Function Loss: 0.01696

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.40078
Value Function Update Magnitude: 0.44576

Collected Steps per Second: 23,119.96759
Overall Steps per Second: 10,913.07716

Timestep Collection Time: 2.16281
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.58203

Cumulative Model Updates: 145,580
Cumulative Timesteps: 1,213,909,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1213909416...
Checkpoint 1213909416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,706.52201
Policy Entropy: 3.72654
Value Function Loss: 0.01842

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15864
Policy Update Magnitude: 0.38360
Value Function Update Magnitude: 0.53341

Collected Steps per Second: 22,908.80253
Overall Steps per Second: 10,730.58186

Timestep Collection Time: 2.18396
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.66256

Cumulative Model Updates: 145,586
Cumulative Timesteps: 1,213,959,448

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,725.04902
Policy Entropy: 3.71974
Value Function Loss: 0.01831

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.38326
Value Function Update Magnitude: 0.59112

Collected Steps per Second: 22,858.07226
Overall Steps per Second: 10,809.58666

Timestep Collection Time: 2.18881
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.62848

Cumulative Model Updates: 145,592
Cumulative Timesteps: 1,214,009,480

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1214009480...
Checkpoint 1214009480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,725.04902
Policy Entropy: 3.72457
Value Function Loss: 0.01725

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14869
Policy Update Magnitude: 0.36810
Value Function Update Magnitude: 0.54517

Collected Steps per Second: 22,972.66781
Overall Steps per Second: 10,742.50585

Timestep Collection Time: 2.17693
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.65534

Cumulative Model Updates: 145,598
Cumulative Timesteps: 1,214,059,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,424.94661
Policy Entropy: 3.72677
Value Function Loss: 0.02062

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.37735
Value Function Update Magnitude: 0.41499

Collected Steps per Second: 22,915.04988
Overall Steps per Second: 10,804.59112

Timestep Collection Time: 2.18206
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.62785

Cumulative Model Updates: 145,604
Cumulative Timesteps: 1,214,109,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1214109492...
Checkpoint 1214109492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,823.51992
Policy Entropy: 3.73332
Value Function Loss: 0.02236

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.42208
Value Function Update Magnitude: 0.41993

Collected Steps per Second: 23,110.35121
Overall Steps per Second: 10,814.67884

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.46011
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.62390

Cumulative Model Updates: 145,610
Cumulative Timesteps: 1,214,159,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,554.71606
Policy Entropy: 3.73357
Value Function Loss: 0.02351

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13834
Policy Update Magnitude: 0.41758
Value Function Update Magnitude: 0.41459

Collected Steps per Second: 22,738.40125
Overall Steps per Second: 10,685.87714

Timestep Collection Time: 2.19910
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.67945

Cumulative Model Updates: 145,616
Cumulative Timesteps: 1,214,209,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1214209502...
Checkpoint 1214209502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,652.38089
Policy Entropy: 3.75242
Value Function Loss: 0.02009

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.42524
Value Function Update Magnitude: 0.40738

Collected Steps per Second: 22,182.15288
Overall Steps per Second: 10,721.41510

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.66580

Cumulative Model Updates: 145,622
Cumulative Timesteps: 1,214,259,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,652.38089
Policy Entropy: 3.74094
Value Function Loss: 0.01908

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.39480
Value Function Update Magnitude: 0.41121

Collected Steps per Second: 22,392.97239
Overall Steps per Second: 10,858.74935

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.37193
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.60495

Cumulative Model Updates: 145,628
Cumulative Timesteps: 1,214,309,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1214309530...
Checkpoint 1214309530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,652.38089
Policy Entropy: 3.73960
Value Function Loss: 0.01803

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.37548
Value Function Update Magnitude: 0.45136

Collected Steps per Second: 22,262.91884
Overall Steps per Second: 10,624.83146

Timestep Collection Time: 2.24589
Timestep Consumption Time: 2.46007
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.70596

Cumulative Model Updates: 145,634
Cumulative Timesteps: 1,214,359,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,652.38089
Policy Entropy: 3.72665
Value Function Loss: 0.01949

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.14307
Policy Update Magnitude: 0.37951
Value Function Update Magnitude: 0.43502

Collected Steps per Second: 23,014.06893
Overall Steps per Second: 10,864.52775

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.60269

Cumulative Model Updates: 145,640
Cumulative Timesteps: 1,214,409,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1214409536...
Checkpoint 1214409536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,360.76430
Policy Entropy: 3.73092
Value Function Loss: 0.01936

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.41403
Value Function Update Magnitude: 0.42154

Collected Steps per Second: 22,762.13073
Overall Steps per Second: 10,756.28896

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.65012

Cumulative Model Updates: 145,646
Cumulative Timesteps: 1,214,459,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,725.09219
Policy Entropy: 3.73996
Value Function Loss: 0.01933

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.44080
Value Function Update Magnitude: 0.48022

Collected Steps per Second: 23,223.29488
Overall Steps per Second: 10,841.53250

Timestep Collection Time: 2.15344
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.61282

Cumulative Model Updates: 145,652
Cumulative Timesteps: 1,214,509,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1214509564...
Checkpoint 1214509564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,423.80506
Policy Entropy: 3.75965
Value Function Loss: 0.01999

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.44570
Value Function Update Magnitude: 0.54363

Collected Steps per Second: 22,749.10847
Overall Steps per Second: 10,674.14792

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.48742
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68628

Cumulative Model Updates: 145,658
Cumulative Timesteps: 1,214,559,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,416.70573
Policy Entropy: 3.77795
Value Function Loss: 0.02085

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.42812
Value Function Update Magnitude: 0.53724

Collected Steps per Second: 23,014.41248
Overall Steps per Second: 10,914.06351

Timestep Collection Time: 2.17429
Timestep Consumption Time: 2.41062
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.58491

Cumulative Model Updates: 145,664
Cumulative Timesteps: 1,214,609,626

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1214609626...
Checkpoint 1214609626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,422.43249
Policy Entropy: 3.79231
Value Function Loss: 0.02201

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.42723
Value Function Update Magnitude: 0.52587

Collected Steps per Second: 23,031.33809
Overall Steps per Second: 10,744.63972

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.65367

Cumulative Model Updates: 145,670
Cumulative Timesteps: 1,214,659,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,724.28082
Policy Entropy: 3.79203
Value Function Loss: 0.02199

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.42749
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 23,196.13522
Overall Steps per Second: 10,739.45150

Timestep Collection Time: 2.15596
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.65666

Cumulative Model Updates: 145,676
Cumulative Timesteps: 1,214,709,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1214709638...
Checkpoint 1214709638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,481.20724
Policy Entropy: 3.78612
Value Function Loss: 0.02375

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.42526
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 23,030.43729
Overall Steps per Second: 10,769.97318

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.64309

Cumulative Model Updates: 145,682
Cumulative Timesteps: 1,214,759,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,311.38383
Policy Entropy: 3.76491
Value Function Loss: 0.02279

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.43884
Value Function Update Magnitude: 0.63485

Collected Steps per Second: 23,252.04554
Overall Steps per Second: 10,748.14244

Timestep Collection Time: 2.15129
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.65401

Cumulative Model Updates: 145,688
Cumulative Timesteps: 1,214,809,666

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1214809666...
Checkpoint 1214809666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.41128
Policy Entropy: 3.76126
Value Function Loss: 0.02221

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.42416
Value Function Update Magnitude: 0.67223

Collected Steps per Second: 22,957.34985
Overall Steps per Second: 10,694.77714

Timestep Collection Time: 2.17874
Timestep Consumption Time: 2.49813
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.67686

Cumulative Model Updates: 145,694
Cumulative Timesteps: 1,214,859,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,664.31447
Policy Entropy: 3.75111
Value Function Loss: 0.01826

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.40425
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 22,950.53132
Overall Steps per Second: 10,909.69535

Timestep Collection Time: 2.17860
Timestep Consumption Time: 2.40448
PPO Batch Consumption Time: 0.27548
Total Iteration Time: 4.58308

Cumulative Model Updates: 145,700
Cumulative Timesteps: 1,214,909,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1214909684...
Checkpoint 1214909684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,664.31447
Policy Entropy: 3.73542
Value Function Loss: 0.01572

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.35900
Value Function Update Magnitude: 0.52230

Collected Steps per Second: 23,298.90580
Overall Steps per Second: 10,972.12217

Timestep Collection Time: 2.14723
Timestep Consumption Time: 2.41233
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.55956

Cumulative Model Updates: 145,706
Cumulative Timesteps: 1,214,959,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,664.31447
Policy Entropy: 3.72047
Value Function Loss: 0.01396

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.31429
Value Function Update Magnitude: 0.40593

Collected Steps per Second: 22,916.05519
Overall Steps per Second: 10,751.15875

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.46918
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.65141

Cumulative Model Updates: 145,712
Cumulative Timesteps: 1,215,009,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1215009720...
Checkpoint 1215009720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,535.73348
Policy Entropy: 3.71907
Value Function Loss: 0.01649

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.31215
Value Function Update Magnitude: 0.40353

Collected Steps per Second: 22,847.83585
Overall Steps per Second: 10,826.33992

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.43114
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.62058

Cumulative Model Updates: 145,718
Cumulative Timesteps: 1,215,059,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,936.18757
Policy Entropy: 3.73805
Value Function Loss: 0.01821

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.35522
Value Function Update Magnitude: 0.38655

Collected Steps per Second: 22,979.50311
Overall Steps per Second: 10,870.41267

Timestep Collection Time: 2.17637
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.60075

Cumulative Model Updates: 145,724
Cumulative Timesteps: 1,215,109,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1215109756...
Checkpoint 1215109756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,876.89384
Policy Entropy: 3.73991
Value Function Loss: 0.01853

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.36490
Value Function Update Magnitude: 0.43354

Collected Steps per Second: 22,983.29089
Overall Steps per Second: 10,735.43365

Timestep Collection Time: 2.17636
Timestep Consumption Time: 2.48297
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.65934

Cumulative Model Updates: 145,730
Cumulative Timesteps: 1,215,159,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,876.89384
Policy Entropy: 3.73791
Value Function Loss: 0.01799

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.37634
Value Function Update Magnitude: 0.48273

Collected Steps per Second: 22,896.76906
Overall Steps per Second: 10,856.24132

Timestep Collection Time: 2.18441
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60712

Cumulative Model Updates: 145,736
Cumulative Timesteps: 1,215,209,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1215209792...
Checkpoint 1215209792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,501.36165
Policy Entropy: 3.73286
Value Function Loss: 0.01700

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.38786
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 22,640.86952
Overall Steps per Second: 10,707.83444

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.67079

Cumulative Model Updates: 145,742
Cumulative Timesteps: 1,215,259,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,579.92398
Policy Entropy: 3.72998
Value Function Loss: 0.01832

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.39072
Value Function Update Magnitude: 0.65283

Collected Steps per Second: 22,998.93536
Overall Steps per Second: 10,945.28539

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.39483
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.56946

Cumulative Model Updates: 145,748
Cumulative Timesteps: 1,215,309,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1215309820...
Checkpoint 1215309820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,039.91245
Policy Entropy: 3.74710
Value Function Loss: 0.01864

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.39290
Value Function Update Magnitude: 0.61156

Collected Steps per Second: 22,733.79810
Overall Steps per Second: 10,731.52484

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.45990
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.65936

Cumulative Model Updates: 145,754
Cumulative Timesteps: 1,215,359,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,516.11929
Policy Entropy: 3.74537
Value Function Loss: 0.01769

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.44306
Value Function Update Magnitude: 0.51665

Collected Steps per Second: 22,357.23347
Overall Steps per Second: 10,743.88631

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.65493

Cumulative Model Updates: 145,760
Cumulative Timesteps: 1,215,409,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1215409834...
Checkpoint 1215409834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313,646.32591
Policy Entropy: 3.72974
Value Function Loss: 0.02357

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.45986
Value Function Update Magnitude: 0.47500

Collected Steps per Second: 22,290.34250
Overall Steps per Second: 10,772.59251

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.64215

Cumulative Model Updates: 145,766
Cumulative Timesteps: 1,215,459,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,383.13159
Policy Entropy: 3.73732
Value Function Loss: 0.02349

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.50147
Value Function Update Magnitude: 0.50750

Collected Steps per Second: 22,559.07767
Overall Steps per Second: 10,804.37802

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.41260
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.63016

Cumulative Model Updates: 145,772
Cumulative Timesteps: 1,215,509,868

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1215509868...
Checkpoint 1215509868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,545.49028
Policy Entropy: 3.72314
Value Function Loss: 0.02514

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.48108
Value Function Update Magnitude: 0.54765

Collected Steps per Second: 22,113.89056
Overall Steps per Second: 10,628.66263

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.70558

Cumulative Model Updates: 145,778
Cumulative Timesteps: 1,215,559,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,545.49028
Policy Entropy: 3.72473
Value Function Loss: 0.02141

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.44958
Value Function Update Magnitude: 0.46037

Collected Steps per Second: 23,317.36629
Overall Steps per Second: 10,902.81491

Timestep Collection Time: 2.14467
Timestep Consumption Time: 2.44204
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.58671

Cumulative Model Updates: 145,784
Cumulative Timesteps: 1,215,609,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1215609890...
Checkpoint 1215609890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,545.49028
Policy Entropy: 3.70038
Value Function Loss: 0.02350

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.42430
Value Function Update Magnitude: 0.38799

Collected Steps per Second: 22,676.41828
Overall Steps per Second: 10,725.81793

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.66519

Cumulative Model Updates: 145,790
Cumulative Timesteps: 1,215,659,928

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,011.01965
Policy Entropy: 3.69752
Value Function Loss: 0.02172

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.44226
Value Function Update Magnitude: 0.49966

Collected Steps per Second: 23,157.91823
Overall Steps per Second: 10,853.14293

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.60807

Cumulative Model Updates: 145,796
Cumulative Timesteps: 1,215,709,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1215709940...
Checkpoint 1215709940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,011.01965
Policy Entropy: 3.71737
Value Function Loss: 0.02088

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 0.46038
Value Function Update Magnitude: 0.47144

Collected Steps per Second: 23,076.61678
Overall Steps per Second: 10,790.52796

Timestep Collection Time: 2.16730
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.63499

Cumulative Model Updates: 145,802
Cumulative Timesteps: 1,215,759,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,011.01965
Policy Entropy: 3.73510
Value Function Loss: 0.01704

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.43354
Value Function Update Magnitude: 0.48679

Collected Steps per Second: 22,912.56338
Overall Steps per Second: 10,742.15435

Timestep Collection Time: 2.18230
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.65475

Cumulative Model Updates: 145,808
Cumulative Timesteps: 1,215,809,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1215809956...
Checkpoint 1215809956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,520.02176
Policy Entropy: 3.74144
Value Function Loss: 0.01605

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.41233
Value Function Update Magnitude: 0.50593

Collected Steps per Second: 22,520.33153
Overall Steps per Second: 10,628.20754

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70484

Cumulative Model Updates: 145,814
Cumulative Timesteps: 1,215,859,960

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,520.02176
Policy Entropy: 3.71845
Value Function Loss: 0.01763

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.40430
Value Function Update Magnitude: 0.41811

Collected Steps per Second: 23,120.12275
Overall Steps per Second: 10,899.05311

Timestep Collection Time: 2.16305
Timestep Consumption Time: 2.42542
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.58847

Cumulative Model Updates: 145,820
Cumulative Timesteps: 1,215,909,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1215909970...
Checkpoint 1215909970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,848.96717
Policy Entropy: 3.72741
Value Function Loss: 0.01895

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.42781
Value Function Update Magnitude: 0.41230

Collected Steps per Second: 22,766.73146
Overall Steps per Second: 10,678.53630

Timestep Collection Time: 2.19671
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68341

Cumulative Model Updates: 145,826
Cumulative Timesteps: 1,215,959,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,848.96717
Policy Entropy: 3.72923
Value Function Loss: 0.01868

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.46489
Value Function Update Magnitude: 0.39667

Collected Steps per Second: 22,967.44770
Overall Steps per Second: 10,873.17170

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.59921

Cumulative Model Updates: 145,832
Cumulative Timesteps: 1,216,009,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1216009990...
Checkpoint 1216009990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369,848.96717
Policy Entropy: 3.73130
Value Function Loss: 0.01843

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.42761
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 22,577.67575
Overall Steps per Second: 10,664.78526

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69095

Cumulative Model Updates: 145,838
Cumulative Timesteps: 1,216,060,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,848.96717
Policy Entropy: 3.72364
Value Function Loss: 0.01797

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.40589
Value Function Update Magnitude: 0.31669

Collected Steps per Second: 22,692.79658
Overall Steps per Second: 10,844.52238

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.40882
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61357

Cumulative Model Updates: 145,844
Cumulative Timesteps: 1,216,110,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1216110050...
Checkpoint 1216110050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571,448.62461
Policy Entropy: 3.72026
Value Function Loss: 0.01962

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.43221
Value Function Update Magnitude: 0.31732

Collected Steps per Second: 22,794.75800
Overall Steps per Second: 10,744.70987

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.46105
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.65550

Cumulative Model Updates: 145,850
Cumulative Timesteps: 1,216,160,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303,691.06408
Policy Entropy: 3.73070
Value Function Loss: 0.01885

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.43656
Value Function Update Magnitude: 0.33943

Collected Steps per Second: 22,279.04560
Overall Steps per Second: 10,891.71039

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.34704
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.59193

Cumulative Model Updates: 145,856
Cumulative Timesteps: 1,216,210,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1216210086...
Checkpoint 1216210086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,920.56750
Policy Entropy: 3.72803
Value Function Loss: 0.02040

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13359
Policy Update Magnitude: 0.42562
Value Function Update Magnitude: 0.43234

Collected Steps per Second: 22,050.21197
Overall Steps per Second: 10,702.33787

Timestep Collection Time: 2.26764
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.67206

Cumulative Model Updates: 145,862
Cumulative Timesteps: 1,216,260,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643,920.56750
Policy Entropy: 3.72887
Value Function Loss: 0.01803

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.43710
Value Function Update Magnitude: 0.41955

Collected Steps per Second: 22,313.34260
Overall Steps per Second: 10,771.70488

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.40146
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.64272

Cumulative Model Updates: 145,868
Cumulative Timesteps: 1,216,310,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1216310098...
Checkpoint 1216310098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,351.64375
Policy Entropy: 3.73403
Value Function Loss: 0.01881

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.43631
Value Function Update Magnitude: 0.44588

Collected Steps per Second: 22,815.17745
Overall Steps per Second: 10,758.32839

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.64998

Cumulative Model Updates: 145,874
Cumulative Timesteps: 1,216,360,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,460.85813
Policy Entropy: 3.73133
Value Function Loss: 0.01735

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.42504
Value Function Update Magnitude: 0.47658

Collected Steps per Second: 23,350.98494
Overall Steps per Second: 10,836.93430

Timestep Collection Time: 2.14158
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.61459

Cumulative Model Updates: 145,880
Cumulative Timesteps: 1,216,410,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1216410132...
Checkpoint 1216410132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 503,460.85813
Policy Entropy: 3.73133
Value Function Loss: 0.01998

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.42588
Value Function Update Magnitude: 0.37789

Collected Steps per Second: 22,922.91090
Overall Steps per Second: 10,707.58433

Timestep Collection Time: 2.18131
Timestep Consumption Time: 2.48846
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.66977

Cumulative Model Updates: 145,886
Cumulative Timesteps: 1,216,460,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 503,460.85813
Policy Entropy: 3.71341
Value Function Loss: 0.02084

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.43013
Value Function Update Magnitude: 0.32237

Collected Steps per Second: 22,921.49331
Overall Steps per Second: 10,884.29089

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.41464
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.59800

Cumulative Model Updates: 145,892
Cumulative Timesteps: 1,216,510,180

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1216510180...
Checkpoint 1216510180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317,024.10581
Policy Entropy: 3.72156
Value Function Loss: 0.01949

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.46080
Value Function Update Magnitude: 0.47877

Collected Steps per Second: 22,949.69119
Overall Steps per Second: 10,767.18068

Timestep Collection Time: 2.17877
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.64393

Cumulative Model Updates: 145,898
Cumulative Timesteps: 1,216,560,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,852.39043
Policy Entropy: 3.72961
Value Function Loss: 0.01909

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.46814
Value Function Update Magnitude: 0.69666

Collected Steps per Second: 23,451.63391
Overall Steps per Second: 10,851.79707

Timestep Collection Time: 2.13256
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.60864

Cumulative Model Updates: 145,904
Cumulative Timesteps: 1,216,610,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1216610194...
Checkpoint 1216610194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,666.65138
Policy Entropy: 3.74747
Value Function Loss: 0.02258

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.51300
Value Function Update Magnitude: 0.70634

Collected Steps per Second: 22,665.85958
Overall Steps per Second: 10,719.55231

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66437

Cumulative Model Updates: 145,910
Cumulative Timesteps: 1,216,660,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326,146.43468
Policy Entropy: 3.74086
Value Function Loss: 0.02394

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.51807
Value Function Update Magnitude: 0.61640

Collected Steps per Second: 23,324.32672
Overall Steps per Second: 10,823.73400

Timestep Collection Time: 2.14368
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.61948

Cumulative Model Updates: 145,916
Cumulative Timesteps: 1,216,710,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1216710194...
Checkpoint 1216710194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,643.74429
Policy Entropy: 3.73222
Value Function Loss: 0.02565

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.59269

Collected Steps per Second: 22,070.85707
Overall Steps per Second: 10,759.92451

Timestep Collection Time: 2.26634
Timestep Consumption Time: 2.38239
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.64873

Cumulative Model Updates: 145,922
Cumulative Timesteps: 1,216,760,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,469.10456
Policy Entropy: 3.73542
Value Function Loss: 0.02442

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.53170

Collected Steps per Second: 22,372.87271
Overall Steps per Second: 10,766.78862

Timestep Collection Time: 2.23556
Timestep Consumption Time: 2.40983
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.64540

Cumulative Model Updates: 145,928
Cumulative Timesteps: 1,216,810,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1216810230...
Checkpoint 1216810230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,639.83177
Policy Entropy: 3.74564
Value Function Loss: 0.02636

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.50696
Value Function Update Magnitude: 0.52196

Collected Steps per Second: 21,733.56031
Overall Steps per Second: 10,590.02627

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.72407

Cumulative Model Updates: 145,934
Cumulative Timesteps: 1,216,860,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,317.05215
Policy Entropy: 3.76295
Value Function Loss: 0.02460

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.69787

Collected Steps per Second: 22,579.72322
Overall Steps per Second: 10,928.88918

Timestep Collection Time: 2.21588
Timestep Consumption Time: 2.36226
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.57814

Cumulative Model Updates: 145,940
Cumulative Timesteps: 1,216,910,292

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1216910292...
Checkpoint 1216910292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,782.70354
Policy Entropy: 3.75506
Value Function Loss: 0.02391

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.76707

Collected Steps per Second: 22,490.50278
Overall Steps per Second: 10,664.47864

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68977

Cumulative Model Updates: 145,946
Cumulative Timesteps: 1,216,960,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,932.11288
Policy Entropy: 3.74476
Value Function Loss: 0.02169

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.48484
Value Function Update Magnitude: 0.67241

Collected Steps per Second: 23,070.36341
Overall Steps per Second: 10,856.85070

Timestep Collection Time: 2.16850
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.60797

Cumulative Model Updates: 145,952
Cumulative Timesteps: 1,217,010,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1217010334...
Checkpoint 1217010334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,537.64515
Policy Entropy: 3.73347
Value Function Loss: 0.01893

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.44438
Value Function Update Magnitude: 0.50316

Collected Steps per Second: 22,786.71946
Overall Steps per Second: 10,774.79545

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.64529

Cumulative Model Updates: 145,958
Cumulative Timesteps: 1,217,060,386

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,851.73089
Policy Entropy: 3.73030
Value Function Loss: 0.01657

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.41292
Value Function Update Magnitude: 0.44297

Collected Steps per Second: 23,437.70495
Overall Steps per Second: 10,787.20741

Timestep Collection Time: 2.13468
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.63809

Cumulative Model Updates: 145,964
Cumulative Timesteps: 1,217,110,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1217110418...
Checkpoint 1217110418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,268.08320
Policy Entropy: 3.74536
Value Function Loss: 0.01654

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13949
Policy Update Magnitude: 0.40708
Value Function Update Magnitude: 0.42017

Collected Steps per Second: 22,936.28674
Overall Steps per Second: 10,707.39054

Timestep Collection Time: 2.18082
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.67154

Cumulative Model Updates: 145,970
Cumulative Timesteps: 1,217,160,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,196.31155
Policy Entropy: 3.74447
Value Function Loss: 0.01756

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.40188
Value Function Update Magnitude: 0.45988

Collected Steps per Second: 23,198.77948
Overall Steps per Second: 10,845.66726

Timestep Collection Time: 2.15529
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61014

Cumulative Model Updates: 145,976
Cumulative Timesteps: 1,217,210,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1217210438...
Checkpoint 1217210438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,991.80499
Policy Entropy: 3.74961
Value Function Loss: 0.01918

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.43580
Value Function Update Magnitude: 0.45622

Collected Steps per Second: 22,807.30047
Overall Steps per Second: 10,668.94398

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68856

Cumulative Model Updates: 145,982
Cumulative Timesteps: 1,217,260,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,884.44173
Policy Entropy: 3.74371
Value Function Loss: 0.01850

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.43996
Value Function Update Magnitude: 0.48485

Collected Steps per Second: 23,169.15578
Overall Steps per Second: 10,957.48713

Timestep Collection Time: 2.15839
Timestep Consumption Time: 2.40543
PPO Batch Consumption Time: 0.27562
Total Iteration Time: 4.56382

Cumulative Model Updates: 145,988
Cumulative Timesteps: 1,217,310,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1217310468...
Checkpoint 1217310468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,884.44173
Policy Entropy: 3.74824
Value Function Loss: 0.01707

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.42329
Value Function Update Magnitude: 0.55804

Collected Steps per Second: 22,840.64314
Overall Steps per Second: 10,746.86109

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.46482
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.65513

Cumulative Model Updates: 145,994
Cumulative Timesteps: 1,217,360,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,884.44173
Policy Entropy: 3.72867
Value Function Loss: 0.01793

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.43940
Value Function Update Magnitude: 0.47737

Collected Steps per Second: 23,194.25452
Overall Steps per Second: 10,764.57262

Timestep Collection Time: 2.15640
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.64635

Cumulative Model Updates: 146,000
Cumulative Timesteps: 1,217,410,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1217410512...
Checkpoint 1217410512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,431.33871
Policy Entropy: 3.72869
Value Function Loss: 0.02092

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.44847
Value Function Update Magnitude: 0.46730

Collected Steps per Second: 22,690.84453
Overall Steps per Second: 10,679.67662

Timestep Collection Time: 2.20415
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.68310

Cumulative Model Updates: 146,006
Cumulative Timesteps: 1,217,460,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358,873.02931
Policy Entropy: 3.73640
Value Function Loss: 0.02026

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.44050
Value Function Update Magnitude: 0.51022

Collected Steps per Second: 23,003.07546
Overall Steps per Second: 10,843.03150

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61292

Cumulative Model Updates: 146,012
Cumulative Timesteps: 1,217,510,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1217510544...
Checkpoint 1217510544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,722.20405
Policy Entropy: 3.73432
Value Function Loss: 0.02194

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.43168
Value Function Update Magnitude: 0.48229

Collected Steps per Second: 22,859.43037
Overall Steps per Second: 10,732.15514

Timestep Collection Time: 2.18728
Timestep Consumption Time: 2.47162
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.65890

Cumulative Model Updates: 146,018
Cumulative Timesteps: 1,217,560,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,722.20405
Policy Entropy: 3.73612
Value Function Loss: 0.01840

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.45977
Value Function Update Magnitude: 0.49291

Collected Steps per Second: 22,455.51405
Overall Steps per Second: 10,786.52748

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.63541

Cumulative Model Updates: 146,024
Cumulative Timesteps: 1,217,610,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1217610544...
Checkpoint 1217610544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,540.79292
Policy Entropy: 3.72582
Value Function Loss: 0.02301

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.45154
Value Function Update Magnitude: 0.42808

Collected Steps per Second: 21,884.46816
Overall Steps per Second: 10,647.56554

Timestep Collection Time: 2.28546
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.69741

Cumulative Model Updates: 146,030
Cumulative Timesteps: 1,217,660,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,917.78788
Policy Entropy: 3.73560
Value Function Loss: 0.01991

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.46547
Value Function Update Magnitude: 0.40504

Collected Steps per Second: 22,589.35085
Overall Steps per Second: 10,916.17127

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.36806
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.58256

Cumulative Model Updates: 146,036
Cumulative Timesteps: 1,217,710,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1217710584...
Checkpoint 1217710584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,101.56839
Policy Entropy: 3.72214
Value Function Loss: 0.02448

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.44309
Value Function Update Magnitude: 0.40284

Collected Steps per Second: 22,283.36821
Overall Steps per Second: 10,662.13527

Timestep Collection Time: 2.24508
Timestep Consumption Time: 2.44704
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69212

Cumulative Model Updates: 146,042
Cumulative Timesteps: 1,217,760,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,101.56839
Policy Entropy: 3.72976
Value Function Loss: 0.02127

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.43185
Value Function Update Magnitude: 0.43227

Collected Steps per Second: 23,221.42739
Overall Steps per Second: 10,897.70439

Timestep Collection Time: 2.15336
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.58849

Cumulative Model Updates: 146,048
Cumulative Timesteps: 1,217,810,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1217810616...
Checkpoint 1217810616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,448.04822
Policy Entropy: 3.71890
Value Function Loss: 0.02151

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.46245
Value Function Update Magnitude: 0.55992

Collected Steps per Second: 23,017.26502
Overall Steps per Second: 10,756.79536

Timestep Collection Time: 2.17341
Timestep Consumption Time: 2.47723
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.65064

Cumulative Model Updates: 146,054
Cumulative Timesteps: 1,217,860,642

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,249.94671
Policy Entropy: 3.72690
Value Function Loss: 0.01852

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.47180
Value Function Update Magnitude: 0.65102

Collected Steps per Second: 23,246.44556
Overall Steps per Second: 10,800.02175

Timestep Collection Time: 2.15147
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.63092

Cumulative Model Updates: 146,060
Cumulative Timesteps: 1,217,910,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1217910656...
Checkpoint 1217910656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178,847.48186
Policy Entropy: 3.73934
Value Function Loss: 0.01680

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.42475
Value Function Update Magnitude: 0.63110

Collected Steps per Second: 22,869.84091
Overall Steps per Second: 10,687.57837

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.68076

Cumulative Model Updates: 146,066
Cumulative Timesteps: 1,217,960,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,866.07449
Policy Entropy: 3.72619
Value Function Loss: 0.01655

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.38255
Value Function Update Magnitude: 0.57077

Collected Steps per Second: 23,120.46869
Overall Steps per Second: 10,865.10017

Timestep Collection Time: 2.16466
Timestep Consumption Time: 2.44165
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.60631

Cumulative Model Updates: 146,072
Cumulative Timesteps: 1,218,010,730

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1218010730...
Checkpoint 1218010730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,866.07449
Policy Entropy: 3.73704
Value Function Loss: 0.01576

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.37552
Value Function Update Magnitude: 0.50900

Collected Steps per Second: 22,740.03920
Overall Steps per Second: 10,681.33681

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.48250
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.68144

Cumulative Model Updates: 146,078
Cumulative Timesteps: 1,218,060,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,736.31890
Policy Entropy: 3.70881
Value Function Loss: 0.01758

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.42626
Value Function Update Magnitude: 0.52621

Collected Steps per Second: 23,148.52205
Overall Steps per Second: 10,878.57358

Timestep Collection Time: 2.16066
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.59766

Cumulative Model Updates: 146,084
Cumulative Timesteps: 1,218,110,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1218110750...
Checkpoint 1218110750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,392.72077
Policy Entropy: 3.72362
Value Function Loss: 0.01758

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.46579
Value Function Update Magnitude: 0.65999

Collected Steps per Second: 21,809.98266
Overall Steps per Second: 10,594.74148

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72159

Cumulative Model Updates: 146,090
Cumulative Timesteps: 1,218,160,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,247.40307
Policy Entropy: 3.72527
Value Function Loss: 0.01755

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.48248
Value Function Update Magnitude: 0.63090

Collected Steps per Second: 22,092.53578
Overall Steps per Second: 10,861.90707

Timestep Collection Time: 2.26438
Timestep Consumption Time: 2.34125
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.60564

Cumulative Model Updates: 146,096
Cumulative Timesteps: 1,218,210,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1218210800...
Checkpoint 1218210800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,247.40307
Policy Entropy: 3.74300
Value Function Loss: 0.01549

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.46023
Value Function Update Magnitude: 0.53674

Collected Steps per Second: 21,996.91231
Overall Steps per Second: 10,702.57982

Timestep Collection Time: 2.27432
Timestep Consumption Time: 2.40007
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.67439

Cumulative Model Updates: 146,102
Cumulative Timesteps: 1,218,260,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,284.88211
Policy Entropy: 3.73870
Value Function Loss: 0.01334

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.43472
Value Function Update Magnitude: 0.52608

Collected Steps per Second: 22,985.45777
Overall Steps per Second: 10,988.66465

Timestep Collection Time: 2.17668
Timestep Consumption Time: 2.37637
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.55306

Cumulative Model Updates: 146,108
Cumulative Timesteps: 1,218,310,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1218310860...
Checkpoint 1218310860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,284.88211
Policy Entropy: 3.72602
Value Function Loss: 0.01390

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.42874
Value Function Update Magnitude: 0.53082

Collected Steps per Second: 22,886.81630
Overall Steps per Second: 10,944.25867

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.38423
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.56915

Cumulative Model Updates: 146,114
Cumulative Timesteps: 1,218,360,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,048.94367
Policy Entropy: 3.74002
Value Function Loss: 0.01475

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.42232
Value Function Update Magnitude: 0.53594

Collected Steps per Second: 22,918.02539
Overall Steps per Second: 10,767.05955

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.64454

Cumulative Model Updates: 146,120
Cumulative Timesteps: 1,218,410,874

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1218410874...
Checkpoint 1218410874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 548,962.84042
Policy Entropy: 3.72464
Value Function Loss: 0.02307

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.45564
Value Function Update Magnitude: 0.44545

Collected Steps per Second: 23,039.96409
Overall Steps per Second: 10,871.31208

Timestep Collection Time: 2.17058
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.60018

Cumulative Model Updates: 146,126
Cumulative Timesteps: 1,218,460,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,219.02103
Policy Entropy: 3.73960
Value Function Loss: 0.02089

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.51468
Value Function Update Magnitude: 0.47057

Collected Steps per Second: 23,200.21450
Overall Steps per Second: 10,985.37041

Timestep Collection Time: 2.15532
Timestep Consumption Time: 2.39655
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.55187

Cumulative Model Updates: 146,132
Cumulative Timesteps: 1,218,510,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1218510888...
Checkpoint 1218510888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,979.48274
Policy Entropy: 3.73708
Value Function Loss: 0.02479

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14069
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.53009

Collected Steps per Second: 22,966.49048
Overall Steps per Second: 10,924.41645

Timestep Collection Time: 2.17822
Timestep Consumption Time: 2.40107
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.57928

Cumulative Model Updates: 146,138
Cumulative Timesteps: 1,218,560,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,188.64834
Policy Entropy: 3.75124
Value Function Loss: 0.02118

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.67416

Collected Steps per Second: 23,195.97935
Overall Steps per Second: 10,904.57533

Timestep Collection Time: 2.15563
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.58541

Cumulative Model Updates: 146,144
Cumulative Timesteps: 1,218,610,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1218610916...
Checkpoint 1218610916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,749.13275
Policy Entropy: 3.74706
Value Function Loss: 0.02570

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.54693
Value Function Update Magnitude: 0.65989

Collected Steps per Second: 22,679.46586
Overall Steps per Second: 10,729.66230

Timestep Collection Time: 2.20561
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.66203

Cumulative Model Updates: 146,150
Cumulative Timesteps: 1,218,660,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,885.35141
Policy Entropy: 3.76877
Value Function Loss: 0.02385

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.59188
Value Function Update Magnitude: 0.86677

Collected Steps per Second: 22,893.61216
Overall Steps per Second: 10,831.05961

Timestep Collection Time: 2.18498
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.61838

Cumulative Model Updates: 146,156
Cumulative Timesteps: 1,218,710,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1218710960...
Checkpoint 1218710960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,885.35141
Policy Entropy: 3.72845
Value Function Loss: 0.02711

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.60032
Value Function Update Magnitude: 0.87096

Collected Steps per Second: 21,920.40207
Overall Steps per Second: 10,668.72242

Timestep Collection Time: 2.28317
Timestep Consumption Time: 2.40793
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.69110

Cumulative Model Updates: 146,162
Cumulative Timesteps: 1,218,761,008

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,949.62059
Policy Entropy: 3.72145
Value Function Loss: 0.02592

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.60863
Value Function Update Magnitude: 0.70009

Collected Steps per Second: 23,010.49622
Overall Steps per Second: 10,895.49741

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.41719
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59107

Cumulative Model Updates: 146,168
Cumulative Timesteps: 1,218,811,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1218811030...
Checkpoint 1218811030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,523.91539
Policy Entropy: 3.70923
Value Function Loss: 0.02646

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.60278
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,769.17248
Overall Steps per Second: 9,922.25996

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.84482
PPO Batch Consumption Time: 0.35039
Total Iteration Time: 5.04200

Cumulative Model Updates: 146,174
Cumulative Timesteps: 1,218,861,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,523.91539
Policy Entropy: 3.73000
Value Function Loss: 0.02315

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.58575
Value Function Update Magnitude: 0.55683

Collected Steps per Second: 11,604.98162
Overall Steps per Second: 7,282.61582

Timestep Collection Time: 4.31091
Timestep Consumption Time: 2.55860
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 6.86951

Cumulative Model Updates: 146,180
Cumulative Timesteps: 1,218,911,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1218911086...
Checkpoint 1218911086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,523.91539
Policy Entropy: 3.72384
Value Function Loss: 0.01933

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.52394
Value Function Update Magnitude: 0.49534

Collected Steps per Second: 18,445.55603
Overall Steps per Second: 9,607.71057

Timestep Collection Time: 2.71144
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 5.20561

Cumulative Model Updates: 146,186
Cumulative Timesteps: 1,218,961,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,588.42040
Policy Entropy: 3.73532
Value Function Loss: 0.01595

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13880
Policy Update Magnitude: 0.45525
Value Function Update Magnitude: 0.45005

Collected Steps per Second: 18,940.73879
Overall Steps per Second: 9,458.20274

Timestep Collection Time: 2.64055
Timestep Consumption Time: 2.64735
PPO Batch Consumption Time: 0.31966
Total Iteration Time: 5.28790

Cumulative Model Updates: 146,192
Cumulative Timesteps: 1,219,011,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1219011114...
Checkpoint 1219011114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,400.49611
Policy Entropy: 3.73593
Value Function Loss: 0.01624

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.47753
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 20,111.28933
Overall Steps per Second: 9,968.30375

Timestep Collection Time: 2.48806
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.30670
Total Iteration Time: 5.01971

Cumulative Model Updates: 146,198
Cumulative Timesteps: 1,219,061,152

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,548.69676
Policy Entropy: 3.73733
Value Function Loss: 0.01619

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.50956
Value Function Update Magnitude: 0.66252

Collected Steps per Second: 18,906.32291
Overall Steps per Second: 9,542.61848

Timestep Collection Time: 2.64462
Timestep Consumption Time: 2.59503
PPO Batch Consumption Time: 0.30680
Total Iteration Time: 5.23965

Cumulative Model Updates: 146,204
Cumulative Timesteps: 1,219,111,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1219111152...
Checkpoint 1219111152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,502.12065
Policy Entropy: 3.72948
Value Function Loss: 0.02046

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.50115
Value Function Update Magnitude: 0.66462

Collected Steps per Second: 20,336.60977
Overall Steps per Second: 9,792.10247

Timestep Collection Time: 2.45901
Timestep Consumption Time: 2.64796
PPO Batch Consumption Time: 0.30556
Total Iteration Time: 5.10697

Cumulative Model Updates: 146,210
Cumulative Timesteps: 1,219,161,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,582.34854
Policy Entropy: 3.73374
Value Function Loss: 0.02131

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.50911
Value Function Update Magnitude: 0.62913

Collected Steps per Second: 17,593.74834
Overall Steps per Second: 9,308.59028

Timestep Collection Time: 2.84271
Timestep Consumption Time: 2.53017
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 5.37289

Cumulative Model Updates: 146,216
Cumulative Timesteps: 1,219,211,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1219211174...
Checkpoint 1219211174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,822.23250
Policy Entropy: 3.74780
Value Function Loss: 0.02479

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.52045
Value Function Update Magnitude: 0.63882

Collected Steps per Second: 20,457.87355
Overall Steps per Second: 9,461.02353

Timestep Collection Time: 2.44502
Timestep Consumption Time: 2.84193
PPO Batch Consumption Time: 0.34746
Total Iteration Time: 5.28695

Cumulative Model Updates: 146,222
Cumulative Timesteps: 1,219,261,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,993.72685
Policy Entropy: 3.75312
Value Function Loss: 0.02261

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.52876
Value Function Update Magnitude: 0.68091

Collected Steps per Second: 15,093.65914
Overall Steps per Second: 7,901.12755

Timestep Collection Time: 3.31397
Timestep Consumption Time: 3.01677
PPO Batch Consumption Time: 0.35245
Total Iteration Time: 6.33074

Cumulative Model Updates: 146,228
Cumulative Timesteps: 1,219,311,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1219311214...
Checkpoint 1219311214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,540.54045
Policy Entropy: 3.75225
Value Function Loss: 0.02159

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.78461

Collected Steps per Second: 17,758.18763
Overall Steps per Second: 8,673.59066

Timestep Collection Time: 2.81774
Timestep Consumption Time: 2.95126
PPO Batch Consumption Time: 0.35243
Total Iteration Time: 5.76901

Cumulative Model Updates: 146,234
Cumulative Timesteps: 1,219,361,252

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,540.54045
Policy Entropy: 3.73988
Value Function Loss: 0.01919

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.51657
Value Function Update Magnitude: 0.72387

Collected Steps per Second: 15,035.80102
Overall Steps per Second: 8,402.82977

Timestep Collection Time: 3.32713
Timestep Consumption Time: 2.62634
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 5.95347

Cumulative Model Updates: 146,240
Cumulative Timesteps: 1,219,411,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1219411278...
Checkpoint 1219411278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,540.54045
Policy Entropy: 3.73298
Value Function Loss: 0.01734

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.48177
Value Function Update Magnitude: 0.62499

Collected Steps per Second: 18,316.44069
Overall Steps per Second: 9,491.21777

Timestep Collection Time: 2.72979
Timestep Consumption Time: 2.53824
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 5.26803

Cumulative Model Updates: 146,246
Cumulative Timesteps: 1,219,461,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,540.54045
Policy Entropy: 3.70172
Value Function Loss: 0.01946

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.47536
Value Function Update Magnitude: 0.60195

Collected Steps per Second: 14,070.83951
Overall Steps per Second: 8,100.70586

Timestep Collection Time: 3.55402
Timestep Consumption Time: 2.61927
PPO Batch Consumption Time: 0.31408
Total Iteration Time: 6.17329

Cumulative Model Updates: 146,252
Cumulative Timesteps: 1,219,511,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1219511286...
Checkpoint 1219511286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198,747.19666
Policy Entropy: 3.73188
Value Function Loss: 0.01959

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.48634
Value Function Update Magnitude: 0.50904

Collected Steps per Second: 17,762.31171
Overall Steps per Second: 9,333.70957

Timestep Collection Time: 2.81551
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.30430
Total Iteration Time: 5.35800

Cumulative Model Updates: 146,258
Cumulative Timesteps: 1,219,561,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,399.86803
Policy Entropy: 3.73279
Value Function Loss: 0.01777

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.45076
Value Function Update Magnitude: 0.53507

Collected Steps per Second: 15,403.63280
Overall Steps per Second: 7,006.49610

Timestep Collection Time: 3.24884
Timestep Consumption Time: 3.89367
PPO Batch Consumption Time: 0.52472
Total Iteration Time: 7.14251

Cumulative Model Updates: 146,264
Cumulative Timesteps: 1,219,611,340

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1219611340...
Checkpoint 1219611340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,399.86803
Policy Entropy: 3.75112
Value Function Loss: 0.01682

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.38772
Value Function Update Magnitude: 0.47183

Collected Steps per Second: 16,057.38101
Overall Steps per Second: 7,579.74573

Timestep Collection Time: 3.11495
Timestep Consumption Time: 3.48395
PPO Batch Consumption Time: 0.45776
Total Iteration Time: 6.59890

Cumulative Model Updates: 146,270
Cumulative Timesteps: 1,219,661,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,399.86803
Policy Entropy: 3.73782
Value Function Loss: 0.01423

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.38129
Value Function Update Magnitude: 0.40084

Collected Steps per Second: 14,599.58062
Overall Steps per Second: 7,114.63178

Timestep Collection Time: 3.42489
Timestep Consumption Time: 3.60316
PPO Batch Consumption Time: 0.46913
Total Iteration Time: 7.02805

Cumulative Model Updates: 146,276
Cumulative Timesteps: 1,219,711,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1219711360...
Checkpoint 1219711360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,399.86803
Policy Entropy: 3.72606
Value Function Loss: 0.01603

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.39882
Value Function Update Magnitude: 0.41158

Collected Steps per Second: 16,102.02198
Overall Steps per Second: 7,446.07304

Timestep Collection Time: 3.10545
Timestep Consumption Time: 3.61004
PPO Batch Consumption Time: 0.48172
Total Iteration Time: 6.71549

Cumulative Model Updates: 146,282
Cumulative Timesteps: 1,219,761,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,932.25312
Policy Entropy: 3.73763
Value Function Loss: 0.01616

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.39807
Value Function Update Magnitude: 0.37477

Collected Steps per Second: 15,223.88044
Overall Steps per Second: 7,150.87814

Timestep Collection Time: 3.28747
Timestep Consumption Time: 3.71139
PPO Batch Consumption Time: 0.49518
Total Iteration Time: 6.99886

Cumulative Model Updates: 146,288
Cumulative Timesteps: 1,219,811,412

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1219811412...
Checkpoint 1219811412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,932.25312
Policy Entropy: 3.72577
Value Function Loss: 0.01631

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.39866
Value Function Update Magnitude: 0.41172

Collected Steps per Second: 15,236.39324
Overall Steps per Second: 7,163.10500

Timestep Collection Time: 3.28175
Timestep Consumption Time: 3.69874
PPO Batch Consumption Time: 0.49539
Total Iteration Time: 6.98049

Cumulative Model Updates: 146,294
Cumulative Timesteps: 1,219,861,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,932.25312
Policy Entropy: 3.73929
Value Function Loss: 0.01395

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.36468
Value Function Update Magnitude: 0.36526

Collected Steps per Second: 15,544.96109
Overall Steps per Second: 7,291.70263

Timestep Collection Time: 3.21763
Timestep Consumption Time: 3.64194
PPO Batch Consumption Time: 0.48499
Total Iteration Time: 6.85958

Cumulative Model Updates: 146,300
Cumulative Timesteps: 1,219,911,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1219911432...
Checkpoint 1219911432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,932.25312
Policy Entropy: 3.74720
Value Function Loss: 0.01388

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.33975
Value Function Update Magnitude: 0.34340

Collected Steps per Second: 16,007.61211
Overall Steps per Second: 8,659.88916

Timestep Collection Time: 3.12639
Timestep Consumption Time: 2.65267
PPO Batch Consumption Time: 0.32048
Total Iteration Time: 5.77906

Cumulative Model Updates: 146,306
Cumulative Timesteps: 1,219,961,478

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,624.28742
Policy Entropy: 3.74798
Value Function Loss: 0.01412

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.34947
Value Function Update Magnitude: 0.48628

Collected Steps per Second: 16,834.35166
Overall Steps per Second: 9,015.96005

Timestep Collection Time: 2.97131
Timestep Consumption Time: 2.57663
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 5.54794

Cumulative Model Updates: 146,312
Cumulative Timesteps: 1,220,011,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1220011498...
Checkpoint 1220011498 saved!
