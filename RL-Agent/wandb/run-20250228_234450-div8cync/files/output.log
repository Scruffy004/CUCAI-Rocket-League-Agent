Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.89510
Policy Entropy: 4.22535
Value Function Loss: 0.03990

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00384
Policy Update Magnitude: 0.21775
Value Function Update Magnitude: 0.18113

Collected Steps per Second: 6,157.79346
Overall Steps per Second: 3,162.46158

Timestep Collection Time: 8.12239
Timestep Consumption Time: 7.69314
PPO Batch Consumption Time: 2.95492
Total Iteration Time: 15.81553

Cumulative Model Updates: 163,156
Cumulative Timesteps: 1,360,511,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.26729
Policy Entropy: 4.01392
Value Function Loss: 0.03618

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.07557
Policy Update Magnitude: 0.53761
Value Function Update Magnitude: 0.41625

Collected Steps per Second: 18,421.17646
Overall Steps per Second: 9,945.88980

Timestep Collection Time: 2.71600
Timestep Consumption Time: 2.31442
PPO Batch Consumption Time: 0.36394
Total Iteration Time: 5.03042

Cumulative Model Updates: 163,160
Cumulative Timesteps: 1,360,561,910

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1360561910...
Checkpoint 1360561910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,202.16445
Policy Entropy: 3.92279
Value Function Loss: 0.03410

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.46968

Collected Steps per Second: 18,238.62416
Overall Steps per Second: 9,771.50500

Timestep Collection Time: 2.74209
Timestep Consumption Time: 2.37605
PPO Batch Consumption Time: 0.37056
Total Iteration Time: 5.11815

Cumulative Model Updates: 163,164
Cumulative Timesteps: 1,360,611,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,008.43633
Policy Entropy: 3.80539
Value Function Loss: 0.03005

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14691
Policy Update Magnitude: 0.73359
Value Function Update Magnitude: 0.72407

Collected Steps per Second: 19,109.74267
Overall Steps per Second: 8,862.38554

Timestep Collection Time: 2.61804
Timestep Consumption Time: 3.02717
PPO Batch Consumption Time: 0.35631
Total Iteration Time: 5.64521

Cumulative Model Updates: 163,170
Cumulative Timesteps: 1,360,661,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1360661952...
Checkpoint 1360661952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.44310
Policy Entropy: 3.80371
Value Function Loss: 0.02291

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.64716
Value Function Update Magnitude: 0.59603

Collected Steps per Second: 18,652.13016
Overall Steps per Second: 8,617.42208

Timestep Collection Time: 2.68120
Timestep Consumption Time: 3.12216
PPO Batch Consumption Time: 0.36418
Total Iteration Time: 5.80336

Cumulative Model Updates: 163,176
Cumulative Timesteps: 1,360,711,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,876.53905
Policy Entropy: 3.79949
Value Function Loss: 0.02461

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.52169

Collected Steps per Second: 18,776.00630
Overall Steps per Second: 8,814.65402

Timestep Collection Time: 2.66457
Timestep Consumption Time: 3.01120
PPO Batch Consumption Time: 0.36387
Total Iteration Time: 5.67578

Cumulative Model Updates: 163,182
Cumulative Timesteps: 1,360,761,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1360761992...
Checkpoint 1360761992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.36320
Policy Entropy: 3.80479
Value Function Loss: 0.02433

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.50454

Collected Steps per Second: 17,810.91202
Overall Steps per Second: 8,678.22199

Timestep Collection Time: 2.80862
Timestep Consumption Time: 2.95570
PPO Batch Consumption Time: 0.35915
Total Iteration Time: 5.76431

Cumulative Model Updates: 163,188
Cumulative Timesteps: 1,360,812,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.76682
Policy Entropy: 3.77948
Value Function Loss: 0.02656

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.48300
Value Function Update Magnitude: 0.54168

Collected Steps per Second: 17,905.42408
Overall Steps per Second: 8,602.43045

Timestep Collection Time: 2.79346
Timestep Consumption Time: 3.02095
PPO Batch Consumption Time: 0.36410
Total Iteration Time: 5.81440

Cumulative Model Updates: 163,194
Cumulative Timesteps: 1,360,862,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1360862034...
Checkpoint 1360862034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.76682
Policy Entropy: 3.79238
Value Function Loss: 0.01931

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.45349
Value Function Update Magnitude: 0.52960

Collected Steps per Second: 18,100.45532
Overall Steps per Second: 9,657.54915

Timestep Collection Time: 2.76336
Timestep Consumption Time: 2.41580
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 5.17916

Cumulative Model Updates: 163,200
Cumulative Timesteps: 1,360,912,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,499.71909
Policy Entropy: 3.73784
Value Function Loss: 0.01956

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.43515
Value Function Update Magnitude: 0.54241

Collected Steps per Second: 19,752.61576
Overall Steps per Second: 9,834.53430

Timestep Collection Time: 2.53283
Timestep Consumption Time: 2.55435
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 5.08718

Cumulative Model Updates: 163,206
Cumulative Timesteps: 1,360,962,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1360962082...
Checkpoint 1360962082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,568.56374
Policy Entropy: 3.73750
Value Function Loss: 0.02025

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.44307
Value Function Update Magnitude: 0.57069

Collected Steps per Second: 19,917.39665
Overall Steps per Second: 9,955.42733

Timestep Collection Time: 2.51077
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 5.02319

Cumulative Model Updates: 163,212
Cumulative Timesteps: 1,361,012,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,014.85630
Policy Entropy: 3.74148
Value Function Loss: 0.02087

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.46808
Value Function Update Magnitude: 0.60664

Collected Steps per Second: 20,114.03016
Overall Steps per Second: 10,046.19103

Timestep Collection Time: 2.48722
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.97980

Cumulative Model Updates: 163,218
Cumulative Timesteps: 1,361,062,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1361062118...
Checkpoint 1361062118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,671.88353
Policy Entropy: 3.75246
Value Function Loss: 0.02433

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.48230
Value Function Update Magnitude: 0.60875

Collected Steps per Second: 20,236.15618
Overall Steps per Second: 9,886.79671

Timestep Collection Time: 2.47211
Timestep Consumption Time: 2.58777
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 5.05988

Cumulative Model Updates: 163,224
Cumulative Timesteps: 1,361,112,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,141.45613
Policy Entropy: 3.79709
Value Function Loss: 0.02418

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.50938
Value Function Update Magnitude: 0.67728

Collected Steps per Second: 20,459.01792
Overall Steps per Second: 10,032.04384

Timestep Collection Time: 2.44430
Timestep Consumption Time: 2.54053
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.98483

Cumulative Model Updates: 163,230
Cumulative Timesteps: 1,361,162,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1361162152...
Checkpoint 1361162152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,001.96619
Policy Entropy: 3.78440
Value Function Loss: 0.02799

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.46857
Value Function Update Magnitude: 0.54013

Collected Steps per Second: 20,481.17282
Overall Steps per Second: 9,959.98222

Timestep Collection Time: 2.44175
Timestep Consumption Time: 2.57934
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 5.02109

Cumulative Model Updates: 163,236
Cumulative Timesteps: 1,361,212,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,273.34848
Policy Entropy: 3.79106
Value Function Loss: 0.02242

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.42745
Value Function Update Magnitude: 0.43139

Collected Steps per Second: 20,574.27611
Overall Steps per Second: 9,996.01853

Timestep Collection Time: 2.43177
Timestep Consumption Time: 2.57342
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 5.00519

Cumulative Model Updates: 163,242
Cumulative Timesteps: 1,361,262,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1361262194...
Checkpoint 1361262194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,160.44751
Policy Entropy: 3.77177
Value Function Loss: 0.02046

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.43285
Value Function Update Magnitude: 0.36445

Collected Steps per Second: 20,545.36898
Overall Steps per Second: 10,119.63869

Timestep Collection Time: 2.43374
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.94109

Cumulative Model Updates: 163,248
Cumulative Timesteps: 1,361,312,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,014.57837
Policy Entropy: 3.77973
Value Function Loss: 0.01971

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.45153
Value Function Update Magnitude: 0.37586

Collected Steps per Second: 20,271.52941
Overall Steps per Second: 10,081.69421

Timestep Collection Time: 2.46789
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.96226

Cumulative Model Updates: 163,254
Cumulative Timesteps: 1,361,362,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1361362224...
Checkpoint 1361362224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,479.70492
Policy Entropy: 3.78116
Value Function Loss: 0.02083

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.49295
Value Function Update Magnitude: 0.43881

Collected Steps per Second: 20,369.42033
Overall Steps per Second: 10,074.44597

Timestep Collection Time: 2.45564
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.96504

Cumulative Model Updates: 163,260
Cumulative Timesteps: 1,361,412,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,270.43873
Policy Entropy: 3.77594
Value Function Loss: 0.01934

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.48004
Value Function Update Magnitude: 0.42378

Collected Steps per Second: 20,779.86942
Overall Steps per Second: 10,216.87798

Timestep Collection Time: 2.40743
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.89641

Cumulative Model Updates: 163,266
Cumulative Timesteps: 1,361,462,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1361462270...
Checkpoint 1361462270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.61712
Policy Entropy: 3.77857
Value Function Loss: 0.01514

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.44825
Value Function Update Magnitude: 0.36828

Collected Steps per Second: 20,647.39348
Overall Steps per Second: 10,122.82786

Timestep Collection Time: 2.42181
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.93973

Cumulative Model Updates: 163,272
Cumulative Timesteps: 1,361,512,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,800.00094
Policy Entropy: 3.77498
Value Function Loss: 0.01710

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.42402
Value Function Update Magnitude: 0.33413

Collected Steps per Second: 20,278.49978
Overall Steps per Second: 10,021.04540

Timestep Collection Time: 2.46665
Timestep Consumption Time: 2.52484
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.99150

Cumulative Model Updates: 163,278
Cumulative Timesteps: 1,361,562,294

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1361562294...
Checkpoint 1361562294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,368.63656
Policy Entropy: 3.76752
Value Function Loss: 0.01904

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.44512
Value Function Update Magnitude: 0.39762

Collected Steps per Second: 19,727.43492
Overall Steps per Second: 9,795.22307

Timestep Collection Time: 2.53495
Timestep Consumption Time: 2.57040
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 5.10535

Cumulative Model Updates: 163,284
Cumulative Timesteps: 1,361,612,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,897.44509
Policy Entropy: 3.77683
Value Function Loss: 0.02350

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.50173
Value Function Update Magnitude: 0.40088

Collected Steps per Second: 19,803.19668
Overall Steps per Second: 9,723.75744

Timestep Collection Time: 2.52636
Timestep Consumption Time: 2.61877
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 5.14513

Cumulative Model Updates: 163,290
Cumulative Timesteps: 1,361,662,332

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1361662332...
Checkpoint 1361662332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,442.19549
Policy Entropy: 3.78106
Value Function Loss: 0.02252

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.44893

Collected Steps per Second: 20,593.69778
Overall Steps per Second: 10,134.71658

Timestep Collection Time: 2.42822
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.93413

Cumulative Model Updates: 163,296
Cumulative Timesteps: 1,361,712,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,350.94118
Policy Entropy: 3.79852
Value Function Loss: 0.02243

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.52182
Value Function Update Magnitude: 0.51476

Collected Steps per Second: 19,979.91145
Overall Steps per Second: 10,131.05521

Timestep Collection Time: 2.50361
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.93749

Cumulative Model Updates: 163,302
Cumulative Timesteps: 1,361,762,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1361762360...
Checkpoint 1361762360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,326.82062
Policy Entropy: 3.78918
Value Function Loss: 0.02258

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.50985
Value Function Update Magnitude: 0.57266

Collected Steps per Second: 19,978.76393
Overall Steps per Second: 10,133.70486

Timestep Collection Time: 2.50376
Timestep Consumption Time: 2.43244
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.93620

Cumulative Model Updates: 163,308
Cumulative Timesteps: 1,361,812,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,984.78486
Policy Entropy: 3.80994
Value Function Loss: 0.02632

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.54455
Value Function Update Magnitude: 0.63729

Collected Steps per Second: 18,936.73368
Overall Steps per Second: 9,777.84996

Timestep Collection Time: 2.64058
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 5.11401

Cumulative Model Updates: 163,314
Cumulative Timesteps: 1,361,862,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1361862386...
Checkpoint 1361862386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.10999
Policy Entropy: 3.83901
Value Function Loss: 0.02498

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.57084
Value Function Update Magnitude: 0.84678

Collected Steps per Second: 19,784.53753
Overall Steps per Second: 10,065.81462

Timestep Collection Time: 2.52925
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.97128

Cumulative Model Updates: 163,320
Cumulative Timesteps: 1,361,912,426

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,153.71925
Policy Entropy: 3.84041
Value Function Loss: 0.02426

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.52202
Value Function Update Magnitude: 0.92895

Collected Steps per Second: 19,993.21750
Overall Steps per Second: 10,055.85808

Timestep Collection Time: 2.50085
Timestep Consumption Time: 2.47138
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.97223

Cumulative Model Updates: 163,326
Cumulative Timesteps: 1,361,962,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1361962426...
Checkpoint 1361962426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,350.97759
Policy Entropy: 3.81761
Value Function Loss: 0.02281

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12264
Policy Update Magnitude: 0.51486
Value Function Update Magnitude: 0.88718

Collected Steps per Second: 19,850.53129
Overall Steps per Second: 9,852.74286

Timestep Collection Time: 2.51983
Timestep Consumption Time: 2.55693
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 5.07676

Cumulative Model Updates: 163,332
Cumulative Timesteps: 1,362,012,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,308.89239
Policy Entropy: 3.80106
Value Function Loss: 0.02312

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.53945
Value Function Update Magnitude: 0.81145

Collected Steps per Second: 20,522.99158
Overall Steps per Second: 10,090.79944

Timestep Collection Time: 2.43688
Timestep Consumption Time: 2.51932
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.95620

Cumulative Model Updates: 163,338
Cumulative Timesteps: 1,362,062,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1362062458...
Checkpoint 1362062458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,372.69041
Policy Entropy: 3.82421
Value Function Loss: 0.02350

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.69093

Collected Steps per Second: 20,612.32620
Overall Steps per Second: 10,226.25121

Timestep Collection Time: 2.42670
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.89133

Cumulative Model Updates: 163,344
Cumulative Timesteps: 1,362,112,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192.42747
Policy Entropy: 3.83438
Value Function Loss: 0.02296

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.47187
Value Function Update Magnitude: 0.61410

Collected Steps per Second: 20,482.10424
Overall Steps per Second: 9,919.26457

Timestep Collection Time: 2.44194
Timestep Consumption Time: 2.60037
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 5.04231

Cumulative Model Updates: 163,350
Cumulative Timesteps: 1,362,162,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1362162494...
Checkpoint 1362162494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113.53363
Policy Entropy: 3.79849
Value Function Loss: 0.02379

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.42209
Value Function Update Magnitude: 0.56257

Collected Steps per Second: 20,058.56391
Overall Steps per Second: 9,771.46050

Timestep Collection Time: 2.49290
Timestep Consumption Time: 2.62445
PPO Batch Consumption Time: 0.31081
Total Iteration Time: 5.11735

Cumulative Model Updates: 163,356
Cumulative Timesteps: 1,362,212,498

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,337.89722
Policy Entropy: 3.77259
Value Function Loss: 0.01956

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.39132
Value Function Update Magnitude: 0.57227

Collected Steps per Second: 20,674.18595
Overall Steps per Second: 10,136.78335

Timestep Collection Time: 2.41944
Timestep Consumption Time: 2.51506
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.93450

Cumulative Model Updates: 163,362
Cumulative Timesteps: 1,362,262,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1362262518...
Checkpoint 1362262518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,337.89722
Policy Entropy: 3.74321
Value Function Loss: 0.01607

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.34929
Value Function Update Magnitude: 0.50874

Collected Steps per Second: 20,022.18049
Overall Steps per Second: 9,846.27566

Timestep Collection Time: 2.49733
Timestep Consumption Time: 2.58093
PPO Batch Consumption Time: 0.29930
Total Iteration Time: 5.07827

Cumulative Model Updates: 163,368
Cumulative Timesteps: 1,362,312,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,650.92572
Policy Entropy: 3.76359
Value Function Loss: 0.01304

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.33436
Value Function Update Magnitude: 0.39583

Collected Steps per Second: 20,416.79544
Overall Steps per Second: 10,061.41210

Timestep Collection Time: 2.45073
Timestep Consumption Time: 2.52233
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.97306

Cumulative Model Updates: 163,374
Cumulative Timesteps: 1,362,362,556

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1362362556...
Checkpoint 1362362556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,312.58543
Policy Entropy: 3.75910
Value Function Loss: 0.01347

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.35740
Value Function Update Magnitude: 0.40609

Collected Steps per Second: 20,482.72352
Overall Steps per Second: 9,982.52987

Timestep Collection Time: 2.44216
Timestep Consumption Time: 2.56880
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 5.01095

Cumulative Model Updates: 163,380
Cumulative Timesteps: 1,362,412,578

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,312.58543
Policy Entropy: 3.76283
Value Function Loss: 0.01389

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.36665
Value Function Update Magnitude: 0.54456

Collected Steps per Second: 20,690.67169
Overall Steps per Second: 10,048.70654

Timestep Collection Time: 2.41664
Timestep Consumption Time: 2.55932
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.97596

Cumulative Model Updates: 163,386
Cumulative Timesteps: 1,362,462,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1362462580...
Checkpoint 1362462580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,815.63274
Policy Entropy: 3.75684
Value Function Loss: 0.01549

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.39189
Value Function Update Magnitude: 0.68591

Collected Steps per Second: 20,661.00596
Overall Steps per Second: 10,008.86106

Timestep Collection Time: 2.42089
Timestep Consumption Time: 2.57648
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.99737

Cumulative Model Updates: 163,392
Cumulative Timesteps: 1,362,512,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,137.09662
Policy Entropy: 3.74351
Value Function Loss: 0.01521

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.40000
Value Function Update Magnitude: 0.73846

Collected Steps per Second: 19,930.69577
Overall Steps per Second: 10,100.12745

Timestep Collection Time: 2.50879
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.95063

Cumulative Model Updates: 163,398
Cumulative Timesteps: 1,362,562,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1362562600...
Checkpoint 1362562600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,137.09662
Policy Entropy: 3.73707
Value Function Loss: 0.01446

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.40094
Value Function Update Magnitude: 0.64267

Collected Steps per Second: 19,728.06953
Overall Steps per Second: 10,088.59397

Timestep Collection Time: 2.53466
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.95649

Cumulative Model Updates: 163,404
Cumulative Timesteps: 1,362,612,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,137.09662
Policy Entropy: 3.72927
Value Function Loss: 0.01496

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.37361
Value Function Update Magnitude: 0.48835

Collected Steps per Second: 19,974.70063
Overall Steps per Second: 10,093.57316

Timestep Collection Time: 2.50457
Timestep Consumption Time: 2.45185
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.95642

Cumulative Model Updates: 163,410
Cumulative Timesteps: 1,362,662,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1362662632...
Checkpoint 1362662632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,952.99397
Policy Entropy: 3.75065
Value Function Loss: 0.01843

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.38881
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 20,042.64864
Overall Steps per Second: 9,854.66895

Timestep Collection Time: 2.49518
Timestep Consumption Time: 2.57957
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 5.07475

Cumulative Model Updates: 163,416
Cumulative Timesteps: 1,362,712,642

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,596.71672
Policy Entropy: 3.76877
Value Function Loss: 0.02177

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.42573
Value Function Update Magnitude: 0.64117

Collected Steps per Second: 20,433.39634
Overall Steps per Second: 10,082.89767

Timestep Collection Time: 2.44795
Timestep Consumption Time: 2.51292
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.96088

Cumulative Model Updates: 163,422
Cumulative Timesteps: 1,362,762,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1362762662...
Checkpoint 1362762662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,965.92748
Policy Entropy: 3.78410
Value Function Loss: 0.02273

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.48554
Value Function Update Magnitude: 0.79045

Collected Steps per Second: 20,285.17128
Overall Steps per Second: 10,017.30893

Timestep Collection Time: 2.46505
Timestep Consumption Time: 2.52671
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.99176

Cumulative Model Updates: 163,428
Cumulative Timesteps: 1,362,812,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,008.49679
Policy Entropy: 3.77508
Value Function Loss: 0.02426

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11786
Policy Update Magnitude: 0.50804
Value Function Update Magnitude: 0.83138

Collected Steps per Second: 20,392.41598
Overall Steps per Second: 10,125.24796

Timestep Collection Time: 2.45238
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.93914

Cumulative Model Updates: 163,434
Cumulative Timesteps: 1,362,862,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1362862676...
Checkpoint 1362862676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,473.75912
Policy Entropy: 3.77763
Value Function Loss: 0.02248

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.75235

Collected Steps per Second: 20,388.07105
Overall Steps per Second: 9,924.31766

Timestep Collection Time: 2.45379
Timestep Consumption Time: 2.58716
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 5.04095

Cumulative Model Updates: 163,440
Cumulative Timesteps: 1,362,912,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,520.55704
Policy Entropy: 3.74973
Value Function Loss: 0.02116

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 20,552.87488
Overall Steps per Second: 9,982.01194

Timestep Collection Time: 2.43285
Timestep Consumption Time: 2.57636
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 5.00921

Cumulative Model Updates: 163,446
Cumulative Timesteps: 1,362,962,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1362962706...
Checkpoint 1362962706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,520.55704
Policy Entropy: 3.75925
Value Function Loss: 0.01584

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.45601
Value Function Update Magnitude: 0.54555

Collected Steps per Second: 20,118.59927
Overall Steps per Second: 9,864.98682

Timestep Collection Time: 2.48636
Timestep Consumption Time: 2.58430
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 5.07066

Cumulative Model Updates: 163,452
Cumulative Timesteps: 1,363,012,728

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,250.10552
Policy Entropy: 3.74688
Value Function Loss: 0.01467

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14385
Policy Update Magnitude: 0.43491
Value Function Update Magnitude: 0.46873

Collected Steps per Second: 20,482.59473
Overall Steps per Second: 9,990.18336

Timestep Collection Time: 2.44227
Timestep Consumption Time: 2.56505
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 5.00732

Cumulative Model Updates: 163,458
Cumulative Timesteps: 1,363,062,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1363062752...
Checkpoint 1363062752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,054.15847
Policy Entropy: 3.75520
Value Function Loss: 0.01597

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.42439
Value Function Update Magnitude: 0.50078

Collected Steps per Second: 20,233.05260
Overall Steps per Second: 9,858.09533

Timestep Collection Time: 2.47249
Timestep Consumption Time: 2.60212
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 5.07461

Cumulative Model Updates: 163,464
Cumulative Timesteps: 1,363,112,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,237.01332
Policy Entropy: 3.75037
Value Function Loss: 0.01873

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.44268
Value Function Update Magnitude: 0.57900

Collected Steps per Second: 20,272.39809
Overall Steps per Second: 9,961.30682

Timestep Collection Time: 2.46700
Timestep Consumption Time: 2.55363
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 5.02063

Cumulative Model Updates: 163,470
Cumulative Timesteps: 1,363,162,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1363162790...
Checkpoint 1363162790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,491.26441
Policy Entropy: 3.74462
Value Function Loss: 0.02170

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.47742
Value Function Update Magnitude: 0.67749

Collected Steps per Second: 20,480.44349
Overall Steps per Second: 9,968.28798

Timestep Collection Time: 2.44174
Timestep Consumption Time: 2.57497
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 5.01671

Cumulative Model Updates: 163,476
Cumulative Timesteps: 1,363,212,798

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,170.90501
Policy Entropy: 3.75824
Value Function Loss: 0.02398

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.46627
Value Function Update Magnitude: 0.55739

Collected Steps per Second: 20,387.81783
Overall Steps per Second: 9,941.57520

Timestep Collection Time: 2.45274
Timestep Consumption Time: 2.57725
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 5.02999

Cumulative Model Updates: 163,482
Cumulative Timesteps: 1,363,262,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1363262804...
Checkpoint 1363262804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,637.38045
Policy Entropy: 3.76328
Value Function Loss: 0.02337

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.49580
Value Function Update Magnitude: 0.49947

Collected Steps per Second: 20,373.21481
Overall Steps per Second: 10,133.52813

Timestep Collection Time: 2.45469
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.93510

Cumulative Model Updates: 163,488
Cumulative Timesteps: 1,363,312,814

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,637.38045
Policy Entropy: 3.74967
Value Function Loss: 0.02256

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.46408
Value Function Update Magnitude: 0.42014

Collected Steps per Second: 20,423.34413
Overall Steps per Second: 10,053.23826

Timestep Collection Time: 2.44857
Timestep Consumption Time: 2.52575
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.97432

Cumulative Model Updates: 163,494
Cumulative Timesteps: 1,363,362,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1363362822...
Checkpoint 1363362822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,796.57335
Policy Entropy: 3.73251
Value Function Loss: 0.02735

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.43443
Value Function Update Magnitude: 0.30471

Collected Steps per Second: 19,978.80757
Overall Steps per Second: 9,746.03693

Timestep Collection Time: 2.50325
Timestep Consumption Time: 2.62827
PPO Batch Consumption Time: 0.30477
Total Iteration Time: 5.13152

Cumulative Model Updates: 163,500
Cumulative Timesteps: 1,363,412,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,798.12705
Policy Entropy: 3.74032
Value Function Loss: 0.02555

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.45916
Value Function Update Magnitude: 0.26228

Collected Steps per Second: 20,760.57382
Overall Steps per Second: 10,152.15321

Timestep Collection Time: 2.40928
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.92684

Cumulative Model Updates: 163,506
Cumulative Timesteps: 1,363,462,852

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1363462852...
Checkpoint 1363462852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,662.98212
Policy Entropy: 3.73757
Value Function Loss: 0.02739

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.47936
Value Function Update Magnitude: 0.36867

Collected Steps per Second: 20,471.33272
Overall Steps per Second: 9,940.53095

Timestep Collection Time: 2.44273
Timestep Consumption Time: 2.58778
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 5.03052

Cumulative Model Updates: 163,512
Cumulative Timesteps: 1,363,512,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,264.49532
Policy Entropy: 3.75626
Value Function Loss: 0.02531

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.52302
Value Function Update Magnitude: 0.50572

Collected Steps per Second: 20,745.04762
Overall Steps per Second: 10,070.92793

Timestep Collection Time: 2.41137
Timestep Consumption Time: 2.55580
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.96717

Cumulative Model Updates: 163,518
Cumulative Timesteps: 1,363,562,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1363562882...
Checkpoint 1363562882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,492.79956
Policy Entropy: 3.73278
Value Function Loss: 0.02801

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.50944
Value Function Update Magnitude: 0.57553

Collected Steps per Second: 20,473.45132
Overall Steps per Second: 10,096.83157

Timestep Collection Time: 2.44346
Timestep Consumption Time: 2.51117
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.95462

Cumulative Model Updates: 163,524
Cumulative Timesteps: 1,363,612,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,704.74974
Policy Entropy: 3.74934
Value Function Loss: 0.02057

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.46258
Value Function Update Magnitude: 0.46436

Collected Steps per Second: 20,401.18718
Overall Steps per Second: 10,033.73457

Timestep Collection Time: 2.45182
Timestep Consumption Time: 2.53336
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.98518

Cumulative Model Updates: 163,530
Cumulative Timesteps: 1,363,662,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1363662928...
Checkpoint 1363662928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,980.91212
Policy Entropy: 3.75617
Value Function Loss: 0.01967

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14025
Policy Update Magnitude: 0.41248
Value Function Update Magnitude: 0.43406

Collected Steps per Second: 20,384.05636
Overall Steps per Second: 9,905.14720

Timestep Collection Time: 2.45378
Timestep Consumption Time: 2.59592
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 5.04970

Cumulative Model Updates: 163,536
Cumulative Timesteps: 1,363,712,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,392.61640
Policy Entropy: 3.75724
Value Function Loss: 0.01742

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.38513
Value Function Update Magnitude: 0.45943

Collected Steps per Second: 20,649.88476
Overall Steps per Second: 9,999.93963

Timestep Collection Time: 2.42239
Timestep Consumption Time: 2.57984
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 5.00223

Cumulative Model Updates: 163,542
Cumulative Timesteps: 1,363,762,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1363762968...
Checkpoint 1363762968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,392.61640
Policy Entropy: 3.75527
Value Function Loss: 0.01489

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.36653
Value Function Update Magnitude: 0.45837

Collected Steps per Second: 20,734.33173
Overall Steps per Second: 10,144.89870

Timestep Collection Time: 2.41271
Timestep Consumption Time: 2.51843
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.93115

Cumulative Model Updates: 163,548
Cumulative Timesteps: 1,363,812,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,392.61640
Policy Entropy: 3.73276
Value Function Loss: 0.01356

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.37749
Value Function Update Magnitude: 0.44421

Collected Steps per Second: 19,702.89515
Overall Steps per Second: 10,042.01828

Timestep Collection Time: 2.53871
Timestep Consumption Time: 2.44236
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.98107

Cumulative Model Updates: 163,554
Cumulative Timesteps: 1,363,863,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1363863014...
Checkpoint 1363863014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,392.61640
Policy Entropy: 3.73970
Value Function Loss: 0.01576

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.41172
Value Function Update Magnitude: 0.47988

Collected Steps per Second: 19,650.90028
Overall Steps per Second: 9,906.43611

Timestep Collection Time: 2.54523
Timestep Consumption Time: 2.50361
PPO Batch Consumption Time: 0.29736
Total Iteration Time: 5.04884

Cumulative Model Updates: 163,560
Cumulative Timesteps: 1,363,913,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,606.51381
Policy Entropy: 3.74198
Value Function Loss: 0.01914

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.53721

Collected Steps per Second: 19,645.35660
Overall Steps per Second: 9,901.32789

Timestep Collection Time: 2.54533
Timestep Consumption Time: 2.50490
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 5.05023

Cumulative Model Updates: 163,566
Cumulative Timesteps: 1,363,963,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1363963034...
Checkpoint 1363963034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,065.41927
Policy Entropy: 3.74759
Value Function Loss: 0.01898

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.47738
Value Function Update Magnitude: 0.56724

Collected Steps per Second: 20,338.73513
Overall Steps per Second: 10,004.44538

Timestep Collection Time: 2.45836
Timestep Consumption Time: 2.53942
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.99778

Cumulative Model Updates: 163,572
Cumulative Timesteps: 1,364,013,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,802.17013
Policy Entropy: 3.75577
Value Function Loss: 0.01931

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.46325
Value Function Update Magnitude: 0.48694

Collected Steps per Second: 20,245.16162
Overall Steps per Second: 9,853.08751

Timestep Collection Time: 2.46973
Timestep Consumption Time: 2.60483
PPO Batch Consumption Time: 0.30670
Total Iteration Time: 5.07455

Cumulative Model Updates: 163,578
Cumulative Timesteps: 1,364,063,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1364063034...
Checkpoint 1364063034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,802.17013
Policy Entropy: 3.74395
Value Function Loss: 0.01874

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.45738
Value Function Update Magnitude: 0.45836

Collected Steps per Second: 20,245.19386
Overall Steps per Second: 9,918.19787

Timestep Collection Time: 2.47031
Timestep Consumption Time: 2.57213
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 5.04245

Cumulative Model Updates: 163,584
Cumulative Timesteps: 1,364,113,046

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,802.17013
Policy Entropy: 3.73179
Value Function Loss: 0.01890

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.44178
Value Function Update Magnitude: 0.38891

Collected Steps per Second: 20,656.54693
Overall Steps per Second: 9,991.25540

Timestep Collection Time: 2.42102
Timestep Consumption Time: 2.58435
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 5.00538

Cumulative Model Updates: 163,590
Cumulative Timesteps: 1,364,163,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1364163056...
Checkpoint 1364163056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,802.17013
Policy Entropy: 3.73042
Value Function Loss: 0.01597

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.40921
Value Function Update Magnitude: 0.28959

Collected Steps per Second: 20,398.80708
Overall Steps per Second: 9,940.23777

Timestep Collection Time: 2.45259
Timestep Consumption Time: 2.58048
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 5.03308

Cumulative Model Updates: 163,596
Cumulative Timesteps: 1,364,213,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,802.17013
Policy Entropy: 3.72663
Value Function Loss: 0.01382

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.37761
Value Function Update Magnitude: 0.23218

Collected Steps per Second: 20,493.08043
Overall Steps per Second: 9,936.67742

Timestep Collection Time: 2.44043
Timestep Consumption Time: 2.59264
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 5.03307

Cumulative Model Updates: 163,602
Cumulative Timesteps: 1,364,263,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1364263098...
Checkpoint 1364263098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,742.80078
Policy Entropy: 3.74045
Value Function Loss: 0.01380

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.40064
Value Function Update Magnitude: 0.34283

Collected Steps per Second: 20,125.24828
Overall Steps per Second: 9,864.67209

Timestep Collection Time: 2.48444
Timestep Consumption Time: 2.58415
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.06859

Cumulative Model Updates: 163,608
Cumulative Timesteps: 1,364,313,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,258.13638
Policy Entropy: 3.73003
Value Function Loss: 0.01719

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.47455
Value Function Update Magnitude: 0.45050

Collected Steps per Second: 20,453.88635
Overall Steps per Second: 9,940.98025

Timestep Collection Time: 2.44511
Timestep Consumption Time: 2.58578
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 5.03089

Cumulative Model Updates: 163,614
Cumulative Timesteps: 1,364,363,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1364363110...
Checkpoint 1364363110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,258.13638
Policy Entropy: 3.73111
Value Function Loss: 0.01668

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.48916
Value Function Update Magnitude: 0.45072

Collected Steps per Second: 19,730.59826
Overall Steps per Second: 9,966.72413

Timestep Collection Time: 2.53566
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 5.01970

Cumulative Model Updates: 163,620
Cumulative Timesteps: 1,364,413,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,258.13638
Policy Entropy: 3.72904
Value Function Loss: 0.01551

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12228
Policy Update Magnitude: 0.48250
Value Function Update Magnitude: 0.40350

Collected Steps per Second: 19,870.84270
Overall Steps per Second: 9,927.01000

Timestep Collection Time: 2.51705
Timestep Consumption Time: 2.52132
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 5.03838

Cumulative Model Updates: 163,626
Cumulative Timesteps: 1,364,463,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1364463156...
Checkpoint 1364463156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,177.96013
Policy Entropy: 3.72517
Value Function Loss: 0.01728

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.49007
Value Function Update Magnitude: 0.39912

Collected Steps per Second: 19,919.22537
Overall Steps per Second: 9,853.57850

Timestep Collection Time: 2.51064
Timestep Consumption Time: 2.56467
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 5.07531

Cumulative Model Updates: 163,632
Cumulative Timesteps: 1,364,513,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,552.88419
Policy Entropy: 3.74692
Value Function Loss: 0.01886

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.54117
Value Function Update Magnitude: 0.54158

Collected Steps per Second: 20,401.82957
Overall Steps per Second: 9,990.67683

Timestep Collection Time: 2.45174
Timestep Consumption Time: 2.55493
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 5.00667

Cumulative Model Updates: 163,638
Cumulative Timesteps: 1,364,563,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1364563186...
Checkpoint 1364563186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,799.19017
Policy Entropy: 3.73696
Value Function Loss: 0.02168

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.58255

Collected Steps per Second: 20,229.56471
Overall Steps per Second: 9,990.74707

Timestep Collection Time: 2.47262
Timestep Consumption Time: 2.53401
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 5.00663

Cumulative Model Updates: 163,644
Cumulative Timesteps: 1,364,613,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,735.57777
Policy Entropy: 3.75241
Value Function Loss: 0.02089

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.56687
Value Function Update Magnitude: 0.67070

Collected Steps per Second: 20,452.25089
Overall Steps per Second: 9,901.82727

Timestep Collection Time: 2.44550
Timestep Consumption Time: 2.60569
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 5.05119

Cumulative Model Updates: 163,650
Cumulative Timesteps: 1,364,663,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1364663222...
Checkpoint 1364663222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,304.71097
Policy Entropy: 3.72949
Value Function Loss: 0.02138

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.78569

Collected Steps per Second: 20,283.58505
Overall Steps per Second: 9,976.48491

Timestep Collection Time: 2.46663
Timestep Consumption Time: 2.54837
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 5.01499

Cumulative Model Updates: 163,656
Cumulative Timesteps: 1,364,713,254

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,229.51276
Policy Entropy: 3.73983
Value Function Loss: 0.01981

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.50671
Value Function Update Magnitude: 0.68127

Collected Steps per Second: 20,537.43101
Overall Steps per Second: 9,964.26355

Timestep Collection Time: 2.43565
Timestep Consumption Time: 2.58449
PPO Batch Consumption Time: 0.29877
Total Iteration Time: 5.02014

Cumulative Model Updates: 163,662
Cumulative Timesteps: 1,364,763,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1364763276...
Checkpoint 1364763276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,004.21899
Policy Entropy: 3.74627
Value Function Loss: 0.01857

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.48485
Value Function Update Magnitude: 0.53968

Collected Steps per Second: 20,529.74864
Overall Steps per Second: 10,057.77124

Timestep Collection Time: 2.43588
Timestep Consumption Time: 2.53620
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.97208

Cumulative Model Updates: 163,668
Cumulative Timesteps: 1,364,813,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,841.59753
Policy Entropy: 3.75253
Value Function Loss: 0.01753

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.46418
Value Function Update Magnitude: 0.49133

Collected Steps per Second: 20,392.46963
Overall Steps per Second: 10,019.58488

Timestep Collection Time: 2.45296
Timestep Consumption Time: 2.53946
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.99242

Cumulative Model Updates: 163,674
Cumulative Timesteps: 1,364,863,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1364863306...
Checkpoint 1364863306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,547.92605
Policy Entropy: 3.75313
Value Function Loss: 0.01767

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.49489
Value Function Update Magnitude: 0.52049

Collected Steps per Second: 20,316.26896
Overall Steps per Second: 9,987.55080

Timestep Collection Time: 2.46197
Timestep Consumption Time: 2.54607
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 5.00803

Cumulative Model Updates: 163,680
Cumulative Timesteps: 1,364,913,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,437.27230
Policy Entropy: 3.75300
Value Function Loss: 0.01807

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.48462
Value Function Update Magnitude: 0.51798

Collected Steps per Second: 20,560.39428
Overall Steps per Second: 9,923.72163

Timestep Collection Time: 2.43254
Timestep Consumption Time: 2.60730
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 5.03984

Cumulative Model Updates: 163,686
Cumulative Timesteps: 1,364,963,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1364963338...
Checkpoint 1364963338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,153.36546
Policy Entropy: 3.76489
Value Function Loss: 0.01736

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.44744
Value Function Update Magnitude: 0.51188

Collected Steps per Second: 20,641.96682
Overall Steps per Second: 10,157.32560

Timestep Collection Time: 2.42225
Timestep Consumption Time: 2.50031
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.92256

Cumulative Model Updates: 163,692
Cumulative Timesteps: 1,365,013,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,869.98731
Policy Entropy: 3.75779
Value Function Loss: 0.01620

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.42577
Value Function Update Magnitude: 0.50945

Collected Steps per Second: 20,650.55012
Overall Steps per Second: 10,119.20326

Timestep Collection Time: 2.42241
Timestep Consumption Time: 2.52107
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.94347

Cumulative Model Updates: 163,698
Cumulative Timesteps: 1,365,063,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1365063362...
Checkpoint 1365063362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,346.67319
Policy Entropy: 3.74849
Value Function Loss: 0.01624

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.42438
Value Function Update Magnitude: 0.56156

Collected Steps per Second: 20,405.69582
Overall Steps per Second: 9,972.74406

Timestep Collection Time: 2.45069
Timestep Consumption Time: 2.56378
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 5.01447

Cumulative Model Updates: 163,704
Cumulative Timesteps: 1,365,113,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,545.82562
Policy Entropy: 3.74684
Value Function Loss: 0.01790

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.45653
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 20,298.49274
Overall Steps per Second: 9,900.67472

Timestep Collection Time: 2.46531
Timestep Consumption Time: 2.58910
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 5.05440

Cumulative Model Updates: 163,710
Cumulative Timesteps: 1,365,163,412

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1365163412...
Checkpoint 1365163412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,951.85372
Policy Entropy: 3.74873
Value Function Loss: 0.01861

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.49354
Value Function Update Magnitude: 0.71977

Collected Steps per Second: 20,031.91104
Overall Steps per Second: 9,831.26108

Timestep Collection Time: 2.49682
Timestep Consumption Time: 2.59063
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 5.08745

Cumulative Model Updates: 163,716
Cumulative Timesteps: 1,365,213,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,737.67269
Policy Entropy: 3.76299
Value Function Loss: 0.01880

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.70795

Collected Steps per Second: 20,129.50421
Overall Steps per Second: 9,939.10214

Timestep Collection Time: 2.48511
Timestep Consumption Time: 2.54794
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 5.03305

Cumulative Model Updates: 163,722
Cumulative Timesteps: 1,365,263,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1365263452...
Checkpoint 1365263452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,193.94267
Policy Entropy: 3.77267
Value Function Loss: 0.01860

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12008
Policy Update Magnitude: 0.47599
Value Function Update Magnitude: 0.64060

Collected Steps per Second: 20,149.82018
Overall Steps per Second: 9,847.48292

Timestep Collection Time: 2.48260
Timestep Consumption Time: 2.59727
PPO Batch Consumption Time: 0.30385
Total Iteration Time: 5.07988

Cumulative Model Updates: 163,728
Cumulative Timesteps: 1,365,313,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,083.83503
Policy Entropy: 3.76908
Value Function Loss: 0.01988

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.48747
Value Function Update Magnitude: 0.56018

Collected Steps per Second: 20,119.73289
Overall Steps per Second: 9,862.84536

Timestep Collection Time: 2.48602
Timestep Consumption Time: 2.58534
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 5.07136

Cumulative Model Updates: 163,734
Cumulative Timesteps: 1,365,363,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1365363494...
Checkpoint 1365363494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,992.15948
Policy Entropy: 3.77544
Value Function Loss: 0.01898

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.47209
Value Function Update Magnitude: 0.66566

Collected Steps per Second: 20,699.38586
Overall Steps per Second: 10,055.93337

Timestep Collection Time: 2.41688
Timestep Consumption Time: 2.55809
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.97497

Cumulative Model Updates: 163,740
Cumulative Timesteps: 1,365,413,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,960.74829
Policy Entropy: 3.76147
Value Function Loss: 0.01969

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.46287
Value Function Update Magnitude: 0.63834

Collected Steps per Second: 20,250.95437
Overall Steps per Second: 10,004.75187

Timestep Collection Time: 2.46912
Timestep Consumption Time: 2.52871
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.99783

Cumulative Model Updates: 163,746
Cumulative Timesteps: 1,365,463,524

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1365463524...
Checkpoint 1365463524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,053.87714
Policy Entropy: 3.76826
Value Function Loss: 0.01805

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.46630
Value Function Update Magnitude: 0.61134

Collected Steps per Second: 20,459.65892
Overall Steps per Second: 10,005.02531

Timestep Collection Time: 2.44510
Timestep Consumption Time: 2.55498
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 5.00009

Cumulative Model Updates: 163,752
Cumulative Timesteps: 1,365,513,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,974.91101
Policy Entropy: 3.77723
Value Function Loss: 0.01718

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.48047
Value Function Update Magnitude: 0.61915

Collected Steps per Second: 20,507.16927
Overall Steps per Second: 9,995.87985

Timestep Collection Time: 2.43885
Timestep Consumption Time: 2.56461
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 5.00346

Cumulative Model Updates: 163,758
Cumulative Timesteps: 1,365,563,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1365563564...
Checkpoint 1365563564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242,457.20891
Policy Entropy: 3.76350
Value Function Loss: 0.01961

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.51838
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 20,608.66895
Overall Steps per Second: 10,095.47692

Timestep Collection Time: 2.42704
Timestep Consumption Time: 2.52746
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.95450

Cumulative Model Updates: 163,764
Cumulative Timesteps: 1,365,613,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,749.13028
Policy Entropy: 3.77109
Value Function Loss: 0.02010

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 20,037.10230
Overall Steps per Second: 10,046.23579

Timestep Collection Time: 2.49537
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.97699

Cumulative Model Updates: 163,770
Cumulative Timesteps: 1,365,663,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1365663582...
Checkpoint 1365663582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,165.09034
Policy Entropy: 3.76156
Value Function Loss: 0.02345

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.67080

Collected Steps per Second: 19,781.16767
Overall Steps per Second: 9,944.44069

Timestep Collection Time: 2.52847
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 5.02954

Cumulative Model Updates: 163,776
Cumulative Timesteps: 1,365,713,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,579.76083
Policy Entropy: 3.76984
Value Function Loss: 0.02137

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.59212
Value Function Update Magnitude: 0.71919

Collected Steps per Second: 19,949.97387
Overall Steps per Second: 9,982.37724

Timestep Collection Time: 2.50677
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 5.00983

Cumulative Model Updates: 163,782
Cumulative Timesteps: 1,365,763,608

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1365763608...
Checkpoint 1365763608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,776.99187
Policy Entropy: 3.74730
Value Function Loss: 0.02256

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 19,968.88769
Overall Steps per Second: 10,049.34926

Timestep Collection Time: 2.50480
Timestep Consumption Time: 2.47244
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.97724

Cumulative Model Updates: 163,788
Cumulative Timesteps: 1,365,813,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,243.05043
Policy Entropy: 3.75501
Value Function Loss: 0.02065

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.54042

Collected Steps per Second: 20,089.16711
Overall Steps per Second: 10,058.07532

Timestep Collection Time: 2.49000
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.97332

Cumulative Model Updates: 163,794
Cumulative Timesteps: 1,365,863,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1365863648...
Checkpoint 1365863648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,161.49401
Policy Entropy: 3.76710
Value Function Loss: 0.01836

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.49950
Value Function Update Magnitude: 0.63653

Collected Steps per Second: 20,121.81385
Overall Steps per Second: 9,925.99165

Timestep Collection Time: 2.48576
Timestep Consumption Time: 2.55333
PPO Batch Consumption Time: 0.29847
Total Iteration Time: 5.03909

Cumulative Model Updates: 163,800
Cumulative Timesteps: 1,365,913,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,026.07480
Policy Entropy: 3.76597
Value Function Loss: 0.01585

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.45318
Value Function Update Magnitude: 0.56335

Collected Steps per Second: 19,920.02357
Overall Steps per Second: 9,903.92135

Timestep Collection Time: 2.51064
Timestep Consumption Time: 2.53908
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 5.04972

Cumulative Model Updates: 163,806
Cumulative Timesteps: 1,365,963,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1365963678...
Checkpoint 1365963678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,026.07480
Policy Entropy: 3.75436
Value Function Loss: 0.01369

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.41185
Value Function Update Magnitude: 0.48110

Collected Steps per Second: 20,712.14928
Overall Steps per Second: 10,034.63051

Timestep Collection Time: 2.41501
Timestep Consumption Time: 2.56973
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.98474

Cumulative Model Updates: 163,812
Cumulative Timesteps: 1,366,013,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,026.07480
Policy Entropy: 3.72455
Value Function Loss: 0.01461

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.43008
Value Function Update Magnitude: 0.47701

Collected Steps per Second: 20,612.50360
Overall Steps per Second: 9,975.21431

Timestep Collection Time: 2.42697
Timestep Consumption Time: 2.58806
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 5.01503

Cumulative Model Updates: 163,818
Cumulative Timesteps: 1,366,063,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1366063724...
Checkpoint 1366063724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 318,851.66543
Policy Entropy: 3.73656
Value Function Loss: 0.01493

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.48390
Value Function Update Magnitude: 0.53300

Collected Steps per Second: 20,240.39812
Overall Steps per Second: 9,948.80500

Timestep Collection Time: 2.47159
Timestep Consumption Time: 2.55675
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 5.02834

Cumulative Model Updates: 163,824
Cumulative Timesteps: 1,366,113,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,135.17977
Policy Entropy: 3.74403
Value Function Loss: 0.01667

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.50808
Value Function Update Magnitude: 0.65695

Collected Steps per Second: 20,639.22087
Overall Steps per Second: 9,995.07280

Timestep Collection Time: 2.42364
Timestep Consumption Time: 2.58103
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 5.00467

Cumulative Model Updates: 163,830
Cumulative Timesteps: 1,366,163,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1366163772...
Checkpoint 1366163772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,058.63878
Policy Entropy: 3.78895
Value Function Loss: 0.02028

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.53049
Value Function Update Magnitude: 0.67554

Collected Steps per Second: 20,609.07645
Overall Steps per Second: 10,025.47455

Timestep Collection Time: 2.42718
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.98949

Cumulative Model Updates: 163,836
Cumulative Timesteps: 1,366,213,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,481.44761
Policy Entropy: 3.78319
Value Function Loss: 0.02031

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.54638
Value Function Update Magnitude: 0.70312

Collected Steps per Second: 20,611.89651
Overall Steps per Second: 10,097.53507

Timestep Collection Time: 2.42617
Timestep Consumption Time: 2.52632
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.95250

Cumulative Model Updates: 163,842
Cumulative Timesteps: 1,366,263,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1366263802...
Checkpoint 1366263802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,423.58999
Policy Entropy: 3.78120
Value Function Loss: 0.01912

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.68005

Collected Steps per Second: 19,653.36032
Overall Steps per Second: 9,946.38738

Timestep Collection Time: 2.54409
Timestep Consumption Time: 2.48286
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 5.02695

Cumulative Model Updates: 163,848
Cumulative Timesteps: 1,366,313,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,423.58999
Policy Entropy: 3.75989
Value Function Loss: 0.01535

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.51999
Value Function Update Magnitude: 0.65902

Collected Steps per Second: 19,801.39947
Overall Steps per Second: 9,890.28176

Timestep Collection Time: 2.52669
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 5.05870

Cumulative Model Updates: 163,854
Cumulative Timesteps: 1,366,363,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1366363834...
Checkpoint 1366363834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,423.58999
Policy Entropy: 3.74481
Value Function Loss: 0.01512

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.44969
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 19,635.76870
Overall Steps per Second: 9,921.38490

Timestep Collection Time: 2.54648
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 5.03982

Cumulative Model Updates: 163,860
Cumulative Timesteps: 1,366,413,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,183.58625
Policy Entropy: 3.74858
Value Function Loss: 0.01394

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14696
Policy Update Magnitude: 0.42766
Value Function Update Magnitude: 0.53408

Collected Steps per Second: 20,151.44878
Overall Steps per Second: 9,966.10493

Timestep Collection Time: 2.48310
Timestep Consumption Time: 2.53772
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 5.02082

Cumulative Model Updates: 163,866
Cumulative Timesteps: 1,366,463,874

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1366463874...
Checkpoint 1366463874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,280.12531
Policy Entropy: 3.74949
Value Function Loss: 0.01702

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.40519
Value Function Update Magnitude: 0.53589

Collected Steps per Second: 20,211.93641
Overall Steps per Second: 9,970.78773

Timestep Collection Time: 2.47468
Timestep Consumption Time: 2.54178
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 5.01645

Cumulative Model Updates: 163,872
Cumulative Timesteps: 1,366,513,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,136.24393
Policy Entropy: 3.76313
Value Function Loss: 0.01798

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.50972
Value Function Update Magnitude: 0.64004

Collected Steps per Second: 20,411.64894
Overall Steps per Second: 9,886.64818

Timestep Collection Time: 2.44968
Timestep Consumption Time: 2.60785
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 5.05753

Cumulative Model Updates: 163,878
Cumulative Timesteps: 1,366,563,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1366563894...
Checkpoint 1366563894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,595.65360
Policy Entropy: 3.76980
Value Function Loss: 0.02402

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.67661

Collected Steps per Second: 20,080.12621
Overall Steps per Second: 9,879.64549

Timestep Collection Time: 2.49102
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 5.06293

Cumulative Model Updates: 163,884
Cumulative Timesteps: 1,366,613,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,608.18597
Policy Entropy: 3.79789
Value Function Loss: 0.02393

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.62976
Value Function Update Magnitude: 0.79245

Collected Steps per Second: 20,261.94961
Overall Steps per Second: 9,929.98058

Timestep Collection Time: 2.46886
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 5.03767

Cumulative Model Updates: 163,890
Cumulative Timesteps: 1,366,663,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1366663938...
Checkpoint 1366663938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,402.61348
Policy Entropy: 3.81323
Value Function Loss: 0.02696

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.62253
Value Function Update Magnitude: 0.86573

Collected Steps per Second: 20,256.69416
Overall Steps per Second: 9,858.87633

Timestep Collection Time: 2.46881
Timestep Consumption Time: 2.60377
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 5.07259

Cumulative Model Updates: 163,896
Cumulative Timesteps: 1,366,713,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,367.64233
Policy Entropy: 3.83066
Value Function Loss: 0.02399

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.60774
Value Function Update Magnitude: 0.83021

Collected Steps per Second: 20,660.98203
Overall Steps per Second: 10,027.40332

Timestep Collection Time: 2.42041
Timestep Consumption Time: 2.56673
PPO Batch Consumption Time: 0.29825
Total Iteration Time: 4.98713

Cumulative Model Updates: 163,902
Cumulative Timesteps: 1,366,763,956

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1366763956...
Checkpoint 1366763956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,170.11769
Policy Entropy: 3.80102
Value Function Loss: 0.03095

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.73778

Collected Steps per Second: 20,553.40372
Overall Steps per Second: 10,123.49396

Timestep Collection Time: 2.43405
Timestep Consumption Time: 2.50772
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.94177

Cumulative Model Updates: 163,908
Cumulative Timesteps: 1,366,813,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,105.95691
Policy Entropy: 3.79893
Value Function Loss: 0.02642

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.66568

Collected Steps per Second: 20,661.05633
Overall Steps per Second: 10,127.66847

Timestep Collection Time: 2.42117
Timestep Consumption Time: 2.51817
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.93934

Cumulative Model Updates: 163,914
Cumulative Timesteps: 1,366,864,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1366864008...
Checkpoint 1366864008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,027.11926
Policy Entropy: 3.77491
Value Function Loss: 0.02846

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.60799
Value Function Update Magnitude: 0.63498

Collected Steps per Second: 20,516.68158
Overall Steps per Second: 9,985.74087

Timestep Collection Time: 2.43802
Timestep Consumption Time: 2.57113
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 5.00914

Cumulative Model Updates: 163,920
Cumulative Timesteps: 1,366,914,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,937.40233
Policy Entropy: 3.78655
Value Function Loss: 0.02252

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12250
Policy Update Magnitude: 0.54985
Value Function Update Magnitude: 0.57292

Collected Steps per Second: 20,436.14793
Overall Steps per Second: 9,933.17566

Timestep Collection Time: 2.44762
Timestep Consumption Time: 2.58803
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 5.03565

Cumulative Model Updates: 163,926
Cumulative Timesteps: 1,366,964,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1366964048...
Checkpoint 1366964048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,479.84126
Policy Entropy: 3.76853
Value Function Loss: 0.02154

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.50822
Value Function Update Magnitude: 0.52298

Collected Steps per Second: 20,266.60134
Overall Steps per Second: 9,872.82611

Timestep Collection Time: 2.46721
Timestep Consumption Time: 2.59740
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 5.06461

Cumulative Model Updates: 163,932
Cumulative Timesteps: 1,367,014,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,134.62772
Policy Entropy: 3.77469
Value Function Loss: 0.01660

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.45454
Value Function Update Magnitude: 0.42729

Collected Steps per Second: 20,704.27307
Overall Steps per Second: 10,013.36229

Timestep Collection Time: 2.41622
Timestep Consumption Time: 2.57971
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.99592

Cumulative Model Updates: 163,938
Cumulative Timesteps: 1,367,064,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1367064076...
Checkpoint 1367064076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,401.07767
Policy Entropy: 3.76288
Value Function Loss: 0.01530

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.42178
Value Function Update Magnitude: 0.37100

Collected Steps per Second: 20,564.04931
Overall Steps per Second: 10,125.43199

Timestep Collection Time: 2.43221
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.93964

Cumulative Model Updates: 163,944
Cumulative Timesteps: 1,367,114,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,168.34280
Policy Entropy: 3.77456
Value Function Loss: 0.01503

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.41538
Value Function Update Magnitude: 0.37514

Collected Steps per Second: 20,109.98169
Overall Steps per Second: 9,899.26504

Timestep Collection Time: 2.48712
Timestep Consumption Time: 2.56537
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 5.05250

Cumulative Model Updates: 163,950
Cumulative Timesteps: 1,367,164,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1367164108...
Checkpoint 1367164108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,500.06953
Policy Entropy: 3.78346
Value Function Loss: 0.01554

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.42580
Value Function Update Magnitude: 0.47788

Collected Steps per Second: 20,699.31170
Overall Steps per Second: 9,984.76447

Timestep Collection Time: 2.41573
Timestep Consumption Time: 2.59230
PPO Batch Consumption Time: 0.30051
Total Iteration Time: 5.00803

Cumulative Model Updates: 163,956
Cumulative Timesteps: 1,367,214,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,123.55551
Policy Entropy: 3.79323
Value Function Loss: 0.01502

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.42044
Value Function Update Magnitude: 0.59113

Collected Steps per Second: 20,724.87595
Overall Steps per Second: 10,030.78561

Timestep Collection Time: 2.41352
Timestep Consumption Time: 2.57312
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.98665

Cumulative Model Updates: 163,962
Cumulative Timesteps: 1,367,264,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1367264132...
Checkpoint 1367264132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,329.21274
Policy Entropy: 3.78993
Value Function Loss: 0.01468

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.42259
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 20,582.34735
Overall Steps per Second: 10,105.37793

Timestep Collection Time: 2.43014
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.94964

Cumulative Model Updates: 163,968
Cumulative Timesteps: 1,367,314,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,809.67552
Policy Entropy: 3.78243
Value Function Loss: 0.01536

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.40101
Value Function Update Magnitude: 0.61904

Collected Steps per Second: 20,761.39534
Overall Steps per Second: 10,124.18349

Timestep Collection Time: 2.40899
Timestep Consumption Time: 2.53106
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.94005

Cumulative Model Updates: 163,974
Cumulative Timesteps: 1,367,364,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1367364164...
Checkpoint 1367364164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,256.50393
Policy Entropy: 3.76903
Value Function Loss: 0.01626

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.41663
Value Function Update Magnitude: 0.62498

Collected Steps per Second: 20,468.77078
Overall Steps per Second: 9,965.24596

Timestep Collection Time: 2.44362
Timestep Consumption Time: 2.57562
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 5.01924

Cumulative Model Updates: 163,980
Cumulative Timesteps: 1,367,414,182

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,224.12363
Policy Entropy: 3.75962
Value Function Loss: 0.01650

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.43594
Value Function Update Magnitude: 0.56536

Collected Steps per Second: 20,489.77142
Overall Steps per Second: 9,906.00193

Timestep Collection Time: 2.44063
Timestep Consumption Time: 2.60762
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 5.04825

Cumulative Model Updates: 163,986
Cumulative Timesteps: 1,367,464,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1367464190...
Checkpoint 1367464190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342,841.50113
Policy Entropy: 3.76371
Value Function Loss: 0.01838

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.44530
Value Function Update Magnitude: 0.52985

Collected Steps per Second: 20,372.21535
Overall Steps per Second: 9,874.33150

Timestep Collection Time: 2.45491
Timestep Consumption Time: 2.60994
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 5.06485

Cumulative Model Updates: 163,992
Cumulative Timesteps: 1,367,514,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,578.29408
Policy Entropy: 3.78484
Value Function Loss: 0.01812

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.48955
Value Function Update Magnitude: 0.65468

Collected Steps per Second: 20,200.93732
Overall Steps per Second: 10,001.61114

Timestep Collection Time: 2.47563
Timestep Consumption Time: 2.52457
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 5.00019

Cumulative Model Updates: 163,998
Cumulative Timesteps: 1,367,564,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1367564212...
Checkpoint 1367564212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,292.24845
Policy Entropy: 3.79735
Value Function Loss: 0.01949

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.52640
Value Function Update Magnitude: 0.73080

Collected Steps per Second: 20,578.32618
Overall Steps per Second: 10,094.84271

Timestep Collection Time: 2.43032
Timestep Consumption Time: 2.52389
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.95421

Cumulative Model Updates: 164,004
Cumulative Timesteps: 1,367,614,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,789.50798
Policy Entropy: 3.79718
Value Function Loss: 0.01879

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.51605
Value Function Update Magnitude: 0.78644

Collected Steps per Second: 19,969.79025
Overall Steps per Second: 9,844.62881

Timestep Collection Time: 2.50528
Timestep Consumption Time: 2.57667
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 5.08196

Cumulative Model Updates: 164,010
Cumulative Timesteps: 1,367,664,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1367664254...
Checkpoint 1367664254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,116.82379
Policy Entropy: 3.78869
Value Function Loss: 0.01806

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.76695

Collected Steps per Second: 20,188.56385
Overall Steps per Second: 10,039.50095

Timestep Collection Time: 2.47715
Timestep Consumption Time: 2.50418
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.98132

Cumulative Model Updates: 164,016
Cumulative Timesteps: 1,367,714,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.75539
Policy Entropy: 3.78725
Value Function Loss: 0.01695

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.47331
Value Function Update Magnitude: 0.68563

Collected Steps per Second: 20,267.07527
Overall Steps per Second: 9,929.35869

Timestep Collection Time: 2.46775
Timestep Consumption Time: 2.56924
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 5.03698

Cumulative Model Updates: 164,022
Cumulative Timesteps: 1,367,764,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1367764278...
Checkpoint 1367764278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,474.97482
Policy Entropy: 3.78042
Value Function Loss: 0.01644

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.47045
Value Function Update Magnitude: 0.59052

Collected Steps per Second: 20,455.51206
Overall Steps per Second: 10,028.21576

Timestep Collection Time: 2.44482
Timestep Consumption Time: 2.54211
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.98693

Cumulative Model Updates: 164,028
Cumulative Timesteps: 1,367,814,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,243.33040
Policy Entropy: 3.76764
Value Function Loss: 0.01573

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.49280
Value Function Update Magnitude: 0.55854

Collected Steps per Second: 19,439.88331
Overall Steps per Second: 9,728.62279

Timestep Collection Time: 2.57203
Timestep Consumption Time: 2.56744
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 5.13947

Cumulative Model Updates: 164,034
Cumulative Timesteps: 1,367,864,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1367864288...
Checkpoint 1367864288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,120.42449
Policy Entropy: 3.76528
Value Function Loss: 0.01847

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.48198
Value Function Update Magnitude: 0.53068

Collected Steps per Second: 20,494.93208
Overall Steps per Second: 10,111.75047

Timestep Collection Time: 2.44031
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.94613

Cumulative Model Updates: 164,040
Cumulative Timesteps: 1,367,914,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,111.15314
Policy Entropy: 3.78600
Value Function Loss: 0.02003

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.45855
Value Function Update Magnitude: 0.57369

Collected Steps per Second: 19,729.96975
Overall Steps per Second: 10,032.77409

Timestep Collection Time: 2.53533
Timestep Consumption Time: 2.45053
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.98586

Cumulative Model Updates: 164,046
Cumulative Timesteps: 1,367,964,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1367964324...
Checkpoint 1367964324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,125.84782
Policy Entropy: 3.76142
Value Function Loss: 0.02226

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14097
Policy Update Magnitude: 0.47479
Value Function Update Magnitude: 0.70355

Collected Steps per Second: 19,875.80384
Overall Steps per Second: 10,102.12944

Timestep Collection Time: 2.51713
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.95242

Cumulative Model Updates: 164,052
Cumulative Timesteps: 1,368,014,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,427.05579
Policy Entropy: 3.75684
Value Function Loss: 0.02078

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.49503
Value Function Update Magnitude: 0.73418

Collected Steps per Second: 19,953.05080
Overall Steps per Second: 10,076.28319

Timestep Collection Time: 2.50628
Timestep Consumption Time: 2.45666
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.96294

Cumulative Model Updates: 164,058
Cumulative Timesteps: 1,368,064,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1368064362...
Checkpoint 1368064362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,577.63267
Policy Entropy: 3.74180
Value Function Loss: 0.02039

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.51495
Value Function Update Magnitude: 0.56930

Collected Steps per Second: 19,646.21886
Overall Steps per Second: 9,945.19628

Timestep Collection Time: 2.54685
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 5.03117

Cumulative Model Updates: 164,064
Cumulative Timesteps: 1,368,114,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,711.49855
Policy Entropy: 3.76482
Value Function Loss: 0.01753

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.50920

Collected Steps per Second: 20,588.14059
Overall Steps per Second: 9,986.04191

Timestep Collection Time: 2.42858
Timestep Consumption Time: 2.57841
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.00699

Cumulative Model Updates: 164,070
Cumulative Timesteps: 1,368,164,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1368164398...
Checkpoint 1368164398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,621.33981
Policy Entropy: 3.77461
Value Function Loss: 0.01951

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.48458
Value Function Update Magnitude: 0.45853

Collected Steps per Second: 20,515.16478
Overall Steps per Second: 9,964.08488

Timestep Collection Time: 2.43868
Timestep Consumption Time: 2.58235
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 5.02103

Cumulative Model Updates: 164,076
Cumulative Timesteps: 1,368,214,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,945.67998
Policy Entropy: 3.80586
Value Function Loss: 0.02096

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.54539

Collected Steps per Second: 20,718.91229
Overall Steps per Second: 10,073.11649

Timestep Collection Time: 2.41422
Timestep Consumption Time: 2.55147
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.96569

Cumulative Model Updates: 164,082
Cumulative Timesteps: 1,368,264,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1368264448...
Checkpoint 1368264448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,642.12002
Policy Entropy: 3.82439
Value Function Loss: 0.02202

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07355
Policy Update Magnitude: 0.67182
Value Function Update Magnitude: 0.64603

Collected Steps per Second: 20,775.19373
Overall Steps per Second: 10,041.85115

Timestep Collection Time: 2.40710
Timestep Consumption Time: 2.57286
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.97996

Cumulative Model Updates: 164,088
Cumulative Timesteps: 1,368,314,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,448.91640
Policy Entropy: 3.81660
Value Function Loss: 0.01892

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.71264
Value Function Update Magnitude: 0.75355

Collected Steps per Second: 20,328.07133
Overall Steps per Second: 10,027.06000

Timestep Collection Time: 2.46192
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.99109

Cumulative Model Updates: 164,094
Cumulative Timesteps: 1,368,364,502

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1368364502...
Checkpoint 1368364502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,097.63355
Policy Entropy: 3.79708
Value Function Loss: 0.01816

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.76592

Collected Steps per Second: 20,239.81752
Overall Steps per Second: 9,750.11154

Timestep Collection Time: 2.47166
Timestep Consumption Time: 2.65915
PPO Batch Consumption Time: 0.31023
Total Iteration Time: 5.13081

Cumulative Model Updates: 164,100
Cumulative Timesteps: 1,368,414,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,607.78635
Policy Entropy: 3.77158
Value Function Loss: 0.02113

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.70966

Collected Steps per Second: 20,171.82724
Overall Steps per Second: 10,024.60662

Timestep Collection Time: 2.47880
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.98793

Cumulative Model Updates: 164,106
Cumulative Timesteps: 1,368,464,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1368464530...
Checkpoint 1368464530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,838.46643
Policy Entropy: 3.79265
Value Function Loss: 0.02432

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.69336

Collected Steps per Second: 20,266.32065
Overall Steps per Second: 9,930.62048

Timestep Collection Time: 2.46774
Timestep Consumption Time: 2.56840
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 5.03614

Cumulative Model Updates: 164,112
Cumulative Timesteps: 1,368,514,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,706.06472
Policy Entropy: 3.80029
Value Function Loss: 0.02644

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.59949
Value Function Update Magnitude: 0.68376

Collected Steps per Second: 20,032.80441
Overall Steps per Second: 9,922.74795

Timestep Collection Time: 2.49601
Timestep Consumption Time: 2.54312
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 5.03913

Cumulative Model Updates: 164,118
Cumulative Timesteps: 1,368,564,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1368564544...
Checkpoint 1368564544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,968.27868
Policy Entropy: 3.82920
Value Function Loss: 0.02594

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.57261
Value Function Update Magnitude: 0.59842

Collected Steps per Second: 20,225.89941
Overall Steps per Second: 9,875.22952

Timestep Collection Time: 2.47297
Timestep Consumption Time: 2.59203
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 5.06500

Cumulative Model Updates: 164,124
Cumulative Timesteps: 1,368,614,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,046.13895
Policy Entropy: 3.81670
Value Function Loss: 0.02256

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.52637
Value Function Update Magnitude: 0.67694

Collected Steps per Second: 20,092.96370
Overall Steps per Second: 9,984.97004

Timestep Collection Time: 2.48923
Timestep Consumption Time: 2.51990
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 5.00913

Cumulative Model Updates: 164,130
Cumulative Timesteps: 1,368,664,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1368664578...
Checkpoint 1368664578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.58353
Policy Entropy: 3.82844
Value Function Loss: 0.02064

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.51154
Value Function Update Magnitude: 0.74619

Collected Steps per Second: 20,449.95710
Overall Steps per Second: 9,955.63151

Timestep Collection Time: 2.44626
Timestep Consumption Time: 2.57863
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 5.02489

Cumulative Model Updates: 164,136
Cumulative Timesteps: 1,368,714,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,629.64903
Policy Entropy: 3.82469
Value Function Loss: 0.02357

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.53380
Value Function Update Magnitude: 0.80554

Collected Steps per Second: 20,360.49458
Overall Steps per Second: 9,971.56294

Timestep Collection Time: 2.45633
Timestep Consumption Time: 2.55914
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 5.01546

Cumulative Model Updates: 164,142
Cumulative Timesteps: 1,368,764,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1368764616...
Checkpoint 1368764616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.59525
Policy Entropy: 3.85429
Value Function Loss: 0.02212

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.88268

Collected Steps per Second: 20,053.09970
Overall Steps per Second: 9,887.24270

Timestep Collection Time: 2.49448
Timestep Consumption Time: 2.56477
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 5.05925

Cumulative Model Updates: 164,148
Cumulative Timesteps: 1,368,814,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.92386
Policy Entropy: 3.84818
Value Function Loss: 0.02179

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.59890
Value Function Update Magnitude: 0.88276

Collected Steps per Second: 20,425.90128
Overall Steps per Second: 9,983.55648

Timestep Collection Time: 2.44787
Timestep Consumption Time: 2.56036
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 5.00824

Cumulative Model Updates: 164,154
Cumulative Timesteps: 1,368,864,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1368864638...
Checkpoint 1368864638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.86400
Policy Entropy: 3.82953
Value Function Loss: 0.02121

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.84371

Collected Steps per Second: 20,548.99092
Overall Steps per Second: 9,970.65270

Timestep Collection Time: 2.43525
Timestep Consumption Time: 2.58368
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 5.01893

Cumulative Model Updates: 164,160
Cumulative Timesteps: 1,368,914,680

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.70789
Policy Entropy: 3.81715
Value Function Loss: 0.02273

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.54705
Value Function Update Magnitude: 0.73122

Collected Steps per Second: 20,578.48810
Overall Steps per Second: 9,939.67093

Timestep Collection Time: 2.43099
Timestep Consumption Time: 2.60198
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 5.03296

Cumulative Model Updates: 164,166
Cumulative Timesteps: 1,368,964,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1368964706...
Checkpoint 1368964706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,237.07754
Policy Entropy: 3.82989
Value Function Loss: 0.02689

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12187
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.76498

Collected Steps per Second: 20,551.29257
Overall Steps per Second: 10,079.26386

Timestep Collection Time: 2.43352
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.96187

Cumulative Model Updates: 164,172
Cumulative Timesteps: 1,369,014,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,978.98461
Policy Entropy: 3.86522
Value Function Loss: 0.02710

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.60430
Value Function Update Magnitude: 0.78301

Collected Steps per Second: 20,141.54401
Overall Steps per Second: 9,837.69243

Timestep Collection Time: 2.48372
Timestep Consumption Time: 2.60141
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 5.08514

Cumulative Model Updates: 164,178
Cumulative Timesteps: 1,369,064,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1369064744...
Checkpoint 1369064744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,288.69887
Policy Entropy: 3.85513
Value Function Loss: 0.02834

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.60270
Value Function Update Magnitude: 0.76349

Collected Steps per Second: 20,464.47601
Overall Steps per Second: 10,074.07454

Timestep Collection Time: 2.44404
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.96482

Cumulative Model Updates: 164,184
Cumulative Timesteps: 1,369,114,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.17557
Policy Entropy: 3.83877
Value Function Loss: 0.02344

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.57556
Value Function Update Magnitude: 0.84342

Collected Steps per Second: 19,893.04298
Overall Steps per Second: 9,797.26711

Timestep Collection Time: 2.51475
Timestep Consumption Time: 2.59137
PPO Batch Consumption Time: 0.29917
Total Iteration Time: 5.10612

Cumulative Model Updates: 164,190
Cumulative Timesteps: 1,369,164,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1369164786...
Checkpoint 1369164786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222.08092
Policy Entropy: 3.81471
Value Function Loss: 0.02212

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.53285
Value Function Update Magnitude: 0.85456

Collected Steps per Second: 20,718.23061
Overall Steps per Second: 10,142.82992

Timestep Collection Time: 2.41449
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.93196

Cumulative Model Updates: 164,196
Cumulative Timesteps: 1,369,214,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,303.70636
Policy Entropy: 3.79582
Value Function Loss: 0.01948

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.84032

Collected Steps per Second: 20,425.11839
Overall Steps per Second: 10,023.33109

Timestep Collection Time: 2.44992
Timestep Consumption Time: 2.54243
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.99235

Cumulative Model Updates: 164,202
Cumulative Timesteps: 1,369,264,850

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1369264850...
Checkpoint 1369264850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,196.42189
Policy Entropy: 3.78597
Value Function Loss: 0.01971

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.57078
Value Function Update Magnitude: 0.81477

Collected Steps per Second: 20,434.80395
Overall Steps per Second: 9,989.06145

Timestep Collection Time: 2.44700
Timestep Consumption Time: 2.55887
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 5.00588

Cumulative Model Updates: 164,208
Cumulative Timesteps: 1,369,314,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,749.32756
Policy Entropy: 3.77864
Value Function Loss: 0.01983

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.51850
Value Function Update Magnitude: 0.80155

Collected Steps per Second: 20,179.28218
Overall Steps per Second: 9,876.53131

Timestep Collection Time: 2.47838
Timestep Consumption Time: 2.58534
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 5.06372

Cumulative Model Updates: 164,214
Cumulative Timesteps: 1,369,364,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1369364866...
Checkpoint 1369364866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,255.92496
Policy Entropy: 3.78669
Value Function Loss: 0.02168

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.48733
Value Function Update Magnitude: 0.87317

Collected Steps per Second: 20,534.72756
Overall Steps per Second: 10,126.14362

Timestep Collection Time: 2.43500
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.93791

Cumulative Model Updates: 164,220
Cumulative Timesteps: 1,369,414,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,950.88688
Policy Entropy: 3.79611
Value Function Loss: 0.02382

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.51814
Value Function Update Magnitude: 0.94761

Collected Steps per Second: 20,299.43142
Overall Steps per Second: 10,073.65755

Timestep Collection Time: 2.46440
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.96602

Cumulative Model Updates: 164,226
Cumulative Timesteps: 1,369,464,894

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1369464894...
Checkpoint 1369464894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,091.85253
Policy Entropy: 3.80901
Value Function Loss: 0.02390

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.54589
Value Function Update Magnitude: 0.88713

Collected Steps per Second: 20,634.20681
Overall Steps per Second: 9,995.44244

Timestep Collection Time: 2.42335
Timestep Consumption Time: 2.57933
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 5.00268

Cumulative Model Updates: 164,232
Cumulative Timesteps: 1,369,514,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,359.59109
Policy Entropy: 3.80120
Value Function Loss: 0.02278

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.52511
Value Function Update Magnitude: 0.81232

Collected Steps per Second: 20,370.80467
Overall Steps per Second: 9,930.53429

Timestep Collection Time: 2.45606
Timestep Consumption Time: 2.58213
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 5.03820

Cumulative Model Updates: 164,238
Cumulative Timesteps: 1,369,564,930

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1369564930...
Checkpoint 1369564930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,438.87230
Policy Entropy: 3.78020
Value Function Loss: 0.02304

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.52488
Value Function Update Magnitude: 0.70855

Collected Steps per Second: 20,521.46937
Overall Steps per Second: 10,033.79569

Timestep Collection Time: 2.43696
Timestep Consumption Time: 2.54720
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.98416

Cumulative Model Updates: 164,244
Cumulative Timesteps: 1,369,614,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,627.27236
Policy Entropy: 3.78578
Value Function Loss: 0.02139

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.59430

Collected Steps per Second: 19,791.64969
Overall Steps per Second: 9,836.10341

Timestep Collection Time: 2.52793
Timestep Consumption Time: 2.55863
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 5.08657

Cumulative Model Updates: 164,250
Cumulative Timesteps: 1,369,664,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1369664972...
Checkpoint 1369664972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.60000
Policy Entropy: 3.77834
Value Function Loss: 0.02058

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.59569
Value Function Update Magnitude: 0.58599

Collected Steps per Second: 20,434.73819
Overall Steps per Second: 9,990.95473

Timestep Collection Time: 2.44799
Timestep Consumption Time: 2.55894
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 5.00693

Cumulative Model Updates: 164,256
Cumulative Timesteps: 1,369,714,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,231.33159
Policy Entropy: 3.78342
Value Function Loss: 0.02220

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16560
Policy Update Magnitude: 0.52836
Value Function Update Magnitude: 0.50181

Collected Steps per Second: 20,380.44973
Overall Steps per Second: 9,917.97460

Timestep Collection Time: 2.45353
Timestep Consumption Time: 2.58823
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 5.04176

Cumulative Model Updates: 164,262
Cumulative Timesteps: 1,369,765,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1369765000...
Checkpoint 1369765000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,010.34578
Policy Entropy: 3.78759
Value Function Loss: 0.02295

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.58950
Value Function Update Magnitude: 0.51857

Collected Steps per Second: 20,203.13803
Overall Steps per Second: 9,895.84554

Timestep Collection Time: 2.47595
Timestep Consumption Time: 2.57890
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 5.05485

Cumulative Model Updates: 164,268
Cumulative Timesteps: 1,369,815,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,461.02494
Policy Entropy: 3.78480
Value Function Loss: 0.02075

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.11580
Policy Update Magnitude: 0.68426
Value Function Update Magnitude: 0.52263

Collected Steps per Second: 20,219.56343
Overall Steps per Second: 9,868.73653

Timestep Collection Time: 2.47285
Timestep Consumption Time: 2.59365
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 5.06650

Cumulative Model Updates: 164,274
Cumulative Timesteps: 1,369,865,022

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1369865022...
Checkpoint 1369865022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,285.73059
Policy Entropy: 3.80306
Value Function Loss: 0.01801

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06608
Policy Update Magnitude: 0.65567
Value Function Update Magnitude: 0.51990

Collected Steps per Second: 20,285.70563
Overall Steps per Second: 9,892.87101

Timestep Collection Time: 2.46578
Timestep Consumption Time: 2.59039
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 5.05617

Cumulative Model Updates: 164,280
Cumulative Timesteps: 1,369,915,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,121.53294
Policy Entropy: 3.79189
Value Function Loss: 0.01661

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07560
Policy Update Magnitude: 0.63111
Value Function Update Magnitude: 0.52633

Collected Steps per Second: 20,151.18546
Overall Steps per Second: 9,944.85394

Timestep Collection Time: 2.48204
Timestep Consumption Time: 2.54730
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 5.02933

Cumulative Model Updates: 164,286
Cumulative Timesteps: 1,369,965,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1369965058...
Checkpoint 1369965058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.15096
Policy Entropy: 3.81406
Value Function Loss: 0.01573

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07545
Policy Update Magnitude: 0.59247
Value Function Update Magnitude: 0.42408

Collected Steps per Second: 20,652.98419
Overall Steps per Second: 9,940.05515

Timestep Collection Time: 2.42135
Timestep Consumption Time: 2.60961
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 5.03096

Cumulative Model Updates: 164,292
Cumulative Timesteps: 1,370,015,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.15096
Policy Entropy: 3.78016
Value Function Loss: 0.01524

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.38178

Collected Steps per Second: 20,050.89442
Overall Steps per Second: 9,998.68301

Timestep Collection Time: 2.49485
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 5.00306

Cumulative Model Updates: 164,298
Cumulative Timesteps: 1,370,065,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1370065090...
Checkpoint 1370065090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,438.15096
Policy Entropy: 3.75899
Value Function Loss: 0.01414

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15952
Policy Update Magnitude: 0.48704
Value Function Update Magnitude: 0.38960

Collected Steps per Second: 20,180.72699
Overall Steps per Second: 9,892.32614

Timestep Collection Time: 2.47900
Timestep Consumption Time: 2.57825
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 5.05725

Cumulative Model Updates: 164,304
Cumulative Timesteps: 1,370,115,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,619.96772
Policy Entropy: 3.73671
Value Function Loss: 0.01416

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17755
Policy Update Magnitude: 0.42257
Value Function Update Magnitude: 0.37893

Collected Steps per Second: 20,478.18033
Overall Steps per Second: 9,918.17447

Timestep Collection Time: 2.44299
Timestep Consumption Time: 2.60108
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 5.04407

Cumulative Model Updates: 164,310
Cumulative Timesteps: 1,370,165,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1370165146...
Checkpoint 1370165146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,540.06211
Policy Entropy: 3.78902
Value Function Loss: 0.01381

Mean KL Divergence: 0.01602
SB3 Clip Fraction: 0.19475
Policy Update Magnitude: 0.38425
Value Function Update Magnitude: 0.36251

Collected Steps per Second: 20,327.77108
Overall Steps per Second: 9,923.57588

Timestep Collection Time: 2.46008
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 5.03931

Cumulative Model Updates: 164,316
Cumulative Timesteps: 1,370,215,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,842.45701
Policy Entropy: 3.79379
Value Function Loss: 0.01541

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.20268
Policy Update Magnitude: 0.35060
Value Function Update Magnitude: 0.49472

Collected Steps per Second: 20,543.38729
Overall Steps per Second: 9,925.17695

Timestep Collection Time: 2.43563
Timestep Consumption Time: 2.60570
PPO Batch Consumption Time: 0.30390
Total Iteration Time: 5.04132

Cumulative Model Updates: 164,322
Cumulative Timesteps: 1,370,265,190

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1370265190...
Checkpoint 1370265190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304,148.55063
Policy Entropy: 3.79787
Value Function Loss: 0.01627

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.16523
Policy Update Magnitude: 0.41945
Value Function Update Magnitude: 0.64660

Collected Steps per Second: 19,655.09597
Overall Steps per Second: 9,881.76257

Timestep Collection Time: 2.54509
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 5.06225

Cumulative Model Updates: 164,328
Cumulative Timesteps: 1,370,315,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,589.10842
Policy Entropy: 3.76271
Value Function Loss: 0.01787

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15866
Policy Update Magnitude: 0.46869
Value Function Update Magnitude: 0.73800

Collected Steps per Second: 19,638.62650
Overall Steps per Second: 10,046.06748

Timestep Collection Time: 2.54651
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.97807

Cumulative Model Updates: 164,334
Cumulative Timesteps: 1,370,365,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1370365224...
Checkpoint 1370365224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,176.24110
Policy Entropy: 3.73754
Value Function Loss: 0.02009

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.52125
Value Function Update Magnitude: 0.76855

Collected Steps per Second: 19,667.42647
Overall Steps per Second: 10,045.81437

Timestep Collection Time: 2.54299
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.97859

Cumulative Model Updates: 164,340
Cumulative Timesteps: 1,370,415,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,238.63056
Policy Entropy: 3.74942
Value Function Loss: 0.02033

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.67595
Value Function Update Magnitude: 0.73551

Collected Steps per Second: 19,589.27241
Overall Steps per Second: 9,786.63366

Timestep Collection Time: 2.55283
Timestep Consumption Time: 2.55700
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 5.10983

Cumulative Model Updates: 164,346
Cumulative Timesteps: 1,370,465,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1370465246...
Checkpoint 1370465246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,359.66335
Policy Entropy: 3.75550
Value Function Loss: 0.02037

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07573
Policy Update Magnitude: 0.75615
Value Function Update Magnitude: 0.51282

Collected Steps per Second: 20,177.42418
Overall Steps per Second: 9,939.78541

Timestep Collection Time: 2.47901
Timestep Consumption Time: 2.55329
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 5.03230

Cumulative Model Updates: 164,352
Cumulative Timesteps: 1,370,515,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,447.64968
Policy Entropy: 3.76004
Value Function Loss: 0.02111

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.18663
Policy Update Magnitude: 0.67523
Value Function Update Magnitude: 0.44410

Collected Steps per Second: 20,257.68701
Overall Steps per Second: 9,965.35242

Timestep Collection Time: 2.46869
Timestep Consumption Time: 2.54970
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 5.01839

Cumulative Model Updates: 164,358
Cumulative Timesteps: 1,370,565,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1370565276...
Checkpoint 1370565276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,479.99361
Policy Entropy: 3.82625
Value Function Loss: 0.03676

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.19963
Policy Update Magnitude: 0.68022
Value Function Update Magnitude: 0.49523

Collected Steps per Second: 20,350.68366
Overall Steps per Second: 10,079.60408

Timestep Collection Time: 2.45741
Timestep Consumption Time: 2.50409
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.96150

Cumulative Model Updates: 164,364
Cumulative Timesteps: 1,370,615,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.10600
Policy Entropy: 3.93646
Value Function Loss: 0.04166

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 1.07994
Value Function Update Magnitude: 0.75933

Collected Steps per Second: 20,018.99996
Overall Steps per Second: 10,029.76604

Timestep Collection Time: 2.49843
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.98676

Cumulative Model Updates: 164,370
Cumulative Timesteps: 1,370,665,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1370665302...
Checkpoint 1370665302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,547.37253
Policy Entropy: 4.04272
Value Function Loss: 0.04194

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 1.13714
Value Function Update Magnitude: 0.81015

Collected Steps per Second: 20,387.53099
Overall Steps per Second: 10,244.34780

Timestep Collection Time: 2.45385
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.88347

Cumulative Model Updates: 164,376
Cumulative Timesteps: 1,370,715,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,891.28502
Policy Entropy: 4.07572
Value Function Loss: 0.03553

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 1.17362
Value Function Update Magnitude: 1.01686

Collected Steps per Second: 20,231.56009
Overall Steps per Second: 9,979.55215

Timestep Collection Time: 2.47267
Timestep Consumption Time: 2.54018
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 5.01285

Cumulative Model Updates: 164,382
Cumulative Timesteps: 1,370,765,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1370765356...
Checkpoint 1370765356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.97251
Policy Entropy: 4.06794
Value Function Loss: 0.03252

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08775
Policy Update Magnitude: 1.15620
Value Function Update Magnitude: 1.06912

Collected Steps per Second: 21,056.06192
Overall Steps per Second: 10,137.49286

Timestep Collection Time: 2.37509
Timestep Consumption Time: 2.55808
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.93317

Cumulative Model Updates: 164,388
Cumulative Timesteps: 1,370,815,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,703.27061
Policy Entropy: 4.02508
Value Function Loss: 0.03253

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 1.07441
Value Function Update Magnitude: 1.07749

Collected Steps per Second: 20,790.25155
Overall Steps per Second: 10,023.28947

Timestep Collection Time: 2.40545
Timestep Consumption Time: 2.58393
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.98938

Cumulative Model Updates: 164,394
Cumulative Timesteps: 1,370,865,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1370865376...
Checkpoint 1370865376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.25024
Policy Entropy: 4.03682
Value Function Loss: 0.03013

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06777
Policy Update Magnitude: 0.94598
Value Function Update Magnitude: 0.95062

Collected Steps per Second: 20,333.50031
Overall Steps per Second: 10,086.00513

Timestep Collection Time: 2.45949
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.95836

Cumulative Model Updates: 164,400
Cumulative Timesteps: 1,370,915,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,338.84748
Policy Entropy: 4.00822
Value Function Loss: 0.03330

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.07201
Policy Update Magnitude: 0.86225
Value Function Update Magnitude: 0.77345

Collected Steps per Second: 20,600.12624
Overall Steps per Second: 9,967.07541

Timestep Collection Time: 2.42785
Timestep Consumption Time: 2.59007
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 5.01792

Cumulative Model Updates: 164,406
Cumulative Timesteps: 1,370,965,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1370965400...
Checkpoint 1370965400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.61818
Policy Entropy: 4.01781
Value Function Loss: 0.03164

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.07143
Policy Update Magnitude: 0.85666
Value Function Update Magnitude: 0.79106

Collected Steps per Second: 20,808.53328
Overall Steps per Second: 10,165.72940

Timestep Collection Time: 2.40305
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.91888

Cumulative Model Updates: 164,412
Cumulative Timesteps: 1,371,015,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.10440
Policy Entropy: 3.97629
Value Function Loss: 0.03100

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.80907
Value Function Update Magnitude: 0.89781

Collected Steps per Second: 20,357.01214
Overall Steps per Second: 10,106.42094

Timestep Collection Time: 2.45675
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.94854

Cumulative Model Updates: 164,418
Cumulative Timesteps: 1,371,065,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1371065416...
Checkpoint 1371065416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,687.50455
Policy Entropy: 3.95140
Value Function Loss: 0.02690

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.19171
Policy Update Magnitude: 0.64924
Value Function Update Magnitude: 0.86310

Collected Steps per Second: 20,777.80113
Overall Steps per Second: 10,165.44450

Timestep Collection Time: 2.40776
Timestep Consumption Time: 2.51362
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.92138

Cumulative Model Updates: 164,424
Cumulative Timesteps: 1,371,115,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.35116
Policy Entropy: 3.89639
Value Function Loss: 0.02893

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.21914
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.83418

Collected Steps per Second: 20,296.28995
Overall Steps per Second: 10,018.20222

Timestep Collection Time: 2.46370
Timestep Consumption Time: 2.52761
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.99131

Cumulative Model Updates: 164,430
Cumulative Timesteps: 1,371,165,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1371165448...
Checkpoint 1371165448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.94439
Policy Entropy: 3.89777
Value Function Loss: 0.03003

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.21047
Policy Update Magnitude: 0.45095
Value Function Update Magnitude: 0.89573

Collected Steps per Second: 20,317.92615
Overall Steps per Second: 9,822.55564

Timestep Collection Time: 2.46206
Timestep Consumption Time: 2.63071
PPO Batch Consumption Time: 0.30339
Total Iteration Time: 5.09277

Cumulative Model Updates: 164,436
Cumulative Timesteps: 1,371,215,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,545.54343
Policy Entropy: 3.90485
Value Function Loss: 0.04079

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.19544
Policy Update Magnitude: 0.42663
Value Function Update Magnitude: 0.73690

Collected Steps per Second: 20,453.33886
Overall Steps per Second: 10,115.38983

Timestep Collection Time: 2.44547
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.94474

Cumulative Model Updates: 164,442
Cumulative Timesteps: 1,371,265,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1371265490...
Checkpoint 1371265490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,911.35674
Policy Entropy: 4.00928
Value Function Loss: 0.03887

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.49464
Value Function Update Magnitude: 0.54129

Collected Steps per Second: 20,759.81022
Overall Steps per Second: 10,255.93407

Timestep Collection Time: 2.40908
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.87640

Cumulative Model Updates: 164,448
Cumulative Timesteps: 1,371,315,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.97168
Policy Entropy: 4.09775
Value Function Loss: 0.03535

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09580
Policy Update Magnitude: 0.61317
Value Function Update Magnitude: 0.58911

Collected Steps per Second: 20,457.03187
Overall Steps per Second: 9,924.48391

Timestep Collection Time: 2.44483
Timestep Consumption Time: 2.59462
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 5.03946

Cumulative Model Updates: 164,454
Cumulative Timesteps: 1,371,365,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1371365516...
Checkpoint 1371365516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195.19925
Policy Entropy: 4.18710
Value Function Loss: 0.02791

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06715
Policy Update Magnitude: 0.76223
Value Function Update Magnitude: 0.84071

Collected Steps per Second: 20,901.37700
Overall Steps per Second: 10,197.74436

Timestep Collection Time: 2.39286
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.90442

Cumulative Model Updates: 164,460
Cumulative Timesteps: 1,371,415,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.89495
Policy Entropy: 4.22461
Value Function Loss: 0.02526

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.04970
Policy Update Magnitude: 0.82840
Value Function Update Magnitude: 0.83639

Collected Steps per Second: 20,608.53198
Overall Steps per Second: 10,155.19532

Timestep Collection Time: 2.42637
Timestep Consumption Time: 2.49761
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.92398

Cumulative Model Updates: 164,466
Cumulative Timesteps: 1,371,465,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1371465534...
Checkpoint 1371465534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,349.21197
Policy Entropy: 4.21325
Value Function Loss: 0.02477

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.86107
Value Function Update Magnitude: 0.86515

Collected Steps per Second: 20,347.28500
Overall Steps per Second: 10,195.77456

Timestep Collection Time: 2.45880
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.90693

Cumulative Model Updates: 164,472
Cumulative Timesteps: 1,371,515,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.00078
Policy Entropy: 4.16113
Value Function Loss: 0.02759

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04746
Policy Update Magnitude: 0.87387
Value Function Update Magnitude: 0.92104

Collected Steps per Second: 20,746.24776
Overall Steps per Second: 10,048.50644

Timestep Collection Time: 2.41104
Timestep Consumption Time: 2.56682
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.97785

Cumulative Model Updates: 164,478
Cumulative Timesteps: 1,371,565,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1371565584...
Checkpoint 1371565584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,076.35717
Policy Entropy: 4.10632
Value Function Loss: 0.03029

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.87329
Value Function Update Magnitude: 0.91786

Collected Steps per Second: 20,827.80105
Overall Steps per Second: 10,183.66490

Timestep Collection Time: 2.40294
Timestep Consumption Time: 2.51160
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.91454

Cumulative Model Updates: 164,484
Cumulative Timesteps: 1,371,615,632

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.51499
Policy Entropy: 4.05869
Value Function Loss: 0.03076

Mean KL Divergence: 0.00609
SB3 Clip Fraction: 0.07979
Policy Update Magnitude: 0.81491
Value Function Update Magnitude: 0.89424

Collected Steps per Second: 20,797.51039
Overall Steps per Second: 10,126.18886

Timestep Collection Time: 2.40500
Timestep Consumption Time: 2.53447
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.93947

Cumulative Model Updates: 164,490
Cumulative Timesteps: 1,371,665,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1371665650...
Checkpoint 1371665650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.82951
Policy Entropy: 4.00652
Value Function Loss: 0.03158

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.68513
Value Function Update Magnitude: 0.84645

Collected Steps per Second: 20,523.27753
Overall Steps per Second: 10,115.68656

Timestep Collection Time: 2.43752
Timestep Consumption Time: 2.50786
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.94539

Cumulative Model Updates: 164,496
Cumulative Timesteps: 1,371,715,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.36441
Policy Entropy: 3.96587
Value Function Loss: 0.03481

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.61811
Value Function Update Magnitude: 0.84301

Collected Steps per Second: 20,717.53543
Overall Steps per Second: 10,120.38691

Timestep Collection Time: 2.41399
Timestep Consumption Time: 2.52771
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.94171

Cumulative Model Updates: 164,502
Cumulative Timesteps: 1,371,765,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1371765688...
Checkpoint 1371765688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,336.63709
Policy Entropy: 3.95774
Value Function Loss: 0.03637

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.86306

Collected Steps per Second: 20,553.73026
Overall Steps per Second: 10,139.81832

Timestep Collection Time: 2.43352
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.93283

Cumulative Model Updates: 164,508
Cumulative Timesteps: 1,371,815,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,787.83938
Policy Entropy: 3.97388
Value Function Loss: 0.03534

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06748
Policy Update Magnitude: 0.70555
Value Function Update Magnitude: 0.86963

Collected Steps per Second: 20,780.72571
Overall Steps per Second: 10,130.88292

Timestep Collection Time: 2.40733
Timestep Consumption Time: 2.53064
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.93797

Cumulative Model Updates: 164,514
Cumulative Timesteps: 1,371,865,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1371865732...
Checkpoint 1371865732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,055.72031
Policy Entropy: 3.96495
Value Function Loss: 0.03028

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05759
Policy Update Magnitude: 0.78146
Value Function Update Magnitude: 0.85941

Collected Steps per Second: 20,600.84239
Overall Steps per Second: 10,154.20875

Timestep Collection Time: 2.42835
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.92663

Cumulative Model Updates: 164,520
Cumulative Timesteps: 1,371,915,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,245.16685
Policy Entropy: 3.93769
Value Function Loss: 0.02689

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05905
Policy Update Magnitude: 0.74035
Value Function Update Magnitude: 0.78071

Collected Steps per Second: 20,405.36882
Overall Steps per Second: 10,053.90940

Timestep Collection Time: 2.45092
Timestep Consumption Time: 2.52346
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.97438

Cumulative Model Updates: 164,526
Cumulative Timesteps: 1,371,965,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1371965770...
Checkpoint 1371965770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,706.06478
Policy Entropy: 3.91017
Value Function Loss: 0.02751

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.70051
Value Function Update Magnitude: 0.74179

Collected Steps per Second: 20,457.46996
Overall Steps per Second: 9,987.25249

Timestep Collection Time: 2.44517
Timestep Consumption Time: 2.56341
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 5.00858

Cumulative Model Updates: 164,532
Cumulative Timesteps: 1,372,015,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.69623
Policy Entropy: 3.90966
Value Function Loss: 0.02748

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07866
Policy Update Magnitude: 0.64805
Value Function Update Magnitude: 0.71387

Collected Steps per Second: 20,593.65357
Overall Steps per Second: 10,055.34157

Timestep Collection Time: 2.42871
Timestep Consumption Time: 2.54536
PPO Batch Consumption Time: 0.29770
Total Iteration Time: 4.97407

Cumulative Model Updates: 164,538
Cumulative Timesteps: 1,372,065,808

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1372065808...
Checkpoint 1372065808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,200.18996
Policy Entropy: 3.90189
Value Function Loss: 0.03148

Mean KL Divergence: 0.02577
SB3 Clip Fraction: 0.25428
Policy Update Magnitude: 0.51989
Value Function Update Magnitude: 0.72797

Collected Steps per Second: 20,535.78935
Overall Steps per Second: 9,949.22576

Timestep Collection Time: 2.43487
Timestep Consumption Time: 2.59085
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 5.02572

Cumulative Model Updates: 164,544
Cumulative Timesteps: 1,372,115,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.27469
Policy Entropy: 3.90949
Value Function Loss: 0.03140

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.45152
Value Function Update Magnitude: 0.69082

Collected Steps per Second: 20,775.38453
Overall Steps per Second: 10,075.60673

Timestep Collection Time: 2.40766
Timestep Consumption Time: 2.55681
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.96447

Cumulative Model Updates: 164,550
Cumulative Timesteps: 1,372,165,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1372165830...
Checkpoint 1372165830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,809.67981
Policy Entropy: 3.90970
Value Function Loss: 0.03484

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.57497

Collected Steps per Second: 20,054.37120
Overall Steps per Second: 9,874.49936

Timestep Collection Time: 2.49382
Timestep Consumption Time: 2.57094
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 5.06476

Cumulative Model Updates: 164,556
Cumulative Timesteps: 1,372,215,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,942.30762
Policy Entropy: 3.88900
Value Function Loss: 0.03936

Mean KL Divergence: 0.02238
SB3 Clip Fraction: 0.20662
Policy Update Magnitude: 0.56893
Value Function Update Magnitude: 0.44944

Collected Steps per Second: 20,281.83722
Overall Steps per Second: 10,125.33955

Timestep Collection Time: 2.46526
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.93811

Cumulative Model Updates: 164,562
Cumulative Timesteps: 1,372,265,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372265842...
Checkpoint 1372265842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,187.29237
Policy Entropy: 3.90542
Value Function Loss: 0.03932

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.72942
Value Function Update Magnitude: 0.44761

Collected Steps per Second: 20,374.77962
Overall Steps per Second: 10,130.22618

Timestep Collection Time: 2.45519
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.93809

Cumulative Model Updates: 164,568
Cumulative Timesteps: 1,372,315,866

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.85243
Policy Entropy: 3.89739
Value Function Loss: 0.03923

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.77292
Value Function Update Magnitude: 0.53319

Collected Steps per Second: 20,491.85366
Overall Steps per Second: 10,012.86264

Timestep Collection Time: 2.44058
Timestep Consumption Time: 2.55420
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.99478

Cumulative Model Updates: 164,574
Cumulative Timesteps: 1,372,365,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1372365878...
Checkpoint 1372365878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.42900
Policy Entropy: 3.90672
Value Function Loss: 0.03527

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.75046
Value Function Update Magnitude: 0.55397

Collected Steps per Second: 20,885.97694
Overall Steps per Second: 10,199.90796

Timestep Collection Time: 2.39405
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.90220

Cumulative Model Updates: 164,580
Cumulative Timesteps: 1,372,415,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,888.40550
Policy Entropy: 3.88315
Value Function Loss: 0.03097

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07397
Policy Update Magnitude: 0.69695
Value Function Update Magnitude: 0.60536

Collected Steps per Second: 20,041.12638
Overall Steps per Second: 10,006.68459

Timestep Collection Time: 2.49587
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.99866

Cumulative Model Updates: 164,586
Cumulative Timesteps: 1,372,465,900

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1372465900...
Checkpoint 1372465900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.24299
Policy Entropy: 3.86699
Value Function Loss: 0.02565

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.59059
Value Function Update Magnitude: 0.63258

Collected Steps per Second: 20,497.83861
Overall Steps per Second: 10,036.71775

Timestep Collection Time: 2.43987
Timestep Consumption Time: 2.54304
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.98290

Cumulative Model Updates: 164,592
Cumulative Timesteps: 1,372,515,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.97030
Policy Entropy: 3.84509
Value Function Loss: 0.02210

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.49166
Value Function Update Magnitude: 0.55959

Collected Steps per Second: 20,263.41631
Overall Steps per Second: 9,951.94381

Timestep Collection Time: 2.46987
Timestep Consumption Time: 2.55910
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 5.02897

Cumulative Model Updates: 164,598
Cumulative Timesteps: 1,372,565,960

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1372565960...
Checkpoint 1372565960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,437.13599
Policy Entropy: 3.84314
Value Function Loss: 0.01879

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.50208
Value Function Update Magnitude: 0.53948

Collected Steps per Second: 20,563.60794
Overall Steps per Second: 10,087.45553

Timestep Collection Time: 2.43274
Timestep Consumption Time: 2.52648
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.95923

Cumulative Model Updates: 164,604
Cumulative Timesteps: 1,372,615,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,233.27543
Policy Entropy: 3.82928
Value Function Loss: 0.02638

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11955
Policy Update Magnitude: 0.51486
Value Function Update Magnitude: 0.51495

Collected Steps per Second: 20,306.43908
Overall Steps per Second: 10,038.91701

Timestep Collection Time: 2.46296
Timestep Consumption Time: 2.51905
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.98201

Cumulative Model Updates: 164,610
Cumulative Timesteps: 1,372,666,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1372666000...
Checkpoint 1372666000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.27055
Policy Entropy: 3.85904
Value Function Loss: 0.03085

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.67326
Value Function Update Magnitude: 0.52079

Collected Steps per Second: 20,469.90169
Overall Steps per Second: 10,050.04387

Timestep Collection Time: 2.44359
Timestep Consumption Time: 2.53350
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.97709

Cumulative Model Updates: 164,616
Cumulative Timesteps: 1,372,716,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.36086
Policy Entropy: 3.87097
Value Function Loss: 0.03654

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.70541
Value Function Update Magnitude: 0.49445

Collected Steps per Second: 20,398.09491
Overall Steps per Second: 9,927.80305

Timestep Collection Time: 2.45141
Timestep Consumption Time: 2.58536
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 5.03676

Cumulative Model Updates: 164,622
Cumulative Timesteps: 1,372,766,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1372766024...
Checkpoint 1372766024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,551.74727
Policy Entropy: 3.91710
Value Function Loss: 0.04143

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.66631
Value Function Update Magnitude: 0.48697

Collected Steps per Second: 20,494.72534
Overall Steps per Second: 10,142.46860

Timestep Collection Time: 2.43975
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.92996

Cumulative Model Updates: 164,628
Cumulative Timesteps: 1,372,816,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.45751
Policy Entropy: 3.95011
Value Function Loss: 0.04155

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.71577
Value Function Update Magnitude: 0.54926

Collected Steps per Second: 20,585.95280
Overall Steps per Second: 10,069.03856

Timestep Collection Time: 2.42884
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29987
Total Iteration Time: 4.96572

Cumulative Model Updates: 164,634
Cumulative Timesteps: 1,372,866,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1372866026...
Checkpoint 1372866026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,965.68315
Policy Entropy: 4.03104
Value Function Loss: 0.04221

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.85692
Value Function Update Magnitude: 0.67123

Collected Steps per Second: 20,048.58760
Overall Steps per Second: 10,141.24001

Timestep Collection Time: 2.49434
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.93115

Cumulative Model Updates: 164,640
Cumulative Timesteps: 1,372,916,034

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193.76959
Policy Entropy: 4.06942
Value Function Loss: 0.03750

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.90396
Value Function Update Magnitude: 0.70375

Collected Steps per Second: 19,962.70393
Overall Steps per Second: 9,873.66884

Timestep Collection Time: 2.50557
Timestep Consumption Time: 2.56022
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 5.06580

Cumulative Model Updates: 164,646
Cumulative Timesteps: 1,372,966,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1372966052...
Checkpoint 1372966052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.76309
Policy Entropy: 4.06632
Value Function Loss: 0.03658

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08035
Policy Update Magnitude: 0.88436
Value Function Update Magnitude: 0.65459

Collected Steps per Second: 20,703.26697
Overall Steps per Second: 9,974.99789

Timestep Collection Time: 2.41575
Timestep Consumption Time: 2.59818
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 5.01394

Cumulative Model Updates: 164,652
Cumulative Timesteps: 1,373,016,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 416.80663
Policy Entropy: 4.02722
Value Function Loss: 0.03808

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.79719
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 20,476.80331
Overall Steps per Second: 10,068.59244

Timestep Collection Time: 2.44276
Timestep Consumption Time: 2.52516
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.96792

Cumulative Model Updates: 164,658
Cumulative Timesteps: 1,373,066,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1373066086...
Checkpoint 1373066086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.62341
Policy Entropy: 3.98426
Value Function Loss: 0.03660

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.76043
Value Function Update Magnitude: 0.56779

Collected Steps per Second: 20,742.24586
Overall Steps per Second: 10,053.52753

Timestep Collection Time: 2.41073
Timestep Consumption Time: 2.56304
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.97378

Cumulative Model Updates: 164,664
Cumulative Timesteps: 1,373,116,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230.06485
Policy Entropy: 3.93487
Value Function Loss: 0.03131

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07339
Policy Update Magnitude: 0.72689
Value Function Update Magnitude: 0.57556

Collected Steps per Second: 20,381.72095
Overall Steps per Second: 9,918.47299

Timestep Collection Time: 2.45347
Timestep Consumption Time: 2.58823
PPO Batch Consumption Time: 0.29970
Total Iteration Time: 5.04170

Cumulative Model Updates: 164,670
Cumulative Timesteps: 1,373,166,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1373166096...
Checkpoint 1373166096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,939.20900
Policy Entropy: 3.88749
Value Function Loss: 0.02587

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.63347
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 20,331.21429
Overall Steps per Second: 10,073.33799

Timestep Collection Time: 2.45957
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.96419

Cumulative Model Updates: 164,676
Cumulative Timesteps: 1,373,216,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.28540
Policy Entropy: 3.82975
Value Function Loss: 0.02417

Mean KL Divergence: 0.02229
SB3 Clip Fraction: 0.24782
Policy Update Magnitude: 0.46639
Value Function Update Magnitude: 0.61933

Collected Steps per Second: 20,297.47454
Overall Steps per Second: 10,081.72792

Timestep Collection Time: 2.46523
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.96324

Cumulative Model Updates: 164,682
Cumulative Timesteps: 1,373,266,140

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1373266140...
Checkpoint 1373266140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,663.40372
Policy Entropy: 3.86072
Value Function Loss: 0.02985

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.20329
Policy Update Magnitude: 0.37967
Value Function Update Magnitude: 0.54397

Collected Steps per Second: 20,269.81106
Overall Steps per Second: 9,968.46866

Timestep Collection Time: 2.46751
Timestep Consumption Time: 2.54991
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.01742

Cumulative Model Updates: 164,688
Cumulative Timesteps: 1,373,316,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,188.26566
Policy Entropy: 3.88067
Value Function Loss: 0.03917

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.16098
Policy Update Magnitude: 0.42808
Value Function Update Magnitude: 0.46262

Collected Steps per Second: 20,471.92000
Overall Steps per Second: 9,877.88988

Timestep Collection Time: 2.44315
Timestep Consumption Time: 2.62028
PPO Batch Consumption Time: 0.30972
Total Iteration Time: 5.06343

Cumulative Model Updates: 164,694
Cumulative Timesteps: 1,373,366,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1373366172...
Checkpoint 1373366172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.63713
Policy Entropy: 3.89767
Value Function Loss: 0.04342

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.17399
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.46672

Collected Steps per Second: 20,530.02661
Overall Steps per Second: 10,049.40297

Timestep Collection Time: 2.43575
Timestep Consumption Time: 2.54027
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.97602

Cumulative Model Updates: 164,700
Cumulative Timesteps: 1,373,416,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,233.98107
Policy Entropy: 3.90963
Value Function Loss: 0.04529

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.16574
Policy Update Magnitude: 0.51084
Value Function Update Magnitude: 0.47155

Collected Steps per Second: 20,710.02192
Overall Steps per Second: 10,206.15582

Timestep Collection Time: 2.41448
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.89940

Cumulative Model Updates: 164,706
Cumulative Timesteps: 1,373,466,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1373466182...
Checkpoint 1373466182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,963.82435
Policy Entropy: 3.91017
Value Function Loss: 0.04581

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.47641
Value Function Update Magnitude: 0.44045

Collected Steps per Second: 20,516.74170
Overall Steps per Second: 10,020.07139

Timestep Collection Time: 2.43830
Timestep Consumption Time: 2.55428
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.99258

Cumulative Model Updates: 164,712
Cumulative Timesteps: 1,373,516,208

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.57255
Policy Entropy: 3.92277
Value Function Loss: 0.04215

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.48142
Value Function Update Magnitude: 0.48598

Collected Steps per Second: 19,676.58124
Overall Steps per Second: 9,902.39041

Timestep Collection Time: 2.54170
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29918
Total Iteration Time: 5.05050

Cumulative Model Updates: 164,718
Cumulative Timesteps: 1,373,566,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1373566220...
Checkpoint 1373566220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.53289
Policy Entropy: 3.94037
Value Function Loss: 0.03818

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.51976
Value Function Update Magnitude: 0.52615

Collected Steps per Second: 19,684.59934
Overall Steps per Second: 9,900.99774

Timestep Collection Time: 2.54097
Timestep Consumption Time: 2.51084
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 5.05181

Cumulative Model Updates: 164,724
Cumulative Timesteps: 1,373,616,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,553.53032
Policy Entropy: 3.97287
Value Function Loss: 0.03463

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 20,431.56536
Overall Steps per Second: 9,971.23643

Timestep Collection Time: 2.44876
Timestep Consumption Time: 2.56887
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 5.01763

Cumulative Model Updates: 164,730
Cumulative Timesteps: 1,373,666,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1373666270...
Checkpoint 1373666270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,151.03090
Policy Entropy: 3.99167
Value Function Loss: 0.03564

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 20,678.80739
Overall Steps per Second: 9,982.55936

Timestep Collection Time: 2.41842
Timestep Consumption Time: 2.59132
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 5.00974

Cumulative Model Updates: 164,736
Cumulative Timesteps: 1,373,716,280

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,021.80259
Policy Entropy: 4.01250
Value Function Loss: 0.03495

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 21,046.18015
Overall Steps per Second: 10,215.92948

Timestep Collection Time: 2.37630
Timestep Consumption Time: 2.51919
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.89549

Cumulative Model Updates: 164,742
Cumulative Timesteps: 1,373,766,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1373766292...
Checkpoint 1373766292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.45195
Policy Entropy: 4.03235
Value Function Loss: 0.03396

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.61048
Value Function Update Magnitude: 0.57960

Collected Steps per Second: 20,537.12357
Overall Steps per Second: 9,967.44294

Timestep Collection Time: 2.43608
Timestep Consumption Time: 2.58327
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 5.01934

Cumulative Model Updates: 164,748
Cumulative Timesteps: 1,373,816,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,377.69564
Policy Entropy: 4.02947
Value Function Loss: 0.03327

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.60521
Value Function Update Magnitude: 0.60689

Collected Steps per Second: 20,718.28925
Overall Steps per Second: 10,058.33941

Timestep Collection Time: 2.41458
Timestep Consumption Time: 2.55900
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.97358

Cumulative Model Updates: 164,754
Cumulative Timesteps: 1,373,866,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1373866348...
Checkpoint 1373866348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400.72814
Policy Entropy: 4.03413
Value Function Loss: 0.03331

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.60251
Value Function Update Magnitude: 0.65310

Collected Steps per Second: 20,762.86234
Overall Steps per Second: 10,128.69660

Timestep Collection Time: 2.40959
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.93943

Cumulative Model Updates: 164,760
Cumulative Timesteps: 1,373,916,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177.98019
Policy Entropy: 4.04761
Value Function Loss: 0.03219

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.61554
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 20,557.53352
Overall Steps per Second: 10,197.13247

Timestep Collection Time: 2.43376
Timestep Consumption Time: 2.47272
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.90648

Cumulative Model Updates: 164,766
Cumulative Timesteps: 1,373,966,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1373966410...
Checkpoint 1373966410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.62132
Policy Entropy: 4.05355
Value Function Loss: 0.03058

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.63137
Value Function Update Magnitude: 0.58405

Collected Steps per Second: 19,613.12349
Overall Steps per Second: 10,003.64287

Timestep Collection Time: 2.55033
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 5.00018

Cumulative Model Updates: 164,772
Cumulative Timesteps: 1,374,016,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.55630
Policy Entropy: 4.06533
Value Function Loss: 0.02994

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.64656
Value Function Update Magnitude: 0.57440

Collected Steps per Second: 20,346.95783
Overall Steps per Second: 10,049.43650

Timestep Collection Time: 2.45953
Timestep Consumption Time: 2.52025
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.97978

Cumulative Model Updates: 164,778
Cumulative Timesteps: 1,374,066,474

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1374066474...
Checkpoint 1374066474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,521.36791
Policy Entropy: 4.05609
Value Function Loss: 0.03050

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.64035
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 20,314.83526
Overall Steps per Second: 9,946.39859

Timestep Collection Time: 2.46185
Timestep Consumption Time: 2.56631
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 5.02815

Cumulative Model Updates: 164,784
Cumulative Timesteps: 1,374,116,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,379.82997
Policy Entropy: 4.05774
Value Function Loss: 0.03051

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.60100
Value Function Update Magnitude: 0.58000

Collected Steps per Second: 20,384.82002
Overall Steps per Second: 9,949.26614

Timestep Collection Time: 2.45388
Timestep Consumption Time: 2.57382
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 5.02771

Cumulative Model Updates: 164,790
Cumulative Timesteps: 1,374,166,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1374166508...
Checkpoint 1374166508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.82573
Policy Entropy: 4.07890
Value Function Loss: 0.02826

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09077
Policy Update Magnitude: 0.61151
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 20,550.58275
Overall Steps per Second: 10,175.24213

Timestep Collection Time: 2.43429
Timestep Consumption Time: 2.48216
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.91644

Cumulative Model Updates: 164,796
Cumulative Timesteps: 1,374,216,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.15806
Policy Entropy: 4.08614
Value Function Loss: 0.02911

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.64194
Value Function Update Magnitude: 0.59242

Collected Steps per Second: 20,435.19079
Overall Steps per Second: 10,158.02723

Timestep Collection Time: 2.44754
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.92379

Cumulative Model Updates: 164,802
Cumulative Timesteps: 1,374,266,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1374266550...
Checkpoint 1374266550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.92819
Policy Entropy: 4.12165
Value Function Loss: 0.02803

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08220
Policy Update Magnitude: 0.67184
Value Function Update Magnitude: 0.56767

Collected Steps per Second: 20,543.41709
Overall Steps per Second: 10,197.05179

Timestep Collection Time: 2.43426
Timestep Consumption Time: 2.46990
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.90416

Cumulative Model Updates: 164,808
Cumulative Timesteps: 1,374,316,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522.64212
Policy Entropy: 4.13775
Value Function Loss: 0.02851

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.67272
Value Function Update Magnitude: 0.58160

Collected Steps per Second: 20,580.43934
Overall Steps per Second: 9,994.07926

Timestep Collection Time: 2.42988
Timestep Consumption Time: 2.57388
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 5.00376

Cumulative Model Updates: 164,814
Cumulative Timesteps: 1,374,366,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1374366566...
Checkpoint 1374366566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,712.97018
Policy Entropy: 4.18685
Value Function Loss: 0.02301

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.72653
Value Function Update Magnitude: 0.62623

Collected Steps per Second: 20,720.46536
Overall Steps per Second: 10,130.79760

Timestep Collection Time: 2.41385
Timestep Consumption Time: 2.52318
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.93702

Cumulative Model Updates: 164,820
Cumulative Timesteps: 1,374,416,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.03324
Policy Entropy: 4.19568
Value Function Loss: 0.02111

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05410
Policy Update Magnitude: 0.82824
Value Function Update Magnitude: 0.69717

Collected Steps per Second: 20,767.91009
Overall Steps per Second: 10,126.61530

Timestep Collection Time: 2.40756
Timestep Consumption Time: 2.52992
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 4.93748

Cumulative Model Updates: 164,826
Cumulative Timesteps: 1,374,466,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1374466582...
Checkpoint 1374466582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.77959
Policy Entropy: 4.16455
Value Function Loss: 0.02339

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05288
Policy Update Magnitude: 0.84815
Value Function Update Magnitude: 0.74039

Collected Steps per Second: 20,975.08262
Overall Steps per Second: 10,194.14422

Timestep Collection Time: 2.38483
Timestep Consumption Time: 2.52211
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.90693

Cumulative Model Updates: 164,832
Cumulative Timesteps: 1,374,516,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.70242
Policy Entropy: 4.05930
Value Function Loss: 0.02877

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05157
Policy Update Magnitude: 0.83488
Value Function Update Magnitude: 0.75595

Collected Steps per Second: 20,532.16593
Overall Steps per Second: 10,046.48760

Timestep Collection Time: 2.43657
Timestep Consumption Time: 2.54308
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.97965

Cumulative Model Updates: 164,838
Cumulative Timesteps: 1,374,566,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1374566632...
Checkpoint 1374566632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.55878
Policy Entropy: 3.95043
Value Function Loss: 0.03169

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.06338
Policy Update Magnitude: 0.77460
Value Function Update Magnitude: 0.67248

Collected Steps per Second: 20,620.99541
Overall Steps per Second: 9,911.96839

Timestep Collection Time: 2.42481
Timestep Consumption Time: 2.61980
PPO Batch Consumption Time: 0.30477
Total Iteration Time: 5.04461

Cumulative Model Updates: 164,844
Cumulative Timesteps: 1,374,616,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.07523
Policy Entropy: 3.88304
Value Function Loss: 0.02941

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08371
Policy Update Magnitude: 0.69262
Value Function Update Magnitude: 0.54900

Collected Steps per Second: 19,134.72753
Overall Steps per Second: 9,644.56849

Timestep Collection Time: 2.61347
Timestep Consumption Time: 2.57163
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 5.18509

Cumulative Model Updates: 164,850
Cumulative Timesteps: 1,374,666,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1374666642...
Checkpoint 1374666642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,058.60689
Policy Entropy: 3.86646
Value Function Loss: 0.02744

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.60946
Value Function Update Magnitude: 0.43319

Collected Steps per Second: 21,431.30626
Overall Steps per Second: 10,232.80668

Timestep Collection Time: 2.33444
Timestep Consumption Time: 2.55474
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.88918

Cumulative Model Updates: 164,856
Cumulative Timesteps: 1,374,716,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,905.60795
Policy Entropy: 3.86591
Value Function Loss: 0.02417

Mean KL Divergence: 0.02152
SB3 Clip Fraction: 0.24663
Policy Update Magnitude: 0.46564
Value Function Update Magnitude: 0.33956

Collected Steps per Second: 20,192.27349
Overall Steps per Second: 10,047.46159

Timestep Collection Time: 2.47709
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.97817

Cumulative Model Updates: 164,862
Cumulative Timesteps: 1,374,766,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1374766690...
Checkpoint 1374766690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,905.60795
Policy Entropy: 3.83022
Value Function Loss: 0.02050

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.19089
Policy Update Magnitude: 0.34755
Value Function Update Magnitude: 0.29318

Collected Steps per Second: 19,903.91278
Overall Steps per Second: 10,153.25301

Timestep Collection Time: 2.51257
Timestep Consumption Time: 2.41294
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.92551

Cumulative Model Updates: 164,868
Cumulative Timesteps: 1,374,816,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,239.16222
Policy Entropy: 3.79399
Value Function Loss: 0.02212

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.17190
Policy Update Magnitude: 0.30980
Value Function Update Magnitude: 0.24424

Collected Steps per Second: 20,166.40205
Overall Steps per Second: 10,096.06785

Timestep Collection Time: 2.48046
Timestep Consumption Time: 2.47414
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.95460

Cumulative Model Updates: 164,874
Cumulative Timesteps: 1,374,866,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1374866722...
Checkpoint 1374866722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,770.81535
Policy Entropy: 3.79497
Value Function Loss: 0.02410

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.19523
Policy Update Magnitude: 0.32144
Value Function Update Magnitude: 0.30806

Collected Steps per Second: 20,942.97830
Overall Steps per Second: 10,222.45895

Timestep Collection Time: 2.38849
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.89334

Cumulative Model Updates: 164,880
Cumulative Timesteps: 1,374,916,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,397.16152
Policy Entropy: 3.80835
Value Function Loss: 0.02862

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.38422
Value Function Update Magnitude: 0.42244

Collected Steps per Second: 20,932.65754
Overall Steps per Second: 10,119.11159

Timestep Collection Time: 2.38938
Timestep Consumption Time: 2.55335
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.94273

Cumulative Model Updates: 164,886
Cumulative Timesteps: 1,374,966,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1374966760...
Checkpoint 1374966760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,671.11173
Policy Entropy: 3.83862
Value Function Loss: 0.02999

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.47395
Value Function Update Magnitude: 0.63504

Collected Steps per Second: 20,766.04050
Overall Steps per Second: 10,132.00816

Timestep Collection Time: 2.40903
Timestep Consumption Time: 2.52839
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.93742

Cumulative Model Updates: 164,892
Cumulative Timesteps: 1,375,016,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,395.25171
Policy Entropy: 3.85573
Value Function Loss: 0.03098

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.49425
Value Function Update Magnitude: 0.66618

Collected Steps per Second: 20,390.72644
Overall Steps per Second: 10,047.49708

Timestep Collection Time: 2.45259
Timestep Consumption Time: 2.52477
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.97736

Cumulative Model Updates: 164,898
Cumulative Timesteps: 1,375,066,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1375066796...
Checkpoint 1375066796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145.79577
Policy Entropy: 3.85793
Value Function Loss: 0.03044

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11400
Policy Update Magnitude: 0.48778
Value Function Update Magnitude: 0.61140

Collected Steps per Second: 20,638.69295
Overall Steps per Second: 10,274.80671

Timestep Collection Time: 2.42380
Timestep Consumption Time: 2.44481
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.86861

Cumulative Model Updates: 164,904
Cumulative Timesteps: 1,375,116,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,006.63150
Policy Entropy: 3.84602
Value Function Loss: 0.02934

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.49492
Value Function Update Magnitude: 0.57168

Collected Steps per Second: 20,587.64261
Overall Steps per Second: 10,106.13543

Timestep Collection Time: 2.42961
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.94947

Cumulative Model Updates: 164,910
Cumulative Timesteps: 1,375,166,840

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1375166840...
Checkpoint 1375166840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,055.06636
Policy Entropy: 3.81787
Value Function Loss: 0.02620

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.48086
Value Function Update Magnitude: 0.55454

Collected Steps per Second: 20,689.07531
Overall Steps per Second: 10,106.87168

Timestep Collection Time: 2.41673
Timestep Consumption Time: 2.53039
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.94713

Cumulative Model Updates: 164,916
Cumulative Timesteps: 1,375,216,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,486.88683
Policy Entropy: 3.80061
Value Function Loss: 0.02676

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.46565
Value Function Update Magnitude: 0.50803

Collected Steps per Second: 20,844.56766
Overall Steps per Second: 10,132.80142

Timestep Collection Time: 2.39890
Timestep Consumption Time: 2.53597
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.93486

Cumulative Model Updates: 164,922
Cumulative Timesteps: 1,375,266,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1375266844...
Checkpoint 1375266844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,012.51213
Policy Entropy: 3.78896
Value Function Loss: 0.03090

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.47133
Value Function Update Magnitude: 0.46577

Collected Steps per Second: 20,912.17147
Overall Steps per Second: 10,199.05452

Timestep Collection Time: 2.39124
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.90300

Cumulative Model Updates: 164,928
Cumulative Timesteps: 1,375,316,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.18963
Policy Entropy: 3.82237
Value Function Loss: 0.03253

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.48689
Value Function Update Magnitude: 0.45875

Collected Steps per Second: 21,010.62421
Overall Steps per Second: 10,330.60410

Timestep Collection Time: 2.38194
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.84444

Cumulative Model Updates: 164,934
Cumulative Timesteps: 1,375,366,896

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1375366896...
Checkpoint 1375366896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,858.79848
Policy Entropy: 3.81006
Value Function Loss: 0.03340

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.51162
Value Function Update Magnitude: 0.45117

Collected Steps per Second: 20,452.25655
Overall Steps per Second: 10,212.31905

Timestep Collection Time: 2.44570
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.89801

Cumulative Model Updates: 164,940
Cumulative Timesteps: 1,375,416,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,974.61121
Policy Entropy: 3.80945
Value Function Loss: 0.02856

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.50619
Value Function Update Magnitude: 0.44574

Collected Steps per Second: 20,739.77501
Overall Steps per Second: 10,070.16312

Timestep Collection Time: 2.41276
Timestep Consumption Time: 2.55638
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.96914

Cumulative Model Updates: 164,946
Cumulative Timesteps: 1,375,466,956

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1375466956...
Checkpoint 1375466956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,504.21527
Policy Entropy: 3.78519
Value Function Loss: 0.02943

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12170
Policy Update Magnitude: 0.47804
Value Function Update Magnitude: 0.36041

Collected Steps per Second: 20,883.75554
Overall Steps per Second: 10,265.14249

Timestep Collection Time: 2.39507
Timestep Consumption Time: 2.47754
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.87261

Cumulative Model Updates: 164,952
Cumulative Timesteps: 1,375,516,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,456.85161
Policy Entropy: 3.78181
Value Function Loss: 0.02735

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.44085
Value Function Update Magnitude: 0.37539

Collected Steps per Second: 20,834.16623
Overall Steps per Second: 10,070.93783

Timestep Collection Time: 2.40125
Timestep Consumption Time: 2.56631
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.96756

Cumulative Model Updates: 164,958
Cumulative Timesteps: 1,375,567,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1375567002...
Checkpoint 1375567002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,989.66948
Policy Entropy: 3.78409
Value Function Loss: 0.03113

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.42477
Value Function Update Magnitude: 0.40050

Collected Steps per Second: 21,166.63396
Overall Steps per Second: 10,162.23130

Timestep Collection Time: 2.36363
Timestep Consumption Time: 2.55951
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.92313

Cumulative Model Updates: 164,964
Cumulative Timesteps: 1,375,617,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,726.72528
Policy Entropy: 3.77030
Value Function Loss: 0.02739

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.39652
Value Function Update Magnitude: 0.37347

Collected Steps per Second: 20,982.67491
Overall Steps per Second: 10,153.70593

Timestep Collection Time: 2.38406
Timestep Consumption Time: 2.54261
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.92667

Cumulative Model Updates: 164,970
Cumulative Timesteps: 1,375,667,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1375667056...
Checkpoint 1375667056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,746.20415
Policy Entropy: 3.76306
Value Function Loss: 0.02752

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.38189
Value Function Update Magnitude: 0.34484

Collected Steps per Second: 21,039.25049
Overall Steps per Second: 10,156.35005

Timestep Collection Time: 2.37775
Timestep Consumption Time: 2.54784
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.92559

Cumulative Model Updates: 164,976
Cumulative Timesteps: 1,375,717,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,734.52386
Policy Entropy: 3.75898
Value Function Loss: 0.02571

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.37865
Value Function Update Magnitude: 0.36258

Collected Steps per Second: 21,088.33574
Overall Steps per Second: 10,359.42790

Timestep Collection Time: 2.37136
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.82729

Cumulative Model Updates: 164,982
Cumulative Timesteps: 1,375,767,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1375767090...
Checkpoint 1375767090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,334.48482
Policy Entropy: 3.75007
Value Function Loss: 0.02361

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.38992
Value Function Update Magnitude: 0.42648

Collected Steps per Second: 21,007.59179
Overall Steps per Second: 10,274.92246

Timestep Collection Time: 2.38152
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.86914

Cumulative Model Updates: 164,988
Cumulative Timesteps: 1,375,817,120

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,763.76265
Policy Entropy: 3.74911
Value Function Loss: 0.02419

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.41183
Value Function Update Magnitude: 0.46182

Collected Steps per Second: 20,806.56355
Overall Steps per Second: 10,091.27511

Timestep Collection Time: 2.40453
Timestep Consumption Time: 2.55322
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.95775

Cumulative Model Updates: 164,994
Cumulative Timesteps: 1,375,867,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1375867150...
Checkpoint 1375867150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,263.37315
Policy Entropy: 3.75350
Value Function Loss: 0.02336

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.43654
Value Function Update Magnitude: 0.52029

Collected Steps per Second: 21,075.70620
Overall Steps per Second: 10,178.96373

Timestep Collection Time: 2.37344
Timestep Consumption Time: 2.54081
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.91425

Cumulative Model Updates: 165,000
Cumulative Timesteps: 1,375,917,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,014.65560
Policy Entropy: 3.78685
Value Function Loss: 0.02538

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.43666
Value Function Update Magnitude: 0.54317

Collected Steps per Second: 20,946.30011
Overall Steps per Second: 10,116.11203

Timestep Collection Time: 2.38820
Timestep Consumption Time: 2.55678
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.94498

Cumulative Model Updates: 165,006
Cumulative Timesteps: 1,375,967,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1375967196...
Checkpoint 1375967196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,671.76387
Policy Entropy: 3.78275
Value Function Loss: 0.02462

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.44710
Value Function Update Magnitude: 0.48630

Collected Steps per Second: 20,894.17545
Overall Steps per Second: 10,031.08755

Timestep Collection Time: 2.39349
Timestep Consumption Time: 2.59201
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.98550

Cumulative Model Updates: 165,012
Cumulative Timesteps: 1,376,017,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.76911
Policy Entropy: 3.78330
Value Function Loss: 0.02407

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.46081
Value Function Update Magnitude: 0.54281

Collected Steps per Second: 20,633.19196
Overall Steps per Second: 10,148.79332

Timestep Collection Time: 2.42473
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.92965

Cumulative Model Updates: 165,018
Cumulative Timesteps: 1,376,067,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1376067236...
Checkpoint 1376067236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140.85360
Policy Entropy: 3.75774
Value Function Loss: 0.02384

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.44600
Value Function Update Magnitude: 0.53358

Collected Steps per Second: 20,889.32178
Overall Steps per Second: 10,188.94169

Timestep Collection Time: 2.39577
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.91180

Cumulative Model Updates: 165,024
Cumulative Timesteps: 1,376,117,282

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,826.27628
Policy Entropy: 3.75921
Value Function Loss: 0.02392

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.44627
Value Function Update Magnitude: 0.47338

Collected Steps per Second: 21,045.33379
Overall Steps per Second: 10,193.18722

Timestep Collection Time: 2.37592
Timestep Consumption Time: 2.52951
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.90543

Cumulative Model Updates: 165,030
Cumulative Timesteps: 1,376,167,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1376167284...
Checkpoint 1376167284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,538.50771
Policy Entropy: 3.76427
Value Function Loss: 0.02588

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.44996
Value Function Update Magnitude: 0.51662

Collected Steps per Second: 21,062.08642
Overall Steps per Second: 10,109.26252

Timestep Collection Time: 2.37517
Timestep Consumption Time: 2.57336
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.94853

Cumulative Model Updates: 165,036
Cumulative Timesteps: 1,376,217,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,717.28675
Policy Entropy: 3.77972
Value Function Loss: 0.02835

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.45659
Value Function Update Magnitude: 0.60449

Collected Steps per Second: 21,333.36337
Overall Steps per Second: 10,402.02958

Timestep Collection Time: 2.34393
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.80714

Cumulative Model Updates: 165,042
Cumulative Timesteps: 1,376,267,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1376267314...
Checkpoint 1376267314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,082.65302
Policy Entropy: 3.79685
Value Function Loss: 0.02735

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.47211
Value Function Update Magnitude: 0.60828

Collected Steps per Second: 20,964.90809
Overall Steps per Second: 10,233.54152

Timestep Collection Time: 2.38551
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.88707

Cumulative Model Updates: 165,048
Cumulative Timesteps: 1,376,317,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,081.01291
Policy Entropy: 3.79995
Value Function Loss: 0.02610

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.46986
Value Function Update Magnitude: 0.56362

Collected Steps per Second: 21,049.37358
Overall Steps per Second: 10,149.47271

Timestep Collection Time: 2.37537
Timestep Consumption Time: 2.55100
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.92636

Cumulative Model Updates: 165,054
Cumulative Timesteps: 1,376,367,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1376367326...
Checkpoint 1376367326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,537.46517
Policy Entropy: 3.80213
Value Function Loss: 0.02501

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.45063
Value Function Update Magnitude: 0.52200

Collected Steps per Second: 21,127.78228
Overall Steps per Second: 10,175.37624

Timestep Collection Time: 2.36759
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.91599

Cumulative Model Updates: 165,060
Cumulative Timesteps: 1,376,417,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.85085
Policy Entropy: 3.79906
Value Function Loss: 0.02531

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.44039
Value Function Update Magnitude: 0.51513

Collected Steps per Second: 21,222.46111
Overall Steps per Second: 10,337.11210

Timestep Collection Time: 2.35713
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.83926

Cumulative Model Updates: 165,066
Cumulative Timesteps: 1,376,467,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1376467372...
Checkpoint 1376467372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,506.49503
Policy Entropy: 3.77800
Value Function Loss: 0.02782

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.47742
Value Function Update Magnitude: 0.57340

Collected Steps per Second: 21,033.56752
Overall Steps per Second: 10,297.58225

Timestep Collection Time: 2.37725
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.85570

Cumulative Model Updates: 165,072
Cumulative Timesteps: 1,376,517,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.61806
Policy Entropy: 3.78775
Value Function Loss: 0.02608

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.51124
Value Function Update Magnitude: 0.53398

Collected Steps per Second: 21,032.96489
Overall Steps per Second: 10,122.17070

Timestep Collection Time: 2.37741
Timestep Consumption Time: 2.56264
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.94005

Cumulative Model Updates: 165,078
Cumulative Timesteps: 1,376,567,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1376567378...
Checkpoint 1376567378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,772.67556
Policy Entropy: 3.78395
Value Function Loss: 0.02878

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.55164

Collected Steps per Second: 19,974.94865
Overall Steps per Second: 9,863.99927

Timestep Collection Time: 2.50414
Timestep Consumption Time: 2.56683
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 5.07097

Cumulative Model Updates: 165,084
Cumulative Timesteps: 1,376,617,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,833.39176
Policy Entropy: 3.82964
Value Function Loss: 0.02838

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.55734

Collected Steps per Second: 21,301.00083
Overall Steps per Second: 10,296.97143

Timestep Collection Time: 2.34787
Timestep Consumption Time: 2.50909
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.85696

Cumulative Model Updates: 165,090
Cumulative Timesteps: 1,376,667,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1376667410...
Checkpoint 1376667410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,871.81724
Policy Entropy: 3.82149
Value Function Loss: 0.03160

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.58151
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 20,890.96258
Overall Steps per Second: 10,282.55309

Timestep Collection Time: 2.39386
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.86358

Cumulative Model Updates: 165,096
Cumulative Timesteps: 1,376,717,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,671.25620
Policy Entropy: 3.85185
Value Function Loss: 0.02961

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.59455
Value Function Update Magnitude: 0.60822

Collected Steps per Second: 20,851.94469
Overall Steps per Second: 10,093.20276

Timestep Collection Time: 2.39795
Timestep Consumption Time: 2.55607
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.95403

Cumulative Model Updates: 165,102
Cumulative Timesteps: 1,376,767,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1376767422...
Checkpoint 1376767422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,422.69809
Policy Entropy: 3.82657
Value Function Loss: 0.03331

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.57867

Collected Steps per Second: 21,083.93165
Overall Steps per Second: 10,287.75452

Timestep Collection Time: 2.37356
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.86442

Cumulative Model Updates: 165,108
Cumulative Timesteps: 1,376,817,466

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,063.01984
Policy Entropy: 3.84695
Value Function Loss: 0.03378

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.62942
Value Function Update Magnitude: 0.60354

Collected Steps per Second: 21,232.07128
Overall Steps per Second: 10,249.77065

Timestep Collection Time: 2.35625
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.88089

Cumulative Model Updates: 165,114
Cumulative Timesteps: 1,376,867,494

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1376867494...
Checkpoint 1376867494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,472.17871
Policy Entropy: 3.81443
Value Function Loss: 0.03443

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.62032
Value Function Update Magnitude: 0.63361

Collected Steps per Second: 21,024.31117
Overall Steps per Second: 10,307.65250

Timestep Collection Time: 2.37820
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.85076

Cumulative Model Updates: 165,120
Cumulative Timesteps: 1,376,917,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,685.39909
Policy Entropy: 3.84199
Value Function Loss: 0.03030

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.60620
Value Function Update Magnitude: 0.74152

Collected Steps per Second: 20,998.35480
Overall Steps per Second: 10,287.82352

Timestep Collection Time: 2.38171
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.86128

Cumulative Model Updates: 165,126
Cumulative Timesteps: 1,376,967,506

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1376967506...
Checkpoint 1376967506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,281.50235
Policy Entropy: 3.82976
Value Function Loss: 0.02671

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.57424
Value Function Update Magnitude: 0.81442

Collected Steps per Second: 21,122.41755
Overall Steps per Second: 10,313.82789

Timestep Collection Time: 2.36838
Timestep Consumption Time: 2.48200
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.85038

Cumulative Model Updates: 165,132
Cumulative Timesteps: 1,377,017,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,760.65159
Policy Entropy: 3.81406
Value Function Loss: 0.02534

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.78786

Collected Steps per Second: 21,026.22683
Overall Steps per Second: 10,138.97642

Timestep Collection Time: 2.37884
Timestep Consumption Time: 2.55440
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.93324

Cumulative Model Updates: 165,138
Cumulative Timesteps: 1,377,067,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1377067550...
Checkpoint 1377067550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,118.56524
Policy Entropy: 3.79277
Value Function Loss: 0.02499

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.73593

Collected Steps per Second: 20,846.97707
Overall Steps per Second: 10,158.98662

Timestep Collection Time: 2.40083
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.92667

Cumulative Model Updates: 165,144
Cumulative Timesteps: 1,377,117,600

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.74194
Policy Entropy: 3.81013
Value Function Loss: 0.02548

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.64243

Collected Steps per Second: 21,051.06392
Overall Steps per Second: 10,143.79113

Timestep Collection Time: 2.37565
Timestep Consumption Time: 2.55446
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.93011

Cumulative Model Updates: 165,150
Cumulative Timesteps: 1,377,167,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377167610...
Checkpoint 1377167610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.93692
Policy Entropy: 3.84334
Value Function Loss: 0.02469

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.52614
Value Function Update Magnitude: 0.62883

Collected Steps per Second: 21,062.20630
Overall Steps per Second: 10,106.86225

Timestep Collection Time: 2.37402
Timestep Consumption Time: 2.57332
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.94733

Cumulative Model Updates: 165,156
Cumulative Timesteps: 1,377,217,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,717.92179
Policy Entropy: 3.86340
Value Function Loss: 0.02410

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 20,933.12271
Overall Steps per Second: 10,184.90581

Timestep Collection Time: 2.38999
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.91217

Cumulative Model Updates: 165,162
Cumulative Timesteps: 1,377,267,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1377267642...
Checkpoint 1377267642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,740.89682
Policy Entropy: 3.83255
Value Function Loss: 0.02077

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.55456

Collected Steps per Second: 20,843.60942
Overall Steps per Second: 10,076.74736

Timestep Collection Time: 2.39958
Timestep Consumption Time: 2.56392
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.96351

Cumulative Model Updates: 165,168
Cumulative Timesteps: 1,377,317,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,968.78844
Policy Entropy: 3.81790
Value Function Loss: 0.02200

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.45488

Collected Steps per Second: 21,094.27200
Overall Steps per Second: 10,211.35988

Timestep Collection Time: 2.37098
Timestep Consumption Time: 2.52690
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.89788

Cumulative Model Updates: 165,174
Cumulative Timesteps: 1,377,367,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1377367672...
Checkpoint 1377367672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,446.79303
Policy Entropy: 3.82158
Value Function Loss: 0.02195

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.57425
Value Function Update Magnitude: 0.40460

Collected Steps per Second: 20,900.57337
Overall Steps per Second: 10,065.28070

Timestep Collection Time: 2.39410
Timestep Consumption Time: 2.57725
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.97135

Cumulative Model Updates: 165,180
Cumulative Timesteps: 1,377,417,710

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.07770
Policy Entropy: 3.82026
Value Function Loss: 0.02294

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.57780
Value Function Update Magnitude: 0.37435

Collected Steps per Second: 20,795.73831
Overall Steps per Second: 10,071.96150

Timestep Collection Time: 2.40607
Timestep Consumption Time: 2.56178
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.96785

Cumulative Model Updates: 165,186
Cumulative Timesteps: 1,377,467,746

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1377467746...
Checkpoint 1377467746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,625.95853
Policy Entropy: 3.82175
Value Function Loss: 0.02411

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.35142

Collected Steps per Second: 21,002.80123
Overall Steps per Second: 10,169.40087

Timestep Collection Time: 2.38092
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.91730

Cumulative Model Updates: 165,192
Cumulative Timesteps: 1,377,517,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,704.98092
Policy Entropy: 3.80938
Value Function Loss: 0.02857

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.28874

Collected Steps per Second: 20,751.07834
Overall Steps per Second: 10,054.10247

Timestep Collection Time: 2.41019
Timestep Consumption Time: 2.56430
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.97449

Cumulative Model Updates: 165,198
Cumulative Timesteps: 1,377,567,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1377567766...
Checkpoint 1377567766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 399.75747
Policy Entropy: 3.83331
Value Function Loss: 0.03163

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07840
Policy Update Magnitude: 0.60956
Value Function Update Magnitude: 0.26685

Collected Steps per Second: 20,651.46790
Overall Steps per Second: 10,212.13984

Timestep Collection Time: 2.42220
Timestep Consumption Time: 2.47609
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.89829

Cumulative Model Updates: 165,204
Cumulative Timesteps: 1,377,617,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,602.64356
Policy Entropy: 3.83649
Value Function Loss: 0.03349

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08696
Policy Update Magnitude: 0.67616
Value Function Update Magnitude: 0.26945

Collected Steps per Second: 20,680.80129
Overall Steps per Second: 10,060.79111

Timestep Collection Time: 2.41780
Timestep Consumption Time: 2.55219
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.96999

Cumulative Model Updates: 165,210
Cumulative Timesteps: 1,377,667,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1377667790...
Checkpoint 1377667790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,236.33521
Policy Entropy: 3.81504
Value Function Loss: 0.02787

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.63362
Value Function Update Magnitude: 0.38346

Collected Steps per Second: 20,499.57784
Overall Steps per Second: 10,179.11068

Timestep Collection Time: 2.44044
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.91477

Cumulative Model Updates: 165,216
Cumulative Timesteps: 1,377,717,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,547.84200
Policy Entropy: 3.80434
Value Function Loss: 0.02535

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09119
Policy Update Magnitude: 0.62088
Value Function Update Magnitude: 0.45591

Collected Steps per Second: 20,815.83592
Overall Steps per Second: 10,046.13125

Timestep Collection Time: 2.40250
Timestep Consumption Time: 2.57554
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.97804

Cumulative Model Updates: 165,222
Cumulative Timesteps: 1,377,767,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1377767828...
Checkpoint 1377767828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,860.29920
Policy Entropy: 3.77701
Value Function Loss: 0.02078

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.59419
Value Function Update Magnitude: 0.49133

Collected Steps per Second: 20,700.52223
Overall Steps per Second: 10,188.75733

Timestep Collection Time: 2.41540
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.90737

Cumulative Model Updates: 165,228
Cumulative Timesteps: 1,377,817,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,860.29920
Policy Entropy: 3.78423
Value Function Loss: 0.01627

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.52979
Value Function Update Magnitude: 0.42442

Collected Steps per Second: 20,605.70882
Overall Steps per Second: 10,109.57346

Timestep Collection Time: 2.42777
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.94838

Cumulative Model Updates: 165,234
Cumulative Timesteps: 1,377,867,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1377867854...
Checkpoint 1377867854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,333.25685
Policy Entropy: 3.76953
Value Function Loss: 0.02145

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17624
Policy Update Magnitude: 0.48193
Value Function Update Magnitude: 0.32608

Collected Steps per Second: 20,200.54188
Overall Steps per Second: 10,153.30995

Timestep Collection Time: 2.47756
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.92923

Cumulative Model Updates: 165,240
Cumulative Timesteps: 1,377,917,902

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,019.99380
Policy Entropy: 3.79717
Value Function Loss: 0.02224

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.19198
Policy Update Magnitude: 0.46234
Value Function Update Magnitude: 0.33471

Collected Steps per Second: 21,010.82050
Overall Steps per Second: 10,099.99251

Timestep Collection Time: 2.38058
Timestep Consumption Time: 2.57170
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.95228

Cumulative Model Updates: 165,246
Cumulative Timesteps: 1,377,967,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1377967920...
Checkpoint 1377967920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,350.21024
Policy Entropy: 3.78223
Value Function Loss: 0.02478

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15562
Policy Update Magnitude: 0.51649
Value Function Update Magnitude: 0.38479

Collected Steps per Second: 20,050.90313
Overall Steps per Second: 10,192.70989

Timestep Collection Time: 2.49525
Timestep Consumption Time: 2.41336
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.90861

Cumulative Model Updates: 165,252
Cumulative Timesteps: 1,378,017,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,963.80153
Policy Entropy: 3.78522
Value Function Loss: 0.01886

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.18408
Policy Update Magnitude: 0.46813
Value Function Update Magnitude: 0.48710

Collected Steps per Second: 20,276.29882
Overall Steps per Second: 10,117.68145

Timestep Collection Time: 2.46731
Timestep Consumption Time: 2.47730
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.94461

Cumulative Model Updates: 165,258
Cumulative Timesteps: 1,378,067,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1378067980...
Checkpoint 1378067980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,752.23245
Policy Entropy: 3.76206
Value Function Loss: 0.01672

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.16255
Policy Update Magnitude: 0.38561
Value Function Update Magnitude: 0.52835

Collected Steps per Second: 20,299.35338
Overall Steps per Second: 10,181.81276

Timestep Collection Time: 2.46451
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.91347

Cumulative Model Updates: 165,264
Cumulative Timesteps: 1,378,118,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,752.23245
Policy Entropy: 3.76439
Value Function Loss: 0.01356

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15615
Policy Update Magnitude: 0.34458
Value Function Update Magnitude: 0.49940

Collected Steps per Second: 21,123.54903
Overall Steps per Second: 10,178.82215

Timestep Collection Time: 2.36845
Timestep Consumption Time: 2.54666
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.91511

Cumulative Model Updates: 165,270
Cumulative Timesteps: 1,378,168,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1378168038...
Checkpoint 1378168038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,605.93856
Policy Entropy: 3.76019
Value Function Loss: 0.01428

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.31016
Value Function Update Magnitude: 0.46123

Collected Steps per Second: 20,584.03823
Overall Steps per Second: 10,061.80628

Timestep Collection Time: 2.42936
Timestep Consumption Time: 2.54052
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.96988

Cumulative Model Updates: 165,276
Cumulative Timesteps: 1,378,218,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,330.91596
Policy Entropy: 3.75864
Value Function Loss: 0.01534

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14698
Policy Update Magnitude: 0.35111
Value Function Update Magnitude: 0.50678

Collected Steps per Second: 21,102.37380
Overall Steps per Second: 10,165.86026

Timestep Collection Time: 2.37092
Timestep Consumption Time: 2.55065
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.92157

Cumulative Model Updates: 165,282
Cumulative Timesteps: 1,378,268,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1378268076...
Checkpoint 1378268076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,255.10922
Policy Entropy: 3.75322
Value Function Loss: 0.01427

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.38621
Value Function Update Magnitude: 0.50991

Collected Steps per Second: 21,017.39257
Overall Steps per Second: 10,133.62146

Timestep Collection Time: 2.37984
Timestep Consumption Time: 2.55601
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.93585

Cumulative Model Updates: 165,288
Cumulative Timesteps: 1,378,318,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,255.10922
Policy Entropy: 3.76038
Value Function Loss: 0.01240

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.36101
Value Function Update Magnitude: 0.44509

Collected Steps per Second: 20,613.43041
Overall Steps per Second: 10,022.11411

Timestep Collection Time: 2.42735
Timestep Consumption Time: 2.56521
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.99256

Cumulative Model Updates: 165,294
Cumulative Timesteps: 1,378,368,130

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1378368130...
Checkpoint 1378368130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,180.85978
Policy Entropy: 3.75645
Value Function Loss: 0.01112

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.34436
Value Function Update Magnitude: 0.37152

Collected Steps per Second: 20,012.91202
Overall Steps per Second: 9,768.37379

Timestep Collection Time: 2.49969
Timestep Consumption Time: 2.62153
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 5.12122

Cumulative Model Updates: 165,300
Cumulative Timesteps: 1,378,418,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,180.85978
Policy Entropy: 3.78038
Value Function Loss: 0.00993

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09182
Policy Update Magnitude: 0.35654
Value Function Update Magnitude: 0.31102

Collected Steps per Second: 19,895.46091
Overall Steps per Second: 9,800.59593

Timestep Collection Time: 2.51374
Timestep Consumption Time: 2.58922
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 5.10295

Cumulative Model Updates: 165,306
Cumulative Timesteps: 1,378,468,168

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1378468168...
Checkpoint 1378468168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,620.05898
Policy Entropy: 3.77423
Value Function Loss: 0.01039

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06665
Policy Update Magnitude: 0.34860
Value Function Update Magnitude: 0.27494

Collected Steps per Second: 20,763.60225
Overall Steps per Second: 10,103.60977

Timestep Collection Time: 2.40893
Timestep Consumption Time: 2.54158
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.95051

Cumulative Model Updates: 165,312
Cumulative Timesteps: 1,378,518,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,788.69541
Policy Entropy: 3.79325
Value Function Loss: 0.01136

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05486
Policy Update Magnitude: 0.36997
Value Function Update Magnitude: 0.31502

Collected Steps per Second: 21,102.84344
Overall Steps per Second: 10,140.06939

Timestep Collection Time: 2.36954
Timestep Consumption Time: 2.56179
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.93133

Cumulative Model Updates: 165,318
Cumulative Timesteps: 1,378,568,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1378568190...
Checkpoint 1378568190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,643.36505
Policy Entropy: 3.77503
Value Function Loss: 0.01453

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04353
Policy Update Magnitude: 0.42615
Value Function Update Magnitude: 0.41703

Collected Steps per Second: 21,016.53749
Overall Steps per Second: 10,133.07507

Timestep Collection Time: 2.37974
Timestep Consumption Time: 2.55597
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.93572

Cumulative Model Updates: 165,324
Cumulative Timesteps: 1,378,618,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,770.82562
Policy Entropy: 3.79618
Value Function Loss: 0.01484

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07170
Policy Update Magnitude: 0.48607
Value Function Update Magnitude: 0.49797

Collected Steps per Second: 20,807.98520
Overall Steps per Second: 10,089.12077

Timestep Collection Time: 2.40427
Timestep Consumption Time: 2.55434
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.95861

Cumulative Model Updates: 165,330
Cumulative Timesteps: 1,378,668,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1378668232...
Checkpoint 1378668232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,986.76621
Policy Entropy: 3.78064
Value Function Loss: 0.02122

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.42868
Value Function Update Magnitude: 0.49826

Collected Steps per Second: 20,577.55190
Overall Steps per Second: 10,175.04118

Timestep Collection Time: 2.43110
Timestep Consumption Time: 2.48544
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.91654

Cumulative Model Updates: 165,336
Cumulative Timesteps: 1,378,718,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,905.07525
Policy Entropy: 3.80701
Value Function Loss: 0.02519

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.45293
Value Function Update Magnitude: 0.54619

Collected Steps per Second: 20,763.41527
Overall Steps per Second: 10,053.77614

Timestep Collection Time: 2.40856
Timestep Consumption Time: 2.56569
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.97425

Cumulative Model Updates: 165,342
Cumulative Timesteps: 1,378,768,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1378768268...
Checkpoint 1378768268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,161.75490
Policy Entropy: 3.81145
Value Function Loss: 0.02932

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.49433

Collected Steps per Second: 19,938.88757
Overall Steps per Second: 9,876.71037

Timestep Collection Time: 2.50816
Timestep Consumption Time: 2.55526
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 5.06343

Cumulative Model Updates: 165,348
Cumulative Timesteps: 1,378,818,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,788.26882
Policy Entropy: 3.82753
Value Function Loss: 0.02643

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.52413
Value Function Update Magnitude: 0.49042

Collected Steps per Second: 20,615.61084
Overall Steps per Second: 10,068.77201

Timestep Collection Time: 2.42661
Timestep Consumption Time: 2.54182
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.96843

Cumulative Model Updates: 165,354
Cumulative Timesteps: 1,378,868,304

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1378868304...
Checkpoint 1378868304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,876.30326
Policy Entropy: 3.80467
Value Function Loss: 0.02648

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.61594

Collected Steps per Second: 20,615.02649
Overall Steps per Second: 10,096.35237

Timestep Collection Time: 2.42736
Timestep Consumption Time: 2.52889
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.95625

Cumulative Model Updates: 165,360
Cumulative Timesteps: 1,378,918,344

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,748.80891
Policy Entropy: 3.80443
Value Function Loss: 0.02517

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.58560

Collected Steps per Second: 20,702.15077
Overall Steps per Second: 10,005.96866

Timestep Collection Time: 2.41646
Timestep Consumption Time: 2.58315
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.99962

Cumulative Model Updates: 165,366
Cumulative Timesteps: 1,378,968,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1378968370...
Checkpoint 1378968370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,090.69323
Policy Entropy: 3.78310
Value Function Loss: 0.02658

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.53041

Collected Steps per Second: 20,842.59492
Overall Steps per Second: 10,195.67462

Timestep Collection Time: 2.40037
Timestep Consumption Time: 2.50661
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.90698

Cumulative Model Updates: 165,372
Cumulative Timesteps: 1,379,018,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,015.54186
Policy Entropy: 3.75944
Value Function Loss: 0.02319

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.51139
Value Function Update Magnitude: 0.52029

Collected Steps per Second: 20,942.91262
Overall Steps per Second: 10,153.30941

Timestep Collection Time: 2.38811
Timestep Consumption Time: 2.53777
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.92588

Cumulative Model Updates: 165,378
Cumulative Timesteps: 1,379,068,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1379068414...
Checkpoint 1379068414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,891.12840
Policy Entropy: 3.73737
Value Function Loss: 0.02405

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15043
Policy Update Magnitude: 0.49650
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 20,838.88165
Overall Steps per Second: 10,247.86512

Timestep Collection Time: 2.40013
Timestep Consumption Time: 2.48050
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.88063

Cumulative Model Updates: 165,384
Cumulative Timesteps: 1,379,118,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,481.49829
Policy Entropy: 3.74147
Value Function Loss: 0.02374

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14137
Policy Update Magnitude: 0.48925
Value Function Update Magnitude: 0.60596

Collected Steps per Second: 20,707.82415
Overall Steps per Second: 10,061.80212

Timestep Collection Time: 2.41503
Timestep Consumption Time: 2.55525
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.97028

Cumulative Model Updates: 165,390
Cumulative Timesteps: 1,379,168,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1379168440...
Checkpoint 1379168440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,219.81216
Policy Entropy: 3.76044
Value Function Loss: 0.02939

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14008
Policy Update Magnitude: 0.48815
Value Function Update Magnitude: 0.49869

Collected Steps per Second: 20,599.06342
Overall Steps per Second: 10,175.82185

Timestep Collection Time: 2.42875
Timestep Consumption Time: 2.48780
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.91656

Cumulative Model Updates: 165,396
Cumulative Timesteps: 1,379,218,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,657.06205
Policy Entropy: 3.79071
Value Function Loss: 0.02806

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12113
Policy Update Magnitude: 0.51690
Value Function Update Magnitude: 0.46784

Collected Steps per Second: 20,829.99059
Overall Steps per Second: 10,130.53525

Timestep Collection Time: 2.40135
Timestep Consumption Time: 2.53620
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.93755

Cumulative Model Updates: 165,402
Cumulative Timesteps: 1,379,268,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1379268490...
Checkpoint 1379268490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,093.23646
Policy Entropy: 3.78739
Value Function Loss: 0.02873

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.49253
Value Function Update Magnitude: 0.47519

Collected Steps per Second: 20,893.91288
Overall Steps per Second: 10,126.76252

Timestep Collection Time: 2.39362
Timestep Consumption Time: 2.54498
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.93860

Cumulative Model Updates: 165,408
Cumulative Timesteps: 1,379,318,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,238.34167
Policy Entropy: 3.77918
Value Function Loss: 0.02515

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.46740
Value Function Update Magnitude: 0.44898

Collected Steps per Second: 20,851.91017
Overall Steps per Second: 10,111.95053

Timestep Collection Time: 2.39882
Timestep Consumption Time: 2.54780
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.94662

Cumulative Model Updates: 165,414
Cumulative Timesteps: 1,379,368,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1379368522...
Checkpoint 1379368522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,414.58496
Policy Entropy: 3.75766
Value Function Loss: 0.02824

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.45617
Value Function Update Magnitude: 0.43863

Collected Steps per Second: 20,618.73607
Overall Steps per Second: 10,117.19438

Timestep Collection Time: 2.42546
Timestep Consumption Time: 2.51761
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.94307

Cumulative Model Updates: 165,420
Cumulative Timesteps: 1,379,418,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,725.93608
Policy Entropy: 3.76900
Value Function Loss: 0.02761

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.45735
Value Function Update Magnitude: 0.47764

Collected Steps per Second: 20,527.67881
Overall Steps per Second: 10,066.34238

Timestep Collection Time: 2.43642
Timestep Consumption Time: 2.53202
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.96844

Cumulative Model Updates: 165,426
Cumulative Timesteps: 1,379,468,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1379468546...
Checkpoint 1379468546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,223.50637
Policy Entropy: 3.76998
Value Function Loss: 0.02504

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.49227
Value Function Update Magnitude: 0.49168

Collected Steps per Second: 20,755.30703
Overall Steps per Second: 10,272.19321

Timestep Collection Time: 2.41105
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.87160

Cumulative Model Updates: 165,432
Cumulative Timesteps: 1,379,518,588

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,418.36843
Policy Entropy: 3.78896
Value Function Loss: 0.02477

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.48831
Value Function Update Magnitude: 0.51984

Collected Steps per Second: 20,527.38710
Overall Steps per Second: 10,039.80163

Timestep Collection Time: 2.43606
Timestep Consumption Time: 2.54471
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.98078

Cumulative Model Updates: 165,438
Cumulative Timesteps: 1,379,568,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1379568594...
Checkpoint 1379568594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,078.00205
Policy Entropy: 3.77640
Value Function Loss: 0.02416

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.47292
Value Function Update Magnitude: 0.51819

Collected Steps per Second: 20,708.10631
Overall Steps per Second: 10,126.94714

Timestep Collection Time: 2.41596
Timestep Consumption Time: 2.52432
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.94028

Cumulative Model Updates: 165,444
Cumulative Timesteps: 1,379,618,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,704.56082
Policy Entropy: 3.78113
Value Function Loss: 0.02531

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.47381
Value Function Update Magnitude: 0.48762

Collected Steps per Second: 20,382.43354
Overall Steps per Second: 10,171.76603

Timestep Collection Time: 2.45329
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.91596

Cumulative Model Updates: 165,450
Cumulative Timesteps: 1,379,668,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1379668628...
Checkpoint 1379668628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,379.99473
Policy Entropy: 3.78870
Value Function Loss: 0.02336

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.48099
Value Function Update Magnitude: 0.53449

Collected Steps per Second: 20,247.74459
Overall Steps per Second: 10,038.39104

Timestep Collection Time: 2.47000
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.98207

Cumulative Model Updates: 165,456
Cumulative Timesteps: 1,379,718,640

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,536.36239
Policy Entropy: 3.78867
Value Function Loss: 0.02505

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.45954
Value Function Update Magnitude: 0.56288

Collected Steps per Second: 20,207.77581
Overall Steps per Second: 10,097.18291

Timestep Collection Time: 2.47558
Timestep Consumption Time: 2.47887
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.95445

Cumulative Model Updates: 165,462
Cumulative Timesteps: 1,379,768,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1379768666...
Checkpoint 1379768666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,115.40639
Policy Entropy: 3.78600
Value Function Loss: 0.02431

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.43553
Value Function Update Magnitude: 0.53397

Collected Steps per Second: 20,219.78921
Overall Steps per Second: 10,295.13044

Timestep Collection Time: 2.47292
Timestep Consumption Time: 2.38394
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.85686

Cumulative Model Updates: 165,468
Cumulative Timesteps: 1,379,818,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,488.69538
Policy Entropy: 3.76198
Value Function Loss: 0.02354

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.42622
Value Function Update Magnitude: 0.43824

Collected Steps per Second: 20,473.65733
Overall Steps per Second: 10,063.63011

Timestep Collection Time: 2.44353
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.97117

Cumulative Model Updates: 165,474
Cumulative Timesteps: 1,379,868,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1379868696...
Checkpoint 1379868696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,488.69538
Policy Entropy: 3.76918
Value Function Loss: 0.01863

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.42982
Value Function Update Magnitude: 0.39571

Collected Steps per Second: 20,778.48477
Overall Steps per Second: 10,152.58930

Timestep Collection Time: 2.40682
Timestep Consumption Time: 2.51902
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.92584

Cumulative Model Updates: 165,480
Cumulative Timesteps: 1,379,918,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,178.90654
Policy Entropy: 3.75346
Value Function Loss: 0.01971

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.43146
Value Function Update Magnitude: 0.52553

Collected Steps per Second: 20,682.58228
Overall Steps per Second: 10,145.01975

Timestep Collection Time: 2.41836
Timestep Consumption Time: 2.51194
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.93030

Cumulative Model Updates: 165,486
Cumulative Timesteps: 1,379,968,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1379968724...
Checkpoint 1379968724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,842.87755
Policy Entropy: 3.76845
Value Function Loss: 0.02002

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11879
Policy Update Magnitude: 0.45871
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 21,071.25275
Overall Steps per Second: 10,170.09110

Timestep Collection Time: 2.37376
Timestep Consumption Time: 2.54439
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.91815

Cumulative Model Updates: 165,492
Cumulative Timesteps: 1,380,018,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,334.75735
Policy Entropy: 3.76632
Value Function Loss: 0.02162

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.45835
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 20,632.02807
Overall Steps per Second: 9,913.78515

Timestep Collection Time: 2.42439
Timestep Consumption Time: 2.62111
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 5.04550

Cumulative Model Updates: 165,498
Cumulative Timesteps: 1,380,068,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1380068762...
Checkpoint 1380068762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,292.04265
Policy Entropy: 3.77661
Value Function Loss: 0.02352

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.47894
Value Function Update Magnitude: 0.60286

Collected Steps per Second: 21,298.08829
Overall Steps per Second: 10,380.30123

Timestep Collection Time: 2.34866
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.81894

Cumulative Model Updates: 165,504
Cumulative Timesteps: 1,380,118,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,272.92465
Policy Entropy: 3.77643
Value Function Loss: 0.02299

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.48326
Value Function Update Magnitude: 0.52134

Collected Steps per Second: 20,943.46570
Overall Steps per Second: 10,285.21573

Timestep Collection Time: 2.38872
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.86407

Cumulative Model Updates: 165,510
Cumulative Timesteps: 1,380,168,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1380168812...
Checkpoint 1380168812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288,105.86189
Policy Entropy: 3.76600
Value Function Loss: 0.02570

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.46908
Value Function Update Magnitude: 0.52739

Collected Steps per Second: 20,316.04268
Overall Steps per Second: 9,993.90689

Timestep Collection Time: 2.46150
Timestep Consumption Time: 2.54235
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 5.00385

Cumulative Model Updates: 165,516
Cumulative Timesteps: 1,380,218,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,470.45204
Policy Entropy: 3.77175
Value Function Loss: 0.02354

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.47330
Value Function Update Magnitude: 0.68125

Collected Steps per Second: 20,987.58269
Overall Steps per Second: 10,319.82483

Timestep Collection Time: 2.38360
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.84756

Cumulative Model Updates: 165,522
Cumulative Timesteps: 1,380,268,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1380268846...
Checkpoint 1380268846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,674.58957
Policy Entropy: 3.75996
Value Function Loss: 0.02402

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.45362
Value Function Update Magnitude: 0.67213

Collected Steps per Second: 20,745.16830
Overall Steps per Second: 10,208.62684

Timestep Collection Time: 2.41049
Timestep Consumption Time: 2.48792
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.89841

Cumulative Model Updates: 165,528
Cumulative Timesteps: 1,380,318,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,397.16616
Policy Entropy: 3.76331
Value Function Loss: 0.02377

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.45790
Value Function Update Magnitude: 0.64337

Collected Steps per Second: 20,801.63632
Overall Steps per Second: 10,031.62573

Timestep Collection Time: 2.40520
Timestep Consumption Time: 2.58223
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.98743

Cumulative Model Updates: 165,534
Cumulative Timesteps: 1,380,368,884

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1380368884...
Checkpoint 1380368884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,720.23295
Policy Entropy: 3.77358
Value Function Loss: 0.02602

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.48488
Value Function Update Magnitude: 0.72351

Collected Steps per Second: 20,823.96630
Overall Steps per Second: 10,232.47270

Timestep Collection Time: 2.40204
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.88836

Cumulative Model Updates: 165,540
Cumulative Timesteps: 1,380,418,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,579.58764
Policy Entropy: 3.79885
Value Function Loss: 0.02780

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.50280
Value Function Update Magnitude: 0.66650

Collected Steps per Second: 20,872.22782
Overall Steps per Second: 10,073.01101

Timestep Collection Time: 2.39687
Timestep Consumption Time: 2.56967
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.96654

Cumulative Model Updates: 165,546
Cumulative Timesteps: 1,380,468,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1380468932...
Checkpoint 1380468932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,740.73142
Policy Entropy: 3.80347
Value Function Loss: 0.02634

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11783
Policy Update Magnitude: 0.50882
Value Function Update Magnitude: 0.60790

Collected Steps per Second: 20,829.51214
Overall Steps per Second: 10,205.46994

Timestep Collection Time: 2.40054
Timestep Consumption Time: 2.49899
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.89953

Cumulative Model Updates: 165,552
Cumulative Timesteps: 1,380,518,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,997.50405
Policy Entropy: 3.77962
Value Function Loss: 0.02321

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.48932
Value Function Update Magnitude: 0.64358

Collected Steps per Second: 20,747.62689
Overall Steps per Second: 10,006.68992

Timestep Collection Time: 2.41184
Timestep Consumption Time: 2.58881
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 5.00065

Cumulative Model Updates: 165,558
Cumulative Timesteps: 1,380,568,974

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1380568974...
Checkpoint 1380568974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,024.68980
Policy Entropy: 3.76060
Value Function Loss: 0.02140

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.53623

Collected Steps per Second: 20,265.07401
Overall Steps per Second: 9,924.13495

Timestep Collection Time: 2.46799
Timestep Consumption Time: 2.57164
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 5.03963

Cumulative Model Updates: 165,564
Cumulative Timesteps: 1,380,618,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,256.38610
Policy Entropy: 3.76123
Value Function Loss: 0.02324

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.40824
Value Function Update Magnitude: 0.45763

Collected Steps per Second: 20,727.83677
Overall Steps per Second: 10,099.29520

Timestep Collection Time: 2.41357
Timestep Consumption Time: 2.54005
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.95361

Cumulative Model Updates: 165,570
Cumulative Timesteps: 1,380,669,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1380669016...
Checkpoint 1380669016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,318.45355
Policy Entropy: 3.78185
Value Function Loss: 0.02213

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.41211
Value Function Update Magnitude: 0.45284

Collected Steps per Second: 20,914.75341
Overall Steps per Second: 10,136.14657

Timestep Collection Time: 2.39094
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.93343

Cumulative Model Updates: 165,576
Cumulative Timesteps: 1,380,719,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,974.57544
Policy Entropy: 3.77270
Value Function Loss: 0.02326

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12059
Policy Update Magnitude: 0.41886
Value Function Update Magnitude: 0.46508

Collected Steps per Second: 20,703.09910
Overall Steps per Second: 10,034.35573

Timestep Collection Time: 2.41606
Timestep Consumption Time: 2.56881
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.98487

Cumulative Model Updates: 165,582
Cumulative Timesteps: 1,380,769,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1380769042...
Checkpoint 1380769042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,324.80662
Policy Entropy: 3.77359
Value Function Loss: 0.02088

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12304
Policy Update Magnitude: 0.41320
Value Function Update Magnitude: 0.45075

Collected Steps per Second: 20,884.76491
Overall Steps per Second: 10,190.02899

Timestep Collection Time: 2.39533
Timestep Consumption Time: 2.51397
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.90931

Cumulative Model Updates: 165,588
Cumulative Timesteps: 1,380,819,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,211.53152
Policy Entropy: 3.75568
Value Function Loss: 0.02226

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.41536
Value Function Update Magnitude: 0.44901

Collected Steps per Second: 20,962.52128
Overall Steps per Second: 10,178.59164

Timestep Collection Time: 2.38674
Timestep Consumption Time: 2.52868
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.91541

Cumulative Model Updates: 165,594
Cumulative Timesteps: 1,380,869,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1380869100...
Checkpoint 1380869100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,099.01081
Policy Entropy: 3.76437
Value Function Loss: 0.02062

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.41384
Value Function Update Magnitude: 0.46693

Collected Steps per Second: 20,808.98984
Overall Steps per Second: 10,036.68746

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.57933
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.98252

Cumulative Model Updates: 165,600
Cumulative Timesteps: 1,380,919,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,637.88174
Policy Entropy: 3.75450
Value Function Loss: 0.02065

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.41288
Value Function Update Magnitude: 0.45933

Collected Steps per Second: 20,320.43507
Overall Steps per Second: 10,106.62046

Timestep Collection Time: 2.46127
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.94864

Cumulative Model Updates: 165,606
Cumulative Timesteps: 1,380,969,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1380969122...
Checkpoint 1380969122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,581.15577
Policy Entropy: 3.77073
Value Function Loss: 0.01962

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.37553
Value Function Update Magnitude: 0.43283

Collected Steps per Second: 19,992.09063
Overall Steps per Second: 10,170.06305

Timestep Collection Time: 2.50159
Timestep Consumption Time: 2.41598
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.91757

Cumulative Model Updates: 165,612
Cumulative Timesteps: 1,381,019,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,536.53494
Policy Entropy: 3.78811
Value Function Loss: 0.01925

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.36778
Value Function Update Magnitude: 0.46881

Collected Steps per Second: 20,471.61990
Overall Steps per Second: 10,195.73824

Timestep Collection Time: 2.44358
Timestep Consumption Time: 2.46279
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.90636

Cumulative Model Updates: 165,618
Cumulative Timesteps: 1,381,069,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1381069158...
Checkpoint 1381069158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,898.01677
Policy Entropy: 3.79771
Value Function Loss: 0.01719

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.37573
Value Function Update Magnitude: 0.49995

Collected Steps per Second: 20,325.60469
Overall Steps per Second: 10,141.82351

Timestep Collection Time: 2.46064
Timestep Consumption Time: 2.47082
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.93146

Cumulative Model Updates: 165,624
Cumulative Timesteps: 1,381,119,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,358.05965
Policy Entropy: 3.77532
Value Function Loss: 0.01623

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.38572
Value Function Update Magnitude: 0.52203

Collected Steps per Second: 20,310.27736
Overall Steps per Second: 10,029.32490

Timestep Collection Time: 2.46230
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.98638

Cumulative Model Updates: 165,630
Cumulative Timesteps: 1,381,169,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1381169182...
Checkpoint 1381169182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,358.05965
Policy Entropy: 3.74858
Value Function Loss: 0.01638

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.41447
Value Function Update Magnitude: 0.53602

Collected Steps per Second: 20,728.51464
Overall Steps per Second: 10,180.50058

Timestep Collection Time: 2.41329
Timestep Consumption Time: 2.50041
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.91371

Cumulative Model Updates: 165,636
Cumulative Timesteps: 1,381,219,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,909.95300
Policy Entropy: 3.75767
Value Function Loss: 0.02246

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.43583
Value Function Update Magnitude: 0.57047

Collected Steps per Second: 20,563.18343
Overall Steps per Second: 10,027.17894

Timestep Collection Time: 2.43260
Timestep Consumption Time: 2.55604
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.98864

Cumulative Model Updates: 165,642
Cumulative Timesteps: 1,381,269,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1381269228...
Checkpoint 1381269228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.48563
Policy Entropy: 3.80033
Value Function Loss: 0.02289

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.46881
Value Function Update Magnitude: 0.57460

Collected Steps per Second: 20,774.97729
Overall Steps per Second: 10,360.65567

Timestep Collection Time: 2.40674
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.82595

Cumulative Model Updates: 165,648
Cumulative Timesteps: 1,381,319,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,447.25128
Policy Entropy: 3.80339
Value Function Loss: 0.02643

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.49295

Collected Steps per Second: 20,972.51926
Overall Steps per Second: 10,279.97121

Timestep Collection Time: 2.38560
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.86694

Cumulative Model Updates: 165,654
Cumulative Timesteps: 1,381,369,260

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1381369260...
Checkpoint 1381369260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,051.10661
Policy Entropy: 3.80264
Value Function Loss: 0.02166

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.47181
Value Function Update Magnitude: 0.48251

Collected Steps per Second: 20,736.45896
Overall Steps per Second: 10,244.65887

Timestep Collection Time: 2.41208
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.88235

Cumulative Model Updates: 165,660
Cumulative Timesteps: 1,381,419,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,453.24659
Policy Entropy: 3.77334
Value Function Loss: 0.02374

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.46196
Value Function Update Magnitude: 0.42450

Collected Steps per Second: 20,687.29167
Overall Steps per Second: 10,027.47185

Timestep Collection Time: 2.41897
Timestep Consumption Time: 2.57152
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.99049

Cumulative Model Updates: 165,666
Cumulative Timesteps: 1,381,469,320

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1381469320...
Checkpoint 1381469320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,987.23017
Policy Entropy: 3.77497
Value Function Loss: 0.02259

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.47849
Value Function Update Magnitude: 0.44971

Collected Steps per Second: 20,729.16330
Overall Steps per Second: 10,205.69238

Timestep Collection Time: 2.41312
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.90138

Cumulative Model Updates: 165,672
Cumulative Timesteps: 1,381,519,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,650.65174
Policy Entropy: 3.77705
Value Function Loss: 0.02183

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.47605
Value Function Update Magnitude: 0.51245

Collected Steps per Second: 20,616.93481
Overall Steps per Second: 10,191.50109

Timestep Collection Time: 2.42558
Timestep Consumption Time: 2.48125
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.90683

Cumulative Model Updates: 165,678
Cumulative Timesteps: 1,381,569,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1381569350...
Checkpoint 1381569350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,650.65174
Policy Entropy: 3.77268
Value Function Loss: 0.01708

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.42822
Value Function Update Magnitude: 0.48408

Collected Steps per Second: 20,862.40881
Overall Steps per Second: 10,149.30317

Timestep Collection Time: 2.39800
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.92921

Cumulative Model Updates: 165,684
Cumulative Timesteps: 1,381,619,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,451.61860
Policy Entropy: 3.76359
Value Function Loss: 0.01991

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.39081
Value Function Update Magnitude: 0.42068

Collected Steps per Second: 20,810.28730
Overall Steps per Second: 10,087.77949

Timestep Collection Time: 2.40352
Timestep Consumption Time: 2.55475
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.95828

Cumulative Model Updates: 165,690
Cumulative Timesteps: 1,381,669,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1381669396...
Checkpoint 1381669396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,380.55693
Policy Entropy: 3.78249
Value Function Loss: 0.02229

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.41565
Value Function Update Magnitude: 0.43463

Collected Steps per Second: 20,621.11725
Overall Steps per Second: 10,225.32349

Timestep Collection Time: 2.42538
Timestep Consumption Time: 2.46581
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.89119

Cumulative Model Updates: 165,696
Cumulative Timesteps: 1,381,719,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,987.00047
Policy Entropy: 3.79416
Value Function Loss: 0.02291

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.46164
Value Function Update Magnitude: 0.50297

Collected Steps per Second: 20,734.33431
Overall Steps per Second: 10,047.16803

Timestep Collection Time: 2.41271
Timestep Consumption Time: 2.56640
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.97911

Cumulative Model Updates: 165,702
Cumulative Timesteps: 1,381,769,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1381769436...
Checkpoint 1381769436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,918.63871
Policy Entropy: 3.81243
Value Function Loss: 0.02150

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.47858
Value Function Update Magnitude: 0.54120

Collected Steps per Second: 20,915.35551
Overall Steps per Second: 10,177.78100

Timestep Collection Time: 2.39059
Timestep Consumption Time: 2.52207
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.91266

Cumulative Model Updates: 165,708
Cumulative Timesteps: 1,381,819,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,583.79196
Policy Entropy: 3.80343
Value Function Loss: 0.02049

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.46769
Value Function Update Magnitude: 0.47990

Collected Steps per Second: 20,429.60515
Overall Steps per Second: 10,045.94005

Timestep Collection Time: 2.44753
Timestep Consumption Time: 2.52981
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.97733

Cumulative Model Updates: 165,714
Cumulative Timesteps: 1,381,869,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1381869438...
Checkpoint 1381869438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,121.58716
Policy Entropy: 3.81546
Value Function Loss: 0.02045

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.46677
Value Function Update Magnitude: 0.46594

Collected Steps per Second: 20,648.65764
Overall Steps per Second: 10,142.34503

Timestep Collection Time: 2.42243
Timestep Consumption Time: 2.50936
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.93180

Cumulative Model Updates: 165,720
Cumulative Timesteps: 1,381,919,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.99793
Policy Entropy: 3.79897
Value Function Loss: 0.02216

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.45915
Value Function Update Magnitude: 0.45800

Collected Steps per Second: 20,535.06639
Overall Steps per Second: 10,136.04227

Timestep Collection Time: 2.43535
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.93388

Cumulative Model Updates: 165,726
Cumulative Timesteps: 1,381,969,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1381969468...
Checkpoint 1381969468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,821.06768
Policy Entropy: 3.81135
Value Function Loss: 0.02451

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.46603
Value Function Update Magnitude: 0.42685

Collected Steps per Second: 21,062.15686
Overall Steps per Second: 10,274.80714

Timestep Collection Time: 2.37507
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.86861

Cumulative Model Updates: 165,732
Cumulative Timesteps: 1,382,019,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,493.28922
Policy Entropy: 3.79797
Value Function Loss: 0.02871

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.47126
Value Function Update Magnitude: 0.55685

Collected Steps per Second: 20,920.63686
Overall Steps per Second: 10,164.96441

Timestep Collection Time: 2.39056
Timestep Consumption Time: 2.52948
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.92004

Cumulative Model Updates: 165,738
Cumulative Timesteps: 1,382,069,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1382069504...
Checkpoint 1382069504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,224.08997
Policy Entropy: 3.79405
Value Function Loss: 0.02860

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.50828
Value Function Update Magnitude: 0.66307

Collected Steps per Second: 20,604.70805
Overall Steps per Second: 10,351.95723

Timestep Collection Time: 2.42682
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.83039

Cumulative Model Updates: 165,744
Cumulative Timesteps: 1,382,119,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,149.22823
Policy Entropy: 3.77481
Value Function Loss: 0.02756

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.72167

Collected Steps per Second: 19,934.95099
Overall Steps per Second: 10,009.03867

Timestep Collection Time: 2.50946
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.99808

Cumulative Model Updates: 165,750
Cumulative Timesteps: 1,382,169,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1382169534...
Checkpoint 1382169534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,847.39681
Policy Entropy: 3.76195
Value Function Loss: 0.02521

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.51758
Value Function Update Magnitude: 0.68457

Collected Steps per Second: 20,287.03132
Overall Steps per Second: 10,279.08214

Timestep Collection Time: 2.46542
Timestep Consumption Time: 2.40039
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.86580

Cumulative Model Updates: 165,756
Cumulative Timesteps: 1,382,219,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,192.61172
Policy Entropy: 3.77864
Value Function Loss: 0.02287

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.55806

Collected Steps per Second: 19,855.39756
Overall Steps per Second: 10,029.39823

Timestep Collection Time: 2.51841
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.98574

Cumulative Model Updates: 165,762
Cumulative Timesteps: 1,382,269,554

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1382269554...
Checkpoint 1382269554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,359.93616
Policy Entropy: 3.76976
Value Function Loss: 0.02382

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.46248
Value Function Update Magnitude: 0.48165

Collected Steps per Second: 20,996.67979
Overall Steps per Second: 10,353.83976

Timestep Collection Time: 2.38190
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.83029

Cumulative Model Updates: 165,768
Cumulative Timesteps: 1,382,319,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,060.10491
Policy Entropy: 3.77897
Value Function Loss: 0.02379

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.48693
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 20,651.13440
Overall Steps per Second: 10,142.37768

Timestep Collection Time: 2.42117
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.92981

Cumulative Model Updates: 165,774
Cumulative Timesteps: 1,382,369,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1382369566...
Checkpoint 1382369566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,138.71215
Policy Entropy: 3.78268
Value Function Loss: 0.02227

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.48705
Value Function Update Magnitude: 0.64292

Collected Steps per Second: 20,890.83492
Overall Steps per Second: 10,168.70672

Timestep Collection Time: 2.39406
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.91842

Cumulative Model Updates: 165,780
Cumulative Timesteps: 1,382,419,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,687.39562
Policy Entropy: 3.77560
Value Function Loss: 0.02277

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.45740
Value Function Update Magnitude: 0.52018

Collected Steps per Second: 20,771.93612
Overall Steps per Second: 10,106.98738

Timestep Collection Time: 2.40748
Timestep Consumption Time: 2.54039
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.94786

Cumulative Model Updates: 165,786
Cumulative Timesteps: 1,382,469,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1382469588...
Checkpoint 1382469588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,998.77803
Policy Entropy: 3.78928
Value Function Loss: 0.02099

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.47659
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 20,676.19824
Overall Steps per Second: 10,055.16348

Timestep Collection Time: 2.41911
Timestep Consumption Time: 2.55525
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.97436

Cumulative Model Updates: 165,792
Cumulative Timesteps: 1,382,519,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,854.82776
Policy Entropy: 3.75976
Value Function Loss: 0.02200

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.51390
Value Function Update Magnitude: 0.54105

Collected Steps per Second: 20,606.10666
Overall Steps per Second: 10,038.87756

Timestep Collection Time: 2.42685
Timestep Consumption Time: 2.55458
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.98143

Cumulative Model Updates: 165,798
Cumulative Timesteps: 1,382,569,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1382569614...
Checkpoint 1382569614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,130.20647
Policy Entropy: 3.77260
Value Function Loss: 0.02198

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.51435
Value Function Update Magnitude: 0.48507

Collected Steps per Second: 20,961.22362
Overall Steps per Second: 10,155.89782

Timestep Collection Time: 2.38650
Timestep Consumption Time: 2.53911
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.92561

Cumulative Model Updates: 165,804
Cumulative Timesteps: 1,382,619,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,001.48588
Policy Entropy: 3.77193
Value Function Loss: 0.02031

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.48559
Value Function Update Magnitude: 0.44616

Collected Steps per Second: 20,766.69947
Overall Steps per Second: 10,110.81340

Timestep Collection Time: 2.40828
Timestep Consumption Time: 2.53811
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.94639

Cumulative Model Updates: 165,810
Cumulative Timesteps: 1,382,669,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1382669650...
Checkpoint 1382669650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,027.97329
Policy Entropy: 3.79233
Value Function Loss: 0.02548

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.51079
Value Function Update Magnitude: 0.57161

Collected Steps per Second: 19,989.44387
Overall Steps per Second: 10,106.23956

Timestep Collection Time: 2.50262
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.95001

Cumulative Model Updates: 165,816
Cumulative Timesteps: 1,382,719,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,882.60657
Policy Entropy: 3.80302
Value Function Loss: 0.02537

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.68272

Collected Steps per Second: 20,094.33975
Overall Steps per Second: 10,044.66865

Timestep Collection Time: 2.48926
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.97976

Cumulative Model Updates: 165,822
Cumulative Timesteps: 1,382,769,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1382769696...
Checkpoint 1382769696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,808.29258
Policy Entropy: 3.78505
Value Function Loss: 0.02757

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.56632
Value Function Update Magnitude: 0.67787

Collected Steps per Second: 20,049.09993
Overall Steps per Second: 10,238.56822

Timestep Collection Time: 2.49507
Timestep Consumption Time: 2.39076
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.88584

Cumulative Model Updates: 165,828
Cumulative Timesteps: 1,382,819,720

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,123.89157
Policy Entropy: 3.80407
Value Function Loss: 0.02435

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.51958
Value Function Update Magnitude: 0.54396

Collected Steps per Second: 20,127.50478
Overall Steps per Second: 10,111.02008

Timestep Collection Time: 2.48496
Timestep Consumption Time: 2.46172
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.94668

Cumulative Model Updates: 165,834
Cumulative Timesteps: 1,382,869,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1382869736...
Checkpoint 1382869736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,578.21044
Policy Entropy: 3.79567
Value Function Loss: 0.02435

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.50176
Value Function Update Magnitude: 0.56745

Collected Steps per Second: 20,147.66358
Overall Steps per Second: 10,224.25482

Timestep Collection Time: 2.48207
Timestep Consumption Time: 2.40904
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.89111

Cumulative Model Updates: 165,840
Cumulative Timesteps: 1,382,919,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,908.83389
Policy Entropy: 3.80796
Value Function Loss: 0.02337

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.51627
Value Function Update Magnitude: 0.65096

Collected Steps per Second: 20,355.60920
Overall Steps per Second: 10,043.79863

Timestep Collection Time: 2.45780
Timestep Consumption Time: 2.52338
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.98118

Cumulative Model Updates: 165,846
Cumulative Timesteps: 1,382,969,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1382969774...
Checkpoint 1382969774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,593.98763
Policy Entropy: 3.79211
Value Function Loss: 0.02247

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.50460
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 20,397.27251
Overall Steps per Second: 10,138.42845

Timestep Collection Time: 2.45199
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.93311

Cumulative Model Updates: 165,852
Cumulative Timesteps: 1,383,019,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,076.84355
Policy Entropy: 3.78264
Value Function Loss: 0.02329

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.47647
Value Function Update Magnitude: 0.61419

Collected Steps per Second: 19,695.03381
Overall Steps per Second: 10,042.69541

Timestep Collection Time: 2.53881
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.97894

Cumulative Model Updates: 165,858
Cumulative Timesteps: 1,383,069,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1383069790...
Checkpoint 1383069790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,321.85170
Policy Entropy: 3.79987
Value Function Loss: 0.02259

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.47451
Value Function Update Magnitude: 0.60780

Collected Steps per Second: 20,914.75056
Overall Steps per Second: 10,240.47252

Timestep Collection Time: 2.39085
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.88298

Cumulative Model Updates: 165,864
Cumulative Timesteps: 1,383,119,794

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,927.86233
Policy Entropy: 3.78613
Value Function Loss: 0.02454

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.49752
Value Function Update Magnitude: 0.67070

Collected Steps per Second: 20,302.24091
Overall Steps per Second: 10,131.68599

Timestep Collection Time: 2.46347
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.93639

Cumulative Model Updates: 165,870
Cumulative Timesteps: 1,383,169,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1383169808...
Checkpoint 1383169808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,974.80821
Policy Entropy: 3.79195
Value Function Loss: 0.02407

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.48693
Value Function Update Magnitude: 0.59570

Collected Steps per Second: 20,935.78980
Overall Steps per Second: 10,147.08260

Timestep Collection Time: 2.38959
Timestep Consumption Time: 2.54069
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.93028

Cumulative Model Updates: 165,876
Cumulative Timesteps: 1,383,219,836

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,911.13256
Policy Entropy: 3.77392
Value Function Loss: 0.02462

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.45679
Value Function Update Magnitude: 0.63140

Collected Steps per Second: 20,650.29179
Overall Steps per Second: 10,078.25112

Timestep Collection Time: 2.42205
Timestep Consumption Time: 2.54072
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.96277

Cumulative Model Updates: 165,882
Cumulative Timesteps: 1,383,269,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1383269852...
Checkpoint 1383269852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,731.30979
Policy Entropy: 3.79389
Value Function Loss: 0.02339

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13332
Policy Update Magnitude: 0.46927
Value Function Update Magnitude: 0.69660

Collected Steps per Second: 20,858.56805
Overall Steps per Second: 10,248.60709

Timestep Collection Time: 2.39815
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.88086

Cumulative Model Updates: 165,888
Cumulative Timesteps: 1,383,319,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,139.63700
Policy Entropy: 3.78458
Value Function Loss: 0.02365

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.47347
Value Function Update Magnitude: 0.71029

Collected Steps per Second: 20,701.26294
Overall Steps per Second: 10,094.35620

Timestep Collection Time: 2.41628
Timestep Consumption Time: 2.53897
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.95524

Cumulative Model Updates: 165,894
Cumulative Timesteps: 1,383,369,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1383369894...
Checkpoint 1383369894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,265.48366
Policy Entropy: 3.79028
Value Function Loss: 0.02218

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.48100
Value Function Update Magnitude: 0.70096

Collected Steps per Second: 20,546.88135
Overall Steps per Second: 10,123.84561

Timestep Collection Time: 2.43492
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.94180

Cumulative Model Updates: 165,900
Cumulative Timesteps: 1,383,419,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,618.35179
Policy Entropy: 3.78300
Value Function Loss: 0.02101

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.45499
Value Function Update Magnitude: 0.66990

Collected Steps per Second: 20,569.27320
Overall Steps per Second: 10,064.54390

Timestep Collection Time: 2.43188
Timestep Consumption Time: 2.53824
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.97012

Cumulative Model Updates: 165,906
Cumulative Timesteps: 1,383,469,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1383469946...
Checkpoint 1383469946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,488.42642
Policy Entropy: 3.77617
Value Function Loss: 0.01829

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.42805
Value Function Update Magnitude: 0.58346

Collected Steps per Second: 20,785.51366
Overall Steps per Second: 10,144.29756

Timestep Collection Time: 2.40552
Timestep Consumption Time: 2.52336
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.92888

Cumulative Model Updates: 165,912
Cumulative Timesteps: 1,383,519,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,574.51128
Policy Entropy: 3.76244
Value Function Loss: 0.01735

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.41962
Value Function Update Magnitude: 0.51027

Collected Steps per Second: 20,290.57822
Overall Steps per Second: 10,021.43153

Timestep Collection Time: 2.46508
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.99110

Cumulative Model Updates: 165,918
Cumulative Timesteps: 1,383,569,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1383569964...
Checkpoint 1383569964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,574.51128
Policy Entropy: 3.74635
Value Function Loss: 0.01881

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.44079
Value Function Update Magnitude: 0.44666

Collected Steps per Second: 20,444.04819
Overall Steps per Second: 10,184.61135

Timestep Collection Time: 2.44648
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.91094

Cumulative Model Updates: 165,924
Cumulative Timesteps: 1,383,619,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,237.88208
Policy Entropy: 3.77459
Value Function Loss: 0.01784

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.46481
Value Function Update Magnitude: 0.54386

Collected Steps per Second: 20,521.73515
Overall Steps per Second: 10,104.78161

Timestep Collection Time: 2.43771
Timestep Consumption Time: 2.51302
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.95073

Cumulative Model Updates: 165,930
Cumulative Timesteps: 1,383,670,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1383670006...
Checkpoint 1383670006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,531.67051
Policy Entropy: 3.77948
Value Function Loss: 0.01864

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.45889
Value Function Update Magnitude: 0.54432

Collected Steps per Second: 20,560.43839
Overall Steps per Second: 10,190.55158

Timestep Collection Time: 2.43322
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.90925

Cumulative Model Updates: 165,936
Cumulative Timesteps: 1,383,720,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,154.04626
Policy Entropy: 3.80010
Value Function Loss: 0.01930

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.58447

Collected Steps per Second: 20,806.48373
Overall Steps per Second: 10,093.40414

Timestep Collection Time: 2.40444
Timestep Consumption Time: 2.55206
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.95650

Cumulative Model Updates: 165,942
Cumulative Timesteps: 1,383,770,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1383770062...
Checkpoint 1383770062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,019.99082
Policy Entropy: 3.80543
Value Function Loss: 0.02125

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.44751
Value Function Update Magnitude: 0.61682

Collected Steps per Second: 20,007.77978
Overall Steps per Second: 10,190.13153

Timestep Collection Time: 2.50033
Timestep Consumption Time: 2.40893
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.90926

Cumulative Model Updates: 165,948
Cumulative Timesteps: 1,383,820,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,889.07489
Policy Entropy: 3.81286
Value Function Loss: 0.02115

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.49402
Value Function Update Magnitude: 0.58713

Collected Steps per Second: 20,135.78730
Overall Steps per Second: 10,067.64453

Timestep Collection Time: 2.48334
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.96680

Cumulative Model Updates: 165,954
Cumulative Timesteps: 1,383,870,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1383870092...
Checkpoint 1383870092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,813.46959
Policy Entropy: 3.81399
Value Function Loss: 0.02156

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.50341
Value Function Update Magnitude: 0.58136

Collected Steps per Second: 19,628.04028
Overall Steps per Second: 10,128.79562

Timestep Collection Time: 2.54870
Timestep Consumption Time: 2.39029
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.93899

Cumulative Model Updates: 165,960
Cumulative Timesteps: 1,383,920,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,347.09131
Policy Entropy: 3.78729
Value Function Loss: 0.02238

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.53459

Collected Steps per Second: 20,042.10525
Overall Steps per Second: 10,043.25789

Timestep Collection Time: 2.49575
Timestep Consumption Time: 2.48471
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.98046

Cumulative Model Updates: 165,966
Cumulative Timesteps: 1,383,970,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1383970138...
Checkpoint 1383970138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,160.91953
Policy Entropy: 3.78325
Value Function Loss: 0.02083

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.49015
Value Function Update Magnitude: 0.49161

Collected Steps per Second: 20,119.22285
Overall Steps per Second: 9,983.75075

Timestep Collection Time: 2.48578
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 5.00934

Cumulative Model Updates: 165,972
Cumulative Timesteps: 1,384,020,150

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,654.89576
Policy Entropy: 3.77056
Value Function Loss: 0.02038

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.46135
Value Function Update Magnitude: 0.46557

Collected Steps per Second: 20,605.90031
Overall Steps per Second: 10,075.09773

Timestep Collection Time: 2.42736
Timestep Consumption Time: 2.53715
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.96452

Cumulative Model Updates: 165,978
Cumulative Timesteps: 1,384,070,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1384070168...
Checkpoint 1384070168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.44444
Policy Entropy: 3.77932
Value Function Loss: 0.01819

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.44566
Value Function Update Magnitude: 0.42195

Collected Steps per Second: 20,571.31398
Overall Steps per Second: 10,095.42129

Timestep Collection Time: 2.43144
Timestep Consumption Time: 2.52308
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.95452

Cumulative Model Updates: 165,984
Cumulative Timesteps: 1,384,120,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,821.51515
Policy Entropy: 3.77110
Value Function Loss: 0.02109

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.43945
Value Function Update Magnitude: 0.38740

Collected Steps per Second: 20,588.35536
Overall Steps per Second: 10,034.90877

Timestep Collection Time: 2.43001
Timestep Consumption Time: 2.55558
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.98560

Cumulative Model Updates: 165,990
Cumulative Timesteps: 1,384,170,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1384170216...
Checkpoint 1384170216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,657.53431
Policy Entropy: 3.77281
Value Function Loss: 0.02035

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.47314
Value Function Update Magnitude: 0.41671

Collected Steps per Second: 20,955.26516
Overall Steps per Second: 10,215.37469

Timestep Collection Time: 2.38699
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.89654

Cumulative Model Updates: 165,996
Cumulative Timesteps: 1,384,220,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,819.83994
Policy Entropy: 3.76874
Value Function Loss: 0.01993

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.45595
Value Function Update Magnitude: 0.45233

Collected Steps per Second: 20,676.64302
Overall Steps per Second: 10,046.05607

Timestep Collection Time: 2.41954
Timestep Consumption Time: 2.56032
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.97986

Cumulative Model Updates: 166,002
Cumulative Timesteps: 1,384,270,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1384270264...
Checkpoint 1384270264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,168.27479
Policy Entropy: 3.78082
Value Function Loss: 0.02336

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.45318
Value Function Update Magnitude: 0.44447

Collected Steps per Second: 20,878.13729
Overall Steps per Second: 10,282.08030

Timestep Collection Time: 2.39581
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.86477

Cumulative Model Updates: 166,008
Cumulative Timesteps: 1,384,320,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,779.19578
Policy Entropy: 3.79516
Value Function Loss: 0.02467

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.51721
Value Function Update Magnitude: 0.43719

Collected Steps per Second: 20,687.81163
Overall Steps per Second: 10,056.61909

Timestep Collection Time: 2.41814
Timestep Consumption Time: 2.55630
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.97444

Cumulative Model Updates: 166,014
Cumulative Timesteps: 1,384,370,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1384370310...
Checkpoint 1384370310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,695.20307
Policy Entropy: 3.78390
Value Function Loss: 0.02569

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.50957
Value Function Update Magnitude: 0.48751

Collected Steps per Second: 21,014.00827
Overall Steps per Second: 10,137.14441

Timestep Collection Time: 2.37937
Timestep Consumption Time: 2.55299
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.93236

Cumulative Model Updates: 166,020
Cumulative Timesteps: 1,384,420,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,832.91151
Policy Entropy: 3.76191
Value Function Loss: 0.02147

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.44154
Value Function Update Magnitude: 0.39446

Collected Steps per Second: 20,895.32015
Overall Steps per Second: 10,116.03922

Timestep Collection Time: 2.39412
Timestep Consumption Time: 2.55109
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.94522

Cumulative Model Updates: 166,026
Cumulative Timesteps: 1,384,470,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1384470336...
Checkpoint 1384470336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,054.11872
Policy Entropy: 3.73850
Value Function Loss: 0.02260

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.40557
Value Function Update Magnitude: 0.33698

Collected Steps per Second: 20,431.21999
Overall Steps per Second: 10,163.47130

Timestep Collection Time: 2.44782
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.92076

Cumulative Model Updates: 166,032
Cumulative Timesteps: 1,384,520,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,267.87933
Policy Entropy: 3.75050
Value Function Loss: 0.01856

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.39343
Value Function Update Magnitude: 0.32499

Collected Steps per Second: 20,246.89436
Overall Steps per Second: 10,183.02897

Timestep Collection Time: 2.46971
Timestep Consumption Time: 2.44081
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.91052

Cumulative Model Updates: 166,038
Cumulative Timesteps: 1,384,570,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1384570352...
Checkpoint 1384570352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,142.35741
Policy Entropy: 3.74617
Value Function Loss: 0.01983

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12390
Policy Update Magnitude: 0.39921
Value Function Update Magnitude: 0.39464

Collected Steps per Second: 20,352.09764
Overall Steps per Second: 10,176.54706

Timestep Collection Time: 2.45714
Timestep Consumption Time: 2.45690
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.91404

Cumulative Model Updates: 166,044
Cumulative Timesteps: 1,384,620,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,767.59496
Policy Entropy: 3.75269
Value Function Loss: 0.01732

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.42453
Value Function Update Magnitude: 0.45686

Collected Steps per Second: 20,285.78279
Overall Steps per Second: 10,077.33623

Timestep Collection Time: 2.46488
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.96183

Cumulative Model Updates: 166,050
Cumulative Timesteps: 1,384,670,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1384670362...
Checkpoint 1384670362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,164.63178
Policy Entropy: 3.74516
Value Function Loss: 0.02108

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.46298
Value Function Update Magnitude: 0.48145

Collected Steps per Second: 20,907.97705
Overall Steps per Second: 10,243.61035

Timestep Collection Time: 2.39153
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.88129

Cumulative Model Updates: 166,056
Cumulative Timesteps: 1,384,720,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,368.86690
Policy Entropy: 3.77229
Value Function Loss: 0.02343

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.47196
Value Function Update Magnitude: 0.39115

Collected Steps per Second: 20,785.76994
Overall Steps per Second: 10,170.66898

Timestep Collection Time: 2.40578
Timestep Consumption Time: 2.51091
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.91669

Cumulative Model Updates: 166,062
Cumulative Timesteps: 1,384,770,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1384770370...
Checkpoint 1384770370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,177.25609
Policy Entropy: 3.79964
Value Function Loss: 0.02584

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.38380

Collected Steps per Second: 20,754.69123
Overall Steps per Second: 10,293.79608

Timestep Collection Time: 2.41015
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.85943

Cumulative Model Updates: 166,068
Cumulative Timesteps: 1,384,820,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,716.50930
Policy Entropy: 3.81349
Value Function Loss: 0.02457

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.43214

Collected Steps per Second: 20,508.45493
Overall Steps per Second: 10,055.58159

Timestep Collection Time: 2.44007
Timestep Consumption Time: 2.53647
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.97654

Cumulative Model Updates: 166,074
Cumulative Timesteps: 1,384,870,434

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1384870434...
Checkpoint 1384870434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,132.81948
Policy Entropy: 3.79938
Value Function Loss: 0.02364

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.47203

Collected Steps per Second: 20,796.95411
Overall Steps per Second: 10,219.50152

Timestep Collection Time: 2.40545
Timestep Consumption Time: 2.48970
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.89515

Cumulative Model Updates: 166,080
Cumulative Timesteps: 1,384,920,460

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,862.83913
Policy Entropy: 3.77352
Value Function Loss: 0.02018

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.51851
Value Function Update Magnitude: 0.48019

Collected Steps per Second: 20,307.36028
Overall Steps per Second: 10,060.08573

Timestep Collection Time: 2.46265
Timestep Consumption Time: 2.50848
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.97113

Cumulative Model Updates: 166,086
Cumulative Timesteps: 1,384,970,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1384970470...
Checkpoint 1384970470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,377.90038
Policy Entropy: 3.76699
Value Function Loss: 0.01984

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.49108
Value Function Update Magnitude: 0.45279

Collected Steps per Second: 21,139.09341
Overall Steps per Second: 10,207.33499

Timestep Collection Time: 2.36595
Timestep Consumption Time: 2.53386
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.89981

Cumulative Model Updates: 166,092
Cumulative Timesteps: 1,385,020,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,612.84239
Policy Entropy: 3.77545
Value Function Loss: 0.02035

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12004
Policy Update Magnitude: 0.46459
Value Function Update Magnitude: 0.43260

Collected Steps per Second: 20,949.27447
Overall Steps per Second: 10,110.53606

Timestep Collection Time: 2.38672
Timestep Consumption Time: 2.55862
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.94534

Cumulative Model Updates: 166,098
Cumulative Timesteps: 1,385,070,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1385070484...
Checkpoint 1385070484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,498.61858
Policy Entropy: 3.78318
Value Function Loss: 0.02213

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.47867
Value Function Update Magnitude: 0.46581

Collected Steps per Second: 20,975.32537
Overall Steps per Second: 10,157.49581

Timestep Collection Time: 2.38480
Timestep Consumption Time: 2.53984
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.92464

Cumulative Model Updates: 166,104
Cumulative Timesteps: 1,385,120,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,173.97724
Policy Entropy: 3.77681
Value Function Loss: 0.02163

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11567
Policy Update Magnitude: 0.49262
Value Function Update Magnitude: 0.46727

Collected Steps per Second: 20,883.18730
Overall Steps per Second: 10,031.83245

Timestep Collection Time: 2.39504
Timestep Consumption Time: 2.59069
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.98573

Cumulative Model Updates: 166,110
Cumulative Timesteps: 1,385,170,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1385170522...
Checkpoint 1385170522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,993.12704
Policy Entropy: 3.76235
Value Function Loss: 0.02377

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.41291

Collected Steps per Second: 20,818.61114
Overall Steps per Second: 10,276.20290

Timestep Collection Time: 2.40199
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.86619

Cumulative Model Updates: 166,116
Cumulative Timesteps: 1,385,220,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,174.78402
Policy Entropy: 3.74741
Value Function Loss: 0.02269

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.51372
Value Function Update Magnitude: 0.41268

Collected Steps per Second: 20,823.59338
Overall Steps per Second: 10,137.49486

Timestep Collection Time: 2.40333
Timestep Consumption Time: 2.53339
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.93672

Cumulative Model Updates: 166,122
Cumulative Timesteps: 1,385,270,574

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1385270574...
Checkpoint 1385270574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,257.45222
Policy Entropy: 3.76296
Value Function Loss: 0.02131

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11659
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.52093

Collected Steps per Second: 20,740.44878
Overall Steps per Second: 10,106.67520

Timestep Collection Time: 2.41229
Timestep Consumption Time: 2.53810
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.95039

Cumulative Model Updates: 166,128
Cumulative Timesteps: 1,385,320,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,508.15736
Policy Entropy: 3.76956
Value Function Loss: 0.01978

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.46473
Value Function Update Magnitude: 0.51257

Collected Steps per Second: 20,979.73773
Overall Steps per Second: 10,119.99211

Timestep Collection Time: 2.38354
Timestep Consumption Time: 2.55777
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.94131

Cumulative Model Updates: 166,134
Cumulative Timesteps: 1,385,370,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1385370612...
Checkpoint 1385370612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,119.24322
Policy Entropy: 3.78892
Value Function Loss: 0.02091

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.49620

Collected Steps per Second: 21,184.33417
Overall Steps per Second: 10,225.05404

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.53002
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.89054

Cumulative Model Updates: 166,140
Cumulative Timesteps: 1,385,420,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,904.72075
Policy Entropy: 3.78748
Value Function Loss: 0.02471

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11952
Policy Update Magnitude: 0.51471
Value Function Update Magnitude: 0.46268

Collected Steps per Second: 20,961.47189
Overall Steps per Second: 10,289.06824

Timestep Collection Time: 2.38695
Timestep Consumption Time: 2.47588
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.86283

Cumulative Model Updates: 166,146
Cumulative Timesteps: 1,385,470,652

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1385470652...
Checkpoint 1385470652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,904.72075
Policy Entropy: 3.79088
Value Function Loss: 0.02131

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.52201
Value Function Update Magnitude: 0.45679

Collected Steps per Second: 20,011.97822
Overall Steps per Second: 9,881.12351

Timestep Collection Time: 2.49970
Timestep Consumption Time: 2.56288
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 5.06258

Cumulative Model Updates: 166,152
Cumulative Timesteps: 1,385,520,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,848.95357
Policy Entropy: 3.77092
Value Function Loss: 0.02177

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.47116
Value Function Update Magnitude: 0.39665

Collected Steps per Second: 20,960.53003
Overall Steps per Second: 10,117.88808

Timestep Collection Time: 2.38620
Timestep Consumption Time: 2.55712
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.94332

Cumulative Model Updates: 166,158
Cumulative Timesteps: 1,385,570,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1385570692...
Checkpoint 1385570692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,084.67107
Policy Entropy: 3.75844
Value Function Loss: 0.02171

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.45123
Value Function Update Magnitude: 0.35459

Collected Steps per Second: 21,119.56497
Overall Steps per Second: 10,164.59411

Timestep Collection Time: 2.36814
Timestep Consumption Time: 2.55228
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.92041

Cumulative Model Updates: 166,164
Cumulative Timesteps: 1,385,620,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,247.10163
Policy Entropy: 3.74909
Value Function Loss: 0.02094

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.44756
Value Function Update Magnitude: 0.39119

Collected Steps per Second: 20,902.56930
Overall Steps per Second: 10,150.68955

Timestep Collection Time: 2.39224
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.92617

Cumulative Model Updates: 166,170
Cumulative Timesteps: 1,385,670,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1385670710...
Checkpoint 1385670710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,325.16626
Policy Entropy: 3.75397
Value Function Loss: 0.01926

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.43188
Value Function Update Magnitude: 0.49432

Collected Steps per Second: 20,770.54046
Overall Steps per Second: 10,141.31937

Timestep Collection Time: 2.40831
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.93249

Cumulative Model Updates: 166,176
Cumulative Timesteps: 1,385,720,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,325.16626
Policy Entropy: 3.76253
Value Function Loss: 0.01753

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.41924
Value Function Update Magnitude: 0.46412

Collected Steps per Second: 21,145.96714
Overall Steps per Second: 10,334.84433

Timestep Collection Time: 2.36480
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.83858

Cumulative Model Updates: 166,182
Cumulative Timesteps: 1,385,770,738

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1385770738...
Checkpoint 1385770738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,325.16626
Policy Entropy: 3.75920
Value Function Loss: 0.01786

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.41446
Value Function Update Magnitude: 0.40128

Collected Steps per Second: 20,449.02341
Overall Steps per Second: 10,201.82413

Timestep Collection Time: 2.44647
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.90383

Cumulative Model Updates: 166,188
Cumulative Timesteps: 1,385,820,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,055.30230
Policy Entropy: 3.78008
Value Function Loss: 0.01811

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.46768
Value Function Update Magnitude: 0.53924

Collected Steps per Second: 20,264.73956
Overall Steps per Second: 10,140.45043

Timestep Collection Time: 2.46852
Timestep Consumption Time: 2.46459
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.93311

Cumulative Model Updates: 166,194
Cumulative Timesteps: 1,385,870,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1385870790...
Checkpoint 1385870790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,135.29345
Policy Entropy: 3.78626
Value Function Loss: 0.02182

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.53349
Value Function Update Magnitude: 0.68628

Collected Steps per Second: 20,528.43903
Overall Steps per Second: 10,201.86874

Timestep Collection Time: 2.43642
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.90263

Cumulative Model Updates: 166,200
Cumulative Timesteps: 1,385,920,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,137.36284
Policy Entropy: 3.80206
Value Function Loss: 0.02311

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.72836

Collected Steps per Second: 19,770.27543
Overall Steps per Second: 10,017.92877

Timestep Collection Time: 2.52915
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.99125

Cumulative Model Updates: 166,206
Cumulative Timesteps: 1,385,970,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1385970808...
Checkpoint 1385970808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,326.83045
Policy Entropy: 3.78529
Value Function Loss: 0.02496

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 20,029.61579
Overall Steps per Second: 10,225.22824

Timestep Collection Time: 2.49630
Timestep Consumption Time: 2.39356
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.88987

Cumulative Model Updates: 166,212
Cumulative Timesteps: 1,386,020,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,508.60494
Policy Entropy: 3.80011
Value Function Loss: 0.02194

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.52762

Collected Steps per Second: 20,017.78700
Overall Steps per Second: 10,032.17358

Timestep Collection Time: 2.49778
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.98396

Cumulative Model Updates: 166,218
Cumulative Timesteps: 1,386,070,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1386070808...
Checkpoint 1386070808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,079.21225
Policy Entropy: 3.78427
Value Function Loss: 0.02408

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.52897
Value Function Update Magnitude: 0.41924

Collected Steps per Second: 20,383.35005
Overall Steps per Second: 10,193.67390

Timestep Collection Time: 2.45475
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.90853

Cumulative Model Updates: 166,224
Cumulative Timesteps: 1,386,120,844

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,352.77152
Policy Entropy: 3.80192
Value Function Loss: 0.02127

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.49813
Value Function Update Magnitude: 0.36667

Collected Steps per Second: 20,961.41650
Overall Steps per Second: 10,214.48520

Timestep Collection Time: 2.38619
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.89677

Cumulative Model Updates: 166,230
Cumulative Timesteps: 1,386,170,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1386170862...
Checkpoint 1386170862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,949.10771
Policy Entropy: 3.78088
Value Function Loss: 0.02954

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.50476
Value Function Update Magnitude: 0.34911

Collected Steps per Second: 20,768.24312
Overall Steps per Second: 10,192.21768

Timestep Collection Time: 2.40820
Timestep Consumption Time: 2.49888
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.90708

Cumulative Model Updates: 166,236
Cumulative Timesteps: 1,386,220,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,154.07331
Policy Entropy: 3.79719
Value Function Loss: 0.02646

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.57985
Value Function Update Magnitude: 0.56528

Collected Steps per Second: 21,167.08262
Overall Steps per Second: 10,289.07657

Timestep Collection Time: 2.36358
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.86244

Cumulative Model Updates: 166,242
Cumulative Timesteps: 1,386,270,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1386270906...
Checkpoint 1386270906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,197.93550
Policy Entropy: 3.77045
Value Function Loss: 0.02739

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.61142
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 20,798.01929
Overall Steps per Second: 10,215.29119

Timestep Collection Time: 2.40456
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.89560

Cumulative Model Updates: 166,248
Cumulative Timesteps: 1,386,320,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,966.48797
Policy Entropy: 3.77143
Value Function Loss: 0.02151

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.56153
Value Function Update Magnitude: 0.55147

Collected Steps per Second: 20,908.14035
Overall Steps per Second: 10,091.27372

Timestep Collection Time: 2.39266
Timestep Consumption Time: 2.56470
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.95735

Cumulative Model Updates: 166,254
Cumulative Timesteps: 1,386,370,942

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1386370942...
Checkpoint 1386370942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,219.62317
Policy Entropy: 3.74903
Value Function Loss: 0.02069

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.50123
Value Function Update Magnitude: 0.42006

Collected Steps per Second: 20,727.49652
Overall Steps per Second: 10,209.21671

Timestep Collection Time: 2.41380
Timestep Consumption Time: 2.48687
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.90067

Cumulative Model Updates: 166,260
Cumulative Timesteps: 1,386,420,974

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,742.70326
Policy Entropy: 3.76360
Value Function Loss: 0.02043

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.47711
Value Function Update Magnitude: 0.34237

Collected Steps per Second: 21,036.84374
Overall Steps per Second: 10,188.53702

Timestep Collection Time: 2.37811
Timestep Consumption Time: 2.53211
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.91022

Cumulative Model Updates: 166,266
Cumulative Timesteps: 1,386,471,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1386471002...
Checkpoint 1386471002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,087.19134
Policy Entropy: 3.78372
Value Function Loss: 0.02108

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.45798
Value Function Update Magnitude: 0.42602

Collected Steps per Second: 20,930.46337
Overall Steps per Second: 10,163.75657

Timestep Collection Time: 2.38896
Timestep Consumption Time: 2.53068
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.91964

Cumulative Model Updates: 166,272
Cumulative Timesteps: 1,386,521,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280,118.18057
Policy Entropy: 3.79067
Value Function Loss: 0.02125

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.45899
Value Function Update Magnitude: 0.57737

Collected Steps per Second: 21,035.80584
Overall Steps per Second: 10,331.21026

Timestep Collection Time: 2.37718
Timestep Consumption Time: 2.46310
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.84028

Cumulative Model Updates: 166,278
Cumulative Timesteps: 1,386,571,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1386571010...
Checkpoint 1386571010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,355.33231
Policy Entropy: 3.79649
Value Function Loss: 0.02270

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.51351

Collected Steps per Second: 20,746.44660
Overall Steps per Second: 10,209.97824

Timestep Collection Time: 2.41140
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.89991

Cumulative Model Updates: 166,284
Cumulative Timesteps: 1,386,621,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,653.99617
Policy Entropy: 3.80658
Value Function Loss: 0.02011

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.56582

Collected Steps per Second: 20,917.54033
Overall Steps per Second: 10,101.81578

Timestep Collection Time: 2.39101
Timestep Consumption Time: 2.55998
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.95099

Cumulative Model Updates: 166,290
Cumulative Timesteps: 1,386,671,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1386671052...
Checkpoint 1386671052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,870.21832
Policy Entropy: 3.80491
Value Function Loss: 0.01965

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13772
Policy Update Magnitude: 0.60867
Value Function Update Magnitude: 0.64538

Collected Steps per Second: 20,894.28999
Overall Steps per Second: 10,167.45246

Timestep Collection Time: 2.39309
Timestep Consumption Time: 2.52476
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.91785

Cumulative Model Updates: 166,296
Cumulative Timesteps: 1,386,721,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,984.21783
Policy Entropy: 3.79976
Value Function Loss: 0.02051

Mean KL Divergence: 0.02346
SB3 Clip Fraction: 0.25412
Policy Update Magnitude: 0.51728
Value Function Update Magnitude: 0.57563

Collected Steps per Second: 20,516.24319
Overall Steps per Second: 10,060.58020

Timestep Collection Time: 2.43924
Timestep Consumption Time: 2.53503
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.97427

Cumulative Model Updates: 166,302
Cumulative Timesteps: 1,386,771,098

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1386771098...
Checkpoint 1386771098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,096.70653
Policy Entropy: 3.81332
Value Function Loss: 0.02936

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.16556
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 20,763.48257
Overall Steps per Second: 10,218.72208

Timestep Collection Time: 2.40942
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.89572

Cumulative Model Updates: 166,308
Cumulative Timesteps: 1,386,821,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.61028
Policy Entropy: 3.85653
Value Function Loss: 0.03152

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.77577
Value Function Update Magnitude: 0.70971

Collected Steps per Second: 20,961.13290
Overall Steps per Second: 10,166.05050

Timestep Collection Time: 2.38632
Timestep Consumption Time: 2.53398
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.92030

Cumulative Model Updates: 166,314
Cumulative Timesteps: 1,386,871,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1386871146...
Checkpoint 1386871146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93.50956
Policy Entropy: 3.85877
Value Function Loss: 0.02956

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.75131
Value Function Update Magnitude: 0.68404

Collected Steps per Second: 20,705.37194
Overall Steps per Second: 10,056.47590

Timestep Collection Time: 2.41705
Timestep Consumption Time: 2.55944
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.97649

Cumulative Model Updates: 166,320
Cumulative Timesteps: 1,386,921,192

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.86434
Policy Entropy: 3.84699
Value Function Loss: 0.02308

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.71916
Value Function Update Magnitude: 0.65570

Collected Steps per Second: 20,692.94951
Overall Steps per Second: 10,037.33455

Timestep Collection Time: 2.41773
Timestep Consumption Time: 2.56666
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.98439

Cumulative Model Updates: 166,326
Cumulative Timesteps: 1,386,971,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1386971222...
Checkpoint 1386971222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,844.43087
Policy Entropy: 3.82762
Value Function Loss: 0.02129

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.67938
Value Function Update Magnitude: 0.67064

Collected Steps per Second: 20,516.44206
Overall Steps per Second: 10,039.18462

Timestep Collection Time: 2.43726
Timestep Consumption Time: 2.54362
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.98088

Cumulative Model Updates: 166,332
Cumulative Timesteps: 1,387,021,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,766.25248
Policy Entropy: 3.82256
Value Function Loss: 0.02679

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.18881
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.60920

Collected Steps per Second: 20,908.42221
Overall Steps per Second: 10,250.79449

Timestep Collection Time: 2.39272
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.88040

Cumulative Model Updates: 166,338
Cumulative Timesteps: 1,387,071,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1387071254...
Checkpoint 1387071254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,645.35453
Policy Entropy: 3.85057
Value Function Loss: 0.03734

Mean KL Divergence: 0.02266
SB3 Clip Fraction: 0.22415
Policy Update Magnitude: 0.62853
Value Function Update Magnitude: 0.59432

Collected Steps per Second: 20,785.75767
Overall Steps per Second: 10,234.22947

Timestep Collection Time: 2.40569
Timestep Consumption Time: 2.48027
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.88596

Cumulative Model Updates: 166,344
Cumulative Timesteps: 1,387,121,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.29077
Policy Entropy: 3.88254
Value Function Loss: 0.04574

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.17821
Policy Update Magnitude: 0.74470
Value Function Update Magnitude: 0.62168

Collected Steps per Second: 20,908.42086
Overall Steps per Second: 10,227.28362

Timestep Collection Time: 2.39262
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.89143

Cumulative Model Updates: 166,350
Cumulative Timesteps: 1,387,171,284

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1387171284...
Checkpoint 1387171284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,253.50870
Policy Entropy: 3.98220
Value Function Loss: 0.04685

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.14619
Policy Update Magnitude: 0.87635
Value Function Update Magnitude: 0.62262

Collected Steps per Second: 21,075.62984
Overall Steps per Second: 10,368.22689

Timestep Collection Time: 2.37345
Timestep Consumption Time: 2.45110
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.82455

Cumulative Model Updates: 166,356
Cumulative Timesteps: 1,387,221,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.94074
Policy Entropy: 4.07570
Value Function Loss: 0.04056

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 1.03463
Value Function Update Magnitude: 0.85682

Collected Steps per Second: 20,891.62005
Overall Steps per Second: 10,372.01252

Timestep Collection Time: 2.39359
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.82124

Cumulative Model Updates: 166,362
Cumulative Timesteps: 1,387,271,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1387271312...
Checkpoint 1387271312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.67202
Policy Entropy: 4.15369
Value Function Loss: 0.03209

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 1.15767
Value Function Update Magnitude: 0.95990

Collected Steps per Second: 21,642.02938
Overall Steps per Second: 10,417.25199

Timestep Collection Time: 2.31115
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.80146

Cumulative Model Updates: 166,368
Cumulative Timesteps: 1,387,321,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,240.93153
Policy Entropy: 4.13899
Value Function Loss: 0.03026

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06417
Policy Update Magnitude: 1.08662
Value Function Update Magnitude: 0.90777

Collected Steps per Second: 20,814.83535
Overall Steps per Second: 10,059.90492

Timestep Collection Time: 2.40319
Timestep Consumption Time: 2.56922
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.97241

Cumulative Model Updates: 166,374
Cumulative Timesteps: 1,387,371,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1387371352...
Checkpoint 1387371352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.91639
Policy Entropy: 4.07506
Value Function Loss: 0.03294

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 1.00068
Value Function Update Magnitude: 0.98126

Collected Steps per Second: 20,668.16402
Overall Steps per Second: 10,191.28153

Timestep Collection Time: 2.41995
Timestep Consumption Time: 2.48777
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.90772

Cumulative Model Updates: 166,380
Cumulative Timesteps: 1,387,421,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,234.57307
Policy Entropy: 3.98242
Value Function Loss: 0.03445

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08718
Policy Update Magnitude: 0.95232
Value Function Update Magnitude: 0.89545

Collected Steps per Second: 21,118.03214
Overall Steps per Second: 10,218.54276

Timestep Collection Time: 2.36850
Timestep Consumption Time: 2.52633
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.89483

Cumulative Model Updates: 166,386
Cumulative Timesteps: 1,387,471,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1387471386...
Checkpoint 1387471386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,458.52758
Policy Entropy: 3.96097
Value Function Loss: 0.03647

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.86682
Value Function Update Magnitude: 0.75774

Collected Steps per Second: 20,966.73772
Overall Steps per Second: 10,136.87189

Timestep Collection Time: 2.38559
Timestep Consumption Time: 2.54868
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.93426

Cumulative Model Updates: 166,392
Cumulative Timesteps: 1,387,521,404

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.11167
Policy Entropy: 3.94310
Value Function Loss: 0.03595

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.80365
Value Function Update Magnitude: 0.69798

Collected Steps per Second: 21,329.61236
Overall Steps per Second: 10,400.47894

Timestep Collection Time: 2.34519
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.80959

Cumulative Model Updates: 166,398
Cumulative Timesteps: 1,387,571,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1387571426...
Checkpoint 1387571426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,000.08219
Policy Entropy: 3.91868
Value Function Loss: 0.03679

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.76319
Value Function Update Magnitude: 0.71593

Collected Steps per Second: 20,991.38109
Overall Steps per Second: 10,184.20012

Timestep Collection Time: 2.38269
Timestep Consumption Time: 2.52844
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.91114

Cumulative Model Updates: 166,404
Cumulative Timesteps: 1,387,621,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.46189
Policy Entropy: 3.93150
Value Function Loss: 0.03132

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.77977
Value Function Update Magnitude: 0.71057

Collected Steps per Second: 20,680.61084
Overall Steps per Second: 10,104.05753

Timestep Collection Time: 2.41927
Timestep Consumption Time: 2.53240
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.95167

Cumulative Model Updates: 166,410
Cumulative Timesteps: 1,387,671,474

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1387671474...
Checkpoint 1387671474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152.51928
Policy Entropy: 3.91626
Value Function Loss: 0.03011

Mean KL Divergence: 0.00637
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.75352
Value Function Update Magnitude: 0.64364

Collected Steps per Second: 20,433.00753
Overall Steps per Second: 10,201.07839

Timestep Collection Time: 2.44790
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.90321

Cumulative Model Updates: 166,416
Cumulative Timesteps: 1,387,721,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 240.65858
Policy Entropy: 3.89420
Value Function Loss: 0.02729

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07624
Policy Update Magnitude: 0.69460
Value Function Update Magnitude: 0.65841

Collected Steps per Second: 20,973.61036
Overall Steps per Second: 10,343.00865

Timestep Collection Time: 2.38433
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.83496

Cumulative Model Updates: 166,422
Cumulative Timesteps: 1,387,771,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1387771500...
Checkpoint 1387771500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,408.31868
Policy Entropy: 3.84323
Value Function Loss: 0.02562

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04540
Policy Update Magnitude: 0.64757
Value Function Update Magnitude: 0.64491

Collected Steps per Second: 20,413.54198
Overall Steps per Second: 10,088.49461

Timestep Collection Time: 2.44994
Timestep Consumption Time: 2.50739
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.95733

Cumulative Model Updates: 166,428
Cumulative Timesteps: 1,387,821,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,360.82376
Policy Entropy: 3.80588
Value Function Loss: 0.02408

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06835
Policy Update Magnitude: 0.62601
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 20,906.56436
Overall Steps per Second: 10,293.57268

Timestep Collection Time: 2.39169
Timestep Consumption Time: 2.46591
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.85759

Cumulative Model Updates: 166,434
Cumulative Timesteps: 1,387,871,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1387871514...
Checkpoint 1387871514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,422.43697
Policy Entropy: 3.78435
Value Function Loss: 0.02091

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07432
Policy Update Magnitude: 0.60907
Value Function Update Magnitude: 0.54271

Collected Steps per Second: 20,946.78461
Overall Steps per Second: 10,154.25720

Timestep Collection Time: 2.38748
Timestep Consumption Time: 2.53755
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.92503

Cumulative Model Updates: 166,440
Cumulative Timesteps: 1,387,921,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,786.89710
Policy Entropy: 3.77780
Value Function Loss: 0.01913

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.49069
Value Function Update Magnitude: 0.50140

Collected Steps per Second: 20,712.69199
Overall Steps per Second: 10,069.96984

Timestep Collection Time: 2.41523
Timestep Consumption Time: 2.55261
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.96784

Cumulative Model Updates: 166,446
Cumulative Timesteps: 1,387,971,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1387971550...
Checkpoint 1387971550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,462.31519
Policy Entropy: 3.78249
Value Function Loss: 0.01901

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.37414
Value Function Update Magnitude: 0.44217

Collected Steps per Second: 20,873.03157
Overall Steps per Second: 10,200.89227

Timestep Collection Time: 2.39620
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.90310

Cumulative Model Updates: 166,452
Cumulative Timesteps: 1,388,021,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,622.95398
Policy Entropy: 3.77649
Value Function Loss: 0.01862

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.32177
Value Function Update Magnitude: 0.41260

Collected Steps per Second: 20,594.26663
Overall Steps per Second: 10,037.15647

Timestep Collection Time: 2.42796
Timestep Consumption Time: 2.55373
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.98169

Cumulative Model Updates: 166,458
Cumulative Timesteps: 1,388,071,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388071568...
Checkpoint 1388071568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,622.95398
Policy Entropy: 3.77528
Value Function Loss: 0.01701

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.30081
Value Function Update Magnitude: 0.39024

Collected Steps per Second: 20,827.08374
Overall Steps per Second: 10,223.62754

Timestep Collection Time: 2.40149
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.89220

Cumulative Model Updates: 166,464
Cumulative Timesteps: 1,388,121,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,432.62434
Policy Entropy: 3.76693
Value Function Loss: 0.01462

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.29661
Value Function Update Magnitude: 0.34669

Collected Steps per Second: 20,899.28353
Overall Steps per Second: 10,111.91472

Timestep Collection Time: 2.39281
Timestep Consumption Time: 2.55264
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.94545

Cumulative Model Updates: 166,470
Cumulative Timesteps: 1,388,171,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1388171592...
Checkpoint 1388171592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,568.54651
Policy Entropy: 3.77675
Value Function Loss: 0.01518

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.36951

Collected Steps per Second: 20,849.18357
Overall Steps per Second: 10,164.42234

Timestep Collection Time: 2.39981
Timestep Consumption Time: 2.52266
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.92246

Cumulative Model Updates: 166,476
Cumulative Timesteps: 1,388,221,626

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,472.13211
Policy Entropy: 3.77252
Value Function Loss: 0.01668

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13564
Policy Update Magnitude: 0.30773
Value Function Update Magnitude: 0.43373

Collected Steps per Second: 20,883.94043
Overall Steps per Second: 10,140.58812

Timestep Collection Time: 2.39562
Timestep Consumption Time: 2.53802
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.93364

Cumulative Model Updates: 166,482
Cumulative Timesteps: 1,388,271,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1388271656...
Checkpoint 1388271656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,397.42087
Policy Entropy: 3.78093
Value Function Loss: 0.01733

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.29104
Value Function Update Magnitude: 0.46066

Collected Steps per Second: 20,960.14321
Overall Steps per Second: 10,127.01228

Timestep Collection Time: 2.38605
Timestep Consumption Time: 2.55242
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.93848

Cumulative Model Updates: 166,488
Cumulative Timesteps: 1,388,321,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,369.18288
Policy Entropy: 3.78985
Value Function Loss: 0.01685

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.27615
Value Function Update Magnitude: 0.45424

Collected Steps per Second: 20,902.41479
Overall Steps per Second: 10,126.95124

Timestep Collection Time: 2.39216
Timestep Consumption Time: 2.54535
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.93752

Cumulative Model Updates: 166,494
Cumulative Timesteps: 1,388,371,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388371670...
Checkpoint 1388371670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,478.53475
Policy Entropy: 3.78941
Value Function Loss: 0.01511

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.30257
Value Function Update Magnitude: 0.47111

Collected Steps per Second: 20,931.28966
Overall Steps per Second: 10,127.94329

Timestep Collection Time: 2.38982
Timestep Consumption Time: 2.54919
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.93901

Cumulative Model Updates: 166,500
Cumulative Timesteps: 1,388,421,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,532.26455
Policy Entropy: 3.77739
Value Function Loss: 0.01555

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.31350
Value Function Update Magnitude: 0.49554

Collected Steps per Second: 20,413.77894
Overall Steps per Second: 10,189.57863

Timestep Collection Time: 2.45050
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.90933

Cumulative Model Updates: 166,506
Cumulative Timesteps: 1,388,471,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1388471716...
Checkpoint 1388471716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,592.82538
Policy Entropy: 3.76419
Value Function Loss: 0.01567

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.31867
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 20,342.29232
Overall Steps per Second: 10,176.69663

Timestep Collection Time: 2.45843
Timestep Consumption Time: 2.45574
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.91417

Cumulative Model Updates: 166,512
Cumulative Timesteps: 1,388,521,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,877.99499
Policy Entropy: 3.75182
Value Function Loss: 0.01872

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.33098
Value Function Update Magnitude: 0.47467

Collected Steps per Second: 20,148.57479
Overall Steps per Second: 9,895.94537

Timestep Collection Time: 2.48236
Timestep Consumption Time: 2.57183
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 5.05419

Cumulative Model Updates: 166,518
Cumulative Timesteps: 1,388,571,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1388571742...
Checkpoint 1388571742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,859.83521
Policy Entropy: 3.77625
Value Function Loss: 0.01695

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.37959
Value Function Update Magnitude: 0.47606

Collected Steps per Second: 20,385.67516
Overall Steps per Second: 10,193.13635

Timestep Collection Time: 2.45300
Timestep Consumption Time: 2.45285
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.90585

Cumulative Model Updates: 166,524
Cumulative Timesteps: 1,388,621,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,951.47573
Policy Entropy: 3.75801
Value Function Loss: 0.01606

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.36976
Value Function Update Magnitude: 0.48772

Collected Steps per Second: 20,828.82841
Overall Steps per Second: 10,170.79044

Timestep Collection Time: 2.40062
Timestep Consumption Time: 2.51562
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.91624

Cumulative Model Updates: 166,530
Cumulative Timesteps: 1,388,671,750

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1388671750...
Checkpoint 1388671750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,951.47573
Policy Entropy: 3.74829
Value Function Loss: 0.01349

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.34172
Value Function Update Magnitude: 0.46961

Collected Steps per Second: 20,474.56967
Overall Steps per Second: 10,152.83991

Timestep Collection Time: 2.44352
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.92769

Cumulative Model Updates: 166,536
Cumulative Timesteps: 1,388,721,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,951.47573
Policy Entropy: 3.72384
Value Function Loss: 0.01426

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.33309
Value Function Update Magnitude: 0.38386

Collected Steps per Second: 20,809.89083
Overall Steps per Second: 10,083.12551

Timestep Collection Time: 2.40366
Timestep Consumption Time: 2.55710
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.96076

Cumulative Model Updates: 166,542
Cumulative Timesteps: 1,388,771,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1388771800...
Checkpoint 1388771800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,959.81859
Policy Entropy: 3.73450
Value Function Loss: 0.01459

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.34749
Value Function Update Magnitude: 0.35924

Collected Steps per Second: 20,509.32530
Overall Steps per Second: 10,172.05545

Timestep Collection Time: 2.43909
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.91779

Cumulative Model Updates: 166,548
Cumulative Timesteps: 1,388,821,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,473.98804
Policy Entropy: 3.74508
Value Function Loss: 0.01414

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.35510
Value Function Update Magnitude: 0.45657

Collected Steps per Second: 20,237.53678
Overall Steps per Second: 10,133.98920

Timestep Collection Time: 2.47174
Timestep Consumption Time: 2.46432
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.93606

Cumulative Model Updates: 166,554
Cumulative Timesteps: 1,388,871,846

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1388871846...
Checkpoint 1388871846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,739.21530
Policy Entropy: 3.74222
Value Function Loss: 0.01528

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.36250
Value Function Update Magnitude: 0.44602

Collected Steps per Second: 20,715.20281
Overall Steps per Second: 10,097.51594

Timestep Collection Time: 2.41523
Timestep Consumption Time: 2.53965
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.95488

Cumulative Model Updates: 166,560
Cumulative Timesteps: 1,388,921,878

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,972.41614
Policy Entropy: 3.75089
Value Function Loss: 0.01567

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.36956
Value Function Update Magnitude: 0.39777

Collected Steps per Second: 20,678.74753
Overall Steps per Second: 10,069.86282

Timestep Collection Time: 2.41842
Timestep Consumption Time: 2.54788
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.96630

Cumulative Model Updates: 166,566
Cumulative Timesteps: 1,388,971,888

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1388971888...
Checkpoint 1388971888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,110.27872
Policy Entropy: 3.74959
Value Function Loss: 0.01557

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.33217
Value Function Update Magnitude: 0.42311

Collected Steps per Second: 20,512.68587
Overall Steps per Second: 10,126.60873

Timestep Collection Time: 2.43761
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.93768

Cumulative Model Updates: 166,572
Cumulative Timesteps: 1,389,021,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,037.96222
Policy Entropy: 3.75843
Value Function Loss: 0.01553

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.50034

Collected Steps per Second: 20,701.92701
Overall Steps per Second: 10,155.68827

Timestep Collection Time: 2.41630
Timestep Consumption Time: 2.50922
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.92552

Cumulative Model Updates: 166,578
Cumulative Timesteps: 1,389,071,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1389071912...
Checkpoint 1389071912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,735.70539
Policy Entropy: 3.74424
Value Function Loss: 0.01541

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.33224
Value Function Update Magnitude: 0.54940

Collected Steps per Second: 20,751.56147
Overall Steps per Second: 10,253.28517

Timestep Collection Time: 2.41052
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.87863

Cumulative Model Updates: 166,584
Cumulative Timesteps: 1,389,121,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,977.66169
Policy Entropy: 3.73350
Value Function Loss: 0.01870

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.36589
Value Function Update Magnitude: 0.58883

Collected Steps per Second: 20,428.61033
Overall Steps per Second: 10,324.13179

Timestep Collection Time: 2.44823
Timestep Consumption Time: 2.39615
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.84438

Cumulative Model Updates: 166,590
Cumulative Timesteps: 1,389,171,948

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1389171948...
Checkpoint 1389171948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,144.90035
Policy Entropy: 3.73616
Value Function Loss: 0.01907

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.41347
Value Function Update Magnitude: 0.57781

Collected Steps per Second: 20,524.96750
Overall Steps per Second: 10,311.57632

Timestep Collection Time: 2.43732
Timestep Consumption Time: 2.41412
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.85144

Cumulative Model Updates: 166,596
Cumulative Timesteps: 1,389,221,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,385.13737
Policy Entropy: 3.74601
Value Function Loss: 0.02046

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.41929
Value Function Update Magnitude: 0.68030

Collected Steps per Second: 20,620.49754
Overall Steps per Second: 10,373.10382

Timestep Collection Time: 2.42535
Timestep Consumption Time: 2.39596
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.82131

Cumulative Model Updates: 166,602
Cumulative Timesteps: 1,389,271,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1389271986...
Checkpoint 1389271986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,423.68512
Policy Entropy: 3.75143
Value Function Loss: 0.02069

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.42785
Value Function Update Magnitude: 0.64822

Collected Steps per Second: 20,057.76077
Overall Steps per Second: 9,960.84445

Timestep Collection Time: 2.49450
Timestep Consumption Time: 2.52857
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 5.02307

Cumulative Model Updates: 166,608
Cumulative Timesteps: 1,389,322,020

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,766.58210
Policy Entropy: 3.75673
Value Function Loss: 0.02090

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.44102
Value Function Update Magnitude: 0.58068

Collected Steps per Second: 20,723.95289
Overall Steps per Second: 10,273.41243

Timestep Collection Time: 2.41363
Timestep Consumption Time: 2.45525
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.86888

Cumulative Model Updates: 166,614
Cumulative Timesteps: 1,389,372,040

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1389372040...
Checkpoint 1389372040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,990.28175
Policy Entropy: 3.75313
Value Function Loss: 0.02184

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.44399
Value Function Update Magnitude: 0.56824

Collected Steps per Second: 20,666.66956
Overall Steps per Second: 10,284.63213

Timestep Collection Time: 2.41935
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.86162

Cumulative Model Updates: 166,620
Cumulative Timesteps: 1,389,422,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,705.09158
Policy Entropy: 3.76416
Value Function Loss: 0.02135

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.45696
Value Function Update Magnitude: 0.55857

Collected Steps per Second: 21,016.28510
Overall Steps per Second: 10,192.80901

Timestep Collection Time: 2.38025
Timestep Consumption Time: 2.52752
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.90777

Cumulative Model Updates: 166,626
Cumulative Timesteps: 1,389,472,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1389472064...
Checkpoint 1389472064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,009.35672
Policy Entropy: 3.77483
Value Function Loss: 0.02271

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.45633
Value Function Update Magnitude: 0.53147

Collected Steps per Second: 20,973.60494
Overall Steps per Second: 10,146.88490

Timestep Collection Time: 2.38414
Timestep Consumption Time: 2.54388
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.92801

Cumulative Model Updates: 166,632
Cumulative Timesteps: 1,389,522,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,699.28591
Policy Entropy: 3.78540
Value Function Loss: 0.02304

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.48400
Value Function Update Magnitude: 0.57315

Collected Steps per Second: 21,122.02034
Overall Steps per Second: 10,346.60827

Timestep Collection Time: 2.36796
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.83405

Cumulative Model Updates: 166,638
Cumulative Timesteps: 1,389,572,084

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1389572084...
Checkpoint 1389572084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,796.39710
Policy Entropy: 3.78744
Value Function Loss: 0.02272

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 20,820.60214
Overall Steps per Second: 10,271.08173

Timestep Collection Time: 2.40224
Timestep Consumption Time: 2.46736
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.86959

Cumulative Model Updates: 166,644
Cumulative Timesteps: 1,389,622,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,718.51630
Policy Entropy: 3.77963
Value Function Loss: 0.02117

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.50706
Value Function Update Magnitude: 0.70171

Collected Steps per Second: 20,709.90883
Overall Steps per Second: 10,033.11111

Timestep Collection Time: 2.41652
Timestep Consumption Time: 2.57156
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.98808

Cumulative Model Updates: 166,650
Cumulative Timesteps: 1,389,672,146

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1389672146...
Checkpoint 1389672146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,991.89235
Policy Entropy: 3.79080
Value Function Loss: 0.02186

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.49286
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 20,872.72119
Overall Steps per Second: 10,232.78198

Timestep Collection Time: 2.39557
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.88645

Cumulative Model Updates: 166,656
Cumulative Timesteps: 1,389,722,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,218.18561
Policy Entropy: 3.77620
Value Function Loss: 0.02255

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11765
Policy Update Magnitude: 0.51430
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 20,662.39537
Overall Steps per Second: 10,046.63586

Timestep Collection Time: 2.42092
Timestep Consumption Time: 2.55806
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.97898

Cumulative Model Updates: 166,662
Cumulative Timesteps: 1,389,772,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1389772170...
Checkpoint 1389772170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,500.08335
Policy Entropy: 3.77921
Value Function Loss: 0.02106

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.49018
Value Function Update Magnitude: 0.66651

Collected Steps per Second: 20,885.07750
Overall Steps per Second: 10,184.33280

Timestep Collection Time: 2.39492
Timestep Consumption Time: 2.51635
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.91127

Cumulative Model Updates: 166,668
Cumulative Timesteps: 1,389,822,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,728.38036
Policy Entropy: 3.76428
Value Function Loss: 0.02468

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12167
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 20,633.45388
Overall Steps per Second: 10,074.02116

Timestep Collection Time: 2.42432
Timestep Consumption Time: 2.54113
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.96545

Cumulative Model Updates: 166,674
Cumulative Timesteps: 1,389,872,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1389872210...
Checkpoint 1389872210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,508.10530
Policy Entropy: 3.78624
Value Function Loss: 0.02267

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.51155
Value Function Update Magnitude: 0.55338

Collected Steps per Second: 20,917.41334
Overall Steps per Second: 10,293.73811

Timestep Collection Time: 2.39227
Timestep Consumption Time: 2.46894
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.86121

Cumulative Model Updates: 166,680
Cumulative Timesteps: 1,389,922,250

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,756.93237
Policy Entropy: 3.76464
Value Function Loss: 0.02373

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.49992
Value Function Update Magnitude: 0.59485

Collected Steps per Second: 20,788.64988
Overall Steps per Second: 10,162.54961

Timestep Collection Time: 2.40670
Timestep Consumption Time: 2.51648
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.92317

Cumulative Model Updates: 166,686
Cumulative Timesteps: 1,389,972,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1389972282...
Checkpoint 1389972282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,182.30607
Policy Entropy: 3.76964
Value Function Loss: 0.02200

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.48124
Value Function Update Magnitude: 0.53475

Collected Steps per Second: 20,378.67823
Overall Steps per Second: 10,175.91511

Timestep Collection Time: 2.45354
Timestep Consumption Time: 2.46002
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.91356

Cumulative Model Updates: 166,692
Cumulative Timesteps: 1,390,022,282

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,457.27260
Policy Entropy: 3.76400
Value Function Loss: 0.02165

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.48006
Value Function Update Magnitude: 0.53345

Collected Steps per Second: 19,949.29156
Overall Steps per Second: 10,043.32227

Timestep Collection Time: 2.50716
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.98003

Cumulative Model Updates: 166,698
Cumulative Timesteps: 1,390,072,298

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1390072298...
Checkpoint 1390072298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,309.94322
Policy Entropy: 3.77768
Value Function Loss: 0.02037

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.46434
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 20,171.15402
Overall Steps per Second: 10,161.72556

Timestep Collection Time: 2.48018
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.92318

Cumulative Model Updates: 166,704
Cumulative Timesteps: 1,390,122,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,786.56215
Policy Entropy: 3.76837
Value Function Loss: 0.01945

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.46561
Value Function Update Magnitude: 0.59353

Collected Steps per Second: 20,560.15465
Overall Steps per Second: 10,086.24536

Timestep Collection Time: 2.43237
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.95824

Cumulative Model Updates: 166,710
Cumulative Timesteps: 1,390,172,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1390172336...
Checkpoint 1390172336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,281.50382
Policy Entropy: 3.76694
Value Function Loss: 0.01770

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.47459
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 20,987.37886
Overall Steps per Second: 10,381.80907

Timestep Collection Time: 2.38257
Timestep Consumption Time: 2.43393
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.81650

Cumulative Model Updates: 166,716
Cumulative Timesteps: 1,390,222,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,424.79103
Policy Entropy: 3.77617
Value Function Loss: 0.01530

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.44601
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 20,784.21746
Overall Steps per Second: 10,106.54558

Timestep Collection Time: 2.40596
Timestep Consumption Time: 2.54192
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.94788

Cumulative Model Updates: 166,722
Cumulative Timesteps: 1,390,272,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1390272346...
Checkpoint 1390272346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,424.79103
Policy Entropy: 3.76129
Value Function Loss: 0.01477

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.39395
Value Function Update Magnitude: 0.46588

Collected Steps per Second: 20,892.88861
Overall Steps per Second: 10,250.74063

Timestep Collection Time: 2.39392
Timestep Consumption Time: 2.48533
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.87926

Cumulative Model Updates: 166,728
Cumulative Timesteps: 1,390,322,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,424.79103
Policy Entropy: 3.75320
Value Function Loss: 0.01434

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.40163
Value Function Update Magnitude: 0.40405

Collected Steps per Second: 21,062.96128
Overall Steps per Second: 10,149.09624

Timestep Collection Time: 2.37516
Timestep Consumption Time: 2.55414
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.92931

Cumulative Model Updates: 166,734
Cumulative Timesteps: 1,390,372,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1390372390...
Checkpoint 1390372390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,840.02606
Policy Entropy: 3.74630
Value Function Loss: 0.01520

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.39150
Value Function Update Magnitude: 0.38850

Collected Steps per Second: 20,682.40267
Overall Steps per Second: 10,031.22231

Timestep Collection Time: 2.41809
Timestep Consumption Time: 2.56754
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.98563

Cumulative Model Updates: 166,740
Cumulative Timesteps: 1,390,422,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,840.02606
Policy Entropy: 3.75952
Value Function Loss: 0.01573

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.35957
Value Function Update Magnitude: 0.38198

Collected Steps per Second: 20,414.94576
Overall Steps per Second: 10,131.53078

Timestep Collection Time: 2.44928
Timestep Consumption Time: 2.48600
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.93529

Cumulative Model Updates: 166,746
Cumulative Timesteps: 1,390,472,404

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1390472404...
Checkpoint 1390472404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,806.26193
Policy Entropy: 3.76706
Value Function Loss: 0.01712

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.37389
Value Function Update Magnitude: 0.38693

Collected Steps per Second: 20,950.26028
Overall Steps per Second: 10,207.15138

Timestep Collection Time: 2.38766
Timestep Consumption Time: 2.51303
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.90068

Cumulative Model Updates: 166,752
Cumulative Timesteps: 1,390,522,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,149.47343
Policy Entropy: 3.78673
Value Function Loss: 0.01665

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.39493
Value Function Update Magnitude: 0.38175

Collected Steps per Second: 20,643.19130
Overall Steps per Second: 10,088.15663

Timestep Collection Time: 2.42346
Timestep Consumption Time: 2.53562
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.95908

Cumulative Model Updates: 166,758
Cumulative Timesteps: 1,390,572,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1390572454...
Checkpoint 1390572454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,436.63632
Policy Entropy: 3.79119
Value Function Loss: 0.01574

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.38944
Value Function Update Magnitude: 0.36887

Collected Steps per Second: 20,495.28636
Overall Steps per Second: 10,176.66788

Timestep Collection Time: 2.43978
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.91359

Cumulative Model Updates: 166,764
Cumulative Timesteps: 1,390,622,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,730.13839
Policy Entropy: 3.77727
Value Function Loss: 0.01507

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.36949
Value Function Update Magnitude: 0.41686

Collected Steps per Second: 20,515.80209
Overall Steps per Second: 10,392.90033

Timestep Collection Time: 2.43822
Timestep Consumption Time: 2.37488
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.81309

Cumulative Model Updates: 166,770
Cumulative Timesteps: 1,390,672,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1390672480...
Checkpoint 1390672480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,486.44050
Policy Entropy: 3.76766
Value Function Loss: 0.01463

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.37946
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 20,011.70785
Overall Steps per Second: 10,235.99950

Timestep Collection Time: 2.49884
Timestep Consumption Time: 2.38647
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.88531

Cumulative Model Updates: 166,776
Cumulative Timesteps: 1,390,722,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,708.05974
Policy Entropy: 3.77293
Value Function Loss: 0.01528

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.38033
Value Function Update Magnitude: 0.53639

Collected Steps per Second: 19,871.57345
Overall Steps per Second: 10,043.32930

Timestep Collection Time: 2.51666
Timestep Consumption Time: 2.46276
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.97942

Cumulative Model Updates: 166,782
Cumulative Timesteps: 1,390,772,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1390772496...
Checkpoint 1390772496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,672.29699
Policy Entropy: 3.77585
Value Function Loss: 0.01543

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.36810
Value Function Update Magnitude: 0.54790

Collected Steps per Second: 20,845.13866
Overall Steps per Second: 10,326.13195

Timestep Collection Time: 2.40075
Timestep Consumption Time: 2.44559
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.84635

Cumulative Model Updates: 166,788
Cumulative Timesteps: 1,390,822,540

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,994.75712
Policy Entropy: 3.77831
Value Function Loss: 0.01929

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.42576
Value Function Update Magnitude: 0.56127

Collected Steps per Second: 20,538.22638
Overall Steps per Second: 10,080.69088

Timestep Collection Time: 2.43497
Timestep Consumption Time: 2.52600
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.96097

Cumulative Model Updates: 166,794
Cumulative Timesteps: 1,390,872,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1390872550...
Checkpoint 1390872550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,811.99617
Policy Entropy: 3.79247
Value Function Loss: 0.01985

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.46855
Value Function Update Magnitude: 0.62199

Collected Steps per Second: 20,807.71486
Overall Steps per Second: 10,168.81407

Timestep Collection Time: 2.40305
Timestep Consumption Time: 2.51414
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.91719

Cumulative Model Updates: 166,800
Cumulative Timesteps: 1,390,922,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,035.90505
Policy Entropy: 3.79157
Value Function Loss: 0.02034

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.69561

Collected Steps per Second: 20,702.99214
Overall Steps per Second: 10,001.17868

Timestep Collection Time: 2.41646
Timestep Consumption Time: 2.58575
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 5.00221

Cumulative Model Updates: 166,806
Cumulative Timesteps: 1,390,972,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1390972580...
Checkpoint 1390972580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,994.53383
Policy Entropy: 3.79314
Value Function Loss: 0.01948

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.47268
Value Function Update Magnitude: 0.64696

Collected Steps per Second: 20,609.18893
Overall Steps per Second: 10,181.37366

Timestep Collection Time: 2.42639
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.91152

Cumulative Model Updates: 166,812
Cumulative Timesteps: 1,391,022,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,039.99202
Policy Entropy: 3.79039
Value Function Loss: 0.01906

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.48127
Value Function Update Magnitude: 0.61242

Collected Steps per Second: 20,552.27279
Overall Steps per Second: 10,083.23192

Timestep Collection Time: 2.43389
Timestep Consumption Time: 2.52702
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.96091

Cumulative Model Updates: 166,818
Cumulative Timesteps: 1,391,072,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1391072608...
Checkpoint 1391072608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,646.13755
Policy Entropy: 3.79814
Value Function Loss: 0.01941

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.47510
Value Function Update Magnitude: 0.62643

Collected Steps per Second: 20,853.82159
Overall Steps per Second: 10,257.68364

Timestep Collection Time: 2.39812
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.87537

Cumulative Model Updates: 166,824
Cumulative Timesteps: 1,391,122,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186.14427
Policy Entropy: 3.82444
Value Function Loss: 0.01940

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.46173
Value Function Update Magnitude: 0.59500

Collected Steps per Second: 20,922.14398
Overall Steps per Second: 10,118.28759

Timestep Collection Time: 2.39163
Timestep Consumption Time: 2.55367
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.94530

Cumulative Model Updates: 166,830
Cumulative Timesteps: 1,391,172,656

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1391172656...
Checkpoint 1391172656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,173.63253
Policy Entropy: 3.83751
Value Function Loss: 0.02160

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.47351
Value Function Update Magnitude: 0.57663

Collected Steps per Second: 21,075.08646
Overall Steps per Second: 10,207.13221

Timestep Collection Time: 2.37304
Timestep Consumption Time: 2.52667
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.89971

Cumulative Model Updates: 166,836
Cumulative Timesteps: 1,391,222,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,813.86505
Policy Entropy: 3.84057
Value Function Loss: 0.02370

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.53133
Value Function Update Magnitude: 0.65132

Collected Steps per Second: 20,743.95885
Overall Steps per Second: 10,081.58746

Timestep Collection Time: 2.41034
Timestep Consumption Time: 2.54920
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.95954

Cumulative Model Updates: 166,842
Cumulative Timesteps: 1,391,272,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1391272668...
Checkpoint 1391272668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,489.55948
Policy Entropy: 3.82901
Value Function Loss: 0.02498

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.54536
Value Function Update Magnitude: 0.67266

Collected Steps per Second: 20,904.98900
Overall Steps per Second: 10,065.74085

Timestep Collection Time: 2.39263
Timestep Consumption Time: 2.57650
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.96913

Cumulative Model Updates: 166,848
Cumulative Timesteps: 1,391,322,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,416.37779
Policy Entropy: 3.79488
Value Function Loss: 0.02717

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.50256
Value Function Update Magnitude: 0.65855

Collected Steps per Second: 20,901.96294
Overall Steps per Second: 10,120.47451

Timestep Collection Time: 2.39356
Timestep Consumption Time: 2.54989
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.94344

Cumulative Model Updates: 166,854
Cumulative Timesteps: 1,391,372,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1391372716...
Checkpoint 1391372716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,525.92226
Policy Entropy: 3.78713
Value Function Loss: 0.02463

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.50145
Value Function Update Magnitude: 0.54927

Collected Steps per Second: 21,211.60008
Overall Steps per Second: 10,162.51244

Timestep Collection Time: 2.35852
Timestep Consumption Time: 2.56428
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.92280

Cumulative Model Updates: 166,860
Cumulative Timesteps: 1,391,422,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,299.96254
Policy Entropy: 3.74926
Value Function Loss: 0.02555

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.48556
Value Function Update Magnitude: 0.42328

Collected Steps per Second: 20,647.71203
Overall Steps per Second: 9,981.61766

Timestep Collection Time: 2.42187
Timestep Consumption Time: 2.58794
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 5.00981

Cumulative Model Updates: 166,866
Cumulative Timesteps: 1,391,472,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1391472750...
Checkpoint 1391472750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,494.35600
Policy Entropy: 3.75745
Value Function Loss: 0.02033

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12183
Policy Update Magnitude: 0.47405
Value Function Update Magnitude: 0.48194

Collected Steps per Second: 20,604.84209
Overall Steps per Second: 10,029.02353

Timestep Collection Time: 2.42739
Timestep Consumption Time: 2.55973
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.98713

Cumulative Model Updates: 166,872
Cumulative Timesteps: 1,391,522,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,135.48182
Policy Entropy: 3.75696
Value Function Loss: 0.02241

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.46294
Value Function Update Magnitude: 0.49005

Collected Steps per Second: 21,072.11472
Overall Steps per Second: 10,271.14673

Timestep Collection Time: 2.37366
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.86976

Cumulative Model Updates: 166,878
Cumulative Timesteps: 1,391,572,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1391572784...
Checkpoint 1391572784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,788.32944
Policy Entropy: 3.78384
Value Function Loss: 0.01870

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.47601
Value Function Update Magnitude: 0.51026

Collected Steps per Second: 20,548.12545
Overall Steps per Second: 10,155.03523

Timestep Collection Time: 2.43575
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.92859

Cumulative Model Updates: 166,884
Cumulative Timesteps: 1,391,622,834

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,649.59069
Policy Entropy: 3.77937
Value Function Loss: 0.01911

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.47897
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 20,422.53648
Overall Steps per Second: 10,101.58087

Timestep Collection Time: 2.45014
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.95348

Cumulative Model Updates: 166,890
Cumulative Timesteps: 1,391,672,872

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1391672872...
Checkpoint 1391672872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,117.21130
Policy Entropy: 3.76608
Value Function Loss: 0.01781

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.46339
Value Function Update Magnitude: 0.58437

Collected Steps per Second: 20,135.80229
Overall Steps per Second: 10,231.46877

Timestep Collection Time: 2.48314
Timestep Consumption Time: 2.40374
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.88688

Cumulative Model Updates: 166,896
Cumulative Timesteps: 1,391,722,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,799.56114
Policy Entropy: 3.75970
Value Function Loss: 0.01907

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.47442
Value Function Update Magnitude: 0.46072

Collected Steps per Second: 19,962.97413
Overall Steps per Second: 10,050.17252

Timestep Collection Time: 2.50614
Timestep Consumption Time: 2.47188
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.97802

Cumulative Model Updates: 166,902
Cumulative Timesteps: 1,391,772,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1391772902...
Checkpoint 1391772902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,268.69970
Policy Entropy: 3.75541
Value Function Loss: 0.01987

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.46569
Value Function Update Magnitude: 0.43290

Collected Steps per Second: 20,148.80256
Overall Steps per Second: 10,227.52616

Timestep Collection Time: 2.48243
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.89053

Cumulative Model Updates: 166,908
Cumulative Timesteps: 1,391,822,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,531.21088
Policy Entropy: 3.77309
Value Function Loss: 0.02091

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.49827
Value Function Update Magnitude: 0.49420

Collected Steps per Second: 20,396.73605
Overall Steps per Second: 10,134.92635

Timestep Collection Time: 2.45226
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.93521

Cumulative Model Updates: 166,914
Cumulative Timesteps: 1,391,872,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1391872938...
Checkpoint 1391872938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,833.60374
Policy Entropy: 3.79039
Value Function Loss: 0.02166

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.52742
Value Function Update Magnitude: 0.56418

Collected Steps per Second: 20,652.42707
Overall Steps per Second: 10,116.13796

Timestep Collection Time: 2.42160
Timestep Consumption Time: 2.52218
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.94378

Cumulative Model Updates: 166,920
Cumulative Timesteps: 1,391,922,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,410.55714
Policy Entropy: 3.80283
Value Function Loss: 0.02431

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.52971
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 20,699.80246
Overall Steps per Second: 10,143.47146

Timestep Collection Time: 2.41654
Timestep Consumption Time: 2.51490
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.93145

Cumulative Model Updates: 166,926
Cumulative Timesteps: 1,391,972,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1391972972...
Checkpoint 1391972972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,348.56783
Policy Entropy: 3.79738
Value Function Loss: 0.02235

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.52801
Value Function Update Magnitude: 0.64282

Collected Steps per Second: 20,779.49823
Overall Steps per Second: 10,123.71842

Timestep Collection Time: 2.40785
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.94226

Cumulative Model Updates: 166,932
Cumulative Timesteps: 1,392,023,006

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,305.90493
Policy Entropy: 3.78760
Value Function Loss: 0.02584

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.63825

Collected Steps per Second: 20,616.05377
Overall Steps per Second: 10,162.47674

Timestep Collection Time: 2.42685
Timestep Consumption Time: 2.49636
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.92321

Cumulative Model Updates: 166,938
Cumulative Timesteps: 1,392,073,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1392073038...
Checkpoint 1392073038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,160.00841
Policy Entropy: 3.78651
Value Function Loss: 0.02627

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.52197

Collected Steps per Second: 20,899.56186
Overall Steps per Second: 10,124.18459

Timestep Collection Time: 2.39354
Timestep Consumption Time: 2.54750
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.94104

Cumulative Model Updates: 166,944
Cumulative Timesteps: 1,392,123,062

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,002.11156
Policy Entropy: 3.80037
Value Function Loss: 0.02775

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.60982
Value Function Update Magnitude: 0.50477

Collected Steps per Second: 20,821.52926
Overall Steps per Second: 10,066.52301

Timestep Collection Time: 2.40136
Timestep Consumption Time: 2.56560
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.96696

Cumulative Model Updates: 166,950
Cumulative Timesteps: 1,392,173,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1392173062...
Checkpoint 1392173062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.19418
Policy Entropy: 3.79376
Value Function Loss: 0.02369

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11398
Policy Update Magnitude: 0.60294
Value Function Update Magnitude: 0.49872

Collected Steps per Second: 20,609.37072
Overall Steps per Second: 10,212.43790

Timestep Collection Time: 2.42705
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.89795

Cumulative Model Updates: 166,956
Cumulative Timesteps: 1,392,223,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.19418
Policy Entropy: 3.76755
Value Function Loss: 0.02039

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.47290

Collected Steps per Second: 20,748.28744
Overall Steps per Second: 10,084.22101

Timestep Collection Time: 2.41051
Timestep Consumption Time: 2.54912
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.95963

Cumulative Model Updates: 166,962
Cumulative Timesteps: 1,392,273,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1392273096...
Checkpoint 1392273096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,163.19418
Policy Entropy: 3.75937
Value Function Loss: 0.01614

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15849
Policy Update Magnitude: 0.50272
Value Function Update Magnitude: 0.37234

Collected Steps per Second: 20,321.15901
Overall Steps per Second: 10,102.80506

Timestep Collection Time: 2.46059
Timestep Consumption Time: 2.48873
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.94932

Cumulative Model Updates: 166,968
Cumulative Timesteps: 1,392,323,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,348.10318
Policy Entropy: 3.74665
Value Function Loss: 0.02347

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.19925
Policy Update Magnitude: 0.51207
Value Function Update Magnitude: 0.37102

Collected Steps per Second: 20,612.63694
Overall Steps per Second: 10,044.95492

Timestep Collection Time: 2.42696
Timestep Consumption Time: 2.55325
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.98021

Cumulative Model Updates: 166,974
Cumulative Timesteps: 1,392,373,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392373124...
Checkpoint 1392373124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,682.54132
Policy Entropy: 3.78886
Value Function Loss: 0.02764

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.68722
Value Function Update Magnitude: 0.52844

Collected Steps per Second: 20,929.89064
Overall Steps per Second: 10,239.31178

Timestep Collection Time: 2.39007
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.88548

Cumulative Model Updates: 166,980
Cumulative Timesteps: 1,392,423,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,755.76691
Policy Entropy: 3.81954
Value Function Loss: 0.03925

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.16177
Policy Update Magnitude: 0.68501
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 20,947.78664
Overall Steps per Second: 10,140.63878

Timestep Collection Time: 2.38813
Timestep Consumption Time: 2.54509
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.93322

Cumulative Model Updates: 166,986
Cumulative Timesteps: 1,392,473,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392473174...
Checkpoint 1392473174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,216.03350
Policy Entropy: 3.87158
Value Function Loss: 0.04288

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.68855
Value Function Update Magnitude: 0.56944

Collected Steps per Second: 21,087.51204
Overall Steps per Second: 10,286.63929

Timestep Collection Time: 2.37183
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.86223

Cumulative Model Updates: 166,992
Cumulative Timesteps: 1,392,523,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,600.83854
Policy Entropy: 3.90073
Value Function Loss: 0.04107

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.74899
Value Function Update Magnitude: 0.71740

Collected Steps per Second: 21,042.99580
Overall Steps per Second: 10,298.65015

Timestep Collection Time: 2.37732
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.85753

Cumulative Model Updates: 166,998
Cumulative Timesteps: 1,392,573,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1392573216...
Checkpoint 1392573216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118.85792
Policy Entropy: 3.91078
Value Function Loss: 0.03473

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.73609
Value Function Update Magnitude: 0.92519

Collected Steps per Second: 21,083.94690
Overall Steps per Second: 10,228.65065

Timestep Collection Time: 2.37214
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.88960

Cumulative Model Updates: 167,004
Cumulative Timesteps: 1,392,623,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,598.49849
Policy Entropy: 3.90735
Value Function Loss: 0.03573

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.70275
Value Function Update Magnitude: 0.89974

Collected Steps per Second: 20,857.24425
Overall Steps per Second: 10,159.42396

Timestep Collection Time: 2.39744
Timestep Consumption Time: 2.52449
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.92193

Cumulative Model Updates: 167,010
Cumulative Timesteps: 1,392,673,234

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1392673234...
Checkpoint 1392673234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154.17127
Policy Entropy: 3.88195
Value Function Loss: 0.03239

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.65864
Value Function Update Magnitude: 0.70156

Collected Steps per Second: 21,246.29737
Overall Steps per Second: 10,419.67026

Timestep Collection Time: 2.35410
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.80015

Cumulative Model Updates: 167,016
Cumulative Timesteps: 1,392,723,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118.78200
Policy Entropy: 3.83587
Value Function Loss: 0.02841

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.69720

Collected Steps per Second: 20,745.68818
Overall Steps per Second: 10,115.02688

Timestep Collection Time: 2.41052
Timestep Consumption Time: 2.53341
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.94393

Cumulative Model Updates: 167,022
Cumulative Timesteps: 1,392,773,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1392773258...
Checkpoint 1392773258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.81380
Policy Entropy: 3.79566
Value Function Loss: 0.02345

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.48273
Value Function Update Magnitude: 0.62069

Collected Steps per Second: 20,562.79962
Overall Steps per Second: 10,158.66562

Timestep Collection Time: 2.43187
Timestep Consumption Time: 2.49063
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.92250

Cumulative Model Updates: 167,028
Cumulative Timesteps: 1,392,823,264

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,107.63753
Policy Entropy: 3.77047
Value Function Loss: 0.02148

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.41089
Value Function Update Magnitude: 0.54317

Collected Steps per Second: 20,459.02688
Overall Steps per Second: 10,132.87067

Timestep Collection Time: 2.44616
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.93898

Cumulative Model Updates: 167,034
Cumulative Timesteps: 1,392,873,310

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1392873310...
Checkpoint 1392873310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,593.55414
Policy Entropy: 3.78599
Value Function Loss: 0.02051

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.38658
Value Function Update Magnitude: 0.45490

Collected Steps per Second: 20,702.37376
Overall Steps per Second: 10,270.51298

Timestep Collection Time: 2.41547
Timestep Consumption Time: 2.45342
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.86889

Cumulative Model Updates: 167,040
Cumulative Timesteps: 1,392,923,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.23445
Policy Entropy: 3.79251
Value Function Loss: 0.01813

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.36752
Value Function Update Magnitude: 0.44052

Collected Steps per Second: 20,631.90097
Overall Steps per Second: 10,032.59621

Timestep Collection Time: 2.42353
Timestep Consumption Time: 2.56043
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.98395

Cumulative Model Updates: 167,046
Cumulative Timesteps: 1,392,973,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1392973318...
Checkpoint 1392973318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,657.79244
Policy Entropy: 3.79918
Value Function Loss: 0.01697

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.34283
Value Function Update Magnitude: 0.40627

Collected Steps per Second: 21,140.69245
Overall Steps per Second: 10,122.46934

Timestep Collection Time: 2.36700
Timestep Consumption Time: 2.57646
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.94346

Cumulative Model Updates: 167,052
Cumulative Timesteps: 1,393,023,358

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,295.97799
Policy Entropy: 3.77646
Value Function Loss: 0.02168

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.39151
Value Function Update Magnitude: 0.51614

Collected Steps per Second: 20,548.69173
Overall Steps per Second: 10,076.51223

Timestep Collection Time: 2.43412
Timestep Consumption Time: 2.52970
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.96382

Cumulative Model Updates: 167,058
Cumulative Timesteps: 1,393,073,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393073376...
Checkpoint 1393073376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,729.29384
Policy Entropy: 3.78904
Value Function Loss: 0.02372

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.47984
Value Function Update Magnitude: 0.70899

Collected Steps per Second: 21,018.85501
Overall Steps per Second: 10,223.73597

Timestep Collection Time: 2.37910
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.89117

Cumulative Model Updates: 167,064
Cumulative Timesteps: 1,393,123,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,280.09374
Policy Entropy: 3.79381
Value Function Loss: 0.02841

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.51027
Value Function Update Magnitude: 0.76113

Collected Steps per Second: 20,762.73862
Overall Steps per Second: 10,066.47946

Timestep Collection Time: 2.40903
Timestep Consumption Time: 2.55974
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.96877

Cumulative Model Updates: 167,070
Cumulative Timesteps: 1,393,173,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393173400...
Checkpoint 1393173400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,368.14236
Policy Entropy: 3.82479
Value Function Loss: 0.02600

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.72739

Collected Steps per Second: 21,027.04056
Overall Steps per Second: 10,154.26605

Timestep Collection Time: 2.37789
Timestep Consumption Time: 2.54615
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.92404

Cumulative Model Updates: 167,076
Cumulative Timesteps: 1,393,223,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,180.43458
Policy Entropy: 3.81933
Value Function Loss: 0.02505

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.07449
Policy Update Magnitude: 0.59558
Value Function Update Magnitude: 0.58881

Collected Steps per Second: 20,908.93723
Overall Steps per Second: 10,085.75310

Timestep Collection Time: 2.39218
Timestep Consumption Time: 2.56709
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.95927

Cumulative Model Updates: 167,082
Cumulative Timesteps: 1,393,273,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393273418...
Checkpoint 1393273418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,882.11214
Policy Entropy: 3.83315
Value Function Loss: 0.02317

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.57238
Value Function Update Magnitude: 0.58384

Collected Steps per Second: 20,806.71827
Overall Steps per Second: 10,189.08016

Timestep Collection Time: 2.40317
Timestep Consumption Time: 2.50424
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.90741

Cumulative Model Updates: 167,088
Cumulative Timesteps: 1,393,323,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169.00599
Policy Entropy: 3.82366
Value Function Loss: 0.02312

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.51390
Value Function Update Magnitude: 0.66082

Collected Steps per Second: 20,815.20909
Overall Steps per Second: 10,083.15600

Timestep Collection Time: 2.40286
Timestep Consumption Time: 2.55749
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.96035

Cumulative Model Updates: 167,094
Cumulative Timesteps: 1,393,373,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1393373436...
Checkpoint 1393373436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,527.15496
Policy Entropy: 3.82353
Value Function Loss: 0.02174

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.54478
Value Function Update Magnitude: 0.65816

Collected Steps per Second: 20,932.19592
Overall Steps per Second: 10,083.77628

Timestep Collection Time: 2.38924
Timestep Consumption Time: 2.57041
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.95965

Cumulative Model Updates: 167,100
Cumulative Timesteps: 1,393,423,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,346.72231
Policy Entropy: 3.80329
Value Function Loss: 0.02018

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.48445
Value Function Update Magnitude: 0.62466

Collected Steps per Second: 20,397.31048
Overall Steps per Second: 10,123.67075

Timestep Collection Time: 2.45268
Timestep Consumption Time: 2.48901
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.94169

Cumulative Model Updates: 167,106
Cumulative Timesteps: 1,393,473,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1393473476...
Checkpoint 1393473476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,902.28903
Policy Entropy: 3.78918
Value Function Loss: 0.01977

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.44190
Value Function Update Magnitude: 0.55320

Collected Steps per Second: 20,999.89902
Overall Steps per Second: 10,231.50441

Timestep Collection Time: 2.38163
Timestep Consumption Time: 2.50660
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.88824

Cumulative Model Updates: 167,112
Cumulative Timesteps: 1,393,523,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,574.92322
Policy Entropy: 3.76025
Value Function Loss: 0.01889

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.38454
Value Function Update Magnitude: 0.47319

Collected Steps per Second: 20,193.41805
Overall Steps per Second: 10,126.27168

Timestep Collection Time: 2.47695
Timestep Consumption Time: 2.46248
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.93943

Cumulative Model Updates: 167,118
Cumulative Timesteps: 1,393,573,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1393573508...
Checkpoint 1393573508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,574.92322
Policy Entropy: 3.74937
Value Function Loss: 0.01582

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.37796
Value Function Update Magnitude: 0.38517

Collected Steps per Second: 20,105.68022
Overall Steps per Second: 10,092.01845

Timestep Collection Time: 2.48805
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.95679

Cumulative Model Updates: 167,124
Cumulative Timesteps: 1,393,623,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,488.32844
Policy Entropy: 3.73646
Value Function Loss: 0.01472

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.37896
Value Function Update Magnitude: 0.35211

Collected Steps per Second: 20,311.22880
Overall Steps per Second: 10,149.98404

Timestep Collection Time: 2.46297
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.92868

Cumulative Model Updates: 167,130
Cumulative Timesteps: 1,393,673,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1393673558...
Checkpoint 1393673558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,635.39391
Policy Entropy: 3.76452
Value Function Loss: 0.01799

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.40879
Value Function Update Magnitude: 0.41436

Collected Steps per Second: 20,577.21885
Overall Steps per Second: 10,143.82399

Timestep Collection Time: 2.43016
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.92970

Cumulative Model Updates: 167,136
Cumulative Timesteps: 1,393,723,564

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,693.59977
Policy Entropy: 3.81283
Value Function Loss: 0.02264

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.46393
Value Function Update Magnitude: 0.63383

Collected Steps per Second: 20,771.84598
Overall Steps per Second: 10,173.88176

Timestep Collection Time: 2.40778
Timestep Consumption Time: 2.50814
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.91592

Cumulative Model Updates: 167,142
Cumulative Timesteps: 1,393,773,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1393773578...
Checkpoint 1393773578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,331.82850
Policy Entropy: 3.82469
Value Function Loss: 0.02660

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12051
Policy Update Magnitude: 0.50720
Value Function Update Magnitude: 0.74597

Collected Steps per Second: 20,491.71597
Overall Steps per Second: 9,970.72152

Timestep Collection Time: 2.44099
Timestep Consumption Time: 2.57570
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 5.01669

Cumulative Model Updates: 167,148
Cumulative Timesteps: 1,393,823,598

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,225.27328
Policy Entropy: 3.81056
Value Function Loss: 0.02398

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.52721
Value Function Update Magnitude: 0.73702

Collected Steps per Second: 20,954.14006
Overall Steps per Second: 10,220.01798

Timestep Collection Time: 2.38616
Timestep Consumption Time: 2.50620
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.89236

Cumulative Model Updates: 167,154
Cumulative Timesteps: 1,393,873,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1393873598...
Checkpoint 1393873598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,510.76291
Policy Entropy: 3.76461
Value Function Loss: 0.02533

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.50976
Value Function Update Magnitude: 0.60838

Collected Steps per Second: 20,722.61042
Overall Steps per Second: 10,165.77781

Timestep Collection Time: 2.41408
Timestep Consumption Time: 2.50694
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.92102

Cumulative Model Updates: 167,160
Cumulative Timesteps: 1,393,923,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,149.14049
Policy Entropy: 3.76869
Value Function Loss: 0.02052

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.59090

Collected Steps per Second: 21,158.62058
Overall Steps per Second: 10,187.99980

Timestep Collection Time: 2.36424
Timestep Consumption Time: 2.54585
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.91009

Cumulative Model Updates: 167,166
Cumulative Timesteps: 1,393,973,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1393973648...
Checkpoint 1393973648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,048.88035
Policy Entropy: 3.78877
Value Function Loss: 0.02378

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.55598
Value Function Update Magnitude: 0.68945

Collected Steps per Second: 21,259.69247
Overall Steps per Second: 10,350.11844

Timestep Collection Time: 2.35243
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.83202

Cumulative Model Updates: 167,172
Cumulative Timesteps: 1,394,023,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,808.64865
Policy Entropy: 3.83061
Value Function Loss: 0.02370

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.71922

Collected Steps per Second: 20,614.05834
Overall Steps per Second: 10,146.14697

Timestep Collection Time: 2.42563
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.92818

Cumulative Model Updates: 167,178
Cumulative Timesteps: 1,394,073,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1394073662...
Checkpoint 1394073662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,750.98153
Policy Entropy: 3.82734
Value Function Loss: 0.02677

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.57531
Value Function Update Magnitude: 0.64324

Collected Steps per Second: 21,073.84941
Overall Steps per Second: 10,214.51419

Timestep Collection Time: 2.37318
Timestep Consumption Time: 2.52299
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.89617

Cumulative Model Updates: 167,184
Cumulative Timesteps: 1,394,123,674

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,253.54705
Policy Entropy: 3.82540
Value Function Loss: 0.02710

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.52485

Collected Steps per Second: 21,193.92710
Overall Steps per Second: 10,259.57845

Timestep Collection Time: 2.35992
Timestep Consumption Time: 2.51513
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.87505

Cumulative Model Updates: 167,190
Cumulative Timesteps: 1,394,173,690

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1394173690...
Checkpoint 1394173690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,741.16562
Policy Entropy: 3.80135
Value Function Loss: 0.03044

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.53628
Value Function Update Magnitude: 0.52217

Collected Steps per Second: 21,202.39214
Overall Steps per Second: 10,344.30404

Timestep Collection Time: 2.35832
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.83377

Cumulative Model Updates: 167,196
Cumulative Timesteps: 1,394,223,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,932.19411
Policy Entropy: 3.81858
Value Function Loss: 0.03003

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.67286

Collected Steps per Second: 21,028.68079
Overall Steps per Second: 10,142.52213

Timestep Collection Time: 2.37856
Timestep Consumption Time: 2.55295
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.93152

Cumulative Model Updates: 167,202
Cumulative Timesteps: 1,394,273,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1394273710...
Checkpoint 1394273710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,189.24621
Policy Entropy: 3.82273
Value Function Loss: 0.03077

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.59187
Value Function Update Magnitude: 0.73291

Collected Steps per Second: 21,186.84088
Overall Steps per Second: 10,201.26098

Timestep Collection Time: 2.36109
Timestep Consumption Time: 2.54262
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.90371

Cumulative Model Updates: 167,208
Cumulative Timesteps: 1,394,323,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,804.21629
Policy Entropy: 3.82395
Value Function Loss: 0.02979

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.61066
Value Function Update Magnitude: 0.70805

Collected Steps per Second: 21,246.83229
Overall Steps per Second: 10,216.39207

Timestep Collection Time: 2.35395
Timestep Consumption Time: 2.54152
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.89547

Cumulative Model Updates: 167,214
Cumulative Timesteps: 1,394,373,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1394373748...
Checkpoint 1394373748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,569.54228
Policy Entropy: 3.80829
Value Function Loss: 0.03026

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.58719
Value Function Update Magnitude: 0.61981

Collected Steps per Second: 21,122.26308
Overall Steps per Second: 10,215.95049

Timestep Collection Time: 2.36783
Timestep Consumption Time: 2.52784
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.89568

Cumulative Model Updates: 167,220
Cumulative Timesteps: 1,394,423,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,944.23207
Policy Entropy: 3.79364
Value Function Loss: 0.02596

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.61762

Collected Steps per Second: 21,168.55986
Overall Steps per Second: 10,346.90708

Timestep Collection Time: 2.36275
Timestep Consumption Time: 2.47116
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.83391

Cumulative Model Updates: 167,226
Cumulative Timesteps: 1,394,473,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1394473778...
Checkpoint 1394473778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,990.15311
Policy Entropy: 3.77286
Value Function Loss: 0.02968

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.54110
Value Function Update Magnitude: 0.57109

Collected Steps per Second: 21,322.29349
Overall Steps per Second: 10,245.27603

Timestep Collection Time: 2.34506
Timestep Consumption Time: 2.53544
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.88049

Cumulative Model Updates: 167,232
Cumulative Timesteps: 1,394,523,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,787.26309
Policy Entropy: 3.77488
Value Function Loss: 0.02912

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.51333

Collected Steps per Second: 20,637.86618
Overall Steps per Second: 10,096.62293

Timestep Collection Time: 2.42389
Timestep Consumption Time: 2.53063
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.95453

Cumulative Model Updates: 167,238
Cumulative Timesteps: 1,394,573,804

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1394573804...
Checkpoint 1394573804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,422.94972
Policy Entropy: 3.77840
Value Function Loss: 0.02937

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.58648
Value Function Update Magnitude: 0.49141

Collected Steps per Second: 20,938.16846
Overall Steps per Second: 10,107.90906

Timestep Collection Time: 2.38817
Timestep Consumption Time: 2.55884
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.94702

Cumulative Model Updates: 167,244
Cumulative Timesteps: 1,394,623,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,561.39185
Policy Entropy: 3.78530
Value Function Loss: 0.02497

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.56761
Value Function Update Magnitude: 0.45394

Collected Steps per Second: 20,932.77784
Overall Steps per Second: 10,179.45839

Timestep Collection Time: 2.38965
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.91401

Cumulative Model Updates: 167,250
Cumulative Timesteps: 1,394,673,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1394673830...
Checkpoint 1394673830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,298.69708
Policy Entropy: 3.77455
Value Function Loss: 0.02495

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.51673
Value Function Update Magnitude: 0.42842

Collected Steps per Second: 21,078.58826
Overall Steps per Second: 10,213.48737

Timestep Collection Time: 2.37245
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.89627

Cumulative Model Updates: 167,256
Cumulative Timesteps: 1,394,723,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,125.12291
Policy Entropy: 3.80016
Value Function Loss: 0.02436

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.47967
Value Function Update Magnitude: 0.47876

Collected Steps per Second: 20,982.15112
Overall Steps per Second: 10,272.23075

Timestep Collection Time: 2.38355
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.86866

Cumulative Model Updates: 167,262
Cumulative Timesteps: 1,394,773,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1394773850...
Checkpoint 1394773850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,112.01281
Policy Entropy: 3.80790
Value Function Loss: 0.02135

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.45875
Value Function Update Magnitude: 0.59890

Collected Steps per Second: 21,147.36523
Overall Steps per Second: 10,272.87886

Timestep Collection Time: 2.36597
Timestep Consumption Time: 2.50453
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.87049

Cumulative Model Updates: 167,268
Cumulative Timesteps: 1,394,823,884

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,602.04680
Policy Entropy: 3.78658
Value Function Loss: 0.01874

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.43405
Value Function Update Magnitude: 0.60631

Collected Steps per Second: 21,253.13631
Overall Steps per Second: 10,318.84624

Timestep Collection Time: 2.35372
Timestep Consumption Time: 2.49411
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.84783

Cumulative Model Updates: 167,274
Cumulative Timesteps: 1,394,873,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1394873908...
Checkpoint 1394873908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,870.39558
Policy Entropy: 3.77313
Value Function Loss: 0.01535

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.42184
Value Function Update Magnitude: 0.56859

Collected Steps per Second: 20,858.12806
Overall Steps per Second: 10,275.54851

Timestep Collection Time: 2.39743
Timestep Consumption Time: 2.46907
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.86650

Cumulative Model Updates: 167,280
Cumulative Timesteps: 1,394,923,914

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,213.07230
Policy Entropy: 3.76288
Value Function Loss: 0.01405

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12486
Policy Update Magnitude: 0.37733
Value Function Update Magnitude: 0.50070

Collected Steps per Second: 20,972.47517
Overall Steps per Second: 10,130.72405

Timestep Collection Time: 2.38513
Timestep Consumption Time: 2.55253
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.93765

Cumulative Model Updates: 167,286
Cumulative Timesteps: 1,394,973,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1394973936...
Checkpoint 1394973936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,004.00591
Policy Entropy: 3.77177
Value Function Loss: 0.01429

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.36919
Value Function Update Magnitude: 0.47846

Collected Steps per Second: 21,056.69332
Overall Steps per Second: 10,175.87778

Timestep Collection Time: 2.37492
Timestep Consumption Time: 2.53945
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.91437

Cumulative Model Updates: 167,292
Cumulative Timesteps: 1,395,023,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,088.80709
Policy Entropy: 3.76514
Value Function Loss: 0.01598

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.37392
Value Function Update Magnitude: 0.52545

Collected Steps per Second: 21,155.01476
Overall Steps per Second: 10,188.52871

Timestep Collection Time: 2.36492
Timestep Consumption Time: 2.54550
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.91042

Cumulative Model Updates: 167,298
Cumulative Timesteps: 1,395,073,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1395073974...
Checkpoint 1395073974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,399.12498
Policy Entropy: 3.76627
Value Function Loss: 0.01661

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.39225
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 21,036.70094
Overall Steps per Second: 10,156.11659

Timestep Collection Time: 2.37794
Timestep Consumption Time: 2.54757
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.92550

Cumulative Model Updates: 167,304
Cumulative Timesteps: 1,395,123,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,147.41046
Policy Entropy: 3.77097
Value Function Loss: 0.01700

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.38836
Value Function Update Magnitude: 0.51987

Collected Steps per Second: 20,737.81428
Overall Steps per Second: 10,065.42729

Timestep Collection Time: 2.41202
Timestep Consumption Time: 2.55747
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.96949

Cumulative Model Updates: 167,310
Cumulative Timesteps: 1,395,174,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1395174018...
Checkpoint 1395174018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.70117
Policy Entropy: 3.78887
Value Function Loss: 0.01667

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11420
Policy Update Magnitude: 0.41156
Value Function Update Magnitude: 0.58101

Collected Steps per Second: 21,052.52969
Overall Steps per Second: 10,181.80539

Timestep Collection Time: 2.37615
Timestep Consumption Time: 2.53693
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.91308

Cumulative Model Updates: 167,316
Cumulative Timesteps: 1,395,224,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,393.62125
Policy Entropy: 3.78004
Value Function Loss: 0.01816

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.41224
Value Function Update Magnitude: 0.64701

Collected Steps per Second: 20,854.47991
Overall Steps per Second: 10,132.69634

Timestep Collection Time: 2.39814
Timestep Consumption Time: 2.53756
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.93570

Cumulative Model Updates: 167,322
Cumulative Timesteps: 1,395,274,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395274054...
Checkpoint 1395274054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,934.85950
Policy Entropy: 3.78962
Value Function Loss: 0.01994

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.43226
Value Function Update Magnitude: 0.61526

Collected Steps per Second: 20,649.80105
Overall Steps per Second: 10,075.70357

Timestep Collection Time: 2.42182
Timestep Consumption Time: 2.54161
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.96343

Cumulative Model Updates: 167,328
Cumulative Timesteps: 1,395,324,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,315.67098
Policy Entropy: 3.77414
Value Function Loss: 0.02277

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12541
Policy Update Magnitude: 0.46446
Value Function Update Magnitude: 0.52226

Collected Steps per Second: 20,799.85966
Overall Steps per Second: 10,166.98395

Timestep Collection Time: 2.40444
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.91906

Cumulative Model Updates: 167,334
Cumulative Timesteps: 1,395,374,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395374076...
Checkpoint 1395374076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,134.63564
Policy Entropy: 3.77335
Value Function Loss: 0.02824

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.47279
Value Function Update Magnitude: 0.45584

Collected Steps per Second: 20,704.14207
Overall Steps per Second: 10,073.99308

Timestep Collection Time: 2.41498
Timestep Consumption Time: 2.54830
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.96328

Cumulative Model Updates: 167,340
Cumulative Timesteps: 1,395,424,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,425.67549
Policy Entropy: 3.78058
Value Function Loss: 0.02924

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.52067
Value Function Update Magnitude: 0.40572

Collected Steps per Second: 20,815.29902
Overall Steps per Second: 10,149.68956

Timestep Collection Time: 2.40352
Timestep Consumption Time: 2.52569
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.92921

Cumulative Model Updates: 167,346
Cumulative Timesteps: 1,395,474,106

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1395474106...
Checkpoint 1395474106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,297.37783
Policy Entropy: 3.80236
Value Function Loss: 0.03338

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.51891
Value Function Update Magnitude: 0.37982

Collected Steps per Second: 20,237.31952
Overall Steps per Second: 10,104.77491

Timestep Collection Time: 2.47128
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.94934

Cumulative Model Updates: 167,352
Cumulative Timesteps: 1,395,524,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,223.69949
Policy Entropy: 3.85695
Value Function Loss: 0.03226

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.44719

Collected Steps per Second: 20,759.27766
Overall Steps per Second: 10,088.70502

Timestep Collection Time: 2.40981
Timestep Consumption Time: 2.54880
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.95861

Cumulative Model Updates: 167,358
Cumulative Timesteps: 1,395,574,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1395574144...
Checkpoint 1395574144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,066.45276
Policy Entropy: 3.85216
Value Function Loss: 0.03327

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.57018
Value Function Update Magnitude: 0.47331

Collected Steps per Second: 20,602.59671
Overall Steps per Second: 10,094.21204

Timestep Collection Time: 2.42824
Timestep Consumption Time: 2.52787
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.95611

Cumulative Model Updates: 167,364
Cumulative Timesteps: 1,395,624,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,965.87832
Policy Entropy: 3.85382
Value Function Loss: 0.02663

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.50916

Collected Steps per Second: 20,654.62849
Overall Steps per Second: 10,104.34598

Timestep Collection Time: 2.42135
Timestep Consumption Time: 2.52821
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.94955

Cumulative Model Updates: 167,370
Cumulative Timesteps: 1,395,674,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1395674184...
Checkpoint 1395674184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.21747
Policy Entropy: 3.79397
Value Function Loss: 0.02368

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.47981
Value Function Update Magnitude: 0.46287

Collected Steps per Second: 20,661.95188
Overall Steps per Second: 10,174.15607

Timestep Collection Time: 2.42000
Timestep Consumption Time: 2.49461
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.91461

Cumulative Model Updates: 167,376
Cumulative Timesteps: 1,395,724,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,063.21747
Policy Entropy: 3.77951
Value Function Loss: 0.01916

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.40842
Value Function Update Magnitude: 0.36218

Collected Steps per Second: 20,815.13289
Overall Steps per Second: 10,046.58464

Timestep Collection Time: 2.40344
Timestep Consumption Time: 2.57616
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.97960

Cumulative Model Updates: 167,382
Cumulative Timesteps: 1,395,774,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1395774214...
Checkpoint 1395774214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,743.65534
Policy Entropy: 3.75405
Value Function Loss: 0.01886

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.39410
Value Function Update Magnitude: 0.33026

Collected Steps per Second: 20,669.53133
Overall Steps per Second: 10,229.10061

Timestep Collection Time: 2.42008
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.89017

Cumulative Model Updates: 167,388
Cumulative Timesteps: 1,395,824,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,115.88257
Policy Entropy: 3.74871
Value Function Loss: 0.01996

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.40366
Value Function Update Magnitude: 0.33309

Collected Steps per Second: 20,718.23919
Overall Steps per Second: 10,105.35624

Timestep Collection Time: 2.41536
Timestep Consumption Time: 2.53667
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.95203

Cumulative Model Updates: 167,394
Cumulative Timesteps: 1,395,874,278

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1395874278...
Checkpoint 1395874278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,642.23202
Policy Entropy: 3.77695
Value Function Loss: 0.01929

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11805
Policy Update Magnitude: 0.43701
Value Function Update Magnitude: 0.41701

Collected Steps per Second: 20,666.26409
Overall Steps per Second: 10,278.64850

Timestep Collection Time: 2.42008
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.86581

Cumulative Model Updates: 167,400
Cumulative Timesteps: 1,395,924,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,869.77708
Policy Entropy: 3.75600
Value Function Loss: 0.02123

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.44340
Value Function Update Magnitude: 0.44511

Collected Steps per Second: 20,646.65918
Overall Steps per Second: 10,050.31084

Timestep Collection Time: 2.42199
Timestep Consumption Time: 2.55358
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.97557

Cumulative Model Updates: 167,406
Cumulative Timesteps: 1,395,974,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1395974298...
Checkpoint 1395974298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,548.77395
Policy Entropy: 3.78415
Value Function Loss: 0.01883

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.48068
Value Function Update Magnitude: 0.50454

Collected Steps per Second: 20,931.06149
Overall Steps per Second: 10,139.12493

Timestep Collection Time: 2.38975
Timestep Consumption Time: 2.54361
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.93336

Cumulative Model Updates: 167,412
Cumulative Timesteps: 1,396,024,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,699.92458
Policy Entropy: 3.76455
Value Function Loss: 0.02326

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.47822
Value Function Update Magnitude: 0.51531

Collected Steps per Second: 20,535.43844
Overall Steps per Second: 10,047.38833

Timestep Collection Time: 2.43501
Timestep Consumption Time: 2.54181
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.97682

Cumulative Model Updates: 167,418
Cumulative Timesteps: 1,396,074,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1396074322...
Checkpoint 1396074322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,419.63169
Policy Entropy: 3.79505
Value Function Loss: 0.02270

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.49214
Value Function Update Magnitude: 0.42681

Collected Steps per Second: 21,018.49719
Overall Steps per Second: 10,223.62431

Timestep Collection Time: 2.38019
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.89337

Cumulative Model Updates: 167,424
Cumulative Timesteps: 1,396,124,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,825.74390
Policy Entropy: 3.77784
Value Function Loss: 0.02310

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.48714
Value Function Update Magnitude: 0.41045

Collected Steps per Second: 21,101.49126
Overall Steps per Second: 10,184.45598

Timestep Collection Time: 2.37035
Timestep Consumption Time: 2.54086
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.91121

Cumulative Model Updates: 167,430
Cumulative Timesteps: 1,396,174,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1396174368...
Checkpoint 1396174368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,240.01713
Policy Entropy: 3.79405
Value Function Loss: 0.01920

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.49975
Value Function Update Magnitude: 0.54460

Collected Steps per Second: 20,643.17533
Overall Steps per Second: 10,037.10429

Timestep Collection Time: 2.42269
Timestep Consumption Time: 2.56002
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.98271

Cumulative Model Updates: 167,436
Cumulative Timesteps: 1,396,224,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,611.86656
Policy Entropy: 3.78719
Value Function Loss: 0.01834

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.48503
Value Function Update Magnitude: 0.61547

Collected Steps per Second: 20,979.49781
Overall Steps per Second: 10,120.86634

Timestep Collection Time: 2.38461
Timestep Consumption Time: 2.55844
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.94306

Cumulative Model Updates: 167,442
Cumulative Timesteps: 1,396,274,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1396274408...
Checkpoint 1396274408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,976.23590
Policy Entropy: 3.79290
Value Function Loss: 0.02244

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.46747
Value Function Update Magnitude: 0.52513

Collected Steps per Second: 20,639.79741
Overall Steps per Second: 10,236.34314

Timestep Collection Time: 2.42386
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.88729

Cumulative Model Updates: 167,448
Cumulative Timesteps: 1,396,324,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,363.87118
Policy Entropy: 3.81852
Value Function Loss: 0.02319

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.49876
Value Function Update Magnitude: 0.50089

Collected Steps per Second: 20,919.19798
Overall Steps per Second: 10,285.71398

Timestep Collection Time: 2.39024
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.86131

Cumulative Model Updates: 167,454
Cumulative Timesteps: 1,396,374,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1396374438...
Checkpoint 1396374438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,456.46458
Policy Entropy: 3.81725
Value Function Loss: 0.02747

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11102
Policy Update Magnitude: 0.54791
Value Function Update Magnitude: 0.55213

Collected Steps per Second: 20,811.55064
Overall Steps per Second: 10,241.65659

Timestep Collection Time: 2.40405
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.88515

Cumulative Model Updates: 167,460
Cumulative Timesteps: 1,396,424,470

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,826.06223
Policy Entropy: 3.82329
Value Function Loss: 0.02357

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.55733

Collected Steps per Second: 20,969.06528
Overall Steps per Second: 10,130.79681

Timestep Collection Time: 2.38532
Timestep Consumption Time: 2.55190
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.93722

Cumulative Model Updates: 167,466
Cumulative Timesteps: 1,396,474,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1396474488...
Checkpoint 1396474488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,485.12043
Policy Entropy: 3.80354
Value Function Loss: 0.02326

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.61934
Value Function Update Magnitude: 0.61006

Collected Steps per Second: 20,684.79325
Overall Steps per Second: 10,197.44788

Timestep Collection Time: 2.41723
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.90319

Cumulative Model Updates: 167,472
Cumulative Timesteps: 1,396,524,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,667.01700
Policy Entropy: 3.80593
Value Function Loss: 0.02188

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.61289
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 20,969.24970
Overall Steps per Second: 10,053.67986

Timestep Collection Time: 2.38540
Timestep Consumption Time: 2.58989
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.97529

Cumulative Model Updates: 167,478
Cumulative Timesteps: 1,396,574,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1396574508...
Checkpoint 1396574508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,142.85949
Policy Entropy: 3.79357
Value Function Loss: 0.02516

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.59805
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 20,866.79911
Overall Steps per Second: 10,174.10472

Timestep Collection Time: 2.39797
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.91817

Cumulative Model Updates: 167,484
Cumulative Timesteps: 1,396,624,546

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,988.10906
Policy Entropy: 3.79906
Value Function Loss: 0.02400

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.63073
Value Function Update Magnitude: 0.66977

Collected Steps per Second: 20,767.09069
Overall Steps per Second: 10,061.07938

Timestep Collection Time: 2.40775
Timestep Consumption Time: 2.56209
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.96984

Cumulative Model Updates: 167,490
Cumulative Timesteps: 1,396,674,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1396674548...
Checkpoint 1396674548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,724.75063
Policy Entropy: 3.80534
Value Function Loss: 0.02662

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.61704
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 18,950.97508
Overall Steps per Second: 9,797.91751

Timestep Collection Time: 2.63997
Timestep Consumption Time: 2.46622
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 5.10619

Cumulative Model Updates: 167,496
Cumulative Timesteps: 1,396,724,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244.96005
Policy Entropy: 3.83444
Value Function Loss: 0.02678

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11450
Policy Update Magnitude: 0.62040
Value Function Update Magnitude: 0.58177

Collected Steps per Second: 20,894.61091
Overall Steps per Second: 10,135.34212

Timestep Collection Time: 2.39334
Timestep Consumption Time: 2.54068
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.93402

Cumulative Model Updates: 167,502
Cumulative Timesteps: 1,396,774,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1396774586...
Checkpoint 1396774586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.06752
Policy Entropy: 3.85063
Value Function Loss: 0.02744

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.59022
Value Function Update Magnitude: 0.50040

Collected Steps per Second: 20,644.32270
Overall Steps per Second: 10,212.15343

Timestep Collection Time: 2.42372
Timestep Consumption Time: 2.47593
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.89965

Cumulative Model Updates: 167,508
Cumulative Timesteps: 1,396,824,622

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,485.63396
Policy Entropy: 3.81952
Value Function Loss: 0.02584

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.48194

Collected Steps per Second: 20,958.25692
Overall Steps per Second: 10,158.57138

Timestep Collection Time: 2.38713
Timestep Consumption Time: 2.53778
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.92491

Cumulative Model Updates: 167,514
Cumulative Timesteps: 1,396,874,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1396874652...
Checkpoint 1396874652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,653.21524
Policy Entropy: 3.80007
Value Function Loss: 0.02685

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11607
Policy Update Magnitude: 0.52442
Value Function Update Magnitude: 0.56551

Collected Steps per Second: 19,947.32464
Overall Steps per Second: 10,192.22347

Timestep Collection Time: 2.50690
Timestep Consumption Time: 2.39939
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.90629

Cumulative Model Updates: 167,520
Cumulative Timesteps: 1,396,924,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,901.36980
Policy Entropy: 3.77840
Value Function Loss: 0.02681

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 20,436.72067
Overall Steps per Second: 10,339.05736

Timestep Collection Time: 2.44677
Timestep Consumption Time: 2.38965
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.83642

Cumulative Model Updates: 167,526
Cumulative Timesteps: 1,396,974,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1396974662...
Checkpoint 1396974662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,858.71812
Policy Entropy: 3.80294
Value Function Loss: 0.02621

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.61451
Value Function Update Magnitude: 0.63867

Collected Steps per Second: 20,191.70653
Overall Steps per Second: 10,241.07823

Timestep Collection Time: 2.47646
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.88269

Cumulative Model Updates: 167,532
Cumulative Timesteps: 1,397,024,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,669.84572
Policy Entropy: 3.79982
Value Function Loss: 0.02204

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.60379
Value Function Update Magnitude: 0.63592

Collected Steps per Second: 19,929.88636
Overall Steps per Second: 10,058.33812

Timestep Collection Time: 2.50950
Timestep Consumption Time: 2.46289
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.97239

Cumulative Model Updates: 167,538
Cumulative Timesteps: 1,397,074,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1397074680...
Checkpoint 1397074680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,726.60268
Policy Entropy: 3.79964
Value Function Loss: 0.01944

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.53031
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 19,920.04345
Overall Steps per Second: 9,948.23952

Timestep Collection Time: 2.51104
Timestep Consumption Time: 2.51699
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 5.02803

Cumulative Model Updates: 167,544
Cumulative Timesteps: 1,397,124,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,292.34347
Policy Entropy: 3.77788
Value Function Loss: 0.01760

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.44022
Value Function Update Magnitude: 0.48453

Collected Steps per Second: 20,828.52724
Overall Steps per Second: 10,278.55184

Timestep Collection Time: 2.40103
Timestep Consumption Time: 2.46444
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.86547

Cumulative Model Updates: 167,550
Cumulative Timesteps: 1,397,174,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1397174710...
Checkpoint 1397174710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,398.97219
Policy Entropy: 3.76175
Value Function Loss: 0.01638

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.41912
Value Function Update Magnitude: 0.50219

Collected Steps per Second: 20,700.87521
Overall Steps per Second: 10,272.24362

Timestep Collection Time: 2.41594
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.86865

Cumulative Model Updates: 167,556
Cumulative Timesteps: 1,397,224,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,398.97219
Policy Entropy: 3.75550
Value Function Loss: 0.01749

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.41883
Value Function Update Magnitude: 0.51455

Collected Steps per Second: 20,870.28443
Overall Steps per Second: 10,100.32596

Timestep Collection Time: 2.39585
Timestep Consumption Time: 2.55469
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.95053

Cumulative Model Updates: 167,562
Cumulative Timesteps: 1,397,274,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1397274724...
Checkpoint 1397274724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,739.82783
Policy Entropy: 3.77428
Value Function Loss: 0.01770

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.43947
Value Function Update Magnitude: 0.48777

Collected Steps per Second: 20,649.93577
Overall Steps per Second: 10,135.71974

Timestep Collection Time: 2.42180
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.93404

Cumulative Model Updates: 167,568
Cumulative Timesteps: 1,397,324,734

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,259.50358
Policy Entropy: 3.78874
Value Function Loss: 0.01809

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.43052
Value Function Update Magnitude: 0.49443

Collected Steps per Second: 21,310.55754
Overall Steps per Second: 10,357.57119

Timestep Collection Time: 2.34757
Timestep Consumption Time: 2.48252
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.83009

Cumulative Model Updates: 167,574
Cumulative Timesteps: 1,397,374,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1397374762...
Checkpoint 1397374762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,606.85756
Policy Entropy: 3.78991
Value Function Loss: 0.01917

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.43768
Value Function Update Magnitude: 0.57494

Collected Steps per Second: 20,347.28711
Overall Steps per Second: 9,931.64079

Timestep Collection Time: 2.45802
Timestep Consumption Time: 2.57781
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 5.03582

Cumulative Model Updates: 167,580
Cumulative Timesteps: 1,397,424,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,455.46522
Policy Entropy: 3.79469
Value Function Loss: 0.01816

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.46839
Value Function Update Magnitude: 0.61060

Collected Steps per Second: 21,496.42411
Overall Steps per Second: 10,385.02472

Timestep Collection Time: 2.32681
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.81636

Cumulative Model Updates: 167,586
Cumulative Timesteps: 1,397,474,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1397474794...
Checkpoint 1397474794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.20718
Policy Entropy: 3.78545
Value Function Loss: 0.01753

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.46350
Value Function Update Magnitude: 0.56260

Collected Steps per Second: 20,976.19034
Overall Steps per Second: 10,260.66726

Timestep Collection Time: 2.38499
Timestep Consumption Time: 2.49072
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.87571

Cumulative Model Updates: 167,592
Cumulative Timesteps: 1,397,524,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.26852
Policy Entropy: 3.79077
Value Function Loss: 0.01498

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12235
Policy Update Magnitude: 0.41513
Value Function Update Magnitude: 0.52993

Collected Steps per Second: 21,099.71342
Overall Steps per Second: 10,126.07492

Timestep Collection Time: 2.37074
Timestep Consumption Time: 2.56918
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.93992

Cumulative Model Updates: 167,598
Cumulative Timesteps: 1,397,574,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397574844...
Checkpoint 1397574844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,397.87401
Policy Entropy: 3.78367
Value Function Loss: 0.01522

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.38893
Value Function Update Magnitude: 0.47038

Collected Steps per Second: 20,979.10485
Overall Steps per Second: 10,147.59734

Timestep Collection Time: 2.38475
Timestep Consumption Time: 2.54548
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.93023

Cumulative Model Updates: 167,604
Cumulative Timesteps: 1,397,624,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,942.53258
Policy Entropy: 3.78112
Value Function Loss: 0.01386

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.37761
Value Function Update Magnitude: 0.47655

Collected Steps per Second: 20,861.37520
Overall Steps per Second: 10,134.62548

Timestep Collection Time: 2.39783
Timestep Consumption Time: 2.53792
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.93575

Cumulative Model Updates: 167,610
Cumulative Timesteps: 1,397,674,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397674896...
Checkpoint 1397674896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,026.96283
Policy Entropy: 3.77194
Value Function Loss: 0.01456

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.37884
Value Function Update Magnitude: 0.44554

Collected Steps per Second: 20,942.88801
Overall Steps per Second: 10,157.90155

Timestep Collection Time: 2.38840
Timestep Consumption Time: 2.53585
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.92425

Cumulative Model Updates: 167,616
Cumulative Timesteps: 1,397,724,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,026.96283
Policy Entropy: 3.75480
Value Function Loss: 0.01403

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.37782
Value Function Update Magnitude: 0.38781

Collected Steps per Second: 20,515.15674
Overall Steps per Second: 9,996.11942

Timestep Collection Time: 2.43742
Timestep Consumption Time: 2.56492
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 5.00234

Cumulative Model Updates: 167,622
Cumulative Timesteps: 1,397,774,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1397774920...
Checkpoint 1397774920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,809.53270
Policy Entropy: 3.75145
Value Function Loss: 0.01676

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.37771
Value Function Update Magnitude: 0.37617

Collected Steps per Second: 20,454.91328
Overall Steps per Second: 10,158.05560

Timestep Collection Time: 2.44557
Timestep Consumption Time: 2.47899
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.92456

Cumulative Model Updates: 167,628
Cumulative Timesteps: 1,397,824,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,567.47547
Policy Entropy: 3.76491
Value Function Loss: 0.01657

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.37628
Value Function Update Magnitude: 0.44976

Collected Steps per Second: 20,686.34497
Overall Steps per Second: 10,109.23001

Timestep Collection Time: 2.41802
Timestep Consumption Time: 2.52993
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.94795

Cumulative Model Updates: 167,634
Cumulative Timesteps: 1,397,874,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1397874964...
Checkpoint 1397874964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.33583
Policy Entropy: 3.78959
Value Function Loss: 0.01838

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.38600
Value Function Update Magnitude: 0.53414

Collected Steps per Second: 21,109.00531
Overall Steps per Second: 10,324.04777

Timestep Collection Time: 2.36923
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.84422

Cumulative Model Updates: 167,640
Cumulative Timesteps: 1,397,924,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,759.90083
Policy Entropy: 3.81365
Value Function Loss: 0.01945

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.42101
Value Function Update Magnitude: 0.66550

Collected Steps per Second: 21,385.57327
Overall Steps per Second: 10,399.50658

Timestep Collection Time: 2.33905
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.81004

Cumulative Model Updates: 167,646
Cumulative Timesteps: 1,397,974,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1397974998...
Checkpoint 1397974998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,155.36970
Policy Entropy: 3.82693
Value Function Loss: 0.02073

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.47599
Value Function Update Magnitude: 0.80640

Collected Steps per Second: 21,470.58293
Overall Steps per Second: 10,206.95893

Timestep Collection Time: 2.32895
Timestep Consumption Time: 2.57006
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.89901

Cumulative Model Updates: 167,652
Cumulative Timesteps: 1,398,025,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,310.95263
Policy Entropy: 3.80455
Value Function Loss: 0.02091

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.50603
Value Function Update Magnitude: 0.80937

Collected Steps per Second: 21,115.55995
Overall Steps per Second: 10,192.00722

Timestep Collection Time: 2.36821
Timestep Consumption Time: 2.53819
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.90639

Cumulative Model Updates: 167,658
Cumulative Timesteps: 1,398,075,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1398075008...
Checkpoint 1398075008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,904.86003
Policy Entropy: 3.78533
Value Function Loss: 0.01922

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.48786
Value Function Update Magnitude: 0.73011

Collected Steps per Second: 21,058.65521
Overall Steps per Second: 10,159.61724

Timestep Collection Time: 2.37556
Timestep Consumption Time: 2.54845
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.92400

Cumulative Model Updates: 167,664
Cumulative Timesteps: 1,398,125,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,998.61945
Policy Entropy: 3.77030
Value Function Loss: 0.01760

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.44559
Value Function Update Magnitude: 0.72305

Collected Steps per Second: 21,093.11249
Overall Steps per Second: 10,323.04974

Timestep Collection Time: 2.37092
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.84450

Cumulative Model Updates: 167,670
Cumulative Timesteps: 1,398,175,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1398175044...
Checkpoint 1398175044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,944.87545
Policy Entropy: 3.78909
Value Function Loss: 0.01423

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.41493
Value Function Update Magnitude: 0.68070

Collected Steps per Second: 21,204.03643
Overall Steps per Second: 10,326.24192

Timestep Collection Time: 2.35804
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.84203

Cumulative Model Updates: 167,676
Cumulative Timesteps: 1,398,225,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,231.43392
Policy Entropy: 3.78163
Value Function Loss: 0.01258

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.38446
Value Function Update Magnitude: 0.58471

Collected Steps per Second: 20,553.65161
Overall Steps per Second: 10,049.46206

Timestep Collection Time: 2.43334
Timestep Consumption Time: 2.54344
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.97678

Cumulative Model Updates: 167,682
Cumulative Timesteps: 1,398,275,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1398275058...
Checkpoint 1398275058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,744.21323
Policy Entropy: 3.77214
Value Function Loss: 0.01066

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.36563
Value Function Update Magnitude: 0.51236

Collected Steps per Second: 21,092.04219
Overall Steps per Second: 10,157.20085

Timestep Collection Time: 2.37142
Timestep Consumption Time: 2.55297
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.92439

Cumulative Model Updates: 167,688
Cumulative Timesteps: 1,398,325,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,518.87238
Policy Entropy: 3.76891
Value Function Loss: 0.01826

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12909
Policy Update Magnitude: 0.39012
Value Function Update Magnitude: 0.59937

Collected Steps per Second: 21,068.01160
Overall Steps per Second: 10,193.10788

Timestep Collection Time: 2.37355
Timestep Consumption Time: 2.53231
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.90586

Cumulative Model Updates: 167,694
Cumulative Timesteps: 1,398,375,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1398375082...
Checkpoint 1398375082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,721.53546
Policy Entropy: 3.79335
Value Function Loss: 0.01962

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.50041
Value Function Update Magnitude: 0.80560

Collected Steps per Second: 21,188.33818
Overall Steps per Second: 10,193.78646

Timestep Collection Time: 2.36149
Timestep Consumption Time: 2.54699
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.90848

Cumulative Model Updates: 167,700
Cumulative Timesteps: 1,398,425,118

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.18869
Policy Entropy: 3.79772
Value Function Loss: 0.02325

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.53730
Value Function Update Magnitude: 0.85424

Collected Steps per Second: 20,985.10309
Overall Steps per Second: 10,291.92539

Timestep Collection Time: 2.38312
Timestep Consumption Time: 2.47603
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.85915

Cumulative Model Updates: 167,706
Cumulative Timesteps: 1,398,475,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1398475128...
Checkpoint 1398475128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,268.54529
Policy Entropy: 3.79154
Value Function Loss: 0.02093

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.83064

Collected Steps per Second: 20,805.14142
Overall Steps per Second: 10,193.62693

Timestep Collection Time: 2.40354
Timestep Consumption Time: 2.50207
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.90561

Cumulative Model Updates: 167,712
Cumulative Timesteps: 1,398,525,134

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,318.58661
Policy Entropy: 3.75983
Value Function Loss: 0.01975

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.72852

Collected Steps per Second: 20,629.73048
Overall Steps per Second: 10,052.05982

Timestep Collection Time: 2.42504
Timestep Consumption Time: 2.55185
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.97689

Cumulative Model Updates: 167,718
Cumulative Timesteps: 1,398,575,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1398575162...
Checkpoint 1398575162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,318.58661
Policy Entropy: 3.75264
Value Function Loss: 0.01802

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.49584
Value Function Update Magnitude: 0.55229

Collected Steps per Second: 20,732.60166
Overall Steps per Second: 10,197.10634

Timestep Collection Time: 2.41272
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.90551

Cumulative Model Updates: 167,724
Cumulative Timesteps: 1,398,625,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,318.58661
Policy Entropy: 3.74656
Value Function Loss: 0.01624

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.44449
Value Function Update Magnitude: 0.42455

Collected Steps per Second: 20,663.97019
Overall Steps per Second: 10,007.23105

Timestep Collection Time: 2.42074
Timestep Consumption Time: 2.57785
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.99859

Cumulative Model Updates: 167,730
Cumulative Timesteps: 1,398,675,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1398675206...
Checkpoint 1398675206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,407.47686
Policy Entropy: 3.74631
Value Function Loss: 0.01581

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.41345
Value Function Update Magnitude: 0.35290

Collected Steps per Second: 19,703.93424
Overall Steps per Second: 9,915.45923

Timestep Collection Time: 2.53777
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 5.04303

Cumulative Model Updates: 167,736
Cumulative Timesteps: 1,398,725,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,462.51995
Policy Entropy: 3.74295
Value Function Loss: 0.01663

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.41103
Value Function Update Magnitude: 0.32846

Collected Steps per Second: 19,917.35608
Overall Steps per Second: 9,992.74015

Timestep Collection Time: 2.51067
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 5.00423

Cumulative Model Updates: 167,742
Cumulative Timesteps: 1,398,775,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1398775216...
Checkpoint 1398775216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,462.51995
Policy Entropy: 3.75028
Value Function Loss: 0.01698

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.41840
Value Function Update Magnitude: 0.31691

Collected Steps per Second: 20,678.69996
Overall Steps per Second: 10,206.86108

Timestep Collection Time: 2.41862
Timestep Consumption Time: 2.48141
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.90004

Cumulative Model Updates: 167,748
Cumulative Timesteps: 1,398,825,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,462.51995
Policy Entropy: 3.74261
Value Function Loss: 0.01527

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.42956
Value Function Update Magnitude: 0.33383

Collected Steps per Second: 20,803.22168
Overall Steps per Second: 10,110.09298

Timestep Collection Time: 2.40376
Timestep Consumption Time: 2.54238
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.94615

Cumulative Model Updates: 167,754
Cumulative Timesteps: 1,398,875,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1398875236...
Checkpoint 1398875236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,462.51995
Policy Entropy: 3.74654
Value Function Loss: 0.01537

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.43429
Value Function Update Magnitude: 0.33303

Collected Steps per Second: 20,938.19996
Overall Steps per Second: 10,252.65128

Timestep Collection Time: 2.38913
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.87913

Cumulative Model Updates: 167,760
Cumulative Timesteps: 1,398,925,260

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,178.31326
Policy Entropy: 3.75163
Value Function Loss: 0.01529

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.42247
Value Function Update Magnitude: 0.33152

Collected Steps per Second: 19,975.33765
Overall Steps per Second: 10,031.66213

Timestep Collection Time: 2.50309
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.98422

Cumulative Model Updates: 167,766
Cumulative Timesteps: 1,398,975,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1398975260...
Checkpoint 1398975260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,524.79159
Policy Entropy: 3.78229
Value Function Loss: 0.01639

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.41556
Value Function Update Magnitude: 0.38199

Collected Steps per Second: 20,234.67187
Overall Steps per Second: 10,250.69574

Timestep Collection Time: 2.47219
Timestep Consumption Time: 2.40787
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.88006

Cumulative Model Updates: 167,772
Cumulative Timesteps: 1,399,025,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,491.71649
Policy Entropy: 3.77775
Value Function Loss: 0.01717

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.44023
Value Function Update Magnitude: 0.41984

Collected Steps per Second: 19,661.06776
Overall Steps per Second: 10,005.07337

Timestep Collection Time: 2.54320
Timestep Consumption Time: 2.45447
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.99766

Cumulative Model Updates: 167,778
Cumulative Timesteps: 1,399,075,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1399075286...
Checkpoint 1399075286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.30172
Policy Entropy: 3.78782
Value Function Loss: 0.01747

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.46350
Value Function Update Magnitude: 0.50802

Collected Steps per Second: 20,078.35495
Overall Steps per Second: 10,125.86657

Timestep Collection Time: 2.49174
Timestep Consumption Time: 2.44907
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.94081

Cumulative Model Updates: 167,784
Cumulative Timesteps: 1,399,125,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,313.31857
Policy Entropy: 3.76121
Value Function Loss: 0.01655

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.45866
Value Function Update Magnitude: 0.52735

Collected Steps per Second: 20,534.00147
Overall Steps per Second: 10,197.28758

Timestep Collection Time: 2.43538
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.90405

Cumulative Model Updates: 167,790
Cumulative Timesteps: 1,399,175,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1399175324...
Checkpoint 1399175324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,974.74304
Policy Entropy: 3.78063
Value Function Loss: 0.02050

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.50222
Value Function Update Magnitude: 0.48584

Collected Steps per Second: 20,614.97127
Overall Steps per Second: 10,213.10004

Timestep Collection Time: 2.42620
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.89724

Cumulative Model Updates: 167,796
Cumulative Timesteps: 1,399,225,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,123.07045
Policy Entropy: 3.78643
Value Function Loss: 0.02105

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.60081
Value Function Update Magnitude: 0.57058

Collected Steps per Second: 20,667.48531
Overall Steps per Second: 10,107.10042

Timestep Collection Time: 2.41994
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.94840

Cumulative Model Updates: 167,802
Cumulative Timesteps: 1,399,275,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1399275354...
Checkpoint 1399275354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,613.68202
Policy Entropy: 3.80644
Value Function Loss: 0.02314

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13158
Policy Update Magnitude: 0.60823
Value Function Update Magnitude: 0.66229

Collected Steps per Second: 20,901.53469
Overall Steps per Second: 10,098.54268

Timestep Collection Time: 2.39246
Timestep Consumption Time: 2.55935
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.95180

Cumulative Model Updates: 167,808
Cumulative Timesteps: 1,399,325,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,599.85372
Policy Entropy: 3.79637
Value Function Loss: 0.02320

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.61458

Collected Steps per Second: 20,877.94837
Overall Steps per Second: 10,073.24351

Timestep Collection Time: 2.39545
Timestep Consumption Time: 2.56939
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.96484

Cumulative Model Updates: 167,814
Cumulative Timesteps: 1,399,375,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1399375372...
Checkpoint 1399375372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,674.35826
Policy Entropy: 3.78541
Value Function Loss: 0.02167

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.54190
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 20,927.83323
Overall Steps per Second: 10,220.56778

Timestep Collection Time: 2.39107
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.89601

Cumulative Model Updates: 167,820
Cumulative Timesteps: 1,399,425,412

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,770.13891
Policy Entropy: 3.76251
Value Function Loss: 0.02103

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.52296
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 20,987.66815
Overall Steps per Second: 10,184.05236

Timestep Collection Time: 2.38349
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.91199

Cumulative Model Updates: 167,826
Cumulative Timesteps: 1,399,475,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1399475436...
Checkpoint 1399475436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,901.84268
Policy Entropy: 3.77568
Value Function Loss: 0.01811

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.51172
Value Function Update Magnitude: 0.57455

Collected Steps per Second: 20,920.00072
Overall Steps per Second: 10,113.18853

Timestep Collection Time: 2.39092
Timestep Consumption Time: 2.55490
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.94582

Cumulative Model Updates: 167,832
Cumulative Timesteps: 1,399,525,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,044.93023
Policy Entropy: 3.77477
Value Function Loss: 0.01740

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.48402
Value Function Update Magnitude: 0.49032

Collected Steps per Second: 20,622.73908
Overall Steps per Second: 9,983.90794

Timestep Collection Time: 2.42451
Timestep Consumption Time: 2.58355
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 5.00806

Cumulative Model Updates: 167,838
Cumulative Timesteps: 1,399,575,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1399575454...
Checkpoint 1399575454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.49150
Policy Entropy: 3.79368
Value Function Loss: 0.01453

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.44623
Value Function Update Magnitude: 0.45574

Collected Steps per Second: 20,963.17145
Overall Steps per Second: 10,250.38582

Timestep Collection Time: 2.38533
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.87826

Cumulative Model Updates: 167,844
Cumulative Timesteps: 1,399,625,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,409.60982
Policy Entropy: 3.78662
Value Function Loss: 0.01826

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.46372
Value Function Update Magnitude: 0.50187

Collected Steps per Second: 20,884.83030
Overall Steps per Second: 10,139.49128

Timestep Collection Time: 2.39533
Timestep Consumption Time: 2.53845
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.93378

Cumulative Model Updates: 167,850
Cumulative Timesteps: 1,399,675,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1399675484...
Checkpoint 1399675484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,985.62645
Policy Entropy: 3.78948
Value Function Loss: 0.01944

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13248
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.61351

Collected Steps per Second: 20,956.22936
Overall Steps per Second: 10,176.10650

Timestep Collection Time: 2.38669
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.91504

Cumulative Model Updates: 167,856
Cumulative Timesteps: 1,399,725,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,218.36648
Policy Entropy: 3.79411
Value Function Loss: 0.02174

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.61224
Value Function Update Magnitude: 0.73540

Collected Steps per Second: 21,107.92958
Overall Steps per Second: 10,287.57729

Timestep Collection Time: 2.36982
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.86237

Cumulative Model Updates: 167,862
Cumulative Timesteps: 1,399,775,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1399775522...
Checkpoint 1399775522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,713.56784
Policy Entropy: 3.79579
Value Function Loss: 0.01925

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.59646
Value Function Update Magnitude: 0.71235

Collected Steps per Second: 20,829.38120
Overall Steps per Second: 10,252.85177

Timestep Collection Time: 2.40218
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.88020

Cumulative Model Updates: 167,868
Cumulative Timesteps: 1,399,825,558

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,834.66155
Policy Entropy: 3.79049
Value Function Loss: 0.01815

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 20,835.73880
Overall Steps per Second: 10,069.02623

Timestep Collection Time: 2.40078
Timestep Consumption Time: 2.56713
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.96791

Cumulative Model Updates: 167,874
Cumulative Timesteps: 1,399,875,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1399875580...
Checkpoint 1399875580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,595.45366
Policy Entropy: 3.77570
Value Function Loss: 0.01686

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.51382
Value Function Update Magnitude: 0.55884

Collected Steps per Second: 21,132.28795
Overall Steps per Second: 10,210.74215

Timestep Collection Time: 2.36709
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.89896

Cumulative Model Updates: 167,880
Cumulative Timesteps: 1,399,925,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,392.82174
Policy Entropy: 3.76520
Value Function Loss: 0.01725

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.47406
Value Function Update Magnitude: 0.51445

Collected Steps per Second: 20,902.77452
Overall Steps per Second: 10,128.34974

Timestep Collection Time: 2.39279
Timestep Consumption Time: 2.54543
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.93822

Cumulative Model Updates: 167,886
Cumulative Timesteps: 1,399,975,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1399975618...
Checkpoint 1399975618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,704.05211
Policy Entropy: 3.76483
Value Function Loss: 0.01865

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.46574
Value Function Update Magnitude: 0.52681

Collected Steps per Second: 20,669.55796
Overall Steps per Second: 10,199.72691

Timestep Collection Time: 2.41979
Timestep Consumption Time: 2.48387
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.90366

Cumulative Model Updates: 167,892
Cumulative Timesteps: 1,400,025,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,679.20779
Policy Entropy: 3.77036
Value Function Loss: 0.02069

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.51995
Value Function Update Magnitude: 0.62754

Collected Steps per Second: 20,912.76027
Overall Steps per Second: 10,171.57369

Timestep Collection Time: 2.39232
Timestep Consumption Time: 2.52629
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.91861

Cumulative Model Updates: 167,898
Cumulative Timesteps: 1,400,075,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1400075664...
Checkpoint 1400075664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267,845.34657
Policy Entropy: 3.79345
Value Function Loss: 0.02419

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.66260

Collected Steps per Second: 21,225.20185
Overall Steps per Second: 10,393.46391

Timestep Collection Time: 2.35569
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.81072

Cumulative Model Updates: 167,904
Cumulative Timesteps: 1,400,125,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,373.83744
Policy Entropy: 3.79661
Value Function Loss: 0.02551

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.56992
Value Function Update Magnitude: 0.62741

Collected Steps per Second: 20,943.26955
Overall Steps per Second: 10,088.84147

Timestep Collection Time: 2.38807
Timestep Consumption Time: 2.56929
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.95736

Cumulative Model Updates: 167,910
Cumulative Timesteps: 1,400,175,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1400175678...
Checkpoint 1400175678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.56787
Policy Entropy: 3.80741
Value Function Loss: 0.02581

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11983
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.69588

Collected Steps per Second: 20,994.32660
Overall Steps per Second: 10,087.03236

Timestep Collection Time: 2.38264
Timestep Consumption Time: 2.57640
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.95904

Cumulative Model Updates: 167,916
Cumulative Timesteps: 1,400,225,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,932.24490
Policy Entropy: 3.79867
Value Function Loss: 0.02444

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11942
Policy Update Magnitude: 0.57461
Value Function Update Magnitude: 0.72601

Collected Steps per Second: 20,840.27238
Overall Steps per Second: 10,191.59020

Timestep Collection Time: 2.40006
Timestep Consumption Time: 2.50771
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.90777

Cumulative Model Updates: 167,922
Cumulative Timesteps: 1,400,275,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1400275718...
Checkpoint 1400275718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,896.89871
Policy Entropy: 3.79728
Value Function Loss: 0.02254

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.68220

Collected Steps per Second: 20,861.52310
Overall Steps per Second: 10,275.72792

Timestep Collection Time: 2.39781
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.86798

Cumulative Model Updates: 167,928
Cumulative Timesteps: 1,400,325,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,520.55567
Policy Entropy: 3.78097
Value Function Loss: 0.02066

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.63233

Collected Steps per Second: 21,143.89477
Overall Steps per Second: 10,277.67263

Timestep Collection Time: 2.36579
Timestep Consumption Time: 2.50127
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.86706

Cumulative Model Updates: 167,934
Cumulative Timesteps: 1,400,375,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1400375762...
Checkpoint 1400375762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,261.84622
Policy Entropy: 3.78571
Value Function Loss: 0.01887

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.66088

Collected Steps per Second: 20,151.39989
Overall Steps per Second: 9,871.60107

Timestep Collection Time: 2.48122
Timestep Consumption Time: 2.58382
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 5.06503

Cumulative Model Updates: 167,940
Cumulative Timesteps: 1,400,425,762

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,775.94890
Policy Entropy: 3.78308
Value Function Loss: 0.02434

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.68993

Collected Steps per Second: 20,941.68488
Overall Steps per Second: 10,166.86590

Timestep Collection Time: 2.38806
Timestep Consumption Time: 2.53086
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.91892

Cumulative Model Updates: 167,946
Cumulative Timesteps: 1,400,475,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1400475772...
Checkpoint 1400475772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,730.75182
Policy Entropy: 3.79538
Value Function Loss: 0.02644

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.71873

Collected Steps per Second: 21,191.62724
Overall Steps per Second: 10,152.69325

Timestep Collection Time: 2.36065
Timestep Consumption Time: 2.56671
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.92736

Cumulative Model Updates: 167,952
Cumulative Timesteps: 1,400,525,798

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,536.53781
Policy Entropy: 3.79154
Value Function Loss: 0.02566

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.60124
Value Function Update Magnitude: 0.72715

Collected Steps per Second: 21,307.69446
Overall Steps per Second: 10,367.89506

Timestep Collection Time: 2.34723
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.82393

Cumulative Model Updates: 167,958
Cumulative Timesteps: 1,400,575,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1400575812...
Checkpoint 1400575812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,907.51272
Policy Entropy: 3.78766
Value Function Loss: 0.02474

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.60368
Value Function Update Magnitude: 0.80807

Collected Steps per Second: 20,715.03352
Overall Steps per Second: 10,215.26895

Timestep Collection Time: 2.41457
Timestep Consumption Time: 2.48182
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.89640

Cumulative Model Updates: 167,964
Cumulative Timesteps: 1,400,625,830

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,692.22263
Policy Entropy: 3.79572
Value Function Loss: 0.02362

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.58765
Value Function Update Magnitude: 0.83900

Collected Steps per Second: 20,703.68429
Overall Steps per Second: 10,046.61558

Timestep Collection Time: 2.41522
Timestep Consumption Time: 2.56198
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.97720

Cumulative Model Updates: 167,970
Cumulative Timesteps: 1,400,675,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1400675834...
Checkpoint 1400675834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,970.30651
Policy Entropy: 3.80520
Value Function Loss: 0.02342

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.86586

Collected Steps per Second: 21,095.07859
Overall Steps per Second: 10,296.18753

Timestep Collection Time: 2.37041
Timestep Consumption Time: 2.48614
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.85655

Cumulative Model Updates: 167,976
Cumulative Timesteps: 1,400,725,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,286.28547
Policy Entropy: 3.81588
Value Function Loss: 0.02090

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.48729
Value Function Update Magnitude: 0.80948

Collected Steps per Second: 21,122.07764
Overall Steps per Second: 10,146.66776

Timestep Collection Time: 2.36776
Timestep Consumption Time: 2.56115
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.92891

Cumulative Model Updates: 167,982
Cumulative Timesteps: 1,400,775,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1400775850...
Checkpoint 1400775850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,464.91001
Policy Entropy: 3.79954
Value Function Loss: 0.02255

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.47425
Value Function Update Magnitude: 0.72445

Collected Steps per Second: 21,208.07311
Overall Steps per Second: 10,213.59362

Timestep Collection Time: 2.35816
Timestep Consumption Time: 2.53845
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.89661

Cumulative Model Updates: 167,988
Cumulative Timesteps: 1,400,825,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,446.56432
Policy Entropy: 3.80183
Value Function Loss: 0.02395

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.51699
Value Function Update Magnitude: 0.74178

Collected Steps per Second: 20,972.19348
Overall Steps per Second: 10,291.17013

Timestep Collection Time: 2.38525
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.86087

Cumulative Model Updates: 167,994
Cumulative Timesteps: 1,400,875,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1400875886...
Checkpoint 1400875886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,982.44008
Policy Entropy: 3.81494
Value Function Loss: 0.02776

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.82586

Collected Steps per Second: 20,869.05320
Overall Steps per Second: 10,251.03335

Timestep Collection Time: 2.39800
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.88185

Cumulative Model Updates: 168,000
Cumulative Timesteps: 1,400,925,930

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,396.14546
Policy Entropy: 3.83400
Value Function Loss: 0.02642

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.58129
Value Function Update Magnitude: 0.90488

Collected Steps per Second: 20,683.20915
Overall Steps per Second: 10,074.44475

Timestep Collection Time: 2.41839
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.96504

Cumulative Model Updates: 168,006
Cumulative Timesteps: 1,400,975,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1400975950...
Checkpoint 1400975950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,140.18416
Policy Entropy: 3.83367
Value Function Loss: 0.02761

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.57458
Value Function Update Magnitude: 0.82995

Collected Steps per Second: 20,921.04011
Overall Steps per Second: 10,236.76577

Timestep Collection Time: 2.39137
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.88729

Cumulative Model Updates: 168,012
Cumulative Timesteps: 1,401,025,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,721.76109
Policy Entropy: 3.82568
Value Function Loss: 0.02436

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.54367
Value Function Update Magnitude: 0.81049

Collected Steps per Second: 20,719.32092
Overall Steps per Second: 10,139.32780

Timestep Collection Time: 2.41456
Timestep Consumption Time: 2.51950
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.93405

Cumulative Model Updates: 168,018
Cumulative Timesteps: 1,401,076,008

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1401076008...
Checkpoint 1401076008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,056.96285
Policy Entropy: 3.80955
Value Function Loss: 0.02404

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12085
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.85630

Collected Steps per Second: 20,844.07153
Overall Steps per Second: 10,103.07900

Timestep Collection Time: 2.39934
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.95017

Cumulative Model Updates: 168,024
Cumulative Timesteps: 1,401,126,020

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,151.65749
Policy Entropy: 3.81028
Value Function Loss: 0.02096

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.55763
Value Function Update Magnitude: 0.80413

Collected Steps per Second: 20,706.55103
Overall Steps per Second: 10,059.18276

Timestep Collection Time: 2.41585
Timestep Consumption Time: 2.55711
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.97297

Cumulative Model Updates: 168,030
Cumulative Timesteps: 1,401,176,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1401176044...
Checkpoint 1401176044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,057.86078
Policy Entropy: 3.78811
Value Function Loss: 0.02188

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.50556
Value Function Update Magnitude: 0.71553

Collected Steps per Second: 20,720.99452
Overall Steps per Second: 10,192.95469

Timestep Collection Time: 2.41446
Timestep Consumption Time: 2.49383
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.90829

Cumulative Model Updates: 168,036
Cumulative Timesteps: 1,401,226,074

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,934.10726
Policy Entropy: 3.79233
Value Function Loss: 0.02079

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.48111
Value Function Update Magnitude: 0.73683

Collected Steps per Second: 20,415.49118
Overall Steps per Second: 10,155.18999

Timestep Collection Time: 2.44912
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.92359

Cumulative Model Updates: 168,042
Cumulative Timesteps: 1,401,276,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1401276074...
Checkpoint 1401276074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,449.42156
Policy Entropy: 3.79380
Value Function Loss: 0.01971

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.48042
Value Function Update Magnitude: 0.76443

Collected Steps per Second: 20,982.29092
Overall Steps per Second: 10,179.90980

Timestep Collection Time: 2.38344
Timestep Consumption Time: 2.52918
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.91262

Cumulative Model Updates: 168,048
Cumulative Timesteps: 1,401,326,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,629.89948
Policy Entropy: 3.80067
Value Function Loss: 0.01668

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.46562
Value Function Update Magnitude: 0.73731

Collected Steps per Second: 20,784.91494
Overall Steps per Second: 10,106.57522

Timestep Collection Time: 2.40684
Timestep Consumption Time: 2.54301
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.94985

Cumulative Model Updates: 168,054
Cumulative Timesteps: 1,401,376,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1401376110...
Checkpoint 1401376110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,928.85900
Policy Entropy: 3.78787
Value Function Loss: 0.01591

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.46043
Value Function Update Magnitude: 0.69851

Collected Steps per Second: 21,225.02498
Overall Steps per Second: 10,230.52632

Timestep Collection Time: 2.35693
Timestep Consumption Time: 2.53294
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.88988

Cumulative Model Updates: 168,060
Cumulative Timesteps: 1,401,426,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,766.35445
Policy Entropy: 3.77997
Value Function Loss: 0.01487

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.51549
Value Function Update Magnitude: 0.68012

Collected Steps per Second: 20,393.20524
Overall Steps per Second: 10,318.09625

Timestep Collection Time: 2.45190
Timestep Consumption Time: 2.39415
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.84605

Cumulative Model Updates: 168,066
Cumulative Timesteps: 1,401,476,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1401476138...
Checkpoint 1401476138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,251.34275
Policy Entropy: 3.76633
Value Function Loss: 0.02366

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.70607

Collected Steps per Second: 19,924.08443
Overall Steps per Second: 10,155.52825

Timestep Collection Time: 2.51113
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.92658

Cumulative Model Updates: 168,072
Cumulative Timesteps: 1,401,526,170

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,809.24347
Policy Entropy: 3.76553
Value Function Loss: 0.02379

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15385
Policy Update Magnitude: 0.63805
Value Function Update Magnitude: 0.62632

Collected Steps per Second: 20,076.76799
Overall Steps per Second: 10,092.30589

Timestep Collection Time: 2.49104
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.95546

Cumulative Model Updates: 168,078
Cumulative Timesteps: 1,401,576,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1401576182...
Checkpoint 1401576182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,622.78084
Policy Entropy: 3.75677
Value Function Loss: 0.02453

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11449
Policy Update Magnitude: 0.75923
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 20,222.00382
Overall Steps per Second: 10,156.63578

Timestep Collection Time: 2.47364
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.92506

Cumulative Model Updates: 168,084
Cumulative Timesteps: 1,401,626,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,152.62526
Policy Entropy: 3.78099
Value Function Loss: 0.02030

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.76229
Value Function Update Magnitude: 0.62155

Collected Steps per Second: 20,298.80052
Overall Steps per Second: 10,176.49997

Timestep Collection Time: 2.46379
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.91446

Cumulative Model Updates: 168,090
Cumulative Timesteps: 1,401,676,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1401676216...
Checkpoint 1401676216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,492.86328
Policy Entropy: 3.77881
Value Function Loss: 0.03075

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.18457
Policy Update Magnitude: 0.68776
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 20,482.04493
Overall Steps per Second: 10,230.80052

Timestep Collection Time: 2.44116
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.88720

Cumulative Model Updates: 168,096
Cumulative Timesteps: 1,401,726,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,241.42626
Policy Entropy: 3.81442
Value Function Loss: 0.03522

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.79992
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 19,461.94018
Overall Steps per Second: 9,876.66624

Timestep Collection Time: 2.57066
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 5.06547

Cumulative Model Updates: 168,102
Cumulative Timesteps: 1,401,776,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1401776246...
Checkpoint 1401776246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,113.72105
Policy Entropy: 3.79822
Value Function Loss: 0.03400

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.78435
Value Function Update Magnitude: 0.48589

Collected Steps per Second: 19,990.38143
Overall Steps per Second: 9,884.48008

Timestep Collection Time: 2.50120
Timestep Consumption Time: 2.55723
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 5.05843

Cumulative Model Updates: 168,108
Cumulative Timesteps: 1,401,826,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,570.58324
Policy Entropy: 3.81836
Value Function Loss: 0.02269

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.70656
Value Function Update Magnitude: 0.50797

Collected Steps per Second: 20,205.51048
Overall Steps per Second: 10,001.19367

Timestep Collection Time: 2.47556
Timestep Consumption Time: 2.52584
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 5.00140

Cumulative Model Updates: 168,114
Cumulative Timesteps: 1,401,876,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1401876266...
Checkpoint 1401876266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,467.05372
Policy Entropy: 3.79052
Value Function Loss: 0.01854

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.65912
Value Function Update Magnitude: 0.49364

Collected Steps per Second: 19,103.98833
Overall Steps per Second: 9,812.70674

Timestep Collection Time: 2.61757
Timestep Consumption Time: 2.47848
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 5.09605

Cumulative Model Updates: 168,120
Cumulative Timesteps: 1,401,926,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,709.43450
Policy Entropy: 3.79573
Value Function Loss: 0.01585

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.63483
Value Function Update Magnitude: 0.42156

Collected Steps per Second: 20,837.76843
Overall Steps per Second: 10,137.61794

Timestep Collection Time: 2.40083
Timestep Consumption Time: 2.53405
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.93489

Cumulative Model Updates: 168,126
Cumulative Timesteps: 1,401,976,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1401976300...
Checkpoint 1401976300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,018.98441
Policy Entropy: 3.78282
Value Function Loss: 0.01631

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08643
Policy Update Magnitude: 0.62716
Value Function Update Magnitude: 0.38375

Collected Steps per Second: 20,802.42413
Overall Steps per Second: 10,256.70931

Timestep Collection Time: 2.40462
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.87700

Cumulative Model Updates: 168,132
Cumulative Timesteps: 1,402,026,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,704.94450
Policy Entropy: 3.77699
Value Function Loss: 0.01560

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.59559
Value Function Update Magnitude: 0.43335

Collected Steps per Second: 20,323.08737
Overall Steps per Second: 9,950.50422

Timestep Collection Time: 2.46203
Timestep Consumption Time: 2.56646
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 5.02849

Cumulative Model Updates: 168,138
Cumulative Timesteps: 1,402,076,358

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1402076358...
Checkpoint 1402076358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,367.65521
Policy Entropy: 3.76918
Value Function Loss: 0.01630

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.45260

Collected Steps per Second: 20,310.50006
Overall Steps per Second: 9,948.48263

Timestep Collection Time: 2.46296
Timestep Consumption Time: 2.56534
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 5.02830

Cumulative Model Updates: 168,144
Cumulative Timesteps: 1,402,126,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,677.08170
Policy Entropy: 3.77228
Value Function Loss: 0.01787

Mean KL Divergence: 0.00614
SB3 Clip Fraction: 0.07577
Policy Update Magnitude: 0.60021
Value Function Update Magnitude: 0.47062

Collected Steps per Second: 21,096.71709
Overall Steps per Second: 10,319.73705

Timestep Collection Time: 2.37032
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.84567

Cumulative Model Updates: 168,150
Cumulative Timesteps: 1,402,176,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1402176388...
Checkpoint 1402176388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,401.30076
Policy Entropy: 3.78583
Value Function Loss: 0.01813

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.51767
Value Function Update Magnitude: 0.49304

Collected Steps per Second: 21,106.03650
Overall Steps per Second: 10,355.63371

Timestep Collection Time: 2.36946
Timestep Consumption Time: 2.45979
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.82926

Cumulative Model Updates: 168,156
Cumulative Timesteps: 1,402,226,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,651.19732
Policy Entropy: 3.78496
Value Function Loss: 0.02093

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.21024
Policy Update Magnitude: 0.46180
Value Function Update Magnitude: 0.53481

Collected Steps per Second: 20,745.46401
Overall Steps per Second: 10,042.23242

Timestep Collection Time: 2.41132
Timestep Consumption Time: 2.57004
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.98136

Cumulative Model Updates: 168,162
Cumulative Timesteps: 1,402,276,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1402276422...
Checkpoint 1402276422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,204.24019
Policy Entropy: 3.80430
Value Function Loss: 0.03408

Mean KL Divergence: 0.02829
SB3 Clip Fraction: 0.26866
Policy Update Magnitude: 0.50732
Value Function Update Magnitude: 0.56808

Collected Steps per Second: 20,633.83302
Overall Steps per Second: 10,206.29497

Timestep Collection Time: 2.42340
Timestep Consumption Time: 2.47593
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.89933

Cumulative Model Updates: 168,168
Cumulative Timesteps: 1,402,326,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,295.60065
Policy Entropy: 3.82575
Value Function Loss: 0.04234

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.17998
Policy Update Magnitude: 0.61693
Value Function Update Magnitude: 0.57942

Collected Steps per Second: 20,677.14316
Overall Steps per Second: 10,170.47966

Timestep Collection Time: 2.41919
Timestep Consumption Time: 2.49916
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.91835

Cumulative Model Updates: 168,174
Cumulative Timesteps: 1,402,376,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1402376448...
Checkpoint 1402376448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,576.93192
Policy Entropy: 3.81941
Value Function Loss: 0.03946

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.18337
Policy Update Magnitude: 0.71429
Value Function Update Magnitude: 0.70285

Collected Steps per Second: 21,227.19994
Overall Steps per Second: 10,394.91121

Timestep Collection Time: 2.35566
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.81043

Cumulative Model Updates: 168,180
Cumulative Timesteps: 1,402,426,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,777.35980
Policy Entropy: 3.80514
Value Function Loss: 0.03306

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.77306
Value Function Update Magnitude: 0.73240

Collected Steps per Second: 21,186.61483
Overall Steps per Second: 10,189.45121

Timestep Collection Time: 2.36008
Timestep Consumption Time: 2.54716
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.90723

Cumulative Model Updates: 168,186
Cumulative Timesteps: 1,402,476,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1402476454...
Checkpoint 1402476454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,528.52251
Policy Entropy: 3.78897
Value Function Loss: 0.02624

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.68807
Value Function Update Magnitude: 0.66800

Collected Steps per Second: 21,060.32604
Overall Steps per Second: 10,148.78350

Timestep Collection Time: 2.37546
Timestep Consumption Time: 2.55400
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.92946

Cumulative Model Updates: 168,192
Cumulative Timesteps: 1,402,526,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,135.44577
Policy Entropy: 3.76132
Value Function Loss: 0.02276

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.25793
Policy Update Magnitude: 0.63292
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 21,302.41159
Overall Steps per Second: 10,319.36717

Timestep Collection Time: 2.34847
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.84797

Cumulative Model Updates: 168,198
Cumulative Timesteps: 1,402,576,510

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1402576510...
Checkpoint 1402576510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,168.83124
Policy Entropy: 3.76975
Value Function Loss: 0.02308

Mean KL Divergence: 0.02588
SB3 Clip Fraction: 0.28143
Policy Update Magnitude: 0.46108
Value Function Update Magnitude: 0.49240

Collected Steps per Second: 20,360.66676
Overall Steps per Second: 9,944.68774

Timestep Collection Time: 2.45689
Timestep Consumption Time: 2.57333
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 5.03022

Cumulative Model Updates: 168,204
Cumulative Timesteps: 1,402,626,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,168.83124
Policy Entropy: 3.77603
Value Function Loss: 0.02120

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.27049
Policy Update Magnitude: 0.39537
Value Function Update Magnitude: 0.41045

Collected Steps per Second: 21,308.45209
Overall Steps per Second: 10,361.17688

Timestep Collection Time: 2.34771
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.82822

Cumulative Model Updates: 168,210
Cumulative Timesteps: 1,402,676,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1402676560...
Checkpoint 1402676560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,502.43869
Policy Entropy: 3.74182
Value Function Loss: 0.02442

Mean KL Divergence: 0.02199
SB3 Clip Fraction: 0.24254
Policy Update Magnitude: 0.37157
Value Function Update Magnitude: 0.40342

Collected Steps per Second: 20,845.78198
Overall Steps per Second: 10,261.59032

Timestep Collection Time: 2.39885
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.87312

Cumulative Model Updates: 168,216
Cumulative Timesteps: 1,402,726,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 459,479.14407
Policy Entropy: 3.79828
Value Function Loss: 0.02723

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.19125
Policy Update Magnitude: 0.38047
Value Function Update Magnitude: 0.45410

Collected Steps per Second: 20,795.29249
Overall Steps per Second: 10,077.54531

Timestep Collection Time: 2.40487
Timestep Consumption Time: 2.55765
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.96252

Cumulative Model Updates: 168,222
Cumulative Timesteps: 1,402,776,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1402776576...
Checkpoint 1402776576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,206.48452
Policy Entropy: 3.82331
Value Function Loss: 0.03084

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.19496
Policy Update Magnitude: 0.43150
Value Function Update Magnitude: 0.49837

Collected Steps per Second: 21,167.58829
Overall Steps per Second: 10,202.20879

Timestep Collection Time: 2.36314
Timestep Consumption Time: 2.53991
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.90306

Cumulative Model Updates: 168,228
Cumulative Timesteps: 1,402,826,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,856.09521
Policy Entropy: 3.84127
Value Function Loss: 0.03175

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.18750
Policy Update Magnitude: 0.50407
Value Function Update Magnitude: 0.55178

Collected Steps per Second: 20,941.02595
Overall Steps per Second: 10,171.35298

Timestep Collection Time: 2.38899
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.91852

Cumulative Model Updates: 168,234
Cumulative Timesteps: 1,402,876,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1402876626...
Checkpoint 1402876626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,705.05705
Policy Entropy: 3.83394
Value Function Loss: 0.03236

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16536
Policy Update Magnitude: 0.46366
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 20,697.42284
Overall Steps per Second: 10,090.26509

Timestep Collection Time: 2.41576
Timestep Consumption Time: 2.53951
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.95527

Cumulative Model Updates: 168,240
Cumulative Timesteps: 1,402,926,626

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,647.91647
Policy Entropy: 3.79735
Value Function Loss: 0.03196

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.20266
Policy Update Magnitude: 0.47180
Value Function Update Magnitude: 0.51956

Collected Steps per Second: 20,775.91147
Overall Steps per Second: 10,031.02595

Timestep Collection Time: 2.40769
Timestep Consumption Time: 2.57904
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.98673

Cumulative Model Updates: 168,246
Cumulative Timesteps: 1,402,976,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1402976648...
Checkpoint 1402976648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,462.38516
Policy Entropy: 3.80352
Value Function Loss: 0.03650

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16045
Policy Update Magnitude: 0.49030
Value Function Update Magnitude: 0.44971

Collected Steps per Second: 20,655.71745
Overall Steps per Second: 10,182.04186

Timestep Collection Time: 2.42180
Timestep Consumption Time: 2.49116
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.91296

Cumulative Model Updates: 168,252
Cumulative Timesteps: 1,403,026,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,068.93834
Policy Entropy: 3.82965
Value Function Loss: 0.04204

Mean KL Divergence: 0.01950
SB3 Clip Fraction: 0.21138
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.38376

Collected Steps per Second: 20,906.34701
Overall Steps per Second: 10,094.81752

Timestep Collection Time: 2.39324
Timestep Consumption Time: 2.56316
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.95640

Cumulative Model Updates: 168,258
Cumulative Timesteps: 1,403,076,706

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1403076706...
Checkpoint 1403076706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,536.59334
Policy Entropy: 3.85924
Value Function Loss: 0.04168

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.32808

Collected Steps per Second: 21,027.48363
Overall Steps per Second: 10,217.73539

Timestep Collection Time: 2.37927
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.89639

Cumulative Model Updates: 168,264
Cumulative Timesteps: 1,403,126,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.75608
Policy Entropy: 3.87429
Value Function Loss: 0.03214

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.64476
Value Function Update Magnitude: 0.30612

Collected Steps per Second: 20,929.98522
Overall Steps per Second: 10,110.87051

Timestep Collection Time: 2.39006
Timestep Consumption Time: 2.55748
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.94755

Cumulative Model Updates: 168,270
Cumulative Timesteps: 1,403,176,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1403176760...
Checkpoint 1403176760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,905.04064
Policy Entropy: 3.86025
Value Function Loss: 0.02907

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08372
Policy Update Magnitude: 0.66647
Value Function Update Magnitude: 0.32959

Collected Steps per Second: 21,014.59994
Overall Steps per Second: 10,148.33505

Timestep Collection Time: 2.38035
Timestep Consumption Time: 2.54874
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.92908

Cumulative Model Updates: 168,276
Cumulative Timesteps: 1,403,226,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,031.42655
Policy Entropy: 3.83576
Value Function Loss: 0.02754

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07850
Policy Update Magnitude: 0.62985
Value Function Update Magnitude: 0.30069

Collected Steps per Second: 21,047.00605
Overall Steps per Second: 10,127.50693

Timestep Collection Time: 2.37563
Timestep Consumption Time: 2.56141
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.93705

Cumulative Model Updates: 168,282
Cumulative Timesteps: 1,403,276,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1403276782...
Checkpoint 1403276782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,434.28620
Policy Entropy: 3.80650
Value Function Loss: 0.02743

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.60798
Value Function Update Magnitude: 0.27910

Collected Steps per Second: 21,243.03531
Overall Steps per Second: 10,267.14829

Timestep Collection Time: 2.35409
Timestep Consumption Time: 2.51659
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.87068

Cumulative Model Updates: 168,288
Cumulative Timesteps: 1,403,326,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,611.60239
Policy Entropy: 3.80431
Value Function Loss: 0.02415

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07612
Policy Update Magnitude: 0.63783
Value Function Update Magnitude: 0.34499

Collected Steps per Second: 21,133.36747
Overall Steps per Second: 10,330.94897

Timestep Collection Time: 2.36649
Timestep Consumption Time: 2.47449
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.84099

Cumulative Model Updates: 168,294
Cumulative Timesteps: 1,403,376,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1403376802...
Checkpoint 1403376802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.57642
Policy Entropy: 3.81329
Value Function Loss: 0.02243

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06759
Policy Update Magnitude: 0.69457
Value Function Update Magnitude: 0.43240

Collected Steps per Second: 21,240.05495
Overall Steps per Second: 10,175.43090

Timestep Collection Time: 2.35546
Timestep Consumption Time: 2.56129
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.91675

Cumulative Model Updates: 168,300
Cumulative Timesteps: 1,403,426,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,575.53592
Policy Entropy: 3.83319
Value Function Loss: 0.02249

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06676
Policy Update Magnitude: 0.70984
Value Function Update Magnitude: 0.55629

Collected Steps per Second: 21,022.88530
Overall Steps per Second: 10,159.20717

Timestep Collection Time: 2.37836
Timestep Consumption Time: 2.54328
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.92164

Cumulative Model Updates: 168,306
Cumulative Timesteps: 1,403,476,832

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1403476832...
Checkpoint 1403476832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,491.71819
Policy Entropy: 3.84325
Value Function Loss: 0.02198

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11444
Policy Update Magnitude: 0.63713
Value Function Update Magnitude: 0.61188

Collected Steps per Second: 20,928.76325
Overall Steps per Second: 10,142.69122

Timestep Collection Time: 2.38982
Timestep Consumption Time: 2.54141
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.93124

Cumulative Model Updates: 168,312
Cumulative Timesteps: 1,403,526,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,257.95077
Policy Entropy: 3.83033
Value Function Loss: 0.02059

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.49127
Value Function Update Magnitude: 0.54677

Collected Steps per Second: 20,836.80968
Overall Steps per Second: 10,032.97681

Timestep Collection Time: 2.40075
Timestep Consumption Time: 2.58521
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.98596

Cumulative Model Updates: 168,318
Cumulative Timesteps: 1,403,576,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1403576872...
Checkpoint 1403576872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,877.89819
Policy Entropy: 3.82405
Value Function Loss: 0.01934

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.41142
Value Function Update Magnitude: 0.48012

Collected Steps per Second: 21,110.98021
Overall Steps per Second: 10,197.61211

Timestep Collection Time: 2.36986
Timestep Consumption Time: 2.53619
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.90605

Cumulative Model Updates: 168,324
Cumulative Timesteps: 1,403,626,902

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,483.34014
Policy Entropy: 3.82536
Value Function Loss: 0.01881

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13997
Policy Update Magnitude: 0.40705
Value Function Update Magnitude: 0.46853

Collected Steps per Second: 21,146.52120
Overall Steps per Second: 10,211.23278

Timestep Collection Time: 2.36578
Timestep Consumption Time: 2.53353
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.89931

Cumulative Model Updates: 168,330
Cumulative Timesteps: 1,403,676,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1403676930...
Checkpoint 1403676930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.97927
Policy Entropy: 3.85205
Value Function Loss: 0.02059

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.38654
Value Function Update Magnitude: 0.54627

Collected Steps per Second: 21,354.86197
Overall Steps per Second: 10,429.02874

Timestep Collection Time: 2.34176
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.79508

Cumulative Model Updates: 168,336
Cumulative Timesteps: 1,403,726,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.54353
Policy Entropy: 3.85637
Value Function Loss: 0.02178

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.36664
Value Function Update Magnitude: 0.51549

Collected Steps per Second: 20,405.10514
Overall Steps per Second: 10,149.89233

Timestep Collection Time: 2.45115
Timestep Consumption Time: 2.47659
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.92774

Cumulative Model Updates: 168,342
Cumulative Timesteps: 1,403,776,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1403776954...
Checkpoint 1403776954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240.22732
Policy Entropy: 3.82336
Value Function Loss: 0.02129

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.40021
Value Function Update Magnitude: 0.43929

Collected Steps per Second: 20,467.00298
Overall Steps per Second: 10,160.00546

Timestep Collection Time: 2.44296
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.92126

Cumulative Model Updates: 168,348
Cumulative Timesteps: 1,403,826,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164.46846
Policy Entropy: 3.77795
Value Function Loss: 0.01980

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.44760
Value Function Update Magnitude: 0.39979

Collected Steps per Second: 20,488.00490
Overall Steps per Second: 10,231.21452

Timestep Collection Time: 2.44065
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.88740

Cumulative Model Updates: 168,354
Cumulative Timesteps: 1,403,876,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1403876958...
Checkpoint 1403876958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,673.83249
Policy Entropy: 3.72316
Value Function Loss: 0.01963

Mean KL Divergence: 0.03151
SB3 Clip Fraction: 0.30043
Policy Update Magnitude: 0.42357
Value Function Update Magnitude: 0.38491

Collected Steps per Second: 20,294.29034
Overall Steps per Second: 10,031.86104

Timestep Collection Time: 2.46424
Timestep Consumption Time: 2.52088
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.98512

Cumulative Model Updates: 168,360
Cumulative Timesteps: 1,403,926,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.45741
Policy Entropy: 3.79005
Value Function Loss: 0.02018

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.20454
Policy Update Magnitude: 0.33900
Value Function Update Magnitude: 0.37733

Collected Steps per Second: 20,657.41268
Overall Steps per Second: 10,111.98223

Timestep Collection Time: 2.42073
Timestep Consumption Time: 2.52449
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.94522

Cumulative Model Updates: 168,366
Cumulative Timesteps: 1,403,976,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1403976974...
Checkpoint 1403976974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 515.01445
Policy Entropy: 3.78738
Value Function Loss: 0.02063

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.23210
Policy Update Magnitude: 0.33962
Value Function Update Magnitude: 0.35786

Collected Steps per Second: 21,086.96550
Overall Steps per Second: 10,244.46124

Timestep Collection Time: 2.37237
Timestep Consumption Time: 2.51086
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.88322

Cumulative Model Updates: 168,372
Cumulative Timesteps: 1,404,027,000

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,127.55993
Policy Entropy: 3.77094
Value Function Loss: 0.02419

Mean KL Divergence: 0.01791
SB3 Clip Fraction: 0.21431
Policy Update Magnitude: 0.33090
Value Function Update Magnitude: 0.46328

Collected Steps per Second: 21,158.28721
Overall Steps per Second: 10,314.52028

Timestep Collection Time: 2.36409
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.84947

Cumulative Model Updates: 168,378
Cumulative Timesteps: 1,404,077,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1404077020...
Checkpoint 1404077020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,102.70051
Policy Entropy: 3.75161
Value Function Loss: 0.03008

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.21025
Policy Update Magnitude: 0.36254
Value Function Update Magnitude: 0.66888

Collected Steps per Second: 20,977.74535
Overall Steps per Second: 10,297.91394

Timestep Collection Time: 2.38357
Timestep Consumption Time: 2.47197
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.85555

Cumulative Model Updates: 168,384
Cumulative Timesteps: 1,404,127,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,003.07282
Policy Entropy: 3.74913
Value Function Loss: 0.03547

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.20375
Policy Update Magnitude: 0.39855
Value Function Update Magnitude: 0.66048

Collected Steps per Second: 21,044.80453
Overall Steps per Second: 10,299.88510

Timestep Collection Time: 2.37664
Timestep Consumption Time: 2.47933
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.85598

Cumulative Model Updates: 168,390
Cumulative Timesteps: 1,404,177,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1404177038...
Checkpoint 1404177038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,126.04761
Policy Entropy: 3.76079
Value Function Loss: 0.04082

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.19223
Policy Update Magnitude: 0.42237
Value Function Update Magnitude: 0.57983

Collected Steps per Second: 20,806.70800
Overall Steps per Second: 10,216.37002

Timestep Collection Time: 2.40365
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.89528

Cumulative Model Updates: 168,396
Cumulative Timesteps: 1,404,227,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,514.29206
Policy Entropy: 3.80083
Value Function Loss: 0.03918

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.17896
Policy Update Magnitude: 0.45075
Value Function Update Magnitude: 0.48280

Collected Steps per Second: 20,912.45574
Overall Steps per Second: 10,157.10748

Timestep Collection Time: 2.39226
Timestep Consumption Time: 2.53316
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.92542

Cumulative Model Updates: 168,402
Cumulative Timesteps: 1,404,277,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1404277078...
Checkpoint 1404277078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,114.79348
Policy Entropy: 3.80545
Value Function Loss: 0.03939

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.17686
Policy Update Magnitude: 0.47114
Value Function Update Magnitude: 0.57002

Collected Steps per Second: 21,150.13651
Overall Steps per Second: 10,218.39982

Timestep Collection Time: 2.36613
Timestep Consumption Time: 2.53131
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.89744

Cumulative Model Updates: 168,408
Cumulative Timesteps: 1,404,327,122

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,455.23354
Policy Entropy: 3.80923
Value Function Loss: 0.03888

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.49259
Value Function Update Magnitude: 0.64671

Collected Steps per Second: 20,532.55920
Overall Steps per Second: 10,037.46198

Timestep Collection Time: 2.43603
Timestep Consumption Time: 2.54710
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.98313

Cumulative Model Updates: 168,414
Cumulative Timesteps: 1,404,377,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1404377140...
Checkpoint 1404377140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,688.42933
Policy Entropy: 3.80676
Value Function Loss: 0.04098

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.50528
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 21,102.83525
Overall Steps per Second: 10,184.39693

Timestep Collection Time: 2.37143
Timestep Consumption Time: 2.54236
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.91379

Cumulative Model Updates: 168,420
Cumulative Timesteps: 1,404,427,184

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,763.48356
Policy Entropy: 3.80366
Value Function Loss: 0.04269

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.16818
Policy Update Magnitude: 0.51828
Value Function Update Magnitude: 0.56451

Collected Steps per Second: 21,041.77793
Overall Steps per Second: 10,185.57134

Timestep Collection Time: 2.37708
Timestep Consumption Time: 2.53359
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.91067

Cumulative Model Updates: 168,426
Cumulative Timesteps: 1,404,477,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1404477202...
Checkpoint 1404477202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,152.62820
Policy Entropy: 3.81768
Value Function Loss: 0.04078

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.16798
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.56039

Collected Steps per Second: 20,656.29609
Overall Steps per Second: 10,187.99883

Timestep Collection Time: 2.42105
Timestep Consumption Time: 2.48766
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.90872

Cumulative Model Updates: 168,432
Cumulative Timesteps: 1,404,527,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,140.29335
Policy Entropy: 3.81307
Value Function Loss: 0.03753

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.18678
Policy Update Magnitude: 0.54701
Value Function Update Magnitude: 0.55078

Collected Steps per Second: 20,961.43735
Overall Steps per Second: 10,109.36014

Timestep Collection Time: 2.38600
Timestep Consumption Time: 2.56130
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.94730

Cumulative Model Updates: 168,438
Cumulative Timesteps: 1,404,577,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1404577226...
Checkpoint 1404577226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,563.60069
Policy Entropy: 3.78948
Value Function Loss: 0.03519

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.19029
Policy Update Magnitude: 0.51394
Value Function Update Magnitude: 0.52251

Collected Steps per Second: 20,746.45586
Overall Steps per Second: 10,053.97608

Timestep Collection Time: 2.41024
Timestep Consumption Time: 2.56331
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.97355

Cumulative Model Updates: 168,444
Cumulative Timesteps: 1,404,627,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,391.54522
Policy Entropy: 3.76086
Value Function Loss: 0.03784

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.19514
Policy Update Magnitude: 0.47257
Value Function Update Magnitude: 0.48645

Collected Steps per Second: 21,359.85530
Overall Steps per Second: 10,400.82285

Timestep Collection Time: 2.34271
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.81116

Cumulative Model Updates: 168,450
Cumulative Timesteps: 1,404,677,270

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1404677270...
Checkpoint 1404677270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,283.23479
Policy Entropy: 3.74270
Value Function Loss: 0.03858

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18264
Policy Update Magnitude: 0.42848
Value Function Update Magnitude: 0.42992

Collected Steps per Second: 20,277.57506
Overall Steps per Second: 9,895.17463

Timestep Collection Time: 2.46617
Timestep Consumption Time: 2.58760
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 5.05378

Cumulative Model Updates: 168,456
Cumulative Timesteps: 1,404,727,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205,856.29809
Policy Entropy: 3.75584
Value Function Loss: 0.04071

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17604
Policy Update Magnitude: 0.41782
Value Function Update Magnitude: 0.43961

Collected Steps per Second: 20,894.88070
Overall Steps per Second: 10,113.41215

Timestep Collection Time: 2.39389
Timestep Consumption Time: 2.55202
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.94591

Cumulative Model Updates: 168,462
Cumulative Timesteps: 1,404,777,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1404777298...
Checkpoint 1404777298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,155.12358
Policy Entropy: 3.80412
Value Function Loss: 0.03602

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.16157
Policy Update Magnitude: 0.45461
Value Function Update Magnitude: 0.46861

Collected Steps per Second: 20,868.90937
Overall Steps per Second: 10,104.92703

Timestep Collection Time: 2.39610
Timestep Consumption Time: 2.55238
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.94848

Cumulative Model Updates: 168,468
Cumulative Timesteps: 1,404,827,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,543.62283
Policy Entropy: 3.82537
Value Function Loss: 0.03773

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.15382
Policy Update Magnitude: 0.47558
Value Function Update Magnitude: 0.54018

Collected Steps per Second: 21,106.61423
Overall Steps per Second: 10,144.52747

Timestep Collection Time: 2.36949
Timestep Consumption Time: 2.56045
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.92995

Cumulative Model Updates: 168,474
Cumulative Timesteps: 1,404,877,314

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1404877314...
Checkpoint 1404877314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,422.42933
Policy Entropy: 3.83542
Value Function Loss: 0.03574

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.62233

Collected Steps per Second: 20,881.17298
Overall Steps per Second: 10,209.76995

Timestep Collection Time: 2.39546
Timestep Consumption Time: 2.50377
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.89923

Cumulative Model Updates: 168,480
Cumulative Timesteps: 1,404,927,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,529.45279
Policy Entropy: 3.80218
Value Function Loss: 0.04287

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.16678
Policy Update Magnitude: 0.49001
Value Function Update Magnitude: 0.59714

Collected Steps per Second: 20,983.71481
Overall Steps per Second: 10,123.00098

Timestep Collection Time: 2.38433
Timestep Consumption Time: 2.55808
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.94241

Cumulative Model Updates: 168,486
Cumulative Timesteps: 1,404,977,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1404977366...
Checkpoint 1404977366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,605.37043
Policy Entropy: 3.82929
Value Function Loss: 0.03638

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.15972
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.54339

Collected Steps per Second: 20,787.25722
Overall Steps per Second: 10,117.69092

Timestep Collection Time: 2.40657
Timestep Consumption Time: 2.53784
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.94441

Cumulative Model Updates: 168,492
Cumulative Timesteps: 1,405,027,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,793.59447
Policy Entropy: 3.86681
Value Function Loss: 0.03627

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.55815
Value Function Update Magnitude: 0.67990

Collected Steps per Second: 20,689.60753
Overall Steps per Second: 10,118.38617

Timestep Collection Time: 2.41735
Timestep Consumption Time: 2.52553
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.94288

Cumulative Model Updates: 168,498
Cumulative Timesteps: 1,405,077,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1405077406...
Checkpoint 1405077406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,997.12353
Policy Entropy: 3.89544
Value Function Loss: 0.03559

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.15322
Policy Update Magnitude: 0.59982
Value Function Update Magnitude: 0.69804

Collected Steps per Second: 20,798.92162
Overall Steps per Second: 10,106.52692

Timestep Collection Time: 2.40464
Timestep Consumption Time: 2.54404
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.94868

Cumulative Model Updates: 168,504
Cumulative Timesteps: 1,405,127,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,202.83917
Policy Entropy: 3.87482
Value Function Loss: 0.03622

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15214
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.80574

Collected Steps per Second: 20,673.12915
Overall Steps per Second: 10,129.12868

Timestep Collection Time: 2.42005
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.93922

Cumulative Model Updates: 168,510
Cumulative Timesteps: 1,405,177,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1405177450...
Checkpoint 1405177450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,673.53435
Policy Entropy: 3.85640
Value Function Loss: 0.03779

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15469
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.82554

Collected Steps per Second: 20,872.36608
Overall Steps per Second: 10,142.27884

Timestep Collection Time: 2.39628
Timestep Consumption Time: 2.53516
PPO Batch Consumption Time: 0.29455
Total Iteration Time: 4.93144

Cumulative Model Updates: 168,516
Cumulative Timesteps: 1,405,227,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,813.16099
Policy Entropy: 3.84045
Value Function Loss: 0.03819

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.15894
Policy Update Magnitude: 0.49292
Value Function Update Magnitude: 0.76450

Collected Steps per Second: 20,939.32632
Overall Steps per Second: 10,328.16883

Timestep Collection Time: 2.38842
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.84229

Cumulative Model Updates: 168,522
Cumulative Timesteps: 1,405,277,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1405277478...
Checkpoint 1405277478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,039.65329
Policy Entropy: 3.83292
Value Function Loss: 0.04453

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.16352
Policy Update Magnitude: 0.48018
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 20,661.98689
Overall Steps per Second: 10,098.69157

Timestep Collection Time: 2.42000
Timestep Consumption Time: 2.53133
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.95133

Cumulative Model Updates: 168,528
Cumulative Timesteps: 1,405,327,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,985.50676
Policy Entropy: 3.80498
Value Function Loss: 0.03940

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.46159
Value Function Update Magnitude: 0.47109

Collected Steps per Second: 20,590.24434
Overall Steps per Second: 10,013.52948

Timestep Collection Time: 2.42931
Timestep Consumption Time: 2.56594
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.99524

Cumulative Model Updates: 168,534
Cumulative Timesteps: 1,405,377,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1405377500...
Checkpoint 1405377500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,958.89660
Policy Entropy: 3.79372
Value Function Loss: 0.04421

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17900
Policy Update Magnitude: 0.45461
Value Function Update Magnitude: 0.39937

Collected Steps per Second: 21,052.28790
Overall Steps per Second: 10,182.19880

Timestep Collection Time: 2.37675
Timestep Consumption Time: 2.53732
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.91407

Cumulative Model Updates: 168,540
Cumulative Timesteps: 1,405,427,536

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.62060
Policy Entropy: 3.77088
Value Function Loss: 0.03751

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.17682
Policy Update Magnitude: 0.46156
Value Function Update Magnitude: 0.36627

Collected Steps per Second: 20,843.37215
Overall Steps per Second: 10,272.64708

Timestep Collection Time: 2.39923
Timestep Consumption Time: 2.46885
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.86807

Cumulative Model Updates: 168,546
Cumulative Timesteps: 1,405,477,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1405477544...
Checkpoint 1405477544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,239.70013
Policy Entropy: 3.78231
Value Function Loss: 0.03453

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17708
Policy Update Magnitude: 0.46453
Value Function Update Magnitude: 0.48762

Collected Steps per Second: 20,924.98703
Overall Steps per Second: 10,239.71403

Timestep Collection Time: 2.38968
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.88334

Cumulative Model Updates: 168,552
Cumulative Timesteps: 1,405,527,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,217.85516
Policy Entropy: 3.78685
Value Function Loss: 0.03442

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.16779
Policy Update Magnitude: 0.47365
Value Function Update Magnitude: 0.55357

Collected Steps per Second: 20,864.05077
Overall Steps per Second: 10,086.26567

Timestep Collection Time: 2.39800
Timestep Consumption Time: 2.56241
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.96041

Cumulative Model Updates: 168,558
Cumulative Timesteps: 1,405,577,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1405577580...
Checkpoint 1405577580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,633.25941
Policy Entropy: 3.79792
Value Function Loss: 0.03388

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17262
Policy Update Magnitude: 0.47165
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 20,591.00558
Overall Steps per Second: 10,279.23748

Timestep Collection Time: 2.42892
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.86554

Cumulative Model Updates: 168,564
Cumulative Timesteps: 1,405,627,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,042.29670
Policy Entropy: 3.80851
Value Function Loss: 0.03429

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16052
Policy Update Magnitude: 0.49486
Value Function Update Magnitude: 0.57646

Collected Steps per Second: 20,804.47550
Overall Steps per Second: 10,273.05876

Timestep Collection Time: 2.40381
Timestep Consumption Time: 2.46426
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.86807

Cumulative Model Updates: 168,570
Cumulative Timesteps: 1,405,677,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1405677604...
Checkpoint 1405677604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,298.60927
Policy Entropy: 3.84437
Value Function Loss: 0.03507

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.49669
Value Function Update Magnitude: 0.46300

Collected Steps per Second: 20,950.50778
Overall Steps per Second: 10,379.56060

Timestep Collection Time: 2.38658
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.81716

Cumulative Model Updates: 168,576
Cumulative Timesteps: 1,405,727,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,625.22050
Policy Entropy: 3.87703
Value Function Loss: 0.03417

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.15119
Policy Update Magnitude: 0.48107
Value Function Update Magnitude: 0.45631

Collected Steps per Second: 21,193.15244
Overall Steps per Second: 10,409.03663

Timestep Collection Time: 2.35925
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.80352

Cumulative Model Updates: 168,582
Cumulative Timesteps: 1,405,777,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1405777604...
Checkpoint 1405777604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,561.94533
Policy Entropy: 3.87935
Value Function Loss: 0.03532

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.48454
Value Function Update Magnitude: 0.50605

Collected Steps per Second: 20,534.28449
Overall Steps per Second: 10,205.72331

Timestep Collection Time: 2.43709
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.90352

Cumulative Model Updates: 168,588
Cumulative Timesteps: 1,405,827,648

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,751.41693
Policy Entropy: 3.84055
Value Function Loss: 0.03656

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.51677
Value Function Update Magnitude: 0.48514

Collected Steps per Second: 20,958.86756
Overall Steps per Second: 10,210.73810

Timestep Collection Time: 2.38648
Timestep Consumption Time: 2.51208
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.89857

Cumulative Model Updates: 168,594
Cumulative Timesteps: 1,405,877,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1405877666...
Checkpoint 1405877666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,830.15548
Policy Entropy: 3.78800
Value Function Loss: 0.03788

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17544
Policy Update Magnitude: 0.51030
Value Function Update Magnitude: 0.45560

Collected Steps per Second: 20,897.76400
Overall Steps per Second: 10,108.04680

Timestep Collection Time: 2.39327
Timestep Consumption Time: 2.55467
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.94794

Cumulative Model Updates: 168,600
Cumulative Timesteps: 1,405,927,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,021.45105
Policy Entropy: 3.78458
Value Function Loss: 0.03749

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.16967
Policy Update Magnitude: 0.49751
Value Function Update Magnitude: 0.44332

Collected Steps per Second: 20,834.26888
Overall Steps per Second: 10,123.76891

Timestep Collection Time: 2.40056
Timestep Consumption Time: 2.53969
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.94025

Cumulative Model Updates: 168,606
Cumulative Timesteps: 1,405,977,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1405977694...
Checkpoint 1405977694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,933.91697
Policy Entropy: 3.80357
Value Function Loss: 0.04062

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16289
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.44994

Collected Steps per Second: 20,664.69537
Overall Steps per Second: 10,076.49924

Timestep Collection Time: 2.42152
Timestep Consumption Time: 2.54449
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.96601

Cumulative Model Updates: 168,612
Cumulative Timesteps: 1,406,027,734

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,861.21596
Policy Entropy: 3.82480
Value Function Loss: 0.04107

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.49667
Value Function Update Magnitude: 0.46848

Collected Steps per Second: 20,736.52236
Overall Steps per Second: 10,058.05014

Timestep Collection Time: 2.41342
Timestep Consumption Time: 2.56229
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.97572

Cumulative Model Updates: 168,618
Cumulative Timesteps: 1,406,077,780

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1406077780...
Checkpoint 1406077780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,331.07910
Policy Entropy: 3.81704
Value Function Loss: 0.04573

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.15775
Policy Update Magnitude: 0.49565
Value Function Update Magnitude: 0.46706

Collected Steps per Second: 21,044.51477
Overall Steps per Second: 10,125.93374

Timestep Collection Time: 2.37791
Timestep Consumption Time: 2.56405
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.94196

Cumulative Model Updates: 168,624
Cumulative Timesteps: 1,406,127,822

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,555.03538
Policy Entropy: 3.79462
Value Function Loss: 0.04418

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.50020
Value Function Update Magnitude: 0.42868

Collected Steps per Second: 20,311.38825
Overall Steps per Second: 10,083.53931

Timestep Collection Time: 2.46374
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.96274

Cumulative Model Updates: 168,630
Cumulative Timesteps: 1,406,177,864

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1406177864...
Checkpoint 1406177864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,260.47135
Policy Entropy: 3.79208
Value Function Loss: 0.04760

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.15757
Policy Update Magnitude: 0.50359
Value Function Update Magnitude: 0.41526

Collected Steps per Second: 21,169.95911
Overall Steps per Second: 10,259.45915

Timestep Collection Time: 2.36307
Timestep Consumption Time: 2.51302
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.87609

Cumulative Model Updates: 168,636
Cumulative Timesteps: 1,406,227,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,287.66016
Policy Entropy: 3.82437
Value Function Loss: 0.04663

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.14770
Policy Update Magnitude: 0.52294
Value Function Update Magnitude: 0.37682

Collected Steps per Second: 21,046.05471
Overall Steps per Second: 10,261.05597

Timestep Collection Time: 2.37707
Timestep Consumption Time: 2.49845
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.87552

Cumulative Model Updates: 168,642
Cumulative Timesteps: 1,406,277,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1406277918...
Checkpoint 1406277918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.54031
Policy Entropy: 3.83842
Value Function Loss: 0.04201

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.43252

Collected Steps per Second: 21,295.04648
Overall Steps per Second: 10,348.68606

Timestep Collection Time: 2.34806
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.83172

Cumulative Model Updates: 168,648
Cumulative Timesteps: 1,406,327,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,415.92697
Policy Entropy: 3.81712
Value Function Loss: 0.04028

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.59468
Value Function Update Magnitude: 0.50288

Collected Steps per Second: 20,855.43566
Overall Steps per Second: 10,116.60944

Timestep Collection Time: 2.39803
Timestep Consumption Time: 2.54552
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.94355

Cumulative Model Updates: 168,654
Cumulative Timesteps: 1,406,377,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1406377932...
Checkpoint 1406377932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,026.37692
Policy Entropy: 3.83001
Value Function Loss: 0.04040

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.60130
Value Function Update Magnitude: 0.51698

Collected Steps per Second: 21,004.29218
Overall Steps per Second: 10,215.05021

Timestep Collection Time: 2.38180
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.89748

Cumulative Model Updates: 168,660
Cumulative Timesteps: 1,406,427,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,630.36279
Policy Entropy: 3.86981
Value Function Loss: 0.04063

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.62998
Value Function Update Magnitude: 0.61009

Collected Steps per Second: 21,144.77667
Overall Steps per Second: 10,419.15034

Timestep Collection Time: 2.36588
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.80135

Cumulative Model Updates: 168,666
Cumulative Timesteps: 1,406,477,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1406477986...
Checkpoint 1406477986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,617.72000
Policy Entropy: 3.92421
Value Function Loss: 0.04032

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.66293
Value Function Update Magnitude: 0.77810

Collected Steps per Second: 20,839.34611
Overall Steps per Second: 10,310.98629

Timestep Collection Time: 2.39940
Timestep Consumption Time: 2.44999
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.84939

Cumulative Model Updates: 168,672
Cumulative Timesteps: 1,406,527,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.90232
Policy Entropy: 3.96810
Value Function Loss: 0.04114

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.12229
Policy Update Magnitude: 0.66431
Value Function Update Magnitude: 0.71026

Collected Steps per Second: 21,090.83140
Overall Steps per Second: 10,418.54496

Timestep Collection Time: 2.37108
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.79990

Cumulative Model Updates: 168,678
Cumulative Timesteps: 1,406,577,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1406577996...
Checkpoint 1406577996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,696.98510
Policy Entropy: 3.99216
Value Function Loss: 0.03763

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.68494
Value Function Update Magnitude: 0.70455

Collected Steps per Second: 20,361.14586
Overall Steps per Second: 10,126.52383

Timestep Collection Time: 2.45576
Timestep Consumption Time: 2.48197
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.93773

Cumulative Model Updates: 168,684
Cumulative Timesteps: 1,406,627,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,331.94228
Policy Entropy: 4.02786
Value Function Loss: 0.03257

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.67840
Value Function Update Magnitude: 0.77810

Collected Steps per Second: 20,824.37911
Overall Steps per Second: 10,150.27443

Timestep Collection Time: 2.40180
Timestep Consumption Time: 2.52575
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.92755

Cumulative Model Updates: 168,690
Cumulative Timesteps: 1,406,678,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1406678014...
Checkpoint 1406678014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,843.86227
Policy Entropy: 4.02098
Value Function Loss: 0.03203

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11724
Policy Update Magnitude: 0.71606
Value Function Update Magnitude: 0.93989

Collected Steps per Second: 20,891.55749
Overall Steps per Second: 10,162.88684

Timestep Collection Time: 2.39369
Timestep Consumption Time: 2.52695
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.92065

Cumulative Model Updates: 168,696
Cumulative Timesteps: 1,406,728,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173.68629
Policy Entropy: 4.06182
Value Function Loss: 0.02942

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.79748
Value Function Update Magnitude: 1.03560

Collected Steps per Second: 21,102.57249
Overall Steps per Second: 10,209.92559

Timestep Collection Time: 2.36966
Timestep Consumption Time: 2.52812
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.89778

Cumulative Model Updates: 168,702
Cumulative Timesteps: 1,406,778,028

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1406778028...
Checkpoint 1406778028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.26416
Policy Entropy: 4.08366
Value Function Loss: 0.02896

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07197
Policy Update Magnitude: 0.91971
Value Function Update Magnitude: 1.07091

Collected Steps per Second: 20,896.16386
Overall Steps per Second: 10,062.60947

Timestep Collection Time: 2.39374
Timestep Consumption Time: 2.57714
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.97088

Cumulative Model Updates: 168,708
Cumulative Timesteps: 1,406,828,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 706.97572
Policy Entropy: 4.07750
Value Function Loss: 0.02802

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.07077
Policy Update Magnitude: 0.93138
Value Function Update Magnitude: 1.03887

Collected Steps per Second: 21,198.90492
Overall Steps per Second: 10,418.86092

Timestep Collection Time: 2.35861
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.79899

Cumulative Model Updates: 168,714
Cumulative Timesteps: 1,406,878,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1406878048...
Checkpoint 1406878048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.43407
Policy Entropy: 4.02986
Value Function Loss: 0.02891

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.85365
Value Function Update Magnitude: 0.95566

Collected Steps per Second: 21,013.56095
Overall Steps per Second: 10,274.27741

Timestep Collection Time: 2.38084
Timestep Consumption Time: 2.48860
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.86944

Cumulative Model Updates: 168,720
Cumulative Timesteps: 1,406,928,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.82834
Policy Entropy: 3.97425
Value Function Loss: 0.02604

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05007
Policy Update Magnitude: 0.77566
Value Function Update Magnitude: 0.89212

Collected Steps per Second: 21,156.88543
Overall Steps per Second: 10,399.31723

Timestep Collection Time: 2.36443
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.81032

Cumulative Model Updates: 168,726
Cumulative Timesteps: 1,406,978,102

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1406978102...
Checkpoint 1406978102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163.24894
Policy Entropy: 3.94294
Value Function Loss: 0.02604

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05379
Policy Update Magnitude: 0.73245
Value Function Update Magnitude: 0.80710

Collected Steps per Second: 21,159.14145
Overall Steps per Second: 10,286.67104

Timestep Collection Time: 2.36418
Timestep Consumption Time: 2.49881
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.86299

Cumulative Model Updates: 168,732
Cumulative Timesteps: 1,407,028,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,454.25482
Policy Entropy: 3.91881
Value Function Loss: 0.02656

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06301
Policy Update Magnitude: 0.71606
Value Function Update Magnitude: 0.70926

Collected Steps per Second: 20,778.94670
Overall Steps per Second: 10,107.55336

Timestep Collection Time: 2.40715
Timestep Consumption Time: 2.54143
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.94858

Cumulative Model Updates: 168,738
Cumulative Timesteps: 1,407,078,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1407078144...
Checkpoint 1407078144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.42783
Policy Entropy: 3.89175
Value Function Loss: 0.02667

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.05435
Policy Update Magnitude: 0.68433
Value Function Update Magnitude: 0.62329

Collected Steps per Second: 21,016.12626
Overall Steps per Second: 10,195.32138

Timestep Collection Time: 2.37970
Timestep Consumption Time: 2.52569
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.90539

Cumulative Model Updates: 168,744
Cumulative Timesteps: 1,407,128,156

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.43160
Policy Entropy: 3.87980
Value Function Loss: 0.02393

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04002
Policy Update Magnitude: 0.66077
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 20,580.89564
Overall Steps per Second: 10,066.50256

Timestep Collection Time: 2.43167
Timestep Consumption Time: 2.53987
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.97154

Cumulative Model Updates: 168,750
Cumulative Timesteps: 1,407,178,202

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1407178202...
Checkpoint 1407178202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.49275
Policy Entropy: 3.88350
Value Function Loss: 0.02079

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04768
Policy Update Magnitude: 0.62054
Value Function Update Magnitude: 0.51133

Collected Steps per Second: 20,805.83722
Overall Steps per Second: 10,148.26899

Timestep Collection Time: 2.40375
Timestep Consumption Time: 2.52438
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.92813

Cumulative Model Updates: 168,756
Cumulative Timesteps: 1,407,228,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,508.38328
Policy Entropy: 3.88340
Value Function Loss: 0.01966

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04902
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.49331

Collected Steps per Second: 21,023.25355
Overall Steps per Second: 10,250.35606

Timestep Collection Time: 2.37937
Timestep Consumption Time: 2.50066
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.88003

Cumulative Model Updates: 168,762
Cumulative Timesteps: 1,407,278,236

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1407278236...
Checkpoint 1407278236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.43072
Policy Entropy: 3.86621
Value Function Loss: 0.02034

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.45703
Value Function Update Magnitude: 0.54394

Collected Steps per Second: 20,848.08040
Overall Steps per Second: 10,372.23786

Timestep Collection Time: 2.39878
Timestep Consumption Time: 2.42274
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.82152

Cumulative Model Updates: 168,768
Cumulative Timesteps: 1,407,328,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.14374
Policy Entropy: 3.86163
Value Function Loss: 0.01878

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.38037
Value Function Update Magnitude: 0.51614

Collected Steps per Second: 21,000.30078
Overall Steps per Second: 10,227.36605

Timestep Collection Time: 2.38149
Timestep Consumption Time: 2.50853
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.89002

Cumulative Model Updates: 168,774
Cumulative Timesteps: 1,407,378,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1407378258...
Checkpoint 1407378258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234.11560
Policy Entropy: 3.83613
Value Function Loss: 0.01774

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.38764
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 21,217.98137
Overall Steps per Second: 10,261.65118

Timestep Collection Time: 2.35706
Timestep Consumption Time: 2.51662
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.87368

Cumulative Model Updates: 168,780
Cumulative Timesteps: 1,407,428,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,207.32126
Policy Entropy: 3.83397
Value Function Loss: 0.02428

Mean KL Divergence: 0.02124
SB3 Clip Fraction: 0.22127
Policy Update Magnitude: 0.42402
Value Function Update Magnitude: 0.72496

Collected Steps per Second: 21,127.49842
Overall Steps per Second: 10,356.73688

Timestep Collection Time: 2.36791
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.83048

Cumulative Model Updates: 168,786
Cumulative Timesteps: 1,407,478,298

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1407478298...
Checkpoint 1407478298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,145.85781
Policy Entropy: 3.84409
Value Function Loss: 0.03186

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.21565
Policy Update Magnitude: 0.54396
Value Function Update Magnitude: 0.79737

Collected Steps per Second: 20,910.75950
Overall Steps per Second: 10,128.20264

Timestep Collection Time: 2.39255
Timestep Consumption Time: 2.54712
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.93967

Cumulative Model Updates: 168,792
Cumulative Timesteps: 1,407,528,328

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.53732
Policy Entropy: 3.86114
Value Function Loss: 0.03487

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.61838
Value Function Update Magnitude: 0.79319

Collected Steps per Second: 21,449.83711
Overall Steps per Second: 10,372.05394

Timestep Collection Time: 2.33186
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.82238

Cumulative Model Updates: 168,798
Cumulative Timesteps: 1,407,578,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1407578346...
Checkpoint 1407578346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,671.20865
Policy Entropy: 3.88937
Value Function Loss: 0.03619

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.62242
Value Function Update Magnitude: 0.72855

Collected Steps per Second: 20,675.01425
Overall Steps per Second: 10,281.75537

Timestep Collection Time: 2.41915
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.86454

Cumulative Model Updates: 168,804
Cumulative Timesteps: 1,407,628,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.57967
Policy Entropy: 3.90534
Value Function Loss: 0.03269

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.77716
Value Function Update Magnitude: 0.77707

Collected Steps per Second: 20,763.91959
Overall Steps per Second: 10,099.13918

Timestep Collection Time: 2.40850
Timestep Consumption Time: 2.54340
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.95191

Cumulative Model Updates: 168,810
Cumulative Timesteps: 1,407,678,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1407678372...
Checkpoint 1407678372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,270.44135
Policy Entropy: 3.87995
Value Function Loss: 0.03542

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.86231
Value Function Update Magnitude: 0.73630

Collected Steps per Second: 20,782.88403
Overall Steps per Second: 10,204.92413

Timestep Collection Time: 2.40621
Timestep Consumption Time: 2.49417
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.90038

Cumulative Model Updates: 168,816
Cumulative Timesteps: 1,407,728,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.62939
Policy Entropy: 3.87062
Value Function Loss: 0.02883

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07591
Policy Update Magnitude: 0.84287
Value Function Update Magnitude: 0.77279

Collected Steps per Second: 20,459.84006
Overall Steps per Second: 9,964.68616

Timestep Collection Time: 2.44498
Timestep Consumption Time: 2.57514
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 5.02013

Cumulative Model Updates: 168,822
Cumulative Timesteps: 1,407,778,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1407778404...
Checkpoint 1407778404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,972.14911
Policy Entropy: 3.81830
Value Function Loss: 0.02893

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.77521
Value Function Update Magnitude: 0.80814

Collected Steps per Second: 20,512.75574
Overall Steps per Second: 10,024.59215

Timestep Collection Time: 2.43868
Timestep Consumption Time: 2.55145
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.99013

Cumulative Model Updates: 168,828
Cumulative Timesteps: 1,407,828,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,261.49655
Policy Entropy: 3.81096
Value Function Loss: 0.02936

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.59617
Value Function Update Magnitude: 0.76215

Collected Steps per Second: 20,546.39628
Overall Steps per Second: 10,077.22447

Timestep Collection Time: 2.43430
Timestep Consumption Time: 2.52898
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.96327

Cumulative Model Updates: 168,834
Cumulative Timesteps: 1,407,878,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1407878444...
Checkpoint 1407878444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,975.96968
Policy Entropy: 3.83214
Value Function Loss: 0.03312

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10694
Policy Update Magnitude: 0.61360
Value Function Update Magnitude: 0.70355

Collected Steps per Second: 20,851.16105
Overall Steps per Second: 10,209.56780

Timestep Collection Time: 2.39900
Timestep Consumption Time: 2.50052
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.89952

Cumulative Model Updates: 168,840
Cumulative Timesteps: 1,407,928,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172.81229
Policy Entropy: 3.85287
Value Function Loss: 0.03289

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.66677
Value Function Update Magnitude: 0.67886

Collected Steps per Second: 20,958.67846
Overall Steps per Second: 10,248.59400

Timestep Collection Time: 2.38565
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.87872

Cumulative Model Updates: 168,846
Cumulative Timesteps: 1,407,978,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1407978466...
Checkpoint 1407978466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,509.71064
Policy Entropy: 3.86044
Value Function Loss: 0.02966

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.58495
Value Function Update Magnitude: 0.66560

Collected Steps per Second: 20,811.15920
Overall Steps per Second: 10,218.80639

Timestep Collection Time: 2.40333
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.89451

Cumulative Model Updates: 168,852
Cumulative Timesteps: 1,408,028,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 833.07475
Policy Entropy: 3.85905
Value Function Loss: 0.02434

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.60518
Value Function Update Magnitude: 0.68102

Collected Steps per Second: 21,070.93215
Overall Steps per Second: 10,199.21567

Timestep Collection Time: 2.37370
Timestep Consumption Time: 2.53021
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.90391

Cumulative Model Updates: 168,858
Cumulative Timesteps: 1,408,078,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1408078498...
Checkpoint 1408078498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,592.95131
Policy Entropy: 3.84548
Value Function Loss: 0.02695

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.17795
Policy Update Magnitude: 0.53241
Value Function Update Magnitude: 0.74684

Collected Steps per Second: 20,451.54011
Overall Steps per Second: 10,145.37786

Timestep Collection Time: 2.44549
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.92973

Cumulative Model Updates: 168,864
Cumulative Timesteps: 1,408,128,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,974.11456
Policy Entropy: 3.82506
Value Function Loss: 0.03146

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.79934

Collected Steps per Second: 20,992.66906
Overall Steps per Second: 10,335.39497

Timestep Collection Time: 2.38293
Timestep Consumption Time: 2.45714
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.84007

Cumulative Model Updates: 168,870
Cumulative Timesteps: 1,408,178,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1408178536...
Checkpoint 1408178536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,364.19345
Policy Entropy: 3.80858
Value Function Loss: 0.03223

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.64625
Value Function Update Magnitude: 0.88129

Collected Steps per Second: 21,207.70803
Overall Steps per Second: 10,339.60733

Timestep Collection Time: 2.35829
Timestep Consumption Time: 2.47883
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.83713

Cumulative Model Updates: 168,876
Cumulative Timesteps: 1,408,228,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,657.56450
Policy Entropy: 3.77608
Value Function Loss: 0.03671

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.61654
Value Function Update Magnitude: 0.73989

Collected Steps per Second: 21,093.98323
Overall Steps per Second: 10,336.98125

Timestep Collection Time: 2.37129
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.83894

Cumulative Model Updates: 168,882
Cumulative Timesteps: 1,408,278,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1408278570...
Checkpoint 1408278570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,221.47282
Policy Entropy: 3.79672
Value Function Loss: 0.03071

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.56554
Value Function Update Magnitude: 0.59514

Collected Steps per Second: 20,854.52357
Overall Steps per Second: 10,278.05986

Timestep Collection Time: 2.39890
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.86746

Cumulative Model Updates: 168,888
Cumulative Timesteps: 1,408,328,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,721.77538
Policy Entropy: 3.77854
Value Function Loss: 0.03441

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.51684
Value Function Update Magnitude: 0.51073

Collected Steps per Second: 20,947.14702
Overall Steps per Second: 10,142.81175

Timestep Collection Time: 2.38830
Timestep Consumption Time: 2.54406
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.93236

Cumulative Model Updates: 168,894
Cumulative Timesteps: 1,408,378,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1408378626...
Checkpoint 1408378626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,647.67507
Policy Entropy: 3.78033
Value Function Loss: 0.02763

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.49896
Value Function Update Magnitude: 0.50142

Collected Steps per Second: 20,193.04415
Overall Steps per Second: 10,092.85503

Timestep Collection Time: 2.47640
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.95459

Cumulative Model Updates: 168,900
Cumulative Timesteps: 1,408,428,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,863.52171
Policy Entropy: 3.77269
Value Function Loss: 0.03084

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.48342
Value Function Update Magnitude: 0.49077

Collected Steps per Second: 20,910.38764
Overall Steps per Second: 10,241.08831

Timestep Collection Time: 2.39125
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.88249

Cumulative Model Updates: 168,906
Cumulative Timesteps: 1,408,478,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1408478634...
Checkpoint 1408478634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,843.03393
Policy Entropy: 3.77666
Value Function Loss: 0.02643

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.50427
Value Function Update Magnitude: 0.50513

Collected Steps per Second: 20,931.64182
Overall Steps per Second: 10,190.18887

Timestep Collection Time: 2.38901
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.90727

Cumulative Model Updates: 168,912
Cumulative Timesteps: 1,408,528,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,644.66744
Policy Entropy: 3.75109
Value Function Loss: 0.03298

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.50635
Value Function Update Magnitude: 0.46430

Collected Steps per Second: 20,789.08227
Overall Steps per Second: 10,219.07505

Timestep Collection Time: 2.40569
Timestep Consumption Time: 2.48830
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.89398

Cumulative Model Updates: 168,918
Cumulative Timesteps: 1,408,578,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1408578652...
Checkpoint 1408578652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,871.24226
Policy Entropy: 3.74717
Value Function Loss: 0.02547

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.48122
Value Function Update Magnitude: 0.38629

Collected Steps per Second: 20,810.59953
Overall Steps per Second: 10,249.76216

Timestep Collection Time: 2.40272
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.87836

Cumulative Model Updates: 168,924
Cumulative Timesteps: 1,408,628,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,506.41098
Policy Entropy: 3.74944
Value Function Loss: 0.02263

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.47459
Value Function Update Magnitude: 0.45392

Collected Steps per Second: 20,553.59175
Overall Steps per Second: 10,079.18075

Timestep Collection Time: 2.43354
Timestep Consumption Time: 2.52897
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.96251

Cumulative Model Updates: 168,930
Cumulative Timesteps: 1,408,678,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1408678672...
Checkpoint 1408678672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,044.63361
Policy Entropy: 3.75096
Value Function Loss: 0.01884

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.45735
Value Function Update Magnitude: 0.59282

Collected Steps per Second: 20,751.91518
Overall Steps per Second: 10,234.98780

Timestep Collection Time: 2.40971
Timestep Consumption Time: 2.47608
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.88579

Cumulative Model Updates: 168,936
Cumulative Timesteps: 1,408,728,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,111.22930
Policy Entropy: 3.76072
Value Function Loss: 0.01971

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.44552
Value Function Update Magnitude: 0.57634

Collected Steps per Second: 20,959.45833
Overall Steps per Second: 10,196.16349

Timestep Collection Time: 2.38584
Timestep Consumption Time: 2.51855
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.90439

Cumulative Model Updates: 168,942
Cumulative Timesteps: 1,408,778,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1408778684...
Checkpoint 1408778684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,370.11898
Policy Entropy: 3.75743
Value Function Loss: 0.02015

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.43782
Value Function Update Magnitude: 0.54970

Collected Steps per Second: 21,210.50864
Overall Steps per Second: 10,229.38903

Timestep Collection Time: 2.35949
Timestep Consumption Time: 2.53288
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.89237

Cumulative Model Updates: 168,948
Cumulative Timesteps: 1,408,828,730

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,863.22959
Policy Entropy: 3.76023
Value Function Loss: 0.02214

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12036
Policy Update Magnitude: 0.45568
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 20,216.82852
Overall Steps per Second: 10,285.67147

Timestep Collection Time: 2.47418
Timestep Consumption Time: 2.38890
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.86308

Cumulative Model Updates: 168,954
Cumulative Timesteps: 1,408,878,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1408878750...
Checkpoint 1408878750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,789.77596
Policy Entropy: 3.75951
Value Function Loss: 0.02152

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12105
Policy Update Magnitude: 0.49171
Value Function Update Magnitude: 0.68042

Collected Steps per Second: 20,321.98491
Overall Steps per Second: 10,152.85095

Timestep Collection Time: 2.46049
Timestep Consumption Time: 2.46443
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.92492

Cumulative Model Updates: 168,960
Cumulative Timesteps: 1,408,928,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,302.05642
Policy Entropy: 3.76401
Value Function Loss: 0.02062

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.48208
Value Function Update Magnitude: 0.69694

Collected Steps per Second: 20,236.10160
Overall Steps per Second: 10,078.13963

Timestep Collection Time: 2.47222
Timestep Consumption Time: 2.49180
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.96401

Cumulative Model Updates: 168,966
Cumulative Timesteps: 1,408,978,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1408978780...
Checkpoint 1408978780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,556.89504
Policy Entropy: 3.74038
Value Function Loss: 0.01837

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.45189
Value Function Update Magnitude: 0.66614

Collected Steps per Second: 20,462.21328
Overall Steps per Second: 10,170.14245

Timestep Collection Time: 2.44392
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.91714

Cumulative Model Updates: 168,972
Cumulative Timesteps: 1,409,028,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,117.76385
Policy Entropy: 3.74234
Value Function Loss: 0.01949

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.47298
Value Function Update Magnitude: 0.69811

Collected Steps per Second: 20,207.75515
Overall Steps per Second: 10,107.58350

Timestep Collection Time: 2.47499
Timestep Consumption Time: 2.47318
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.94817

Cumulative Model Updates: 168,978
Cumulative Timesteps: 1,409,078,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1409078802...
Checkpoint 1409078802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,805.69208
Policy Entropy: 3.73410
Value Function Loss: 0.02081

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.51563
Value Function Update Magnitude: 0.68066

Collected Steps per Second: 20,621.01768
Overall Steps per Second: 10,288.93123

Timestep Collection Time: 2.42549
Timestep Consumption Time: 2.43566
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.86115

Cumulative Model Updates: 168,984
Cumulative Timesteps: 1,409,128,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,503.25087
Policy Entropy: 3.73946
Value Function Loss: 0.02232

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.50656
Value Function Update Magnitude: 0.54324

Collected Steps per Second: 20,659.41831
Overall Steps per Second: 10,099.93408

Timestep Collection Time: 2.42175
Timestep Consumption Time: 2.53194
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.95370

Cumulative Model Updates: 168,990
Cumulative Timesteps: 1,409,178,850

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1409178850...
Checkpoint 1409178850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,503.25087
Policy Entropy: 3.73141
Value Function Loss: 0.01923

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.46905
Value Function Update Magnitude: 0.49089

Collected Steps per Second: 21,027.36029
Overall Steps per Second: 10,165.74672

Timestep Collection Time: 2.37823
Timestep Consumption Time: 2.54103
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.91926

Cumulative Model Updates: 168,996
Cumulative Timesteps: 1,409,228,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,793.55461
Policy Entropy: 3.73271
Value Function Loss: 0.01702

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.43850
Value Function Update Magnitude: 0.53108

Collected Steps per Second: 21,048.00973
Overall Steps per Second: 10,296.43258

Timestep Collection Time: 2.37590
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.85683

Cumulative Model Updates: 169,002
Cumulative Timesteps: 1,409,278,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1409278866...
Checkpoint 1409278866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,454.83164
Policy Entropy: 3.73496
Value Function Loss: 0.01531

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.41765
Value Function Update Magnitude: 0.50327

Collected Steps per Second: 20,887.65651
Overall Steps per Second: 10,250.01484

Timestep Collection Time: 2.39500
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.88058

Cumulative Model Updates: 169,008
Cumulative Timesteps: 1,409,328,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,981.66763
Policy Entropy: 3.75273
Value Function Loss: 0.01918

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.43274
Value Function Update Magnitude: 0.43843

Collected Steps per Second: 20,919.15027
Overall Steps per Second: 10,137.32634

Timestep Collection Time: 2.39101
Timestep Consumption Time: 2.54303
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.93404

Cumulative Model Updates: 169,014
Cumulative Timesteps: 1,409,378,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1409378910...
Checkpoint 1409378910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,210.84271
Policy Entropy: 3.77078
Value Function Loss: 0.01830

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12431
Policy Update Magnitude: 0.47166
Value Function Update Magnitude: 0.47577

Collected Steps per Second: 20,890.12532
Overall Steps per Second: 10,139.55357

Timestep Collection Time: 2.39434
Timestep Consumption Time: 2.53862
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.93296

Cumulative Model Updates: 169,020
Cumulative Timesteps: 1,409,428,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,259.35134
Policy Entropy: 3.79847
Value Function Loss: 0.02024

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.47932
Value Function Update Magnitude: 0.54812

Collected Steps per Second: 21,177.43560
Overall Steps per Second: 10,198.01160

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.54212
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.90331

Cumulative Model Updates: 169,026
Cumulative Timesteps: 1,409,478,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1409478932...
Checkpoint 1409478932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.98826
Policy Entropy: 3.79018
Value Function Loss: 0.02195

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.52669
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 21,159.21094
Overall Steps per Second: 10,237.41625

Timestep Collection Time: 2.36313
Timestep Consumption Time: 2.52111
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.88424

Cumulative Model Updates: 169,032
Cumulative Timesteps: 1,409,528,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,678.18848
Policy Entropy: 3.77707
Value Function Loss: 0.02778

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.62411
Value Function Update Magnitude: 0.64041

Collected Steps per Second: 20,948.70960
Overall Steps per Second: 10,209.59375

Timestep Collection Time: 2.38697
Timestep Consumption Time: 2.51077
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.89775

Cumulative Model Updates: 169,038
Cumulative Timesteps: 1,409,578,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1409578938...
Checkpoint 1409578938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,655.99184
Policy Entropy: 3.77167
Value Function Loss: 0.02854

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.65649
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 21,035.76787
Overall Steps per Second: 10,306.19571

Timestep Collection Time: 2.37795
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.85359

Cumulative Model Updates: 169,044
Cumulative Timesteps: 1,409,628,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113.06370
Policy Entropy: 3.80295
Value Function Loss: 0.02659

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.64539
Value Function Update Magnitude: 0.67894

Collected Steps per Second: 20,942.08747
Overall Steps per Second: 10,126.00786

Timestep Collection Time: 2.38849
Timestep Consumption Time: 2.55126
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.93976

Cumulative Model Updates: 169,050
Cumulative Timesteps: 1,409,678,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1409678980...
Checkpoint 1409678980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.81932
Policy Entropy: 3.79261
Value Function Loss: 0.02095

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07520
Policy Update Magnitude: 0.63580
Value Function Update Magnitude: 0.55248

Collected Steps per Second: 20,806.97549
Overall Steps per Second: 10,124.42832

Timestep Collection Time: 2.40362
Timestep Consumption Time: 2.53612
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.93974

Cumulative Model Updates: 169,056
Cumulative Timesteps: 1,409,728,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85.81932
Policy Entropy: 3.77505
Value Function Loss: 0.01761

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.60979
Value Function Update Magnitude: 0.51066

Collected Steps per Second: 20,940.91275
Overall Steps per Second: 10,139.66258

Timestep Collection Time: 2.38882
Timestep Consumption Time: 2.54468
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.93350

Cumulative Model Updates: 169,062
Cumulative Timesteps: 1,409,779,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1409779016...
Checkpoint 1409779016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,727.02872
Policy Entropy: 3.74608
Value Function Loss: 0.01975

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.52735

Collected Steps per Second: 20,531.52047
Overall Steps per Second: 10,184.35333

Timestep Collection Time: 2.43664
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.91224

Cumulative Model Updates: 169,068
Cumulative Timesteps: 1,409,829,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,917.96497
Policy Entropy: 3.75741
Value Function Loss: 0.01957

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.61025

Collected Steps per Second: 21,192.99606
Overall Steps per Second: 10,380.81045

Timestep Collection Time: 2.36059
Timestep Consumption Time: 2.45869
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.81928

Cumulative Model Updates: 169,074
Cumulative Timesteps: 1,409,879,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1409879072...
Checkpoint 1409879072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,141.96061
Policy Entropy: 3.76979
Value Function Loss: 0.01997

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.58440
Value Function Update Magnitude: 0.68822

Collected Steps per Second: 20,845.94726
Overall Steps per Second: 10,225.39739

Timestep Collection Time: 2.39979
Timestep Consumption Time: 2.49253
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.89233

Cumulative Model Updates: 169,080
Cumulative Timesteps: 1,409,929,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,466.70433
Policy Entropy: 3.77432
Value Function Loss: 0.01681

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.59804
Value Function Update Magnitude: 0.65389

Collected Steps per Second: 20,826.15061
Overall Steps per Second: 10,068.89835

Timestep Collection Time: 2.40160
Timestep Consumption Time: 2.56578
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.96738

Cumulative Model Updates: 169,086
Cumulative Timesteps: 1,409,979,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1409979114...
Checkpoint 1409979114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,466.70433
Policy Entropy: 3.76734
Value Function Loss: 0.01727

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.52146

Collected Steps per Second: 20,774.44700
Overall Steps per Second: 10,274.76451

Timestep Collection Time: 2.40796
Timestep Consumption Time: 2.46067
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.86863

Cumulative Model Updates: 169,092
Cumulative Timesteps: 1,410,029,138

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,423.35969
Policy Entropy: 3.77368
Value Function Loss: 0.01433

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.16350
Policy Update Magnitude: 0.46004
Value Function Update Magnitude: 0.49328

Collected Steps per Second: 20,175.65834
Overall Steps per Second: 10,118.74792

Timestep Collection Time: 2.47932
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.94350

Cumulative Model Updates: 169,098
Cumulative Timesteps: 1,410,079,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1410079160...
Checkpoint 1410079160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,255.69868
Policy Entropy: 3.77035
Value Function Loss: 0.01956

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.41151
Value Function Update Magnitude: 0.53762

Collected Steps per Second: 20,251.48913
Overall Steps per Second: 10,018.35650

Timestep Collection Time: 2.46905
Timestep Consumption Time: 2.52199
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.99104

Cumulative Model Updates: 169,104
Cumulative Timesteps: 1,410,129,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,983.73171
Policy Entropy: 3.78261
Value Function Loss: 0.02130

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.47841
Value Function Update Magnitude: 0.58334

Collected Steps per Second: 20,212.28886
Overall Steps per Second: 10,093.76074

Timestep Collection Time: 2.47374
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.95356

Cumulative Model Updates: 169,110
Cumulative Timesteps: 1,410,179,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1410179162...
Checkpoint 1410179162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,262.65397
Policy Entropy: 3.78746
Value Function Loss: 0.02515

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.52675
Value Function Update Magnitude: 0.66000

Collected Steps per Second: 20,198.01878
Overall Steps per Second: 10,146.79784

Timestep Collection Time: 2.47589
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.92845

Cumulative Model Updates: 169,116
Cumulative Timesteps: 1,410,229,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,994.28696
Policy Entropy: 3.80259
Value Function Loss: 0.02199

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.66568

Collected Steps per Second: 20,756.21176
Overall Steps per Second: 10,142.74026

Timestep Collection Time: 2.40940
Timestep Consumption Time: 2.52122
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.93062

Cumulative Model Updates: 169,122
Cumulative Timesteps: 1,410,279,180

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1410279180...
Checkpoint 1410279180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,532.84240
Policy Entropy: 3.79022
Value Function Loss: 0.01863

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.53047
Value Function Update Magnitude: 0.74022

Collected Steps per Second: 20,659.79739
Overall Steps per Second: 10,116.68618

Timestep Collection Time: 2.42074
Timestep Consumption Time: 2.52278
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.94352

Cumulative Model Updates: 169,128
Cumulative Timesteps: 1,410,329,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,673.11986
Policy Entropy: 3.77499
Value Function Loss: 0.02114

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12364
Policy Update Magnitude: 0.49981
Value Function Update Magnitude: 0.59575

Collected Steps per Second: 20,585.89439
Overall Steps per Second: 10,101.70762

Timestep Collection Time: 2.43030
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.95263

Cumulative Model Updates: 169,134
Cumulative Timesteps: 1,410,379,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1410379222...
Checkpoint 1410379222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 225,580.33854
Policy Entropy: 3.78053
Value Function Loss: 0.02145

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.49926
Value Function Update Magnitude: 0.57545

Collected Steps per Second: 20,702.92838
Overall Steps per Second: 10,189.04166

Timestep Collection Time: 2.41560
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.90821

Cumulative Model Updates: 169,140
Cumulative Timesteps: 1,410,429,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,946.88758
Policy Entropy: 3.77766
Value Function Loss: 0.02316

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.49816
Value Function Update Magnitude: 0.60901

Collected Steps per Second: 20,743.48253
Overall Steps per Second: 10,005.58855

Timestep Collection Time: 2.41194
Timestep Consumption Time: 2.58847
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 5.00041

Cumulative Model Updates: 169,146
Cumulative Timesteps: 1,410,479,264

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1410479264...
Checkpoint 1410479264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,533.39944
Policy Entropy: 3.77261
Value Function Loss: 0.02281

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.53138
Value Function Update Magnitude: 0.55373

Collected Steps per Second: 20,856.32293
Overall Steps per Second: 10,259.18590

Timestep Collection Time: 2.39764
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.87427

Cumulative Model Updates: 169,152
Cumulative Timesteps: 1,410,529,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,368.50880
Policy Entropy: 3.75669
Value Function Loss: 0.02186

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.53698
Value Function Update Magnitude: 0.54611

Collected Steps per Second: 20,558.48778
Overall Steps per Second: 10,069.05041

Timestep Collection Time: 2.43325
Timestep Consumption Time: 2.53484
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.96810

Cumulative Model Updates: 169,158
Cumulative Timesteps: 1,410,579,294

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1410579294...
Checkpoint 1410579294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,338.53903
Policy Entropy: 3.76095
Value Function Loss: 0.02108

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.50575
Value Function Update Magnitude: 0.49375

Collected Steps per Second: 20,709.16470
Overall Steps per Second: 10,184.03432

Timestep Collection Time: 2.41555
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.91200

Cumulative Model Updates: 169,164
Cumulative Timesteps: 1,410,629,318

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,273.59524
Policy Entropy: 3.76423
Value Function Loss: 0.02034

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.45288
Value Function Update Magnitude: 0.43963

Collected Steps per Second: 20,880.46039
Overall Steps per Second: 10,112.75015

Timestep Collection Time: 2.39640
Timestep Consumption Time: 2.55161
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.94801

Cumulative Model Updates: 169,170
Cumulative Timesteps: 1,410,679,356

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1410679356...
Checkpoint 1410679356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,829.75595
Policy Entropy: 3.76573
Value Function Loss: 0.02083

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.43682
Value Function Update Magnitude: 0.48468

Collected Steps per Second: 21,085.24449
Overall Steps per Second: 10,237.88578

Timestep Collection Time: 2.37142
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.88402

Cumulative Model Updates: 169,176
Cumulative Timesteps: 1,410,729,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,139.05626
Policy Entropy: 3.76373
Value Function Loss: 0.02308

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.45044
Value Function Update Magnitude: 0.54120

Collected Steps per Second: 21,099.29441
Overall Steps per Second: 10,159.36403

Timestep Collection Time: 2.37155
Timestep Consumption Time: 2.55376
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.92531

Cumulative Model Updates: 169,182
Cumulative Timesteps: 1,410,779,396

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1410779396...
Checkpoint 1410779396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,442.73505
Policy Entropy: 3.76626
Value Function Loss: 0.02314

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.49916
Value Function Update Magnitude: 0.59998

Collected Steps per Second: 21,085.67573
Overall Steps per Second: 10,188.40459

Timestep Collection Time: 2.37137
Timestep Consumption Time: 2.53636
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.90774

Cumulative Model Updates: 169,188
Cumulative Timesteps: 1,410,829,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,901.41790
Policy Entropy: 3.74405
Value Function Loss: 0.02287

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.69312

Collected Steps per Second: 21,188.81307
Overall Steps per Second: 10,337.26328

Timestep Collection Time: 2.36210
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.84171

Cumulative Model Updates: 169,194
Cumulative Timesteps: 1,410,879,448

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1410879448...
Checkpoint 1410879448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,874.30669
Policy Entropy: 3.76402
Value Function Loss: 0.02273

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.75438

Collected Steps per Second: 21,067.45419
Overall Steps per Second: 10,299.06948

Timestep Collection Time: 2.37361
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.85539

Cumulative Model Updates: 169,200
Cumulative Timesteps: 1,410,929,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,315.11553
Policy Entropy: 3.75916
Value Function Loss: 0.02200

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.58510
Value Function Update Magnitude: 0.69627

Collected Steps per Second: 20,936.58787
Overall Steps per Second: 10,132.93079

Timestep Collection Time: 2.38874
Timestep Consumption Time: 2.54685
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.93559

Cumulative Model Updates: 169,206
Cumulative Timesteps: 1,410,979,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1410979466...
Checkpoint 1410979466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,331.79409
Policy Entropy: 3.76607
Value Function Loss: 0.02501

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.55576
Value Function Update Magnitude: 0.61681

Collected Steps per Second: 20,509.92723
Overall Steps per Second: 10,224.69543

Timestep Collection Time: 2.43960
Timestep Consumption Time: 2.45404
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.89364

Cumulative Model Updates: 169,212
Cumulative Timesteps: 1,411,029,502

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,106.06727
Policy Entropy: 3.74177
Value Function Loss: 0.02425

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.56531

Collected Steps per Second: 20,411.99406
Overall Steps per Second: 10,273.11846

Timestep Collection Time: 2.44954
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.86707

Cumulative Model Updates: 169,218
Cumulative Timesteps: 1,411,079,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1411079502...
Checkpoint 1411079502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,730.76286
Policy Entropy: 3.75664
Value Function Loss: 0.02738

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.56148
Value Function Update Magnitude: 0.48879

Collected Steps per Second: 20,210.74985
Overall Steps per Second: 10,216.73982

Timestep Collection Time: 2.47433
Timestep Consumption Time: 2.42039
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.89471

Cumulative Model Updates: 169,224
Cumulative Timesteps: 1,411,129,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,627.34119
Policy Entropy: 3.76970
Value Function Loss: 0.02427

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.42157

Collected Steps per Second: 20,174.40623
Overall Steps per Second: 10,129.25022

Timestep Collection Time: 2.47898
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.93738

Cumulative Model Updates: 169,230
Cumulative Timesteps: 1,411,179,522

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1411179522...
Checkpoint 1411179522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,543.19916
Policy Entropy: 3.77922
Value Function Loss: 0.02548

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.47516
Value Function Update Magnitude: 0.38733

Collected Steps per Second: 20,337.19996
Overall Steps per Second: 10,153.78344

Timestep Collection Time: 2.46002
Timestep Consumption Time: 2.46720
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.92723

Cumulative Model Updates: 169,236
Cumulative Timesteps: 1,411,229,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,220.32007
Policy Entropy: 3.77520
Value Function Loss: 0.02306

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11674
Policy Update Magnitude: 0.45845
Value Function Update Magnitude: 0.37989

Collected Steps per Second: 20,916.04219
Overall Steps per Second: 10,254.83316

Timestep Collection Time: 2.39137
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.87751

Cumulative Model Updates: 169,242
Cumulative Timesteps: 1,411,279,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1411279570...
Checkpoint 1411279570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,299.63270
Policy Entropy: 3.77030
Value Function Loss: 0.02376

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.48046
Value Function Update Magnitude: 0.40634

Collected Steps per Second: 20,971.56219
Overall Steps per Second: 10,367.82286

Timestep Collection Time: 2.38504
Timestep Consumption Time: 2.43931
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.82435

Cumulative Model Updates: 169,248
Cumulative Timesteps: 1,411,329,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,955.28051
Policy Entropy: 3.77069
Value Function Loss: 0.02121

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.47570
Value Function Update Magnitude: 0.39623

Collected Steps per Second: 20,702.57877
Overall Steps per Second: 10,102.20784

Timestep Collection Time: 2.41728
Timestep Consumption Time: 2.53649
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.95377

Cumulative Model Updates: 169,254
Cumulative Timesteps: 1,411,379,632

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1411379632...
Checkpoint 1411379632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,457.59285
Policy Entropy: 3.77695
Value Function Loss: 0.02016

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.44825
Value Function Update Magnitude: 0.42372

Collected Steps per Second: 20,989.05565
Overall Steps per Second: 10,291.64121

Timestep Collection Time: 2.38362
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.86123

Cumulative Model Updates: 169,260
Cumulative Timesteps: 1,411,429,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,316.68947
Policy Entropy: 3.77682
Value Function Loss: 0.01719

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.43530
Value Function Update Magnitude: 0.44588

Collected Steps per Second: 20,961.15760
Overall Steps per Second: 10,318.71474

Timestep Collection Time: 2.38575
Timestep Consumption Time: 2.46059
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.84634

Cumulative Model Updates: 169,266
Cumulative Timesteps: 1,411,479,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1411479670...
Checkpoint 1411479670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,509.35460
Policy Entropy: 3.78438
Value Function Loss: 0.01709

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.42245
Value Function Update Magnitude: 0.48884

Collected Steps per Second: 20,891.43994
Overall Steps per Second: 10,283.45640

Timestep Collection Time: 2.39438
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.86432

Cumulative Model Updates: 169,272
Cumulative Timesteps: 1,411,529,692

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,393.06330
Policy Entropy: 3.77451
Value Function Loss: 0.01769

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.40630
Value Function Update Magnitude: 0.47091

Collected Steps per Second: 20,967.84213
Overall Steps per Second: 10,129.80996

Timestep Collection Time: 2.38575
Timestep Consumption Time: 2.55255
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.93830

Cumulative Model Updates: 169,278
Cumulative Timesteps: 1,411,579,716

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1411579716...
Checkpoint 1411579716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,889.05834
Policy Entropy: 3.77455
Value Function Loss: 0.01748

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.41574
Value Function Update Magnitude: 0.45025

Collected Steps per Second: 21,011.61122
Overall Steps per Second: 10,179.17991

Timestep Collection Time: 2.37992
Timestep Consumption Time: 2.53265
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.91258

Cumulative Model Updates: 169,284
Cumulative Timesteps: 1,411,629,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,466.98414
Policy Entropy: 3.75473
Value Function Loss: 0.01646

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.46906
Value Function Update Magnitude: 0.39989

Collected Steps per Second: 20,352.53752
Overall Steps per Second: 10,349.26472

Timestep Collection Time: 2.45768
Timestep Consumption Time: 2.37551
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.83319

Cumulative Model Updates: 169,290
Cumulative Timesteps: 1,411,679,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1411679742...
Checkpoint 1411679742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,591.62670
Policy Entropy: 3.75636
Value Function Loss: 0.01617

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.48917
Value Function Update Magnitude: 0.40235

Collected Steps per Second: 20,199.65620
Overall Steps per Second: 10,257.15644

Timestep Collection Time: 2.47569
Timestep Consumption Time: 2.39974
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.87543

Cumulative Model Updates: 169,296
Cumulative Timesteps: 1,411,729,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,591.62670
Policy Entropy: 3.74791
Value Function Loss: 0.01589

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.40375

Collected Steps per Second: 20,072.41254
Overall Steps per Second: 10,066.34153

Timestep Collection Time: 2.49178
Timestep Consumption Time: 2.47686
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.96864

Cumulative Model Updates: 169,302
Cumulative Timesteps: 1,411,779,766

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1411779766...
Checkpoint 1411779766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,232.36122
Policy Entropy: 3.77102
Value Function Loss: 0.01566

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.51301
Value Function Update Magnitude: 0.42026

Collected Steps per Second: 20,159.83077
Overall Steps per Second: 10,104.48956

Timestep Collection Time: 2.48087
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.94968

Cumulative Model Updates: 169,308
Cumulative Timesteps: 1,411,829,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.79631
Value Function Loss: 0.01342

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07606
Policy Update Magnitude: 0.46164
Value Function Update Magnitude: 0.44885

Collected Steps per Second: 21,103.57727
Overall Steps per Second: 10,234.04616

Timestep Collection Time: 2.37012
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.88741

Cumulative Model Updates: 169,314
Cumulative Timesteps: 1,411,879,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1411879798...
Checkpoint 1411879798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.78441
Value Function Loss: 0.01184

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06548
Policy Update Magnitude: 0.44636
Value Function Update Magnitude: 0.41908

Collected Steps per Second: 20,996.00877
Overall Steps per Second: 10,141.49622

Timestep Collection Time: 2.38160
Timestep Consumption Time: 2.54904
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.93063

Cumulative Model Updates: 169,320
Cumulative Timesteps: 1,411,929,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.77878
Value Function Loss: 0.00992

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.40831
Value Function Update Magnitude: 0.33569

Collected Steps per Second: 20,955.57418
Overall Steps per Second: 10,090.60687

Timestep Collection Time: 2.38695
Timestep Consumption Time: 2.57013
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.95709

Cumulative Model Updates: 169,326
Cumulative Timesteps: 1,411,979,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1411979822...
Checkpoint 1411979822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.78701
Value Function Loss: 0.00823

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.35438
Value Function Update Magnitude: 0.23174

Collected Steps per Second: 21,110.94391
Overall Steps per Second: 10,209.63029

Timestep Collection Time: 2.36967
Timestep Consumption Time: 2.53021
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.89988

Cumulative Model Updates: 169,332
Cumulative Timesteps: 1,412,029,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.78958
Value Function Loss: 0.00685

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.18445
Policy Update Magnitude: 0.26492
Value Function Update Magnitude: 0.15530

Collected Steps per Second: 20,806.05911
Overall Steps per Second: 10,175.79055

Timestep Collection Time: 2.40497
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.91736

Cumulative Model Updates: 169,338
Cumulative Timesteps: 1,412,079,886

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1412079886...
Checkpoint 1412079886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.78450
Value Function Loss: 0.00783

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.23787
Value Function Update Magnitude: 0.17577

Collected Steps per Second: 20,891.06157
Overall Steps per Second: 10,158.19896

Timestep Collection Time: 2.39452
Timestep Consumption Time: 2.52998
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.92450

Cumulative Model Updates: 169,344
Cumulative Timesteps: 1,412,129,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.74392
Value Function Loss: 0.00952

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.08614
Policy Update Magnitude: 0.33516
Value Function Update Magnitude: 0.27129

Collected Steps per Second: 20,685.08666
Overall Steps per Second: 10,092.08701

Timestep Collection Time: 2.41730
Timestep Consumption Time: 2.53728
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.95457

Cumulative Model Updates: 169,350
Cumulative Timesteps: 1,412,179,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1412179912...
Checkpoint 1412179912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.76234
Value Function Loss: 0.00988

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04497
Policy Update Magnitude: 0.44715
Value Function Update Magnitude: 0.31504

Collected Steps per Second: 20,925.16667
Overall Steps per Second: 10,137.39975

Timestep Collection Time: 2.39004
Timestep Consumption Time: 2.54337
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.93341

Cumulative Model Updates: 169,356
Cumulative Timesteps: 1,412,229,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.76780
Value Function Loss: 0.01045

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.04310
Policy Update Magnitude: 0.46761
Value Function Update Magnitude: 0.27613

Collected Steps per Second: 20,294.10137
Overall Steps per Second: 10,289.08080

Timestep Collection Time: 2.46476
Timestep Consumption Time: 2.39671
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.86146

Cumulative Model Updates: 169,362
Cumulative Timesteps: 1,412,279,944

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1412279944...
Checkpoint 1412279944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,318.02802
Policy Entropy: 3.78148
Value Function Loss: 0.00896

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04619
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.24547

Collected Steps per Second: 20,218.49855
Overall Steps per Second: 10,267.31821

Timestep Collection Time: 2.47328
Timestep Consumption Time: 2.39713
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.87041

Cumulative Model Updates: 169,368
Cumulative Timesteps: 1,412,329,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,665.02768
Policy Entropy: 3.76920
Value Function Loss: 0.00985

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04605
Policy Update Magnitude: 0.49167
Value Function Update Magnitude: 0.30378

Collected Steps per Second: 19,850.04647
Overall Steps per Second: 10,047.42730

Timestep Collection Time: 2.51999
Timestep Consumption Time: 2.45859
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.97859

Cumulative Model Updates: 169,374
Cumulative Timesteps: 1,412,379,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1412379972...
Checkpoint 1412379972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,665.02768
Policy Entropy: 3.77119
Value Function Loss: 0.00925

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03946
Policy Update Magnitude: 0.49259
Value Function Update Magnitude: 0.37687

Collected Steps per Second: 20,521.94814
Overall Steps per Second: 10,269.92034

Timestep Collection Time: 2.43768
Timestep Consumption Time: 2.43344
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.87112

Cumulative Model Updates: 169,380
Cumulative Timesteps: 1,412,429,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,653.96473
Policy Entropy: 3.76905
Value Function Loss: 0.01070

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04007
Policy Update Magnitude: 0.48980
Value Function Update Magnitude: 0.42192

Collected Steps per Second: 20,454.12693
Overall Steps per Second: 10,049.42010

Timestep Collection Time: 2.44528
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.97700

Cumulative Model Updates: 169,386
Cumulative Timesteps: 1,412,480,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1412480014...
Checkpoint 1412480014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,378.62259
Policy Entropy: 3.77988
Value Function Loss: 0.01027

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04483
Policy Update Magnitude: 0.49860
Value Function Update Magnitude: 0.48705

Collected Steps per Second: 20,751.25725
Overall Steps per Second: 10,166.96996

Timestep Collection Time: 2.41026
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.91946

Cumulative Model Updates: 169,392
Cumulative Timesteps: 1,412,530,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,563.31669
Policy Entropy: 3.78605
Value Function Loss: 0.01405

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07226
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.60804

Collected Steps per Second: 20,657.89969
Overall Steps per Second: 10,039.38192

Timestep Collection Time: 2.42048
Timestep Consumption Time: 2.56011
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.98059

Cumulative Model Updates: 169,398
Cumulative Timesteps: 1,412,580,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1412580032...
Checkpoint 1412580032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,532.05940
Policy Entropy: 3.80722
Value Function Loss: 0.01690

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07875
Policy Update Magnitude: 0.60879
Value Function Update Magnitude: 0.73591

Collected Steps per Second: 20,603.64987
Overall Steps per Second: 10,177.27627

Timestep Collection Time: 2.42773
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.91487

Cumulative Model Updates: 169,404
Cumulative Timesteps: 1,412,630,052

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,274.27903
Policy Entropy: 3.79824
Value Function Loss: 0.01902

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.81106

Collected Steps per Second: 20,687.26592
Overall Steps per Second: 10,004.76214

Timestep Collection Time: 2.41772
Timestep Consumption Time: 2.58150
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.99922

Cumulative Model Updates: 169,410
Cumulative Timesteps: 1,412,680,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1412680068...
Checkpoint 1412680068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,687.23097
Policy Entropy: 3.79953
Value Function Loss: 0.02088

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.18923
Policy Update Magnitude: 0.51199
Value Function Update Magnitude: 0.73496

Collected Steps per Second: 20,697.36227
Overall Steps per Second: 10,059.62866

Timestep Collection Time: 2.41712
Timestep Consumption Time: 2.55603
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.97315

Cumulative Model Updates: 169,416
Cumulative Timesteps: 1,412,730,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,446.24070
Policy Entropy: 3.76177
Value Function Loss: 0.01972

Mean KL Divergence: 0.02837
SB3 Clip Fraction: 0.29025
Policy Update Magnitude: 0.44448
Value Function Update Magnitude: 0.62905

Collected Steps per Second: 20,725.53285
Overall Steps per Second: 10,218.12905

Timestep Collection Time: 2.41374
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.89581

Cumulative Model Updates: 169,422
Cumulative Timesteps: 1,412,780,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1412780122...
Checkpoint 1412780122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,040.69196
Policy Entropy: 3.75020
Value Function Loss: 0.02210

Mean KL Divergence: 0.02310
SB3 Clip Fraction: 0.24187
Policy Update Magnitude: 0.48406
Value Function Update Magnitude: 0.57922

Collected Steps per Second: 20,646.02095
Overall Steps per Second: 10,200.11286

Timestep Collection Time: 2.42197
Timestep Consumption Time: 2.48033
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.90230

Cumulative Model Updates: 169,428
Cumulative Timesteps: 1,412,830,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,828.13880
Policy Entropy: 3.75431
Value Function Loss: 0.02348

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.19263
Policy Update Magnitude: 0.56349
Value Function Update Magnitude: 0.52755

Collected Steps per Second: 20,635.51002
Overall Steps per Second: 10,024.46705

Timestep Collection Time: 2.42436
Timestep Consumption Time: 2.56622
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.99059

Cumulative Model Updates: 169,434
Cumulative Timesteps: 1,412,880,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1412880154...
Checkpoint 1412880154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544,290.74017
Policy Entropy: 3.77630
Value Function Loss: 0.03275

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.64984
Value Function Update Magnitude: 0.61077

Collected Steps per Second: 20,557.42862
Overall Steps per Second: 10,032.87251

Timestep Collection Time: 2.43309
Timestep Consumption Time: 2.55233
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.98541

Cumulative Model Updates: 169,440
Cumulative Timesteps: 1,412,930,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,180.74748
Policy Entropy: 3.82520
Value Function Loss: 0.03868

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.74955
Value Function Update Magnitude: 0.75903

Collected Steps per Second: 20,834.02688
Overall Steps per Second: 10,297.93370

Timestep Collection Time: 2.40011
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.85573

Cumulative Model Updates: 169,446
Cumulative Timesteps: 1,412,980,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1412980176...
Checkpoint 1412980176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.29116
Policy Entropy: 3.83922
Value Function Loss: 0.04060

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.73933
Value Function Update Magnitude: 0.82240

Collected Steps per Second: 20,569.77157
Overall Steps per Second: 10,173.34274

Timestep Collection Time: 2.43221
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.91775

Cumulative Model Updates: 169,452
Cumulative Timesteps: 1,413,030,206

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336,202.12539
Policy Entropy: 3.84909
Value Function Loss: 0.03725

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.75188
Value Function Update Magnitude: 0.77445

Collected Steps per Second: 20,876.54706
Overall Steps per Second: 10,183.32281

Timestep Collection Time: 2.39628
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.91254

Cumulative Model Updates: 169,458
Cumulative Timesteps: 1,413,080,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1413080232...
Checkpoint 1413080232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,966.22211
Policy Entropy: 3.81193
Value Function Loss: 0.03463

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.76648
Value Function Update Magnitude: 0.68982

Collected Steps per Second: 20,406.48081
Overall Steps per Second: 10,168.67570

Timestep Collection Time: 2.45148
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.91962

Cumulative Model Updates: 169,464
Cumulative Timesteps: 1,413,130,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,280.63614
Policy Entropy: 3.81115
Value Function Loss: 0.03100

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.68879
Value Function Update Magnitude: 0.65069

Collected Steps per Second: 20,658.34537
Overall Steps per Second: 9,967.19355

Timestep Collection Time: 2.42130
Timestep Consumption Time: 2.59717
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 5.01846

Cumulative Model Updates: 169,470
Cumulative Timesteps: 1,413,180,278

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1413180278...
Checkpoint 1413180278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,665.45523
Policy Entropy: 3.81382
Value Function Loss: 0.02764

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11754
Policy Update Magnitude: 0.60482
Value Function Update Magnitude: 0.66795

Collected Steps per Second: 20,584.53089
Overall Steps per Second: 10,214.91133

Timestep Collection Time: 2.43017
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.89715

Cumulative Model Updates: 169,476
Cumulative Timesteps: 1,413,230,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,610.79234
Policy Entropy: 3.80883
Value Function Loss: 0.02487

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11760
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.75728

Collected Steps per Second: 20,941.24052
Overall Steps per Second: 10,077.37681

Timestep Collection Time: 2.38859
Timestep Consumption Time: 2.57501
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.96359

Cumulative Model Updates: 169,482
Cumulative Timesteps: 1,413,280,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1413280322...
Checkpoint 1413280322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.71212
Policy Entropy: 3.79015
Value Function Loss: 0.02248

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.53339
Value Function Update Magnitude: 0.77394

Collected Steps per Second: 21,184.88001
Overall Steps per Second: 10,240.34989

Timestep Collection Time: 2.36074
Timestep Consumption Time: 2.52308
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.88382

Cumulative Model Updates: 169,488
Cumulative Timesteps: 1,413,330,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,483.54953
Policy Entropy: 3.76078
Value Function Loss: 0.02231

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.48584
Value Function Update Magnitude: 0.78046

Collected Steps per Second: 20,917.17116
Overall Steps per Second: 10,140.78238

Timestep Collection Time: 2.39105
Timestep Consumption Time: 2.54092
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.93197

Cumulative Model Updates: 169,494
Cumulative Timesteps: 1,413,380,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1413380348...
Checkpoint 1413380348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,541.37234
Policy Entropy: 3.74164
Value Function Loss: 0.02190

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.48091
Value Function Update Magnitude: 0.81914

Collected Steps per Second: 21,122.07776
Overall Steps per Second: 10,183.38293

Timestep Collection Time: 2.36842
Timestep Consumption Time: 2.54409
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.91251

Cumulative Model Updates: 169,500
Cumulative Timesteps: 1,413,430,374

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,753.13065
Policy Entropy: 3.73920
Value Function Loss: 0.02344

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.46231
Value Function Update Magnitude: 0.70820

Collected Steps per Second: 21,086.15047
Overall Steps per Second: 10,336.01491

Timestep Collection Time: 2.37227
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.83958

Cumulative Model Updates: 169,506
Cumulative Timesteps: 1,413,480,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1413480396...
Checkpoint 1413480396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,634.99115
Policy Entropy: 3.75677
Value Function Loss: 0.02131

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.46561
Value Function Update Magnitude: 0.63730

Collected Steps per Second: 20,711.53860
Overall Steps per Second: 10,243.28865

Timestep Collection Time: 2.41537
Timestep Consumption Time: 2.46841
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.88378

Cumulative Model Updates: 169,512
Cumulative Timesteps: 1,413,530,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,253.89100
Policy Entropy: 3.75686
Value Function Loss: 0.01931

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.65853

Collected Steps per Second: 20,584.99933
Overall Steps per Second: 10,043.66524

Timestep Collection Time: 2.42895
Timestep Consumption Time: 2.54931
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.97826

Cumulative Model Updates: 169,518
Cumulative Timesteps: 1,413,580,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1413580422...
Checkpoint 1413580422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,843.32595
Policy Entropy: 3.77995
Value Function Loss: 0.01843

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.47199
Value Function Update Magnitude: 0.67060

Collected Steps per Second: 21,117.84823
Overall Steps per Second: 10,216.38637

Timestep Collection Time: 2.36814
Timestep Consumption Time: 2.52694
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.89508

Cumulative Model Updates: 169,524
Cumulative Timesteps: 1,413,630,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,640.71127
Policy Entropy: 3.76955
Value Function Loss: 0.01997

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.46356
Value Function Update Magnitude: 0.69213

Collected Steps per Second: 21,003.27712
Overall Steps per Second: 10,175.71927

Timestep Collection Time: 2.38106
Timestep Consumption Time: 2.53358
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.91464

Cumulative Model Updates: 169,530
Cumulative Timesteps: 1,413,680,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1413680442...
Checkpoint 1413680442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,110.13818
Policy Entropy: 3.78346
Value Function Loss: 0.01942

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.47870
Value Function Update Magnitude: 0.73210

Collected Steps per Second: 20,533.96269
Overall Steps per Second: 10,230.72967

Timestep Collection Time: 2.43538
Timestep Consumption Time: 2.45264
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.88802

Cumulative Model Updates: 169,536
Cumulative Timesteps: 1,413,730,450

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,601.76657
Policy Entropy: 3.78419
Value Function Loss: 0.01836

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.46029
Value Function Update Magnitude: 0.74202

Collected Steps per Second: 20,026.71243
Overall Steps per Second: 10,229.63715

Timestep Collection Time: 2.49667
Timestep Consumption Time: 2.39109
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.88776

Cumulative Model Updates: 169,542
Cumulative Timesteps: 1,413,780,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1413780450...
Checkpoint 1413780450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,155.32078
Policy Entropy: 3.79763
Value Function Loss: 0.01606

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.45044
Value Function Update Magnitude: 0.71863

Collected Steps per Second: 20,449.93703
Overall Steps per Second: 10,328.80852

Timestep Collection Time: 2.44705
Timestep Consumption Time: 2.39785
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.84490

Cumulative Model Updates: 169,548
Cumulative Timesteps: 1,413,830,492

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,498.93080
Policy Entropy: 3.75412
Value Function Loss: 0.01861

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.46261
Value Function Update Magnitude: 0.78102

Collected Steps per Second: 20,487.64360
Overall Steps per Second: 10,051.77347

Timestep Collection Time: 2.44147
Timestep Consumption Time: 2.53476
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.97624

Cumulative Model Updates: 169,554
Cumulative Timesteps: 1,413,880,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1413880512...
Checkpoint 1413880512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,267.46101
Policy Entropy: 3.75251
Value Function Loss: 0.01813

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.47584
Value Function Update Magnitude: 0.78232

Collected Steps per Second: 21,250.94686
Overall Steps per Second: 10,298.18881

Timestep Collection Time: 2.35397
Timestep Consumption Time: 2.50359
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.85755

Cumulative Model Updates: 169,560
Cumulative Timesteps: 1,413,930,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,878.84424
Policy Entropy: 3.74104
Value Function Loss: 0.02365

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.46882
Value Function Update Magnitude: 0.68504

Collected Steps per Second: 21,117.24309
Overall Steps per Second: 10,305.06690

Timestep Collection Time: 2.36859
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.85373

Cumulative Model Updates: 169,566
Cumulative Timesteps: 1,413,980,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1413980554...
Checkpoint 1413980554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,299.52799
Policy Entropy: 3.76852
Value Function Loss: 0.02011

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.47551
Value Function Update Magnitude: 0.58811

Collected Steps per Second: 20,936.19548
Overall Steps per Second: 10,254.53730

Timestep Collection Time: 2.38821
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.87589

Cumulative Model Updates: 169,572
Cumulative Timesteps: 1,414,030,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,977.32663
Policy Entropy: 3.75454
Value Function Loss: 0.02174

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.43000
Value Function Update Magnitude: 0.51730

Collected Steps per Second: 20,866.88857
Overall Steps per Second: 10,094.41336

Timestep Collection Time: 2.39729
Timestep Consumption Time: 2.55832
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.95561

Cumulative Model Updates: 169,578
Cumulative Timesteps: 1,414,080,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1414080578...
Checkpoint 1414080578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,412.23835
Policy Entropy: 3.76691
Value Function Loss: 0.01674

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.39381
Value Function Update Magnitude: 0.45174

Collected Steps per Second: 21,058.54375
Overall Steps per Second: 10,194.43692

Timestep Collection Time: 2.37547
Timestep Consumption Time: 2.53152
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.90699

Cumulative Model Updates: 169,584
Cumulative Timesteps: 1,414,130,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,676.07898
Policy Entropy: 3.74835
Value Function Loss: 0.02059

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.38740
Value Function Update Magnitude: 0.39750

Collected Steps per Second: 20,799.69482
Overall Steps per Second: 10,085.34875

Timestep Collection Time: 2.40436
Timestep Consumption Time: 2.55432
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.95868

Cumulative Model Updates: 169,590
Cumulative Timesteps: 1,414,180,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1414180612...
Checkpoint 1414180612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,700.82370
Policy Entropy: 3.78374
Value Function Loss: 0.01811

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.42287
Value Function Update Magnitude: 0.40902

Collected Steps per Second: 21,333.08137
Overall Steps per Second: 10,245.65426

Timestep Collection Time: 2.34528
Timestep Consumption Time: 2.53796
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.88324

Cumulative Model Updates: 169,596
Cumulative Timesteps: 1,414,230,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,729.07033
Policy Entropy: 3.78030
Value Function Loss: 0.02041

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.42272
Value Function Update Magnitude: 0.43912

Collected Steps per Second: 20,919.72757
Overall Steps per Second: 10,134.31268

Timestep Collection Time: 2.39047
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.93452

Cumulative Model Updates: 169,602
Cumulative Timesteps: 1,414,280,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1414280652...
Checkpoint 1414280652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,827.66357
Policy Entropy: 3.80934
Value Function Loss: 0.02007

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.47444
Value Function Update Magnitude: 0.52347

Collected Steps per Second: 21,016.20600
Overall Steps per Second: 10,120.30918

Timestep Collection Time: 2.37988
Timestep Consumption Time: 2.56226
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.94214

Cumulative Model Updates: 169,608
Cumulative Timesteps: 1,414,330,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,472.59258
Policy Entropy: 3.80833
Value Function Loss: 0.02138

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.51672
Value Function Update Magnitude: 0.59891

Collected Steps per Second: 20,806.44981
Overall Steps per Second: 10,129.40990

Timestep Collection Time: 2.40397
Timestep Consumption Time: 2.53393
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.93790

Cumulative Model Updates: 169,614
Cumulative Timesteps: 1,414,380,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1414380686...
Checkpoint 1414380686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,140.11984
Policy Entropy: 3.79635
Value Function Loss: 0.02009

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.51164
Value Function Update Magnitude: 0.63727

Collected Steps per Second: 20,990.17168
Overall Steps per Second: 10,215.32703

Timestep Collection Time: 2.38331
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.89715

Cumulative Model Updates: 169,620
Cumulative Timesteps: 1,414,430,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,946.17022
Policy Entropy: 3.78082
Value Function Loss: 0.01956

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.46039
Value Function Update Magnitude: 0.61534

Collected Steps per Second: 20,959.50967
Overall Steps per Second: 10,350.67019

Timestep Collection Time: 2.38603
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.83157

Cumulative Model Updates: 169,626
Cumulative Timesteps: 1,414,480,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1414480722...
Checkpoint 1414480722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,668.68450
Policy Entropy: 3.77121
Value Function Loss: 0.01769

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.41892
Value Function Update Magnitude: 0.60258

Collected Steps per Second: 20,413.91616
Overall Steps per Second: 10,177.05836

Timestep Collection Time: 2.45058
Timestep Consumption Time: 2.46498
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.91557

Cumulative Model Updates: 169,632
Cumulative Timesteps: 1,414,530,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,015.55302
Policy Entropy: 3.77183
Value Function Loss: 0.01828

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.39868
Value Function Update Magnitude: 0.56599

Collected Steps per Second: 18,820.19155
Overall Steps per Second: 9,652.55363

Timestep Collection Time: 2.65672
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 5.17998

Cumulative Model Updates: 169,638
Cumulative Timesteps: 1,414,580,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1414580748...
Checkpoint 1414580748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,157.96927
Policy Entropy: 3.76683
Value Function Loss: 0.01737

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.42925
Value Function Update Magnitude: 0.52975

Collected Steps per Second: 20,428.48538
Overall Steps per Second: 10,194.42181

Timestep Collection Time: 2.44923
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.90798

Cumulative Model Updates: 169,644
Cumulative Timesteps: 1,414,630,782

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,842.63400
Policy Entropy: 3.74773
Value Function Loss: 0.01800

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13803
Policy Update Magnitude: 0.47180
Value Function Update Magnitude: 0.57450

Collected Steps per Second: 20,363.62287
Overall Steps per Second: 10,073.26715

Timestep Collection Time: 2.45693
Timestep Consumption Time: 2.50988
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.96681

Cumulative Model Updates: 169,650
Cumulative Timesteps: 1,414,680,814

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1414680814...
Checkpoint 1414680814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,002.62521
Policy Entropy: 3.75273
Value Function Loss: 0.01831

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.49601
Value Function Update Magnitude: 0.65185

Collected Steps per Second: 20,690.52936
Overall Steps per Second: 10,227.55022

Timestep Collection Time: 2.41801
Timestep Consumption Time: 2.47368
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.89169

Cumulative Model Updates: 169,656
Cumulative Timesteps: 1,414,730,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,799.59159
Policy Entropy: 3.76959
Value Function Loss: 0.01831

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.53151
Value Function Update Magnitude: 0.69317

Collected Steps per Second: 20,917.82735
Overall Steps per Second: 10,373.83532

Timestep Collection Time: 2.39260
Timestep Consumption Time: 2.43184
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.82445

Cumulative Model Updates: 169,662
Cumulative Timesteps: 1,414,780,892

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1414780892...
Checkpoint 1414780892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,983.62087
Policy Entropy: 3.79040
Value Function Loss: 0.01690

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.49456
Value Function Update Magnitude: 0.71760

Collected Steps per Second: 21,083.51394
Overall Steps per Second: 10,359.97464

Timestep Collection Time: 2.37294
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.82916

Cumulative Model Updates: 169,668
Cumulative Timesteps: 1,414,830,922

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,279.34876
Policy Entropy: 3.78400
Value Function Loss: 0.01650

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.45616
Value Function Update Magnitude: 0.61147

Collected Steps per Second: 21,008.35218
Overall Steps per Second: 10,321.75105

Timestep Collection Time: 2.38086
Timestep Consumption Time: 2.46502
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.84588

Cumulative Model Updates: 169,674
Cumulative Timesteps: 1,414,880,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1414880940...
Checkpoint 1414880940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,875.41650
Policy Entropy: 3.76287
Value Function Loss: 0.01674

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.46516
Value Function Update Magnitude: 0.54354

Collected Steps per Second: 20,913.49266
Overall Steps per Second: 10,273.04104

Timestep Collection Time: 2.39128
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.86808

Cumulative Model Updates: 169,680
Cumulative Timesteps: 1,414,930,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,972.62153
Policy Entropy: 3.76127
Value Function Loss: 0.02241

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.55642

Collected Steps per Second: 20,800.37822
Overall Steps per Second: 10,108.32132

Timestep Collection Time: 2.40409
Timestep Consumption Time: 2.54292
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.94701

Cumulative Model Updates: 169,686
Cumulative Timesteps: 1,414,980,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1414980956...
Checkpoint 1414980956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,954.24417
Policy Entropy: 3.77948
Value Function Loss: 0.02248

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 20,931.95107
Overall Steps per Second: 10,089.85621

Timestep Collection Time: 2.38917
Timestep Consumption Time: 2.56729
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.95646

Cumulative Model Updates: 169,692
Cumulative Timesteps: 1,415,030,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,657.70712
Policy Entropy: 3.79671
Value Function Loss: 0.02641

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.56693
Value Function Update Magnitude: 0.66078

Collected Steps per Second: 20,628.93206
Overall Steps per Second: 10,113.23470

Timestep Collection Time: 2.42446
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.94540

Cumulative Model Updates: 169,698
Cumulative Timesteps: 1,415,080,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1415080980...
Checkpoint 1415080980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,990.40215
Policy Entropy: 3.80619
Value Function Loss: 0.02391

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.55297
Value Function Update Magnitude: 0.72346

Collected Steps per Second: 20,863.62199
Overall Steps per Second: 10,226.09448

Timestep Collection Time: 2.39776
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.89199

Cumulative Model Updates: 169,704
Cumulative Timesteps: 1,415,131,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,176.67929
Policy Entropy: 3.79352
Value Function Loss: 0.03121

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.57019

Collected Steps per Second: 20,142.12286
Overall Steps per Second: 9,943.58189

Timestep Collection Time: 2.48405
Timestep Consumption Time: 2.54774
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 5.03179

Cumulative Model Updates: 169,710
Cumulative Timesteps: 1,415,181,040

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1415181040...
Checkpoint 1415181040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,643.25876
Policy Entropy: 3.78061
Value Function Loss: 0.02704

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.49907

Collected Steps per Second: 20,359.00548
Overall Steps per Second: 10,321.83662

Timestep Collection Time: 2.45768
Timestep Consumption Time: 2.38990
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.84759

Cumulative Model Updates: 169,716
Cumulative Timesteps: 1,415,231,076

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,448.75269
Policy Entropy: 3.76331
Value Function Loss: 0.02783

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.55989
Value Function Update Magnitude: 0.49629

Collected Steps per Second: 20,087.03337
Overall Steps per Second: 10,115.19238

Timestep Collection Time: 2.48996
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.94464

Cumulative Model Updates: 169,722
Cumulative Timesteps: 1,415,281,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1415281092...
Checkpoint 1415281092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,077.05999
Policy Entropy: 3.76051
Value Function Loss: 0.02368

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.57415

Collected Steps per Second: 20,251.06181
Overall Steps per Second: 10,126.44713

Timestep Collection Time: 2.46911
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.93776

Cumulative Model Updates: 169,728
Cumulative Timesteps: 1,415,331,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,259.92251
Policy Entropy: 3.74102
Value Function Loss: 0.02792

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 20,258.91961
Overall Steps per Second: 10,036.22896

Timestep Collection Time: 2.46854
Timestep Consumption Time: 2.51440
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.98295

Cumulative Model Updates: 169,734
Cumulative Timesteps: 1,415,381,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1415381104...
Checkpoint 1415381104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,526.46726
Policy Entropy: 3.74314
Value Function Loss: 0.02711

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.66379

Collected Steps per Second: 20,761.63063
Overall Steps per Second: 10,297.60944

Timestep Collection Time: 2.40896
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.85686

Cumulative Model Updates: 169,740
Cumulative Timesteps: 1,415,431,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,161.84486
Policy Entropy: 3.75254
Value Function Loss: 0.02682

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 21,013.09599
Overall Steps per Second: 10,383.97014

Timestep Collection Time: 2.37947
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.81511

Cumulative Model Updates: 169,746
Cumulative Timesteps: 1,415,481,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1415481118...
Checkpoint 1415481118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,541.39132
Policy Entropy: 3.78755
Value Function Loss: 0.02453

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.52237
Value Function Update Magnitude: 0.61928

Collected Steps per Second: 21,093.68860
Overall Steps per Second: 10,222.84698

Timestep Collection Time: 2.37057
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.89140

Cumulative Model Updates: 169,752
Cumulative Timesteps: 1,415,531,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,086.12613
Policy Entropy: 3.79748
Value Function Loss: 0.02297

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.49629
Value Function Update Magnitude: 0.65688

Collected Steps per Second: 20,920.96597
Overall Steps per Second: 10,052.22691

Timestep Collection Time: 2.39023
Timestep Consumption Time: 2.58439
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.97462

Cumulative Model Updates: 169,758
Cumulative Timesteps: 1,415,581,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1415581128...
Checkpoint 1415581128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,505.37247
Policy Entropy: 3.79174
Value Function Loss: 0.02097

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.47795
Value Function Update Magnitude: 0.65867

Collected Steps per Second: 21,099.25160
Overall Steps per Second: 10,211.94629

Timestep Collection Time: 2.36975
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.89623

Cumulative Model Updates: 169,764
Cumulative Timesteps: 1,415,631,128

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,455.94892
Policy Entropy: 3.76505
Value Function Loss: 0.01945

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.45888
Value Function Update Magnitude: 0.60747

Collected Steps per Second: 20,999.45499
Overall Steps per Second: 10,149.49091

Timestep Collection Time: 2.38178
Timestep Consumption Time: 2.54616
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.92793

Cumulative Model Updates: 169,770
Cumulative Timesteps: 1,415,681,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1415681144...
Checkpoint 1415681144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,595.33314
Policy Entropy: 3.75830
Value Function Loss: 0.01842

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.42173
Value Function Update Magnitude: 0.52335

Collected Steps per Second: 20,906.08060
Overall Steps per Second: 10,092.90117

Timestep Collection Time: 2.39299
Timestep Consumption Time: 2.56376
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.95675

Cumulative Model Updates: 169,776
Cumulative Timesteps: 1,415,731,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,410.26138
Policy Entropy: 3.76709
Value Function Loss: 0.01774

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.39822
Value Function Update Magnitude: 0.48224

Collected Steps per Second: 20,615.04745
Overall Steps per Second: 10,018.70416

Timestep Collection Time: 2.42658
Timestep Consumption Time: 2.56648
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.99306

Cumulative Model Updates: 169,782
Cumulative Timesteps: 1,415,781,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1415781196...
Checkpoint 1415781196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,962.83433
Policy Entropy: 3.77309
Value Function Loss: 0.01737

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.40194
Value Function Update Magnitude: 0.39188

Collected Steps per Second: 20,712.78325
Overall Steps per Second: 10,247.73380

Timestep Collection Time: 2.41513
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.88147

Cumulative Model Updates: 169,788
Cumulative Timesteps: 1,415,831,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,111.84654
Policy Entropy: 3.79143
Value Function Loss: 0.01777

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.41884
Value Function Update Magnitude: 0.37440

Collected Steps per Second: 19,969.19449
Overall Steps per Second: 10,081.92364

Timestep Collection Time: 2.50436
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.96036

Cumulative Model Updates: 169,794
Cumulative Timesteps: 1,415,881,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1415881230...
Checkpoint 1415881230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,332.43544
Policy Entropy: 3.78768
Value Function Loss: 0.01816

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.42820
Value Function Update Magnitude: 0.42883

Collected Steps per Second: 20,282.77941
Overall Steps per Second: 10,188.53932

Timestep Collection Time: 2.46544
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.90806

Cumulative Model Updates: 169,800
Cumulative Timesteps: 1,415,931,236

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,205.55899
Policy Entropy: 3.78093
Value Function Loss: 0.01837

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.44671
Value Function Update Magnitude: 0.46444

Collected Steps per Second: 20,322.07188
Overall Steps per Second: 10,188.57357

Timestep Collection Time: 2.46067
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.90805

Cumulative Model Updates: 169,806
Cumulative Timesteps: 1,415,981,242

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1415981242...
Checkpoint 1415981242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,064.05151
Policy Entropy: 3.76596
Value Function Loss: 0.01877

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.44995
Value Function Update Magnitude: 0.49103

Collected Steps per Second: 20,230.91615
Overall Steps per Second: 10,031.15391

Timestep Collection Time: 2.47156
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.98467

Cumulative Model Updates: 169,812
Cumulative Timesteps: 1,416,031,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,044.42536
Policy Entropy: 3.75986
Value Function Loss: 0.02013

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.45956
Value Function Update Magnitude: 0.52360

Collected Steps per Second: 20,422.82899
Overall Steps per Second: 10,089.08421

Timestep Collection Time: 2.44942
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.95823

Cumulative Model Updates: 169,818
Cumulative Timesteps: 1,416,081,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1416081268...
Checkpoint 1416081268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,483.39644
Policy Entropy: 3.76179
Value Function Loss: 0.01896

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.48882
Value Function Update Magnitude: 0.52783

Collected Steps per Second: 20,951.83227
Overall Steps per Second: 10,248.36152

Timestep Collection Time: 2.38738
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.88078

Cumulative Model Updates: 169,824
Cumulative Timesteps: 1,416,131,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,487.05985
Policy Entropy: 3.76137
Value Function Loss: 0.01902

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.49228
Value Function Update Magnitude: 0.54769

Collected Steps per Second: 20,842.73147
Overall Steps per Second: 10,106.27198

Timestep Collection Time: 2.40074
Timestep Consumption Time: 2.55044
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.95118

Cumulative Model Updates: 169,830
Cumulative Timesteps: 1,416,181,326

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1416181326...
Checkpoint 1416181326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,487.05985
Policy Entropy: 3.77048
Value Function Loss: 0.01521

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.46605
Value Function Update Magnitude: 0.56789

Collected Steps per Second: 20,800.62656
Overall Steps per Second: 10,101.88685

Timestep Collection Time: 2.40425
Timestep Consumption Time: 2.54631
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.95056

Cumulative Model Updates: 169,836
Cumulative Timesteps: 1,416,231,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,924.28911
Policy Entropy: 3.76547
Value Function Loss: 0.01935

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.45895
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 20,500.83996
Overall Steps per Second: 10,015.90424

Timestep Collection Time: 2.43951
Timestep Consumption Time: 2.55375
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.99326

Cumulative Model Updates: 169,842
Cumulative Timesteps: 1,416,281,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1416281348...
Checkpoint 1416281348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,023.34959
Policy Entropy: 3.76610
Value Function Loss: 0.01860

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.67835

Collected Steps per Second: 20,757.27278
Overall Steps per Second: 10,233.80584

Timestep Collection Time: 2.40976
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.88772

Cumulative Model Updates: 169,848
Cumulative Timesteps: 1,416,331,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,386.57117
Policy Entropy: 3.76104
Value Function Loss: 0.02406

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.49898
Value Function Update Magnitude: 0.62554

Collected Steps per Second: 20,696.59184
Overall Steps per Second: 10,068.04173

Timestep Collection Time: 2.41615
Timestep Consumption Time: 2.55066
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.96681

Cumulative Model Updates: 169,854
Cumulative Timesteps: 1,416,381,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1416381374...
Checkpoint 1416381374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,016.06824
Policy Entropy: 3.78414
Value Function Loss: 0.02272

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.56282
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 20,766.59047
Overall Steps per Second: 10,259.67818

Timestep Collection Time: 2.40897
Timestep Consumption Time: 2.46702
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.87598

Cumulative Model Updates: 169,860
Cumulative Timesteps: 1,416,431,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,594.33941
Policy Entropy: 3.78276
Value Function Loss: 0.02632

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.59246
Value Function Update Magnitude: 0.60227

Collected Steps per Second: 20,708.73529
Overall Steps per Second: 10,125.36450

Timestep Collection Time: 2.41512
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.93948

Cumulative Model Updates: 169,866
Cumulative Timesteps: 1,416,481,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1416481414...
Checkpoint 1416481414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,181.76138
Policy Entropy: 3.78877
Value Function Loss: 0.02209

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.60030
Value Function Update Magnitude: 0.55283

Collected Steps per Second: 21,084.28911
Overall Steps per Second: 10,198.73445

Timestep Collection Time: 2.37276
Timestep Consumption Time: 2.53255
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.90531

Cumulative Model Updates: 169,872
Cumulative Timesteps: 1,416,531,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,209.88681
Policy Entropy: 3.77259
Value Function Loss: 0.02719

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.55075

Collected Steps per Second: 20,397.43054
Overall Steps per Second: 10,312.05206

Timestep Collection Time: 2.45178
Timestep Consumption Time: 2.39789
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.84967

Cumulative Model Updates: 169,878
Cumulative Timesteps: 1,416,581,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1416581452...
Checkpoint 1416581452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,328.10228
Policy Entropy: 3.78667
Value Function Loss: 0.02774

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.55737

Collected Steps per Second: 20,410.77241
Overall Steps per Second: 10,222.44058

Timestep Collection Time: 2.45057
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.89296

Cumulative Model Updates: 169,884
Cumulative Timesteps: 1,416,631,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,866.54852
Policy Entropy: 3.77630
Value Function Loss: 0.02834

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.58839

Collected Steps per Second: 20,285.79404
Overall Steps per Second: 10,160.91727

Timestep Collection Time: 2.46636
Timestep Consumption Time: 2.45761
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.92396

Cumulative Model Updates: 169,890
Cumulative Timesteps: 1,416,681,502

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1416681502...
Checkpoint 1416681502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,883.77689
Policy Entropy: 3.78811
Value Function Loss: 0.02274

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.51142
Value Function Update Magnitude: 0.49962

Collected Steps per Second: 20,404.51935
Overall Steps per Second: 10,198.36376

Timestep Collection Time: 2.45083
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.90353

Cumulative Model Updates: 169,896
Cumulative Timesteps: 1,416,731,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.26247
Policy Entropy: 3.80761
Value Function Loss: 0.01933

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.44304
Value Function Update Magnitude: 0.44661

Collected Steps per Second: 20,600.10159
Overall Steps per Second: 10,071.29381

Timestep Collection Time: 2.42863
Timestep Consumption Time: 2.53896
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.96758

Cumulative Model Updates: 169,902
Cumulative Timesteps: 1,416,781,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1416781540...
Checkpoint 1416781540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,230.65678
Policy Entropy: 3.81956
Value Function Loss: 0.01860

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.11066
Policy Update Magnitude: 0.42987
Value Function Update Magnitude: 0.53820

Collected Steps per Second: 20,894.11194
Overall Steps per Second: 10,185.81943

Timestep Collection Time: 2.39407
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.91095

Cumulative Model Updates: 169,908
Cumulative Timesteps: 1,416,831,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,681.16388
Policy Entropy: 3.82275
Value Function Loss: 0.01640

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11934
Policy Update Magnitude: 0.45977
Value Function Update Magnitude: 0.63254

Collected Steps per Second: 21,118.32306
Overall Steps per Second: 10,350.94675

Timestep Collection Time: 2.36903
Timestep Consumption Time: 2.46434
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.83337

Cumulative Model Updates: 169,914
Cumulative Timesteps: 1,416,881,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1416881592...
Checkpoint 1416881592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,902.10512
Policy Entropy: 3.78628
Value Function Loss: 0.01727

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.46504
Value Function Update Magnitude: 0.65898

Collected Steps per Second: 20,819.73068
Overall Steps per Second: 10,304.19994

Timestep Collection Time: 2.40195
Timestep Consumption Time: 2.45121
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.85317

Cumulative Model Updates: 169,920
Cumulative Timesteps: 1,416,931,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,704.69297
Policy Entropy: 3.79135
Value Function Loss: 0.01638

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.46664
Value Function Update Magnitude: 0.66045

Collected Steps per Second: 20,724.93006
Overall Steps per Second: 10,035.38727

Timestep Collection Time: 2.41361
Timestep Consumption Time: 2.57095
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.98456

Cumulative Model Updates: 169,926
Cumulative Timesteps: 1,416,981,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1416981622...
Checkpoint 1416981622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,973.38870
Policy Entropy: 3.78863
Value Function Loss: 0.01744

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.45621
Value Function Update Magnitude: 0.60162

Collected Steps per Second: 21,017.76903
Overall Steps per Second: 10,241.74067

Timestep Collection Time: 2.37951
Timestep Consumption Time: 2.50364
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.88315

Cumulative Model Updates: 169,932
Cumulative Timesteps: 1,417,031,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,104.44601
Policy Entropy: 3.78615
Value Function Loss: 0.01733

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.43649
Value Function Update Magnitude: 0.50827

Collected Steps per Second: 20,823.29286
Overall Steps per Second: 10,053.17688

Timestep Collection Time: 2.40298
Timestep Consumption Time: 2.57435
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.97733

Cumulative Model Updates: 169,938
Cumulative Timesteps: 1,417,081,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1417081672...
Checkpoint 1417081672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,990.49656
Policy Entropy: 3.78079
Value Function Loss: 0.01699

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.44657
Value Function Update Magnitude: 0.46844

Collected Steps per Second: 20,766.59737
Overall Steps per Second: 10,198.86003

Timestep Collection Time: 2.40896
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.90506

Cumulative Model Updates: 169,944
Cumulative Timesteps: 1,417,131,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,950.45581
Policy Entropy: 3.77155
Value Function Loss: 0.01838

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.46981
Value Function Update Magnitude: 0.54559

Collected Steps per Second: 20,321.99634
Overall Steps per Second: 10,037.53315

Timestep Collection Time: 2.46039
Timestep Consumption Time: 2.52092
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.98130

Cumulative Model Updates: 169,950
Cumulative Timesteps: 1,417,181,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1417181698...
Checkpoint 1417181698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,880.89166
Policy Entropy: 3.79313
Value Function Loss: 0.01976

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.49160
Value Function Update Magnitude: 0.55461

Collected Steps per Second: 20,612.36771
Overall Steps per Second: 10,171.54918

Timestep Collection Time: 2.42699
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.91823

Cumulative Model Updates: 169,956
Cumulative Timesteps: 1,417,231,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,491.68725
Policy Entropy: 3.78543
Value Function Loss: 0.02256

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.49869
Value Function Update Magnitude: 0.51721

Collected Steps per Second: 20,763.77846
Overall Steps per Second: 10,097.09925

Timestep Collection Time: 2.40910
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.95410

Cumulative Model Updates: 169,962
Cumulative Timesteps: 1,417,281,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1417281746...
Checkpoint 1417281746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,848.67479
Policy Entropy: 3.77706
Value Function Loss: 0.02212

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.57335

Collected Steps per Second: 20,076.63955
Overall Steps per Second: 10,293.43660

Timestep Collection Time: 2.49195
Timestep Consumption Time: 2.36843
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.86038

Cumulative Model Updates: 169,968
Cumulative Timesteps: 1,417,331,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,288.69954
Policy Entropy: 3.76518
Value Function Loss: 0.02235

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.53307
Value Function Update Magnitude: 0.52247

Collected Steps per Second: 19,871.79383
Overall Steps per Second: 10,068.88810

Timestep Collection Time: 2.51643
Timestep Consumption Time: 2.44996
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.96639

Cumulative Model Updates: 169,974
Cumulative Timesteps: 1,417,381,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1417381782...
Checkpoint 1417381782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,747.23598
Policy Entropy: 3.76648
Value Function Loss: 0.02213

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.50926
Value Function Update Magnitude: 0.51658

Collected Steps per Second: 20,096.51148
Overall Steps per Second: 10,093.23130

Timestep Collection Time: 2.48849
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.95481

Cumulative Model Updates: 169,980
Cumulative Timesteps: 1,417,431,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,806.47129
Policy Entropy: 3.75802
Value Function Loss: 0.02371

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.50393
Value Function Update Magnitude: 0.45265

Collected Steps per Second: 19,997.97462
Overall Steps per Second: 10,107.92197

Timestep Collection Time: 2.50125
Timestep Consumption Time: 2.44734
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.94859

Cumulative Model Updates: 169,986
Cumulative Timesteps: 1,417,481,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1417481812...
Checkpoint 1417481812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,365.79213
Policy Entropy: 3.76718
Value Function Loss: 0.02120

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.48394
Value Function Update Magnitude: 0.40300

Collected Steps per Second: 20,784.04083
Overall Steps per Second: 10,150.06792

Timestep Collection Time: 2.40791
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.93061

Cumulative Model Updates: 169,992
Cumulative Timesteps: 1,417,531,858

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,106.27374
Policy Entropy: 3.76316
Value Function Loss: 0.01926

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.43169
Value Function Update Magnitude: 0.35314

Collected Steps per Second: 20,587.06655
Overall Steps per Second: 10,036.52653

Timestep Collection Time: 2.42871
Timestep Consumption Time: 2.55309
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.98180

Cumulative Model Updates: 169,998
Cumulative Timesteps: 1,417,581,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1417581858...
Checkpoint 1417581858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,358.45404
Policy Entropy: 3.77524
Value Function Loss: 0.01594

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.41038
Value Function Update Magnitude: 0.30364

Collected Steps per Second: 20,565.46346
Overall Steps per Second: 10,146.45394

Timestep Collection Time: 2.43136
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.92803

Cumulative Model Updates: 170,004
Cumulative Timesteps: 1,417,631,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,768.09900
Policy Entropy: 3.75728
Value Function Loss: 0.01899

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.39696
Value Function Update Magnitude: 0.27279

Collected Steps per Second: 20,641.72971
Overall Steps per Second: 10,181.64430

Timestep Collection Time: 2.42363
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.91355

Cumulative Model Updates: 170,010
Cumulative Timesteps: 1,417,681,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1417681888...
Checkpoint 1417681888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,504.70997
Policy Entropy: 3.76537
Value Function Loss: 0.01806

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.41411
Value Function Update Magnitude: 0.32572

Collected Steps per Second: 20,633.73000
Overall Steps per Second: 10,236.90752

Timestep Collection Time: 2.42341
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.88468

Cumulative Model Updates: 170,016
Cumulative Timesteps: 1,417,731,892

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,504.70997
Policy Entropy: 3.75799
Value Function Loss: 0.01917

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.44178
Value Function Update Magnitude: 0.39147

Collected Steps per Second: 20,570.70607
Overall Steps per Second: 10,050.78090

Timestep Collection Time: 2.43093
Timestep Consumption Time: 2.54440
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.97533

Cumulative Model Updates: 170,022
Cumulative Timesteps: 1,417,781,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1417781898...
Checkpoint 1417781898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,928.23790
Policy Entropy: 3.76419
Value Function Loss: 0.01622

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11907
Policy Update Magnitude: 0.46441
Value Function Update Magnitude: 0.47935

Collected Steps per Second: 20,997.26738
Overall Steps per Second: 10,201.76304

Timestep Collection Time: 2.38288
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.90445

Cumulative Model Updates: 170,028
Cumulative Timesteps: 1,417,831,932

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,325.29053
Policy Entropy: 3.76544
Value Function Loss: 0.01661

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.45561
Value Function Update Magnitude: 0.51422

Collected Steps per Second: 20,654.67021
Overall Steps per Second: 10,113.38402

Timestep Collection Time: 2.42163
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.94572

Cumulative Model Updates: 170,034
Cumulative Timesteps: 1,417,881,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1417881950...
Checkpoint 1417881950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,652.77651
Policy Entropy: 3.78129
Value Function Loss: 0.01545

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.43958
Value Function Update Magnitude: 0.46876

Collected Steps per Second: 20,068.53009
Overall Steps per Second: 10,107.77633

Timestep Collection Time: 2.49216
Timestep Consumption Time: 2.45591
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.94807

Cumulative Model Updates: 170,040
Cumulative Timesteps: 1,417,931,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,771.69876
Policy Entropy: 3.77365
Value Function Loss: 0.01561

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.41176
Value Function Update Magnitude: 0.40771

Collected Steps per Second: 20,052.95523
Overall Steps per Second: 10,132.95117

Timestep Collection Time: 2.49430
Timestep Consumption Time: 2.44188
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.93617

Cumulative Model Updates: 170,046
Cumulative Timesteps: 1,417,981,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1417981982...
Checkpoint 1417981982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,037.55551
Policy Entropy: 3.77672
Value Function Loss: 0.01599

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.41651
Value Function Update Magnitude: 0.45784

Collected Steps per Second: 19,965.79790
Overall Steps per Second: 10,081.61032

Timestep Collection Time: 2.50458
Timestep Consumption Time: 2.45554
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.96012

Cumulative Model Updates: 170,052
Cumulative Timesteps: 1,418,031,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.67660
Policy Entropy: 3.77059
Value Function Loss: 0.01723

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.46601
Value Function Update Magnitude: 0.52702

Collected Steps per Second: 20,400.74393
Overall Steps per Second: 10,045.19272

Timestep Collection Time: 2.45168
Timestep Consumption Time: 2.52742
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.97910

Cumulative Model Updates: 170,058
Cumulative Timesteps: 1,418,082,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1418082004...
Checkpoint 1418082004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,852.63080
Policy Entropy: 3.77356
Value Function Loss: 0.01732

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.47419
Value Function Update Magnitude: 0.58778

Collected Steps per Second: 20,603.54882
Overall Steps per Second: 10,247.90985

Timestep Collection Time: 2.42677
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.87904

Cumulative Model Updates: 170,064
Cumulative Timesteps: 1,418,132,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,946.10717
Policy Entropy: 3.76597
Value Function Loss: 0.01929

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 20,414.69752
Overall Steps per Second: 10,064.54751

Timestep Collection Time: 2.45020
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.96992

Cumulative Model Updates: 170,070
Cumulative Timesteps: 1,418,182,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1418182024...
Checkpoint 1418182024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,296.53378
Policy Entropy: 3.75266
Value Function Loss: 0.02155

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.50253
Value Function Update Magnitude: 0.76114

Collected Steps per Second: 20,747.16853
Overall Steps per Second: 10,226.08179

Timestep Collection Time: 2.41064
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.89083

Cumulative Model Updates: 170,076
Cumulative Timesteps: 1,418,232,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,477.97726
Policy Entropy: 3.74201
Value Function Loss: 0.02309

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.77297

Collected Steps per Second: 20,713.51952
Overall Steps per Second: 10,081.89473

Timestep Collection Time: 2.41408
Timestep Consumption Time: 2.54571
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.95978

Cumulative Model Updates: 170,082
Cumulative Timesteps: 1,418,282,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1418282042...
Checkpoint 1418282042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,871.43696
Policy Entropy: 3.74839
Value Function Loss: 0.02087

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12173
Policy Update Magnitude: 0.53055
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 20,949.71950
Overall Steps per Second: 10,107.51044

Timestep Collection Time: 2.38896
Timestep Consumption Time: 2.56261
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.95157

Cumulative Model Updates: 170,088
Cumulative Timesteps: 1,418,332,090

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,245.86821
Policy Entropy: 3.74606
Value Function Loss: 0.01843

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.49242
Value Function Update Magnitude: 0.47847

Collected Steps per Second: 20,725.72778
Overall Steps per Second: 10,028.16563

Timestep Collection Time: 2.41362
Timestep Consumption Time: 2.57473
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.98835

Cumulative Model Updates: 170,094
Cumulative Timesteps: 1,418,382,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1418382114...
Checkpoint 1418382114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,162.30721
Policy Entropy: 3.76479
Value Function Loss: 0.01495

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.46307
Value Function Update Magnitude: 0.45617

Collected Steps per Second: 20,960.36657
Overall Steps per Second: 10,201.05911

Timestep Collection Time: 2.38669
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.90400

Cumulative Model Updates: 170,100
Cumulative Timesteps: 1,418,432,140

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,142.79728
Policy Entropy: 3.76992
Value Function Loss: 0.01581

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.46946
Value Function Update Magnitude: 0.52765

Collected Steps per Second: 20,897.78865
Overall Steps per Second: 10,114.45840

Timestep Collection Time: 2.39384
Timestep Consumption Time: 2.55215
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.94599

Cumulative Model Updates: 170,106
Cumulative Timesteps: 1,418,482,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1418482166...
Checkpoint 1418482166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,641.20076
Policy Entropy: 3.77937
Value Function Loss: 0.01402

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.46804
Value Function Update Magnitude: 0.56555

Collected Steps per Second: 20,915.15075
Overall Steps per Second: 10,168.19152

Timestep Collection Time: 2.39138
Timestep Consumption Time: 2.52749
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.91887

Cumulative Model Updates: 170,112
Cumulative Timesteps: 1,418,532,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 371,926.63280
Policy Entropy: 3.77834
Value Function Loss: 0.01842

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.47738
Value Function Update Magnitude: 0.55053

Collected Steps per Second: 20,966.67916
Overall Steps per Second: 10,184.88446

Timestep Collection Time: 2.38617
Timestep Consumption Time: 2.52601
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.91218

Cumulative Model Updates: 170,118
Cumulative Timesteps: 1,418,582,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1418582212...
Checkpoint 1418582212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,159.62091
Policy Entropy: 3.77752
Value Function Loss: 0.01911

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12441
Policy Update Magnitude: 0.48628
Value Function Update Magnitude: 0.56040

Collected Steps per Second: 21,343.24829
Overall Steps per Second: 10,258.09970

Timestep Collection Time: 2.34388
Timestep Consumption Time: 2.53285
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.87673

Cumulative Model Updates: 170,124
Cumulative Timesteps: 1,418,632,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,496.47231
Policy Entropy: 3.78936
Value Function Loss: 0.02171

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.69212

Collected Steps per Second: 20,806.99757
Overall Steps per Second: 10,244.78957

Timestep Collection Time: 2.40429
Timestep Consumption Time: 2.47878
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.88307

Cumulative Model Updates: 170,130
Cumulative Timesteps: 1,418,682,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1418682264...
Checkpoint 1418682264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,940.18897
Policy Entropy: 3.79130
Value Function Loss: 0.01989

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.72267

Collected Steps per Second: 20,686.66427
Overall Steps per Second: 10,226.96930

Timestep Collection Time: 2.41837
Timestep Consumption Time: 2.47340
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.89177

Cumulative Model Updates: 170,136
Cumulative Timesteps: 1,418,732,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,120.05571
Policy Entropy: 3.78824
Value Function Loss: 0.01949

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 20,841.17068
Overall Steps per Second: 10,065.56904

Timestep Collection Time: 2.40063
Timestep Consumption Time: 2.56998
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.97061

Cumulative Model Updates: 170,142
Cumulative Timesteps: 1,418,782,324

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1418782324...
Checkpoint 1418782324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,590.36023
Policy Entropy: 3.77851
Value Function Loss: 0.01774

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.51107
Value Function Update Magnitude: 0.62440

Collected Steps per Second: 20,782.23947
Overall Steps per Second: 10,239.66869

Timestep Collection Time: 2.40648
Timestep Consumption Time: 2.47766
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.88414

Cumulative Model Updates: 170,148
Cumulative Timesteps: 1,418,832,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356,265.80385
Policy Entropy: 3.76692
Value Function Loss: 0.01724

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.47929
Value Function Update Magnitude: 0.61621

Collected Steps per Second: 21,011.24649
Overall Steps per Second: 10,181.32627

Timestep Collection Time: 2.38006
Timestep Consumption Time: 2.53168
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.91174

Cumulative Model Updates: 170,154
Cumulative Timesteps: 1,418,882,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1418882344...
Checkpoint 1418882344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,575.92130
Policy Entropy: 3.76460
Value Function Loss: 0.01633

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.43838
Value Function Update Magnitude: 0.58490

Collected Steps per Second: 20,793.45586
Overall Steps per Second: 10,084.29578

Timestep Collection Time: 2.40518
Timestep Consumption Time: 2.55421
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.95939

Cumulative Model Updates: 170,160
Cumulative Timesteps: 1,418,932,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,255.71998
Policy Entropy: 3.78137
Value Function Loss: 0.01867

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.43188
Value Function Update Magnitude: 0.53600

Collected Steps per Second: 21,074.31640
Overall Steps per Second: 10,208.94152

Timestep Collection Time: 2.37265
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.89786

Cumulative Model Updates: 170,166
Cumulative Timesteps: 1,418,982,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1418982358...
Checkpoint 1418982358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.57738
Policy Entropy: 3.78595
Value Function Loss: 0.01735

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12439
Policy Update Magnitude: 0.45212
Value Function Update Magnitude: 0.69016

Collected Steps per Second: 20,982.71158
Overall Steps per Second: 10,202.56643

Timestep Collection Time: 2.38387
Timestep Consumption Time: 2.51882
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.90269

Cumulative Model Updates: 170,172
Cumulative Timesteps: 1,419,032,378

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.02461
Policy Entropy: 3.78772
Value Function Loss: 0.01775

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11959
Policy Update Magnitude: 0.45709
Value Function Update Magnitude: 0.72316

Collected Steps per Second: 20,938.84256
Overall Steps per Second: 10,275.74622

Timestep Collection Time: 2.38800
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.86602

Cumulative Model Updates: 170,178
Cumulative Timesteps: 1,419,082,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1419082380...
Checkpoint 1419082380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.27743
Policy Entropy: 3.75951
Value Function Loss: 0.01823

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.44378
Value Function Update Magnitude: 0.61745

Collected Steps per Second: 20,934.10726
Overall Steps per Second: 10,300.97046

Timestep Collection Time: 2.39064
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.85838

Cumulative Model Updates: 170,184
Cumulative Timesteps: 1,419,132,426

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.27743
Policy Entropy: 3.76195
Value Function Loss: 0.01635

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.45392
Value Function Update Magnitude: 0.44013

Collected Steps per Second: 21,323.33498
Overall Steps per Second: 10,369.46317

Timestep Collection Time: 2.34588
Timestep Consumption Time: 2.47809
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.82397

Cumulative Model Updates: 170,190
Cumulative Timesteps: 1,419,182,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1419182448...
Checkpoint 1419182448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.27743
Policy Entropy: 3.75052
Value Function Loss: 0.01463

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.44553
Value Function Update Magnitude: 0.36879

Collected Steps per Second: 20,593.33460
Overall Steps per Second: 10,203.40841

Timestep Collection Time: 2.43020
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.90483

Cumulative Model Updates: 170,196
Cumulative Timesteps: 1,419,232,494

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.27743
Policy Entropy: 3.76286
Value Function Loss: 0.01309

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.43596
Value Function Update Magnitude: 0.34649

Collected Steps per Second: 21,057.60481
Overall Steps per Second: 10,200.22594

Timestep Collection Time: 2.37482
Timestep Consumption Time: 2.52782
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.90264

Cumulative Model Updates: 170,202
Cumulative Timesteps: 1,419,282,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1419282502...
Checkpoint 1419282502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,661.00384
Policy Entropy: 3.74765
Value Function Loss: 0.01233

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.42251
Value Function Update Magnitude: 0.40098

Collected Steps per Second: 20,857.08923
Overall Steps per Second: 10,099.06221

Timestep Collection Time: 2.39765
Timestep Consumption Time: 2.55410
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.95175

Cumulative Model Updates: 170,208
Cumulative Timesteps: 1,419,332,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,484.35184
Policy Entropy: 3.76176
Value Function Loss: 0.01730

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.41488
Value Function Update Magnitude: 0.42499

Collected Steps per Second: 20,999.89393
Overall Steps per Second: 10,133.59774

Timestep Collection Time: 2.38144
Timestep Consumption Time: 2.55363
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.93507

Cumulative Model Updates: 170,214
Cumulative Timesteps: 1,419,382,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1419382520...
Checkpoint 1419382520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,761.71503
Policy Entropy: 3.78496
Value Function Loss: 0.01751

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.43405
Value Function Update Magnitude: 0.52697

Collected Steps per Second: 20,965.37005
Overall Steps per Second: 10,112.22676

Timestep Collection Time: 2.38622
Timestep Consumption Time: 2.56106
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.94728

Cumulative Model Updates: 170,220
Cumulative Timesteps: 1,419,432,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,613.00571
Policy Entropy: 3.80945
Value Function Loss: 0.02155

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.48446
Value Function Update Magnitude: 0.70973

Collected Steps per Second: 20,926.32154
Overall Steps per Second: 10,151.96999

Timestep Collection Time: 2.38991
Timestep Consumption Time: 2.53643
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.92633

Cumulative Model Updates: 170,226
Cumulative Timesteps: 1,419,482,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1419482560...
Checkpoint 1419482560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.65760
Policy Entropy: 3.80940
Value Function Loss: 0.01948

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.53483
Value Function Update Magnitude: 0.89601

Collected Steps per Second: 20,888.93979
Overall Steps per Second: 10,120.69189

Timestep Collection Time: 2.39428
Timestep Consumption Time: 2.54748
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.94176

Cumulative Model Updates: 170,232
Cumulative Timesteps: 1,419,532,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,182.07932
Policy Entropy: 3.80704
Value Function Loss: 0.02174

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.90407

Collected Steps per Second: 20,889.44665
Overall Steps per Second: 10,145.45551

Timestep Collection Time: 2.39489
Timestep Consumption Time: 2.53618
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.93107

Cumulative Model Updates: 170,238
Cumulative Timesteps: 1,419,582,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1419582602...
Checkpoint 1419582602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,850.16300
Policy Entropy: 3.80693
Value Function Loss: 0.02164

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.82592

Collected Steps per Second: 20,856.36213
Overall Steps per Second: 10,100.02446

Timestep Collection Time: 2.39754
Timestep Consumption Time: 2.55334
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.95088

Cumulative Model Updates: 170,244
Cumulative Timesteps: 1,419,632,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,692.21527
Policy Entropy: 3.79137
Value Function Loss: 0.02569

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12204
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 20,634.85560
Overall Steps per Second: 10,056.11231

Timestep Collection Time: 2.42367
Timestep Consumption Time: 2.54963
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.97329

Cumulative Model Updates: 170,250
Cumulative Timesteps: 1,419,682,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1419682618...
Checkpoint 1419682618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,321.15992
Policy Entropy: 3.79790
Value Function Loss: 0.02432

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.49819

Collected Steps per Second: 20,666.79405
Overall Steps per Second: 10,208.58948

Timestep Collection Time: 2.41944
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.89803

Cumulative Model Updates: 170,256
Cumulative Timesteps: 1,419,732,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,252.39578
Policy Entropy: 3.78498
Value Function Loss: 0.02631

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11773
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.48540

Collected Steps per Second: 20,714.79628
Overall Steps per Second: 10,030.47940

Timestep Collection Time: 2.41509
Timestep Consumption Time: 2.57251
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.98760

Cumulative Model Updates: 170,262
Cumulative Timesteps: 1,419,782,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1419782648...
Checkpoint 1419782648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,640.18000
Policy Entropy: 3.79582
Value Function Loss: 0.02308

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 20,709.17519
Overall Steps per Second: 10,205.60847

Timestep Collection Time: 2.41545
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.90142

Cumulative Model Updates: 170,268
Cumulative Timesteps: 1,419,832,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,950.43809
Policy Entropy: 3.78771
Value Function Loss: 0.02579

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 20,776.50008
Overall Steps per Second: 10,065.94219

Timestep Collection Time: 2.40657
Timestep Consumption Time: 2.56068
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.96724

Cumulative Model Updates: 170,274
Cumulative Timesteps: 1,419,882,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1419882670...
Checkpoint 1419882670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,692.31382
Policy Entropy: 3.79442
Value Function Loss: 0.02307

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.61266
Value Function Update Magnitude: 0.65404

Collected Steps per Second: 20,359.67511
Overall Steps per Second: 10,158.83367

Timestep Collection Time: 2.45711
Timestep Consumption Time: 2.46727
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.92438

Cumulative Model Updates: 170,280
Cumulative Timesteps: 1,419,932,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,546.78290
Policy Entropy: 3.78344
Value Function Loss: 0.02291

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.62969
Value Function Update Magnitude: 0.60515

Collected Steps per Second: 20,688.89879
Overall Steps per Second: 10,090.99064

Timestep Collection Time: 2.41714
Timestep Consumption Time: 2.53857
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.95571

Cumulative Model Updates: 170,286
Cumulative Timesteps: 1,419,982,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1419982704...
Checkpoint 1419982704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,133.16699
Policy Entropy: 3.76747
Value Function Loss: 0.02207

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.62834
Value Function Update Magnitude: 0.61404

Collected Steps per Second: 20,555.00908
Overall Steps per Second: 10,165.47202

Timestep Collection Time: 2.43347
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.92058

Cumulative Model Updates: 170,292
Cumulative Timesteps: 1,420,032,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,318.10611
Policy Entropy: 3.77592
Value Function Loss: 0.02125

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.59090
Value Function Update Magnitude: 0.69881

Collected Steps per Second: 20,191.93113
Overall Steps per Second: 10,117.09499

Timestep Collection Time: 2.47713
Timestep Consumption Time: 2.46678
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.94391

Cumulative Model Updates: 170,298
Cumulative Timesteps: 1,420,082,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1420082742...
Checkpoint 1420082742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 409.32992
Policy Entropy: 3.78236
Value Function Loss: 0.01884

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.65568

Collected Steps per Second: 20,074.21349
Overall Steps per Second: 10,243.60907

Timestep Collection Time: 2.49106
Timestep Consumption Time: 2.39062
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.88168

Cumulative Model Updates: 170,304
Cumulative Timesteps: 1,420,132,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,678.72243
Policy Entropy: 3.80200
Value Function Loss: 0.01941

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.69655

Collected Steps per Second: 19,946.31201
Overall Steps per Second: 10,053.31065

Timestep Collection Time: 2.50693
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.97388

Cumulative Model Updates: 170,310
Cumulative Timesteps: 1,420,182,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1420182752...
Checkpoint 1420182752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,672.54541
Policy Entropy: 3.80174
Value Function Loss: 0.01906

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.79150

Collected Steps per Second: 20,090.81750
Overall Steps per Second: 10,054.31375

Timestep Collection Time: 2.49009
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.97577

Cumulative Model Updates: 170,316
Cumulative Timesteps: 1,420,232,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,277.53660
Policy Entropy: 3.79920
Value Function Loss: 0.01863

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.59002
Value Function Update Magnitude: 0.70553

Collected Steps per Second: 20,291.57626
Overall Steps per Second: 10,168.61249

Timestep Collection Time: 2.46644
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.92181

Cumulative Model Updates: 170,322
Cumulative Timesteps: 1,420,282,828

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1420282828...
Checkpoint 1420282828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,729.59879
Policy Entropy: 3.78206
Value Function Loss: 0.01581

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.61570
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 20,761.24768
Overall Steps per Second: 10,291.62426

Timestep Collection Time: 2.41036
Timestep Consumption Time: 2.45204
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.86240

Cumulative Model Updates: 170,328
Cumulative Timesteps: 1,420,332,870

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,729.59879
Policy Entropy: 3.75920
Value Function Loss: 0.01470

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.51399
Value Function Update Magnitude: 0.52126

Collected Steps per Second: 20,392.10786
Overall Steps per Second: 10,054.55227

Timestep Collection Time: 2.45222
Timestep Consumption Time: 2.52125
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.97347

Cumulative Model Updates: 170,334
Cumulative Timesteps: 1,420,382,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1420382876...
Checkpoint 1420382876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,729.59879
Policy Entropy: 3.75083
Value Function Loss: 0.01274

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.45900
Value Function Update Magnitude: 0.47445

Collected Steps per Second: 20,692.42553
Overall Steps per Second: 10,118.09249

Timestep Collection Time: 2.41721
Timestep Consumption Time: 2.52621
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.94342

Cumulative Model Updates: 170,340
Cumulative Timesteps: 1,420,432,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,373.28441
Policy Entropy: 3.72996
Value Function Loss: 0.01464

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.43761
Value Function Update Magnitude: 0.52912

Collected Steps per Second: 20,646.85245
Overall Steps per Second: 10,068.81781

Timestep Collection Time: 2.42323
Timestep Consumption Time: 2.54578
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.96900

Cumulative Model Updates: 170,346
Cumulative Timesteps: 1,420,482,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1420482926...
Checkpoint 1420482926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,373.28441
Policy Entropy: 3.73905
Value Function Loss: 0.01348

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.45082
Value Function Update Magnitude: 0.50168

Collected Steps per Second: 20,818.31172
Overall Steps per Second: 10,217.20977

Timestep Collection Time: 2.40279
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.89586

Cumulative Model Updates: 170,352
Cumulative Timesteps: 1,420,532,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,377.25327
Policy Entropy: 3.74438
Value Function Loss: 0.01718

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.46946
Value Function Update Magnitude: 0.56974

Collected Steps per Second: 20,930.10015
Overall Steps per Second: 10,147.32318

Timestep Collection Time: 2.39043
Timestep Consumption Time: 2.54013
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.93056

Cumulative Model Updates: 170,358
Cumulative Timesteps: 1,420,582,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1420582980...
Checkpoint 1420582980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,279.45639
Policy Entropy: 3.76457
Value Function Loss: 0.01534

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.47300
Value Function Update Magnitude: 0.65989

Collected Steps per Second: 21,038.61971
Overall Steps per Second: 10,113.64935

Timestep Collection Time: 2.37753
Timestep Consumption Time: 2.56826
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.94579

Cumulative Model Updates: 170,364
Cumulative Timesteps: 1,420,633,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,371.86430
Policy Entropy: 3.75695
Value Function Loss: 0.02015

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.45482
Value Function Update Magnitude: 0.67655

Collected Steps per Second: 20,417.85995
Overall Steps per Second: 10,027.89326

Timestep Collection Time: 2.44982
Timestep Consumption Time: 2.53827
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.98809

Cumulative Model Updates: 170,370
Cumulative Timesteps: 1,420,683,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1420683020...
Checkpoint 1420683020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,873.35663
Policy Entropy: 3.76175
Value Function Loss: 0.01999

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.44938
Value Function Update Magnitude: 0.58099

Collected Steps per Second: 20,858.77650
Overall Steps per Second: 10,269.65301

Timestep Collection Time: 2.39832
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.87125

Cumulative Model Updates: 170,376
Cumulative Timesteps: 1,420,733,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,439.91343
Policy Entropy: 3.74918
Value Function Loss: 0.02315

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.49206
Value Function Update Magnitude: 0.59661

Collected Steps per Second: 21,166.07607
Overall Steps per Second: 10,342.04566

Timestep Collection Time: 2.36265
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.83541

Cumulative Model Updates: 170,382
Cumulative Timesteps: 1,420,783,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1420783054...
Checkpoint 1420783054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,402.63962
Policy Entropy: 3.74590
Value Function Loss: 0.02187

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.54150
Value Function Update Magnitude: 0.64088

Collected Steps per Second: 20,621.62267
Overall Steps per Second: 10,207.56873

Timestep Collection Time: 2.42503
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.89911

Cumulative Model Updates: 170,388
Cumulative Timesteps: 1,420,833,062

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808,720.28761
Policy Entropy: 3.74507
Value Function Loss: 0.02333

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.56866
Value Function Update Magnitude: 0.64331

Collected Steps per Second: 20,819.74347
Overall Steps per Second: 10,103.89795

Timestep Collection Time: 2.40176
Timestep Consumption Time: 2.54722
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.94898

Cumulative Model Updates: 170,394
Cumulative Timesteps: 1,420,883,066

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1420883066...
Checkpoint 1420883066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,355.51027
Policy Entropy: 3.76397
Value Function Loss: 0.02044

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.54852
Value Function Update Magnitude: 0.72407

Collected Steps per Second: 20,625.88333
Overall Steps per Second: 10,181.77770

Timestep Collection Time: 2.42443
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.91132

Cumulative Model Updates: 170,400
Cumulative Timesteps: 1,420,933,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,492.76449
Policy Entropy: 3.77240
Value Function Loss: 0.02239

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.69650

Collected Steps per Second: 20,852.54949
Overall Steps per Second: 10,080.53304

Timestep Collection Time: 2.39913
Timestep Consumption Time: 2.56370
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.96283

Cumulative Model Updates: 170,406
Cumulative Timesteps: 1,420,983,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1420983100...
Checkpoint 1420983100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,249.45859
Policy Entropy: 3.78776
Value Function Loss: 0.02075

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.69100

Collected Steps per Second: 20,791.64909
Overall Steps per Second: 10,225.25764

Timestep Collection Time: 2.40549
Timestep Consumption Time: 2.48574
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.89122

Cumulative Model Updates: 170,412
Cumulative Timesteps: 1,421,033,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,007.82510
Policy Entropy: 3.76407
Value Function Loss: 0.02515

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.55230
Value Function Update Magnitude: 0.69572

Collected Steps per Second: 20,369.00827
Overall Steps per Second: 10,230.11019

Timestep Collection Time: 2.45550
Timestep Consumption Time: 2.43360
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.88910

Cumulative Model Updates: 170,418
Cumulative Timesteps: 1,421,083,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1421083130...
Checkpoint 1421083130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,147.14645
Policy Entropy: 3.76972
Value Function Loss: 0.02215

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.63309

Collected Steps per Second: 20,254.12146
Overall Steps per Second: 10,015.97115

Timestep Collection Time: 2.46893
Timestep Consumption Time: 2.52370
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.99263

Cumulative Model Updates: 170,424
Cumulative Timesteps: 1,421,133,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331,967.76998
Policy Entropy: 3.76373
Value Function Loss: 0.02200

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.66326

Collected Steps per Second: 19,984.59085
Overall Steps per Second: 10,099.42380

Timestep Collection Time: 2.50293
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.95276

Cumulative Model Updates: 170,430
Cumulative Timesteps: 1,421,183,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1421183156...
Checkpoint 1421183156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,172.53791
Policy Entropy: 3.78889
Value Function Loss: 0.01835

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.53251
Value Function Update Magnitude: 0.77876

Collected Steps per Second: 20,997.57500
Overall Steps per Second: 10,157.59628

Timestep Collection Time: 2.38189
Timestep Consumption Time: 2.54191
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.92380

Cumulative Model Updates: 170,436
Cumulative Timesteps: 1,421,233,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,214.52387
Policy Entropy: 3.78451
Value Function Loss: 0.02096

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.52860
Value Function Update Magnitude: 0.78453

Collected Steps per Second: 20,868.46660
Overall Steps per Second: 10,217.20563

Timestep Collection Time: 2.39606
Timestep Consumption Time: 2.49785
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.89390

Cumulative Model Updates: 170,442
Cumulative Timesteps: 1,421,283,172

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1421283172...
Checkpoint 1421283172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,500.29556
Policy Entropy: 3.79423
Value Function Loss: 0.01771

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.51708
Value Function Update Magnitude: 0.74509

Collected Steps per Second: 21,049.78422
Overall Steps per Second: 10,367.03117

Timestep Collection Time: 2.37561
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.82356

Cumulative Model Updates: 170,448
Cumulative Timesteps: 1,421,333,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,001.80663
Policy Entropy: 3.77854
Value Function Loss: 0.01844

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.50150
Value Function Update Magnitude: 0.73568

Collected Steps per Second: 20,528.51887
Overall Steps per Second: 10,210.81760

Timestep Collection Time: 2.43671
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.89892

Cumulative Model Updates: 170,454
Cumulative Timesteps: 1,421,383,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1421383200...
Checkpoint 1421383200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,799.54476
Policy Entropy: 3.78141
Value Function Loss: 0.01605

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.50865
Value Function Update Magnitude: 0.68864

Collected Steps per Second: 21,055.55808
Overall Steps per Second: 10,088.24877

Timestep Collection Time: 2.37467
Timestep Consumption Time: 2.58159
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.95626

Cumulative Model Updates: 170,460
Cumulative Timesteps: 1,421,433,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,635.15646
Policy Entropy: 3.77440
Value Function Loss: 0.01834

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.49998
Value Function Update Magnitude: 0.69501

Collected Steps per Second: 21,350.23802
Overall Steps per Second: 10,438.34910

Timestep Collection Time: 2.34292
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.79214

Cumulative Model Updates: 170,466
Cumulative Timesteps: 1,421,483,222

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1421483222...
Checkpoint 1421483222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,023.59289
Policy Entropy: 3.77175
Value Function Loss: 0.01828

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.47312
Value Function Update Magnitude: 0.67902

Collected Steps per Second: 20,875.92330
Overall Steps per Second: 10,244.87852

Timestep Collection Time: 2.39635
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.88303

Cumulative Model Updates: 170,472
Cumulative Timesteps: 1,421,533,248

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,170.08728
Policy Entropy: 3.75827
Value Function Loss: 0.01835

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.48010
Value Function Update Magnitude: 0.65894

Collected Steps per Second: 20,861.32089
Overall Steps per Second: 10,085.04094

Timestep Collection Time: 2.39764
Timestep Consumption Time: 2.56198
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.95962

Cumulative Model Updates: 170,478
Cumulative Timesteps: 1,421,583,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1421583266...
Checkpoint 1421583266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,353.58787
Policy Entropy: 3.75503
Value Function Loss: 0.01850

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.48365
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 20,718.43688
Overall Steps per Second: 10,252.78946

Timestep Collection Time: 2.41399
Timestep Consumption Time: 2.46410
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.87809

Cumulative Model Updates: 170,484
Cumulative Timesteps: 1,421,633,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,353.58787
Policy Entropy: 3.76191
Value Function Loss: 0.01696

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12598
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.57681

Collected Steps per Second: 20,888.85206
Overall Steps per Second: 10,181.33757

Timestep Collection Time: 2.39439
Timestep Consumption Time: 2.51813
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.91252

Cumulative Model Updates: 170,490
Cumulative Timesteps: 1,421,683,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1421683296...
Checkpoint 1421683296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,637.67170
Policy Entropy: 3.75888
Value Function Loss: 0.01754

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.50881
Value Function Update Magnitude: 0.54846

Collected Steps per Second: 21,238.25969
Overall Steps per Second: 10,388.08786

Timestep Collection Time: 2.35443
Timestep Consumption Time: 2.45916
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.81359

Cumulative Model Updates: 170,496
Cumulative Timesteps: 1,421,733,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,851.11050
Policy Entropy: 3.76423
Value Function Loss: 0.01734

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.47034
Value Function Update Magnitude: 0.55644

Collected Steps per Second: 20,350.67416
Overall Steps per Second: 10,138.74541

Timestep Collection Time: 2.45889
Timestep Consumption Time: 2.47664
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.93552

Cumulative Model Updates: 170,502
Cumulative Timesteps: 1,421,783,340

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1421783340...
Checkpoint 1421783340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,291.42146
Policy Entropy: 3.75404
Value Function Loss: 0.01729

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.45465
Value Function Update Magnitude: 0.57757

Collected Steps per Second: 20,004.00960
Overall Steps per Second: 10,178.42958

Timestep Collection Time: 2.50050
Timestep Consumption Time: 2.41382
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.91431

Cumulative Model Updates: 170,508
Cumulative Timesteps: 1,421,833,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,992.14592
Policy Entropy: 3.76320
Value Function Loss: 0.01836

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.46597
Value Function Update Magnitude: 0.63382

Collected Steps per Second: 20,279.35125
Overall Steps per Second: 10,153.34069

Timestep Collection Time: 2.46684
Timestep Consumption Time: 2.46020
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.92705

Cumulative Model Updates: 170,514
Cumulative Timesteps: 1,421,883,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1421883386...
Checkpoint 1421883386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,973.23653
Policy Entropy: 3.75584
Value Function Loss: 0.01973

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.46340
Value Function Update Magnitude: 0.74674

Collected Steps per Second: 20,039.26500
Overall Steps per Second: 10,105.84357

Timestep Collection Time: 2.49530
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.94803

Cumulative Model Updates: 170,520
Cumulative Timesteps: 1,421,933,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,984.53789
Policy Entropy: 3.75889
Value Function Loss: 0.02006

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.49792
Value Function Update Magnitude: 0.83762

Collected Steps per Second: 20,880.85094
Overall Steps per Second: 10,203.94465

Timestep Collection Time: 2.39521
Timestep Consumption Time: 2.50623
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.90144

Cumulative Model Updates: 170,526
Cumulative Timesteps: 1,421,983,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1421983404...
Checkpoint 1421983404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,762.38954
Policy Entropy: 3.76462
Value Function Loss: 0.01742

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.50830
Value Function Update Magnitude: 0.83596

Collected Steps per Second: 21,026.79549
Overall Steps per Second: 10,258.06076

Timestep Collection Time: 2.38011
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.87870

Cumulative Model Updates: 170,532
Cumulative Timesteps: 1,422,033,450

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,222.72113
Policy Entropy: 3.76401
Value Function Loss: 0.01939

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.48553
Value Function Update Magnitude: 0.79071

Collected Steps per Second: 21,195.80043
Overall Steps per Second: 10,292.94607

Timestep Collection Time: 2.36000
Timestep Consumption Time: 2.49984
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.85983

Cumulative Model Updates: 170,538
Cumulative Timesteps: 1,422,083,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1422083472...
Checkpoint 1422083472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,984.61435
Policy Entropy: 3.77948
Value Function Loss: 0.02156

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.50631
Value Function Update Magnitude: 0.79413

Collected Steps per Second: 21,152.51212
Overall Steps per Second: 10,226.56107

Timestep Collection Time: 2.36501
Timestep Consumption Time: 2.52676
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.89177

Cumulative Model Updates: 170,544
Cumulative Timesteps: 1,422,133,498

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,735.54791
Policy Entropy: 3.79276
Value Function Loss: 0.02632

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.52817
Value Function Update Magnitude: 0.87189

Collected Steps per Second: 20,554.31715
Overall Steps per Second: 10,038.92089

Timestep Collection Time: 2.43297
Timestep Consumption Time: 2.54844
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.98141

Cumulative Model Updates: 170,550
Cumulative Timesteps: 1,422,183,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1422183506...
Checkpoint 1422183506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,266.12035
Policy Entropy: 3.82848
Value Function Loss: 0.02449

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.57980
Value Function Update Magnitude: 0.94206

Collected Steps per Second: 20,809.74192
Overall Steps per Second: 10,163.02925

Timestep Collection Time: 2.40368
Timestep Consumption Time: 2.51808
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.92176

Cumulative Model Updates: 170,556
Cumulative Timesteps: 1,422,233,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,025.99402
Policy Entropy: 3.81842
Value Function Loss: 0.02719

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.60081
Value Function Update Magnitude: 0.93382

Collected Steps per Second: 20,965.66186
Overall Steps per Second: 10,196.05225

Timestep Collection Time: 2.38600
Timestep Consumption Time: 2.52022
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.90621

Cumulative Model Updates: 170,562
Cumulative Timesteps: 1,422,283,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1422283550...
Checkpoint 1422283550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,910.72635
Policy Entropy: 3.82158
Value Function Loss: 0.02592

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.64084
Value Function Update Magnitude: 0.79438

Collected Steps per Second: 20,935.34708
Overall Steps per Second: 10,145.52561

Timestep Collection Time: 2.38955
Timestep Consumption Time: 2.54130
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.93084

Cumulative Model Updates: 170,568
Cumulative Timesteps: 1,422,333,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,242.52099
Policy Entropy: 3.78658
Value Function Loss: 0.03524

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.59566
Value Function Update Magnitude: 0.61800

Collected Steps per Second: 20,869.22792
Overall Steps per Second: 10,163.28911

Timestep Collection Time: 2.39654
Timestep Consumption Time: 2.52450
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.92104

Cumulative Model Updates: 170,574
Cumulative Timesteps: 1,422,383,590

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1422383590...
Checkpoint 1422383590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,514.23067
Policy Entropy: 3.78155
Value Function Loss: 0.02822

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12348
Policy Update Magnitude: 0.63698
Value Function Update Magnitude: 0.56285

Collected Steps per Second: 20,864.73137
Overall Steps per Second: 10,158.79932

Timestep Collection Time: 2.39744
Timestep Consumption Time: 2.52656
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.92401

Cumulative Model Updates: 170,580
Cumulative Timesteps: 1,422,433,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,273.78406
Policy Entropy: 3.74098
Value Function Loss: 0.03176

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13131
Policy Update Magnitude: 0.58888
Value Function Update Magnitude: 0.59830

Collected Steps per Second: 20,893.50360
Overall Steps per Second: 10,291.91178

Timestep Collection Time: 2.39452
Timestep Consumption Time: 2.46657
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.86110

Cumulative Model Updates: 170,586
Cumulative Timesteps: 1,422,483,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1422483642...
Checkpoint 1422483642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,179.15968
Policy Entropy: 3.74948
Value Function Loss: 0.02353

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.56423

Collected Steps per Second: 20,859.97236
Overall Steps per Second: 10,243.62304

Timestep Collection Time: 2.39780
Timestep Consumption Time: 2.48504
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.88284

Cumulative Model Updates: 170,592
Cumulative Timesteps: 1,422,533,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,539.82927
Policy Entropy: 3.75768
Value Function Loss: 0.02152

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.52211
Value Function Update Magnitude: 0.60488

Collected Steps per Second: 20,993.03677
Overall Steps per Second: 10,126.20246

Timestep Collection Time: 2.38308
Timestep Consumption Time: 2.55737
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.94045

Cumulative Model Updates: 170,598
Cumulative Timesteps: 1,422,583,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1422583688...
Checkpoint 1422583688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 175,539.82927
Policy Entropy: 3.75872
Value Function Loss: 0.01780

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.50241
Value Function Update Magnitude: 0.66909

Collected Steps per Second: 20,294.13636
Overall Steps per Second: 10,092.78347

Timestep Collection Time: 2.46465
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.95582

Cumulative Model Updates: 170,604
Cumulative Timesteps: 1,422,633,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,059.84421
Policy Entropy: 3.74598
Value Function Loss: 0.01860

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.49266
Value Function Update Magnitude: 0.60084

Collected Steps per Second: 20,719.96405
Overall Steps per Second: 10,127.70181

Timestep Collection Time: 2.41313
Timestep Consumption Time: 2.52382
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.93695

Cumulative Model Updates: 170,610
Cumulative Timesteps: 1,422,683,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1422683706...
Checkpoint 1422683706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,502.01070
Policy Entropy: 3.73353
Value Function Loss: 0.02035

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.49848
Value Function Update Magnitude: 0.48295

Collected Steps per Second: 20,783.18260
Overall Steps per Second: 10,302.66632

Timestep Collection Time: 2.40608
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.85369

Cumulative Model Updates: 170,616
Cumulative Timesteps: 1,422,733,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,448.93467
Policy Entropy: 3.77094
Value Function Loss: 0.01833

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.49481
Value Function Update Magnitude: 0.51562

Collected Steps per Second: 20,930.59991
Overall Steps per Second: 10,293.14007

Timestep Collection Time: 2.38980
Timestep Consumption Time: 2.46974
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.85955

Cumulative Model Updates: 170,622
Cumulative Timesteps: 1,422,783,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1422783732...
Checkpoint 1422783732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,156.72002
Policy Entropy: 3.76312
Value Function Loss: 0.02273

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.50776
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 20,594.22205
Overall Steps per Second: 10,191.59830

Timestep Collection Time: 2.42825
Timestep Consumption Time: 2.47853
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.90679

Cumulative Model Updates: 170,628
Cumulative Timesteps: 1,422,833,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,654.91879
Policy Entropy: 3.78999
Value Function Loss: 0.02026

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.58453
Value Function Update Magnitude: 0.68386

Collected Steps per Second: 21,021.79063
Overall Steps per Second: 10,155.16548

Timestep Collection Time: 2.37982
Timestep Consumption Time: 2.54654
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.92636

Cumulative Model Updates: 170,634
Cumulative Timesteps: 1,422,883,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1422883768...
Checkpoint 1422883768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,399.00304
Policy Entropy: 3.76537
Value Function Loss: 0.02262

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.62036
Value Function Update Magnitude: 0.70227

Collected Steps per Second: 21,246.51971
Overall Steps per Second: 10,197.90016

Timestep Collection Time: 2.35361
Timestep Consumption Time: 2.54995
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.90356

Cumulative Model Updates: 170,640
Cumulative Timesteps: 1,422,933,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,141.33903
Policy Entropy: 3.78732
Value Function Loss: 0.01826

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.61343
Value Function Update Magnitude: 0.69133

Collected Steps per Second: 20,815.19146
Overall Steps per Second: 10,085.37538

Timestep Collection Time: 2.40248
Timestep Consumption Time: 2.55599
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.95847

Cumulative Model Updates: 170,646
Cumulative Timesteps: 1,422,983,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1422983782...
Checkpoint 1422983782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,312.23319
Policy Entropy: 3.75733
Value Function Loss: 0.01836

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.71288

Collected Steps per Second: 21,035.01867
Overall Steps per Second: 10,143.06608

Timestep Collection Time: 2.37708
Timestep Consumption Time: 2.55259
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.92967

Cumulative Model Updates: 170,652
Cumulative Timesteps: 1,423,033,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,646.79103
Policy Entropy: 3.76625
Value Function Loss: 0.01786

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.52783
Value Function Update Magnitude: 0.68730

Collected Steps per Second: 20,759.36843
Overall Steps per Second: 10,094.73433

Timestep Collection Time: 2.40874
Timestep Consumption Time: 2.54473
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.95347

Cumulative Model Updates: 170,658
Cumulative Timesteps: 1,423,083,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1423083788...
Checkpoint 1423083788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,777.13955
Policy Entropy: 3.75165
Value Function Loss: 0.01979

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.51840
Value Function Update Magnitude: 0.68391

Collected Steps per Second: 20,599.94116
Overall Steps per Second: 9,457.09799

Timestep Collection Time: 2.42797
Timestep Consumption Time: 2.86076
PPO Batch Consumption Time: 0.31230
Total Iteration Time: 5.28873

Cumulative Model Updates: 170,664
Cumulative Timesteps: 1,423,133,804

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,796.79520
Policy Entropy: 3.76712
Value Function Loss: 0.01995

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.50102
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 9,320.75110
Overall Steps per Second: 5,801.17835

Timestep Collection Time: 5.36738
Timestep Consumption Time: 3.25639
PPO Batch Consumption Time: 0.37396
Total Iteration Time: 8.62377

Cumulative Model Updates: 170,670
Cumulative Timesteps: 1,423,183,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1423183832...
Checkpoint 1423183832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,796.79520
Policy Entropy: 3.75368
Value Function Loss: 0.01884

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.50050
Value Function Update Magnitude: 0.55633

Collected Steps per Second: 17,301.29423
Overall Steps per Second: 8,360.25176

Timestep Collection Time: 2.89065
Timestep Consumption Time: 3.09147
PPO Batch Consumption Time: 0.36211
Total Iteration Time: 5.98212

Cumulative Model Updates: 170,676
Cumulative Timesteps: 1,423,233,844

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259,338.66884
Policy Entropy: 3.76744
Value Function Loss: 0.01584

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.49096
Value Function Update Magnitude: 0.51558

Collected Steps per Second: 18,497.96290
Overall Steps per Second: 8,611.96426

Timestep Collection Time: 2.70332
Timestep Consumption Time: 3.10325
PPO Batch Consumption Time: 0.36530
Total Iteration Time: 5.80657

Cumulative Model Updates: 170,682
Cumulative Timesteps: 1,423,283,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1423283850...
Checkpoint 1423283850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 595,717.23184
Policy Entropy: 3.75478
Value Function Loss: 0.01821

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.52781
Value Function Update Magnitude: 0.51403

Collected Steps per Second: 18,356.70603
Overall Steps per Second: 8,596.50160

Timestep Collection Time: 2.72522
Timestep Consumption Time: 3.09413
PPO Batch Consumption Time: 0.36602
Total Iteration Time: 5.81934

Cumulative Model Updates: 170,688
Cumulative Timesteps: 1,423,333,876

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314,057.04770
Policy Entropy: 3.75777
Value Function Loss: 0.02092

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.53709
Value Function Update Magnitude: 0.56810

Collected Steps per Second: 17,882.72649
Overall Steps per Second: 8,535.85798

Timestep Collection Time: 2.79845
Timestep Consumption Time: 3.06434
PPO Batch Consumption Time: 0.36731
Total Iteration Time: 5.86280

Cumulative Model Updates: 170,694
Cumulative Timesteps: 1,423,383,920

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1423383920...
Checkpoint 1423383920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,508.31188
Policy Entropy: 3.76159
Value Function Loss: 0.01977

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.59806

Collected Steps per Second: 15,804.78697
Overall Steps per Second: 8,059.61844

Timestep Collection Time: 3.16626
Timestep Consumption Time: 3.04272
PPO Batch Consumption Time: 0.37641
Total Iteration Time: 6.20898

Cumulative Model Updates: 170,700
Cumulative Timesteps: 1,423,433,962

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,285.66666
Policy Entropy: 3.75447
Value Function Loss: 0.01755

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.45420
Value Function Update Magnitude: 0.62671

Collected Steps per Second: 16,970.81531
Overall Steps per Second: 8,447.47332

Timestep Collection Time: 2.94765
Timestep Consumption Time: 2.97412
PPO Batch Consumption Time: 0.37114
Total Iteration Time: 5.92177

Cumulative Model Updates: 170,706
Cumulative Timesteps: 1,423,483,986

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1423483986...
Checkpoint 1423483986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,097.53346
Policy Entropy: 3.77444
Value Function Loss: 0.01473

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.44939
Value Function Update Magnitude: 0.63718

Collected Steps per Second: 17,811.69306
Overall Steps per Second: 8,553.02159

Timestep Collection Time: 2.80883
Timestep Consumption Time: 3.04057
PPO Batch Consumption Time: 0.36866
Total Iteration Time: 5.84939

Cumulative Model Updates: 170,712
Cumulative Timesteps: 1,423,534,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,097.53346
Policy Entropy: 3.76091
Value Function Loss: 0.01434

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.44220
Value Function Update Magnitude: 0.57109

Collected Steps per Second: 18,647.36426
Overall Steps per Second: 8,701.63539

Timestep Collection Time: 2.68156
Timestep Consumption Time: 3.06495
PPO Batch Consumption Time: 0.36348
Total Iteration Time: 5.74651

Cumulative Model Updates: 170,718
Cumulative Timesteps: 1,423,584,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1423584020...
Checkpoint 1423584020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,097.53346
Policy Entropy: 3.76351
Value Function Loss: 0.01282

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.42252
Value Function Update Magnitude: 0.45644

Collected Steps per Second: 18,406.25914
Overall Steps per Second: 8,713.42944

Timestep Collection Time: 2.71658
Timestep Consumption Time: 3.02192
PPO Batch Consumption Time: 0.36966
Total Iteration Time: 5.73850

Cumulative Model Updates: 170,724
Cumulative Timesteps: 1,423,634,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,536.27817
Policy Entropy: 3.74689
Value Function Loss: 0.01439

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.42343
Value Function Update Magnitude: 0.51628

Collected Steps per Second: 18,521.74722
Overall Steps per Second: 8,620.57225

Timestep Collection Time: 2.69975
Timestep Consumption Time: 3.10080
PPO Batch Consumption Time: 0.37133
Total Iteration Time: 5.80054

Cumulative Model Updates: 170,730
Cumulative Timesteps: 1,423,684,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1423684026...
Checkpoint 1423684026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,047.62218
Policy Entropy: 3.75265
Value Function Loss: 0.01529

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.71103

Collected Steps per Second: 18,320.14158
Overall Steps per Second: 8,658.46771

Timestep Collection Time: 2.73120
Timestep Consumption Time: 3.04765
PPO Batch Consumption Time: 0.35861
Total Iteration Time: 5.77885

Cumulative Model Updates: 170,736
Cumulative Timesteps: 1,423,734,062

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,891.44536
Policy Entropy: 3.75175
Value Function Loss: 0.01854

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.72216

Collected Steps per Second: 18,713.57828
Overall Steps per Second: 8,588.44843

Timestep Collection Time: 2.67196
Timestep Consumption Time: 3.15004
PPO Batch Consumption Time: 0.37457
Total Iteration Time: 5.82201

Cumulative Model Updates: 170,742
Cumulative Timesteps: 1,423,784,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1423784064...
Checkpoint 1423784064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,769.32465
Policy Entropy: 3.76687
Value Function Loss: 0.01623

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.48026
Value Function Update Magnitude: 0.63334

Collected Steps per Second: 18,233.96038
Overall Steps per Second: 8,357.83190

Timestep Collection Time: 2.74323
Timestep Consumption Time: 3.24157
PPO Batch Consumption Time: 0.37969
Total Iteration Time: 5.98481

Cumulative Model Updates: 170,748
Cumulative Timesteps: 1,423,834,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,893.61458
Policy Entropy: 3.76496
Value Function Loss: 0.01706

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.44450
Value Function Update Magnitude: 0.60116

Collected Steps per Second: 17,907.78490
Overall Steps per Second: 8,523.66877

Timestep Collection Time: 2.79331
Timestep Consumption Time: 3.07529
PPO Batch Consumption Time: 0.38428
Total Iteration Time: 5.86860

Cumulative Model Updates: 170,754
Cumulative Timesteps: 1,423,884,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1423884106...
Checkpoint 1423884106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,893.61458
Policy Entropy: 3.76443
Value Function Loss: 0.01271

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.42212
Value Function Update Magnitude: 0.53095

Collected Steps per Second: 18,514.57206
Overall Steps per Second: 8,670.02289

Timestep Collection Time: 2.70144
Timestep Consumption Time: 3.06740
PPO Batch Consumption Time: 0.36943
Total Iteration Time: 5.76884

Cumulative Model Updates: 170,760
Cumulative Timesteps: 1,423,934,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,523.12810
Policy Entropy: 3.74673
Value Function Loss: 0.01804

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.43629
Value Function Update Magnitude: 0.50235

Collected Steps per Second: 17,792.81693
Overall Steps per Second: 8,666.51916

Timestep Collection Time: 2.81080
Timestep Consumption Time: 2.95992
PPO Batch Consumption Time: 0.36864
Total Iteration Time: 5.77071

Cumulative Model Updates: 170,766
Cumulative Timesteps: 1,423,984,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1423984134...
Checkpoint 1423984134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,055.77464
Policy Entropy: 3.75144
Value Function Loss: 0.01664

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.49042
Value Function Update Magnitude: 0.62952

Collected Steps per Second: 17,115.10941
Overall Steps per Second: 8,518.30895

Timestep Collection Time: 2.92163
Timestep Consumption Time: 2.94855
PPO Batch Consumption Time: 0.36388
Total Iteration Time: 5.87018

Cumulative Model Updates: 170,772
Cumulative Timesteps: 1,424,034,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,766.93873
Policy Entropy: 3.75577
Value Function Loss: 0.02033

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.52418
Value Function Update Magnitude: 0.62412

Collected Steps per Second: 17,798.96242
Overall Steps per Second: 8,611.06745

Timestep Collection Time: 2.81151
Timestep Consumption Time: 2.99985
PPO Batch Consumption Time: 0.36880
Total Iteration Time: 5.81136

Cumulative Model Updates: 170,778
Cumulative Timesteps: 1,424,084,180

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1424084180...
Checkpoint 1424084180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,006.71740
Policy Entropy: 3.75399
Value Function Loss: 0.01717

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.50014
Value Function Update Magnitude: 0.60741

Collected Steps per Second: 18,159.87595
Overall Steps per Second: 8,554.49181

Timestep Collection Time: 2.75475
Timestep Consumption Time: 3.09317
PPO Batch Consumption Time: 0.37005
Total Iteration Time: 5.84792

Cumulative Model Updates: 170,784
Cumulative Timesteps: 1,424,134,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,128.48891
Policy Entropy: 3.74810
Value Function Loss: 0.01748

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.47630
Value Function Update Magnitude: 0.60613

Collected Steps per Second: 18,026.06707
Overall Steps per Second: 9,285.50763

Timestep Collection Time: 2.77398
Timestep Consumption Time: 2.61118
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 5.38517

Cumulative Model Updates: 170,790
Cumulative Timesteps: 1,424,184,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1424184210...
Checkpoint 1424184210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,431.51322
Policy Entropy: 3.75174
Value Function Loss: 0.01611

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.44521
Value Function Update Magnitude: 0.54368

Collected Steps per Second: 20,340.46191
Overall Steps per Second: 10,015.56740

Timestep Collection Time: 2.45815
Timestep Consumption Time: 2.53407
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.99223

Cumulative Model Updates: 170,796
Cumulative Timesteps: 1,424,234,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,066.88754
Policy Entropy: 3.75650
Value Function Loss: 0.01811

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.44665
Value Function Update Magnitude: 0.53157

Collected Steps per Second: 16,540.03201
Overall Steps per Second: 8,893.19538

Timestep Collection Time: 3.02454
Timestep Consumption Time: 2.60066
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 5.62520

Cumulative Model Updates: 170,802
Cumulative Timesteps: 1,424,284,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1424284236...
Checkpoint 1424284236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,866.54950
Policy Entropy: 3.77731
Value Function Loss: 0.01814

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.49875
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 19,615.13281
Overall Steps per Second: 9,541.31012

Timestep Collection Time: 2.55048
Timestep Consumption Time: 2.69283
PPO Batch Consumption Time: 0.30599
Total Iteration Time: 5.24331

Cumulative Model Updates: 170,808
Cumulative Timesteps: 1,424,334,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,208.84052
Policy Entropy: 3.76891
Value Function Loss: 0.01909

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.49887
Value Function Update Magnitude: 0.51720

Collected Steps per Second: 19,403.65184
Overall Steps per Second: 9,527.90945

Timestep Collection Time: 2.57694
Timestep Consumption Time: 2.67101
PPO Batch Consumption Time: 0.30629
Total Iteration Time: 5.24795

Cumulative Model Updates: 170,814
Cumulative Timesteps: 1,424,384,266

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1424384266...
Checkpoint 1424384266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,701.56850
Policy Entropy: 3.75663
Value Function Loss: 0.01543

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.46376
Value Function Update Magnitude: 0.44496

Collected Steps per Second: 19,449.40838
Overall Steps per Second: 9,561.90277

Timestep Collection Time: 2.57149
Timestep Consumption Time: 2.65906
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 5.23055

Cumulative Model Updates: 170,820
Cumulative Timesteps: 1,424,434,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,701.56850
Policy Entropy: 3.73138
Value Function Loss: 0.01621

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.42565
Value Function Update Magnitude: 0.37501

Collected Steps per Second: 20,026.01316
Overall Steps per Second: 9,814.32425

Timestep Collection Time: 2.49835
Timestep Consumption Time: 2.59950
PPO Batch Consumption Time: 0.30072
Total Iteration Time: 5.09785

Cumulative Model Updates: 170,826
Cumulative Timesteps: 1,424,484,312

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1424484312...
Checkpoint 1424484312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,640.92735
Policy Entropy: 3.73925
Value Function Loss: 0.01503

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.40175
Value Function Update Magnitude: 0.38007

Collected Steps per Second: 18,537.05420
Overall Steps per Second: 9,426.86597

Timestep Collection Time: 2.69730
Timestep Consumption Time: 2.60669
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 5.30399

Cumulative Model Updates: 170,832
Cumulative Timesteps: 1,424,534,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,640.92735
Policy Entropy: 3.74000
Value Function Loss: 0.01843

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.43736
Value Function Update Magnitude: 0.40877

Collected Steps per Second: 19,915.70267
Overall Steps per Second: 9,891.59351

Timestep Collection Time: 2.51159
Timestep Consumption Time: 2.54523
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 5.05682

Cumulative Model Updates: 170,838
Cumulative Timesteps: 1,424,584,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1424584332...
Checkpoint 1424584332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,144.60996
Policy Entropy: 3.74474
Value Function Loss: 0.01832

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.51883
Value Function Update Magnitude: 0.44785

Collected Steps per Second: 20,477.94341
Overall Steps per Second: 9,908.07811

Timestep Collection Time: 2.44263
Timestep Consumption Time: 2.60578
PPO Batch Consumption Time: 0.29882
Total Iteration Time: 5.04841

Cumulative Model Updates: 170,844
Cumulative Timesteps: 1,424,634,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,144.60996
Policy Entropy: 3.72962
Value Function Loss: 0.02279

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.53684
Value Function Update Magnitude: 0.45997

Collected Steps per Second: 20,435.24015
Overall Steps per Second: 10,096.78239

Timestep Collection Time: 2.44881
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.95623

Cumulative Model Updates: 170,850
Cumulative Timesteps: 1,424,684,394

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1424684394...
Checkpoint 1424684394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,144.60996
Policy Entropy: 3.72531
Value Function Loss: 0.01996

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.52047
Value Function Update Magnitude: 0.39277

Collected Steps per Second: 20,181.63716
Overall Steps per Second: 9,859.04596

Timestep Collection Time: 2.47829
Timestep Consumption Time: 2.59481
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 5.07311

Cumulative Model Updates: 170,856
Cumulative Timesteps: 1,424,734,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,144.60996
Policy Entropy: 3.71984
Value Function Loss: 0.01791

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.49156
Value Function Update Magnitude: 0.40711

Collected Steps per Second: 20,094.16442
Overall Steps per Second: 9,934.02316

Timestep Collection Time: 2.48858
Timestep Consumption Time: 2.54523
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 5.03381

Cumulative Model Updates: 170,862
Cumulative Timesteps: 1,424,784,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1424784416...
Checkpoint 1424784416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,410.61050
Policy Entropy: 3.73557
Value Function Loss: 0.01648

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.46589
Value Function Update Magnitude: 0.44358

Collected Steps per Second: 20,364.92078
Overall Steps per Second: 9,530.98115

Timestep Collection Time: 2.45540
Timestep Consumption Time: 2.79107
PPO Batch Consumption Time: 0.32874
Total Iteration Time: 5.24647

Cumulative Model Updates: 170,868
Cumulative Timesteps: 1,424,834,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,662.66948
Policy Entropy: 3.74169
Value Function Loss: 0.01899

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12557
Policy Update Magnitude: 0.52206
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 19,856.91652
Overall Steps per Second: 9,728.45973

Timestep Collection Time: 2.51942
Timestep Consumption Time: 2.62301
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.14244

Cumulative Model Updates: 170,874
Cumulative Timesteps: 1,424,884,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1424884448...
Checkpoint 1424884448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,143.09261
Policy Entropy: 3.75620
Value Function Loss: 0.01931

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.63692

Collected Steps per Second: 20,191.38161
Overall Steps per Second: 9,831.63545

Timestep Collection Time: 2.47640
Timestep Consumption Time: 2.60942
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 5.08583

Cumulative Model Updates: 170,880
Cumulative Timesteps: 1,424,934,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,814.20134
Policy Entropy: 3.76891
Value Function Loss: 0.02374

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.57307

Collected Steps per Second: 19,117.59384
Overall Steps per Second: 9,560.85103

Timestep Collection Time: 2.61675
Timestep Consumption Time: 2.61563
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 5.23238

Cumulative Model Updates: 170,886
Cumulative Timesteps: 1,424,984,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1424984476...
Checkpoint 1424984476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,198.96341
Policy Entropy: 3.77415
Value Function Loss: 0.02159

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.58343
Value Function Update Magnitude: 0.59908

Collected Steps per Second: 19,997.71592
Overall Steps per Second: 9,304.46804

Timestep Collection Time: 2.50079
Timestep Consumption Time: 2.87405
PPO Batch Consumption Time: 0.34596
Total Iteration Time: 5.37484

Cumulative Model Updates: 170,892
Cumulative Timesteps: 1,425,034,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,953.77203
Policy Entropy: 3.76516
Value Function Loss: 0.02496

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.61059
Value Function Update Magnitude: 0.57147

Collected Steps per Second: 18,667.27734
Overall Steps per Second: 9,310.80460

Timestep Collection Time: 2.67902
Timestep Consumption Time: 2.69216
PPO Batch Consumption Time: 0.31070
Total Iteration Time: 5.37118

Cumulative Model Updates: 170,898
Cumulative Timesteps: 1,425,084,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1425084496...
Checkpoint 1425084496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,872.99920
Policy Entropy: 3.76964
Value Function Loss: 0.02001

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.65575

Collected Steps per Second: 17,767.43841
Overall Steps per Second: 8,977.53425

Timestep Collection Time: 2.81470
Timestep Consumption Time: 2.75587
PPO Batch Consumption Time: 0.32058
Total Iteration Time: 5.57057

Cumulative Model Updates: 170,904
Cumulative Timesteps: 1,425,134,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,482.02391
Policy Entropy: 3.76189
Value Function Loss: 0.02175

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.57057
Value Function Update Magnitude: 0.71475

Collected Steps per Second: 19,219.84910
Overall Steps per Second: 9,606.22803

Timestep Collection Time: 2.60158
Timestep Consumption Time: 2.60358
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 5.20516

Cumulative Model Updates: 170,910
Cumulative Timesteps: 1,425,184,508

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1425184508...
Checkpoint 1425184508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,539.03250
Policy Entropy: 3.77246
Value Function Loss: 0.02006

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.60586
Value Function Update Magnitude: 0.68186

Collected Steps per Second: 20,447.09453
Overall Steps per Second: 9,904.43351

Timestep Collection Time: 2.44534
Timestep Consumption Time: 2.60291
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 5.04824

Cumulative Model Updates: 170,916
Cumulative Timesteps: 1,425,234,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,688.65620
Policy Entropy: 3.76011
Value Function Loss: 0.02446

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.68695

Collected Steps per Second: 18,136.86513
Overall Steps per Second: 9,410.01473

Timestep Collection Time: 2.75803
Timestep Consumption Time: 2.55780
PPO Batch Consumption Time: 0.30672
Total Iteration Time: 5.31583

Cumulative Model Updates: 170,922
Cumulative Timesteps: 1,425,284,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1425284530...
Checkpoint 1425284530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,936.88246
Policy Entropy: 3.77200
Value Function Loss: 0.02394

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.68686

Collected Steps per Second: 18,973.61325
Overall Steps per Second: 9,716.88415

Timestep Collection Time: 2.63629
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 5.14774

Cumulative Model Updates: 170,928
Cumulative Timesteps: 1,425,334,550

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,919.30201
Policy Entropy: 3.75250
Value Function Loss: 0.02244

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.61109
Value Function Update Magnitude: 0.66488

Collected Steps per Second: 18,696.04418
Overall Steps per Second: 9,688.07265

Timestep Collection Time: 2.67533
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 5.16284

Cumulative Model Updates: 170,934
Cumulative Timesteps: 1,425,384,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1425384568...
Checkpoint 1425384568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,780.17113
Policy Entropy: 3.76121
Value Function Loss: 0.01957

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.62202

Collected Steps per Second: 19,225.76999
Overall Steps per Second: 9,635.26489

Timestep Collection Time: 2.60078
Timestep Consumption Time: 2.58870
PPO Batch Consumption Time: 0.31013
Total Iteration Time: 5.18948

Cumulative Model Updates: 170,940
Cumulative Timesteps: 1,425,434,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,535.51840
Policy Entropy: 3.75633
Value Function Loss: 0.01873

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.58875

Collected Steps per Second: 18,933.57014
Overall Steps per Second: 9,499.94714

Timestep Collection Time: 2.64166
Timestep Consumption Time: 2.62321
PPO Batch Consumption Time: 0.30577
Total Iteration Time: 5.26487

Cumulative Model Updates: 170,946
Cumulative Timesteps: 1,425,484,586

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1425484586...
Checkpoint 1425484586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.25635
Policy Entropy: 3.76100
Value Function Loss: 0.01827

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.49017
Value Function Update Magnitude: 0.52464

Collected Steps per Second: 19,473.43468
Overall Steps per Second: 9,608.14775

Timestep Collection Time: 2.56842
Timestep Consumption Time: 2.63716
PPO Batch Consumption Time: 0.31139
Total Iteration Time: 5.20558

Cumulative Model Updates: 170,952
Cumulative Timesteps: 1,425,534,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391.80698
Policy Entropy: 3.75870
Value Function Loss: 0.01681

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.46847
Value Function Update Magnitude: 0.52905

Collected Steps per Second: 18,210.98799
Overall Steps per Second: 9,276.93512

Timestep Collection Time: 2.74636
Timestep Consumption Time: 2.64486
PPO Batch Consumption Time: 0.30427
Total Iteration Time: 5.39122

Cumulative Model Updates: 170,958
Cumulative Timesteps: 1,425,584,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1425584616...
Checkpoint 1425584616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,121.94656
Policy Entropy: 3.74998
Value Function Loss: 0.01795

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.48195
Value Function Update Magnitude: 0.51082

Collected Steps per Second: 20,199.49425
Overall Steps per Second: 9,741.03327

Timestep Collection Time: 2.47531
Timestep Consumption Time: 2.65762
PPO Batch Consumption Time: 0.29856
Total Iteration Time: 5.13293

Cumulative Model Updates: 170,964
Cumulative Timesteps: 1,425,634,616

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,561.40045
Policy Entropy: 3.75510
Value Function Loss: 0.01803

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.61186

Collected Steps per Second: 20,140.93905
Overall Steps per Second: 9,623.61898

Timestep Collection Time: 2.48310
Timestep Consumption Time: 2.71370
PPO Batch Consumption Time: 0.31627
Total Iteration Time: 5.19680

Cumulative Model Updates: 170,970
Cumulative Timesteps: 1,425,684,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1425684628...
Checkpoint 1425684628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,296.17152
Policy Entropy: 3.74173
Value Function Loss: 0.01844

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.60583

Collected Steps per Second: 19,298.18417
Overall Steps per Second: 9,605.53384

Timestep Collection Time: 2.59278
Timestep Consumption Time: 2.61630
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 5.20908

Cumulative Model Updates: 170,976
Cumulative Timesteps: 1,425,734,664

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,296.17152
Policy Entropy: 3.75568
Value Function Loss: 0.01659

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.52023
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 20,285.58110
Overall Steps per Second: 9,862.90028

Timestep Collection Time: 2.46500
Timestep Consumption Time: 2.60491
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 5.06991

Cumulative Model Updates: 170,982
Cumulative Timesteps: 1,425,784,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1425784668...
Checkpoint 1425784668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487,115.69784
Policy Entropy: 3.74069
Value Function Loss: 0.01791

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.51633
Value Function Update Magnitude: 0.47701

Collected Steps per Second: 19,262.81980
Overall Steps per Second: 9,492.20644

Timestep Collection Time: 2.59578
Timestep Consumption Time: 2.67191
PPO Batch Consumption Time: 0.31097
Total Iteration Time: 5.26769

Cumulative Model Updates: 170,988
Cumulative Timesteps: 1,425,834,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,853.01280
Policy Entropy: 3.76183
Value Function Loss: 0.01672

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.49662

Collected Steps per Second: 19,924.57285
Overall Steps per Second: 9,738.13192

Timestep Collection Time: 2.50987
Timestep Consumption Time: 2.62541
PPO Batch Consumption Time: 0.30435
Total Iteration Time: 5.13528

Cumulative Model Updates: 170,994
Cumulative Timesteps: 1,425,884,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1425884678...
Checkpoint 1425884678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,853.01280
Policy Entropy: 3.74095
Value Function Loss: 0.01657

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13668
Policy Update Magnitude: 0.49571
Value Function Update Magnitude: 0.48752

Collected Steps per Second: 20,213.57224
Overall Steps per Second: 9,756.79722

Timestep Collection Time: 2.47418
Timestep Consumption Time: 2.65168
PPO Batch Consumption Time: 0.31075
Total Iteration Time: 5.12586

Cumulative Model Updates: 171,000
Cumulative Timesteps: 1,425,934,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,789.77633
Policy Entropy: 3.75058
Value Function Loss: 0.01609

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.47335
Value Function Update Magnitude: 0.45894

Collected Steps per Second: 20,324.72326
Overall Steps per Second: 10,007.46537

Timestep Collection Time: 2.46025
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.99667

Cumulative Model Updates: 171,006
Cumulative Timesteps: 1,425,984,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1425984694...
Checkpoint 1425984694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,735.17986
Policy Entropy: 3.73390
Value Function Loss: 0.01853

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.52429
Value Function Update Magnitude: 0.51327

Collected Steps per Second: 20,466.78590
Overall Steps per Second: 9,905.75416

Timestep Collection Time: 2.44445
Timestep Consumption Time: 2.60615
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 5.05060

Cumulative Model Updates: 171,012
Cumulative Timesteps: 1,426,034,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,335.60266
Policy Entropy: 3.77101
Value Function Loss: 0.01949

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.69224

Collected Steps per Second: 19,544.30233
Overall Steps per Second: 9,414.59234

Timestep Collection Time: 2.55911
Timestep Consumption Time: 2.75349
PPO Batch Consumption Time: 0.31702
Total Iteration Time: 5.31260

Cumulative Model Updates: 171,018
Cumulative Timesteps: 1,426,084,740

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1426084740...
Checkpoint 1426084740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.81985
Policy Entropy: 3.79631
Value Function Loss: 0.02022

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.54775
Value Function Update Magnitude: 0.78139

Collected Steps per Second: 17,789.83245
Overall Steps per Second: 9,215.04844

Timestep Collection Time: 2.81104
Timestep Consumption Time: 2.61573
PPO Batch Consumption Time: 0.30618
Total Iteration Time: 5.42678

Cumulative Model Updates: 171,024
Cumulative Timesteps: 1,426,134,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235.27263
Policy Entropy: 3.79588
Value Function Loss: 0.01747

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.76462

Collected Steps per Second: 18,610.34679
Overall Steps per Second: 9,265.90978

Timestep Collection Time: 2.68668
Timestep Consumption Time: 2.70945
PPO Batch Consumption Time: 0.31768
Total Iteration Time: 5.39612

Cumulative Model Updates: 171,030
Cumulative Timesteps: 1,426,184,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1426184748...
Checkpoint 1426184748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.77282
Value Function Loss: 0.01596

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.59507
Value Function Update Magnitude: 0.65348

Collected Steps per Second: 18,791.30862
Overall Steps per Second: 9,481.49689

Timestep Collection Time: 2.66187
Timestep Consumption Time: 2.61367
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 5.27554

Cumulative Model Updates: 171,036
Cumulative Timesteps: 1,426,234,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.75915
Value Function Loss: 0.01265

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.59888
Value Function Update Magnitude: 0.49846

Collected Steps per Second: 18,513.78202
Overall Steps per Second: 9,608.73113

Timestep Collection Time: 2.70242
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 5.20693

Cumulative Model Updates: 171,042
Cumulative Timesteps: 1,426,284,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1426284800...
Checkpoint 1426284800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.75502
Value Function Loss: 0.01223

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07975
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.40786

Collected Steps per Second: 18,944.54853
Overall Steps per Second: 9,695.50550

Timestep Collection Time: 2.64034
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 5.15909

Cumulative Model Updates: 171,048
Cumulative Timesteps: 1,426,334,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.75277
Value Function Loss: 0.01146

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.36646

Collected Steps per Second: 17,452.84694
Overall Steps per Second: 9,241.87193

Timestep Collection Time: 2.86727
Timestep Consumption Time: 2.54744
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 5.41470

Cumulative Model Updates: 171,054
Cumulative Timesteps: 1,426,384,862

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1426384862...
Checkpoint 1426384862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.75576
Value Function Loss: 0.01220

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06541
Policy Update Magnitude: 0.56831
Value Function Update Magnitude: 0.36997

Collected Steps per Second: 18,848.71452
Overall Steps per Second: 9,559.97203

Timestep Collection Time: 2.65408
Timestep Consumption Time: 2.57878
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 5.23286

Cumulative Model Updates: 171,060
Cumulative Timesteps: 1,426,434,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157.84539
Policy Entropy: 3.74422
Value Function Loss: 0.01221

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07934
Policy Update Magnitude: 0.59945
Value Function Update Magnitude: 0.36228

Collected Steps per Second: 19,009.38922
Overall Steps per Second: 9,634.18112

Timestep Collection Time: 2.63175
Timestep Consumption Time: 2.56101
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 5.19276

Cumulative Model Updates: 171,066
Cumulative Timesteps: 1,426,484,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426484916...
Checkpoint 1426484916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,541.19897
Policy Entropy: 3.77119
Value Function Loss: 0.01180

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.49829
Value Function Update Magnitude: 0.39689

Collected Steps per Second: 19,047.26449
Overall Steps per Second: 9,468.23427

Timestep Collection Time: 2.62704
Timestep Consumption Time: 2.65779
PPO Batch Consumption Time: 0.30269
Total Iteration Time: 5.28483

Cumulative Model Updates: 171,072
Cumulative Timesteps: 1,426,534,954

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,494.83373
Policy Entropy: 3.77521
Value Function Loss: 0.01326

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.45626

Collected Steps per Second: 20,176.72442
Overall Steps per Second: 9,925.20500

Timestep Collection Time: 2.47919
Timestep Consumption Time: 2.56070
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 5.03990

Cumulative Model Updates: 171,078
Cumulative Timesteps: 1,426,584,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1426584976...
Checkpoint 1426584976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,332.14632
Policy Entropy: 3.78081
Value Function Loss: 0.01490

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.64274
Value Function Update Magnitude: 0.54378

Collected Steps per Second: 19,579.98321
Overall Steps per Second: 9,742.71981

Timestep Collection Time: 2.55445
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 5.13368

Cumulative Model Updates: 171,084
Cumulative Timesteps: 1,426,634,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,343.24365
Policy Entropy: 3.76627
Value Function Loss: 0.01465

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15071
Policy Update Magnitude: 0.59782
Value Function Update Magnitude: 0.63646

Collected Steps per Second: 20,140.42650
Overall Steps per Second: 9,574.58524

Timestep Collection Time: 2.48346
Timestep Consumption Time: 2.74058
PPO Batch Consumption Time: 0.32608
Total Iteration Time: 5.22404

Cumulative Model Updates: 171,090
Cumulative Timesteps: 1,426,685,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1426685010...
Checkpoint 1426685010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,343.24365
Policy Entropy: 3.77861
Value Function Loss: 0.01198

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.16394
Policy Update Magnitude: 0.48319
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 18,942.81881
Overall Steps per Second: 9,295.26283

Timestep Collection Time: 2.64111
Timestep Consumption Time: 2.74121
PPO Batch Consumption Time: 0.32705
Total Iteration Time: 5.38231

Cumulative Model Updates: 171,096
Cumulative Timesteps: 1,426,735,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,343.24365
Policy Entropy: 3.76499
Value Function Loss: 0.01090

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.17594
Policy Update Magnitude: 0.40097
Value Function Update Magnitude: 0.50227

Collected Steps per Second: 20,021.11606
Overall Steps per Second: 9,721.04480

Timestep Collection Time: 2.49876
Timestep Consumption Time: 2.64760
PPO Batch Consumption Time: 0.30269
Total Iteration Time: 5.14636

Cumulative Model Updates: 171,102
Cumulative Timesteps: 1,426,785,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1426785068...
Checkpoint 1426785068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,327.13373
Policy Entropy: 3.75881
Value Function Loss: 0.01175

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.15396
Policy Update Magnitude: 0.38973
Value Function Update Magnitude: 0.49321

Collected Steps per Second: 18,126.23170
Overall Steps per Second: 9,132.38007

Timestep Collection Time: 2.75921
Timestep Consumption Time: 2.71735
PPO Batch Consumption Time: 0.32195
Total Iteration Time: 5.47656

Cumulative Model Updates: 171,108
Cumulative Timesteps: 1,426,835,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,236.92065
Policy Entropy: 3.74611
Value Function Loss: 0.01567

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15726
Policy Update Magnitude: 0.41718
Value Function Update Magnitude: 0.53615

Collected Steps per Second: 18,761.15887
Overall Steps per Second: 9,661.09319

Timestep Collection Time: 2.66604
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.30456
Total Iteration Time: 5.17726

Cumulative Model Updates: 171,114
Cumulative Timesteps: 1,426,885,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1426885100...
Checkpoint 1426885100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,236.92065
Policy Entropy: 3.75413
Value Function Loss: 0.01542

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.42127
Value Function Update Magnitude: 0.49445

Collected Steps per Second: 18,744.29001
Overall Steps per Second: 9,486.71438

Timestep Collection Time: 2.66769
Timestep Consumption Time: 2.60326
PPO Batch Consumption Time: 0.31549
Total Iteration Time: 5.27095

Cumulative Model Updates: 171,120
Cumulative Timesteps: 1,426,935,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,236.92065
Policy Entropy: 3.73605
Value Function Loss: 0.01614

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.39366
Value Function Update Magnitude: 0.41195

Collected Steps per Second: 18,981.94705
Overall Steps per Second: 9,608.10786

Timestep Collection Time: 2.63619
Timestep Consumption Time: 2.57191
PPO Batch Consumption Time: 0.30723
Total Iteration Time: 5.20810

Cumulative Model Updates: 171,126
Cumulative Timesteps: 1,426,985,144

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1426985144...
Checkpoint 1426985144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,544.41105
Policy Entropy: 3.74676
Value Function Loss: 0.01522

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.37884
Value Function Update Magnitude: 0.40346

Collected Steps per Second: 18,943.49441
Overall Steps per Second: 9,501.43092

Timestep Collection Time: 2.64059
Timestep Consumption Time: 2.62409
PPO Batch Consumption Time: 0.31084
Total Iteration Time: 5.26468

Cumulative Model Updates: 171,132
Cumulative Timesteps: 1,427,035,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,637.89352
Policy Entropy: 3.74894
Value Function Loss: 0.01624

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.38430
Value Function Update Magnitude: 0.36449

Collected Steps per Second: 19,201.79539
Overall Steps per Second: 9,669.45398

Timestep Collection Time: 2.60507
Timestep Consumption Time: 2.56813
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 5.17320

Cumulative Model Updates: 171,138
Cumulative Timesteps: 1,427,085,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1427085188...
Checkpoint 1427085188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,440.64701
Policy Entropy: 3.74617
Value Function Loss: 0.01706

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.40888
Value Function Update Magnitude: 0.39702

Collected Steps per Second: 20,075.64671
Overall Steps per Second: 10,003.71724

Timestep Collection Time: 2.49148
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.99994

Cumulative Model Updates: 171,144
Cumulative Timesteps: 1,427,135,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,537.28114
Policy Entropy: 3.74730
Value Function Loss: 0.01541

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.42249
Value Function Update Magnitude: 0.46493

Collected Steps per Second: 19,683.73019
Overall Steps per Second: 9,651.59196

Timestep Collection Time: 2.54261
Timestep Consumption Time: 2.64286
PPO Batch Consumption Time: 0.30623
Total Iteration Time: 5.18547

Cumulative Model Updates: 171,150
Cumulative Timesteps: 1,427,185,254

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1427185254...
Checkpoint 1427185254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,537.28114
Policy Entropy: 3.72159
Value Function Loss: 0.01348

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.40020
Value Function Update Magnitude: 0.51340

Collected Steps per Second: 19,631.36639
Overall Steps per Second: 9,621.11922

Timestep Collection Time: 2.54725
Timestep Consumption Time: 2.65027
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 5.19752

Cumulative Model Updates: 171,156
Cumulative Timesteps: 1,427,235,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,537.28114
Policy Entropy: 3.74266
Value Function Loss: 0.01191

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.37641
Value Function Update Magnitude: 0.40653

Collected Steps per Second: 19,884.46686
Overall Steps per Second: 9,734.00171

Timestep Collection Time: 2.51533
Timestep Consumption Time: 2.62295
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 5.13828

Cumulative Model Updates: 171,162
Cumulative Timesteps: 1,427,285,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1427285276...
Checkpoint 1427285276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,537.28114
Policy Entropy: 3.72574
Value Function Loss: 0.01250

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.38105
Value Function Update Magnitude: 0.30747

Collected Steps per Second: 19,021.62937
Overall Steps per Second: 9,505.58707

Timestep Collection Time: 2.62932
Timestep Consumption Time: 2.63221
PPO Batch Consumption Time: 0.30341
Total Iteration Time: 5.26154

Cumulative Model Updates: 171,168
Cumulative Timesteps: 1,427,335,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,537.28114
Policy Entropy: 3.73844
Value Function Loss: 0.01230

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.39701
Value Function Update Magnitude: 0.28141

Collected Steps per Second: 19,849.36101
Overall Steps per Second: 9,646.33610

Timestep Collection Time: 2.52038
Timestep Consumption Time: 2.66583
PPO Batch Consumption Time: 0.30998
Total Iteration Time: 5.18622

Cumulative Model Updates: 171,174
Cumulative Timesteps: 1,427,385,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1427385318...
Checkpoint 1427385318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779,197.65400
Policy Entropy: 3.72652
Value Function Loss: 0.01596

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.44739
Value Function Update Magnitude: 0.45650

Collected Steps per Second: 19,290.50279
Overall Steps per Second: 9,581.08868

Timestep Collection Time: 2.59350
Timestep Consumption Time: 2.62824
PPO Batch Consumption Time: 0.30673
Total Iteration Time: 5.22174

Cumulative Model Updates: 171,180
Cumulative Timesteps: 1,427,435,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,205.37178
Policy Entropy: 3.75845
Value Function Loss: 0.01665

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.75925

Collected Steps per Second: 19,485.50567
Overall Steps per Second: 9,633.90784

Timestep Collection Time: 2.56683
Timestep Consumption Time: 2.62483
PPO Batch Consumption Time: 0.30062
Total Iteration Time: 5.19166

Cumulative Model Updates: 171,186
Cumulative Timesteps: 1,427,485,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1427485364...
Checkpoint 1427485364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,531.96439
Policy Entropy: 3.76484
Value Function Loss: 0.02042

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.60208
Value Function Update Magnitude: 0.77526

Collected Steps per Second: 19,097.26565
Overall Steps per Second: 9,553.26901

Timestep Collection Time: 2.61870
Timestep Consumption Time: 2.61616
PPO Batch Consumption Time: 0.29938
Total Iteration Time: 5.23486

Cumulative Model Updates: 171,192
Cumulative Timesteps: 1,427,535,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,088.43046
Policy Entropy: 3.79641
Value Function Loss: 0.02195

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11738
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.66319

Collected Steps per Second: 19,100.24966
Overall Steps per Second: 9,192.42611

Timestep Collection Time: 2.61944
Timestep Consumption Time: 2.82330
PPO Batch Consumption Time: 0.31739
Total Iteration Time: 5.44274

Cumulative Model Updates: 171,198
Cumulative Timesteps: 1,427,585,406

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1427585406...
Checkpoint 1427585406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,562.34649
Policy Entropy: 3.76243
Value Function Loss: 0.02424

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.69818

Collected Steps per Second: 18,850.26356
Overall Steps per Second: 9,575.42443

Timestep Collection Time: 2.65365
Timestep Consumption Time: 2.57035
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 5.22400

Cumulative Model Updates: 171,204
Cumulative Timesteps: 1,427,635,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,065.83001
Policy Entropy: 3.76195
Value Function Loss: 0.02152

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.60358
Value Function Update Magnitude: 0.66368

Collected Steps per Second: 19,072.58252
Overall Steps per Second: 9,771.23925

Timestep Collection Time: 2.62219
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 5.11829

Cumulative Model Updates: 171,210
Cumulative Timesteps: 1,427,685,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1427685440...
Checkpoint 1427685440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335,987.63025
Policy Entropy: 3.76687
Value Function Loss: 0.02232

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.63798
Value Function Update Magnitude: 0.68579

Collected Steps per Second: 19,539.31502
Overall Steps per Second: 9,739.16443

Timestep Collection Time: 2.55976
Timestep Consumption Time: 2.57579
PPO Batch Consumption Time: 0.30813
Total Iteration Time: 5.13555

Cumulative Model Updates: 171,216
Cumulative Timesteps: 1,427,735,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,726.43806
Policy Entropy: 3.79602
Value Function Loss: 0.02172

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.65028
Value Function Update Magnitude: 0.63947

Collected Steps per Second: 19,573.33848
Overall Steps per Second: 9,638.62759

Timestep Collection Time: 2.55521
Timestep Consumption Time: 2.63370
PPO Batch Consumption Time: 0.31890
Total Iteration Time: 5.18891

Cumulative Model Updates: 171,222
Cumulative Timesteps: 1,427,785,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1427785470...
Checkpoint 1427785470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347,164.60802
Policy Entropy: 3.81554
Value Function Loss: 0.02160

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.62277
Value Function Update Magnitude: 0.61838

Collected Steps per Second: 17,799.20330
Overall Steps per Second: 9,436.19971

Timestep Collection Time: 2.81069
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 5.30171

Cumulative Model Updates: 171,228
Cumulative Timesteps: 1,427,835,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,847.27312
Policy Entropy: 3.81502
Value Function Loss: 0.01853

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07011
Policy Update Magnitude: 0.71763
Value Function Update Magnitude: 0.74708

Collected Steps per Second: 18,198.44095
Overall Steps per Second: 9,345.04735

Timestep Collection Time: 2.74826
Timestep Consumption Time: 2.60367
PPO Batch Consumption Time: 0.31279
Total Iteration Time: 5.35193

Cumulative Model Updates: 171,234
Cumulative Timesteps: 1,427,885,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1427885512...
Checkpoint 1427885512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200,152.20111
Policy Entropy: 3.80547
Value Function Loss: 0.01963

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11544
Policy Update Magnitude: 0.77187
Value Function Update Magnitude: 0.82329

Collected Steps per Second: 18,131.51359
Overall Steps per Second: 9,304.39022

Timestep Collection Time: 2.75807
Timestep Consumption Time: 2.61660
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 5.37467

Cumulative Model Updates: 171,240
Cumulative Timesteps: 1,427,935,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,796.20438
Policy Entropy: 3.78538
Value Function Loss: 0.02520

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.68932
Value Function Update Magnitude: 0.80222

Collected Steps per Second: 20,172.35615
Overall Steps per Second: 9,920.58731

Timestep Collection Time: 2.48003
Timestep Consumption Time: 2.56282
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 5.04285

Cumulative Model Updates: 171,246
Cumulative Timesteps: 1,427,985,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1427985548...
Checkpoint 1427985548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,607.19925
Policy Entropy: 3.80737
Value Function Loss: 0.02693

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13671
Policy Update Magnitude: 0.64955
Value Function Update Magnitude: 0.68477

Collected Steps per Second: 20,250.22497
Overall Steps per Second: 9,881.21458

Timestep Collection Time: 2.46931
Timestep Consumption Time: 2.59121
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 5.06051

Cumulative Model Updates: 171,252
Cumulative Timesteps: 1,428,035,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,469.11629
Policy Entropy: 3.81690
Value Function Loss: 0.02628

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.64996
Value Function Update Magnitude: 0.53093

Collected Steps per Second: 20,067.87195
Overall Steps per Second: 9,843.36625

Timestep Collection Time: 2.49154
Timestep Consumption Time: 2.58802
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 5.07956

Cumulative Model Updates: 171,258
Cumulative Timesteps: 1,428,085,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1428085552...
Checkpoint 1428085552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,149.22970
Policy Entropy: 3.83215
Value Function Loss: 0.02312

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.66269
Value Function Update Magnitude: 0.47790

Collected Steps per Second: 20,627.47705
Overall Steps per Second: 9,969.94384

Timestep Collection Time: 2.42444
Timestep Consumption Time: 2.59164
PPO Batch Consumption Time: 0.30193
Total Iteration Time: 5.01608

Cumulative Model Updates: 171,264
Cumulative Timesteps: 1,428,135,562

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,337.80102
Policy Entropy: 3.82507
Value Function Loss: 0.02528

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.67099
Value Function Update Magnitude: 0.49704

Collected Steps per Second: 20,115.17526
Overall Steps per Second: 9,862.82802

Timestep Collection Time: 2.48668
Timestep Consumption Time: 2.58489
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 5.07157

Cumulative Model Updates: 171,270
Cumulative Timesteps: 1,428,185,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1428185582...
Checkpoint 1428185582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,637.95783
Policy Entropy: 3.82039
Value Function Loss: 0.02523

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.73305
Value Function Update Magnitude: 0.50381

Collected Steps per Second: 20,464.10422
Overall Steps per Second: 10,035.58619

Timestep Collection Time: 2.44438
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.98446

Cumulative Model Updates: 171,276
Cumulative Timesteps: 1,428,235,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,870.66383
Policy Entropy: 3.80697
Value Function Loss: 0.02542

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.63073
Value Function Update Magnitude: 0.57478

Collected Steps per Second: 20,528.80160
Overall Steps per Second: 10,084.94553

Timestep Collection Time: 2.43570
Timestep Consumption Time: 2.52238
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.95808

Cumulative Model Updates: 171,282
Cumulative Timesteps: 1,428,285,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1428285606...
Checkpoint 1428285606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,688.28040
Policy Entropy: 3.78931
Value Function Loss: 0.02272

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.59550
Value Function Update Magnitude: 0.58836

Collected Steps per Second: 20,500.98031
Overall Steps per Second: 10,111.71215

Timestep Collection Time: 2.44105
Timestep Consumption Time: 2.50806
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.94911

Cumulative Model Updates: 171,288
Cumulative Timesteps: 1,428,335,650

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,049.93124
Policy Entropy: 3.79193
Value Function Loss: 0.02285

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.56640

Collected Steps per Second: 20,140.53300
Overall Steps per Second: 9,886.57093

Timestep Collection Time: 2.48484
Timestep Consumption Time: 2.57718
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 5.06202

Cumulative Model Updates: 171,294
Cumulative Timesteps: 1,428,385,696

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1428385696...
Checkpoint 1428385696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.72346
Policy Entropy: 3.78180
Value Function Loss: 0.01948

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.55522

Collected Steps per Second: 20,289.31892
Overall Steps per Second: 10,048.60247

Timestep Collection Time: 2.46524
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.97761

Cumulative Model Updates: 171,300
Cumulative Timesteps: 1,428,435,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,472.72346
Policy Entropy: 3.75100
Value Function Loss: 0.01917

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.53216
Value Function Update Magnitude: 0.48473

Collected Steps per Second: 20,212.57189
Overall Steps per Second: 10,012.99343

Timestep Collection Time: 2.47440
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.99491

Cumulative Model Updates: 171,306
Cumulative Timesteps: 1,428,485,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1428485728...
Checkpoint 1428485728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 469,681.11661
Policy Entropy: 3.75043
Value Function Loss: 0.01833

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.55450
Value Function Update Magnitude: 0.48519

Collected Steps per Second: 20,508.22291
Overall Steps per Second: 9,827.47722

Timestep Collection Time: 2.43873
Timestep Consumption Time: 2.65047
PPO Batch Consumption Time: 0.30941
Total Iteration Time: 5.08920

Cumulative Model Updates: 171,312
Cumulative Timesteps: 1,428,535,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,471.27060
Policy Entropy: 3.77022
Value Function Loss: 0.01967

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06575
Policy Update Magnitude: 0.65925
Value Function Update Magnitude: 0.54523

Collected Steps per Second: 20,311.18730
Overall Steps per Second: 10,007.78730

Timestep Collection Time: 2.46308
Timestep Consumption Time: 2.53583
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.99891

Cumulative Model Updates: 171,318
Cumulative Timesteps: 1,428,585,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1428585770...
Checkpoint 1428585770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,360.88070
Policy Entropy: 3.80843
Value Function Loss: 0.01879

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05827
Policy Update Magnitude: 0.67315
Value Function Update Magnitude: 0.64255

Collected Steps per Second: 20,382.19156
Overall Steps per Second: 9,901.36988

Timestep Collection Time: 2.45440
Timestep Consumption Time: 2.59803
PPO Batch Consumption Time: 0.30092
Total Iteration Time: 5.05243

Cumulative Model Updates: 171,324
Cumulative Timesteps: 1,428,635,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.18608
Policy Entropy: 3.80040
Value Function Loss: 0.01675

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.63567

Collected Steps per Second: 19,297.41792
Overall Steps per Second: 9,492.01328

Timestep Collection Time: 2.59123
Timestep Consumption Time: 2.67678
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 5.26801

Cumulative Model Updates: 171,330
Cumulative Timesteps: 1,428,685,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1428685800...
Checkpoint 1428685800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,917.78401
Policy Entropy: 3.78591
Value Function Loss: 0.01585

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.48455
Value Function Update Magnitude: 0.58738

Collected Steps per Second: 18,139.94794
Overall Steps per Second: 9,244.63668

Timestep Collection Time: 2.75800
Timestep Consumption Time: 2.65379
PPO Batch Consumption Time: 0.30880
Total Iteration Time: 5.41179

Cumulative Model Updates: 171,336
Cumulative Timesteps: 1,428,735,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197,917.78401
Policy Entropy: 3.76665
Value Function Loss: 0.01288

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.47270
Value Function Update Magnitude: 0.52461

Collected Steps per Second: 17,633.87803
Overall Steps per Second: 9,262.07981

Timestep Collection Time: 2.83693
Timestep Consumption Time: 2.56424
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 5.40116

Cumulative Model Updates: 171,342
Cumulative Timesteps: 1,428,785,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1428785856...
Checkpoint 1428785856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,281.75799
Policy Entropy: 3.72623
Value Function Loss: 0.01916

Mean KL Divergence: 0.02982
SB3 Clip Fraction: 0.28616
Policy Update Magnitude: 0.44312
Value Function Update Magnitude: 0.51913

Collected Steps per Second: 17,580.43344
Overall Steps per Second: 9,142.96529

Timestep Collection Time: 2.84453
Timestep Consumption Time: 2.62503
PPO Batch Consumption Time: 0.30078
Total Iteration Time: 5.46956

Cumulative Model Updates: 171,348
Cumulative Timesteps: 1,428,835,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,057.89337
Policy Entropy: 3.76305
Value Function Loss: 0.02411

Mean KL Divergence: 0.02123
SB3 Clip Fraction: 0.24190
Policy Update Magnitude: 0.42624
Value Function Update Magnitude: 0.54425

Collected Steps per Second: 20,099.38534
Overall Steps per Second: 9,873.02209

Timestep Collection Time: 2.48833
Timestep Consumption Time: 2.57739
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 5.06572

Cumulative Model Updates: 171,354
Cumulative Timesteps: 1,428,885,878

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1428885878...
Checkpoint 1428885878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,151.03566
Policy Entropy: 3.77041
Value Function Loss: 0.04399

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17178
Policy Update Magnitude: 0.49885
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 20,075.69531
Overall Steps per Second: 9,955.04366

Timestep Collection Time: 2.49117
Timestep Consumption Time: 2.53261
PPO Batch Consumption Time: 0.30441
Total Iteration Time: 5.02379

Cumulative Model Updates: 171,360
Cumulative Timesteps: 1,428,935,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.74965
Policy Entropy: 3.86530
Value Function Loss: 0.04490

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.17344
Policy Update Magnitude: 0.66564
Value Function Update Magnitude: 0.64282

Collected Steps per Second: 18,917.23677
Overall Steps per Second: 9,655.74150

Timestep Collection Time: 2.64510
Timestep Consumption Time: 2.53710
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 5.18220

Cumulative Model Updates: 171,366
Cumulative Timesteps: 1,428,985,928

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1428985928...
Checkpoint 1428985928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,764.42180
Policy Entropy: 3.88625
Value Function Loss: 0.05096

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.71281
Value Function Update Magnitude: 0.55226

Collected Steps per Second: 20,228.42047
Overall Steps per Second: 9,869.97155

Timestep Collection Time: 2.47197
Timestep Consumption Time: 2.59431
PPO Batch Consumption Time: 0.30111
Total Iteration Time: 5.06628

Cumulative Model Updates: 171,372
Cumulative Timesteps: 1,429,035,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 197.35184
Policy Entropy: 3.91469
Value Function Loss: 0.03830

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.72175
Value Function Update Magnitude: 0.54341

Collected Steps per Second: 19,419.58108
Overall Steps per Second: 9,304.30701

Timestep Collection Time: 2.57596
Timestep Consumption Time: 2.80048
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 5.37643

Cumulative Model Updates: 171,378
Cumulative Timesteps: 1,429,085,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1429085956...
Checkpoint 1429085956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,448.25110
Policy Entropy: 3.86815
Value Function Loss: 0.04297

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.69548
Value Function Update Magnitude: 0.51577

Collected Steps per Second: 19,535.47820
Overall Steps per Second: 9,481.85000

Timestep Collection Time: 2.56139
Timestep Consumption Time: 2.71585
PPO Batch Consumption Time: 0.31167
Total Iteration Time: 5.27724

Cumulative Model Updates: 171,384
Cumulative Timesteps: 1,429,135,994

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,692.40574
Policy Entropy: 3.89284
Value Function Loss: 0.04501

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.78793
Value Function Update Magnitude: 0.58996

Collected Steps per Second: 19,542.35816
Overall Steps per Second: 9,525.06043

Timestep Collection Time: 2.55865
Timestep Consumption Time: 2.69087
PPO Batch Consumption Time: 0.30273
Total Iteration Time: 5.24952

Cumulative Model Updates: 171,390
Cumulative Timesteps: 1,429,185,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1429185996...
Checkpoint 1429185996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,308.25666
Policy Entropy: 3.89013
Value Function Loss: 0.04316

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.83653
Value Function Update Magnitude: 0.66913

Collected Steps per Second: 20,948.01499
Overall Steps per Second: 10,222.57761

Timestep Collection Time: 2.38686
Timestep Consumption Time: 2.50427
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.89113

Cumulative Model Updates: 171,396
Cumulative Timesteps: 1,429,235,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,435.05344
Policy Entropy: 3.86208
Value Function Loss: 0.03928

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.79656
Value Function Update Magnitude: 0.67252

Collected Steps per Second: 19,348.92230
Overall Steps per Second: 9,742.35142

Timestep Collection Time: 2.58516
Timestep Consumption Time: 2.54913
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 5.13428

Cumulative Model Updates: 171,402
Cumulative Timesteps: 1,429,286,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1429286016...
Checkpoint 1429286016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,401.38934
Policy Entropy: 3.84438
Value Function Loss: 0.03509

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.77973
Value Function Update Magnitude: 0.57377

Collected Steps per Second: 20,437.38355
Overall Steps per Second: 9,993.87569

Timestep Collection Time: 2.44679
Timestep Consumption Time: 2.55687
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 5.00366

Cumulative Model Updates: 171,408
Cumulative Timesteps: 1,429,336,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,236.03324
Policy Entropy: 3.83289
Value Function Loss: 0.03620

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.77941
Value Function Update Magnitude: 0.54904

Collected Steps per Second: 19,868.91552
Overall Steps per Second: 9,801.04878

Timestep Collection Time: 2.51790
Timestep Consumption Time: 2.58645
PPO Batch Consumption Time: 0.29922
Total Iteration Time: 5.10435

Cumulative Model Updates: 171,414
Cumulative Timesteps: 1,429,386,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1429386050...
Checkpoint 1429386050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.98419
Policy Entropy: 3.85039
Value Function Loss: 0.03466

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.67834
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 18,497.10794
Overall Steps per Second: 9,474.95949

Timestep Collection Time: 2.70323
Timestep Consumption Time: 2.57405
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 5.27728

Cumulative Model Updates: 171,420
Cumulative Timesteps: 1,429,436,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,608.86611
Policy Entropy: 3.86250
Value Function Loss: 0.03701

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10691
Policy Update Magnitude: 0.63740
Value Function Update Magnitude: 0.64092

Collected Steps per Second: 18,615.00370
Overall Steps per Second: 9,579.65901

Timestep Collection Time: 2.68848
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 5.22419

Cumulative Model Updates: 171,426
Cumulative Timesteps: 1,429,486,098

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1429486098...
Checkpoint 1429486098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,914.51408
Policy Entropy: 3.87614
Value Function Loss: 0.03480

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.68518
Value Function Update Magnitude: 0.76075

Collected Steps per Second: 18,814.20910
Overall Steps per Second: 9,429.86563

Timestep Collection Time: 2.65874
Timestep Consumption Time: 2.64590
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 5.30464

Cumulative Model Updates: 171,432
Cumulative Timesteps: 1,429,536,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.52438
Policy Entropy: 3.87366
Value Function Loss: 0.03115

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.68747
Value Function Update Magnitude: 0.79490

Collected Steps per Second: 20,656.69916
Overall Steps per Second: 10,021.11278

Timestep Collection Time: 2.42120
Timestep Consumption Time: 2.56966
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.99086

Cumulative Model Updates: 171,438
Cumulative Timesteps: 1,429,586,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1429586134...
Checkpoint 1429586134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,707.93421
Policy Entropy: 3.84304
Value Function Loss: 0.02755

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.65453
Value Function Update Magnitude: 0.67142

Collected Steps per Second: 18,128.47185
Overall Steps per Second: 8,407.21947

Timestep Collection Time: 2.75820
Timestep Consumption Time: 3.18930
PPO Batch Consumption Time: 0.39067
Total Iteration Time: 5.94751

Cumulative Model Updates: 171,444
Cumulative Timesteps: 1,429,636,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,684.27272
Policy Entropy: 3.82936
Value Function Loss: 0.02314

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.58974
Value Function Update Magnitude: 0.64883

Collected Steps per Second: 18,374.44887
Overall Steps per Second: 8,641.11270

Timestep Collection Time: 2.72128
Timestep Consumption Time: 3.06524
PPO Batch Consumption Time: 0.37050
Total Iteration Time: 5.78652

Cumulative Model Updates: 171,450
Cumulative Timesteps: 1,429,686,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1429686138...
Checkpoint 1429686138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,276.26153
Policy Entropy: 3.83354
Value Function Loss: 0.02669

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.77616

Collected Steps per Second: 18,027.13297
Overall Steps per Second: 8,747.23409

Timestep Collection Time: 2.77437
Timestep Consumption Time: 2.94332
PPO Batch Consumption Time: 0.36106
Total Iteration Time: 5.71769

Cumulative Model Updates: 171,456
Cumulative Timesteps: 1,429,736,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,407.77363
Policy Entropy: 3.87491
Value Function Loss: 0.02608

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.86905

Collected Steps per Second: 18,440.75696
Overall Steps per Second: 9,042.46692

Timestep Collection Time: 2.71149
Timestep Consumption Time: 2.81819
PPO Batch Consumption Time: 0.34193
Total Iteration Time: 5.52969

Cumulative Model Updates: 171,462
Cumulative Timesteps: 1,429,786,154

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1429786154...
Checkpoint 1429786154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,480.15112
Policy Entropy: 3.85171
Value Function Loss: 0.03023

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.96430

Collected Steps per Second: 17,601.67795
Overall Steps per Second: 8,413.87703

Timestep Collection Time: 2.84166
Timestep Consumption Time: 3.10304
PPO Batch Consumption Time: 0.38639
Total Iteration Time: 5.94470

Cumulative Model Updates: 171,468
Cumulative Timesteps: 1,429,836,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.00256
Policy Entropy: 3.84767
Value Function Loss: 0.02616

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.50948
Value Function Update Magnitude: 0.98698

Collected Steps per Second: 16,538.92991
Overall Steps per Second: 8,207.58810

Timestep Collection Time: 3.02498
Timestep Consumption Time: 3.07059
PPO Batch Consumption Time: 0.38411
Total Iteration Time: 6.09558

Cumulative Model Updates: 171,474
Cumulative Timesteps: 1,429,886,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1429886202...
Checkpoint 1429886202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,303.40481
Policy Entropy: 3.79197
Value Function Loss: 0.02621

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.50893
Value Function Update Magnitude: 0.96552

Collected Steps per Second: 17,937.61541
Overall Steps per Second: 8,642.00611

Timestep Collection Time: 2.78800
Timestep Consumption Time: 2.99885
PPO Batch Consumption Time: 0.37116
Total Iteration Time: 5.78685

Cumulative Model Updates: 171,480
Cumulative Timesteps: 1,429,936,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,611.18018
Policy Entropy: 3.82155
Value Function Loss: 0.02095

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.50889
Value Function Update Magnitude: 0.91902

Collected Steps per Second: 17,538.98689
Overall Steps per Second: 8,322.27012

Timestep Collection Time: 2.85079
Timestep Consumption Time: 3.15718
PPO Batch Consumption Time: 0.37827
Total Iteration Time: 6.00798

Cumulative Model Updates: 171,486
Cumulative Timesteps: 1,429,986,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1429986212...
Checkpoint 1429986212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,197.01216
Policy Entropy: 3.79249
Value Function Loss: 0.02184

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.51402
Value Function Update Magnitude: 0.83788

Collected Steps per Second: 18,171.30526
Overall Steps per Second: 8,517.93530

Timestep Collection Time: 2.75159
Timestep Consumption Time: 3.11838
PPO Batch Consumption Time: 0.37415
Total Iteration Time: 5.86997

Cumulative Model Updates: 171,492
Cumulative Timesteps: 1,430,036,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,635.34775
Policy Entropy: 3.82728
Value Function Loss: 0.01738

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.47772
Value Function Update Magnitude: 0.66990

Collected Steps per Second: 17,505.09898
Overall Steps per Second: 8,493.04462

Timestep Collection Time: 2.85802
Timestep Consumption Time: 3.03268
PPO Batch Consumption Time: 0.36206
Total Iteration Time: 5.89070

Cumulative Model Updates: 171,498
Cumulative Timesteps: 1,430,086,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1430086242...
Checkpoint 1430086242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,625.78056
Policy Entropy: 3.78987
Value Function Loss: 0.01915

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.45455
Value Function Update Magnitude: 0.65692

Collected Steps per Second: 17,212.34768
Overall Steps per Second: 8,359.93503

Timestep Collection Time: 2.90640
Timestep Consumption Time: 3.07762
PPO Batch Consumption Time: 0.37044
Total Iteration Time: 5.98402

Cumulative Model Updates: 171,504
Cumulative Timesteps: 1,430,136,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,165.32637
Policy Entropy: 3.80074
Value Function Loss: 0.01970

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.45849
Value Function Update Magnitude: 0.70048

Collected Steps per Second: 17,691.26357
Overall Steps per Second: 8,387.34600

Timestep Collection Time: 2.82705
Timestep Consumption Time: 3.13599
PPO Batch Consumption Time: 0.36608
Total Iteration Time: 5.96303

Cumulative Model Updates: 171,510
Cumulative Timesteps: 1,430,186,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1430186282...
Checkpoint 1430186282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,540.69002
Policy Entropy: 3.78181
Value Function Loss: 0.02279

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.48677
Value Function Update Magnitude: 0.72456

Collected Steps per Second: 17,118.44484
Overall Steps per Second: 8,231.12867

Timestep Collection Time: 2.92305
Timestep Consumption Time: 3.15607
PPO Batch Consumption Time: 0.38546
Total Iteration Time: 6.07912

Cumulative Model Updates: 171,516
Cumulative Timesteps: 1,430,236,320

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.54952
Policy Entropy: 3.80868
Value Function Loss: 0.02639

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.50638
Value Function Update Magnitude: 0.63313

Collected Steps per Second: 16,605.01868
Overall Steps per Second: 8,095.84918

Timestep Collection Time: 3.01210
Timestep Consumption Time: 3.16588
PPO Batch Consumption Time: 0.36920
Total Iteration Time: 6.17798

Cumulative Model Updates: 171,522
Cumulative Timesteps: 1,430,286,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1430286336...
Checkpoint 1430286336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585.17898
Policy Entropy: 3.79786
Value Function Loss: 0.02998

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.52368
Value Function Update Magnitude: 0.46835

Collected Steps per Second: 16,409.02890
Overall Steps per Second: 7,949.94270

Timestep Collection Time: 3.04808
Timestep Consumption Time: 3.24329
PPO Batch Consumption Time: 0.37717
Total Iteration Time: 6.29137

Cumulative Model Updates: 171,528
Cumulative Timesteps: 1,430,336,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,182.13435
Policy Entropy: 3.79823
Value Function Loss: 0.02776

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.54027
Value Function Update Magnitude: 0.43605

Collected Steps per Second: 16,078.86001
Overall Steps per Second: 8,011.52160

Timestep Collection Time: 3.11154
Timestep Consumption Time: 3.13322
PPO Batch Consumption Time: 0.37098
Total Iteration Time: 6.24476

Cumulative Model Updates: 171,534
Cumulative Timesteps: 1,430,386,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1430386382...
Checkpoint 1430386382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,290.19684
Policy Entropy: 3.78870
Value Function Loss: 0.02363

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.50321
Value Function Update Magnitude: 0.54895

Collected Steps per Second: 17,774.48721
Overall Steps per Second: 8,483.75421

Timestep Collection Time: 2.81370
Timestep Consumption Time: 3.08134
PPO Batch Consumption Time: 0.38633
Total Iteration Time: 5.89503

Cumulative Model Updates: 171,540
Cumulative Timesteps: 1,430,436,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,658.60088
Policy Entropy: 3.79689
Value Function Loss: 0.02043

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.46795
Value Function Update Magnitude: 0.64359

Collected Steps per Second: 16,426.54836
Overall Steps per Second: 8,104.89672

Timestep Collection Time: 3.04410
Timestep Consumption Time: 3.12551
PPO Batch Consumption Time: 0.38894
Total Iteration Time: 6.16960

Cumulative Model Updates: 171,546
Cumulative Timesteps: 1,430,486,398

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1430486398...
Checkpoint 1430486398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,875.71158
Policy Entropy: 3.78740
Value Function Loss: 0.02007

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.44709
Value Function Update Magnitude: 0.63588

Collected Steps per Second: 17,971.30737
Overall Steps per Second: 8,505.41386

Timestep Collection Time: 2.78244
Timestep Consumption Time: 3.09664
PPO Batch Consumption Time: 0.37693
Total Iteration Time: 5.87908

Cumulative Model Updates: 171,552
Cumulative Timesteps: 1,430,536,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,990.84654
Policy Entropy: 3.80327
Value Function Loss: 0.02454

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.46734
Value Function Update Magnitude: 0.49453

Collected Steps per Second: 18,017.26405
Overall Steps per Second: 8,400.25608

Timestep Collection Time: 2.77689
Timestep Consumption Time: 3.17912
PPO Batch Consumption Time: 0.37741
Total Iteration Time: 5.95601

Cumulative Model Updates: 171,558
Cumulative Timesteps: 1,430,586,434

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1430586434...
Checkpoint 1430586434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,394.26969
Policy Entropy: 3.80391
Value Function Loss: 0.02716

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.53969
Value Function Update Magnitude: 0.47819

Collected Steps per Second: 19,034.34494
Overall Steps per Second: 9,509.91139

Timestep Collection Time: 2.62767
Timestep Consumption Time: 2.63168
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 5.25936

Cumulative Model Updates: 171,564
Cumulative Timesteps: 1,430,636,450

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,188.74000
Policy Entropy: 3.81015
Value Function Loss: 0.02525

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.57712
Value Function Update Magnitude: 0.65423

Collected Steps per Second: 20,330.93375
Overall Steps per Second: 9,792.86225

Timestep Collection Time: 2.46009
Timestep Consumption Time: 2.64730
PPO Batch Consumption Time: 0.30692
Total Iteration Time: 5.10739

Cumulative Model Updates: 171,570
Cumulative Timesteps: 1,430,686,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1430686466...
Checkpoint 1430686466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,284.07446
Policy Entropy: 3.80289
Value Function Loss: 0.02212

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.55669
Value Function Update Magnitude: 0.77990

Collected Steps per Second: 19,244.07426
Overall Steps per Second: 9,558.98676

Timestep Collection Time: 2.59893
Timestep Consumption Time: 2.63321
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 5.23214

Cumulative Model Updates: 171,576
Cumulative Timesteps: 1,430,736,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,664.36269
Policy Entropy: 3.78709
Value Function Loss: 0.01906

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.51183
Value Function Update Magnitude: 0.67371

Collected Steps per Second: 19,740.26031
Overall Steps per Second: 9,391.89057

Timestep Collection Time: 2.53441
Timestep Consumption Time: 2.79252
PPO Batch Consumption Time: 0.31288
Total Iteration Time: 5.32694

Cumulative Model Updates: 171,582
Cumulative Timesteps: 1,430,786,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1430786510...
Checkpoint 1430786510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,043.48231
Policy Entropy: 3.79239
Value Function Loss: 0.01744

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.44520
Value Function Update Magnitude: 0.62111

Collected Steps per Second: 19,207.96841
Overall Steps per Second: 9,445.93614

Timestep Collection Time: 2.60340
Timestep Consumption Time: 2.69052
PPO Batch Consumption Time: 0.31235
Total Iteration Time: 5.29392

Cumulative Model Updates: 171,588
Cumulative Timesteps: 1,430,836,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,754.57344
Policy Entropy: 3.77289
Value Function Loss: 0.01639

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.42923
Value Function Update Magnitude: 0.62983

Collected Steps per Second: 19,593.58533
Overall Steps per Second: 9,661.96904

Timestep Collection Time: 2.55216
Timestep Consumption Time: 2.62339
PPO Batch Consumption Time: 0.30350
Total Iteration Time: 5.17555

Cumulative Model Updates: 171,594
Cumulative Timesteps: 1,430,886,522

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1430886522...
Checkpoint 1430886522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,830.49419
Policy Entropy: 3.76841
Value Function Loss: 0.01521

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.44980
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 19,355.17087
Overall Steps per Second: 9,703.87858

Timestep Collection Time: 2.58329
Timestep Consumption Time: 2.56929
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 5.15258

Cumulative Model Updates: 171,600
Cumulative Timesteps: 1,430,936,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,830.32650
Policy Entropy: 3.75594
Value Function Loss: 0.01376

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.43494
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 19,607.96614
Overall Steps per Second: 9,734.14116

Timestep Collection Time: 2.55049
Timestep Consumption Time: 2.58709
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 5.13759

Cumulative Model Updates: 171,606
Cumulative Timesteps: 1,430,986,532

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1430986532...
Checkpoint 1430986532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,365.35960
Policy Entropy: 3.76157
Value Function Loss: 0.01522

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.43853
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 19,797.42587
Overall Steps per Second: 9,646.66328

Timestep Collection Time: 2.52659
Timestep Consumption Time: 2.65862
PPO Batch Consumption Time: 0.30678
Total Iteration Time: 5.18521

Cumulative Model Updates: 171,612
Cumulative Timesteps: 1,431,036,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,939.32660
Policy Entropy: 3.78418
Value Function Loss: 0.01681

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.78856

Collected Steps per Second: 20,321.04142
Overall Steps per Second: 9,856.43449

Timestep Collection Time: 2.46188
Timestep Consumption Time: 2.61379
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.07567

Cumulative Model Updates: 171,618
Cumulative Timesteps: 1,431,086,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1431086580...
Checkpoint 1431086580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,636.39765
Policy Entropy: 3.77954
Value Function Loss: 0.01830

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.51149
Value Function Update Magnitude: 0.81123

Collected Steps per Second: 17,759.33155
Overall Steps per Second: 9,421.11227

Timestep Collection Time: 2.81621
Timestep Consumption Time: 2.49251
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 5.30872

Cumulative Model Updates: 171,624
Cumulative Timesteps: 1,431,136,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,689.46151
Policy Entropy: 3.79025
Value Function Loss: 0.02013

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.79112

Collected Steps per Second: 19,851.98075
Overall Steps per Second: 10,005.93401

Timestep Collection Time: 2.51894
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.99763

Cumulative Model Updates: 171,630
Cumulative Timesteps: 1,431,186,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1431186600...
Checkpoint 1431186600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,294.81056
Policy Entropy: 3.79407
Value Function Loss: 0.02181

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.52885
Value Function Update Magnitude: 0.81168

Collected Steps per Second: 19,548.67123
Overall Steps per Second: 9,875.99991

Timestep Collection Time: 2.55772
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 5.06278

Cumulative Model Updates: 171,636
Cumulative Timesteps: 1,431,236,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,557.25364
Policy Entropy: 3.79433
Value Function Loss: 0.02188

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.49562
Value Function Update Magnitude: 0.87154

Collected Steps per Second: 20,051.37092
Overall Steps per Second: 9,474.35151

Timestep Collection Time: 2.49499
Timestep Consumption Time: 2.78537
PPO Batch Consumption Time: 0.32773
Total Iteration Time: 5.28036

Cumulative Model Updates: 171,642
Cumulative Timesteps: 1,431,286,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1431286628...
Checkpoint 1431286628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,557.25364
Policy Entropy: 3.77118
Value Function Loss: 0.01992

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.49437
Value Function Update Magnitude: 0.84467

Collected Steps per Second: 19,366.79548
Overall Steps per Second: 9,734.72012

Timestep Collection Time: 2.58215
Timestep Consumption Time: 2.55492
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 5.13708

Cumulative Model Updates: 171,648
Cumulative Timesteps: 1,431,336,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,557.25364
Policy Entropy: 3.73739
Value Function Loss: 0.01652

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.50626
Value Function Update Magnitude: 0.70566

Collected Steps per Second: 18,816.56457
Overall Steps per Second: 9,428.55062

Timestep Collection Time: 2.65819
Timestep Consumption Time: 2.64676
PPO Batch Consumption Time: 0.31573
Total Iteration Time: 5.30495

Cumulative Model Updates: 171,654
Cumulative Timesteps: 1,431,386,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1431386654...
Checkpoint 1431386654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,864.92004
Policy Entropy: 3.73576
Value Function Loss: 0.01538

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.45063
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 19,319.16245
Overall Steps per Second: 9,137.64298

Timestep Collection Time: 2.59017
Timestep Consumption Time: 2.88607
PPO Batch Consumption Time: 0.33962
Total Iteration Time: 5.47625

Cumulative Model Updates: 171,660
Cumulative Timesteps: 1,431,436,694

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,864.92004
Policy Entropy: 3.72960
Value Function Loss: 0.01396

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.40933
Value Function Update Magnitude: 0.50604

Collected Steps per Second: 19,983.12225
Overall Steps per Second: 9,819.45267

Timestep Collection Time: 2.50211
Timestep Consumption Time: 2.58982
PPO Batch Consumption Time: 0.29814
Total Iteration Time: 5.09193

Cumulative Model Updates: 171,666
Cumulative Timesteps: 1,431,486,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1431486694...
Checkpoint 1431486694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,864.92004
Policy Entropy: 3.72835
Value Function Loss: 0.01464

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.42766
Value Function Update Magnitude: 0.52433

Collected Steps per Second: 18,912.98834
Overall Steps per Second: 9,692.60391

Timestep Collection Time: 2.64443
Timestep Consumption Time: 2.51559
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 5.16002

Cumulative Model Updates: 171,672
Cumulative Timesteps: 1,431,536,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,864.92004
Policy Entropy: 3.72771
Value Function Loss: 0.01399

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.47385
Value Function Update Magnitude: 0.52908

Collected Steps per Second: 20,329.06908
Overall Steps per Second: 9,938.23269

Timestep Collection Time: 2.45953
Timestep Consumption Time: 2.57154
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 5.03108

Cumulative Model Updates: 171,678
Cumulative Timesteps: 1,431,586,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1431586708...
Checkpoint 1431586708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,864.92004
Policy Entropy: 3.73001
Value Function Loss: 0.01598

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.47771
Value Function Update Magnitude: 0.50962

Collected Steps per Second: 17,705.46955
Overall Steps per Second: 9,090.72917

Timestep Collection Time: 2.82512
Timestep Consumption Time: 2.67719
PPO Batch Consumption Time: 0.31231
Total Iteration Time: 5.50231

Cumulative Model Updates: 171,684
Cumulative Timesteps: 1,431,636,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,004.95761
Policy Entropy: 3.73872
Value Function Loss: 0.01600

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.48369
Value Function Update Magnitude: 0.57312

Collected Steps per Second: 19,265.20120
Overall Steps per Second: 9,770.92569

Timestep Collection Time: 2.59743
Timestep Consumption Time: 2.52389
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 5.12132

Cumulative Model Updates: 171,690
Cumulative Timesteps: 1,431,686,768

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1431686768...
Checkpoint 1431686768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,816.64469
Policy Entropy: 3.75707
Value Function Loss: 0.01602

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.45011
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 20,000.09119
Overall Steps per Second: 9,853.92695

Timestep Collection Time: 2.50029
Timestep Consumption Time: 2.57444
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 5.07473

Cumulative Model Updates: 171,696
Cumulative Timesteps: 1,431,736,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,539.52300
Policy Entropy: 3.76147
Value Function Loss: 0.01871

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.46507
Value Function Update Magnitude: 0.60718

Collected Steps per Second: 20,459.24169
Overall Steps per Second: 9,739.17867

Timestep Collection Time: 2.44398
Timestep Consumption Time: 2.69013
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 5.13411

Cumulative Model Updates: 171,702
Cumulative Timesteps: 1,431,786,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1431786776...
Checkpoint 1431786776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,564.91496
Policy Entropy: 3.76202
Value Function Loss: 0.01870

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.52033
Value Function Update Magnitude: 0.68595

Collected Steps per Second: 18,441.48684
Overall Steps per Second: 9,071.51741

Timestep Collection Time: 2.71290
Timestep Consumption Time: 2.80216
PPO Batch Consumption Time: 0.30820
Total Iteration Time: 5.51506

Cumulative Model Updates: 171,708
Cumulative Timesteps: 1,431,836,806

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,471.67784
Policy Entropy: 3.74124
Value Function Loss: 0.02142

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.64046

Collected Steps per Second: 18,597.41334
Overall Steps per Second: 9,435.80872

Timestep Collection Time: 2.68898
Timestep Consumption Time: 2.61083
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 5.29981

Cumulative Model Updates: 171,714
Cumulative Timesteps: 1,431,886,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1431886814...
Checkpoint 1431886814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,471.67784
Policy Entropy: 3.74174
Value Function Loss: 0.01766

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.60353
Value Function Update Magnitude: 0.68286

Collected Steps per Second: 20,175.84737
Overall Steps per Second: 9,962.62621

Timestep Collection Time: 2.47940
Timestep Consumption Time: 2.54177
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 5.02117

Cumulative Model Updates: 171,720
Cumulative Timesteps: 1,431,936,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,471.67784
Policy Entropy: 3.72919
Value Function Loss: 0.02116

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.61646
Value Function Update Magnitude: 0.66493

Collected Steps per Second: 19,975.33933
Overall Steps per Second: 9,916.76877

Timestep Collection Time: 2.50399
Timestep Consumption Time: 2.53979
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 5.04378

Cumulative Model Updates: 171,726
Cumulative Timesteps: 1,431,986,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1431986856...
Checkpoint 1431986856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,811.61067
Policy Entropy: 3.75369
Value Function Loss: 0.02029

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.67689
Value Function Update Magnitude: 0.74619

Collected Steps per Second: 20,100.70038
Overall Steps per Second: 9,885.67002

Timestep Collection Time: 2.48887
Timestep Consumption Time: 2.57179
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 5.06066

Cumulative Model Updates: 171,732
Cumulative Timesteps: 1,432,036,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,098.81033
Policy Entropy: 3.74173
Value Function Loss: 0.02435

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.62974
Value Function Update Magnitude: 0.78677

Collected Steps per Second: 19,883.14479
Overall Steps per Second: 9,387.89830

Timestep Collection Time: 2.51590
Timestep Consumption Time: 2.81266
PPO Batch Consumption Time: 0.32488
Total Iteration Time: 5.32856

Cumulative Model Updates: 171,738
Cumulative Timesteps: 1,432,086,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1432086908...
Checkpoint 1432086908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,734.96270
Policy Entropy: 3.75055
Value Function Loss: 0.01984

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.62353

Collected Steps per Second: 20,110.93409
Overall Steps per Second: 9,525.31525

Timestep Collection Time: 2.48800
Timestep Consumption Time: 2.76495
PPO Batch Consumption Time: 0.31990
Total Iteration Time: 5.25295

Cumulative Model Updates: 171,744
Cumulative Timesteps: 1,432,136,944

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,883.33973
Policy Entropy: 3.73401
Value Function Loss: 0.01873

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.49177
Value Function Update Magnitude: 0.49544

Collected Steps per Second: 20,149.87436
Overall Steps per Second: 9,954.72844

Timestep Collection Time: 2.48220
Timestep Consumption Time: 2.54215
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 5.02435

Cumulative Model Updates: 171,750
Cumulative Timesteps: 1,432,186,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1432186960...
Checkpoint 1432186960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,883.33973
Policy Entropy: 3.73453
Value Function Loss: 0.01734

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.44838
Value Function Update Magnitude: 0.58086

Collected Steps per Second: 19,959.07341
Overall Steps per Second: 9,802.17355

Timestep Collection Time: 2.50683
Timestep Consumption Time: 2.59755
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 5.10438

Cumulative Model Updates: 171,756
Cumulative Timesteps: 1,432,236,994

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,883.33973
Policy Entropy: 3.72640
Value Function Loss: 0.02016

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.48806
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 20,304.68225
Overall Steps per Second: 10,057.71101

Timestep Collection Time: 2.46387
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.97409

Cumulative Model Updates: 171,762
Cumulative Timesteps: 1,432,287,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1432287022...
Checkpoint 1432287022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,647.10786
Policy Entropy: 3.73116
Value Function Loss: 0.01880

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.60839

Collected Steps per Second: 20,338.55857
Overall Steps per Second: 9,905.83477

Timestep Collection Time: 2.45966
Timestep Consumption Time: 2.59049
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 5.05015

Cumulative Model Updates: 171,768
Cumulative Timesteps: 1,432,337,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,391.07695
Policy Entropy: 3.75590
Value Function Loss: 0.01766

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.52286
Value Function Update Magnitude: 0.69069

Collected Steps per Second: 19,671.98745
Overall Steps per Second: 9,985.80495

Timestep Collection Time: 2.54179
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 5.00731

Cumulative Model Updates: 171,774
Cumulative Timesteps: 1,432,387,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1432387050...
Checkpoint 1432387050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,992.33458
Policy Entropy: 3.76468
Value Function Loss: 0.01585

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.50661
Value Function Update Magnitude: 0.70606

Collected Steps per Second: 19,517.92908
Overall Steps per Second: 9,912.26714

Timestep Collection Time: 2.56308
Timestep Consumption Time: 2.48380
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 5.04688

Cumulative Model Updates: 171,780
Cumulative Timesteps: 1,432,437,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,992.33458
Policy Entropy: 3.75838
Value Function Loss: 0.01755

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12316
Policy Update Magnitude: 0.52080
Value Function Update Magnitude: 0.70919

Collected Steps per Second: 19,548.45952
Overall Steps per Second: 9,898.30972

Timestep Collection Time: 2.55775
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 5.05137

Cumulative Model Updates: 171,786
Cumulative Timesteps: 1,432,487,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1432487076...
Checkpoint 1432487076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281,162.37903
Policy Entropy: 3.76008
Value Function Loss: 0.01986

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12595
Policy Update Magnitude: 0.56709
Value Function Update Magnitude: 0.78132

Collected Steps per Second: 19,951.84884
Overall Steps per Second: 9,926.63895

Timestep Collection Time: 2.50744
Timestep Consumption Time: 2.53234
PPO Batch Consumption Time: 0.30479
Total Iteration Time: 5.03977

Cumulative Model Updates: 171,792
Cumulative Timesteps: 1,432,537,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,613.49105
Policy Entropy: 3.74725
Value Function Loss: 0.02116

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.60261
Value Function Update Magnitude: 0.91799

Collected Steps per Second: 18,120.12982
Overall Steps per Second: 9,390.29257

Timestep Collection Time: 2.76036
Timestep Consumption Time: 2.56621
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 5.32656

Cumulative Model Updates: 171,798
Cumulative Timesteps: 1,432,587,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1432587122...
Checkpoint 1432587122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,098.73500
Policy Entropy: 3.74258
Value Function Loss: 0.01925

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.61474
Value Function Update Magnitude: 0.91844

Collected Steps per Second: 15,959.79273
Overall Steps per Second: 8,714.61547

Timestep Collection Time: 3.13400
Timestep Consumption Time: 2.60555
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 5.73955

Cumulative Model Updates: 171,804
Cumulative Timesteps: 1,432,637,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,098.73500
Policy Entropy: 3.73224
Value Function Loss: 0.01763

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.74632

Collected Steps per Second: 17,888.99552
Overall Steps per Second: 9,277.76259

Timestep Collection Time: 2.79602
Timestep Consumption Time: 2.59515
PPO Batch Consumption Time: 0.30370
Total Iteration Time: 5.39117

Cumulative Model Updates: 171,810
Cumulative Timesteps: 1,432,687,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1432687158...
Checkpoint 1432687158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,254.91829
Policy Entropy: 3.73270
Value Function Loss: 0.01857

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.54709
Value Function Update Magnitude: 0.60777

Collected Steps per Second: 18,139.52097
Overall Steps per Second: 9,338.32796

Timestep Collection Time: 2.75862
Timestep Consumption Time: 2.59994
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 5.35856

Cumulative Model Updates: 171,816
Cumulative Timesteps: 1,432,737,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,940.72357
Policy Entropy: 3.74246
Value Function Loss: 0.01735

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.53326
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 19,295.52030
Overall Steps per Second: 9,627.88663

Timestep Collection Time: 2.59304
Timestep Consumption Time: 2.60374
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 5.19678

Cumulative Model Updates: 171,822
Cumulative Timesteps: 1,432,787,232

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1432787232...
Checkpoint 1432787232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,664.71514
Policy Entropy: 3.73498
Value Function Loss: 0.01937

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.49043
Value Function Update Magnitude: 0.52371

Collected Steps per Second: 19,393.97023
Overall Steps per Second: 9,475.52223

Timestep Collection Time: 2.57853
Timestep Consumption Time: 2.69906
PPO Batch Consumption Time: 0.31463
Total Iteration Time: 5.27760

Cumulative Model Updates: 171,828
Cumulative Timesteps: 1,432,837,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,664.71514
Policy Entropy: 3.74105
Value Function Loss: 0.01790

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.47877
Value Function Update Magnitude: 0.44403

Collected Steps per Second: 18,923.46279
Overall Steps per Second: 9,703.49938

Timestep Collection Time: 2.64360
Timestep Consumption Time: 2.51186
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 5.15546

Cumulative Model Updates: 171,834
Cumulative Timesteps: 1,432,887,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1432887266...
Checkpoint 1432887266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355,994.61492
Policy Entropy: 3.72654
Value Function Loss: 0.02082

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.49541
Value Function Update Magnitude: 0.49780

Collected Steps per Second: 19,358.59652
Overall Steps per Second: 9,824.48832

Timestep Collection Time: 2.58387
Timestep Consumption Time: 2.50749
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 5.09136

Cumulative Model Updates: 171,840
Cumulative Timesteps: 1,432,937,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,249.77464
Policy Entropy: 3.74182
Value Function Loss: 0.01900

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.52056
Value Function Update Magnitude: 0.59405

Collected Steps per Second: 18,593.62664
Overall Steps per Second: 9,371.99485

Timestep Collection Time: 2.69049
Timestep Consumption Time: 2.64733
PPO Batch Consumption Time: 0.30620
Total Iteration Time: 5.33782

Cumulative Model Updates: 171,846
Cumulative Timesteps: 1,432,987,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1432987312...
Checkpoint 1432987312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,550.72591
Policy Entropy: 3.74147
Value Function Loss: 0.01927

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.65731

Collected Steps per Second: 19,922.22057
Overall Steps per Second: 9,719.79954

Timestep Collection Time: 2.51066
Timestep Consumption Time: 2.63533
PPO Batch Consumption Time: 0.30769
Total Iteration Time: 5.14599

Cumulative Model Updates: 171,852
Cumulative Timesteps: 1,433,037,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,662.75996
Policy Entropy: 3.76456
Value Function Loss: 0.01755

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11922
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.68615

Collected Steps per Second: 19,352.07800
Overall Steps per Second: 9,632.45299

Timestep Collection Time: 2.58443
Timestep Consumption Time: 2.60781
PPO Batch Consumption Time: 0.31685
Total Iteration Time: 5.19224

Cumulative Model Updates: 171,858
Cumulative Timesteps: 1,433,087,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1433087344...
Checkpoint 1433087344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,789.52935
Policy Entropy: 3.76470
Value Function Loss: 0.01833

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.51207
Value Function Update Magnitude: 0.57942

Collected Steps per Second: 17,181.10013
Overall Steps per Second: 9,000.87466

Timestep Collection Time: 2.91134
Timestep Consumption Time: 2.64590
PPO Batch Consumption Time: 0.32386
Total Iteration Time: 5.55724

Cumulative Model Updates: 171,864
Cumulative Timesteps: 1,433,137,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,812.29227
Policy Entropy: 3.76899
Value Function Loss: 0.01920

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.51713
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 18,130.33913
Overall Steps per Second: 9,232.35999

Timestep Collection Time: 2.75946
Timestep Consumption Time: 2.65952
PPO Batch Consumption Time: 0.32317
Total Iteration Time: 5.41898

Cumulative Model Updates: 171,870
Cumulative Timesteps: 1,433,187,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1433187394...
Checkpoint 1433187394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,480.26757
Policy Entropy: 3.74899
Value Function Loss: 0.01885

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.55575
Value Function Update Magnitude: 0.68465

Collected Steps per Second: 19,307.02236
Overall Steps per Second: 9,717.39634

Timestep Collection Time: 2.59160
Timestep Consumption Time: 2.55752
PPO Batch Consumption Time: 0.30729
Total Iteration Time: 5.14912

Cumulative Model Updates: 171,876
Cumulative Timesteps: 1,433,237,430

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,061.01615
Policy Entropy: 3.73343
Value Function Loss: 0.01996

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.73955

Collected Steps per Second: 18,924.74902
Overall Steps per Second: 9,487.89226

Timestep Collection Time: 2.64299
Timestep Consumption Time: 2.62878
PPO Batch Consumption Time: 0.30923
Total Iteration Time: 5.27177

Cumulative Model Updates: 171,882
Cumulative Timesteps: 1,433,287,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1433287448...
Checkpoint 1433287448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,758.58717
Policy Entropy: 3.73579
Value Function Loss: 0.02026

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.61707

Collected Steps per Second: 19,450.92562
Overall Steps per Second: 9,697.04755

Timestep Collection Time: 2.57078
Timestep Consumption Time: 2.58584
PPO Batch Consumption Time: 0.30214
Total Iteration Time: 5.15662

Cumulative Model Updates: 171,888
Cumulative Timesteps: 1,433,337,452

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,256.56655
Policy Entropy: 3.74704
Value Function Loss: 0.02156

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.62962
Value Function Update Magnitude: 0.53824

Collected Steps per Second: 19,872.86453
Overall Steps per Second: 9,476.48135

Timestep Collection Time: 2.51650
Timestep Consumption Time: 2.76078
PPO Batch Consumption Time: 0.32618
Total Iteration Time: 5.27728

Cumulative Model Updates: 171,894
Cumulative Timesteps: 1,433,387,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1433387462...
Checkpoint 1433387462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,703.66544
Policy Entropy: 3.74877
Value Function Loss: 0.02063

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.61027
Value Function Update Magnitude: 0.55872

Collected Steps per Second: 19,460.72994
Overall Steps per Second: 9,619.77419

Timestep Collection Time: 2.56928
Timestep Consumption Time: 2.62835
PPO Batch Consumption Time: 0.30643
Total Iteration Time: 5.19763

Cumulative Model Updates: 171,900
Cumulative Timesteps: 1,433,437,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,549.99400
Policy Entropy: 3.76462
Value Function Loss: 0.02055

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12851
Policy Update Magnitude: 0.58845
Value Function Update Magnitude: 0.58403

Collected Steps per Second: 20,196.30133
Overall Steps per Second: 9,888.61135

Timestep Collection Time: 2.47630
Timestep Consumption Time: 2.58124
PPO Batch Consumption Time: 0.30737
Total Iteration Time: 5.05754

Cumulative Model Updates: 171,906
Cumulative Timesteps: 1,433,487,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1433487474...
Checkpoint 1433487474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,317.67375
Policy Entropy: 3.76629
Value Function Loss: 0.01953

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 18,566.81815
Overall Steps per Second: 9,459.95562

Timestep Collection Time: 2.69448
Timestep Consumption Time: 2.59391
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 5.28840

Cumulative Model Updates: 171,912
Cumulative Timesteps: 1,433,537,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,317.67375
Policy Entropy: 3.77683
Value Function Loss: 0.01764

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.63394

Collected Steps per Second: 18,440.51307
Overall Steps per Second: 9,246.57817

Timestep Collection Time: 2.71294
Timestep Consumption Time: 2.69749
PPO Batch Consumption Time: 0.32040
Total Iteration Time: 5.41043

Cumulative Model Updates: 171,918
Cumulative Timesteps: 1,433,587,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1433587530...
Checkpoint 1433587530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,317.67375
Policy Entropy: 3.75511
Value Function Loss: 0.01686

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.50931
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 19,221.61160
Overall Steps per Second: 9,507.48462

Timestep Collection Time: 2.60165
Timestep Consumption Time: 2.65820
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 5.25986

Cumulative Model Updates: 171,924
Cumulative Timesteps: 1,433,637,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,137.51324
Policy Entropy: 3.74256
Value Function Loss: 0.01848

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.48591
Value Function Update Magnitude: 0.56205

Collected Steps per Second: 18,742.71446
Overall Steps per Second: 9,526.23150

Timestep Collection Time: 2.66856
Timestep Consumption Time: 2.58179
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 5.25034

Cumulative Model Updates: 171,930
Cumulative Timesteps: 1,433,687,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1433687554...
Checkpoint 1433687554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,137.51324
Policy Entropy: 3.74411
Value Function Loss: 0.01763

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.48737
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 19,709.27111
Overall Steps per Second: 9,896.84708

Timestep Collection Time: 2.53840
Timestep Consumption Time: 2.51675
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 5.05515

Cumulative Model Updates: 171,936
Cumulative Timesteps: 1,433,737,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 453,615.17561
Policy Entropy: 3.76234
Value Function Loss: 0.01754

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.50897
Value Function Update Magnitude: 0.57452

Collected Steps per Second: 20,015.53731
Overall Steps per Second: 9,804.16065

Timestep Collection Time: 2.49876
Timestep Consumption Time: 2.60254
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 5.10130

Cumulative Model Updates: 171,942
Cumulative Timesteps: 1,433,787,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1433787598...
Checkpoint 1433787598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,404.62197
Policy Entropy: 3.76237
Value Function Loss: 0.01510

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.58041

Collected Steps per Second: 19,259.95459
Overall Steps per Second: 9,781.73939

Timestep Collection Time: 2.59699
Timestep Consumption Time: 2.51641
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 5.11341

Cumulative Model Updates: 171,948
Cumulative Timesteps: 1,433,837,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,990.59320
Policy Entropy: 3.76512
Value Function Loss: 0.01708

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.46587
Value Function Update Magnitude: 0.58789

Collected Steps per Second: 19,922.27429
Overall Steps per Second: 9,926.61877

Timestep Collection Time: 2.50995
Timestep Consumption Time: 2.52741
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 5.03736

Cumulative Model Updates: 171,954
Cumulative Timesteps: 1,433,887,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1433887620...
Checkpoint 1433887620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,830.02695
Policy Entropy: 3.75172
Value Function Loss: 0.01685

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.47833
Value Function Update Magnitude: 0.57284

Collected Steps per Second: 19,926.88456
Overall Steps per Second: 9,778.91274

Timestep Collection Time: 2.51028
Timestep Consumption Time: 2.60502
PPO Batch Consumption Time: 0.30773
Total Iteration Time: 5.11529

Cumulative Model Updates: 171,960
Cumulative Timesteps: 1,433,937,642

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,830.02695
Policy Entropy: 3.73572
Value Function Loss: 0.01925

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.52051
Value Function Update Magnitude: 0.66622

Collected Steps per Second: 17,295.89399
Overall Steps per Second: 9,293.78895

Timestep Collection Time: 2.89109
Timestep Consumption Time: 2.48928
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 5.38037

Cumulative Model Updates: 171,966
Cumulative Timesteps: 1,433,987,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1433987646...
Checkpoint 1433987646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 553,830.02695
Policy Entropy: 3.73884
Value Function Loss: 0.01732

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.55767
Value Function Update Magnitude: 0.68996

Collected Steps per Second: 20,027.56022
Overall Steps per Second: 9,652.62793

Timestep Collection Time: 2.49766
Timestep Consumption Time: 2.68456
PPO Batch Consumption Time: 0.31329
Total Iteration Time: 5.18222

Cumulative Model Updates: 171,972
Cumulative Timesteps: 1,434,037,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,727.35223
Policy Entropy: 3.72471
Value Function Loss: 0.01968

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.67868

Collected Steps per Second: 19,642.90435
Overall Steps per Second: 9,526.99067

Timestep Collection Time: 2.54586
Timestep Consumption Time: 2.70323
PPO Batch Consumption Time: 0.31524
Total Iteration Time: 5.24909

Cumulative Model Updates: 171,978
Cumulative Timesteps: 1,434,087,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1434087676...
Checkpoint 1434087676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 200,216.16850
Policy Entropy: 3.74814
Value Function Loss: 0.01846

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.76507

Collected Steps per Second: 18,775.78743
Overall Steps per Second: 9,403.23736

Timestep Collection Time: 2.66375
Timestep Consumption Time: 2.65506
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 5.31881

Cumulative Model Updates: 171,984
Cumulative Timesteps: 1,434,137,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,810.07285
Policy Entropy: 3.77275
Value Function Loss: 0.02241

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.60492
Value Function Update Magnitude: 0.74965

Collected Steps per Second: 19,472.95395
Overall Steps per Second: 9,230.59075

Timestep Collection Time: 2.56838
Timestep Consumption Time: 2.84991
PPO Batch Consumption Time: 0.33550
Total Iteration Time: 5.41829

Cumulative Model Updates: 171,990
Cumulative Timesteps: 1,434,187,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1434187704...
Checkpoint 1434187704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,263.33285
Policy Entropy: 3.78964
Value Function Loss: 0.02162

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.60340
Value Function Update Magnitude: 0.69035

Collected Steps per Second: 19,151.27666
Overall Steps per Second: 9,081.02995

Timestep Collection Time: 2.61111
Timestep Consumption Time: 2.89554
PPO Batch Consumption Time: 0.32716
Total Iteration Time: 5.50664

Cumulative Model Updates: 171,996
Cumulative Timesteps: 1,434,237,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,263.33285
Policy Entropy: 3.79031
Value Function Loss: 0.02041

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12525
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.69047

Collected Steps per Second: 19,709.93377
Overall Steps per Second: 9,696.34562

Timestep Collection Time: 2.53781
Timestep Consumption Time: 2.62084
PPO Batch Consumption Time: 0.29905
Total Iteration Time: 5.15864

Cumulative Model Updates: 172,002
Cumulative Timesteps: 1,434,287,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1434287730...
Checkpoint 1434287730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,346.07754
Policy Entropy: 3.77489
Value Function Loss: 0.01845

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.65541

Collected Steps per Second: 19,787.61708
Overall Steps per Second: 9,959.90902

Timestep Collection Time: 2.52724
Timestep Consumption Time: 2.49369
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 5.02093

Cumulative Model Updates: 172,008
Cumulative Timesteps: 1,434,337,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,444.18795
Policy Entropy: 3.77533
Value Function Loss: 0.02103

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.61118

Collected Steps per Second: 20,038.78127
Overall Steps per Second: 9,853.74873

Timestep Collection Time: 2.49636
Timestep Consumption Time: 2.58029
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 5.07665

Cumulative Model Updates: 172,014
Cumulative Timesteps: 1,434,387,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1434387762...
Checkpoint 1434387762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,358.69887
Policy Entropy: 3.77966
Value Function Loss: 0.02265

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 20,336.12714
Overall Steps per Second: 9,446.03002

Timestep Collection Time: 2.45937
Timestep Consumption Time: 2.83534
PPO Batch Consumption Time: 0.34020
Total Iteration Time: 5.29471

Cumulative Model Updates: 172,020
Cumulative Timesteps: 1,434,437,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,799.35679
Policy Entropy: 3.77197
Value Function Loss: 0.02187

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.51413

Collected Steps per Second: 19,671.43410
Overall Steps per Second: 9,956.39136

Timestep Collection Time: 2.54186
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 5.02210

Cumulative Model Updates: 172,026
Cumulative Timesteps: 1,434,487,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1434487778...
Checkpoint 1434487778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,385.31381
Policy Entropy: 3.76783
Value Function Loss: 0.01815

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.52009
Value Function Update Magnitude: 0.52873

Collected Steps per Second: 18,390.97698
Overall Steps per Second: 9,646.89365

Timestep Collection Time: 2.72046
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 5.18633

Cumulative Model Updates: 172,032
Cumulative Timesteps: 1,434,537,810

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,227.61676
Policy Entropy: 3.75962
Value Function Loss: 0.01733

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.53234
Value Function Update Magnitude: 0.54585

Collected Steps per Second: 17,493.85806
Overall Steps per Second: 9,010.39266

Timestep Collection Time: 2.85826
Timestep Consumption Time: 2.69111
PPO Batch Consumption Time: 0.32486
Total Iteration Time: 5.54937

Cumulative Model Updates: 172,038
Cumulative Timesteps: 1,434,587,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1434587812...
Checkpoint 1434587812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,155.28304
Policy Entropy: 3.74344
Value Function Loss: 0.01971

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.53760
Value Function Update Magnitude: 0.46801

Collected Steps per Second: 18,227.39894
Overall Steps per Second: 9,359.23348

Timestep Collection Time: 2.74378
Timestep Consumption Time: 2.59982
PPO Batch Consumption Time: 0.30853
Total Iteration Time: 5.34360

Cumulative Model Updates: 172,044
Cumulative Timesteps: 1,434,637,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,155.28304
Policy Entropy: 3.75264
Value Function Loss: 0.01755

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12273
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.64606

Collected Steps per Second: 18,426.19377
Overall Steps per Second: 9,119.52552

Timestep Collection Time: 2.71592
Timestep Consumption Time: 2.77165
PPO Batch Consumption Time: 0.33036
Total Iteration Time: 5.48757

Cumulative Model Updates: 172,050
Cumulative Timesteps: 1,434,687,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1434687868...
Checkpoint 1434687868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,492.80256
Policy Entropy: 3.73821
Value Function Loss: 0.02134

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.68751

Collected Steps per Second: 19,706.92508
Overall Steps per Second: 9,743.78015

Timestep Collection Time: 2.53860
Timestep Consumption Time: 2.59575
PPO Batch Consumption Time: 0.30695
Total Iteration Time: 5.13435

Cumulative Model Updates: 172,056
Cumulative Timesteps: 1,434,737,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,236.15375
Policy Entropy: 3.76330
Value Function Loss: 0.02097

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 20,109.05919
Overall Steps per Second: 9,910.15061

Timestep Collection Time: 2.48793
Timestep Consumption Time: 2.56043
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 5.04836

Cumulative Model Updates: 172,062
Cumulative Timesteps: 1,434,787,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1434787926...
Checkpoint 1434787926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,353.36136
Policy Entropy: 3.76021
Value Function Loss: 0.02420

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.60311
Value Function Update Magnitude: 0.74190

Collected Steps per Second: 20,187.32608
Overall Steps per Second: 9,926.75210

Timestep Collection Time: 2.47759
Timestep Consumption Time: 2.56091
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 5.03851

Cumulative Model Updates: 172,068
Cumulative Timesteps: 1,434,837,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,178.06741
Policy Entropy: 3.78634
Value Function Loss: 0.02169

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.56560
Value Function Update Magnitude: 0.78660

Collected Steps per Second: 19,739.76984
Overall Steps per Second: 9,635.66952

Timestep Collection Time: 2.53407
Timestep Consumption Time: 2.65726
PPO Batch Consumption Time: 0.31051
Total Iteration Time: 5.19134

Cumulative Model Updates: 172,074
Cumulative Timesteps: 1,434,887,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1434887964...
Checkpoint 1434887964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,823.14447
Policy Entropy: 3.77427
Value Function Loss: 0.02105

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.52420
Value Function Update Magnitude: 0.75473

Collected Steps per Second: 19,216.87857
Overall Steps per Second: 9,488.02211

Timestep Collection Time: 2.60219
Timestep Consumption Time: 2.66824
PPO Batch Consumption Time: 0.30952
Total Iteration Time: 5.27043

Cumulative Model Updates: 172,080
Cumulative Timesteps: 1,434,937,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286,495.38073
Policy Entropy: 3.77395
Value Function Loss: 0.02077

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.85640

Collected Steps per Second: 16,912.77398
Overall Steps per Second: 9,007.50177

Timestep Collection Time: 2.95765
Timestep Consumption Time: 2.59572
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 5.55337

Cumulative Model Updates: 172,086
Cumulative Timesteps: 1,434,987,992

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1434987992...
Checkpoint 1434987992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,317.13505
Policy Entropy: 3.75988
Value Function Loss: 0.02202

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.59983
Value Function Update Magnitude: 0.77170

Collected Steps per Second: 19,966.69929
Overall Steps per Second: 9,789.03652

Timestep Collection Time: 2.50637
Timestep Consumption Time: 2.60588
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 5.11225

Cumulative Model Updates: 172,092
Cumulative Timesteps: 1,435,038,036

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,972.56937
Policy Entropy: 3.78037
Value Function Loss: 0.02046

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.62142
Value Function Update Magnitude: 0.72970

Collected Steps per Second: 19,833.99064
Overall Steps per Second: 9,786.64530

Timestep Collection Time: 2.52213
Timestep Consumption Time: 2.58932
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 5.11146

Cumulative Model Updates: 172,098
Cumulative Timesteps: 1,435,088,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1435088060...
Checkpoint 1435088060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.78256
Value Function Loss: 0.01828

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.59730
Value Function Update Magnitude: 0.72643

Collected Steps per Second: 19,207.64563
Overall Steps per Second: 9,016.93453

Timestep Collection Time: 2.60365
Timestep Consumption Time: 2.94258
PPO Batch Consumption Time: 0.34468
Total Iteration Time: 5.54623

Cumulative Model Updates: 172,104
Cumulative Timesteps: 1,435,138,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.78464
Value Function Loss: 0.01444

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.59139
Value Function Update Magnitude: 0.58365

Collected Steps per Second: 18,533.32262
Overall Steps per Second: 9,065.08551

Timestep Collection Time: 2.69795
Timestep Consumption Time: 2.81794
PPO Batch Consumption Time: 0.33055
Total Iteration Time: 5.51589

Cumulative Model Updates: 172,110
Cumulative Timesteps: 1,435,188,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1435188072...
Checkpoint 1435188072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.76801
Value Function Loss: 0.01342

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.60799
Value Function Update Magnitude: 0.46848

Collected Steps per Second: 15,477.74665
Overall Steps per Second: 8,291.64364

Timestep Collection Time: 3.23044
Timestep Consumption Time: 2.79972
PPO Batch Consumption Time: 0.32528
Total Iteration Time: 6.03017

Cumulative Model Updates: 172,116
Cumulative Timesteps: 1,435,238,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.75779
Value Function Loss: 0.01283

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06331
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.39092

Collected Steps per Second: 16,218.95466
Overall Steps per Second: 8,735.53749

Timestep Collection Time: 3.08540
Timestep Consumption Time: 2.64315
PPO Batch Consumption Time: 0.30536
Total Iteration Time: 5.72855

Cumulative Model Updates: 172,122
Cumulative Timesteps: 1,435,288,114

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1435288114...
Checkpoint 1435288114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.76090
Value Function Loss: 0.01183

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06161
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.37764

Collected Steps per Second: 17,665.38395
Overall Steps per Second: 9,355.00232

Timestep Collection Time: 2.83051
Timestep Consumption Time: 2.51444
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 5.34495

Cumulative Model Updates: 172,128
Cumulative Timesteps: 1,435,338,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.76735
Value Function Loss: 0.01155

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06592
Policy Update Magnitude: 0.55832
Value Function Update Magnitude: 0.39516

Collected Steps per Second: 20,470.49641
Overall Steps per Second: 9,516.61984

Timestep Collection Time: 2.44303
Timestep Consumption Time: 2.81199
PPO Batch Consumption Time: 0.33229
Total Iteration Time: 5.25502

Cumulative Model Updates: 172,134
Cumulative Timesteps: 1,435,388,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1435388126...
Checkpoint 1435388126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.77851
Value Function Loss: 0.01007

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07329
Policy Update Magnitude: 0.52208
Value Function Update Magnitude: 0.38734

Collected Steps per Second: 18,745.05929
Overall Steps per Second: 8,344.87458

Timestep Collection Time: 2.66801
Timestep Consumption Time: 3.32513
PPO Batch Consumption Time: 0.40712
Total Iteration Time: 5.99314

Cumulative Model Updates: 172,140
Cumulative Timesteps: 1,435,438,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.76390
Value Function Loss: 0.01101

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.46882
Value Function Update Magnitude: 0.34645

Collected Steps per Second: 15,071.75403
Overall Steps per Second: 8,231.92302

Timestep Collection Time: 3.31813
Timestep Consumption Time: 2.75700
PPO Batch Consumption Time: 0.32034
Total Iteration Time: 6.07513

Cumulative Model Updates: 172,146
Cumulative Timesteps: 1,435,488,148

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1435488148...
Checkpoint 1435488148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,927.61204
Policy Entropy: 3.77372
Value Function Loss: 0.01317

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16702
Policy Update Magnitude: 0.48459
Value Function Update Magnitude: 0.39056

Collected Steps per Second: 15,403.88683
Overall Steps per Second: 8,391.05822

Timestep Collection Time: 3.24593
Timestep Consumption Time: 2.71279
PPO Batch Consumption Time: 0.32092
Total Iteration Time: 5.95872

Cumulative Model Updates: 172,152
Cumulative Timesteps: 1,435,538,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,209.19815
Policy Entropy: 3.75468
Value Function Loss: 0.01762

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.22660
Policy Update Magnitude: 0.52680
Value Function Update Magnitude: 0.46903

Collected Steps per Second: 17,427.99320
Overall Steps per Second: 9,225.33785

Timestep Collection Time: 2.86906
Timestep Consumption Time: 2.55101
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 5.42007

Cumulative Model Updates: 172,158
Cumulative Timesteps: 1,435,588,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1435588150...
Checkpoint 1435588150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,437.06671
Policy Entropy: 3.76552
Value Function Loss: 0.02404

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.61132
Value Function Update Magnitude: 0.48450

Collected Steps per Second: 19,938.77605
Overall Steps per Second: 9,885.85927

Timestep Collection Time: 2.50778
Timestep Consumption Time: 2.55015
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 5.05793

Cumulative Model Updates: 172,164
Cumulative Timesteps: 1,435,638,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,453.18883
Policy Entropy: 3.78864
Value Function Loss: 0.02615

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.19758
Policy Update Magnitude: 0.68955
Value Function Update Magnitude: 0.51428

Collected Steps per Second: 18,948.32982
Overall Steps per Second: 9,689.58858

Timestep Collection Time: 2.64002
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 5.16265

Cumulative Model Updates: 172,170
Cumulative Timesteps: 1,435,688,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1435688176...
Checkpoint 1435688176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,204.86169
Policy Entropy: 3.78418
Value Function Loss: 0.02274

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.17206
Policy Update Magnitude: 0.66905
Value Function Update Magnitude: 0.51703

Collected Steps per Second: 20,100.35470
Overall Steps per Second: 9,846.19663

Timestep Collection Time: 2.48861
Timestep Consumption Time: 2.59172
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 5.08034

Cumulative Model Updates: 172,176
Cumulative Timesteps: 1,435,738,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,204.86169
Policy Entropy: 3.76263
Value Function Loss: 0.01593

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.50597
Value Function Update Magnitude: 0.48349

Collected Steps per Second: 19,925.10078
Overall Steps per Second: 9,957.41814

Timestep Collection Time: 2.50980
Timestep Consumption Time: 2.51239
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 5.02219

Cumulative Model Updates: 172,182
Cumulative Timesteps: 1,435,788,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1435788206...
Checkpoint 1435788206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,988.95237
Policy Entropy: 3.74380
Value Function Loss: 0.01792

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.50025
Value Function Update Magnitude: 0.52886

Collected Steps per Second: 20,316.48805
Overall Steps per Second: 9,893.90016

Timestep Collection Time: 2.46322
Timestep Consumption Time: 2.59484
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 5.05807

Cumulative Model Updates: 172,188
Cumulative Timesteps: 1,435,838,250

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,525.30140
Policy Entropy: 3.75404
Value Function Loss: 0.01887

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15271
Policy Update Magnitude: 0.51000
Value Function Update Magnitude: 0.60428

Collected Steps per Second: 20,056.59197
Overall Steps per Second: 9,971.30766

Timestep Collection Time: 2.49315
Timestep Consumption Time: 2.52164
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 5.01479

Cumulative Model Updates: 172,194
Cumulative Timesteps: 1,435,888,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1435888254...
Checkpoint 1435888254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,250.53612
Policy Entropy: 3.76577
Value Function Loss: 0.02236

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.47501
Value Function Update Magnitude: 0.62225

Collected Steps per Second: 20,559.15186
Overall Steps per Second: 10,007.85714

Timestep Collection Time: 2.43220
Timestep Consumption Time: 2.56427
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.99647

Cumulative Model Updates: 172,200
Cumulative Timesteps: 1,435,938,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,250.53612
Policy Entropy: 3.77424
Value Function Loss: 0.02044

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14967
Policy Update Magnitude: 0.49734
Value Function Update Magnitude: 0.50101

Collected Steps per Second: 19,588.15459
Overall Steps per Second: 9,922.99916

Timestep Collection Time: 2.55379
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 5.04122

Cumulative Model Updates: 172,206
Cumulative Timesteps: 1,435,988,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1435988282...
Checkpoint 1435988282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374,841.72945
Policy Entropy: 3.73808
Value Function Loss: 0.02737

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.17000
Policy Update Magnitude: 0.46734
Value Function Update Magnitude: 0.37030

Collected Steps per Second: 19,842.17451
Overall Steps per Second: 9,964.49871

Timestep Collection Time: 2.51999
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 5.01801

Cumulative Model Updates: 172,212
Cumulative Timesteps: 1,436,038,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,813.02972
Policy Entropy: 3.78267
Value Function Loss: 0.02398

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15800
Policy Update Magnitude: 0.51258
Value Function Update Magnitude: 0.46813

Collected Steps per Second: 18,818.89723
Overall Steps per Second: 9,536.87161

Timestep Collection Time: 2.65701
Timestep Consumption Time: 2.58601
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 5.24302

Cumulative Model Updates: 172,218
Cumulative Timesteps: 1,436,088,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1436088286...
Checkpoint 1436088286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,000.37930
Policy Entropy: 3.79165
Value Function Loss: 0.02597

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16015
Policy Update Magnitude: 0.51150
Value Function Update Magnitude: 0.69263

Collected Steps per Second: 17,163.66961
Overall Steps per Second: 9,151.21125

Timestep Collection Time: 2.91336
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.30147
Total Iteration Time: 5.46419

Cumulative Model Updates: 172,224
Cumulative Timesteps: 1,436,138,290

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,938.08614
Policy Entropy: 3.79806
Value Function Loss: 0.02602

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.51288
Value Function Update Magnitude: 0.59279

Collected Steps per Second: 19,640.92460
Overall Steps per Second: 9,838.10017

Timestep Collection Time: 2.54642
Timestep Consumption Time: 2.53729
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 5.08371

Cumulative Model Updates: 172,230
Cumulative Timesteps: 1,436,188,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1436188304...
Checkpoint 1436188304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,671.85148
Policy Entropy: 3.76960
Value Function Loss: 0.02456

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.49521
Value Function Update Magnitude: 0.44510

Collected Steps per Second: 17,413.99494
Overall Steps per Second: 9,082.12740

Timestep Collection Time: 2.87160
Timestep Consumption Time: 2.63438
PPO Batch Consumption Time: 0.31117
Total Iteration Time: 5.50598

Cumulative Model Updates: 172,236
Cumulative Timesteps: 1,436,238,310

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,312.93214
Policy Entropy: 3.76775
Value Function Loss: 0.02617

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.48649
Value Function Update Magnitude: 0.36898

Collected Steps per Second: 18,712.74110
Overall Steps per Second: 9,394.14927

Timestep Collection Time: 2.67433
Timestep Consumption Time: 2.65282
PPO Batch Consumption Time: 0.30809
Total Iteration Time: 5.32715

Cumulative Model Updates: 172,242
Cumulative Timesteps: 1,436,288,354

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1436288354...
Checkpoint 1436288354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,961.28526
Policy Entropy: 3.77511
Value Function Loss: 0.02236

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.49963
Value Function Update Magnitude: 0.38976

Collected Steps per Second: 18,672.88364
Overall Steps per Second: 9,314.77920

Timestep Collection Time: 2.67886
Timestep Consumption Time: 2.69132
PPO Batch Consumption Time: 0.31488
Total Iteration Time: 5.37018

Cumulative Model Updates: 172,248
Cumulative Timesteps: 1,436,338,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,791.90764
Policy Entropy: 3.77564
Value Function Loss: 0.02447

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.47278
Value Function Update Magnitude: 0.40305

Collected Steps per Second: 18,749.45394
Overall Steps per Second: 9,302.16775

Timestep Collection Time: 2.66685
Timestep Consumption Time: 2.70846
PPO Batch Consumption Time: 0.31467
Total Iteration Time: 5.37531

Cumulative Model Updates: 172,254
Cumulative Timesteps: 1,436,388,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1436388378...
Checkpoint 1436388378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,458.91571
Policy Entropy: 3.77296
Value Function Loss: 0.02051

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11438
Policy Update Magnitude: 0.46571
Value Function Update Magnitude: 0.51696

Collected Steps per Second: 18,967.37861
Overall Steps per Second: 9,431.89940

Timestep Collection Time: 2.63821
Timestep Consumption Time: 2.66719
PPO Batch Consumption Time: 0.30205
Total Iteration Time: 5.30540

Cumulative Model Updates: 172,260
Cumulative Timesteps: 1,436,438,418

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,103.23149
Policy Entropy: 3.77256
Value Function Loss: 0.02293

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.45520
Value Function Update Magnitude: 0.63304

Collected Steps per Second: 19,759.53673
Overall Steps per Second: 9,645.55181

Timestep Collection Time: 2.53103
Timestep Consumption Time: 2.65395
PPO Batch Consumption Time: 0.30757
Total Iteration Time: 5.18498

Cumulative Model Updates: 172,266
Cumulative Timesteps: 1,436,488,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1436488430...
Checkpoint 1436488430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,247.64435
Policy Entropy: 3.78433
Value Function Loss: 0.02276

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.45778
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 18,750.65343
Overall Steps per Second: 9,696.10388

Timestep Collection Time: 2.66668
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 5.15692

Cumulative Model Updates: 172,272
Cumulative Timesteps: 1,436,538,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,023.71092
Policy Entropy: 3.81240
Value Function Loss: 0.02552

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.48254
Value Function Update Magnitude: 0.67792

Collected Steps per Second: 20,236.08742
Overall Steps per Second: 9,951.13915

Timestep Collection Time: 2.47182
Timestep Consumption Time: 2.55474
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 5.02656

Cumulative Model Updates: 172,278
Cumulative Timesteps: 1,436,588,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1436588452...
Checkpoint 1436588452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,284.81248
Policy Entropy: 3.81673
Value Function Loss: 0.02437

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.70972

Collected Steps per Second: 19,109.87321
Overall Steps per Second: 9,555.23190

Timestep Collection Time: 2.61781
Timestep Consumption Time: 2.61765
PPO Batch Consumption Time: 0.30473
Total Iteration Time: 5.23546

Cumulative Model Updates: 172,284
Cumulative Timesteps: 1,436,638,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,247.57788
Policy Entropy: 3.79717
Value Function Loss: 0.02052

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.52076
Value Function Update Magnitude: 0.75728

Collected Steps per Second: 19,730.82753
Overall Steps per Second: 9,419.37406

Timestep Collection Time: 2.53573
Timestep Consumption Time: 2.77588
PPO Batch Consumption Time: 0.32277
Total Iteration Time: 5.31161

Cumulative Model Updates: 172,290
Cumulative Timesteps: 1,436,688,510

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1436688510...
Checkpoint 1436688510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,952.40239
Policy Entropy: 3.75047
Value Function Loss: 0.02017

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.67926

Collected Steps per Second: 19,488.80101
Overall Steps per Second: 9,428.10205

Timestep Collection Time: 2.56650
Timestep Consumption Time: 2.73870
PPO Batch Consumption Time: 0.31565
Total Iteration Time: 5.30520

Cumulative Model Updates: 172,296
Cumulative Timesteps: 1,436,738,528

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,186.80991
Policy Entropy: 3.74984
Value Function Loss: 0.02345

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.54550
Value Function Update Magnitude: 0.58540

Collected Steps per Second: 20,367.17838
Overall Steps per Second: 9,598.63853

Timestep Collection Time: 2.45621
Timestep Consumption Time: 2.75557
PPO Batch Consumption Time: 0.32028
Total Iteration Time: 5.21178

Cumulative Model Updates: 172,302
Cumulative Timesteps: 1,436,788,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1436788554...
Checkpoint 1436788554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,819.58307
Policy Entropy: 3.76319
Value Function Loss: 0.02387

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.59562
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 17,852.49589
Overall Steps per Second: 9,125.85901

Timestep Collection Time: 2.80252
Timestep Consumption Time: 2.67992
PPO Batch Consumption Time: 0.30520
Total Iteration Time: 5.48244

Cumulative Model Updates: 172,308
Cumulative Timesteps: 1,436,838,586

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,346.76675
Policy Entropy: 3.77136
Value Function Loss: 0.02327

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.66905

Collected Steps per Second: 17,620.12081
Overall Steps per Second: 8,831.79382

Timestep Collection Time: 2.83778
Timestep Consumption Time: 2.82381
PPO Batch Consumption Time: 0.32748
Total Iteration Time: 5.66159

Cumulative Model Updates: 172,314
Cumulative Timesteps: 1,436,888,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1436888588...
Checkpoint 1436888588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,346.76675
Policy Entropy: 3.75320
Value Function Loss: 0.01774

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.47111
Value Function Update Magnitude: 0.52490

Collected Steps per Second: 18,465.16898
Overall Steps per Second: 9,530.77339

Timestep Collection Time: 2.71018
Timestep Consumption Time: 2.54060
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 5.25078

Cumulative Model Updates: 172,320
Cumulative Timesteps: 1,436,938,632

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,346.76675
Policy Entropy: 3.73353
Value Function Loss: 0.01620

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.40255
Value Function Update Magnitude: 0.38830

Collected Steps per Second: 19,868.01834
Overall Steps per Second: 9,788.37590

Timestep Collection Time: 2.51661
Timestep Consumption Time: 2.59149
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 5.10810

Cumulative Model Updates: 172,326
Cumulative Timesteps: 1,436,988,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1436988632...
Checkpoint 1436988632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,346.76675
Policy Entropy: 3.73920
Value Function Loss: 0.01375

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.35456
Value Function Update Magnitude: 0.27816

Collected Steps per Second: 18,510.87262
Overall Steps per Second: 9,279.30169

Timestep Collection Time: 2.70176
Timestep Consumption Time: 2.68787
PPO Batch Consumption Time: 0.31581
Total Iteration Time: 5.38963

Cumulative Model Updates: 172,332
Cumulative Timesteps: 1,437,038,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,220.98866
Policy Entropy: 3.75107
Value Function Loss: 0.01357

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.33820
Value Function Update Magnitude: 0.26569

Collected Steps per Second: 17,839.49032
Overall Steps per Second: 9,095.53996

Timestep Collection Time: 2.80322
Timestep Consumption Time: 2.69486
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 5.49808

Cumulative Model Updates: 172,338
Cumulative Timesteps: 1,437,088,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1437088652...
Checkpoint 1437088652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,920.82197
Policy Entropy: 3.75448
Value Function Loss: 0.01255

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.34600
Value Function Update Magnitude: 0.35298

Collected Steps per Second: 19,529.85044
Overall Steps per Second: 9,655.10081

Timestep Collection Time: 2.56080
Timestep Consumption Time: 2.61905
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 5.17985

Cumulative Model Updates: 172,344
Cumulative Timesteps: 1,437,138,664

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,046.83276
Policy Entropy: 3.76492
Value Function Loss: 0.01366

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.36466
Value Function Update Magnitude: 0.43140

Collected Steps per Second: 18,322.99811
Overall Steps per Second: 9,205.82685

Timestep Collection Time: 2.73034
Timestep Consumption Time: 2.70404
PPO Batch Consumption Time: 0.31606
Total Iteration Time: 5.43438

Cumulative Model Updates: 172,350
Cumulative Timesteps: 1,437,188,692

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1437188692...
Checkpoint 1437188692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,450.75833
Policy Entropy: 3.76132
Value Function Loss: 0.01324

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.39341
Value Function Update Magnitude: 0.45454

Collected Steps per Second: 19,862.37897
Overall Steps per Second: 9,806.27556

Timestep Collection Time: 2.51762
Timestep Consumption Time: 2.58176
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 5.09939

Cumulative Model Updates: 172,356
Cumulative Timesteps: 1,437,238,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,634.76889
Policy Entropy: 3.76369
Value Function Loss: 0.01610

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12565
Policy Update Magnitude: 0.41208
Value Function Update Magnitude: 0.43610

Collected Steps per Second: 16,425.75407
Overall Steps per Second: 9,100.72636

Timestep Collection Time: 3.04485
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 5.49561

Cumulative Model Updates: 172,362
Cumulative Timesteps: 1,437,288,712

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437288712...
Checkpoint 1437288712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,216.23928
Policy Entropy: 3.75346
Value Function Loss: 0.01574

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12103
Policy Update Magnitude: 0.45110
Value Function Update Magnitude: 0.50104

Collected Steps per Second: 16,972.43453
Overall Steps per Second: 8,960.07246

Timestep Collection Time: 2.94772
Timestep Consumption Time: 2.63594
PPO Batch Consumption Time: 0.32015
Total Iteration Time: 5.58366

Cumulative Model Updates: 172,368
Cumulative Timesteps: 1,437,338,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,752.82341
Policy Entropy: 3.75347
Value Function Loss: 0.01568

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.63645

Collected Steps per Second: 18,054.50216
Overall Steps per Second: 9,246.90580

Timestep Collection Time: 2.77094
Timestep Consumption Time: 2.63930
PPO Batch Consumption Time: 0.32032
Total Iteration Time: 5.41024

Cumulative Model Updates: 172,374
Cumulative Timesteps: 1,437,388,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1437388770...
Checkpoint 1437388770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,721.15772
Policy Entropy: 3.75514
Value Function Loss: 0.01584

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.49313
Value Function Update Magnitude: 0.59677

Collected Steps per Second: 12,687.58847
Overall Steps per Second: 7,302.81065

Timestep Collection Time: 3.94307
Timestep Consumption Time: 2.90745
PPO Batch Consumption Time: 0.32799
Total Iteration Time: 6.85051

Cumulative Model Updates: 172,380
Cumulative Timesteps: 1,437,438,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,738.06382
Policy Entropy: 3.75897
Value Function Loss: 0.01662

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.47763
Value Function Update Magnitude: 0.47426

Collected Steps per Second: 16,670.36916
Overall Steps per Second: 8,881.34908

Timestep Collection Time: 3.00113
Timestep Consumption Time: 2.63202
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 5.63315

Cumulative Model Updates: 172,386
Cumulative Timesteps: 1,437,488,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1437488828...
Checkpoint 1437488828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,738.06382
Policy Entropy: 3.75648
Value Function Loss: 0.01443

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.46114
Value Function Update Magnitude: 0.49241

Collected Steps per Second: 18,206.35001
Overall Steps per Second: 9,241.30619

Timestep Collection Time: 2.74871
Timestep Consumption Time: 2.66654
PPO Batch Consumption Time: 0.31740
Total Iteration Time: 5.41525

Cumulative Model Updates: 172,392
Cumulative Timesteps: 1,437,538,872

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,738.06382
Policy Entropy: 3.75251
Value Function Loss: 0.01608

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.46153
Value Function Update Magnitude: 0.47169

Collected Steps per Second: 20,125.05589
Overall Steps per Second: 9,618.61834

Timestep Collection Time: 2.48516
Timestep Consumption Time: 2.71455
PPO Batch Consumption Time: 0.31952
Total Iteration Time: 5.19971

Cumulative Model Updates: 172,398
Cumulative Timesteps: 1,437,588,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437588886...
Checkpoint 1437588886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,994.54640
Policy Entropy: 3.75692
Value Function Loss: 0.01571

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.45108
Value Function Update Magnitude: 0.43727

Collected Steps per Second: 19,222.31701
Overall Steps per Second: 9,269.79618

Timestep Collection Time: 2.60218
Timestep Consumption Time: 2.79384
PPO Batch Consumption Time: 0.33215
Total Iteration Time: 5.39602

Cumulative Model Updates: 172,404
Cumulative Timesteps: 1,437,638,906

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,538.22060
Policy Entropy: 3.77544
Value Function Loss: 0.01817

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.42910
Value Function Update Magnitude: 0.39545

Collected Steps per Second: 18,347.80466
Overall Steps per Second: 9,327.72494

Timestep Collection Time: 2.72588
Timestep Consumption Time: 2.63598
PPO Batch Consumption Time: 0.30551
Total Iteration Time: 5.36186

Cumulative Model Updates: 172,410
Cumulative Timesteps: 1,437,688,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437688920...
Checkpoint 1437688920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,338.34593
Policy Entropy: 3.77580
Value Function Loss: 0.01774

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.45734
Value Function Update Magnitude: 0.54113

Collected Steps per Second: 17,693.87892
Overall Steps per Second: 9,234.30996

Timestep Collection Time: 2.82753
Timestep Consumption Time: 2.59031
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 5.41784

Cumulative Model Updates: 172,416
Cumulative Timesteps: 1,437,738,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,338.34593
Policy Entropy: 3.74485
Value Function Loss: 0.01928

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13356
Policy Update Magnitude: 0.47997
Value Function Update Magnitude: 0.55018

Collected Steps per Second: 18,543.37403
Overall Steps per Second: 9,518.22861

Timestep Collection Time: 2.69692
Timestep Consumption Time: 2.55721
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 5.25413

Cumulative Model Updates: 172,422
Cumulative Timesteps: 1,437,788,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1437788960...
Checkpoint 1437788960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,518.38034
Policy Entropy: 3.73060
Value Function Loss: 0.01877

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.47641
Value Function Update Magnitude: 0.50042

Collected Steps per Second: 18,283.14841
Overall Steps per Second: 9,373.68338

Timestep Collection Time: 2.73640
Timestep Consumption Time: 2.60088
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 5.33728

Cumulative Model Updates: 172,428
Cumulative Timesteps: 1,437,838,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,849.09326
Policy Entropy: 3.73023
Value Function Loss: 0.01916

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.48610
Value Function Update Magnitude: 0.45097

Collected Steps per Second: 17,845.65192
Overall Steps per Second: 9,266.20993

Timestep Collection Time: 2.80236
Timestep Consumption Time: 2.59467
PPO Batch Consumption Time: 0.30966
Total Iteration Time: 5.39703

Cumulative Model Updates: 172,434
Cumulative Timesteps: 1,437,889,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1437889000...
Checkpoint 1437889000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,983.30933
Policy Entropy: 3.74940
Value Function Loss: 0.01868

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.49805
Value Function Update Magnitude: 0.44891

Collected Steps per Second: 18,922.46387
Overall Steps per Second: 9,851.98928

Timestep Collection Time: 2.64289
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 5.07613

Cumulative Model Updates: 172,440
Cumulative Timesteps: 1,437,939,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,702.83873
Policy Entropy: 3.76889
Value Function Loss: 0.02083

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.51672
Value Function Update Magnitude: 0.61605

Collected Steps per Second: 19,377.76757
Overall Steps per Second: 10,004.97007

Timestep Collection Time: 2.58038
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.99772

Cumulative Model Updates: 172,446
Cumulative Timesteps: 1,437,989,012

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1437989012...
Checkpoint 1437989012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,822.96056
Policy Entropy: 3.78942
Value Function Loss: 0.01880

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.53310
Value Function Update Magnitude: 0.78164

Collected Steps per Second: 19,612.70824
Overall Steps per Second: 9,724.63760

Timestep Collection Time: 2.54957
Timestep Consumption Time: 2.59242
PPO Batch Consumption Time: 0.31628
Total Iteration Time: 5.14199

Cumulative Model Updates: 172,452
Cumulative Timesteps: 1,438,039,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,375.28512
Policy Entropy: 3.79228
Value Function Loss: 0.02406

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.53317
Value Function Update Magnitude: 0.73787

Collected Steps per Second: 18,151.01422
Overall Steps per Second: 9,738.13232

Timestep Collection Time: 2.75555
Timestep Consumption Time: 2.38055
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 5.13610

Cumulative Model Updates: 172,458
Cumulative Timesteps: 1,438,089,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1438089032...
Checkpoint 1438089032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,816.07094
Policy Entropy: 3.81900
Value Function Loss: 0.02548

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.59242
Value Function Update Magnitude: 0.79778

Collected Steps per Second: 18,661.24230
Overall Steps per Second: 9,450.78991

Timestep Collection Time: 2.68192
Timestep Consumption Time: 2.61372
PPO Batch Consumption Time: 0.30595
Total Iteration Time: 5.29564

Cumulative Model Updates: 172,464
Cumulative Timesteps: 1,438,139,080

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,232.94017
Policy Entropy: 3.81252
Value Function Loss: 0.02858

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.64722
Value Function Update Magnitude: 0.90401

Collected Steps per Second: 19,087.00105
Overall Steps per Second: 9,299.79860

Timestep Collection Time: 2.62063
Timestep Consumption Time: 2.75798
PPO Batch Consumption Time: 0.32541
Total Iteration Time: 5.37861

Cumulative Model Updates: 172,470
Cumulative Timesteps: 1,438,189,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1438189100...
Checkpoint 1438189100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,128.56301
Policy Entropy: 3.82753
Value Function Loss: 0.02467

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12391
Policy Update Magnitude: 0.62781
Value Function Update Magnitude: 0.93625

Collected Steps per Second: 17,782.21464
Overall Steps per Second: 9,185.23132

Timestep Collection Time: 2.81360
Timestep Consumption Time: 2.63341
PPO Batch Consumption Time: 0.30902
Total Iteration Time: 5.44700

Cumulative Model Updates: 172,476
Cumulative Timesteps: 1,438,239,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,038.49774
Policy Entropy: 3.81656
Value Function Loss: 0.02491

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.94328

Collected Steps per Second: 20,199.35619
Overall Steps per Second: 9,709.30408

Timestep Collection Time: 2.47671
Timestep Consumption Time: 2.67587
PPO Batch Consumption Time: 0.31797
Total Iteration Time: 5.15258

Cumulative Model Updates: 172,482
Cumulative Timesteps: 1,438,289,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1438289160...
Checkpoint 1438289160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.93699
Policy Entropy: 3.81110
Value Function Loss: 0.02345

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.60305
Value Function Update Magnitude: 0.89307

Collected Steps per Second: 18,551.62704
Overall Steps per Second: 9,365.20813

Timestep Collection Time: 2.69529
Timestep Consumption Time: 2.64383
PPO Batch Consumption Time: 0.31471
Total Iteration Time: 5.33912

Cumulative Model Updates: 172,488
Cumulative Timesteps: 1,438,339,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,699.63868
Policy Entropy: 3.79348
Value Function Loss: 0.02588

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.58353
Value Function Update Magnitude: 0.71743

Collected Steps per Second: 18,440.86611
Overall Steps per Second: 9,333.03785

Timestep Collection Time: 2.71376
Timestep Consumption Time: 2.64827
PPO Batch Consumption Time: 0.31321
Total Iteration Time: 5.36203

Cumulative Model Updates: 172,494
Cumulative Timesteps: 1,438,389,206

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1438389206...
Checkpoint 1438389206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.15443
Policy Entropy: 3.79553
Value Function Loss: 0.02535

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 18,735.96053
Overall Steps per Second: 9,385.52382

Timestep Collection Time: 2.66984
Timestep Consumption Time: 2.65986
PPO Batch Consumption Time: 0.31190
Total Iteration Time: 5.32970

Cumulative Model Updates: 172,500
Cumulative Timesteps: 1,438,439,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,171.25944
Policy Entropy: 3.83509
Value Function Loss: 0.02506

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11967
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.69162

Collected Steps per Second: 19,333.37218
Overall Steps per Second: 9,603.62110

Timestep Collection Time: 2.58620
Timestep Consumption Time: 2.62017
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 5.20637

Cumulative Model Updates: 172,506
Cumulative Timesteps: 1,438,489,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1438489228...
Checkpoint 1438489228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,369.69967
Policy Entropy: 3.83019
Value Function Loss: 0.02341

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.81540

Collected Steps per Second: 18,671.20973
Overall Steps per Second: 9,389.78184

Timestep Collection Time: 2.67995
Timestep Consumption Time: 2.64903
PPO Batch Consumption Time: 0.31104
Total Iteration Time: 5.32898

Cumulative Model Updates: 172,512
Cumulative Timesteps: 1,438,539,266

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.24829
Policy Entropy: 3.80893
Value Function Loss: 0.02246

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.89566

Collected Steps per Second: 19,926.43375
Overall Steps per Second: 9,761.62002

Timestep Collection Time: 2.51063
Timestep Consumption Time: 2.61433
PPO Batch Consumption Time: 0.30902
Total Iteration Time: 5.12497

Cumulative Model Updates: 172,518
Cumulative Timesteps: 1,438,589,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1438589294...
Checkpoint 1438589294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491.86301
Policy Entropy: 3.77572
Value Function Loss: 0.01863

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.81431

Collected Steps per Second: 18,920.10783
Overall Steps per Second: 9,334.41817

Timestep Collection Time: 2.64311
Timestep Consumption Time: 2.71426
PPO Batch Consumption Time: 0.31350
Total Iteration Time: 5.35738

Cumulative Model Updates: 172,524
Cumulative Timesteps: 1,438,639,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,506.64501
Policy Entropy: 3.78240
Value Function Loss: 0.02054

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13500
Policy Update Magnitude: 0.52497
Value Function Update Magnitude: 0.72438

Collected Steps per Second: 19,875.34802
Overall Steps per Second: 9,519.43557

Timestep Collection Time: 2.51709
Timestep Consumption Time: 2.73827
PPO Batch Consumption Time: 0.31446
Total Iteration Time: 5.25535

Cumulative Model Updates: 172,530
Cumulative Timesteps: 1,438,689,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1438689330...
Checkpoint 1438689330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.43791
Policy Entropy: 3.79027
Value Function Loss: 0.01939

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12532
Policy Update Magnitude: 0.50797
Value Function Update Magnitude: 0.71066

Collected Steps per Second: 18,855.44196
Overall Steps per Second: 9,641.76886

Timestep Collection Time: 2.65366
Timestep Consumption Time: 2.53584
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 5.18950

Cumulative Model Updates: 172,536
Cumulative Timesteps: 1,438,739,366

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.43791
Policy Entropy: 3.78965
Value Function Loss: 0.01914

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.49481
Value Function Update Magnitude: 0.76912

Collected Steps per Second: 19,242.72837
Overall Steps per Second: 9,795.80822

Timestep Collection Time: 2.59859
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 5.10463

Cumulative Model Updates: 172,542
Cumulative Timesteps: 1,438,789,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1438789370...
Checkpoint 1438789370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,698.04776
Policy Entropy: 3.77477
Value Function Loss: 0.01672

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.47287
Value Function Update Magnitude: 0.70620

Collected Steps per Second: 19,407.08161
Overall Steps per Second: 9,744.65585

Timestep Collection Time: 2.57782
Timestep Consumption Time: 2.55607
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 5.13389

Cumulative Model Updates: 172,548
Cumulative Timesteps: 1,438,839,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,253.13711
Policy Entropy: 3.76806
Value Function Loss: 0.01920

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 17,030.35050
Overall Steps per Second: 9,062.25376

Timestep Collection Time: 2.93852
Timestep Consumption Time: 2.58373
PPO Batch Consumption Time: 0.30289
Total Iteration Time: 5.52225

Cumulative Model Updates: 172,554
Cumulative Timesteps: 1,438,889,442

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1438889442...
Checkpoint 1438889442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,335.57424
Policy Entropy: 3.78545
Value Function Loss: 0.02090

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.60345

Collected Steps per Second: 19,143.36685
Overall Steps per Second: 9,790.24197

Timestep Collection Time: 2.61375
Timestep Consumption Time: 2.49705
PPO Batch Consumption Time: 0.30011
Total Iteration Time: 5.11080

Cumulative Model Updates: 172,560
Cumulative Timesteps: 1,438,939,478

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,993.23628
Policy Entropy: 3.82303
Value Function Loss: 0.02585

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.53382
Value Function Update Magnitude: 0.56072

Collected Steps per Second: 19,351.25672
Overall Steps per Second: 9,920.42029

Timestep Collection Time: 2.58516
Timestep Consumption Time: 2.45757
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 5.04273

Cumulative Model Updates: 172,566
Cumulative Timesteps: 1,438,989,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1438989504...
Checkpoint 1438989504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,563.99495
Policy Entropy: 3.84789
Value Function Loss: 0.02582

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.60748

Collected Steps per Second: 20,405.28232
Overall Steps per Second: 9,923.11844

Timestep Collection Time: 2.45172
Timestep Consumption Time: 2.58984
PPO Batch Consumption Time: 0.30357
Total Iteration Time: 5.04156

Cumulative Model Updates: 172,572
Cumulative Timesteps: 1,439,039,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,671.19082
Policy Entropy: 3.86157
Value Function Loss: 0.02920

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.58680
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 18,953.67956
Overall Steps per Second: 9,588.84417

Timestep Collection Time: 2.63801
Timestep Consumption Time: 2.57638
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.21439

Cumulative Model Updates: 172,578
Cumulative Timesteps: 1,439,089,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1439089532...
Checkpoint 1439089532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,826.45712
Policy Entropy: 3.84389
Value Function Loss: 0.02915

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.59779
Value Function Update Magnitude: 0.66887

Collected Steps per Second: 19,147.00180
Overall Steps per Second: 9,742.51274

Timestep Collection Time: 2.61232
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 5.13399

Cumulative Model Updates: 172,584
Cumulative Timesteps: 1,439,139,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.89923
Policy Entropy: 3.83096
Value Function Loss: 0.02816

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.58611
Value Function Update Magnitude: 0.60964

Collected Steps per Second: 19,328.11745
Overall Steps per Second: 9,814.30163

Timestep Collection Time: 2.58825
Timestep Consumption Time: 2.50901
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 5.09726

Cumulative Model Updates: 172,590
Cumulative Timesteps: 1,439,189,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1439189576...
Checkpoint 1439189576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,860.85125
Policy Entropy: 3.80426
Value Function Loss: 0.02710

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.58934
Value Function Update Magnitude: 0.57410

Collected Steps per Second: 18,516.94777
Overall Steps per Second: 9,366.86675

Timestep Collection Time: 2.70217
Timestep Consumption Time: 2.63963
PPO Batch Consumption Time: 0.30773
Total Iteration Time: 5.34181

Cumulative Model Updates: 172,596
Cumulative Timesteps: 1,439,239,612

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,151.56947
Policy Entropy: 3.80724
Value Function Loss: 0.02737

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.60309
Value Function Update Magnitude: 0.73695

Collected Steps per Second: 19,706.06493
Overall Steps per Second: 9,752.98155

Timestep Collection Time: 2.53759
Timestep Consumption Time: 2.58966
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 5.12725

Cumulative Model Updates: 172,602
Cumulative Timesteps: 1,439,289,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1439289618...
Checkpoint 1439289618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.37029
Policy Entropy: 3.79344
Value Function Loss: 0.03013

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.59159
Value Function Update Magnitude: 0.71309

Collected Steps per Second: 19,052.35646
Overall Steps per Second: 9,714.91968

Timestep Collection Time: 2.62550
Timestep Consumption Time: 2.52349
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 5.14899

Cumulative Model Updates: 172,608
Cumulative Timesteps: 1,439,339,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.13309
Policy Entropy: 3.78101
Value Function Loss: 0.02718

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.59103
Value Function Update Magnitude: 0.70065

Collected Steps per Second: 19,751.45591
Overall Steps per Second: 9,728.84808

Timestep Collection Time: 2.53257
Timestep Consumption Time: 2.60904
PPO Batch Consumption Time: 0.30519
Total Iteration Time: 5.14162

Cumulative Model Updates: 172,614
Cumulative Timesteps: 1,439,389,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1439389662...
Checkpoint 1439389662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.57981
Policy Entropy: 3.76922
Value Function Loss: 0.02353

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.63302

Collected Steps per Second: 19,847.34745
Overall Steps per Second: 9,548.68750

Timestep Collection Time: 2.51933
Timestep Consumption Time: 2.71720
PPO Batch Consumption Time: 0.31955
Total Iteration Time: 5.23653

Cumulative Model Updates: 172,620
Cumulative Timesteps: 1,439,439,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,957.19902
Policy Entropy: 3.77688
Value Function Loss: 0.02127

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.49297
Value Function Update Magnitude: 0.54884

Collected Steps per Second: 19,064.54572
Overall Steps per Second: 9,578.21349

Timestep Collection Time: 2.62477
Timestep Consumption Time: 2.59959
PPO Batch Consumption Time: 0.30456
Total Iteration Time: 5.22436

Cumulative Model Updates: 172,626
Cumulative Timesteps: 1,439,489,704

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1439489704...
Checkpoint 1439489704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,271.09224
Policy Entropy: 3.78430
Value Function Loss: 0.02092

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.47883
Value Function Update Magnitude: 0.58394

Collected Steps per Second: 19,569.42873
Overall Steps per Second: 9,889.40449

Timestep Collection Time: 2.55511
Timestep Consumption Time: 2.50101
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 5.05612

Cumulative Model Updates: 172,632
Cumulative Timesteps: 1,439,539,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.44823
Policy Entropy: 3.78984
Value Function Loss: 0.01954

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.49206
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 20,330.34348
Overall Steps per Second: 9,984.95308

Timestep Collection Time: 2.45948
Timestep Consumption Time: 2.54826
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 5.00774

Cumulative Model Updates: 172,638
Cumulative Timesteps: 1,439,589,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1439589708...
Checkpoint 1439589708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,417.05385
Policy Entropy: 3.79359
Value Function Loss: 0.01873

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.46820
Value Function Update Magnitude: 0.58068

Collected Steps per Second: 20,154.18885
Overall Steps per Second: 9,551.33763

Timestep Collection Time: 2.48216
Timestep Consumption Time: 2.75543
PPO Batch Consumption Time: 0.32784
Total Iteration Time: 5.23759

Cumulative Model Updates: 172,644
Cumulative Timesteps: 1,439,639,734

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,562.07012
Policy Entropy: 3.78884
Value Function Loss: 0.01882

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.47590
Value Function Update Magnitude: 0.49057

Collected Steps per Second: 19,316.63969
Overall Steps per Second: 9,693.00479

Timestep Collection Time: 2.58948
Timestep Consumption Time: 2.57095
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 5.16042

Cumulative Model Updates: 172,650
Cumulative Timesteps: 1,439,689,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1439689754...
Checkpoint 1439689754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,768.17808
Policy Entropy: 3.77537
Value Function Loss: 0.01982

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.51930
Value Function Update Magnitude: 0.52855

Collected Steps per Second: 19,378.16953
Overall Steps per Second: 9,845.44269

Timestep Collection Time: 2.58177
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 5.08154

Cumulative Model Updates: 172,656
Cumulative Timesteps: 1,439,739,784

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,476.64779
Policy Entropy: 3.76679
Value Function Loss: 0.02151

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.55128

Collected Steps per Second: 18,662.64222
Overall Steps per Second: 9,680.72010

Timestep Collection Time: 2.68022
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 5.16697

Cumulative Model Updates: 172,662
Cumulative Timesteps: 1,439,789,804

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1439789804...
Checkpoint 1439789804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,855.20376
Policy Entropy: 3.78768
Value Function Loss: 0.02254

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 19,596.99899
Overall Steps per Second: 9,790.55204

Timestep Collection Time: 2.55202
Timestep Consumption Time: 2.55617
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 5.10819

Cumulative Model Updates: 172,668
Cumulative Timesteps: 1,439,839,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,152.35213
Policy Entropy: 3.79259
Value Function Loss: 0.02393

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.62399

Collected Steps per Second: 19,552.30819
Overall Steps per Second: 9,852.82158

Timestep Collection Time: 2.55857
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.30275
Total Iteration Time: 5.07733

Cumulative Model Updates: 172,674
Cumulative Timesteps: 1,439,889,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1439889842...
Checkpoint 1439889842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,395.53695
Policy Entropy: 3.80564
Value Function Loss: 0.02297

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.57494
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 20,072.52023
Overall Steps per Second: 9,839.04163

Timestep Collection Time: 2.49117
Timestep Consumption Time: 2.59104
PPO Batch Consumption Time: 0.30261
Total Iteration Time: 5.08220

Cumulative Model Updates: 172,680
Cumulative Timesteps: 1,439,939,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,029.78178
Policy Entropy: 3.78569
Value Function Loss: 0.02821

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.58561
Value Function Update Magnitude: 0.60449

Collected Steps per Second: 18,673.60427
Overall Steps per Second: 9,614.58858

Timestep Collection Time: 2.67800
Timestep Consumption Time: 2.52326
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 5.20126

Cumulative Model Updates: 172,686
Cumulative Timesteps: 1,439,989,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1439989854...
Checkpoint 1439989854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,710.75544
Policy Entropy: 3.81678
Value Function Loss: 0.02893

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.61645
Value Function Update Magnitude: 0.61651

Collected Steps per Second: 18,501.43073
Overall Steps per Second: 9,464.72359

Timestep Collection Time: 2.70293
Timestep Consumption Time: 2.58069
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.28362

Cumulative Model Updates: 172,692
Cumulative Timesteps: 1,440,039,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,930.44517
Policy Entropy: 3.83113
Value Function Loss: 0.03082

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.60385
Value Function Update Magnitude: 0.62359

Collected Steps per Second: 17,021.45389
Overall Steps per Second: 8,991.96100

Timestep Collection Time: 2.93782
Timestep Consumption Time: 2.62337
PPO Batch Consumption Time: 0.30697
Total Iteration Time: 5.56119

Cumulative Model Updates: 172,698
Cumulative Timesteps: 1,440,089,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1440089868...
Checkpoint 1440089868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.68455
Policy Entropy: 3.86293
Value Function Loss: 0.02505

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.61813
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 19,653.04642
Overall Steps per Second: 9,732.64577

Timestep Collection Time: 2.54424
Timestep Consumption Time: 2.59332
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.13755

Cumulative Model Updates: 172,704
Cumulative Timesteps: 1,440,139,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.66000
Policy Entropy: 3.85664
Value Function Loss: 0.02308

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12239
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.61599

Collected Steps per Second: 19,109.63732
Overall Steps per Second: 9,661.09142

Timestep Collection Time: 2.61711
Timestep Consumption Time: 2.55953
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 5.17664

Cumulative Model Updates: 172,710
Cumulative Timesteps: 1,440,189,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1440189882...
Checkpoint 1440189882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,067.00823
Policy Entropy: 3.83460
Value Function Loss: 0.02097

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.11337
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.57854

Collected Steps per Second: 19,828.38410
Overall Steps per Second: 9,842.06474

Timestep Collection Time: 2.52355
Timestep Consumption Time: 2.56054
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 5.08410

Cumulative Model Updates: 172,716
Cumulative Timesteps: 1,440,239,920

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,921.50853
Policy Entropy: 3.80353
Value Function Loss: 0.01859

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.50757
Value Function Update Magnitude: 0.50002

Collected Steps per Second: 19,743.73938
Overall Steps per Second: 9,746.78443

Timestep Collection Time: 2.53437
Timestep Consumption Time: 2.59942
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 5.13380

Cumulative Model Updates: 172,722
Cumulative Timesteps: 1,440,289,958

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1440289958...
Checkpoint 1440289958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,854.27680
Policy Entropy: 3.78089
Value Function Loss: 0.01779

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.47422
Value Function Update Magnitude: 0.44646

Collected Steps per Second: 19,836.70438
Overall Steps per Second: 9,806.64016

Timestep Collection Time: 2.52108
Timestep Consumption Time: 2.57852
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 5.09961

Cumulative Model Updates: 172,728
Cumulative Timesteps: 1,440,339,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,282.62469
Policy Entropy: 3.77326
Value Function Loss: 0.01720

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.52825
Value Function Update Magnitude: 0.51645

Collected Steps per Second: 20,067.21398
Overall Steps per Second: 9,981.02819

Timestep Collection Time: 2.49332
Timestep Consumption Time: 2.51959
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 5.01291

Cumulative Model Updates: 172,734
Cumulative Timesteps: 1,440,390,002

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1440390002...
Checkpoint 1440390002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,368.43307
Policy Entropy: 3.76113
Value Function Loss: 0.01734

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.65811

Collected Steps per Second: 16,521.31830
Overall Steps per Second: 8,131.17282

Timestep Collection Time: 3.02797
Timestep Consumption Time: 3.12441
PPO Batch Consumption Time: 0.38419
Total Iteration Time: 6.15237

Cumulative Model Updates: 172,740
Cumulative Timesteps: 1,440,440,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,112.52224
Policy Entropy: 3.75901
Value Function Loss: 0.01738

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.69120

Collected Steps per Second: 15,335.25552
Overall Steps per Second: 7,913.25748

Timestep Collection Time: 3.26163
Timestep Consumption Time: 3.05915
PPO Batch Consumption Time: 0.37536
Total Iteration Time: 6.32079

Cumulative Model Updates: 172,746
Cumulative Timesteps: 1,440,490,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1440490046...
Checkpoint 1440490046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,000.21972
Policy Entropy: 3.75312
Value Function Loss: 0.01600

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.65252

Collected Steps per Second: 18,760.65051
Overall Steps per Second: 9,703.04103

Timestep Collection Time: 2.66537
Timestep Consumption Time: 2.48807
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 5.15344

Cumulative Model Updates: 172,752
Cumulative Timesteps: 1,440,540,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,919.37724
Policy Entropy: 3.76886
Value Function Loss: 0.01497

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.46516
Value Function Update Magnitude: 0.57485

Collected Steps per Second: 18,852.47178
Overall Steps per Second: 9,654.48625

Timestep Collection Time: 2.65313
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 5.18080

Cumulative Model Updates: 172,758
Cumulative Timesteps: 1,440,590,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1440590068...
Checkpoint 1440590068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,315.87188
Policy Entropy: 3.77279
Value Function Loss: 0.01505

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11850
Policy Update Magnitude: 0.42850
Value Function Update Magnitude: 0.48610

Collected Steps per Second: 18,818.88414
Overall Steps per Second: 9,602.56857

Timestep Collection Time: 2.65722
Timestep Consumption Time: 2.55034
PPO Batch Consumption Time: 0.30628
Total Iteration Time: 5.20757

Cumulative Model Updates: 172,764
Cumulative Timesteps: 1,440,640,074

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,311.11869
Policy Entropy: 3.78357
Value Function Loss: 0.02075

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.48614
Value Function Update Magnitude: 0.50346

Collected Steps per Second: 18,550.08579
Overall Steps per Second: 9,541.56512

Timestep Collection Time: 2.69724
Timestep Consumption Time: 2.54656
PPO Batch Consumption Time: 0.30700
Total Iteration Time: 5.24379

Cumulative Model Updates: 172,770
Cumulative Timesteps: 1,440,690,108

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1440690108...
Checkpoint 1440690108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,304.70168
Policy Entropy: 3.79547
Value Function Loss: 0.02239

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12400
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.50768

Collected Steps per Second: 18,653.18669
Overall Steps per Second: 9,717.80909

Timestep Collection Time: 2.68244
Timestep Consumption Time: 2.46646
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 5.14890

Cumulative Model Updates: 172,776
Cumulative Timesteps: 1,440,740,144

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,411.55658
Policy Entropy: 3.78545
Value Function Loss: 0.02357

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.56774
Value Function Update Magnitude: 0.50937

Collected Steps per Second: 18,657.05440
Overall Steps per Second: 9,642.27696

Timestep Collection Time: 2.68274
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 5.19089

Cumulative Model Updates: 172,782
Cumulative Timesteps: 1,440,790,196

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1440790196...
Checkpoint 1440790196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,194.60881
Policy Entropy: 3.76678
Value Function Loss: 0.01956

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.49487

Collected Steps per Second: 18,819.76417
Overall Steps per Second: 9,643.42026

Timestep Collection Time: 2.65912
Timestep Consumption Time: 2.53033
PPO Batch Consumption Time: 0.30671
Total Iteration Time: 5.18945

Cumulative Model Updates: 172,788
Cumulative Timesteps: 1,440,840,240

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,820.93507
Policy Entropy: 3.75226
Value Function Loss: 0.01862

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.48603

Collected Steps per Second: 18,995.65766
Overall Steps per Second: 9,671.33074

Timestep Collection Time: 2.63397
Timestep Consumption Time: 2.53946
PPO Batch Consumption Time: 0.30788
Total Iteration Time: 5.17343

Cumulative Model Updates: 172,794
Cumulative Timesteps: 1,440,890,274

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1440890274...
Checkpoint 1440890274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,100.07799
Policy Entropy: 3.75183
Value Function Loss: 0.01739

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.49358
Value Function Update Magnitude: 0.43132

Collected Steps per Second: 16,548.53606
Overall Steps per Second: 8,771.97149

Timestep Collection Time: 3.02419
Timestep Consumption Time: 2.68102
PPO Batch Consumption Time: 0.30973
Total Iteration Time: 5.70522

Cumulative Model Updates: 172,800
Cumulative Timesteps: 1,440,940,320

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,100.07799
Policy Entropy: 3.74885
Value Function Loss: 0.01763

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.45465
Value Function Update Magnitude: 0.40931

Collected Steps per Second: 18,520.37775
Overall Steps per Second: 9,446.07390

Timestep Collection Time: 2.70124
Timestep Consumption Time: 2.59493
PPO Batch Consumption Time: 0.31244
Total Iteration Time: 5.29617

Cumulative Model Updates: 172,806
Cumulative Timesteps: 1,440,990,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1440990348...
Checkpoint 1440990348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,936.47946
Policy Entropy: 3.74295
Value Function Loss: 0.01752

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.48853
Value Function Update Magnitude: 0.46542

Collected Steps per Second: 18,524.87799
Overall Steps per Second: 9,603.50163

Timestep Collection Time: 2.70026
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 5.20873

Cumulative Model Updates: 172,812
Cumulative Timesteps: 1,441,040,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,208.82682
Policy Entropy: 3.74391
Value Function Loss: 0.01954

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.53913

Collected Steps per Second: 18,999.85715
Overall Steps per Second: 9,658.28805

Timestep Collection Time: 2.63286
Timestep Consumption Time: 2.54652
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 5.17939

Cumulative Model Updates: 172,818
Cumulative Timesteps: 1,441,090,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1441090394...
Checkpoint 1441090394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,894.57360
Policy Entropy: 3.75944
Value Function Loss: 0.01871

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.57627
Value Function Update Magnitude: 0.52655

Collected Steps per Second: 18,898.84559
Overall Steps per Second: 9,598.95651

Timestep Collection Time: 2.64789
Timestep Consumption Time: 2.56539
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.21328

Cumulative Model Updates: 172,824
Cumulative Timesteps: 1,441,140,436

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,677.17525
Policy Entropy: 3.76229
Value Function Loss: 0.02166

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 19,492.11307
Overall Steps per Second: 9,777.96860

Timestep Collection Time: 2.56596
Timestep Consumption Time: 2.54921
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 5.11517

Cumulative Model Updates: 172,830
Cumulative Timesteps: 1,441,190,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1441190452...
Checkpoint 1441190452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,685.29704
Policy Entropy: 3.76319
Value Function Loss: 0.02079

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.60444
Value Function Update Magnitude: 0.72835

Collected Steps per Second: 19,337.35674
Overall Steps per Second: 9,613.78928

Timestep Collection Time: 2.58567
Timestep Consumption Time: 2.61519
PPO Batch Consumption Time: 0.30697
Total Iteration Time: 5.20086

Cumulative Model Updates: 172,836
Cumulative Timesteps: 1,441,240,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,770.58987
Policy Entropy: 3.75849
Value Function Loss: 0.02026

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.72515

Collected Steps per Second: 19,453.53011
Overall Steps per Second: 9,429.84786

Timestep Collection Time: 2.57136
Timestep Consumption Time: 2.73329
PPO Batch Consumption Time: 0.32939
Total Iteration Time: 5.30465

Cumulative Model Updates: 172,842
Cumulative Timesteps: 1,441,290,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1441290474...
Checkpoint 1441290474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,382.32332
Policy Entropy: 3.75867
Value Function Loss: 0.01706

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.53606

Collected Steps per Second: 16,929.61898
Overall Steps per Second: 9,044.76668

Timestep Collection Time: 2.95459
Timestep Consumption Time: 2.57568
PPO Batch Consumption Time: 0.30822
Total Iteration Time: 5.53027

Cumulative Model Updates: 172,848
Cumulative Timesteps: 1,441,340,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,856.56560
Policy Entropy: 3.75915
Value Function Loss: 0.01716

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.48066
Value Function Update Magnitude: 0.46695

Collected Steps per Second: 19,150.69387
Overall Steps per Second: 9,594.73920

Timestep Collection Time: 2.61160
Timestep Consumption Time: 2.60105
PPO Batch Consumption Time: 0.30737
Total Iteration Time: 5.21265

Cumulative Model Updates: 172,854
Cumulative Timesteps: 1,441,390,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1441390508...
Checkpoint 1441390508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,173.45683
Policy Entropy: 3.74835
Value Function Loss: 0.01716

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.46993
Value Function Update Magnitude: 0.50226

Collected Steps per Second: 19,182.66836
Overall Steps per Second: 9,717.88667

Timestep Collection Time: 2.60850
Timestep Consumption Time: 2.54056
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 5.14906

Cumulative Model Updates: 172,860
Cumulative Timesteps: 1,441,440,546

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,173.45683
Policy Entropy: 3.74799
Value Function Loss: 0.01919

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.49124
Value Function Update Magnitude: 0.41160

Collected Steps per Second: 19,353.71432
Overall Steps per Second: 9,675.96480

Timestep Collection Time: 2.58607
Timestep Consumption Time: 2.58654
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 5.17261

Cumulative Model Updates: 172,866
Cumulative Timesteps: 1,441,490,596

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1441490596...
Checkpoint 1441490596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,782.21400
Policy Entropy: 3.74698
Value Function Loss: 0.01904

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.54962
Value Function Update Magnitude: 0.40663

Collected Steps per Second: 18,230.41548
Overall Steps per Second: 9,465.26800

Timestep Collection Time: 2.74344
Timestep Consumption Time: 2.54051
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 5.28395

Cumulative Model Updates: 172,872
Cumulative Timesteps: 1,441,540,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,036.82477
Policy Entropy: 3.74479
Value Function Loss: 0.02004

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.60223
Value Function Update Magnitude: 0.49724

Collected Steps per Second: 18,372.52447
Overall Steps per Second: 9,390.80242

Timestep Collection Time: 2.72374
Timestep Consumption Time: 2.60509
PPO Batch Consumption Time: 0.30838
Total Iteration Time: 5.32883

Cumulative Model Updates: 172,878
Cumulative Timesteps: 1,441,590,652

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1441590652...
Checkpoint 1441590652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,036.82477
Policy Entropy: 3.73670
Value Function Loss: 0.01984

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.66377
Value Function Update Magnitude: 0.53117

Collected Steps per Second: 19,179.41932
Overall Steps per Second: 9,365.39625

Timestep Collection Time: 2.60936
Timestep Consumption Time: 2.73435
PPO Batch Consumption Time: 0.32622
Total Iteration Time: 5.34371

Cumulative Model Updates: 172,884
Cumulative Timesteps: 1,441,640,698

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,854.65213
Policy Entropy: 3.73202
Value Function Loss: 0.01915

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.63301
Value Function Update Magnitude: 0.48102

Collected Steps per Second: 16,769.33630
Overall Steps per Second: 8,917.05045

Timestep Collection Time: 2.98271
Timestep Consumption Time: 2.62655
PPO Batch Consumption Time: 0.30862
Total Iteration Time: 5.60925

Cumulative Model Updates: 172,890
Cumulative Timesteps: 1,441,690,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1441690716...
Checkpoint 1441690716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,947.51730
Policy Entropy: 3.74950
Value Function Loss: 0.01771

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.57557
Value Function Update Magnitude: 0.42950

Collected Steps per Second: 19,401.41123
Overall Steps per Second: 9,701.73508

Timestep Collection Time: 2.57796
Timestep Consumption Time: 2.57741
PPO Batch Consumption Time: 0.30355
Total Iteration Time: 5.15537

Cumulative Model Updates: 172,896
Cumulative Timesteps: 1,441,740,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,025.78862
Policy Entropy: 3.76132
Value Function Loss: 0.02009

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.40410

Collected Steps per Second: 19,538.42140
Overall Steps per Second: 9,885.12682

Timestep Collection Time: 2.55927
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 5.05851

Cumulative Model Updates: 172,902
Cumulative Timesteps: 1,441,790,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1441790736...
Checkpoint 1441790736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,895.84141
Policy Entropy: 3.76467
Value Function Loss: 0.02020

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.61786
Value Function Update Magnitude: 0.47838

Collected Steps per Second: 20,198.61664
Overall Steps per Second: 9,898.06058

Timestep Collection Time: 2.47750
Timestep Consumption Time: 2.57824
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 5.05574

Cumulative Model Updates: 172,908
Cumulative Timesteps: 1,441,840,778

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,750.51662
Policy Entropy: 3.75058
Value Function Loss: 0.01947

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.62623
Value Function Update Magnitude: 0.56136

Collected Steps per Second: 20,049.23083
Overall Steps per Second: 10,000.67208

Timestep Collection Time: 2.49596
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 5.00386

Cumulative Model Updates: 172,914
Cumulative Timesteps: 1,441,890,820

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1441890820...
Checkpoint 1441890820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233,478.84138
Policy Entropy: 3.73661
Value Function Loss: 0.02126

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.60005
Value Function Update Magnitude: 0.62878

Collected Steps per Second: 20,033.76993
Overall Steps per Second: 9,908.50327

Timestep Collection Time: 2.49619
Timestep Consumption Time: 2.55079
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 5.04698

Cumulative Model Updates: 172,920
Cumulative Timesteps: 1,441,940,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,511.95613
Policy Entropy: 3.74665
Value Function Loss: 0.02486

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.61007
Value Function Update Magnitude: 0.57436

Collected Steps per Second: 20,041.57986
Overall Steps per Second: 9,796.33997

Timestep Collection Time: 2.49481
Timestep Consumption Time: 2.60913
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 5.10395

Cumulative Model Updates: 172,926
Cumulative Timesteps: 1,441,990,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1441990828...
Checkpoint 1441990828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,441.74780
Policy Entropy: 3.75596
Value Function Loss: 0.02433

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.63385
Value Function Update Magnitude: 0.53894

Collected Steps per Second: 20,297.01872
Overall Steps per Second: 9,963.95037

Timestep Collection Time: 2.46539
Timestep Consumption Time: 2.55672
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 5.02210

Cumulative Model Updates: 172,932
Cumulative Timesteps: 1,442,040,868

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,933.86878
Policy Entropy: 3.76331
Value Function Loss: 0.02033

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14573
Policy Update Magnitude: 0.62629
Value Function Update Magnitude: 0.54594

Collected Steps per Second: 18,845.12212
Overall Steps per Second: 9,560.19692

Timestep Collection Time: 2.65406
Timestep Consumption Time: 2.57764
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 5.23169

Cumulative Model Updates: 172,938
Cumulative Timesteps: 1,442,090,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1442090884...
Checkpoint 1442090884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,933.86878
Policy Entropy: 3.74486
Value Function Loss: 0.01712

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.63350
Value Function Update Magnitude: 0.52246

Collected Steps per Second: 17,744.21655
Overall Steps per Second: 9,256.29142

Timestep Collection Time: 2.81928
Timestep Consumption Time: 2.58526
PPO Batch Consumption Time: 0.30186
Total Iteration Time: 5.40454

Cumulative Model Updates: 172,944
Cumulative Timesteps: 1,442,140,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,902.20977
Policy Entropy: 3.74518
Value Function Loss: 0.01433

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.66814
Value Function Update Magnitude: 0.56167

Collected Steps per Second: 19,054.90911
Overall Steps per Second: 9,436.29805

Timestep Collection Time: 2.62536
Timestep Consumption Time: 2.67608
PPO Batch Consumption Time: 0.31479
Total Iteration Time: 5.30144

Cumulative Model Updates: 172,950
Cumulative Timesteps: 1,442,190,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1442190936...
Checkpoint 1442190936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,933.24872
Policy Entropy: 3.74171
Value Function Loss: 0.01520

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16037
Policy Update Magnitude: 0.66715
Value Function Update Magnitude: 0.55777

Collected Steps per Second: 19,281.25888
Overall Steps per Second: 9,721.51166

Timestep Collection Time: 2.59516
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.30092
Total Iteration Time: 5.14714

Cumulative Model Updates: 172,956
Cumulative Timesteps: 1,442,240,974

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,671.80577
Policy Entropy: 3.76042
Value Function Loss: 0.01611

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16965
Policy Update Magnitude: 0.62734
Value Function Update Magnitude: 0.59546

Collected Steps per Second: 19,177.35366
Overall Steps per Second: 9,588.07005

Timestep Collection Time: 2.60724
Timestep Consumption Time: 2.60757
PPO Batch Consumption Time: 0.30606
Total Iteration Time: 5.21481

Cumulative Model Updates: 172,962
Cumulative Timesteps: 1,442,290,974

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1442290974...
Checkpoint 1442290974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,964.17262
Policy Entropy: 3.76220
Value Function Loss: 0.01859

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.62108
Value Function Update Magnitude: 0.66620

Collected Steps per Second: 19,241.48323
Overall Steps per Second: 9,601.60901

Timestep Collection Time: 2.60084
Timestep Consumption Time: 2.61120
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 5.21204

Cumulative Model Updates: 172,968
Cumulative Timesteps: 1,442,341,018

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,614.86224
Policy Entropy: 3.77125
Value Function Loss: 0.01755

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.67367
Value Function Update Magnitude: 0.65854

Collected Steps per Second: 16,882.49508
Overall Steps per Second: 8,443.37486

Timestep Collection Time: 2.96248
Timestep Consumption Time: 2.96098
PPO Batch Consumption Time: 0.34545
Total Iteration Time: 5.92346

Cumulative Model Updates: 172,974
Cumulative Timesteps: 1,442,391,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1442391032...
Checkpoint 1442391032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,311.84188
Policy Entropy: 3.78545
Value Function Loss: 0.01571

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.69576
Value Function Update Magnitude: 0.65549

Collected Steps per Second: 18,756.43740
Overall Steps per Second: 9,424.07582

Timestep Collection Time: 2.66703
Timestep Consumption Time: 2.64108
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 5.30811

Cumulative Model Updates: 172,980
Cumulative Timesteps: 1,442,441,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,478.28895
Policy Entropy: 3.78661
Value Function Loss: 0.01482

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06034
Policy Update Magnitude: 0.66443
Value Function Update Magnitude: 0.68093

Collected Steps per Second: 17,898.49802
Overall Steps per Second: 8,383.56726

Timestep Collection Time: 2.79409
Timestep Consumption Time: 3.17115
PPO Batch Consumption Time: 0.37293
Total Iteration Time: 5.96524

Cumulative Model Updates: 172,986
Cumulative Timesteps: 1,442,491,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1442491066...
Checkpoint 1442491066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,982.83118
Policy Entropy: 3.79144
Value Function Loss: 0.01546

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07450
Policy Update Magnitude: 0.61769
Value Function Update Magnitude: 0.67967

Collected Steps per Second: 15,792.78871
Overall Steps per Second: 8,352.15331

Timestep Collection Time: 3.16740
Timestep Consumption Time: 2.82172
PPO Batch Consumption Time: 0.34339
Total Iteration Time: 5.98911

Cumulative Model Updates: 172,992
Cumulative Timesteps: 1,442,541,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,904.52431
Policy Entropy: 3.79138
Value Function Loss: 0.01580

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05895
Policy Update Magnitude: 0.60606
Value Function Update Magnitude: 0.68049

Collected Steps per Second: 17,194.59578
Overall Steps per Second: 9,142.90011

Timestep Collection Time: 2.90789
Timestep Consumption Time: 2.56083
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 5.46872

Cumulative Model Updates: 172,998
Cumulative Timesteps: 1,442,591,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1442591088...
Checkpoint 1442591088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,629.18578
Policy Entropy: 3.76885
Value Function Loss: 0.01913

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07213
Policy Update Magnitude: 0.71173
Value Function Update Magnitude: 0.73225

Collected Steps per Second: 18,113.67472
Overall Steps per Second: 9,450.99802

Timestep Collection Time: 2.76057
Timestep Consumption Time: 2.53030
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 5.29087

Cumulative Model Updates: 173,004
Cumulative Timesteps: 1,442,641,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,931.11683
Policy Entropy: 3.76962
Value Function Loss: 0.01934

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.11842
Policy Update Magnitude: 0.74046
Value Function Update Magnitude: 0.73059

Collected Steps per Second: 18,496.16134
Overall Steps per Second: 9,419.82206

Timestep Collection Time: 2.70391
Timestep Consumption Time: 2.60532
PPO Batch Consumption Time: 0.29950
Total Iteration Time: 5.30923

Cumulative Model Updates: 173,010
Cumulative Timesteps: 1,442,691,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1442691104...
Checkpoint 1442691104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320,830.96478
Policy Entropy: 3.78094
Value Function Loss: 0.03609

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.18299
Policy Update Magnitude: 0.74215
Value Function Update Magnitude: 0.65334

Collected Steps per Second: 19,934.05075
Overall Steps per Second: 9,884.81378

Timestep Collection Time: 2.50947
Timestep Consumption Time: 2.55122
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 5.06069

Cumulative Model Updates: 173,016
Cumulative Timesteps: 1,442,741,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.71622
Policy Entropy: 3.88168
Value Function Loss: 0.04483

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.15561
Policy Update Magnitude: 1.05104
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 20,061.40175
Overall Steps per Second: 9,919.30728

Timestep Collection Time: 2.49354
Timestep Consumption Time: 2.54955
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 5.04309

Cumulative Model Updates: 173,022
Cumulative Timesteps: 1,442,791,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1442791152...
Checkpoint 1442791152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.73712
Policy Entropy: 3.92694
Value Function Loss: 0.04552

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.16678
Policy Update Magnitude: 1.19425
Value Function Update Magnitude: 0.75061

Collected Steps per Second: 19,972.32721
Overall Steps per Second: 9,838.87040

Timestep Collection Time: 2.50426
Timestep Consumption Time: 2.57925
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 5.08351

Cumulative Model Updates: 173,028
Cumulative Timesteps: 1,442,841,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,464.39765
Policy Entropy: 3.99240
Value Function Loss: 0.03916

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 1.28246
Value Function Update Magnitude: 0.91259

Collected Steps per Second: 18,516.62136
Overall Steps per Second: 9,627.03504

Timestep Collection Time: 2.70190
Timestep Consumption Time: 2.49493
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 5.19682

Cumulative Model Updates: 173,034
Cumulative Timesteps: 1,442,891,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1442891198...
Checkpoint 1442891198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.65826
Policy Entropy: 3.95922
Value Function Loss: 0.03691

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 1.29557
Value Function Update Magnitude: 1.12396

Collected Steps per Second: 11,787.69813
Overall Steps per Second: 7,115.62774

Timestep Collection Time: 4.24307
Timestep Consumption Time: 2.78597
PPO Batch Consumption Time: 0.33275
Total Iteration Time: 7.02904

Cumulative Model Updates: 173,040
Cumulative Timesteps: 1,442,941,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205.55737
Policy Entropy: 3.94246
Value Function Loss: 0.03293

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11050
Policy Update Magnitude: 1.25404
Value Function Update Magnitude: 1.22629

Collected Steps per Second: 13,694.87714
Overall Steps per Second: 6,842.74536

Timestep Collection Time: 3.65115
Timestep Consumption Time: 3.65615
PPO Batch Consumption Time: 0.47315
Total Iteration Time: 7.30730

Cumulative Model Updates: 173,046
Cumulative Timesteps: 1,442,991,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1442991216...
Checkpoint 1442991216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,480.44084
Policy Entropy: 3.90211
Value Function Loss: 0.03444

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 1.17388
Value Function Update Magnitude: 1.13571

Collected Steps per Second: 12,873.42582
Overall Steps per Second: 6,152.01463

Timestep Collection Time: 3.88444
Timestep Consumption Time: 4.24396
PPO Batch Consumption Time: 0.57476
Total Iteration Time: 8.12839

Cumulative Model Updates: 173,052
Cumulative Timesteps: 1,443,041,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.54985
Policy Entropy: 3.88501
Value Function Loss: 0.03166

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 1.14566
Value Function Update Magnitude: 0.91342

Collected Steps per Second: 12,526.79127
Overall Steps per Second: 6,698.15287

Timestep Collection Time: 3.99496
Timestep Consumption Time: 3.47636
PPO Batch Consumption Time: 0.46117
Total Iteration Time: 7.47131

Cumulative Model Updates: 173,058
Cumulative Timesteps: 1,443,091,266

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1443091266...
Checkpoint 1443091266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,214.99818
Policy Entropy: 3.88522
Value Function Loss: 0.03171

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.97737
Value Function Update Magnitude: 0.83143

Collected Steps per Second: 14,588.08013
Overall Steps per Second: 6,818.62768

Timestep Collection Time: 3.42828
Timestep Consumption Time: 3.90634
PPO Batch Consumption Time: 0.52329
Total Iteration Time: 7.33461

Cumulative Model Updates: 173,064
Cumulative Timesteps: 1,443,141,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.14744
Policy Entropy: 3.88950
Value Function Loss: 0.02912

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11370
Policy Update Magnitude: 0.79940
Value Function Update Magnitude: 0.71383

Collected Steps per Second: 14,438.49925
Overall Steps per Second: 6,815.61117

Timestep Collection Time: 3.46532
Timestep Consumption Time: 3.87577
PPO Batch Consumption Time: 0.51489
Total Iteration Time: 7.34109

Cumulative Model Updates: 173,070
Cumulative Timesteps: 1,443,191,312

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1443191312...
Checkpoint 1443191312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,671.23365
Policy Entropy: 3.86442
Value Function Loss: 0.02729

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06030
Policy Update Magnitude: 0.71762
Value Function Update Magnitude: 0.68558

Collected Steps per Second: 14,344.73020
Overall Steps per Second: 6,948.24161

Timestep Collection Time: 3.48741
Timestep Consumption Time: 3.71239
PPO Batch Consumption Time: 0.49165
Total Iteration Time: 7.19981

Cumulative Model Updates: 173,076
Cumulative Timesteps: 1,443,241,338

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,395.61337
Policy Entropy: 3.84034
Value Function Loss: 0.02653

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.79415
Value Function Update Magnitude: 0.69768

Collected Steps per Second: 14,787.85343
Overall Steps per Second: 7,153.99237

Timestep Collection Time: 3.38251
Timestep Consumption Time: 3.60939
PPO Batch Consumption Time: 0.47468
Total Iteration Time: 6.99190

Cumulative Model Updates: 173,082
Cumulative Timesteps: 1,443,291,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1443291358...
Checkpoint 1443291358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,704.10962
Policy Entropy: 3.82893
Value Function Loss: 0.02434

Mean KL Divergence: 0.00565
SB3 Clip Fraction: 0.06577
Policy Update Magnitude: 0.84481
Value Function Update Magnitude: 0.79728

Collected Steps per Second: 15,057.43583
Overall Steps per Second: 7,169.42108

Timestep Collection Time: 3.32168
Timestep Consumption Time: 3.65461
PPO Batch Consumption Time: 0.48217
Total Iteration Time: 6.97630

Cumulative Model Updates: 173,088
Cumulative Timesteps: 1,443,341,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,125.87002
Policy Entropy: 3.82676
Value Function Loss: 0.02172

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05913
Policy Update Magnitude: 0.82312
Value Function Update Magnitude: 0.81443

Collected Steps per Second: 14,827.17821
Overall Steps per Second: 6,831.96970

Timestep Collection Time: 3.37340
Timestep Consumption Time: 3.94777
PPO Batch Consumption Time: 0.52263
Total Iteration Time: 7.32117

Cumulative Model Updates: 173,094
Cumulative Timesteps: 1,443,391,392

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1443391392...
Checkpoint 1443391392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,292.05905
Policy Entropy: 3.80722
Value Function Loss: 0.01993

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07147
Policy Update Magnitude: 0.74553
Value Function Update Magnitude: 0.80605

Collected Steps per Second: 15,702.81134
Overall Steps per Second: 8,416.00661

Timestep Collection Time: 3.18453
Timestep Consumption Time: 2.75725
PPO Batch Consumption Time: 0.32546
Total Iteration Time: 5.94177

Cumulative Model Updates: 173,100
Cumulative Timesteps: 1,443,441,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.77264
Policy Entropy: 3.81056
Value Function Loss: 0.01922

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.79380

Collected Steps per Second: 14,944.23208
Overall Steps per Second: 8,410.14652

Timestep Collection Time: 3.34858
Timestep Consumption Time: 2.60161
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 5.95019

Cumulative Model Updates: 173,106
Cumulative Timesteps: 1,443,491,440

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1443491440...
Checkpoint 1443491440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,949.31910
Policy Entropy: 3.81918
Value Function Loss: 0.02015

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.46068
Value Function Update Magnitude: 0.82148

Collected Steps per Second: 16,666.78104
Overall Steps per Second: 8,833.51267

Timestep Collection Time: 3.00178
Timestep Consumption Time: 2.66188
PPO Batch Consumption Time: 0.30813
Total Iteration Time: 5.66366

Cumulative Model Updates: 173,112
Cumulative Timesteps: 1,443,541,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,869.17033
Policy Entropy: 3.83629
Value Function Loss: 0.01815

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.42341
Value Function Update Magnitude: 0.81147

Collected Steps per Second: 18,941.68161
Overall Steps per Second: 9,708.18805

Timestep Collection Time: 2.64179
Timestep Consumption Time: 2.51262
PPO Batch Consumption Time: 0.30276
Total Iteration Time: 5.15441

Cumulative Model Updates: 173,118
Cumulative Timesteps: 1,443,591,510

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1443591510...
Checkpoint 1443591510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,159.39077
Policy Entropy: 3.80912
Value Function Loss: 0.01883

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.37871
Value Function Update Magnitude: 0.73849

Collected Steps per Second: 18,710.32554
Overall Steps per Second: 9,785.26063

Timestep Collection Time: 2.67264
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 5.11034

Cumulative Model Updates: 173,124
Cumulative Timesteps: 1,443,641,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,994.25166
Policy Entropy: 3.79799
Value Function Loss: 0.01672

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.37013
Value Function Update Magnitude: 0.64561

Collected Steps per Second: 19,189.71685
Overall Steps per Second: 9,585.71184

Timestep Collection Time: 2.60577
Timestep Consumption Time: 2.61074
PPO Batch Consumption Time: 0.31883
Total Iteration Time: 5.21651

Cumulative Model Updates: 173,130
Cumulative Timesteps: 1,443,691,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1443691520...
Checkpoint 1443691520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,994.25166
Policy Entropy: 3.76603
Value Function Loss: 0.01707

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.35653
Value Function Update Magnitude: 0.56941

Collected Steps per Second: 17,284.78410
Overall Steps per Second: 9,421.37584

Timestep Collection Time: 2.89341
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 5.30835

Cumulative Model Updates: 173,136
Cumulative Timesteps: 1,443,741,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,270.12665
Policy Entropy: 3.77250
Value Function Loss: 0.01573

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.36094
Value Function Update Magnitude: 0.57519

Collected Steps per Second: 17,030.93374
Overall Steps per Second: 9,175.28470

Timestep Collection Time: 2.93677
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 5.45117

Cumulative Model Updates: 173,142
Cumulative Timesteps: 1,443,791,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1443791548...
Checkpoint 1443791548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,214.98225
Policy Entropy: 3.76275
Value Function Loss: 0.01786

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.36720
Value Function Update Magnitude: 0.53760

Collected Steps per Second: 16,616.21253
Overall Steps per Second: 9,083.03990

Timestep Collection Time: 3.01019
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 5.50675

Cumulative Model Updates: 173,148
Cumulative Timesteps: 1,443,841,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,673.66379
Policy Entropy: 3.78843
Value Function Loss: 0.01703

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13860
Policy Update Magnitude: 0.38101
Value Function Update Magnitude: 0.46087

Collected Steps per Second: 19,545.93094
Overall Steps per Second: 9,910.77665

Timestep Collection Time: 2.55859
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 5.04602

Cumulative Model Updates: 173,154
Cumulative Timesteps: 1,443,891,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1443891576...
Checkpoint 1443891576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,481.05095
Policy Entropy: 3.78125
Value Function Loss: 0.02000

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.42792
Value Function Update Magnitude: 0.46570

Collected Steps per Second: 18,001.98351
Overall Steps per Second: 9,437.50768

Timestep Collection Time: 2.77892
Timestep Consumption Time: 2.52185
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 5.30076

Cumulative Model Updates: 173,160
Cumulative Timesteps: 1,443,941,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,349.02217
Policy Entropy: 3.80322
Value Function Loss: 0.02063

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.46480
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 16,890.11073
Overall Steps per Second: 8,853.82385

Timestep Collection Time: 2.96268
Timestep Consumption Time: 2.68911
PPO Batch Consumption Time: 0.33004
Total Iteration Time: 5.65180

Cumulative Model Updates: 173,166
Cumulative Timesteps: 1,443,991,642

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1443991642...
Checkpoint 1443991642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,901.82986
Policy Entropy: 3.79345
Value Function Loss: 0.02340

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.49585
Value Function Update Magnitude: 0.76773

Collected Steps per Second: 16,633.19094
Overall Steps per Second: 9,184.47359

Timestep Collection Time: 3.00616
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 5.44419

Cumulative Model Updates: 173,172
Cumulative Timesteps: 1,444,041,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,919.61069
Policy Entropy: 3.79590
Value Function Loss: 0.02172

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.85681

Collected Steps per Second: 18,621.23068
Overall Steps per Second: 9,665.58663

Timestep Collection Time: 2.68586
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 5.17444

Cumulative Model Updates: 173,178
Cumulative Timesteps: 1,444,091,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1444091658...
Checkpoint 1444091658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,080.23694
Policy Entropy: 3.78110
Value Function Loss: 0.02072

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.52435
Value Function Update Magnitude: 0.82085

Collected Steps per Second: 18,784.61209
Overall Steps per Second: 9,716.05074

Timestep Collection Time: 2.66292
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 5.14839

Cumulative Model Updates: 173,184
Cumulative Timesteps: 1,444,141,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,626.81222
Policy Entropy: 3.76386
Value Function Loss: 0.01999

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.47776
Value Function Update Magnitude: 0.69907

Collected Steps per Second: 18,589.51593
Overall Steps per Second: 9,652.83982

Timestep Collection Time: 2.69152
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 5.18335

Cumulative Model Updates: 173,190
Cumulative Timesteps: 1,444,191,714

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1444191714...
Checkpoint 1444191714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,318.76271
Policy Entropy: 3.75411
Value Function Loss: 0.02485

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.45945
Value Function Update Magnitude: 0.55725

Collected Steps per Second: 18,556.37294
Overall Steps per Second: 9,536.23073

Timestep Collection Time: 2.69600
Timestep Consumption Time: 2.55010
PPO Batch Consumption Time: 0.30873
Total Iteration Time: 5.24610

Cumulative Model Updates: 173,196
Cumulative Timesteps: 1,444,241,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,123.71878
Policy Entropy: 3.75506
Value Function Loss: 0.02575

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.45241
Value Function Update Magnitude: 0.46756

Collected Steps per Second: 18,353.12976
Overall Steps per Second: 9,577.36538

Timestep Collection Time: 2.72466
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 5.22127

Cumulative Model Updates: 173,202
Cumulative Timesteps: 1,444,291,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1444291748...
Checkpoint 1444291748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,736.10601
Policy Entropy: 3.75123
Value Function Loss: 0.02708

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.46078
Value Function Update Magnitude: 0.52719

Collected Steps per Second: 18,309.30111
Overall Steps per Second: 9,492.49541

Timestep Collection Time: 2.73162
Timestep Consumption Time: 2.53718
PPO Batch Consumption Time: 0.30595
Total Iteration Time: 5.26879

Cumulative Model Updates: 173,208
Cumulative Timesteps: 1,444,341,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,547.12001
Policy Entropy: 3.75333
Value Function Loss: 0.02667

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.50409
Value Function Update Magnitude: 0.54068

Collected Steps per Second: 18,650.90797
Overall Steps per Second: 9,661.16972

Timestep Collection Time: 2.68266
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 5.17888

Cumulative Model Updates: 173,214
Cumulative Timesteps: 1,444,391,796

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1444391796...
Checkpoint 1444391796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,415.64741
Policy Entropy: 3.76042
Value Function Loss: 0.02529

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.49394
Value Function Update Magnitude: 0.53597

Collected Steps per Second: 18,898.56144
Overall Steps per Second: 9,742.65499

Timestep Collection Time: 2.64750
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 5.13556

Cumulative Model Updates: 173,220
Cumulative Timesteps: 1,444,441,830

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,242.39955
Policy Entropy: 3.77749
Value Function Loss: 0.02308

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.44558
Value Function Update Magnitude: 0.54159

Collected Steps per Second: 19,032.39308
Overall Steps per Second: 9,725.12382

Timestep Collection Time: 2.62847
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 5.14400

Cumulative Model Updates: 173,226
Cumulative Timesteps: 1,444,491,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1444491856...
Checkpoint 1444491856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,242.39955
Policy Entropy: 3.77888
Value Function Loss: 0.01739

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.39275
Value Function Update Magnitude: 0.52336

Collected Steps per Second: 18,777.35079
Overall Steps per Second: 9,696.53497

Timestep Collection Time: 2.66427
Timestep Consumption Time: 2.49510
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 5.15937

Cumulative Model Updates: 173,232
Cumulative Timesteps: 1,444,541,884

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,242.39955
Policy Entropy: 3.76440
Value Function Loss: 0.01487

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.35588
Value Function Update Magnitude: 0.44571

Collected Steps per Second: 18,679.05980
Overall Steps per Second: 9,692.92498

Timestep Collection Time: 2.67701
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 5.15881

Cumulative Model Updates: 173,238
Cumulative Timesteps: 1,444,591,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1444591888...
Checkpoint 1444591888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,656.75637
Policy Entropy: 3.76822
Value Function Loss: 0.01270

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.32260
Value Function Update Magnitude: 0.48668

Collected Steps per Second: 19,249.17440
Overall Steps per Second: 9,846.86878

Timestep Collection Time: 2.59751
Timestep Consumption Time: 2.48024
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 5.07776

Cumulative Model Updates: 173,244
Cumulative Timesteps: 1,444,641,888

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,333.75488
Policy Entropy: 3.76674
Value Function Loss: 0.01484

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.32452
Value Function Update Magnitude: 0.56411

Collected Steps per Second: 18,980.69286
Overall Steps per Second: 9,675.05276

Timestep Collection Time: 2.63563
Timestep Consumption Time: 2.53499
PPO Batch Consumption Time: 0.30345
Total Iteration Time: 5.17062

Cumulative Model Updates: 173,250
Cumulative Timesteps: 1,444,691,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1444691914...
Checkpoint 1444691914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,933.57262
Policy Entropy: 3.75877
Value Function Loss: 0.01581

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.36638
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 19,062.99205
Overall Steps per Second: 9,005.52011

Timestep Collection Time: 2.62414
Timestep Consumption Time: 2.93067
PPO Batch Consumption Time: 0.36968
Total Iteration Time: 5.55482

Cumulative Model Updates: 173,256
Cumulative Timesteps: 1,444,741,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,212.97670
Policy Entropy: 3.76044
Value Function Loss: 0.01719

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.41265
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 15,442.51371
Overall Steps per Second: 8,316.54842

Timestep Collection Time: 3.24053
Timestep Consumption Time: 2.77663
PPO Batch Consumption Time: 0.33270
Total Iteration Time: 6.01716

Cumulative Model Updates: 173,262
Cumulative Timesteps: 1,444,791,980

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1444791980...
Checkpoint 1444791980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,275.00969
Policy Entropy: 3.75060
Value Function Loss: 0.01815

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.43497
Value Function Update Magnitude: 0.66214

Collected Steps per Second: 16,910.35256
Overall Steps per Second: 8,930.33309

Timestep Collection Time: 2.95973
Timestep Consumption Time: 2.64477
PPO Batch Consumption Time: 0.31667
Total Iteration Time: 5.60449

Cumulative Model Updates: 173,268
Cumulative Timesteps: 1,444,842,030

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,111.30358
Policy Entropy: 3.77251
Value Function Loss: 0.01791

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.45254
Value Function Update Magnitude: 0.60959

Collected Steps per Second: 16,192.88504
Overall Steps per Second: 7,856.15997

Timestep Collection Time: 3.08790
Timestep Consumption Time: 3.27679
PPO Batch Consumption Time: 0.41187
Total Iteration Time: 6.36469

Cumulative Model Updates: 173,274
Cumulative Timesteps: 1,444,892,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1444892032...
Checkpoint 1444892032 saved!
