Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,920.90230
Policy Entropy: 1.70909
Value Function Loss: 0.06422

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01607
Policy Update Magnitude: 0.18992
Value Function Update Magnitude: 0.15364

Collected Steps per Second: 7,877.18522
Overall Steps per Second: 3,912.17489

Timestep Collection Time: 6.34821
Timestep Consumption Time: 6.43394
PPO Batch Consumption Time: 2.62160
Total Iteration Time: 12.78215

Cumulative Model Updates: 106,266
Cumulative Timesteps: 886,423,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,764.53555
Policy Entropy: 1.66246
Value Function Loss: 0.06870

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04237
Policy Update Magnitude: 0.20945
Value Function Update Magnitude: 0.17977

Collected Steps per Second: 16,739.90220
Overall Steps per Second: 11,410.28509

Timestep Collection Time: 2.98723
Timestep Consumption Time: 1.39530
PPO Batch Consumption Time: 0.33916
Total Iteration Time: 4.38254

Cumulative Model Updates: 106,268
Cumulative Timesteps: 886,473,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 886473152...
Checkpoint 886473152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,056.29690
Policy Entropy: 1.64613
Value Function Loss: 0.06553

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 19,656.37566
Overall Steps per Second: 9,974.42777

Timestep Collection Time: 2.54533
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 5.01603

Cumulative Model Updates: 106,274
Cumulative Timesteps: 886,523,184

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,336.59193
Policy Entropy: 1.62965
Value Function Loss: 0.07198

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.57749
Value Function Update Magnitude: 0.56621

Collected Steps per Second: 20,847.86891
Overall Steps per Second: 10,379.56612

Timestep Collection Time: 2.39929
Timestep Consumption Time: 2.41980
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.81908

Cumulative Model Updates: 106,280
Cumulative Timesteps: 886,573,204

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 886573204...
Checkpoint 886573204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,856.04426
Policy Entropy: 1.63117
Value Function Loss: 0.06799

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17734
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.65720

Collected Steps per Second: 20,168.33938
Overall Steps per Second: 10,128.93360

Timestep Collection Time: 2.48003
Timestep Consumption Time: 2.45811
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.93813

Cumulative Model Updates: 106,286
Cumulative Timesteps: 886,623,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,131.63671
Policy Entropy: 1.63871
Value Function Loss: 0.07687

Mean KL Divergence: 0.02300
SB3 Clip Fraction: 0.19027
Policy Update Magnitude: 0.47354
Value Function Update Magnitude: 0.58401

Collected Steps per Second: 20,614.11241
Overall Steps per Second: 10,168.98350

Timestep Collection Time: 2.42591
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.91770

Cumulative Model Updates: 106,292
Cumulative Timesteps: 886,673,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 886673230...
Checkpoint 886673230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,176.19738
Policy Entropy: 1.64438
Value Function Loss: 0.08058

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.17385
Policy Update Magnitude: 0.48108
Value Function Update Magnitude: 0.43121

Collected Steps per Second: 19,528.46730
Overall Steps per Second: 10,000.07400

Timestep Collection Time: 2.56047
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 5.00016

Cumulative Model Updates: 106,298
Cumulative Timesteps: 886,723,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,641.83788
Policy Entropy: 1.64956
Value Function Loss: 0.08199

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.16830
Policy Update Magnitude: 0.52952
Value Function Update Magnitude: 0.45139

Collected Steps per Second: 19,263.47197
Overall Steps per Second: 9,786.36915

Timestep Collection Time: 2.59694
Timestep Consumption Time: 2.51487
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 5.11180

Cumulative Model Updates: 106,304
Cumulative Timesteps: 886,773,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 886773258...
Checkpoint 886773258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,790.68178
Policy Entropy: 1.65642
Value Function Loss: 0.08421

Mean KL Divergence: 0.02171
SB3 Clip Fraction: 0.18472
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.44389

Collected Steps per Second: 18,056.40384
Overall Steps per Second: 9,447.27473

Timestep Collection Time: 2.76932
Timestep Consumption Time: 2.52363
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 5.29295

Cumulative Model Updates: 106,310
Cumulative Timesteps: 886,823,262

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,678.84826
Policy Entropy: 1.63056
Value Function Loss: 0.07383

Mean KL Divergence: 0.02403
SB3 Clip Fraction: 0.19527
Policy Update Magnitude: 0.52626
Value Function Update Magnitude: 0.57612

Collected Steps per Second: 19,661.66002
Overall Steps per Second: 9,777.40636

Timestep Collection Time: 2.54414
Timestep Consumption Time: 2.57194
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 5.11608

Cumulative Model Updates: 106,316
Cumulative Timesteps: 886,873,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 886873284...
Checkpoint 886873284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,764.80867
Policy Entropy: 1.63124
Value Function Loss: 0.07516

Mean KL Divergence: 0.02234
SB3 Clip Fraction: 0.18207
Policy Update Magnitude: 0.49356
Value Function Update Magnitude: 0.53627

Collected Steps per Second: 19,623.44562
Overall Steps per Second: 9,807.09126

Timestep Collection Time: 2.54899
Timestep Consumption Time: 2.55140
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 5.10039

Cumulative Model Updates: 106,322
Cumulative Timesteps: 886,923,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,822.83749
Policy Entropy: 1.63117
Value Function Loss: 0.07871

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16076
Policy Update Magnitude: 0.52081
Value Function Update Magnitude: 0.42618

Collected Steps per Second: 21,073.62474
Overall Steps per Second: 10,119.87024

Timestep Collection Time: 2.37320
Timestep Consumption Time: 2.56876
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.94196

Cumulative Model Updates: 106,328
Cumulative Timesteps: 886,973,316

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 886973316...
Checkpoint 886973316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,765.01347
Policy Entropy: 1.63044
Value Function Loss: 0.08058

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.42722

Collected Steps per Second: 21,165.90735
Overall Steps per Second: 10,081.67495

Timestep Collection Time: 2.36305
Timestep Consumption Time: 2.59804
PPO Batch Consumption Time: 0.30768
Total Iteration Time: 4.96108

Cumulative Model Updates: 106,334
Cumulative Timesteps: 887,023,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,930.01581
Policy Entropy: 1.62598
Value Function Loss: 0.07629

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.15779
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.45404

Collected Steps per Second: 19,749.39987
Overall Steps per Second: 10,171.67219

Timestep Collection Time: 2.53172
Timestep Consumption Time: 2.38389
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.91561

Cumulative Model Updates: 106,340
Cumulative Timesteps: 887,073,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 887073332...
Checkpoint 887073332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,317.45204
Policy Entropy: 1.61790
Value Function Loss: 0.07434

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.40128

Collected Steps per Second: 18,910.56424
Overall Steps per Second: 9,711.31896

Timestep Collection Time: 2.64445
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 5.14946

Cumulative Model Updates: 106,346
Cumulative Timesteps: 887,123,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,777.18515
Policy Entropy: 1.63024
Value Function Loss: 0.08015

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.17656
Policy Update Magnitude: 0.54565
Value Function Update Magnitude: 0.35866

Collected Steps per Second: 18,717.41902
Overall Steps per Second: 9,048.17533

Timestep Collection Time: 2.67259
Timestep Consumption Time: 2.85604
PPO Batch Consumption Time: 0.33829
Total Iteration Time: 5.52863

Cumulative Model Updates: 106,352
Cumulative Timesteps: 887,173,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 887173364...
Checkpoint 887173364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,054.20635
Policy Entropy: 1.64271
Value Function Loss: 0.08189

Mean KL Divergence: 0.02136
SB3 Clip Fraction: 0.18159
Policy Update Magnitude: 0.51416
Value Function Update Magnitude: 0.37943

Collected Steps per Second: 17,427.55674
Overall Steps per Second: 9,261.00392

Timestep Collection Time: 2.87017
Timestep Consumption Time: 2.53098
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 5.40114

Cumulative Model Updates: 106,358
Cumulative Timesteps: 887,223,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,906.16792
Policy Entropy: 1.64820
Value Function Loss: 0.08383

Mean KL Divergence: 0.01756
SB3 Clip Fraction: 0.16010
Policy Update Magnitude: 0.55160
Value Function Update Magnitude: 0.39010

Collected Steps per Second: 18,865.30142
Overall Steps per Second: 9,514.10881

Timestep Collection Time: 2.65132
Timestep Consumption Time: 2.60592
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 5.25724

Cumulative Model Updates: 106,364
Cumulative Timesteps: 887,273,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 887273402...
Checkpoint 887273402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,631.97165
Policy Entropy: 1.66096
Value Function Loss: 0.08597

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.15991
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.39311

Collected Steps per Second: 16,621.13001
Overall Steps per Second: 8,902.26514

Timestep Collection Time: 3.00966
Timestep Consumption Time: 2.60958
PPO Batch Consumption Time: 0.31101
Total Iteration Time: 5.61924

Cumulative Model Updates: 106,370
Cumulative Timesteps: 887,323,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,095.01663
Policy Entropy: 1.66258
Value Function Loss: 0.07995

Mean KL Divergence: 0.01669
SB3 Clip Fraction: 0.15724
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.38497

Collected Steps per Second: 17,196.19981
Overall Steps per Second: 9,041.59083

Timestep Collection Time: 2.90867
Timestep Consumption Time: 2.62333
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 5.53199

Cumulative Model Updates: 106,376
Cumulative Timesteps: 887,373,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 887373444...
Checkpoint 887373444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,973.10877
Policy Entropy: 1.66208
Value Function Loss: 0.07940

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15034
Policy Update Magnitude: 0.54757
Value Function Update Magnitude: 0.28626

Collected Steps per Second: 19,260.96853
Overall Steps per Second: 10,110.86867

Timestep Collection Time: 2.59717
Timestep Consumption Time: 2.35038
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.94755

Cumulative Model Updates: 106,382
Cumulative Timesteps: 887,423,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,992.62830
Policy Entropy: 1.65671
Value Function Loss: 0.07708

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.13907
Policy Update Magnitude: 0.54494
Value Function Update Magnitude: 0.26961

Collected Steps per Second: 17,694.09399
Overall Steps per Second: 9,355.23545

Timestep Collection Time: 2.82738
Timestep Consumption Time: 2.52021
PPO Batch Consumption Time: 0.30692
Total Iteration Time: 5.34759

Cumulative Model Updates: 106,388
Cumulative Timesteps: 887,473,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887473496...
Checkpoint 887473496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,295.09969
Policy Entropy: 1.66201
Value Function Loss: 0.07631

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13693
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.28238

Collected Steps per Second: 15,246.08663
Overall Steps per Second: 8,017.43028

Timestep Collection Time: 3.27953
Timestep Consumption Time: 2.95688
PPO Batch Consumption Time: 0.34920
Total Iteration Time: 6.23641

Cumulative Model Updates: 106,394
Cumulative Timesteps: 887,523,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,662.80387
Policy Entropy: 1.66297
Value Function Loss: 0.07371

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13599
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.29554

Collected Steps per Second: 17,511.90876
Overall Steps per Second: 9,138.89033

Timestep Collection Time: 2.85531
Timestep Consumption Time: 2.61603
PPO Batch Consumption Time: 0.29996
Total Iteration Time: 5.47134

Cumulative Model Updates: 106,400
Cumulative Timesteps: 887,573,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 887573498...
Checkpoint 887573498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,361.51636
Policy Entropy: 1.68345
Value Function Loss: 0.07456

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.37630

Collected Steps per Second: 17,833.08961
Overall Steps per Second: 9,229.12441

Timestep Collection Time: 2.80523
Timestep Consumption Time: 2.61521
PPO Batch Consumption Time: 0.31213
Total Iteration Time: 5.42045

Cumulative Model Updates: 106,406
Cumulative Timesteps: 887,623,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,799.15882
Policy Entropy: 1.69168
Value Function Loss: 0.07630

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.46111

Collected Steps per Second: 17,916.90716
Overall Steps per Second: 9,202.04114

Timestep Collection Time: 2.79144
Timestep Consumption Time: 2.64366
PPO Batch Consumption Time: 0.31391
Total Iteration Time: 5.43510

Cumulative Model Updates: 106,412
Cumulative Timesteps: 887,673,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 887673538...
Checkpoint 887673538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,385.09873
Policy Entropy: 1.70012
Value Function Loss: 0.07694

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.55923
Value Function Update Magnitude: 0.49381

Collected Steps per Second: 17,850.28144
Overall Steps per Second: 8,739.70437

Timestep Collection Time: 2.80242
Timestep Consumption Time: 2.92134
PPO Batch Consumption Time: 0.34289
Total Iteration Time: 5.72376

Cumulative Model Updates: 106,418
Cumulative Timesteps: 887,723,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,172.19779
Policy Entropy: 1.68425
Value Function Loss: 0.07793

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.42453

Collected Steps per Second: 17,816.53217
Overall Steps per Second: 8,797.14816

Timestep Collection Time: 2.80807
Timestep Consumption Time: 2.87900
PPO Batch Consumption Time: 0.33635
Total Iteration Time: 5.68707

Cumulative Model Updates: 106,424
Cumulative Timesteps: 887,773,592

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 887773592...
Checkpoint 887773592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,495.84987
Policy Entropy: 1.68433
Value Function Loss: 0.07163

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.54284

Collected Steps per Second: 18,325.93295
Overall Steps per Second: 9,297.68669

Timestep Collection Time: 2.72914
Timestep Consumption Time: 2.65005
PPO Batch Consumption Time: 0.32042
Total Iteration Time: 5.37919

Cumulative Model Updates: 106,430
Cumulative Timesteps: 887,823,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,578.01035
Policy Entropy: 1.68593
Value Function Loss: 0.06808

Mean KL Divergence: 0.02221
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.48389
Value Function Update Magnitude: 0.66435

Collected Steps per Second: 18,281.22149
Overall Steps per Second: 9,212.05906

Timestep Collection Time: 2.73505
Timestep Consumption Time: 2.69262
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 5.42767

Cumulative Model Updates: 106,436
Cumulative Timesteps: 887,873,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 887873606...
Checkpoint 887873606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,492.18420
Policy Entropy: 1.68448
Value Function Loss: 0.07327

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.15466
Policy Update Magnitude: 0.49855
Value Function Update Magnitude: 0.63723

Collected Steps per Second: 19,636.69216
Overall Steps per Second: 9,777.39410

Timestep Collection Time: 2.54829
Timestep Consumption Time: 2.56964
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 5.11793

Cumulative Model Updates: 106,442
Cumulative Timesteps: 887,923,646

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,602.80469
Policy Entropy: 1.67446
Value Function Loss: 0.07868

Mean KL Divergence: 0.01674
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.50460
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 20,624.95307
Overall Steps per Second: 9,941.89055

Timestep Collection Time: 2.42502
Timestep Consumption Time: 2.60581
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 5.03083

Cumulative Model Updates: 106,448
Cumulative Timesteps: 887,973,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 887973662...
Checkpoint 887973662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,928.24222
Policy Entropy: 1.67749
Value Function Loss: 0.07927

Mean KL Divergence: 0.01642
SB3 Clip Fraction: 0.15421
Policy Update Magnitude: 0.50522
Value Function Update Magnitude: 0.61816

Collected Steps per Second: 20,773.19274
Overall Steps per Second: 10,045.31075

Timestep Collection Time: 2.40762
Timestep Consumption Time: 2.57122
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.97884

Cumulative Model Updates: 106,454
Cumulative Timesteps: 888,023,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,891.72064
Policy Entropy: 1.68374
Value Function Loss: 0.07863

Mean KL Divergence: 0.01839
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.48813
Value Function Update Magnitude: 0.59198

Collected Steps per Second: 19,348.32002
Overall Steps per Second: 9,070.81875

Timestep Collection Time: 2.58482
Timestep Consumption Time: 2.92868
PPO Batch Consumption Time: 0.34283
Total Iteration Time: 5.51350

Cumulative Model Updates: 106,460
Cumulative Timesteps: 888,073,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 888073688...
Checkpoint 888073688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,457.80771
Policy Entropy: 1.69156
Value Function Loss: 0.08237

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.16056
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 17,357.97294
Overall Steps per Second: 9,189.39762

Timestep Collection Time: 2.88064
Timestep Consumption Time: 2.56063
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 5.44127

Cumulative Model Updates: 106,466
Cumulative Timesteps: 888,123,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,259.32393
Policy Entropy: 1.69417
Value Function Loss: 0.08529

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15815
Policy Update Magnitude: 0.56361
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 18,532.75053
Overall Steps per Second: 9,460.66509

Timestep Collection Time: 2.69814
Timestep Consumption Time: 2.58732
PPO Batch Consumption Time: 0.30250
Total Iteration Time: 5.28546

Cumulative Model Updates: 106,472
Cumulative Timesteps: 888,173,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 888173694...
Checkpoint 888173694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,346.06399
Policy Entropy: 1.69625
Value Function Loss: 0.08328

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15943
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.46967

Collected Steps per Second: 17,328.67453
Overall Steps per Second: 9,077.69468

Timestep Collection Time: 2.88678
Timestep Consumption Time: 2.62387
PPO Batch Consumption Time: 0.30255
Total Iteration Time: 5.51065

Cumulative Model Updates: 106,478
Cumulative Timesteps: 888,223,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,636.66770
Policy Entropy: 1.69540
Value Function Loss: 0.07891

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.55197
Value Function Update Magnitude: 0.51341

Collected Steps per Second: 19,560.55858
Overall Steps per Second: 9,707.47017

Timestep Collection Time: 2.55831
Timestep Consumption Time: 2.59669
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 5.15500

Cumulative Model Updates: 106,484
Cumulative Timesteps: 888,273,760

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 888273760...
Checkpoint 888273760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,320.70251
Policy Entropy: 1.67723
Value Function Loss: 0.07167

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.53566
Value Function Update Magnitude: 0.64652

Collected Steps per Second: 19,251.83227
Overall Steps per Second: 9,612.10059

Timestep Collection Time: 2.59861
Timestep Consumption Time: 2.60608
PPO Batch Consumption Time: 0.30476
Total Iteration Time: 5.20469

Cumulative Model Updates: 106,490
Cumulative Timesteps: 888,323,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,336.64744
Policy Entropy: 1.68217
Value Function Loss: 0.07509

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.56006

Collected Steps per Second: 21,155.46556
Overall Steps per Second: 10,168.67219

Timestep Collection Time: 2.36412
Timestep Consumption Time: 2.55432
PPO Batch Consumption Time: 0.29954
Total Iteration Time: 4.91844

Cumulative Model Updates: 106,496
Cumulative Timesteps: 888,373,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 888373802...
Checkpoint 888373802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,960.32542
Policy Entropy: 1.68458
Value Function Loss: 0.07515

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.47184

Collected Steps per Second: 21,068.35226
Overall Steps per Second: 10,166.27814

Timestep Collection Time: 2.37475
Timestep Consumption Time: 2.54662
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.92137

Cumulative Model Updates: 106,502
Cumulative Timesteps: 888,423,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,274.22102
Policy Entropy: 1.68178
Value Function Loss: 0.07428

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.42652

Collected Steps per Second: 21,276.22568
Overall Steps per Second: 10,307.98292

Timestep Collection Time: 2.35154
Timestep Consumption Time: 2.50217
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.85371

Cumulative Model Updates: 106,508
Cumulative Timesteps: 888,473,866

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 888473866...
Checkpoint 888473866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,644.44542
Policy Entropy: 1.68393
Value Function Loss: 0.06762

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14444
Policy Update Magnitude: 0.54007
Value Function Update Magnitude: 0.49776

Collected Steps per Second: 20,980.68443
Overall Steps per Second: 10,259.14927

Timestep Collection Time: 2.38362
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.87467

Cumulative Model Updates: 106,514
Cumulative Timesteps: 888,523,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,996.80604
Policy Entropy: 1.68561
Value Function Loss: 0.07251

Mean KL Divergence: 0.01736
SB3 Clip Fraction: 0.16064
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.50115

Collected Steps per Second: 20,645.34256
Overall Steps per Second: 10,149.78573

Timestep Collection Time: 2.42311
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.92877

Cumulative Model Updates: 106,520
Cumulative Timesteps: 888,573,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 888573902...
Checkpoint 888573902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,715.53167
Policy Entropy: 1.68008
Value Function Loss: 0.08066

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.51943
Value Function Update Magnitude: 0.51825

Collected Steps per Second: 20,975.70009
Overall Steps per Second: 10,203.53833

Timestep Collection Time: 2.38457
Timestep Consumption Time: 2.51746
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.90202

Cumulative Model Updates: 106,526
Cumulative Timesteps: 888,623,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,459.27445
Policy Entropy: 1.68134
Value Function Loss: 0.09932

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.18141
Policy Update Magnitude: 0.51174
Value Function Update Magnitude: 0.44431

Collected Steps per Second: 21,173.03222
Overall Steps per Second: 10,187.24761

Timestep Collection Time: 2.36206
Timestep Consumption Time: 2.54721
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.90928

Cumulative Model Updates: 106,532
Cumulative Timesteps: 888,673,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 888673932...
Checkpoint 888673932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,446.41635
Policy Entropy: 1.67298
Value Function Loss: 0.09986

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.17163
Policy Update Magnitude: 0.59140
Value Function Update Magnitude: 0.42120

Collected Steps per Second: 21,101.19832
Overall Steps per Second: 10,161.74958

Timestep Collection Time: 2.36991
Timestep Consumption Time: 2.55129
PPO Batch Consumption Time: 0.29748
Total Iteration Time: 4.92120

Cumulative Model Updates: 106,538
Cumulative Timesteps: 888,723,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,527.79996
Policy Entropy: 1.67987
Value Function Loss: 0.09370

Mean KL Divergence: 0.02120
SB3 Clip Fraction: 0.18355
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.41472

Collected Steps per Second: 21,146.78062
Overall Steps per Second: 10,248.70387

Timestep Collection Time: 2.36566
Timestep Consumption Time: 2.51555
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.88120

Cumulative Model Updates: 106,544
Cumulative Timesteps: 888,773,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 888773966...
Checkpoint 888773966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,134.70621
Policy Entropy: 1.66987
Value Function Loss: 0.08212

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.18071
Policy Update Magnitude: 0.47497
Value Function Update Magnitude: 0.45115

Collected Steps per Second: 20,717.04339
Overall Steps per Second: 10,198.26820

Timestep Collection Time: 2.41347
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.90279

Cumulative Model Updates: 106,550
Cumulative Timesteps: 888,823,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,713.40028
Policy Entropy: 1.67463
Value Function Loss: 0.07922

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.13919
Policy Update Magnitude: 0.47719
Value Function Update Magnitude: 0.35981

Collected Steps per Second: 21,027.72369
Overall Steps per Second: 10,117.04029

Timestep Collection Time: 2.37819
Timestep Consumption Time: 2.56475
PPO Batch Consumption Time: 0.29963
Total Iteration Time: 4.94295

Cumulative Model Updates: 106,556
Cumulative Timesteps: 888,873,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 888873974...
Checkpoint 888873974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,460.42894
Policy Entropy: 1.67634
Value Function Loss: 0.07095

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13435
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.26332

Collected Steps per Second: 20,986.87653
Overall Steps per Second: 10,201.39767

Timestep Collection Time: 2.38378
Timestep Consumption Time: 2.52026
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.90403

Cumulative Model Updates: 106,562
Cumulative Timesteps: 888,924,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,666.34171
Policy Entropy: 1.67939
Value Function Loss: 0.07645

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16215
Policy Update Magnitude: 0.48864
Value Function Update Magnitude: 0.23672

Collected Steps per Second: 20,520.44001
Overall Steps per Second: 10,227.86392

Timestep Collection Time: 2.43747
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.89037

Cumulative Model Updates: 106,568
Cumulative Timesteps: 888,974,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 888974020...
Checkpoint 888974020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,191.43481
Policy Entropy: 1.69113
Value Function Loss: 0.07173

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.44976
Value Function Update Magnitude: 0.30689

Collected Steps per Second: 20,515.32397
Overall Steps per Second: 10,339.77656

Timestep Collection Time: 2.43847
Timestep Consumption Time: 2.39974
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.83821

Cumulative Model Updates: 106,574
Cumulative Timesteps: 889,024,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,818.48753
Policy Entropy: 1.69619
Value Function Loss: 0.08102

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.48125
Value Function Update Magnitude: 0.44477

Collected Steps per Second: 20,675.91856
Overall Steps per Second: 10,219.66204

Timestep Collection Time: 2.41876
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.89351

Cumulative Model Updates: 106,580
Cumulative Timesteps: 889,074,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 889074056...
Checkpoint 889074056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,531.05751
Policy Entropy: 1.70294
Value Function Loss: 0.07198

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.54506
Value Function Update Magnitude: 0.54877

Collected Steps per Second: 20,632.14598
Overall Steps per Second: 10,245.21550

Timestep Collection Time: 2.42398
Timestep Consumption Time: 2.45751
PPO Batch Consumption Time: 0.29799
Total Iteration Time: 4.88150

Cumulative Model Updates: 106,586
Cumulative Timesteps: 889,124,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,470.31976
Policy Entropy: 1.69101
Value Function Loss: 0.07431

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.60569

Collected Steps per Second: 19,975.87061
Overall Steps per Second: 9,986.45873

Timestep Collection Time: 2.50342
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.30472
Total Iteration Time: 5.00758

Cumulative Model Updates: 106,592
Cumulative Timesteps: 889,174,076

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 889174076...
Checkpoint 889174076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,949.27243
Policy Entropy: 1.69535
Value Function Loss: 0.07165

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14759
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.73418

Collected Steps per Second: 20,239.56915
Overall Steps per Second: 10,143.66953

Timestep Collection Time: 2.47090
Timestep Consumption Time: 2.45927
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.93017

Cumulative Model Updates: 106,598
Cumulative Timesteps: 889,224,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,116.55072
Policy Entropy: 1.67837
Value Function Loss: 0.07337

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.71012

Collected Steps per Second: 21,151.42410
Overall Steps per Second: 10,332.90892

Timestep Collection Time: 2.36504
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.84123

Cumulative Model Updates: 106,604
Cumulative Timesteps: 889,274,110

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 889274110...
Checkpoint 889274110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,407.73265
Policy Entropy: 1.68827
Value Function Loss: 0.07633

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.54547
Value Function Update Magnitude: 0.69618

Collected Steps per Second: 20,580.35939
Overall Steps per Second: 10,209.55087

Timestep Collection Time: 2.43106
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.90051

Cumulative Model Updates: 106,610
Cumulative Timesteps: 889,324,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,074.22197
Policy Entropy: 1.67499
Value Function Loss: 0.07522

Mean KL Divergence: 0.02061
SB3 Clip Fraction: 0.17511
Policy Update Magnitude: 0.49827
Value Function Update Magnitude: 0.69853

Collected Steps per Second: 21,392.78593
Overall Steps per Second: 10,296.62358

Timestep Collection Time: 2.33808
Timestep Consumption Time: 2.51963
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.85771

Cumulative Model Updates: 106,616
Cumulative Timesteps: 889,374,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 889374160...
Checkpoint 889374160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,660.25283
Policy Entropy: 1.68356
Value Function Loss: 0.07931

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.50492
Value Function Update Magnitude: 0.69332

Collected Steps per Second: 21,155.53391
Overall Steps per Second: 10,372.78266

Timestep Collection Time: 2.36420
Timestep Consumption Time: 2.45765
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.82185

Cumulative Model Updates: 106,622
Cumulative Timesteps: 889,424,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,443.78355
Policy Entropy: 1.68793
Value Function Loss: 0.07977

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.68141

Collected Steps per Second: 21,156.22284
Overall Steps per Second: 10,129.63356

Timestep Collection Time: 2.36545
Timestep Consumption Time: 2.57491
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.94036

Cumulative Model Updates: 106,628
Cumulative Timesteps: 889,474,220

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 889474220...
Checkpoint 889474220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,269.13936
Policy Entropy: 1.70156
Value Function Loss: 0.07519

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15914
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.60048

Collected Steps per Second: 20,381.90371
Overall Steps per Second: 10,100.69691

Timestep Collection Time: 2.45345
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.95075

Cumulative Model Updates: 106,634
Cumulative Timesteps: 889,524,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.69720
Policy Entropy: 1.68460
Value Function Loss: 0.07443

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.57586
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 21,369.81305
Overall Steps per Second: 10,192.49664

Timestep Collection Time: 2.34125
Timestep Consumption Time: 2.56746
PPO Batch Consumption Time: 0.30031
Total Iteration Time: 4.90871

Cumulative Model Updates: 106,640
Cumulative Timesteps: 889,574,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 889574258...
Checkpoint 889574258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,851.61235
Policy Entropy: 1.67859
Value Function Loss: 0.07097

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14734
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.72610

Collected Steps per Second: 19,176.32893
Overall Steps per Second: 9,928.58508

Timestep Collection Time: 2.61009
Timestep Consumption Time: 2.43111
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 5.04120

Cumulative Model Updates: 106,646
Cumulative Timesteps: 889,624,310

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,774.62367
Policy Entropy: 1.68197
Value Function Loss: 0.07044

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.79613

Collected Steps per Second: 21,109.57059
Overall Steps per Second: 10,321.56268

Timestep Collection Time: 2.36926
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.84558

Cumulative Model Updates: 106,652
Cumulative Timesteps: 889,674,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 889674324...
Checkpoint 889674324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,977.53144
Policy Entropy: 1.68800
Value Function Loss: 0.07051

Mean KL Divergence: 0.01719
SB3 Clip Fraction: 0.15854
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.82726

Collected Steps per Second: 18,947.83907
Overall Steps per Second: 9,631.83790

Timestep Collection Time: 2.63914
Timestep Consumption Time: 2.55260
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 5.19174

Cumulative Model Updates: 106,658
Cumulative Timesteps: 889,724,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,962.01954
Policy Entropy: 1.69885
Value Function Loss: 0.07373

Mean KL Divergence: 0.01843
SB3 Clip Fraction: 0.16283
Policy Update Magnitude: 0.50396
Value Function Update Magnitude: 0.66168

Collected Steps per Second: 19,161.40330
Overall Steps per Second: 9,215.91139

Timestep Collection Time: 2.60952
Timestep Consumption Time: 2.81610
PPO Batch Consumption Time: 0.33133
Total Iteration Time: 5.42562

Cumulative Model Updates: 106,664
Cumulative Timesteps: 889,774,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 889774332...
Checkpoint 889774332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,611.38911
Policy Entropy: 1.69977
Value Function Loss: 0.07200

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.17169
Policy Update Magnitude: 0.50441
Value Function Update Magnitude: 0.60753

Collected Steps per Second: 18,701.95442
Overall Steps per Second: 9,691.71977

Timestep Collection Time: 2.67491
Timestep Consumption Time: 2.48682
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 5.16173

Cumulative Model Updates: 106,670
Cumulative Timesteps: 889,824,358

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,376.47216
Policy Entropy: 1.69136
Value Function Loss: 0.07271

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.15993
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 20,341.58670
Overall Steps per Second: 10,014.22199

Timestep Collection Time: 2.45861
Timestep Consumption Time: 2.53549
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.99410

Cumulative Model Updates: 106,676
Cumulative Timesteps: 889,874,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 889874370...
Checkpoint 889874370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,704.92888
Policy Entropy: 1.68404
Value Function Loss: 0.07132

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15561
Policy Update Magnitude: 0.57284
Value Function Update Magnitude: 0.72328

Collected Steps per Second: 21,314.27461
Overall Steps per Second: 10,209.64257

Timestep Collection Time: 2.34716
Timestep Consumption Time: 2.55291
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.90007

Cumulative Model Updates: 106,682
Cumulative Timesteps: 889,924,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,756.22757
Policy Entropy: 1.68112
Value Function Loss: 0.07506

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.63073

Collected Steps per Second: 19,611.67842
Overall Steps per Second: 9,174.52306

Timestep Collection Time: 2.55113
Timestep Consumption Time: 2.90223
PPO Batch Consumption Time: 0.33622
Total Iteration Time: 5.45336

Cumulative Model Updates: 106,688
Cumulative Timesteps: 889,974,430

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 889974430...
Checkpoint 889974430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,155.49343
Policy Entropy: 1.67820
Value Function Loss: 0.07388

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14094
Policy Update Magnitude: 0.58324
Value Function Update Magnitude: 0.59021

Collected Steps per Second: 19,964.06883
Overall Steps per Second: 9,944.65320

Timestep Collection Time: 2.50590
Timestep Consumption Time: 2.52474
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 5.03064

Cumulative Model Updates: 106,694
Cumulative Timesteps: 890,024,458

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,672.31990
Policy Entropy: 1.67832
Value Function Loss: 0.07611

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.58918
Value Function Update Magnitude: 0.51888

Collected Steps per Second: 20,751.65597
Overall Steps per Second: 10,085.65872

Timestep Collection Time: 2.40974
Timestep Consumption Time: 2.54839
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.95813

Cumulative Model Updates: 106,700
Cumulative Timesteps: 890,074,464

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890074464...
Checkpoint 890074464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,184.09186
Policy Entropy: 1.69729
Value Function Loss: 0.07161

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.14998
Policy Update Magnitude: 0.57688
Value Function Update Magnitude: 0.53271

Collected Steps per Second: 21,126.05283
Overall Steps per Second: 10,113.87994

Timestep Collection Time: 2.36722
Timestep Consumption Time: 2.57747
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.94469

Cumulative Model Updates: 106,706
Cumulative Timesteps: 890,124,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,696.82515
Policy Entropy: 1.68649
Value Function Loss: 0.07233

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.55875
Value Function Update Magnitude: 0.55245

Collected Steps per Second: 20,776.18891
Overall Steps per Second: 10,144.40296

Timestep Collection Time: 2.40699
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.92961

Cumulative Model Updates: 106,712
Cumulative Timesteps: 890,174,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890174482...
Checkpoint 890174482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,937.35857
Policy Entropy: 1.68955
Value Function Loss: 0.07357

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14208
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.53238

Collected Steps per Second: 20,569.03269
Overall Steps per Second: 10,165.92298

Timestep Collection Time: 2.43094
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.91859

Cumulative Model Updates: 106,718
Cumulative Timesteps: 890,224,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,765.00945
Policy Entropy: 1.69025
Value Function Loss: 0.07549

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.56346
Value Function Update Magnitude: 0.67590

Collected Steps per Second: 20,723.87801
Overall Steps per Second: 10,029.22259

Timestep Collection Time: 2.41335
Timestep Consumption Time: 2.57348
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.98683

Cumulative Model Updates: 106,724
Cumulative Timesteps: 890,274,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 890274498...
Checkpoint 890274498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,029.96358
Policy Entropy: 1.70952
Value Function Loss: 0.07257

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.15906
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.68110

Collected Steps per Second: 21,507.27400
Overall Steps per Second: 10,186.00695

Timestep Collection Time: 2.32545
Timestep Consumption Time: 2.58462
PPO Batch Consumption Time: 0.30381
Total Iteration Time: 4.91007

Cumulative Model Updates: 106,730
Cumulative Timesteps: 890,324,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,483.07438
Policy Entropy: 1.69856
Value Function Loss: 0.07588

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.57439
Value Function Update Magnitude: 0.49806

Collected Steps per Second: 20,919.36178
Overall Steps per Second: 10,075.44231

Timestep Collection Time: 2.39051
Timestep Consumption Time: 2.57284
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.96336

Cumulative Model Updates: 106,736
Cumulative Timesteps: 890,374,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890374520...
Checkpoint 890374520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,063.04221
Policy Entropy: 1.70606
Value Function Loss: 0.07852

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.58201
Value Function Update Magnitude: 0.47970

Collected Steps per Second: 20,808.67478
Overall Steps per Second: 10,028.11039

Timestep Collection Time: 2.40332
Timestep Consumption Time: 2.58366
PPO Batch Consumption Time: 0.30414
Total Iteration Time: 4.98698

Cumulative Model Updates: 106,742
Cumulative Timesteps: 890,424,530

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,450.51685
Policy Entropy: 1.70396
Value Function Loss: 0.07386

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.58008
Value Function Update Magnitude: 0.61978

Collected Steps per Second: 21,035.98881
Overall Steps per Second: 10,181.42894

Timestep Collection Time: 2.37840
Timestep Consumption Time: 2.53564
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.91404

Cumulative Model Updates: 106,748
Cumulative Timesteps: 890,474,562

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 890474562...
Checkpoint 890474562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,270.03005
Policy Entropy: 1.71361
Value Function Loss: 0.06892

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.57329
Value Function Update Magnitude: 0.59835

Collected Steps per Second: 20,495.72188
Overall Steps per Second: 10,182.98359

Timestep Collection Time: 2.44002
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.91113

Cumulative Model Updates: 106,754
Cumulative Timesteps: 890,524,572

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,745.94068
Policy Entropy: 1.70353
Value Function Loss: 0.07294

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.55496

Collected Steps per Second: 20,262.90422
Overall Steps per Second: 10,087.38902

Timestep Collection Time: 2.46914
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.30127
Total Iteration Time: 4.95986

Cumulative Model Updates: 106,760
Cumulative Timesteps: 890,574,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 890574604...
Checkpoint 890574604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,512.57198
Policy Entropy: 1.69466
Value Function Loss: 0.07116

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.52264

Collected Steps per Second: 19,976.93249
Overall Steps per Second: 10,214.57988

Timestep Collection Time: 2.50439
Timestep Consumption Time: 2.39351
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.89790

Cumulative Model Updates: 106,766
Cumulative Timesteps: 890,624,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,427.15716
Policy Entropy: 1.70697
Value Function Loss: 0.07954

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.43918

Collected Steps per Second: 20,117.08876
Overall Steps per Second: 10,013.53024

Timestep Collection Time: 2.48605
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.30305
Total Iteration Time: 4.99444

Cumulative Model Updates: 106,772
Cumulative Timesteps: 890,674,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 890674646...
Checkpoint 890674646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,947.98951
Policy Entropy: 1.69731
Value Function Loss: 0.07938

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.39476

Collected Steps per Second: 20,376.98315
Overall Steps per Second: 10,146.94507

Timestep Collection Time: 2.45453
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.92917

Cumulative Model Updates: 106,778
Cumulative Timesteps: 890,724,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,474.69294
Policy Entropy: 1.69599
Value Function Loss: 0.07584

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.36390

Collected Steps per Second: 20,967.23648
Overall Steps per Second: 10,137.55634

Timestep Collection Time: 2.38591
Timestep Consumption Time: 2.54881
PPO Batch Consumption Time: 0.30231
Total Iteration Time: 4.93472

Cumulative Model Updates: 106,784
Cumulative Timesteps: 890,774,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 890774688...
Checkpoint 890774688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,090.69725
Policy Entropy: 1.67533
Value Function Loss: 0.07056

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.48418

Collected Steps per Second: 20,238.45935
Overall Steps per Second: 10,161.81489

Timestep Collection Time: 2.47242
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.92412

Cumulative Model Updates: 106,790
Cumulative Timesteps: 890,824,726

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,130.80831
Policy Entropy: 1.68813
Value Function Loss: 0.07760

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.57242
Value Function Update Magnitude: 0.51131

Collected Steps per Second: 20,955.73243
Overall Steps per Second: 10,142.15938

Timestep Collection Time: 2.38627
Timestep Consumption Time: 2.54424
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.93051

Cumulative Model Updates: 106,796
Cumulative Timesteps: 890,874,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890874732...
Checkpoint 890874732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,773.86121
Policy Entropy: 1.69571
Value Function Loss: 0.08381

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.58754
Value Function Update Magnitude: 0.47038

Collected Steps per Second: 21,457.41142
Overall Steps per Second: 10,450.43529

Timestep Collection Time: 2.33020
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.78449

Cumulative Model Updates: 106,802
Cumulative Timesteps: 890,924,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,549.86218
Policy Entropy: 1.70296
Value Function Loss: 0.07809

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.68881

Collected Steps per Second: 20,957.79775
Overall Steps per Second: 10,104.39743

Timestep Collection Time: 2.38718
Timestep Consumption Time: 2.56413
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.95131

Cumulative Model Updates: 106,808
Cumulative Timesteps: 890,974,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 890974762...
Checkpoint 890974762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,027.84551
Policy Entropy: 1.71038
Value Function Loss: 0.06874

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.15737
Policy Update Magnitude: 0.57007
Value Function Update Magnitude: 0.76250

Collected Steps per Second: 21,282.56186
Overall Steps per Second: 10,081.44250

Timestep Collection Time: 2.35122
Timestep Consumption Time: 2.61235
PPO Batch Consumption Time: 0.30659
Total Iteration Time: 4.96358

Cumulative Model Updates: 106,814
Cumulative Timesteps: 891,024,802

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,228.30252
Policy Entropy: 1.70742
Value Function Loss: 0.06707

Mean KL Divergence: 0.01686
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.54303
Value Function Update Magnitude: 0.67496

Collected Steps per Second: 20,591.24562
Overall Steps per Second: 10,038.18336

Timestep Collection Time: 2.42860
Timestep Consumption Time: 2.55317
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.98178

Cumulative Model Updates: 106,820
Cumulative Timesteps: 891,074,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 891074810...
Checkpoint 891074810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,274.41088
Policy Entropy: 1.70700
Value Function Loss: 0.06415

Mean KL Divergence: 0.02004
SB3 Clip Fraction: 0.17660
Policy Update Magnitude: 0.50238
Value Function Update Magnitude: 0.68351

Collected Steps per Second: 21,344.75816
Overall Steps per Second: 10,357.85956

Timestep Collection Time: 2.34409
Timestep Consumption Time: 2.48645
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.83053

Cumulative Model Updates: 106,826
Cumulative Timesteps: 891,124,844

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,769.64693
Policy Entropy: 1.70289
Value Function Loss: 0.06880

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16155
Policy Update Magnitude: 0.50367
Value Function Update Magnitude: 0.68036

Collected Steps per Second: 20,743.93445
Overall Steps per Second: 9,816.98112

Timestep Collection Time: 2.41150
Timestep Consumption Time: 2.68416
PPO Batch Consumption Time: 0.31260
Total Iteration Time: 5.09566

Cumulative Model Updates: 106,832
Cumulative Timesteps: 891,174,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 891174868...
Checkpoint 891174868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,910.15419
Policy Entropy: 1.69176
Value Function Loss: 0.07502

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.16055
Policy Update Magnitude: 0.49930
Value Function Update Magnitude: 0.71208

Collected Steps per Second: 20,005.38883
Overall Steps per Second: 10,010.34410

Timestep Collection Time: 2.50073
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.99763

Cumulative Model Updates: 106,838
Cumulative Timesteps: 891,224,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,956.46459
Policy Entropy: 1.69187
Value Function Loss: 0.07349

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.54544
Value Function Update Magnitude: 0.73539

Collected Steps per Second: 20,785.34872
Overall Steps per Second: 9,834.71244

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.68053
PPO Batch Consumption Time: 0.31673
Total Iteration Time: 5.08790

Cumulative Model Updates: 106,844
Cumulative Timesteps: 891,274,934

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 891274934...
Checkpoint 891274934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,711.97941
Policy Entropy: 1.69386
Value Function Loss: 0.07376

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16201
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.75001

Collected Steps per Second: 20,659.62463
Overall Steps per Second: 10,128.14591

Timestep Collection Time: 2.42153
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.30576
Total Iteration Time: 4.93950

Cumulative Model Updates: 106,850
Cumulative Timesteps: 891,324,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,114.02070
Policy Entropy: 1.69285
Value Function Loss: 0.06482

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.72353

Collected Steps per Second: 21,281.07002
Overall Steps per Second: 10,269.81124

Timestep Collection Time: 2.34960
Timestep Consumption Time: 2.51923
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.86883

Cumulative Model Updates: 106,856
Cumulative Timesteps: 891,374,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 891374964...
Checkpoint 891374964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,022.99136
Policy Entropy: 1.70555
Value Function Loss: 0.06790

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14160
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.63550

Collected Steps per Second: 20,396.36520
Overall Steps per Second: 9,959.16924

Timestep Collection Time: 2.45250
Timestep Consumption Time: 2.57021
PPO Batch Consumption Time: 0.30154
Total Iteration Time: 5.02271

Cumulative Model Updates: 106,862
Cumulative Timesteps: 891,424,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,523.68735
Policy Entropy: 1.70152
Value Function Loss: 0.07191

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.56242

Collected Steps per Second: 21,030.00428
Overall Steps per Second: 9,773.67312

Timestep Collection Time: 2.37803
Timestep Consumption Time: 2.73878
PPO Batch Consumption Time: 0.32832
Total Iteration Time: 5.11681

Cumulative Model Updates: 106,868
Cumulative Timesteps: 891,474,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 891474996...
Checkpoint 891474996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,087.73954
Policy Entropy: 1.71698
Value Function Loss: 0.08407

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.59046
Value Function Update Magnitude: 0.43052

Collected Steps per Second: 20,578.78258
Overall Steps per Second: 10,203.78850

Timestep Collection Time: 2.43027
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.90132

Cumulative Model Updates: 106,874
Cumulative Timesteps: 891,525,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,017.19590
Policy Entropy: 1.70962
Value Function Loss: 0.08386

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14460
Policy Update Magnitude: 0.60020
Value Function Update Magnitude: 0.41346

Collected Steps per Second: 20,947.28092
Overall Steps per Second: 10,242.69098

Timestep Collection Time: 2.38885
Timestep Consumption Time: 2.49658
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.88543

Cumulative Model Updates: 106,880
Cumulative Timesteps: 891,575,048

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 891575048...
Checkpoint 891575048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,917.88884
Policy Entropy: 1.69437
Value Function Loss: 0.08243

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.59965
Value Function Update Magnitude: 0.43454

Collected Steps per Second: 20,198.52071
Overall Steps per Second: 10,018.51582

Timestep Collection Time: 2.47771
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.99535

Cumulative Model Updates: 106,886
Cumulative Timesteps: 891,625,094

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,114.52314
Policy Entropy: 1.68119
Value Function Loss: 0.07656

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.58935
Value Function Update Magnitude: 0.52069

Collected Steps per Second: 20,376.67402
Overall Steps per Second: 9,779.90618

Timestep Collection Time: 2.45545
Timestep Consumption Time: 2.66055
PPO Batch Consumption Time: 0.31669
Total Iteration Time: 5.11600

Cumulative Model Updates: 106,892
Cumulative Timesteps: 891,675,128

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 891675128...
Checkpoint 891675128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,502.78315
Policy Entropy: 1.67095
Value Function Loss: 0.06711

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.56936
Value Function Update Magnitude: 0.51478

Collected Steps per Second: 19,955.71844
Overall Steps per Second: 9,749.39899

Timestep Collection Time: 2.50565
Timestep Consumption Time: 2.62308
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 5.12873

Cumulative Model Updates: 106,898
Cumulative Timesteps: 891,725,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,631.97181
Policy Entropy: 1.70183
Value Function Loss: 0.06890

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.51550

Collected Steps per Second: 21,122.22817
Overall Steps per Second: 9,902.86340

Timestep Collection Time: 2.36793
Timestep Consumption Time: 2.68273
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.05066

Cumulative Model Updates: 106,904
Cumulative Timesteps: 891,775,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 891775146...
Checkpoint 891775146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,239.91682
Policy Entropy: 1.70478
Value Function Loss: 0.06577

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.53644
Value Function Update Magnitude: 0.45695

Collected Steps per Second: 20,528.32759
Overall Steps per Second: 10,165.57278

Timestep Collection Time: 2.43634
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.91994

Cumulative Model Updates: 106,910
Cumulative Timesteps: 891,825,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,865.02750
Policy Entropy: 1.70085
Value Function Loss: 0.07466

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.50865
Value Function Update Magnitude: 0.38143

Collected Steps per Second: 19,521.92252
Overall Steps per Second: 9,823.93123

Timestep Collection Time: 2.56174
Timestep Consumption Time: 2.52889
PPO Batch Consumption Time: 0.30559
Total Iteration Time: 5.09063

Cumulative Model Updates: 106,916
Cumulative Timesteps: 891,875,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 891875170...
Checkpoint 891875170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,980.70007
Policy Entropy: 1.69045
Value Function Loss: 0.07526

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.37041

Collected Steps per Second: 19,689.53182
Overall Steps per Second: 9,730.32577

Timestep Collection Time: 2.54013
Timestep Consumption Time: 2.59988
PPO Batch Consumption Time: 0.30657
Total Iteration Time: 5.14001

Cumulative Model Updates: 106,922
Cumulative Timesteps: 891,925,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,981.14432
Policy Entropy: 1.70524
Value Function Loss: 0.07806

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.45833

Collected Steps per Second: 21,127.48397
Overall Steps per Second: 10,161.08095

Timestep Collection Time: 2.36848
Timestep Consumption Time: 2.55619
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.92467

Cumulative Model Updates: 106,928
Cumulative Timesteps: 891,975,224

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 891975224...
Checkpoint 891975224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,200.26172
Policy Entropy: 1.69706
Value Function Loss: 0.07713

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13831
Policy Update Magnitude: 0.57039
Value Function Update Magnitude: 0.48920

Collected Steps per Second: 20,196.72747
Overall Steps per Second: 9,575.63478

Timestep Collection Time: 2.47604
Timestep Consumption Time: 2.74638
PPO Batch Consumption Time: 0.33186
Total Iteration Time: 5.22242

Cumulative Model Updates: 106,934
Cumulative Timesteps: 892,025,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,349.00289
Policy Entropy: 1.70144
Value Function Loss: 0.08287

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.58674
Value Function Update Magnitude: 0.47763

Collected Steps per Second: 20,272.10056
Overall Steps per Second: 10,128.56943

Timestep Collection Time: 2.46822
Timestep Consumption Time: 2.47187
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.94009

Cumulative Model Updates: 106,940
Cumulative Timesteps: 892,075,268

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 892075268...
Checkpoint 892075268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,449.76923
Policy Entropy: 1.69688
Value Function Loss: 0.08037

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.14904
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.60597

Collected Steps per Second: 20,897.00145
Overall Steps per Second: 10,110.12054

Timestep Collection Time: 2.39422
Timestep Consumption Time: 2.55449
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.94870

Cumulative Model Updates: 106,946
Cumulative Timesteps: 892,125,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,289.00783
Policy Entropy: 1.71330
Value Function Loss: 0.07909

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.16418
Policy Update Magnitude: 0.53308
Value Function Update Magnitude: 0.63682

Collected Steps per Second: 21,227.38677
Overall Steps per Second: 10,133.36731

Timestep Collection Time: 2.35686
Timestep Consumption Time: 2.58029
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.93715

Cumulative Model Updates: 106,952
Cumulative Timesteps: 892,175,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 892175330...
Checkpoint 892175330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,728.59589
Policy Entropy: 1.70826
Value Function Loss: 0.07980

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.17960
Policy Update Magnitude: 0.45989
Value Function Update Magnitude: 0.62520

Collected Steps per Second: 21,153.42252
Overall Steps per Second: 10,176.95921

Timestep Collection Time: 2.36368
Timestep Consumption Time: 2.54938
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 4.91306

Cumulative Model Updates: 106,958
Cumulative Timesteps: 892,225,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,679.16284
Policy Entropy: 1.72215
Value Function Loss: 0.07995

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.47216
Value Function Update Magnitude: 0.64214

Collected Steps per Second: 20,955.09715
Overall Steps per Second: 9,908.40256

Timestep Collection Time: 2.38625
Timestep Consumption Time: 2.66038
PPO Batch Consumption Time: 0.31393
Total Iteration Time: 5.04663

Cumulative Model Updates: 106,964
Cumulative Timesteps: 892,275,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 892275334...
Checkpoint 892275334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,938.00564
Policy Entropy: 1.71613
Value Function Loss: 0.08072

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.53214
Value Function Update Magnitude: 0.52336

Collected Steps per Second: 20,784.48376
Overall Steps per Second: 10,206.76454

Timestep Collection Time: 2.40603
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.89950

Cumulative Model Updates: 106,970
Cumulative Timesteps: 892,325,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,704.48934
Policy Entropy: 1.69541
Value Function Loss: 0.08080

Mean KL Divergence: 0.01800
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.54276
Value Function Update Magnitude: 0.45451

Collected Steps per Second: 21,185.67438
Overall Steps per Second: 10,059.70565

Timestep Collection Time: 2.36112
Timestep Consumption Time: 2.61139
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.97251

Cumulative Model Updates: 106,976
Cumulative Timesteps: 892,375,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 892375364...
Checkpoint 892375364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,985.44639
Policy Entropy: 1.69310
Value Function Loss: 0.08014

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.17143
Policy Update Magnitude: 0.48227
Value Function Update Magnitude: 0.41399

Collected Steps per Second: 20,374.22210
Overall Steps per Second: 10,072.95190

Timestep Collection Time: 2.45575
Timestep Consumption Time: 2.51141
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.96716

Cumulative Model Updates: 106,982
Cumulative Timesteps: 892,425,398

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,798.01653
Policy Entropy: 1.69992
Value Function Loss: 0.07414

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.16140
Policy Update Magnitude: 0.49500
Value Function Update Magnitude: 0.39394

Collected Steps per Second: 21,366.49687
Overall Steps per Second: 10,146.48212

Timestep Collection Time: 2.34011
Timestep Consumption Time: 2.58770
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.92782

Cumulative Model Updates: 106,988
Cumulative Timesteps: 892,475,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 892475398...
Checkpoint 892475398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,996.26263
Policy Entropy: 1.71479
Value Function Loss: 0.07964

Mean KL Divergence: 0.01970
SB3 Clip Fraction: 0.17121
Policy Update Magnitude: 0.48372
Value Function Update Magnitude: 0.39440

Collected Steps per Second: 20,373.65963
Overall Steps per Second: 9,988.55872

Timestep Collection Time: 2.45552
Timestep Consumption Time: 2.55301
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 5.00853

Cumulative Model Updates: 106,994
Cumulative Timesteps: 892,525,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,281.96268
Policy Entropy: 1.71449
Value Function Loss: 0.08266

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.16882
Policy Update Magnitude: 0.51337
Value Function Update Magnitude: 0.37589

Collected Steps per Second: 21,367.82265
Overall Steps per Second: 10,300.10163

Timestep Collection Time: 2.34044
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.85529

Cumulative Model Updates: 107,000
Cumulative Timesteps: 892,575,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 892575436...
Checkpoint 892575436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,012.65015
Policy Entropy: 1.70530
Value Function Loss: 0.08658

Mean KL Divergence: 0.01901
SB3 Clip Fraction: 0.17192
Policy Update Magnitude: 0.52161
Value Function Update Magnitude: 0.40537

Collected Steps per Second: 20,176.10267
Overall Steps per Second: 9,991.43354

Timestep Collection Time: 2.47818
Timestep Consumption Time: 2.52611
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 5.00429

Cumulative Model Updates: 107,006
Cumulative Timesteps: 892,625,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,235.94511
Policy Entropy: 1.69122
Value Function Loss: 0.09753

Mean KL Divergence: 0.02712
SB3 Clip Fraction: 0.20573
Policy Update Magnitude: 0.49932
Value Function Update Magnitude: 0.46130

Collected Steps per Second: 21,188.14913
Overall Steps per Second: 10,256.59518

Timestep Collection Time: 2.35990
Timestep Consumption Time: 2.51520
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.87511

Cumulative Model Updates: 107,012
Cumulative Timesteps: 892,675,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 892675438...
Checkpoint 892675438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,758.63907
Policy Entropy: 1.68092
Value Function Loss: 0.09578

Mean KL Divergence: 0.02668
SB3 Clip Fraction: 0.19596
Policy Update Magnitude: 0.53621
Value Function Update Magnitude: 0.55696

Collected Steps per Second: 20,944.69864
Overall Steps per Second: 10,272.19910

Timestep Collection Time: 2.38753
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.86809

Cumulative Model Updates: 107,018
Cumulative Timesteps: 892,725,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,373.03919
Policy Entropy: 1.69674
Value Function Loss: 0.09794

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.18146
Policy Update Magnitude: 0.54920
Value Function Update Magnitude: 0.52809

Collected Steps per Second: 21,003.89406
Overall Steps per Second: 10,057.86774

Timestep Collection Time: 2.38070
Timestep Consumption Time: 2.59093
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.97163

Cumulative Model Updates: 107,024
Cumulative Timesteps: 892,775,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 892775448...
Checkpoint 892775448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,259.95266
Policy Entropy: 1.69675
Value Function Loss: 0.08791

Mean KL Divergence: 0.02012
SB3 Clip Fraction: 0.17601
Policy Update Magnitude: 0.52403
Value Function Update Magnitude: 0.40609

Collected Steps per Second: 20,902.26044
Overall Steps per Second: 10,164.94355

Timestep Collection Time: 2.39371
Timestep Consumption Time: 2.52850
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.92221

Cumulative Model Updates: 107,030
Cumulative Timesteps: 892,825,482

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,146.26532
Policy Entropy: 1.69756
Value Function Loss: 0.07884

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.17252
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.41734

Collected Steps per Second: 21,309.95790
Overall Steps per Second: 10,280.77245

Timestep Collection Time: 2.34735
Timestep Consumption Time: 2.51823
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.86559

Cumulative Model Updates: 107,036
Cumulative Timesteps: 892,875,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 892875504...
Checkpoint 892875504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,384.82383
Policy Entropy: 1.69424
Value Function Loss: 0.07508

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.16581
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.47428

Collected Steps per Second: 20,562.60268
Overall Steps per Second: 10,058.63500

Timestep Collection Time: 2.43160
Timestep Consumption Time: 2.53925
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.97085

Cumulative Model Updates: 107,042
Cumulative Timesteps: 892,925,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,464.35874
Policy Entropy: 1.70687
Value Function Loss: 0.07607

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.15611
Policy Update Magnitude: 0.54069
Value Function Update Magnitude: 0.46370

Collected Steps per Second: 21,330.44036
Overall Steps per Second: 10,214.85578

Timestep Collection Time: 2.34426
Timestep Consumption Time: 2.55097
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.89522

Cumulative Model Updates: 107,048
Cumulative Timesteps: 892,975,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 892975508...
Checkpoint 892975508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,290.95982
Policy Entropy: 1.72507
Value Function Loss: 0.08141

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.41580

Collected Steps per Second: 20,843.94738
Overall Steps per Second: 10,249.30910

Timestep Collection Time: 2.40012
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.88111

Cumulative Model Updates: 107,054
Cumulative Timesteps: 893,025,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,262.52356
Policy Entropy: 1.72779
Value Function Loss: 0.07630

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13656
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.51952

Collected Steps per Second: 21,405.55833
Overall Steps per Second: 10,129.49087

Timestep Collection Time: 2.33640
Timestep Consumption Time: 2.60086
PPO Batch Consumption Time: 0.30499
Total Iteration Time: 4.93727

Cumulative Model Updates: 107,060
Cumulative Timesteps: 893,075,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 893075548...
Checkpoint 893075548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,997.07251
Policy Entropy: 1.72704
Value Function Loss: 0.06951

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14164
Policy Update Magnitude: 0.57292
Value Function Update Magnitude: 0.69985

Collected Steps per Second: 20,910.56412
Overall Steps per Second: 10,217.69827

Timestep Collection Time: 2.39161
Timestep Consumption Time: 2.50283
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.89445

Cumulative Model Updates: 107,066
Cumulative Timesteps: 893,125,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,334.91932
Policy Entropy: 1.71172
Value Function Loss: 0.06353

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.66291

Collected Steps per Second: 21,073.79992
Overall Steps per Second: 10,076.61604

Timestep Collection Time: 2.37375
Timestep Consumption Time: 2.59061
PPO Batch Consumption Time: 0.30356
Total Iteration Time: 4.96437

Cumulative Model Updates: 107,072
Cumulative Timesteps: 893,175,582

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 893175582...
Checkpoint 893175582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,678.32558
Policy Entropy: 1.71680
Value Function Loss: 0.06538

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.53838

Collected Steps per Second: 20,256.40124
Overall Steps per Second: 10,133.16429

Timestep Collection Time: 2.46885
Timestep Consumption Time: 2.46643
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.93528

Cumulative Model Updates: 107,078
Cumulative Timesteps: 893,225,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,970.81959
Policy Entropy: 1.73257
Value Function Loss: 0.07562

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.41867

Collected Steps per Second: 21,519.56361
Overall Steps per Second: 10,310.64083

Timestep Collection Time: 2.32421
Timestep Consumption Time: 2.52670
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.85091

Cumulative Model Updates: 107,084
Cumulative Timesteps: 893,275,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 893275608...
Checkpoint 893275608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,721.04053
Policy Entropy: 1.74667
Value Function Loss: 0.07926

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14377
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.36592

Collected Steps per Second: 20,885.45578
Overall Steps per Second: 10,145.06567

Timestep Collection Time: 2.39420
Timestep Consumption Time: 2.53470
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.92890

Cumulative Model Updates: 107,090
Cumulative Timesteps: 893,325,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,634.79751
Policy Entropy: 1.74030
Value Function Loss: 0.07990

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.47007

Collected Steps per Second: 21,608.57705
Overall Steps per Second: 10,200.57451

Timestep Collection Time: 2.31390
Timestep Consumption Time: 2.58779
PPO Batch Consumption Time: 0.30134
Total Iteration Time: 4.90168

Cumulative Model Updates: 107,096
Cumulative Timesteps: 893,375,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893375612...
Checkpoint 893375612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,551.69286
Policy Entropy: 1.71950
Value Function Loss: 0.07262

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.63874

Collected Steps per Second: 20,046.42258
Overall Steps per Second: 9,950.18957

Timestep Collection Time: 2.49521
Timestep Consumption Time: 2.53183
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 5.02704

Cumulative Model Updates: 107,102
Cumulative Timesteps: 893,425,632

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,374.70606
Policy Entropy: 1.70586
Value Function Loss: 0.06634

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.15037
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 21,515.10683
Overall Steps per Second: 10,270.46081

Timestep Collection Time: 2.32525
Timestep Consumption Time: 2.54581
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.87106

Cumulative Model Updates: 107,108
Cumulative Timesteps: 893,475,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 893475660...
Checkpoint 893475660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,039.02528
Policy Entropy: 1.70660
Value Function Loss: 0.07360

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.44020

Collected Steps per Second: 20,625.40199
Overall Steps per Second: 9,927.67923

Timestep Collection Time: 2.42623
Timestep Consumption Time: 2.61442
PPO Batch Consumption Time: 0.30525
Total Iteration Time: 5.04065

Cumulative Model Updates: 107,114
Cumulative Timesteps: 893,525,702

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,586.46371
Policy Entropy: 1.70808
Value Function Loss: 0.07803

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14508
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.39763

Collected Steps per Second: 21,303.71169
Overall Steps per Second: 10,125.79846

Timestep Collection Time: 2.34823
Timestep Consumption Time: 2.59222
PPO Batch Consumption Time: 0.30099
Total Iteration Time: 4.94045

Cumulative Model Updates: 107,120
Cumulative Timesteps: 893,575,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 893575728...
Checkpoint 893575728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,151.20603
Policy Entropy: 1.70469
Value Function Loss: 0.07625

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.48480

Collected Steps per Second: 20,249.06496
Overall Steps per Second: 10,111.76892

Timestep Collection Time: 2.47063
Timestep Consumption Time: 2.47687
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.94750

Cumulative Model Updates: 107,126
Cumulative Timesteps: 893,625,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,261.83656
Policy Entropy: 1.70599
Value Function Loss: 0.06961

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.56303
Value Function Update Magnitude: 0.47156

Collected Steps per Second: 21,376.34995
Overall Steps per Second: 10,280.11146

Timestep Collection Time: 2.34016
Timestep Consumption Time: 2.52594
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.86610

Cumulative Model Updates: 107,132
Cumulative Timesteps: 893,675,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 893675780...
Checkpoint 893675780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,076.59802
Policy Entropy: 1.70420
Value Function Loss: 0.06382

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.43887

Collected Steps per Second: 20,668.94832
Overall Steps per Second: 10,045.97530

Timestep Collection Time: 2.42006
Timestep Consumption Time: 2.55905
PPO Batch Consumption Time: 0.29810
Total Iteration Time: 4.97911

Cumulative Model Updates: 107,138
Cumulative Timesteps: 893,725,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,496.89769
Policy Entropy: 1.72267
Value Function Loss: 0.06808

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.52944

Collected Steps per Second: 21,338.07300
Overall Steps per Second: 10,316.62613

Timestep Collection Time: 2.34323
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.84655

Cumulative Model Updates: 107,144
Cumulative Timesteps: 893,775,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893775800...
Checkpoint 893775800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,271.76078
Policy Entropy: 1.71471
Value Function Loss: 0.07047

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.51970
Value Function Update Magnitude: 0.43187

Collected Steps per Second: 20,197.93785
Overall Steps per Second: 9,983.16817

Timestep Collection Time: 2.47629
Timestep Consumption Time: 2.53374
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 5.01003

Cumulative Model Updates: 107,150
Cumulative Timesteps: 893,825,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,689.98256
Policy Entropy: 1.70568
Value Function Loss: 0.07159

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.16132
Policy Update Magnitude: 0.48243
Value Function Update Magnitude: 0.46616

Collected Steps per Second: 20,596.12147
Overall Steps per Second: 10,292.04538

Timestep Collection Time: 2.42871
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.86026

Cumulative Model Updates: 107,156
Cumulative Timesteps: 893,875,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 893875838...
Checkpoint 893875838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,525.37696
Policy Entropy: 1.69471
Value Function Loss: 0.06775

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.15979
Policy Update Magnitude: 0.48904
Value Function Update Magnitude: 0.48321

Collected Steps per Second: 20,027.16354
Overall Steps per Second: 10,125.99932

Timestep Collection Time: 2.49791
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.94035

Cumulative Model Updates: 107,162
Cumulative Timesteps: 893,925,864

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,430.50087
Policy Entropy: 1.67821
Value Function Loss: 0.06550

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.16424
Policy Update Magnitude: 0.47910
Value Function Update Magnitude: 0.52046

Collected Steps per Second: 19,431.12332
Overall Steps per Second: 9,628.67667

Timestep Collection Time: 2.57494
Timestep Consumption Time: 2.62141
PPO Batch Consumption Time: 0.31539
Total Iteration Time: 5.19635

Cumulative Model Updates: 107,168
Cumulative Timesteps: 893,975,898

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 893975898...
Checkpoint 893975898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,326.43800
Policy Entropy: 1.68856
Value Function Loss: 0.06881

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.17836
Policy Update Magnitude: 0.46057
Value Function Update Magnitude: 0.47392

Collected Steps per Second: 19,195.33264
Overall Steps per Second: 9,971.15148

Timestep Collection Time: 2.60574
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 5.01627

Cumulative Model Updates: 107,174
Cumulative Timesteps: 894,025,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,173.80936
Policy Entropy: 1.69951
Value Function Loss: 0.07435

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.48210
Value Function Update Magnitude: 0.39287

Collected Steps per Second: 20,469.59298
Overall Steps per Second: 10,267.01082

Timestep Collection Time: 2.44441
Timestep Consumption Time: 2.42907
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.87347

Cumulative Model Updates: 107,180
Cumulative Timesteps: 894,075,952

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 894075952...
Checkpoint 894075952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,565.72660
Policy Entropy: 1.69882
Value Function Loss: 0.07469

Mean KL Divergence: 0.01954
SB3 Clip Fraction: 0.17108
Policy Update Magnitude: 0.47836
Value Function Update Magnitude: 0.39153

Collected Steps per Second: 20,423.80768
Overall Steps per Second: 10,018.42711

Timestep Collection Time: 2.44998
Timestep Consumption Time: 2.54461
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.99460

Cumulative Model Updates: 107,186
Cumulative Timesteps: 894,125,990

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,542.89321
Policy Entropy: 1.67810
Value Function Loss: 0.07106

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.48410
Value Function Update Magnitude: 0.50117

Collected Steps per Second: 21,332.65578
Overall Steps per Second: 10,277.64438

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.86551

Cumulative Model Updates: 107,192
Cumulative Timesteps: 894,175,996

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 894175996...
Checkpoint 894175996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,684.34393
Policy Entropy: 1.68628
Value Function Loss: 0.06996

Mean KL Divergence: 0.02237
SB3 Clip Fraction: 0.18370
Policy Update Magnitude: 0.46220
Value Function Update Magnitude: 0.56568

Collected Steps per Second: 19,797.36770
Overall Steps per Second: 9,825.70174

Timestep Collection Time: 2.52650
Timestep Consumption Time: 2.56403
PPO Batch Consumption Time: 0.30613
Total Iteration Time: 5.09053

Cumulative Model Updates: 107,198
Cumulative Timesteps: 894,226,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,959.24618
Policy Entropy: 1.69603
Value Function Loss: 0.06870

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.50901
Value Function Update Magnitude: 0.61361

Collected Steps per Second: 21,198.71346
Overall Steps per Second: 10,247.81533

Timestep Collection Time: 2.35967
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.88124

Cumulative Model Updates: 107,204
Cumulative Timesteps: 894,276,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 894276036...
Checkpoint 894276036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,698.19842
Policy Entropy: 1.69830
Value Function Loss: 0.06822

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15936
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.54480

Collected Steps per Second: 20,889.04078
Overall Steps per Second: 9,701.51652

Timestep Collection Time: 2.39465
Timestep Consumption Time: 2.76145
PPO Batch Consumption Time: 0.33162
Total Iteration Time: 5.15610

Cumulative Model Updates: 107,210
Cumulative Timesteps: 894,326,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,940.09294
Policy Entropy: 1.68813
Value Function Loss: 0.06608

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15297
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.51744

Collected Steps per Second: 20,215.05806
Overall Steps per Second: 10,187.56454

Timestep Collection Time: 2.47469
Timestep Consumption Time: 2.43581
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.91050

Cumulative Model Updates: 107,216
Cumulative Timesteps: 894,376,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 894376084...
Checkpoint 894376084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,465.37666
Policy Entropy: 1.68216
Value Function Loss: 0.07005

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14747
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.47396

Collected Steps per Second: 20,059.82977
Overall Steps per Second: 10,011.32594

Timestep Collection Time: 2.49344
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.99614

Cumulative Model Updates: 107,222
Cumulative Timesteps: 894,426,102

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,357.26626
Policy Entropy: 1.69150
Value Function Loss: 0.07663

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.56054

Collected Steps per Second: 21,371.89285
Overall Steps per Second: 10,180.83912

Timestep Collection Time: 2.34083
Timestep Consumption Time: 2.57311
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.91394

Cumulative Model Updates: 107,228
Cumulative Timesteps: 894,476,130

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 894476130...
Checkpoint 894476130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,824.85623
Policy Entropy: 1.68343
Value Function Loss: 0.08285

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15395
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.73367

Collected Steps per Second: 20,720.15636
Overall Steps per Second: 10,032.95861

Timestep Collection Time: 2.41350
Timestep Consumption Time: 2.57088
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.98437

Cumulative Model Updates: 107,234
Cumulative Timesteps: 894,526,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,186.69776
Policy Entropy: 1.69421
Value Function Loss: 0.07767

Mean KL Divergence: 0.02866
SB3 Clip Fraction: 0.20595
Policy Update Magnitude: 0.49899
Value Function Update Magnitude: 0.65491

Collected Steps per Second: 21,371.00509
Overall Steps per Second: 10,207.28294

Timestep Collection Time: 2.34055
Timestep Consumption Time: 2.55987
PPO Batch Consumption Time: 0.29773
Total Iteration Time: 4.90042

Cumulative Model Updates: 107,240
Cumulative Timesteps: 894,576,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 894576158...
Checkpoint 894576158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,555.56848
Policy Entropy: 1.68488
Value Function Loss: 0.08667

Mean KL Divergence: 0.03761
SB3 Clip Fraction: 0.23307
Policy Update Magnitude: 0.42488
Value Function Update Magnitude: 0.50520

Collected Steps per Second: 20,163.23556
Overall Steps per Second: 10,045.88820

Timestep Collection Time: 2.48125
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.98015

Cumulative Model Updates: 107,246
Cumulative Timesteps: 894,626,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,731.18373
Policy Entropy: 1.69569
Value Function Loss: 0.08473

Mean KL Divergence: 0.02183
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.43670
Value Function Update Magnitude: 0.49388

Collected Steps per Second: 21,529.16167
Overall Steps per Second: 10,275.76113

Timestep Collection Time: 2.32410
Timestep Consumption Time: 2.54522
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.86932

Cumulative Model Updates: 107,252
Cumulative Timesteps: 894,676,224

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 894676224...
Checkpoint 894676224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,955.89121
Policy Entropy: 1.69415
Value Function Loss: 0.08138

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.44906
Value Function Update Magnitude: 0.52793

Collected Steps per Second: 20,646.96976
Overall Steps per Second: 9,965.31310

Timestep Collection Time: 2.42215
Timestep Consumption Time: 2.59626
PPO Batch Consumption Time: 0.30166
Total Iteration Time: 5.01841

Cumulative Model Updates: 107,258
Cumulative Timesteps: 894,726,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,153.19743
Policy Entropy: 1.68939
Value Function Loss: 0.07706

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.17253
Policy Update Magnitude: 0.48794
Value Function Update Magnitude: 0.48656

Collected Steps per Second: 21,576.75826
Overall Steps per Second: 10,417.66041

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.80089

Cumulative Model Updates: 107,264
Cumulative Timesteps: 894,776,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 894776248...
Checkpoint 894776248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,517.93759
Policy Entropy: 1.67979
Value Function Loss: 0.07286

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.16594
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.57276

Collected Steps per Second: 19,932.59310
Overall Steps per Second: 9,584.66833

Timestep Collection Time: 2.50936
Timestep Consumption Time: 2.70919
PPO Batch Consumption Time: 0.32593
Total Iteration Time: 5.21854

Cumulative Model Updates: 107,270
Cumulative Timesteps: 894,826,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,429.52016
Policy Entropy: 1.68511
Value Function Loss: 0.07478

Mean KL Divergence: 0.02287
SB3 Clip Fraction: 0.19068
Policy Update Magnitude: 0.52928
Value Function Update Magnitude: 0.65134

Collected Steps per Second: 19,171.82060
Overall Steps per Second: 9,773.47790

Timestep Collection Time: 2.60820
Timestep Consumption Time: 2.50809
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 5.11630

Cumulative Model Updates: 107,276
Cumulative Timesteps: 894,876,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 894876270...
Checkpoint 894876270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,493.20486
Policy Entropy: 1.68969
Value Function Loss: 0.07714

Mean KL Divergence: 0.02473
SB3 Clip Fraction: 0.19874
Policy Update Magnitude: 0.50404
Value Function Update Magnitude: 0.72161

Collected Steps per Second: 20,052.66791
Overall Steps per Second: 9,774.65696

Timestep Collection Time: 2.49503
Timestep Consumption Time: 2.62351
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 5.11854

Cumulative Model Updates: 107,282
Cumulative Timesteps: 894,926,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,403.56478
Policy Entropy: 1.69431
Value Function Loss: 0.07701

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.16880
Policy Update Magnitude: 0.47279
Value Function Update Magnitude: 0.67702

Collected Steps per Second: 21,339.82091
Overall Steps per Second: 10,307.46038

Timestep Collection Time: 2.34491
Timestep Consumption Time: 2.50982
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.85474

Cumulative Model Updates: 107,288
Cumulative Timesteps: 894,976,342

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 894976342...
Checkpoint 894976342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,664.52842
Policy Entropy: 1.67431
Value Function Loss: 0.07107

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.47585
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 20,033.79471
Overall Steps per Second: 9,884.54156

Timestep Collection Time: 2.49678
Timestep Consumption Time: 2.56365
PPO Batch Consumption Time: 0.30081
Total Iteration Time: 5.06043

Cumulative Model Updates: 107,294
Cumulative Timesteps: 895,026,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,936.29455
Policy Entropy: 1.67568
Value Function Loss: 0.07436

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.52480
Value Function Update Magnitude: 0.51788

Collected Steps per Second: 21,636.14708
Overall Steps per Second: 10,338.26557

Timestep Collection Time: 2.31095
Timestep Consumption Time: 2.52545
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.83640

Cumulative Model Updates: 107,300
Cumulative Timesteps: 895,076,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 895076362...
Checkpoint 895076362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,003.07858
Policy Entropy: 1.67805
Value Function Loss: 0.07494

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.57190
Value Function Update Magnitude: 0.52026

Collected Steps per Second: 20,171.07149
Overall Steps per Second: 9,826.35864

Timestep Collection Time: 2.48028
Timestep Consumption Time: 2.61112
PPO Batch Consumption Time: 0.30538
Total Iteration Time: 5.09141

Cumulative Model Updates: 107,306
Cumulative Timesteps: 895,126,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,392.21023
Policy Entropy: 1.69242
Value Function Loss: 0.08405

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.58671
Value Function Update Magnitude: 0.60511

Collected Steps per Second: 21,443.70889
Overall Steps per Second: 10,346.60956

Timestep Collection Time: 2.33225
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.83366

Cumulative Model Updates: 107,312
Cumulative Timesteps: 895,176,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 895176404...
Checkpoint 895176404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,741.56214
Policy Entropy: 1.68290
Value Function Loss: 0.08090

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.58140
Value Function Update Magnitude: 0.56738

Collected Steps per Second: 20,015.31656
Overall Steps per Second: 9,863.63047

Timestep Collection Time: 2.49939
Timestep Consumption Time: 2.57238
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 5.07176

Cumulative Model Updates: 107,318
Cumulative Timesteps: 895,226,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,352.37987
Policy Entropy: 1.67451
Value Function Loss: 0.07612

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.55536
Value Function Update Magnitude: 0.58519

Collected Steps per Second: 21,574.06929
Overall Steps per Second: 10,381.93458

Timestep Collection Time: 2.31806
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.81702

Cumulative Model Updates: 107,324
Cumulative Timesteps: 895,276,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 895276440...
Checkpoint 895276440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,194.30874
Policy Entropy: 1.66876
Value Function Loss: 0.06748

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.65124

Collected Steps per Second: 20,694.85995
Overall Steps per Second: 10,025.58201

Timestep Collection Time: 2.41635
Timestep Consumption Time: 2.57149
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.98784

Cumulative Model Updates: 107,330
Cumulative Timesteps: 895,326,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,411.81054
Policy Entropy: 1.67055
Value Function Loss: 0.07115

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13588
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.64354

Collected Steps per Second: 21,143.17562
Overall Steps per Second: 10,282.83129

Timestep Collection Time: 2.36682
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.86656

Cumulative Model Updates: 107,336
Cumulative Timesteps: 895,376,488

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 895376488...
Checkpoint 895376488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,048.09407
Policy Entropy: 1.68007
Value Function Loss: 0.07486

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14775
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.61750

Collected Steps per Second: 20,386.78564
Overall Steps per Second: 10,081.43412

Timestep Collection Time: 2.45345
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.96140

Cumulative Model Updates: 107,342
Cumulative Timesteps: 895,426,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,418.06934
Policy Entropy: 1.68319
Value Function Loss: 0.08024

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.57237
Value Function Update Magnitude: 0.52458

Collected Steps per Second: 21,660.72700
Overall Steps per Second: 10,244.97104

Timestep Collection Time: 2.31054
Timestep Consumption Time: 2.57459
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.88513

Cumulative Model Updates: 107,348
Cumulative Timesteps: 895,476,554

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 895476554...
Checkpoint 895476554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,078.21689
Policy Entropy: 1.67966
Value Function Loss: 0.08057

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.55294

Collected Steps per Second: 20,751.06684
Overall Steps per Second: 9,989.63098

Timestep Collection Time: 2.41086
Timestep Consumption Time: 2.59713
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 5.00799

Cumulative Model Updates: 107,354
Cumulative Timesteps: 895,526,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,208.59533
Policy Entropy: 1.67434
Value Function Loss: 0.07901

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13994
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 21,521.51564
Overall Steps per Second: 10,216.17078

Timestep Collection Time: 2.32372
Timestep Consumption Time: 2.57146
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.89518

Cumulative Model Updates: 107,360
Cumulative Timesteps: 895,576,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 895576592...
Checkpoint 895576592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,112.58319
Policy Entropy: 1.68334
Value Function Loss: 0.07806

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.55932
Value Function Update Magnitude: 0.49834

Collected Steps per Second: 20,262.02956
Overall Steps per Second: 10,054.76305

Timestep Collection Time: 2.46945
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.97635

Cumulative Model Updates: 107,366
Cumulative Timesteps: 895,626,628

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,644.13330
Policy Entropy: 1.67856
Value Function Loss: 0.07445

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.50329
Value Function Update Magnitude: 0.50366

Collected Steps per Second: 21,673.43359
Overall Steps per Second: 10,271.73279

Timestep Collection Time: 2.30826
Timestep Consumption Time: 2.56219
PPO Batch Consumption Time: 0.30021
Total Iteration Time: 4.87045

Cumulative Model Updates: 107,372
Cumulative Timesteps: 895,676,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 895676656...
Checkpoint 895676656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,527.66806
Policy Entropy: 1.68589
Value Function Loss: 0.07182

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.46797
Value Function Update Magnitude: 0.59407

Collected Steps per Second: 20,967.11773
Overall Steps per Second: 10,074.06747

Timestep Collection Time: 2.38678
Timestep Consumption Time: 2.58082
PPO Batch Consumption Time: 0.30179
Total Iteration Time: 4.96761

Cumulative Model Updates: 107,378
Cumulative Timesteps: 895,726,700

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,473.93830
Policy Entropy: 1.67697
Value Function Loss: 0.06804

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.15018
Policy Update Magnitude: 0.47037
Value Function Update Magnitude: 0.69405

Collected Steps per Second: 21,233.03131
Overall Steps per Second: 10,206.80774

Timestep Collection Time: 2.35567
Timestep Consumption Time: 2.54479
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 4.90045

Cumulative Model Updates: 107,384
Cumulative Timesteps: 895,776,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 895776718...
Checkpoint 895776718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,917.67520
Policy Entropy: 1.67456
Value Function Loss: 0.07287

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.47843
Value Function Update Magnitude: 0.59472

Collected Steps per Second: 19,679.75007
Overall Steps per Second: 10,090.71045

Timestep Collection Time: 2.54078
Timestep Consumption Time: 2.41447
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.95525

Cumulative Model Updates: 107,390
Cumulative Timesteps: 895,826,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,305.84140
Policy Entropy: 1.66147
Value Function Loss: 0.07928

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.16266
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.61424

Collected Steps per Second: 20,667.93215
Overall Steps per Second: 10,192.10399

Timestep Collection Time: 2.42105
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.29961
Total Iteration Time: 4.90949

Cumulative Model Updates: 107,396
Cumulative Timesteps: 895,876,758

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 895876758...
Checkpoint 895876758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,659.38365
Policy Entropy: 1.66394
Value Function Loss: 0.08091

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.16923
Policy Update Magnitude: 0.50615
Value Function Update Magnitude: 0.67869

Collected Steps per Second: 20,478.89422
Overall Steps per Second: 10,113.12200

Timestep Collection Time: 2.44173
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.30352
Total Iteration Time: 4.94447

Cumulative Model Updates: 107,402
Cumulative Timesteps: 895,926,762

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,834.36560
Policy Entropy: 1.67325
Value Function Loss: 0.07904

Mean KL Divergence: 0.01963
SB3 Clip Fraction: 0.17405
Policy Update Magnitude: 0.52391
Value Function Update Magnitude: 0.70324

Collected Steps per Second: 20,523.26825
Overall Steps per Second: 10,330.54011

Timestep Collection Time: 2.43714
Timestep Consumption Time: 2.40462
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.84176

Cumulative Model Updates: 107,408
Cumulative Timesteps: 895,976,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 895976780...
Checkpoint 895976780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,796.41015
Policy Entropy: 1.67857
Value Function Loss: 0.07246

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.17221
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.68482

Collected Steps per Second: 19,608.88605
Overall Steps per Second: 9,959.83456

Timestep Collection Time: 2.55129
Timestep Consumption Time: 2.47168
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 5.02298

Cumulative Model Updates: 107,414
Cumulative Timesteps: 896,026,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,770.08534
Policy Entropy: 1.67615
Value Function Loss: 0.06877

Mean KL Divergence: 0.01887
SB3 Clip Fraction: 0.17041
Policy Update Magnitude: 0.54645
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 20,808.04866
Overall Steps per Second: 10,254.44766

Timestep Collection Time: 2.40388
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.87788

Cumulative Model Updates: 107,420
Cumulative Timesteps: 896,076,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 896076828...
Checkpoint 896076828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,569.53698
Policy Entropy: 1.65945
Value Function Loss: 0.06606

Mean KL Divergence: 0.02046
SB3 Clip Fraction: 0.17998
Policy Update Magnitude: 0.53574
Value Function Update Magnitude: 0.69980

Collected Steps per Second: 20,952.68946
Overall Steps per Second: 10,224.76111

Timestep Collection Time: 2.38633
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.89009

Cumulative Model Updates: 107,426
Cumulative Timesteps: 896,126,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,291.35487
Policy Entropy: 1.65558
Value Function Loss: 0.06983

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.50498
Value Function Update Magnitude: 0.67871

Collected Steps per Second: 20,759.02424
Overall Steps per Second: 10,169.69334

Timestep Collection Time: 2.40936
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.91814

Cumulative Model Updates: 107,432
Cumulative Timesteps: 896,176,844

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 896176844...
Checkpoint 896176844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,656.67032
Policy Entropy: 1.67630
Value Function Loss: 0.07558

Mean KL Divergence: 0.02065
SB3 Clip Fraction: 0.17765
Policy Update Magnitude: 0.50180
Value Function Update Magnitude: 0.69669

Collected Steps per Second: 20,219.73148
Overall Steps per Second: 10,103.58140

Timestep Collection Time: 2.47471
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.95250

Cumulative Model Updates: 107,438
Cumulative Timesteps: 896,226,882

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,483.18762
Policy Entropy: 1.68088
Value Function Loss: 0.07908

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.71060

Collected Steps per Second: 21,181.56069
Overall Steps per Second: 10,252.82143

Timestep Collection Time: 2.36177
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.87924

Cumulative Model Updates: 107,444
Cumulative Timesteps: 896,276,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 896276908...
Checkpoint 896276908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,225.96502
Policy Entropy: 1.69229
Value Function Loss: 0.07564

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.70653

Collected Steps per Second: 21,006.02991
Overall Steps per Second: 10,061.30565

Timestep Collection Time: 2.38103
Timestep Consumption Time: 2.59009
PPO Batch Consumption Time: 0.30538
Total Iteration Time: 4.97112

Cumulative Model Updates: 107,450
Cumulative Timesteps: 896,326,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,709.90718
Policy Entropy: 1.68912
Value Function Loss: 0.07808

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.18156
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.65957

Collected Steps per Second: 21,129.49643
Overall Steps per Second: 10,080.88799

Timestep Collection Time: 2.36683
Timestep Consumption Time: 2.59404
PPO Batch Consumption Time: 0.30052
Total Iteration Time: 4.96087

Cumulative Model Updates: 107,456
Cumulative Timesteps: 896,376,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 896376934...
Checkpoint 896376934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,269.76568
Policy Entropy: 1.68954
Value Function Loss: 0.08025

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.17569
Policy Update Magnitude: 0.47949
Value Function Update Magnitude: 0.64387

Collected Steps per Second: 20,277.17680
Overall Steps per Second: 10,088.18289

Timestep Collection Time: 2.46760
Timestep Consumption Time: 2.49226
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.95986

Cumulative Model Updates: 107,462
Cumulative Timesteps: 896,426,970

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,727.54797
Policy Entropy: 1.67768
Value Function Loss: 0.07750

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.17303
Policy Update Magnitude: 0.47458
Value Function Update Magnitude: 0.73743

Collected Steps per Second: 20,983.24133
Overall Steps per Second: 10,125.11106

Timestep Collection Time: 2.38505
Timestep Consumption Time: 2.55771
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.94276

Cumulative Model Updates: 107,468
Cumulative Timesteps: 896,477,016

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 896477016...
Checkpoint 896477016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,602.85444
Policy Entropy: 1.67453
Value Function Loss: 0.07547

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.17083
Policy Update Magnitude: 0.47951
Value Function Update Magnitude: 0.66881

Collected Steps per Second: 21,133.28442
Overall Steps per Second: 10,123.12023

Timestep Collection Time: 2.36650
Timestep Consumption Time: 2.57387
PPO Batch Consumption Time: 0.29898
Total Iteration Time: 4.94037

Cumulative Model Updates: 107,474
Cumulative Timesteps: 896,527,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,476.98428
Policy Entropy: 1.67305
Value Function Loss: 0.07136

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.52502
Value Function Update Magnitude: 0.55784

Collected Steps per Second: 20,970.99454
Overall Steps per Second: 10,112.31338

Timestep Collection Time: 2.38434
Timestep Consumption Time: 2.56032
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 4.94466

Cumulative Model Updates: 107,480
Cumulative Timesteps: 896,577,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 896577030...
Checkpoint 896577030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,553.23283
Policy Entropy: 1.68048
Value Function Loss: 0.06931

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14295
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.61566

Collected Steps per Second: 20,070.63718
Overall Steps per Second: 9,847.76049

Timestep Collection Time: 2.49260
Timestep Consumption Time: 2.58754
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 5.08014

Cumulative Model Updates: 107,486
Cumulative Timesteps: 896,627,058

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,338.42098
Policy Entropy: 1.68967
Value Function Loss: 0.07423

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13830
Policy Update Magnitude: 0.58182
Value Function Update Magnitude: 0.56122

Collected Steps per Second: 18,571.72459
Overall Steps per Second: 9,617.22695

Timestep Collection Time: 2.69431
Timestep Consumption Time: 2.50864
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 5.20296

Cumulative Model Updates: 107,492
Cumulative Timesteps: 896,677,096

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 896677096...
Checkpoint 896677096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,955.17634
Policy Entropy: 1.67957
Value Function Loss: 0.07283

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14621
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.46719

Collected Steps per Second: 17,367.14101
Overall Steps per Second: 9,154.51097

Timestep Collection Time: 2.88061
Timestep Consumption Time: 2.58423
PPO Batch Consumption Time: 0.30702
Total Iteration Time: 5.46485

Cumulative Model Updates: 107,498
Cumulative Timesteps: 896,727,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,161.58964
Policy Entropy: 1.67912
Value Function Loss: 0.07510

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.43425

Collected Steps per Second: 20,724.55496
Overall Steps per Second: 10,124.22544

Timestep Collection Time: 2.41404
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.94161

Cumulative Model Updates: 107,504
Cumulative Timesteps: 896,777,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 896777154...
Checkpoint 896777154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,916.96186
Policy Entropy: 1.66873
Value Function Loss: 0.06876

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.56565
Value Function Update Magnitude: 0.49125

Collected Steps per Second: 18,925.76836
Overall Steps per Second: 9,739.64167

Timestep Collection Time: 2.64306
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 5.13592

Cumulative Model Updates: 107,510
Cumulative Timesteps: 896,827,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,434.40513
Policy Entropy: 1.68854
Value Function Loss: 0.06857

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14304
Policy Update Magnitude: 0.55978
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 19,880.44864
Overall Steps per Second: 9,967.82566

Timestep Collection Time: 2.51614
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 5.01835

Cumulative Model Updates: 107,516
Cumulative Timesteps: 896,877,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 896877198...
Checkpoint 896877198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,382.87639
Policy Entropy: 1.68837
Value Function Loss: 0.06324

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.54929
Value Function Update Magnitude: 0.59974

Collected Steps per Second: 21,184.56376
Overall Steps per Second: 10,108.60309

Timestep Collection Time: 2.36030
Timestep Consumption Time: 2.58618
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.94648

Cumulative Model Updates: 107,522
Cumulative Timesteps: 896,927,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,557.30812
Policy Entropy: 1.68793
Value Function Loss: 0.06594

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16599
Policy Update Magnitude: 0.49380
Value Function Update Magnitude: 0.49395

Collected Steps per Second: 20,562.23949
Overall Steps per Second: 10,138.67771

Timestep Collection Time: 2.43320
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.93477

Cumulative Model Updates: 107,528
Cumulative Timesteps: 896,977,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 896977232...
Checkpoint 896977232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,558.82936
Policy Entropy: 1.66803
Value Function Loss: 0.07289

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.20007
Policy Update Magnitude: 0.44792
Value Function Update Magnitude: 0.63820

Collected Steps per Second: 20,438.61303
Overall Steps per Second: 10,070.02233

Timestep Collection Time: 2.44752
Timestep Consumption Time: 2.52009
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.96762

Cumulative Model Updates: 107,534
Cumulative Timesteps: 897,027,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,024.82267
Policy Entropy: 1.66619
Value Function Loss: 0.08208

Mean KL Divergence: 0.03028
SB3 Clip Fraction: 0.19990
Policy Update Magnitude: 0.43753
Value Function Update Magnitude: 0.69572

Collected Steps per Second: 20,374.03070
Overall Steps per Second: 10,072.59722

Timestep Collection Time: 2.45460
Timestep Consumption Time: 2.51036
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.96496

Cumulative Model Updates: 107,540
Cumulative Timesteps: 897,077,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 897077266...
Checkpoint 897077266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,556.25205
Policy Entropy: 1.67859
Value Function Loss: 0.09426

Mean KL Divergence: 0.02366
SB3 Clip Fraction: 0.18417
Policy Update Magnitude: 0.45251
Value Function Update Magnitude: 0.51950

Collected Steps per Second: 21,033.38314
Overall Steps per Second: 10,162.57850

Timestep Collection Time: 2.37755
Timestep Consumption Time: 2.54324
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.92080

Cumulative Model Updates: 107,546
Cumulative Timesteps: 897,127,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,158.12469
Policy Entropy: 1.69525
Value Function Loss: 0.10056

Mean KL Divergence: 0.02776
SB3 Clip Fraction: 0.21373
Policy Update Magnitude: 0.42300
Value Function Update Magnitude: 0.39680

Collected Steps per Second: 20,796.96159
Overall Steps per Second: 10,161.80122

Timestep Collection Time: 2.40526
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.92255

Cumulative Model Updates: 107,552
Cumulative Timesteps: 897,177,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 897177296...
Checkpoint 897177296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,401.70439
Policy Entropy: 1.71646
Value Function Loss: 0.10254

Mean KL Divergence: 0.02317
SB3 Clip Fraction: 0.20363
Policy Update Magnitude: 0.46986
Value Function Update Magnitude: 0.34531

Collected Steps per Second: 19,762.80213
Overall Steps per Second: 9,712.53415

Timestep Collection Time: 2.53132
Timestep Consumption Time: 2.61934
PPO Batch Consumption Time: 0.31219
Total Iteration Time: 5.15066

Cumulative Model Updates: 107,558
Cumulative Timesteps: 897,227,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,351.91170
Policy Entropy: 1.71933
Value Function Loss: 0.10005

Mean KL Divergence: 0.01943
SB3 Clip Fraction: 0.17714
Policy Update Magnitude: 0.50002
Value Function Update Magnitude: 0.47587

Collected Steps per Second: 20,436.97470
Overall Steps per Second: 10,191.97223

Timestep Collection Time: 2.44850
Timestep Consumption Time: 2.46124
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.90975

Cumulative Model Updates: 107,564
Cumulative Timesteps: 897,277,362

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 897277362...
Checkpoint 897277362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,614.41883
Policy Entropy: 1.71451
Value Function Loss: 0.09093

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.17692
Policy Update Magnitude: 0.46376
Value Function Update Magnitude: 0.44355

Collected Steps per Second: 22,102.55137
Overall Steps per Second: 10,628.42756

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.70700

Cumulative Model Updates: 107,570
Cumulative Timesteps: 897,327,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,443.37257
Policy Entropy: 1.70807
Value Function Loss: 0.08312

Mean KL Divergence: 0.02126
SB3 Clip Fraction: 0.17746
Policy Update Magnitude: 0.46884
Value Function Update Magnitude: 0.52444

Collected Steps per Second: 21,609.78652
Overall Steps per Second: 10,486.80752

Timestep Collection Time: 2.31451
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.76942

Cumulative Model Updates: 107,576
Cumulative Timesteps: 897,377,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 897377406...
Checkpoint 897377406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,478.74097
Policy Entropy: 1.71019
Value Function Loss: 0.07376

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.17694
Policy Update Magnitude: 0.48781
Value Function Update Magnitude: 0.52941

Collected Steps per Second: 20,443.75238
Overall Steps per Second: 10,256.92914

Timestep Collection Time: 2.44652
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.87631

Cumulative Model Updates: 107,582
Cumulative Timesteps: 897,427,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,797.84042
Policy Entropy: 1.72397
Value Function Loss: 0.07485

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.51335
Value Function Update Magnitude: 0.50507

Collected Steps per Second: 21,196.59597
Overall Steps per Second: 10,430.49865

Timestep Collection Time: 2.36038
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.79670

Cumulative Model Updates: 107,588
Cumulative Timesteps: 897,477,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 897477454...
Checkpoint 897477454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,277.68816
Policy Entropy: 1.73142
Value Function Loss: 0.08403

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14652
Policy Update Magnitude: 0.56631
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 21,417.37243
Overall Steps per Second: 10,668.85452

Timestep Collection Time: 2.33465
Timestep Consumption Time: 2.35208
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.68673

Cumulative Model Updates: 107,594
Cumulative Timesteps: 897,527,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,887.73427
Policy Entropy: 1.71703
Value Function Loss: 0.07540

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.55799
Value Function Update Magnitude: 0.28277

Collected Steps per Second: 21,633.50202
Overall Steps per Second: 10,418.13523

Timestep Collection Time: 2.31151
Timestep Consumption Time: 2.48839
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.79990

Cumulative Model Updates: 107,600
Cumulative Timesteps: 897,577,462

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 897577462...
Checkpoint 897577462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,551.33076
Policy Entropy: 1.72040
Value Function Loss: 0.06925

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.39031

Collected Steps per Second: 21,051.87694
Overall Steps per Second: 10,349.14711

Timestep Collection Time: 2.37689
Timestep Consumption Time: 2.45810
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.83499

Cumulative Model Updates: 107,606
Cumulative Timesteps: 897,627,500

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,542.68737
Policy Entropy: 1.70687
Value Function Loss: 0.06628

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.52599

Collected Steps per Second: 22,022.89948
Overall Steps per Second: 10,669.26788

Timestep Collection Time: 2.27109
Timestep Consumption Time: 2.41677
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.68786

Cumulative Model Updates: 107,612
Cumulative Timesteps: 897,677,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 897677516...
Checkpoint 897677516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,859.78325
Policy Entropy: 1.70897
Value Function Loss: 0.07130

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15036
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.60973

Collected Steps per Second: 21,788.58244
Overall Steps per Second: 10,629.53897

Timestep Collection Time: 2.29533
Timestep Consumption Time: 2.40967
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70500

Cumulative Model Updates: 107,618
Cumulative Timesteps: 897,727,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,661.18350
Policy Entropy: 1.72255
Value Function Loss: 0.07168

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.16973
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 21,910.62853
Overall Steps per Second: 10,588.07684

Timestep Collection Time: 2.28300
Timestep Consumption Time: 2.44137
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.72437

Cumulative Model Updates: 107,624
Cumulative Timesteps: 897,777,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 897777550...
Checkpoint 897777550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,232.12864
Policy Entropy: 1.71752
Value Function Loss: 0.07230

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.54333

Collected Steps per Second: 21,958.89346
Overall Steps per Second: 10,347.17807

Timestep Collection Time: 2.27771
Timestep Consumption Time: 2.55607
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.83378

Cumulative Model Updates: 107,630
Cumulative Timesteps: 897,827,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,606.47500
Policy Entropy: 1.71596
Value Function Loss: 0.07494

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.15263
Policy Update Magnitude: 0.53977
Value Function Update Magnitude: 0.40706

Collected Steps per Second: 22,326.49087
Overall Steps per Second: 10,652.63965

Timestep Collection Time: 2.24039
Timestep Consumption Time: 2.45516
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.69555

Cumulative Model Updates: 107,636
Cumulative Timesteps: 897,877,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 897877586...
Checkpoint 897877586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,124.16647
Policy Entropy: 1.71186
Value Function Loss: 0.09004

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.58126
Value Function Update Magnitude: 0.32752

Collected Steps per Second: 21,939.34316
Overall Steps per Second: 10,605.98100

Timestep Collection Time: 2.27901
Timestep Consumption Time: 2.43531
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71432

Cumulative Model Updates: 107,642
Cumulative Timesteps: 897,927,586

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,165.98807
Policy Entropy: 1.71303
Value Function Loss: 0.08772

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.59158
Value Function Update Magnitude: 0.29948

Collected Steps per Second: 22,085.21065
Overall Steps per Second: 10,519.12628

Timestep Collection Time: 2.26523
Timestep Consumption Time: 2.49068
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.75591

Cumulative Model Updates: 107,648
Cumulative Timesteps: 897,977,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 897977614...
Checkpoint 897977614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,663.55848
Policy Entropy: 1.71535
Value Function Loss: 0.08938

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.15318
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.33481

Collected Steps per Second: 21,764.02355
Overall Steps per Second: 10,240.22174

Timestep Collection Time: 2.29774
Timestep Consumption Time: 2.58575
PPO Batch Consumption Time: 0.30506
Total Iteration Time: 4.88349

Cumulative Model Updates: 107,654
Cumulative Timesteps: 898,027,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,159.80979
Policy Entropy: 1.71068
Value Function Loss: 0.08888

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.56618
Value Function Update Magnitude: 0.33425

Collected Steps per Second: 22,240.40353
Overall Steps per Second: 10,403.24019

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.55824
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.80658

Cumulative Model Updates: 107,660
Cumulative Timesteps: 898,077,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 898077626...
Checkpoint 898077626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,453.23630
Policy Entropy: 1.71790
Value Function Loss: 0.08680

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.24299

Collected Steps per Second: 21,619.17591
Overall Steps per Second: 10,409.94166

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.80483

Cumulative Model Updates: 107,666
Cumulative Timesteps: 898,127,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,369.93610
Policy Entropy: 1.72533
Value Function Loss: 0.08216

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.21808

Collected Steps per Second: 22,273.64547
Overall Steps per Second: 10,630.43155

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.70630

Cumulative Model Updates: 107,672
Cumulative Timesteps: 898,177,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 898177674...
Checkpoint 898177674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,019.37509
Policy Entropy: 1.71079
Value Function Loss: 0.07801

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.28312

Collected Steps per Second: 21,892.02002
Overall Steps per Second: 10,206.45804

Timestep Collection Time: 2.28576
Timestep Consumption Time: 2.61701
PPO Batch Consumption Time: 0.31092
Total Iteration Time: 4.90278

Cumulative Model Updates: 107,678
Cumulative Timesteps: 898,227,714

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,305.19173
Policy Entropy: 1.70589
Value Function Loss: 0.07709

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.55588
Value Function Update Magnitude: 0.34889

Collected Steps per Second: 21,778.62422
Overall Steps per Second: 10,527.37528

Timestep Collection Time: 2.29656
Timestep Consumption Time: 2.45448
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.75104

Cumulative Model Updates: 107,684
Cumulative Timesteps: 898,277,730

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 898277730...
Checkpoint 898277730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,616.31719
Policy Entropy: 1.68912
Value Function Loss: 0.07736

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.36192

Collected Steps per Second: 21,804.48768
Overall Steps per Second: 10,556.18164

Timestep Collection Time: 2.29375
Timestep Consumption Time: 2.44414
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.73789

Cumulative Model Updates: 107,690
Cumulative Timesteps: 898,327,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,306.73653
Policy Entropy: 1.68908
Value Function Loss: 0.06664

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.49232

Collected Steps per Second: 22,167.50482
Overall Steps per Second: 10,560.92562

Timestep Collection Time: 2.25673
Timestep Consumption Time: 2.48017
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.73690

Cumulative Model Updates: 107,696
Cumulative Timesteps: 898,377,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 898377770...
Checkpoint 898377770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,897.46197
Policy Entropy: 1.68510
Value Function Loss: 0.06517

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.58430

Collected Steps per Second: 22,003.80683
Overall Steps per Second: 10,612.56695

Timestep Collection Time: 2.27333
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.71347

Cumulative Model Updates: 107,702
Cumulative Timesteps: 898,427,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,092.41364
Policy Entropy: 1.69433
Value Function Loss: 0.06594

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.54026

Collected Steps per Second: 21,139.04911
Overall Steps per Second: 10,402.73181

Timestep Collection Time: 2.36548
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.80681

Cumulative Model Updates: 107,708
Cumulative Timesteps: 898,477,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 898477796...
Checkpoint 898477796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,330.99378
Policy Entropy: 1.69548
Value Function Loss: 0.07055

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.55860
Value Function Update Magnitude: 0.45914

Collected Steps per Second: 21,891.79032
Overall Steps per Second: 10,411.98214

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.52041
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.80639

Cumulative Model Updates: 107,714
Cumulative Timesteps: 898,527,840

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,283.19146
Policy Entropy: 1.70232
Value Function Loss: 0.08211

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.40624

Collected Steps per Second: 20,267.94177
Overall Steps per Second: 9,979.25344

Timestep Collection Time: 2.46853
Timestep Consumption Time: 2.54507
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 5.01360

Cumulative Model Updates: 107,720
Cumulative Timesteps: 898,577,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 898577872...
Checkpoint 898577872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,133.65025
Policy Entropy: 1.69318
Value Function Loss: 0.07891

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.58113
Value Function Update Magnitude: 0.41127

Collected Steps per Second: 20,854.96254
Overall Steps per Second: 10,084.62949

Timestep Collection Time: 2.39770
Timestep Consumption Time: 2.56073
PPO Batch Consumption Time: 0.30452
Total Iteration Time: 4.95844

Cumulative Model Updates: 107,726
Cumulative Timesteps: 898,627,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,534.22106
Policy Entropy: 1.69606
Value Function Loss: 0.07521

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.56621
Value Function Update Magnitude: 0.50104

Collected Steps per Second: 20,352.08886
Overall Steps per Second: 10,024.05255

Timestep Collection Time: 2.45734
Timestep Consumption Time: 2.53186
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.98920

Cumulative Model Updates: 107,732
Cumulative Timesteps: 898,677,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 898677888...
Checkpoint 898677888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,221.15776
Policy Entropy: 1.68098
Value Function Loss: 0.06423

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.53123

Collected Steps per Second: 20,693.94358
Overall Steps per Second: 10,065.01242

Timestep Collection Time: 2.41791
Timestep Consumption Time: 2.55337
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.97128

Cumulative Model Updates: 107,738
Cumulative Timesteps: 898,727,924

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,759.58863
Policy Entropy: 1.68957
Value Function Loss: 0.06282

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.55478
Value Function Update Magnitude: 0.57718

Collected Steps per Second: 21,069.82802
Overall Steps per Second: 10,177.58924

Timestep Collection Time: 2.37344
Timestep Consumption Time: 2.54010
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.91354

Cumulative Model Updates: 107,744
Cumulative Timesteps: 898,777,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 898777932...
Checkpoint 898777932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,355.63790
Policy Entropy: 1.68803
Value Function Loss: 0.06733

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.56568
Value Function Update Magnitude: 0.62742

Collected Steps per Second: 20,931.56031
Overall Steps per Second: 10,106.23284

Timestep Collection Time: 2.38960
Timestep Consumption Time: 2.55963
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.94922

Cumulative Model Updates: 107,750
Cumulative Timesteps: 898,827,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,980.55461
Policy Entropy: 1.70560
Value Function Loss: 0.07426

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.61188

Collected Steps per Second: 19,881.47020
Overall Steps per Second: 9,940.51388

Timestep Collection Time: 2.51641
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 5.03294

Cumulative Model Updates: 107,756
Cumulative Timesteps: 898,877,980

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 898877980...
Checkpoint 898877980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,678.23364
Policy Entropy: 1.69548
Value Function Loss: 0.07002

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.58945
Value Function Update Magnitude: 0.72418

Collected Steps per Second: 21,052.38080
Overall Steps per Second: 10,188.23049

Timestep Collection Time: 2.37579
Timestep Consumption Time: 2.53341
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.90919

Cumulative Model Updates: 107,762
Cumulative Timesteps: 898,927,996

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,987.15794
Policy Entropy: 1.70156
Value Function Loss: 0.06443

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.73135

Collected Steps per Second: 21,201.28433
Overall Steps per Second: 10,250.85097

Timestep Collection Time: 2.35948
Timestep Consumption Time: 2.52051
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.87999

Cumulative Model Updates: 107,768
Cumulative Timesteps: 898,978,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 898978020...
Checkpoint 898978020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,475.76666
Policy Entropy: 1.68487
Value Function Loss: 0.06174

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.71447

Collected Steps per Second: 21,119.47582
Overall Steps per Second: 10,138.98134

Timestep Collection Time: 2.36767
Timestep Consumption Time: 2.56418
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.93186

Cumulative Model Updates: 107,774
Cumulative Timesteps: 899,028,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,795.97471
Policy Entropy: 1.68537
Value Function Loss: 0.06082

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.13813
Policy Update Magnitude: 0.56371
Value Function Update Magnitude: 0.67921

Collected Steps per Second: 20,438.98166
Overall Steps per Second: 10,117.19015

Timestep Collection Time: 2.44719
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.94386

Cumulative Model Updates: 107,780
Cumulative Timesteps: 899,078,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 899078042...
Checkpoint 899078042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,459.53920
Policy Entropy: 1.68969
Value Function Loss: 0.06352

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.55590
Value Function Update Magnitude: 0.59245

Collected Steps per Second: 20,982.03670
Overall Steps per Second: 10,115.56510

Timestep Collection Time: 2.38309
Timestep Consumption Time: 2.55999
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.94308

Cumulative Model Updates: 107,786
Cumulative Timesteps: 899,128,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,436.25229
Policy Entropy: 1.69857
Value Function Loss: 0.06322

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.48696

Collected Steps per Second: 21,107.44535
Overall Steps per Second: 10,142.01128

Timestep Collection Time: 2.36940
Timestep Consumption Time: 2.56177
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 4.93117

Cumulative Model Updates: 107,792
Cumulative Timesteps: 899,178,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 899178056...
Checkpoint 899178056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,220.59943
Policy Entropy: 1.69253
Value Function Loss: 0.06346

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.54526
Value Function Update Magnitude: 0.53856

Collected Steps per Second: 21,049.29728
Overall Steps per Second: 10,078.75158

Timestep Collection Time: 2.37595
Timestep Consumption Time: 2.58618
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.96212

Cumulative Model Updates: 107,798
Cumulative Timesteps: 899,228,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,044.76197
Policy Entropy: 1.67695
Value Function Loss: 0.06346

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.62185

Collected Steps per Second: 20,417.33773
Overall Steps per Second: 10,162.69561

Timestep Collection Time: 2.44890
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.91995

Cumulative Model Updates: 107,804
Cumulative Timesteps: 899,278,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 899278068...
Checkpoint 899278068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,139.20153
Policy Entropy: 1.68238
Value Function Loss: 0.05704

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.54021
Value Function Update Magnitude: 0.66739

Collected Steps per Second: 19,257.23470
Overall Steps per Second: 9,717.07218

Timestep Collection Time: 2.59663
Timestep Consumption Time: 2.54936
PPO Batch Consumption Time: 0.29875
Total Iteration Time: 5.14599

Cumulative Model Updates: 107,810
Cumulative Timesteps: 899,328,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,700.14681
Policy Entropy: 1.68367
Value Function Loss: 0.06208

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.60615

Collected Steps per Second: 20,581.77968
Overall Steps per Second: 9,912.18399

Timestep Collection Time: 2.43176
Timestep Consumption Time: 2.61758
PPO Batch Consumption Time: 0.30854
Total Iteration Time: 5.04934

Cumulative Model Updates: 107,816
Cumulative Timesteps: 899,378,122

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 899378122...
Checkpoint 899378122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.96246
Policy Entropy: 1.69633
Value Function Loss: 0.06701

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.56959
Value Function Update Magnitude: 0.51848

Collected Steps per Second: 20,903.19315
Overall Steps per Second: 10,053.22638

Timestep Collection Time: 2.39265
Timestep Consumption Time: 2.58227
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.97492

Cumulative Model Updates: 107,822
Cumulative Timesteps: 899,428,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,827.87420
Policy Entropy: 1.69899
Value Function Loss: 0.07177

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.51064

Collected Steps per Second: 19,561.22749
Overall Steps per Second: 9,324.64187

Timestep Collection Time: 2.55700
Timestep Consumption Time: 2.80707
PPO Batch Consumption Time: 0.33477
Total Iteration Time: 5.36407

Cumulative Model Updates: 107,828
Cumulative Timesteps: 899,478,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 899478154...
Checkpoint 899478154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,317.01884
Policy Entropy: 1.70955
Value Function Loss: 0.07045

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.64982

Collected Steps per Second: 20,672.36305
Overall Steps per Second: 10,022.13634

Timestep Collection Time: 2.41956
Timestep Consumption Time: 2.57119
PPO Batch Consumption Time: 0.29981
Total Iteration Time: 4.99075

Cumulative Model Updates: 107,834
Cumulative Timesteps: 899,528,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,528.58228
Policy Entropy: 1.70487
Value Function Loss: 0.06462

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14565
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.73779

Collected Steps per Second: 20,837.29746
Overall Steps per Second: 10,110.19147

Timestep Collection Time: 2.40070
Timestep Consumption Time: 2.54718
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.94788

Cumulative Model Updates: 107,840
Cumulative Timesteps: 899,578,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 899578196...
Checkpoint 899578196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,560.62681
Policy Entropy: 1.69641
Value Function Loss: 0.06693

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.56388
Value Function Update Magnitude: 0.64130

Collected Steps per Second: 20,244.73315
Overall Steps per Second: 10,165.49973

Timestep Collection Time: 2.47057
Timestep Consumption Time: 2.44960
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.92017

Cumulative Model Updates: 107,846
Cumulative Timesteps: 899,628,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,216.39253
Policy Entropy: 1.69304
Value Function Loss: 0.06662

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.56291
Value Function Update Magnitude: 0.51097

Collected Steps per Second: 19,733.17568
Overall Steps per Second: 10,083.73947

Timestep Collection Time: 2.53492
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.96066

Cumulative Model Updates: 107,852
Cumulative Timesteps: 899,678,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 899678234...
Checkpoint 899678234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,816.48505
Policy Entropy: 1.68842
Value Function Loss: 0.06767

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.61482

Collected Steps per Second: 20,303.76874
Overall Steps per Second: 10,169.30179

Timestep Collection Time: 2.46260
Timestep Consumption Time: 2.45416
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.91676

Cumulative Model Updates: 107,858
Cumulative Timesteps: 899,728,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,657.73966
Policy Entropy: 1.68867
Value Function Loss: 0.06174

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14602
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.69838

Collected Steps per Second: 19,569.67680
Overall Steps per Second: 10,045.05374

Timestep Collection Time: 2.55610
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.97976

Cumulative Model Updates: 107,864
Cumulative Timesteps: 899,778,256

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 899778256...
Checkpoint 899778256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,026.44264
Policy Entropy: 1.69210
Value Function Loss: 0.06332

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.56229
Value Function Update Magnitude: 0.62709

Collected Steps per Second: 19,675.21921
Overall Steps per Second: 9,763.00246

Timestep Collection Time: 2.54157
Timestep Consumption Time: 2.58042
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 5.12199

Cumulative Model Updates: 107,870
Cumulative Timesteps: 899,828,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,981.53848
Policy Entropy: 1.69507
Value Function Loss: 0.06462

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.56891
Value Function Update Magnitude: 0.57257

Collected Steps per Second: 20,242.20429
Overall Steps per Second: 10,130.01502

Timestep Collection Time: 2.47236
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.94037

Cumulative Model Updates: 107,876
Cumulative Timesteps: 899,878,308

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 899878308...
Checkpoint 899878308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,001.09188
Policy Entropy: 1.69273
Value Function Loss: 0.06950

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.65960

Collected Steps per Second: 20,814.50039
Overall Steps per Second: 10,160.80307

Timestep Collection Time: 2.40304
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.92264

Cumulative Model Updates: 107,882
Cumulative Timesteps: 899,928,326

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,557.35887
Policy Entropy: 1.69277
Value Function Loss: 0.06721

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14068
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.70465

Collected Steps per Second: 20,012.96759
Overall Steps per Second: 9,672.48525

Timestep Collection Time: 2.50008
Timestep Consumption Time: 2.67274
PPO Batch Consumption Time: 0.32033
Total Iteration Time: 5.17282

Cumulative Model Updates: 107,888
Cumulative Timesteps: 899,978,360

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 899978360...
Checkpoint 899978360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,809.89059
Policy Entropy: 1.69291
Value Function Loss: 0.06946

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.65911

Collected Steps per Second: 20,453.64719
Overall Steps per Second: 9,981.49467

Timestep Collection Time: 2.44563
Timestep Consumption Time: 2.56585
PPO Batch Consumption Time: 0.30201
Total Iteration Time: 5.01147

Cumulative Model Updates: 107,894
Cumulative Timesteps: 900,028,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,958.15994
Policy Entropy: 1.70228
Value Function Loss: 0.06675

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14599
Policy Update Magnitude: 0.56526
Value Function Update Magnitude: 0.64510

Collected Steps per Second: 20,775.49845
Overall Steps per Second: 10,311.68004

Timestep Collection Time: 2.40793
Timestep Consumption Time: 2.44346
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.85139

Cumulative Model Updates: 107,900
Cumulative Timesteps: 900,078,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 900078408...
Checkpoint 900078408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,431.75215
Policy Entropy: 1.70263
Value Function Loss: 0.07041

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14631
Policy Update Magnitude: 0.56662
Value Function Update Magnitude: 0.68684

Collected Steps per Second: 21,395.56007
Overall Steps per Second: 10,223.75454

Timestep Collection Time: 2.33796
Timestep Consumption Time: 2.55476
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.89272

Cumulative Model Updates: 107,906
Cumulative Timesteps: 900,128,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,316.19301
Policy Entropy: 1.70106
Value Function Loss: 0.06249

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.56239
Value Function Update Magnitude: 0.73208

Collected Steps per Second: 21,298.74828
Overall Steps per Second: 10,174.65418

Timestep Collection Time: 2.34765
Timestep Consumption Time: 2.56672
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.91437

Cumulative Model Updates: 107,912
Cumulative Timesteps: 900,178,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 900178432...
Checkpoint 900178432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,155.85398
Policy Entropy: 1.68902
Value Function Loss: 0.06214

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.68359

Collected Steps per Second: 18,316.27223
Overall Steps per Second: 9,367.61744

Timestep Collection Time: 2.72992
Timestep Consumption Time: 2.60783
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 5.33775

Cumulative Model Updates: 107,918
Cumulative Timesteps: 900,228,434

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,966.67553
Policy Entropy: 1.68846
Value Function Loss: 0.06255

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14186
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.64522

Collected Steps per Second: 20,487.72665
Overall Steps per Second: 10,054.20731

Timestep Collection Time: 2.44195
Timestep Consumption Time: 2.53408
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.97603

Cumulative Model Updates: 107,924
Cumulative Timesteps: 900,278,464

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 900278464...
Checkpoint 900278464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,118.76512
Policy Entropy: 1.68519
Value Function Loss: 0.05918

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.15320
Policy Update Magnitude: 0.53989
Value Function Update Magnitude: 0.68771

Collected Steps per Second: 19,718.05881
Overall Steps per Second: 10,035.28707

Timestep Collection Time: 2.53585
Timestep Consumption Time: 2.44677
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.98262

Cumulative Model Updates: 107,930
Cumulative Timesteps: 900,328,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,339.54409
Policy Entropy: 1.70466
Value Function Loss: 0.06435

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.16547
Policy Update Magnitude: 0.49525
Value Function Update Magnitude: 0.65487

Collected Steps per Second: 21,112.22932
Overall Steps per Second: 10,067.60222

Timestep Collection Time: 2.36886
Timestep Consumption Time: 2.59875
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.96762

Cumulative Model Updates: 107,936
Cumulative Timesteps: 900,378,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 900378478...
Checkpoint 900378478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,481.83762
Policy Entropy: 1.70022
Value Function Loss: 0.07018

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.66110

Collected Steps per Second: 17,684.84905
Overall Steps per Second: 9,180.79201

Timestep Collection Time: 2.82943
Timestep Consumption Time: 2.62086
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 5.45029

Cumulative Model Updates: 107,942
Cumulative Timesteps: 900,428,516

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,603.82262
Policy Entropy: 1.70213
Value Function Loss: 0.07285

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15654
Policy Update Magnitude: 0.58965
Value Function Update Magnitude: 0.78350

Collected Steps per Second: 18,110.73096
Overall Steps per Second: 8,408.52578

Timestep Collection Time: 2.76168
Timestep Consumption Time: 3.18657
PPO Batch Consumption Time: 0.37097
Total Iteration Time: 5.94825

Cumulative Model Updates: 107,948
Cumulative Timesteps: 900,478,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 900478532...
Checkpoint 900478532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,534.62571
Policy Entropy: 1.68711
Value Function Loss: 0.07093

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15167
Policy Update Magnitude: 0.58500
Value Function Update Magnitude: 0.86245

Collected Steps per Second: 19,064.36877
Overall Steps per Second: 9,770.43062

Timestep Collection Time: 2.62395
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 5.11994

Cumulative Model Updates: 107,954
Cumulative Timesteps: 900,528,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,504.69497
Policy Entropy: 1.69245
Value Function Loss: 0.06743

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.14997
Policy Update Magnitude: 0.58030
Value Function Update Magnitude: 0.80527

Collected Steps per Second: 21,579.10712
Overall Steps per Second: 10,452.59057

Timestep Collection Time: 2.31715
Timestep Consumption Time: 2.46655
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.78369

Cumulative Model Updates: 107,960
Cumulative Timesteps: 900,578,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 900578558...
Checkpoint 900578558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,817.07670
Policy Entropy: 1.69239
Value Function Loss: 0.07597

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14910
Policy Update Magnitude: 0.59060
Value Function Update Magnitude: 0.62188

Collected Steps per Second: 21,258.79433
Overall Steps per Second: 10,218.68309

Timestep Collection Time: 2.35291
Timestep Consumption Time: 2.54205
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.89496

Cumulative Model Updates: 107,966
Cumulative Timesteps: 900,628,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,673.79729
Policy Entropy: 1.70075
Value Function Loss: 0.07924

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.59898
Value Function Update Magnitude: 0.45703

Collected Steps per Second: 21,243.99869
Overall Steps per Second: 10,334.61455

Timestep Collection Time: 2.35474
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.84043

Cumulative Model Updates: 107,972
Cumulative Timesteps: 900,678,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 900678602...
Checkpoint 900678602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,811.42302
Policy Entropy: 1.69128
Value Function Loss: 0.08293

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.14824
Policy Update Magnitude: 0.59398
Value Function Update Magnitude: 0.44603

Collected Steps per Second: 20,566.32323
Overall Steps per Second: 10,206.52974

Timestep Collection Time: 2.43281
Timestep Consumption Time: 2.46934
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.90216

Cumulative Model Updates: 107,978
Cumulative Timesteps: 900,728,636

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,358.05480
Policy Entropy: 1.68236
Value Function Loss: 0.07885

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14894
Policy Update Magnitude: 0.59719
Value Function Update Magnitude: 0.70770

Collected Steps per Second: 21,522.95634
Overall Steps per Second: 10,326.29498

Timestep Collection Time: 2.32412
Timestep Consumption Time: 2.52002
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.84414

Cumulative Model Updates: 107,984
Cumulative Timesteps: 900,778,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 900778658...
Checkpoint 900778658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,923.62118
Policy Entropy: 1.67626
Value Function Loss: 0.07328

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.59791
Value Function Update Magnitude: 0.69245

Collected Steps per Second: 20,995.80638
Overall Steps per Second: 10,182.52547

Timestep Collection Time: 2.38152
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.91057

Cumulative Model Updates: 107,990
Cumulative Timesteps: 900,828,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,283.15528
Policy Entropy: 1.68154
Value Function Loss: 0.06781

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.16626
Policy Update Magnitude: 0.56001
Value Function Update Magnitude: 0.65106

Collected Steps per Second: 21,318.71206
Overall Steps per Second: 10,282.97510

Timestep Collection Time: 2.34573
Timestep Consumption Time: 2.51745
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.86318

Cumulative Model Updates: 107,996
Cumulative Timesteps: 900,878,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 900878668...
Checkpoint 900878668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,322.21103
Policy Entropy: 1.68890
Value Function Loss: 0.07552

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.17520
Policy Update Magnitude: 0.49683
Value Function Update Magnitude: 0.60758

Collected Steps per Second: 21,149.96040
Overall Steps per Second: 10,186.50541

Timestep Collection Time: 2.36539
Timestep Consumption Time: 2.54581
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.91120

Cumulative Model Updates: 108,002
Cumulative Timesteps: 900,928,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,589.07722
Policy Entropy: 1.69673
Value Function Loss: 0.07307

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.59423

Collected Steps per Second: 21,301.25372
Overall Steps per Second: 10,229.39507

Timestep Collection Time: 2.34812
Timestep Consumption Time: 2.54151
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.88963

Cumulative Model Updates: 108,008
Cumulative Timesteps: 900,978,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 900978714...
Checkpoint 900978714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,329.95536
Policy Entropy: 1.70412
Value Function Loss: 0.07284

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.67030

Collected Steps per Second: 21,318.28653
Overall Steps per Second: 10,399.53115

Timestep Collection Time: 2.34681
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.81079

Cumulative Model Updates: 108,014
Cumulative Timesteps: 901,028,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,059.96056
Policy Entropy: 1.70589
Value Function Loss: 0.06284

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.70835

Collected Steps per Second: 21,340.31864
Overall Steps per Second: 10,395.75808

Timestep Collection Time: 2.34336
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.81042

Cumulative Model Updates: 108,020
Cumulative Timesteps: 901,078,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 901078752...
Checkpoint 901078752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,270.90677
Policy Entropy: 1.70352
Value Function Loss: 0.06292

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.17161
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.74398

Collected Steps per Second: 20,992.72632
Overall Steps per Second: 10,285.84254

Timestep Collection Time: 2.38292
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.86338

Cumulative Model Updates: 108,026
Cumulative Timesteps: 901,128,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,384.45926
Policy Entropy: 1.69321
Value Function Loss: 0.06079

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.17766
Policy Update Magnitude: 0.50600
Value Function Update Magnitude: 0.74232

Collected Steps per Second: 19,697.81219
Overall Steps per Second: 9,969.15786

Timestep Collection Time: 2.53845
Timestep Consumption Time: 2.47721
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 5.01567

Cumulative Model Updates: 108,032
Cumulative Timesteps: 901,178,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 901178778...
Checkpoint 901178778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,713.76440
Policy Entropy: 1.68572
Value Function Loss: 0.06372

Mean KL Divergence: 0.02021
SB3 Clip Fraction: 0.17542
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 20,527.37816
Overall Steps per Second: 10,311.61293

Timestep Collection Time: 2.43587
Timestep Consumption Time: 2.41323
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.84910

Cumulative Model Updates: 108,038
Cumulative Timesteps: 901,228,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,720.71928
Policy Entropy: 1.68028
Value Function Loss: 0.06441

Mean KL Divergence: 0.02041
SB3 Clip Fraction: 0.17638
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.45262

Collected Steps per Second: 20,811.26389
Overall Steps per Second: 10,395.81260

Timestep Collection Time: 2.40274
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.81001

Cumulative Model Updates: 108,044
Cumulative Timesteps: 901,278,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 901278784...
Checkpoint 901278784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,460.10327
Policy Entropy: 1.68747
Value Function Loss: 0.06602

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.56240
Value Function Update Magnitude: 0.36881

Collected Steps per Second: 20,451.13451
Overall Steps per Second: 10,245.29528

Timestep Collection Time: 2.44554
Timestep Consumption Time: 2.43612
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.88166

Cumulative Model Updates: 108,050
Cumulative Timesteps: 901,328,798

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,800.96019
Policy Entropy: 1.70080
Value Function Loss: 0.06765

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.41271

Collected Steps per Second: 20,692.85906
Overall Steps per Second: 10,096.44153

Timestep Collection Time: 2.41668
Timestep Consumption Time: 2.53635
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.95303

Cumulative Model Updates: 108,056
Cumulative Timesteps: 901,378,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 901378806...
Checkpoint 901378806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,058.65089
Policy Entropy: 1.71296
Value Function Loss: 0.06745

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.57936
Value Function Update Magnitude: 0.44684

Collected Steps per Second: 21,314.43264
Overall Steps per Second: 10,297.23452

Timestep Collection Time: 2.34602
Timestep Consumption Time: 2.51005
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.85606

Cumulative Model Updates: 108,062
Cumulative Timesteps: 901,428,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,562.96421
Policy Entropy: 1.71911
Value Function Loss: 0.06869

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.14570
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.43008

Collected Steps per Second: 21,606.84920
Overall Steps per Second: 10,301.34048

Timestep Collection Time: 2.31417
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.85393

Cumulative Model Updates: 108,068
Cumulative Timesteps: 901,478,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 901478812...
Checkpoint 901478812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,063.25700
Policy Entropy: 1.72157
Value Function Loss: 0.07136

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13745
Policy Update Magnitude: 0.57664
Value Function Update Magnitude: 0.35894

Collected Steps per Second: 21,020.87807
Overall Steps per Second: 10,194.40377

Timestep Collection Time: 2.38011
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.90779

Cumulative Model Updates: 108,074
Cumulative Timesteps: 901,528,844

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,659.18112
Policy Entropy: 1.70646
Value Function Loss: 0.07975

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.58744
Value Function Update Magnitude: 0.30897

Collected Steps per Second: 21,226.28575
Overall Steps per Second: 10,405.03072

Timestep Collection Time: 2.35595
Timestep Consumption Time: 2.45019
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.80614

Cumulative Model Updates: 108,080
Cumulative Timesteps: 901,578,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 901578852...
Checkpoint 901578852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,182.77775
Policy Entropy: 1.69844
Value Function Loss: 0.07575

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.14373
Policy Update Magnitude: 0.58229
Value Function Update Magnitude: 0.39161

Collected Steps per Second: 21,057.72500
Overall Steps per Second: 10,320.67666

Timestep Collection Time: 2.37500
Timestep Consumption Time: 2.47081
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.84581

Cumulative Model Updates: 108,086
Cumulative Timesteps: 901,628,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,119.51668
Policy Entropy: 1.69262
Value Function Loss: 0.07254

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.15977
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.37803

Collected Steps per Second: 21,526.45221
Overall Steps per Second: 10,433.74298

Timestep Collection Time: 2.32412
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.79502

Cumulative Model Updates: 108,092
Cumulative Timesteps: 901,678,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 901678894...
Checkpoint 901678894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,618.61039
Policy Entropy: 1.69311
Value Function Loss: 0.07746

Mean KL Divergence: 0.01898
SB3 Clip Fraction: 0.17058
Policy Update Magnitude: 0.51750
Value Function Update Magnitude: 0.35368

Collected Steps per Second: 20,941.00222
Overall Steps per Second: 10,174.96522

Timestep Collection Time: 2.38890
Timestep Consumption Time: 2.52768
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.91658

Cumulative Model Updates: 108,098
Cumulative Timesteps: 901,728,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,683.45011
Policy Entropy: 1.70577
Value Function Loss: 0.07914

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.16717
Policy Update Magnitude: 0.53796
Value Function Update Magnitude: 0.34738

Collected Steps per Second: 21,508.54514
Overall Steps per Second: 10,417.07209

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.80212

Cumulative Model Updates: 108,104
Cumulative Timesteps: 901,778,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 901778944...
Checkpoint 901778944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,537.19750
Policy Entropy: 1.72011
Value Function Loss: 0.08274

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.18156
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.35555

Collected Steps per Second: 21,279.02388
Overall Steps per Second: 10,254.47557

Timestep Collection Time: 2.35011
Timestep Consumption Time: 2.52659
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.87670

Cumulative Model Updates: 108,110
Cumulative Timesteps: 901,828,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,259.53704
Policy Entropy: 1.73671
Value Function Loss: 0.07421

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.17147
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.34987

Collected Steps per Second: 21,540.02477
Overall Steps per Second: 10,420.41386

Timestep Collection Time: 2.32182
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.79943

Cumulative Model Updates: 108,116
Cumulative Timesteps: 901,878,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 901878964...
Checkpoint 901878964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,503.32418
Policy Entropy: 1.73078
Value Function Loss: 0.07530

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.16509
Policy Update Magnitude: 0.55263
Value Function Update Magnitude: 0.36335

Collected Steps per Second: 21,229.71600
Overall Steps per Second: 10,212.36977

Timestep Collection Time: 2.35641
Timestep Consumption Time: 2.54216
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.89857

Cumulative Model Updates: 108,122
Cumulative Timesteps: 901,928,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,331.20245
Policy Entropy: 1.74156
Value Function Loss: 0.07009

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.16502
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.38783

Collected Steps per Second: 21,301.26981
Overall Steps per Second: 10,380.88988

Timestep Collection Time: 2.34840
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.81885

Cumulative Model Updates: 108,128
Cumulative Timesteps: 901,979,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 901979014...
Checkpoint 901979014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,131.25990
Policy Entropy: 1.73986
Value Function Loss: 0.07541

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.15292
Policy Update Magnitude: 0.56713
Value Function Update Magnitude: 0.36731

Collected Steps per Second: 21,214.04737
Overall Steps per Second: 10,360.42478

Timestep Collection Time: 2.35749
Timestep Consumption Time: 2.46972
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.82722

Cumulative Model Updates: 108,134
Cumulative Timesteps: 902,029,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,154.97852
Policy Entropy: 1.74380
Value Function Loss: 0.06645

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.40698

Collected Steps per Second: 21,883.59271
Overall Steps per Second: 10,390.99893

Timestep Collection Time: 2.28591
Timestep Consumption Time: 2.52825
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.81417

Cumulative Model Updates: 108,140
Cumulative Timesteps: 902,079,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 902079050...
Checkpoint 902079050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,301.39864
Policy Entropy: 1.74947
Value Function Loss: 0.07652

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.14654
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.52429

Collected Steps per Second: 21,411.52380
Overall Steps per Second: 10,248.01512

Timestep Collection Time: 2.33631
Timestep Consumption Time: 2.54502
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 4.88134

Cumulative Model Updates: 108,146
Cumulative Timesteps: 902,129,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,757.58979
Policy Entropy: 1.74987
Value Function Loss: 0.06893

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.15363
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.52574

Collected Steps per Second: 20,880.54873
Overall Steps per Second: 10,451.52577

Timestep Collection Time: 2.39505
Timestep Consumption Time: 2.38990
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.78495

Cumulative Model Updates: 108,152
Cumulative Timesteps: 902,179,084

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902179084...
Checkpoint 902179084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,616.55800
Policy Entropy: 1.76710
Value Function Loss: 0.07807

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.15064
Policy Update Magnitude: 0.58347
Value Function Update Magnitude: 0.51985

Collected Steps per Second: 20,860.84868
Overall Steps per Second: 10,303.35295

Timestep Collection Time: 2.39760
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.85434

Cumulative Model Updates: 108,158
Cumulative Timesteps: 902,229,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,518.44142
Policy Entropy: 1.74908
Value Function Loss: 0.07440

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.45462

Collected Steps per Second: 20,689.22346
Overall Steps per Second: 10,301.70358

Timestep Collection Time: 2.41701
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.85415

Cumulative Model Updates: 108,164
Cumulative Timesteps: 902,279,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 902279106...
Checkpoint 902279106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,848.36375
Policy Entropy: 1.75789
Value Function Loss: 0.07873

Mean KL Divergence: 0.01934
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.52564
Value Function Update Magnitude: 0.50853

Collected Steps per Second: 20,539.06362
Overall Steps per Second: 10,244.78225

Timestep Collection Time: 2.43663
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.88502

Cumulative Model Updates: 108,170
Cumulative Timesteps: 902,329,152

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,371.33562
Policy Entropy: 1.75775
Value Function Loss: 0.07272

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15576
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.41035

Collected Steps per Second: 20,678.85273
Overall Steps per Second: 10,396.04263

Timestep Collection Time: 2.41899
Timestep Consumption Time: 2.39265
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.81164

Cumulative Model Updates: 108,176
Cumulative Timesteps: 902,379,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902379174...
Checkpoint 902379174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,447.96736
Policy Entropy: 1.77448
Value Function Loss: 0.07163

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15734
Policy Update Magnitude: 0.54020
Value Function Update Magnitude: 0.35834

Collected Steps per Second: 20,718.05527
Overall Steps per Second: 10,292.50068

Timestep Collection Time: 2.41442
Timestep Consumption Time: 2.44563
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.86004

Cumulative Model Updates: 108,182
Cumulative Timesteps: 902,429,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,859.33371
Policy Entropy: 1.78207
Value Function Loss: 0.06802

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.16518
Policy Update Magnitude: 0.52566
Value Function Update Magnitude: 0.49699

Collected Steps per Second: 21,471.33251
Overall Steps per Second: 10,474.97320

Timestep Collection Time: 2.32869
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.77328

Cumulative Model Updates: 108,188
Cumulative Timesteps: 902,479,196

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 902479196...
Checkpoint 902479196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,744.51917
Policy Entropy: 1.80119
Value Function Loss: 0.07666

Mean KL Divergence: 0.01920
SB3 Clip Fraction: 0.17258
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.41912

Collected Steps per Second: 21,346.40289
Overall Steps per Second: 10,331.04807

Timestep Collection Time: 2.34250
Timestep Consumption Time: 2.49766
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.84017

Cumulative Model Updates: 108,194
Cumulative Timesteps: 902,529,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,767.24855
Policy Entropy: 1.79465
Value Function Loss: 0.07902

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.18034
Policy Update Magnitude: 0.56715
Value Function Update Magnitude: 0.34692

Collected Steps per Second: 21,370.33708
Overall Steps per Second: 10,273.55059

Timestep Collection Time: 2.34035
Timestep Consumption Time: 2.52788
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.86823

Cumulative Model Updates: 108,200
Cumulative Timesteps: 902,579,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 902579214...
Checkpoint 902579214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,147.00251
Policy Entropy: 1.79337
Value Function Loss: 0.08692

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17985
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.36592

Collected Steps per Second: 21,342.89954
Overall Steps per Second: 10,231.67380

Timestep Collection Time: 2.34392
Timestep Consumption Time: 2.54541
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 4.88933

Cumulative Model Updates: 108,206
Cumulative Timesteps: 902,629,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,205.84444
Policy Entropy: 1.78535
Value Function Loss: 0.08027

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.18528
Policy Update Magnitude: 0.54579
Value Function Update Magnitude: 0.30232

Collected Steps per Second: 21,412.87281
Overall Steps per Second: 10,458.93650

Timestep Collection Time: 2.33551
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.78156

Cumulative Model Updates: 108,212
Cumulative Timesteps: 902,679,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902679250...
Checkpoint 902679250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,792.33542
Policy Entropy: 1.78857
Value Function Loss: 0.08453

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.18546
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.32512

Collected Steps per Second: 21,135.88829
Overall Steps per Second: 10,136.06060

Timestep Collection Time: 2.36564
Timestep Consumption Time: 2.56724
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.93288

Cumulative Model Updates: 108,218
Cumulative Timesteps: 902,729,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,367.63946
Policy Entropy: 1.80272
Value Function Loss: 0.08329

Mean KL Divergence: 0.01888
SB3 Clip Fraction: 0.17298
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.44760

Collected Steps per Second: 21,359.76529
Overall Steps per Second: 10,402.59221

Timestep Collection Time: 2.34197
Timestep Consumption Time: 2.46683
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.80880

Cumulative Model Updates: 108,224
Cumulative Timesteps: 902,779,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 902779274...
Checkpoint 902779274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,649.74854
Policy Entropy: 1.81678
Value Function Loss: 0.08102

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.17026
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.42959

Collected Steps per Second: 20,150.02075
Overall Steps per Second: 9,180.33875

Timestep Collection Time: 2.48188
Timestep Consumption Time: 2.96563
PPO Batch Consumption Time: 0.36649
Total Iteration Time: 5.44751

Cumulative Model Updates: 108,230
Cumulative Timesteps: 902,829,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,390.68628
Policy Entropy: 1.83409
Value Function Loss: 0.08225

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.16947
Policy Update Magnitude: 0.57051
Value Function Update Magnitude: 0.46213

Collected Steps per Second: 20,822.20436
Overall Steps per Second: 10,117.12274

Timestep Collection Time: 2.40176
Timestep Consumption Time: 2.54134
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.94310

Cumulative Model Updates: 108,236
Cumulative Timesteps: 902,879,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902879294...
Checkpoint 902879294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,430.27681
Policy Entropy: 1.82939
Value Function Loss: 0.08192

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.17070
Policy Update Magnitude: 0.59566
Value Function Update Magnitude: 0.55997

Collected Steps per Second: 21,436.02419
Overall Steps per Second: 10,425.13773

Timestep Collection Time: 2.33336
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.79783

Cumulative Model Updates: 108,242
Cumulative Timesteps: 902,929,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,304.90030
Policy Entropy: 1.82417
Value Function Loss: 0.08318

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.16900
Policy Update Magnitude: 0.59711
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 21,301.63960
Overall Steps per Second: 10,248.48531

Timestep Collection Time: 2.34865
Timestep Consumption Time: 2.53305
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.88170

Cumulative Model Updates: 108,248
Cumulative Timesteps: 902,979,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 902979342...
Checkpoint 902979342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,096.68682
Policy Entropy: 1.80510
Value Function Loss: 0.07908

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16630
Policy Update Magnitude: 0.58162
Value Function Update Magnitude: 0.60992

Collected Steps per Second: 21,315.06002
Overall Steps per Second: 9,649.05093

Timestep Collection Time: 2.34642
Timestep Consumption Time: 2.83689
PPO Batch Consumption Time: 0.34547
Total Iteration Time: 5.18331

Cumulative Model Updates: 108,254
Cumulative Timesteps: 903,029,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,935.76163
Policy Entropy: 1.80250
Value Function Loss: 0.08767

Mean KL Divergence: 0.01975
SB3 Clip Fraction: 0.17846
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.50140

Collected Steps per Second: 19,018.65373
Overall Steps per Second: 9,755.76811

Timestep Collection Time: 2.63100
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 5.12907

Cumulative Model Updates: 108,260
Cumulative Timesteps: 903,079,394

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 903079394...
Checkpoint 903079394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,287.74624
Policy Entropy: 1.80645
Value Function Loss: 0.08993

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.19677
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.38732

Collected Steps per Second: 20,090.34669
Overall Steps per Second: 9,421.65399

Timestep Collection Time: 2.48886
Timestep Consumption Time: 2.81828
PPO Batch Consumption Time: 0.34514
Total Iteration Time: 5.30714

Cumulative Model Updates: 108,266
Cumulative Timesteps: 903,129,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,051.22843
Policy Entropy: 1.81151
Value Function Loss: 0.08833

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.49723
Value Function Update Magnitude: 0.39888

Collected Steps per Second: 21,397.02985
Overall Steps per Second: 10,380.75974

Timestep Collection Time: 2.33846
Timestep Consumption Time: 2.48162
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.82007

Cumulative Model Updates: 108,272
Cumulative Timesteps: 903,179,432

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 903179432...
Checkpoint 903179432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,691.18363
Policy Entropy: 1.81493
Value Function Loss: 0.07827

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.16046
Policy Update Magnitude: 0.49136
Value Function Update Magnitude: 0.58456

Collected Steps per Second: 20,970.16050
Overall Steps per Second: 10,278.05961

Timestep Collection Time: 2.38491
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.86590

Cumulative Model Updates: 108,278
Cumulative Timesteps: 903,229,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,070.30806
Policy Entropy: 1.80849
Value Function Loss: 0.07299

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.15372
Policy Update Magnitude: 0.52106
Value Function Update Magnitude: 0.70683

Collected Steps per Second: 21,495.49250
Overall Steps per Second: 10,430.85243

Timestep Collection Time: 2.32681
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.79501

Cumulative Model Updates: 108,284
Cumulative Timesteps: 903,279,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 903279460...
Checkpoint 903279460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,316.77554
Policy Entropy: 1.80276
Value Function Loss: 0.06860

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.56645
Value Function Update Magnitude: 0.72455

Collected Steps per Second: 21,357.43691
Overall Steps per Second: 10,200.80518

Timestep Collection Time: 2.34176
Timestep Consumption Time: 2.56119
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 4.90295

Cumulative Model Updates: 108,290
Cumulative Timesteps: 903,329,474

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,813.12679
Policy Entropy: 1.79610
Value Function Loss: 0.06288

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14707
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.75145

Collected Steps per Second: 21,229.89847
Overall Steps per Second: 10,370.30395

Timestep Collection Time: 2.35573
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.82262

Cumulative Model Updates: 108,296
Cumulative Timesteps: 903,379,486

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 903379486...
Checkpoint 903379486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,459.49196
Policy Entropy: 1.79857
Value Function Loss: 0.05922

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.68051

Collected Steps per Second: 21,391.65707
Overall Steps per Second: 10,308.27157

Timestep Collection Time: 2.33792
Timestep Consumption Time: 2.51372
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.85164

Cumulative Model Updates: 108,302
Cumulative Timesteps: 903,429,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,239.87417
Policy Entropy: 1.79136
Value Function Loss: 0.06336

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.58611

Collected Steps per Second: 21,399.53873
Overall Steps per Second: 10,366.70500

Timestep Collection Time: 2.33874
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.82776

Cumulative Model Updates: 108,308
Cumulative Timesteps: 903,479,546

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 903479546...
Checkpoint 903479546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,673.45219
Policy Entropy: 1.79120
Value Function Loss: 0.06705

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.55513

Collected Steps per Second: 21,120.35804
Overall Steps per Second: 10,338.82306

Timestep Collection Time: 2.36757
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.83653

Cumulative Model Updates: 108,314
Cumulative Timesteps: 903,529,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,443.92140
Policy Entropy: 1.79551
Value Function Loss: 0.06777

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.57420
Value Function Update Magnitude: 0.65854

Collected Steps per Second: 21,708.44668
Overall Steps per Second: 10,406.50014

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.80642

Cumulative Model Updates: 108,320
Cumulative Timesteps: 903,579,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 903579568...
Checkpoint 903579568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,457.38113
Policy Entropy: 1.80020
Value Function Loss: 0.06166

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.73300

Collected Steps per Second: 21,344.36373
Overall Steps per Second: 10,234.90197

Timestep Collection Time: 2.34310
Timestep Consumption Time: 2.54332
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.88642

Cumulative Model Updates: 108,326
Cumulative Timesteps: 903,629,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,615.35572
Policy Entropy: 1.79654
Value Function Loss: 0.06432

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.57198
Value Function Update Magnitude: 0.74338

Collected Steps per Second: 21,513.72881
Overall Steps per Second: 10,391.49923

Timestep Collection Time: 2.32447
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.81240

Cumulative Model Updates: 108,332
Cumulative Timesteps: 903,679,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 903679588...
Checkpoint 903679588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,084.86110
Policy Entropy: 1.78582
Value Function Loss: 0.06634

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.74843

Collected Steps per Second: 21,251.43546
Overall Steps per Second: 10,213.81136

Timestep Collection Time: 2.35325
Timestep Consumption Time: 2.54306
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.89631

Cumulative Model Updates: 108,338
Cumulative Timesteps: 903,729,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,210.83875
Policy Entropy: 1.79389
Value Function Loss: 0.07280

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.59036
Value Function Update Magnitude: 0.67995

Collected Steps per Second: 21,014.49842
Overall Steps per Second: 10,129.60270

Timestep Collection Time: 2.38036
Timestep Consumption Time: 2.55784
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.93820

Cumulative Model Updates: 108,344
Cumulative Timesteps: 903,779,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 903779620...
Checkpoint 903779620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,290.26812
Policy Entropy: 1.78660
Value Function Loss: 0.07525

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.69091

Collected Steps per Second: 21,401.99028
Overall Steps per Second: 10,288.95092

Timestep Collection Time: 2.33866
Timestep Consumption Time: 2.52597
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.86464

Cumulative Model Updates: 108,350
Cumulative Timesteps: 903,829,672

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,781.98444
Policy Entropy: 1.80183
Value Function Loss: 0.07255

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.75320

Collected Steps per Second: 21,505.23396
Overall Steps per Second: 10,259.03058

Timestep Collection Time: 2.32604
Timestep Consumption Time: 2.54986
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.87590

Cumulative Model Updates: 108,356
Cumulative Timesteps: 903,879,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 903879694...
Checkpoint 903879694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,369.37511
Policy Entropy: 1.79773
Value Function Loss: 0.06566

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14817
Policy Update Magnitude: 0.57212
Value Function Update Magnitude: 0.74099

Collected Steps per Second: 21,084.85522
Overall Steps per Second: 10,237.07330

Timestep Collection Time: 2.37184
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.88519

Cumulative Model Updates: 108,362
Cumulative Timesteps: 903,929,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,288.65902
Policy Entropy: 1.79538
Value Function Loss: 0.07158

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.55910
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 21,525.49893
Overall Steps per Second: 10,409.07438

Timestep Collection Time: 2.32403
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.80600

Cumulative Model Updates: 108,368
Cumulative Timesteps: 903,979,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 903979730...
Checkpoint 903979730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,751.74063
Policy Entropy: 1.78661
Value Function Loss: 0.07091

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.56628
Value Function Update Magnitude: 0.54771

Collected Steps per Second: 21,192.11581
Overall Steps per Second: 10,258.53468

Timestep Collection Time: 2.36088
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.87711

Cumulative Model Updates: 108,374
Cumulative Timesteps: 904,029,762

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.99647
Policy Entropy: 1.78251
Value Function Loss: 0.07686

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.52742

Collected Steps per Second: 21,783.15744
Overall Steps per Second: 10,426.94510

Timestep Collection Time: 2.29563
Timestep Consumption Time: 2.50022
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.79584

Cumulative Model Updates: 108,380
Cumulative Timesteps: 904,079,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 904079768...
Checkpoint 904079768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,615.35174
Policy Entropy: 1.77911
Value Function Loss: 0.07676

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14764
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.43284

Collected Steps per Second: 20,437.78168
Overall Steps per Second: 10,212.14255

Timestep Collection Time: 2.44753
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.89829

Cumulative Model Updates: 108,386
Cumulative Timesteps: 904,129,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,518.45662
Policy Entropy: 1.77533
Value Function Loss: 0.07756

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 20,512.98962
Overall Steps per Second: 10,372.07018

Timestep Collection Time: 2.43816
Timestep Consumption Time: 2.38383
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.82199

Cumulative Model Updates: 108,392
Cumulative Timesteps: 904,179,804

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 904179804...
Checkpoint 904179804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,963.60421
Policy Entropy: 1.77964
Value Function Loss: 0.07473

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.59239
Value Function Update Magnitude: 0.74136

Collected Steps per Second: 20,551.75537
Overall Steps per Second: 10,294.51023

Timestep Collection Time: 2.43347
Timestep Consumption Time: 2.42466
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.85812

Cumulative Model Updates: 108,398
Cumulative Timesteps: 904,229,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,440.29049
Policy Entropy: 1.77985
Value Function Loss: 0.07240

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.72638

Collected Steps per Second: 20,723.95672
Overall Steps per Second: 10,385.65132

Timestep Collection Time: 2.41286
Timestep Consumption Time: 2.40186
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.81472

Cumulative Model Updates: 108,404
Cumulative Timesteps: 904,279,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 904279820...
Checkpoint 904279820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,005.91188
Policy Entropy: 1.78421
Value Function Loss: 0.07149

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.68515

Collected Steps per Second: 20,640.09289
Overall Steps per Second: 10,259.61859

Timestep Collection Time: 2.42392
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.87640

Cumulative Model Updates: 108,410
Cumulative Timesteps: 904,329,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,154.60939
Policy Entropy: 1.77995
Value Function Loss: 0.06649

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.56716
Value Function Update Magnitude: 0.66157

Collected Steps per Second: 21,354.99943
Overall Steps per Second: 10,426.07281

Timestep Collection Time: 2.34221
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.79740

Cumulative Model Updates: 108,416
Cumulative Timesteps: 904,379,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 904379868...
Checkpoint 904379868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,384.90942
Policy Entropy: 1.78050
Value Function Loss: 0.06583

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.56847
Value Function Update Magnitude: 0.51762

Collected Steps per Second: 21,059.96726
Overall Steps per Second: 10,264.21372

Timestep Collection Time: 2.37484
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.87266

Cumulative Model Updates: 108,422
Cumulative Timesteps: 904,429,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,104.73708
Policy Entropy: 1.77310
Value Function Loss: 0.06907

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.40461

Collected Steps per Second: 21,357.24698
Overall Steps per Second: 10,413.15988

Timestep Collection Time: 2.34131
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.80200

Cumulative Model Updates: 108,428
Cumulative Timesteps: 904,479,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 904479886...
Checkpoint 904479886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,889.03901
Policy Entropy: 1.77673
Value Function Loss: 0.07508

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.33953

Collected Steps per Second: 21,282.24165
Overall Steps per Second: 10,270.57711

Timestep Collection Time: 2.34966
Timestep Consumption Time: 2.51920
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.86886

Cumulative Model Updates: 108,434
Cumulative Timesteps: 904,529,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,221.00370
Policy Entropy: 1.78684
Value Function Loss: 0.08291

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14516
Policy Update Magnitude: 0.58624
Value Function Update Magnitude: 0.42150

Collected Steps per Second: 20,989.94024
Overall Steps per Second: 10,038.21614

Timestep Collection Time: 2.38438
Timestep Consumption Time: 2.60137
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.98575

Cumulative Model Updates: 108,440
Cumulative Timesteps: 904,579,940

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 904579940...
Checkpoint 904579940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,835.33208
Policy Entropy: 1.79393
Value Function Loss: 0.07685

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15783
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.55236

Collected Steps per Second: 19,683.05775
Overall Steps per Second: 9,675.11642

Timestep Collection Time: 2.54107
Timestep Consumption Time: 2.62848
PPO Batch Consumption Time: 0.29818
Total Iteration Time: 5.16955

Cumulative Model Updates: 108,446
Cumulative Timesteps: 904,629,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,909.57222
Policy Entropy: 1.79557
Value Function Loss: 0.07693

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.49809
Value Function Update Magnitude: 0.61617

Collected Steps per Second: 21,176.57989
Overall Steps per Second: 10,154.05274

Timestep Collection Time: 2.36148
Timestep Consumption Time: 2.56345
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.92493

Cumulative Model Updates: 108,452
Cumulative Timesteps: 904,679,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 904679964...
Checkpoint 904679964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,369.23039
Policy Entropy: 1.79348
Value Function Loss: 0.07954

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.17152
Policy Update Magnitude: 0.51684
Value Function Update Magnitude: 0.66834

Collected Steps per Second: 21,154.02911
Overall Steps per Second: 10,174.69455

Timestep Collection Time: 2.36399
Timestep Consumption Time: 2.55094
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.91494

Cumulative Model Updates: 108,458
Cumulative Timesteps: 904,729,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,143.93734
Policy Entropy: 1.80046
Value Function Loss: 0.07831

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16183
Policy Update Magnitude: 0.54972
Value Function Update Magnitude: 0.72013

Collected Steps per Second: 21,492.19327
Overall Steps per Second: 10,393.29478

Timestep Collection Time: 2.32736
Timestep Consumption Time: 2.48536
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.81272

Cumulative Model Updates: 108,464
Cumulative Timesteps: 904,779,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 904779992...
Checkpoint 904779992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,356.85469
Policy Entropy: 1.80585
Value Function Loss: 0.07700

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.16822
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.63791

Collected Steps per Second: 21,269.42050
Overall Steps per Second: 10,322.09293

Timestep Collection Time: 2.35117
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.84475

Cumulative Model Updates: 108,470
Cumulative Timesteps: 904,830,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,747.70010
Policy Entropy: 1.81445
Value Function Loss: 0.06993

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.17430
Policy Update Magnitude: 0.48806
Value Function Update Magnitude: 0.57559

Collected Steps per Second: 21,541.55858
Overall Steps per Second: 10,390.84682

Timestep Collection Time: 2.32212
Timestep Consumption Time: 2.49193
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.81404

Cumulative Model Updates: 108,476
Cumulative Timesteps: 904,880,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904880022...
Checkpoint 904880022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,735.19572
Policy Entropy: 1.80918
Value Function Loss: 0.06487

Mean KL Divergence: 0.02203
SB3 Clip Fraction: 0.17786
Policy Update Magnitude: 0.45994
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 20,907.85787
Overall Steps per Second: 10,240.16536

Timestep Collection Time: 2.39298
Timestep Consumption Time: 2.49288
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.88586

Cumulative Model Updates: 108,482
Cumulative Timesteps: 904,930,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,834.64506
Policy Entropy: 1.80181
Value Function Loss: 0.06850

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.53787
Value Function Update Magnitude: 0.53726

Collected Steps per Second: 21,387.36847
Overall Steps per Second: 10,387.76769

Timestep Collection Time: 2.33839
Timestep Consumption Time: 2.47612
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.81451

Cumulative Model Updates: 108,488
Cumulative Timesteps: 904,980,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 904980066...
Checkpoint 904980066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,392.09599
Policy Entropy: 1.79126
Value Function Loss: 0.07435

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.55811

Collected Steps per Second: 21,201.02811
Overall Steps per Second: 10,266.78700

Timestep Collection Time: 2.35866
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.87066

Cumulative Model Updates: 108,494
Cumulative Timesteps: 905,030,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,276.99682
Policy Entropy: 1.80473
Value Function Loss: 0.07459

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.17352
Policy Update Magnitude: 0.53422
Value Function Update Magnitude: 0.67472

Collected Steps per Second: 21,501.74059
Overall Steps per Second: 10,423.84972

Timestep Collection Time: 2.32577
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.79746

Cumulative Model Updates: 108,500
Cumulative Timesteps: 905,080,080

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 905080080...
Checkpoint 905080080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,847.21269
Policy Entropy: 1.79542
Value Function Loss: 0.07272

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.17706
Policy Update Magnitude: 0.52142
Value Function Update Magnitude: 0.64821

Collected Steps per Second: 21,270.85720
Overall Steps per Second: 10,230.77325

Timestep Collection Time: 2.35251
Timestep Consumption Time: 2.53861
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.89113

Cumulative Model Updates: 108,506
Cumulative Timesteps: 905,130,120

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,124.91487
Policy Entropy: 1.79178
Value Function Loss: 0.07190

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.17856
Policy Update Magnitude: 0.48537
Value Function Update Magnitude: 0.59490

Collected Steps per Second: 21,347.36192
Overall Steps per Second: 10,225.24687

Timestep Collection Time: 2.34371
Timestep Consumption Time: 2.54928
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.89299

Cumulative Model Updates: 108,512
Cumulative Timesteps: 905,180,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 905180152...
Checkpoint 905180152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,972.39501
Policy Entropy: 1.77556
Value Function Loss: 0.07232

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15150
Policy Update Magnitude: 0.51289
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 21,343.59150
Overall Steps per Second: 10,389.22003

Timestep Collection Time: 2.34365
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.81480

Cumulative Model Updates: 108,518
Cumulative Timesteps: 905,230,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,028.55029
Policy Entropy: 1.79306
Value Function Loss: 0.07234

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.57401
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 21,425.24987
Overall Steps per Second: 10,051.99574

Timestep Collection Time: 2.33454
Timestep Consumption Time: 2.64139
PPO Batch Consumption Time: 0.31074
Total Iteration Time: 4.97593

Cumulative Model Updates: 108,524
Cumulative Timesteps: 905,280,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905280192...
Checkpoint 905280192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,504.42827
Policy Entropy: 1.80024
Value Function Loss: 0.07450

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.58327
Value Function Update Magnitude: 0.64502

Collected Steps per Second: 18,048.17618
Overall Steps per Second: 9,458.20540

Timestep Collection Time: 2.77092
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 5.28747

Cumulative Model Updates: 108,530
Cumulative Timesteps: 905,330,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,214.16829
Policy Entropy: 1.80861
Value Function Loss: 0.07411

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.56252
Value Function Update Magnitude: 0.65908

Collected Steps per Second: 21,727.59960
Overall Steps per Second: 10,549.98549

Timestep Collection Time: 2.30196
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.74086

Cumulative Model Updates: 108,536
Cumulative Timesteps: 905,380,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905380218...
Checkpoint 905380218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,567.14188
Policy Entropy: 1.80265
Value Function Loss: 0.07663

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.66679

Collected Steps per Second: 21,659.42780
Overall Steps per Second: 10,388.52398

Timestep Collection Time: 2.30902
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.81416

Cumulative Model Updates: 108,542
Cumulative Timesteps: 905,430,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,016.32333
Policy Entropy: 1.79799
Value Function Loss: 0.07208

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.14181
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.78589

Collected Steps per Second: 18,761.27912
Overall Steps per Second: 9,439.17364

Timestep Collection Time: 2.66549
Timestep Consumption Time: 2.63243
PPO Batch Consumption Time: 0.31169
Total Iteration Time: 5.29792

Cumulative Model Updates: 108,548
Cumulative Timesteps: 905,480,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 905480238...
Checkpoint 905480238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,386.21832
Policy Entropy: 1.80089
Value Function Loss: 0.07075

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14258
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.74323

Collected Steps per Second: 20,998.32892
Overall Steps per Second: 9,850.66306

Timestep Collection Time: 2.38248
Timestep Consumption Time: 2.69617
PPO Batch Consumption Time: 0.31150
Total Iteration Time: 5.07864

Cumulative Model Updates: 108,554
Cumulative Timesteps: 905,530,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,949.17600
Policy Entropy: 1.79918
Value Function Loss: 0.07660

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13725
Policy Update Magnitude: 0.59405
Value Function Update Magnitude: 0.54915

Collected Steps per Second: 19,880.35614
Overall Steps per Second: 9,545.56733

Timestep Collection Time: 2.51575
Timestep Consumption Time: 2.72375
PPO Batch Consumption Time: 0.32283
Total Iteration Time: 5.23950

Cumulative Model Updates: 108,560
Cumulative Timesteps: 905,580,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 905580280...
Checkpoint 905580280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,892.76128
Policy Entropy: 1.81024
Value Function Loss: 0.08477

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.60059
Value Function Update Magnitude: 0.44621

Collected Steps per Second: 20,138.32050
Overall Steps per Second: 9,802.54466

Timestep Collection Time: 2.48362
Timestep Consumption Time: 2.61873
PPO Batch Consumption Time: 0.30593
Total Iteration Time: 5.10235

Cumulative Model Updates: 108,566
Cumulative Timesteps: 905,630,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,336.38371
Policy Entropy: 1.79878
Value Function Loss: 0.07895

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.60165
Value Function Update Magnitude: 0.45828

Collected Steps per Second: 21,333.02716
Overall Steps per Second: 10,218.17639

Timestep Collection Time: 2.34463
Timestep Consumption Time: 2.55038
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.89500

Cumulative Model Updates: 108,572
Cumulative Timesteps: 905,680,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905680314...
Checkpoint 905680314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,020.02424
Policy Entropy: 1.80315
Value Function Loss: 0.07174

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.58164
Value Function Update Magnitude: 0.58964

Collected Steps per Second: 20,975.08297
Overall Steps per Second: 10,201.20159

Timestep Collection Time: 2.38397
Timestep Consumption Time: 2.51780
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.90178

Cumulative Model Updates: 108,578
Cumulative Timesteps: 905,730,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,792.91329
Policy Entropy: 1.79699
Value Function Loss: 0.06880

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14766
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.68245

Collected Steps per Second: 21,453.19352
Overall Steps per Second: 10,365.24002

Timestep Collection Time: 2.33159
Timestep Consumption Time: 2.49416
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.82574

Cumulative Model Updates: 108,584
Cumulative Timesteps: 905,780,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 905780338...
Checkpoint 905780338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,148.16418
Policy Entropy: 1.80206
Value Function Loss: 0.06568

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.56612

Collected Steps per Second: 21,311.63752
Overall Steps per Second: 10,295.48465

Timestep Collection Time: 2.34717
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.85863

Cumulative Model Updates: 108,590
Cumulative Timesteps: 905,830,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,198.96403
Policy Entropy: 1.79063
Value Function Loss: 0.06829

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.56778
Value Function Update Magnitude: 0.45590

Collected Steps per Second: 20,602.64635
Overall Steps per Second: 10,354.00615

Timestep Collection Time: 2.42765
Timestep Consumption Time: 2.40294
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.83059

Cumulative Model Updates: 108,596
Cumulative Timesteps: 905,880,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 905880376...
Checkpoint 905880376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,415.30949
Policy Entropy: 1.77471
Value Function Loss: 0.06372

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.50867

Collected Steps per Second: 20,514.26852
Overall Steps per Second: 10,248.15791

Timestep Collection Time: 2.43801
Timestep Consumption Time: 2.44228
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.88029

Cumulative Model Updates: 108,602
Cumulative Timesteps: 905,930,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,209.39788
Policy Entropy: 1.76892
Value Function Loss: 0.06382

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13765
Policy Update Magnitude: 0.56217
Value Function Update Magnitude: 0.55105

Collected Steps per Second: 20,960.96816
Overall Steps per Second: 10,450.71859

Timestep Collection Time: 2.38539
Timestep Consumption Time: 2.39897
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.78436

Cumulative Model Updates: 108,608
Cumulative Timesteps: 905,980,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 905980390...
Checkpoint 905980390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,217.26606
Policy Entropy: 1.76758
Value Function Loss: 0.06130

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.55892
Value Function Update Magnitude: 0.57325

Collected Steps per Second: 20,734.69898
Overall Steps per Second: 10,275.92184

Timestep Collection Time: 2.41171
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.86633

Cumulative Model Updates: 108,614
Cumulative Timesteps: 906,030,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,237.06099
Policy Entropy: 1.78031
Value Function Loss: 0.07394

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14308
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.62292

Collected Steps per Second: 21,181.68663
Overall Steps per Second: 10,401.22015

Timestep Collection Time: 2.36195
Timestep Consumption Time: 2.44807
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.81001

Cumulative Model Updates: 108,620
Cumulative Timesteps: 906,080,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 906080426...
Checkpoint 906080426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,859.54660
Policy Entropy: 1.78125
Value Function Loss: 0.07229

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.71106

Collected Steps per Second: 20,502.08927
Overall Steps per Second: 10,146.75282

Timestep Collection Time: 2.43965
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.92946

Cumulative Model Updates: 108,626
Cumulative Timesteps: 906,130,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,101.19373
Policy Entropy: 1.79914
Value Function Loss: 0.07482

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13840
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.67723

Collected Steps per Second: 21,514.33810
Overall Steps per Second: 10,475.83719

Timestep Collection Time: 2.32505
Timestep Consumption Time: 2.44993
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.77499

Cumulative Model Updates: 108,632
Cumulative Timesteps: 906,180,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 906180466...
Checkpoint 906180466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,160.22282
Policy Entropy: 1.79010
Value Function Loss: 0.06608

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13841
Policy Update Magnitude: 0.56747
Value Function Update Magnitude: 0.59081

Collected Steps per Second: 21,192.25096
Overall Steps per Second: 10,281.75440

Timestep Collection Time: 2.36030
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.86493

Cumulative Model Updates: 108,638
Cumulative Timesteps: 906,230,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,338.38907
Policy Entropy: 1.78885
Value Function Loss: 0.07007

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.51390
Value Function Update Magnitude: 0.47817

Collected Steps per Second: 21,473.10700
Overall Steps per Second: 10,369.79508

Timestep Collection Time: 2.32952
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.82382

Cumulative Model Updates: 108,644
Cumulative Timesteps: 906,280,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 906280508...
Checkpoint 906280508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,148.57934
Policy Entropy: 1.78188
Value Function Loss: 0.07024

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14479
Policy Update Magnitude: 0.50455
Value Function Update Magnitude: 0.40715

Collected Steps per Second: 20,706.85629
Overall Steps per Second: 10,257.96542

Timestep Collection Time: 2.41572
Timestep Consumption Time: 2.46068
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.87641

Cumulative Model Updates: 108,650
Cumulative Timesteps: 906,330,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,983.70454
Policy Entropy: 1.78595
Value Function Loss: 0.07079

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.39378

Collected Steps per Second: 21,618.47953
Overall Steps per Second: 10,414.75458

Timestep Collection Time: 2.31348
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.80223

Cumulative Model Updates: 108,656
Cumulative Timesteps: 906,380,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 906380544...
Checkpoint 906380544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,300.60043
Policy Entropy: 1.78021
Value Function Loss: 0.07308

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.47569

Collected Steps per Second: 21,125.42546
Overall Steps per Second: 10,321.14646

Timestep Collection Time: 2.36833
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.84752

Cumulative Model Updates: 108,662
Cumulative Timesteps: 906,430,576

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,536.22793
Policy Entropy: 1.76693
Value Function Loss: 0.07649

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.56971
Value Function Update Magnitude: 0.52093

Collected Steps per Second: 21,643.19693
Overall Steps per Second: 10,454.88863

Timestep Collection Time: 2.31075
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.78360

Cumulative Model Updates: 108,668
Cumulative Timesteps: 906,480,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 906480588...
Checkpoint 906480588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,432.02103
Policy Entropy: 1.77559
Value Function Loss: 0.08475

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14432
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.44408

Collected Steps per Second: 21,041.20657
Overall Steps per Second: 10,173.24102

Timestep Collection Time: 2.37724
Timestep Consumption Time: 2.53958
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.91682

Cumulative Model Updates: 108,674
Cumulative Timesteps: 906,530,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,180.20005
Policy Entropy: 1.79062
Value Function Loss: 0.08758

Mean KL Divergence: 0.02059
SB3 Clip Fraction: 0.17935
Policy Update Magnitude: 0.54820
Value Function Update Magnitude: 0.42035

Collected Steps per Second: 21,838.78995
Overall Steps per Second: 10,486.03915

Timestep Collection Time: 2.28969
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.76863

Cumulative Model Updates: 108,680
Cumulative Timesteps: 906,580,612

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 906580612...
Checkpoint 906580612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,829.32707
Policy Entropy: 1.79469
Value Function Loss: 0.08035

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.41883

Collected Steps per Second: 20,912.48217
Overall Steps per Second: 10,194.90097

Timestep Collection Time: 2.39101
Timestep Consumption Time: 2.51360
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.90461

Cumulative Model Updates: 108,686
Cumulative Timesteps: 906,630,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,160.42747
Policy Entropy: 1.79439
Value Function Loss: 0.07719

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.45111

Collected Steps per Second: 21,466.75347
Overall Steps per Second: 10,371.64021

Timestep Collection Time: 2.32984
Timestep Consumption Time: 2.49235
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.82219

Cumulative Model Updates: 108,692
Cumulative Timesteps: 906,680,628

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 906680628...
Checkpoint 906680628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,600.95312
Policy Entropy: 1.77315
Value Function Loss: 0.07770

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15172
Policy Update Magnitude: 0.56845
Value Function Update Magnitude: 0.40141

Collected Steps per Second: 21,026.68427
Overall Steps per Second: 10,319.06230

Timestep Collection Time: 2.37907
Timestep Consumption Time: 2.46866
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.84773

Cumulative Model Updates: 108,698
Cumulative Timesteps: 906,730,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,485.06598
Policy Entropy: 1.77408
Value Function Loss: 0.08010

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.57882
Value Function Update Magnitude: 0.41499

Collected Steps per Second: 21,326.61817
Overall Steps per Second: 10,365.52294

Timestep Collection Time: 2.34486
Timestep Consumption Time: 2.47959
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.82446

Cumulative Model Updates: 108,704
Cumulative Timesteps: 906,780,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 906780660...
Checkpoint 906780660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,340.54059
Policy Entropy: 1.78229
Value Function Loss: 0.08146

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14875
Policy Update Magnitude: 0.59568
Value Function Update Magnitude: 0.52083

Collected Steps per Second: 20,778.90865
Overall Steps per Second: 10,272.03515

Timestep Collection Time: 2.40657
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.86817

Cumulative Model Updates: 108,710
Cumulative Timesteps: 906,830,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,992.51134
Policy Entropy: 1.79056
Value Function Loss: 0.07707

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.58919
Value Function Update Magnitude: 0.61311

Collected Steps per Second: 21,613.67749
Overall Steps per Second: 10,460.57965

Timestep Collection Time: 2.31400
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.78119

Cumulative Model Updates: 108,716
Cumulative Timesteps: 906,880,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 906880680...
Checkpoint 906880680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,101.33489
Policy Entropy: 1.77603
Value Function Loss: 0.07175

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.60111
Value Function Update Magnitude: 0.66732

Collected Steps per Second: 20,881.79793
Overall Steps per Second: 10,144.88162

Timestep Collection Time: 2.39500
Timestep Consumption Time: 2.53477
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.92978

Cumulative Model Updates: 108,722
Cumulative Timesteps: 906,930,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,656.10013
Policy Entropy: 1.76711
Value Function Loss: 0.07292

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14973
Policy Update Magnitude: 0.58537
Value Function Update Magnitude: 0.61802

Collected Steps per Second: 21,473.66492
Overall Steps per Second: 10,307.91480

Timestep Collection Time: 2.32927
Timestep Consumption Time: 2.52312
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.85239

Cumulative Model Updates: 108,728
Cumulative Timesteps: 906,980,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 906980710...
Checkpoint 906980710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,073.36482
Policy Entropy: 1.77716
Value Function Loss: 0.07697

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.58225
Value Function Update Magnitude: 0.49166

Collected Steps per Second: 21,437.54062
Overall Steps per Second: 10,433.76163

Timestep Collection Time: 2.33394
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.79539

Cumulative Model Updates: 108,734
Cumulative Timesteps: 907,030,744

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,088.04292
Policy Entropy: 1.78464
Value Function Loss: 0.07499

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 18,922.74919
Overall Steps per Second: 9,611.85377

Timestep Collection Time: 2.64359
Timestep Consumption Time: 2.56082
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 5.20441

Cumulative Model Updates: 108,740
Cumulative Timesteps: 907,080,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 907080768...
Checkpoint 907080768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,226.79421
Policy Entropy: 1.79484
Value Function Loss: 0.06876

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.61296

Collected Steps per Second: 19,637.32598
Overall Steps per Second: 10,125.38896

Timestep Collection Time: 2.54658
Timestep Consumption Time: 2.39229
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.93887

Cumulative Model Updates: 108,746
Cumulative Timesteps: 907,130,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,947.93156
Policy Entropy: 1.78084
Value Function Loss: 0.06215

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.57576
Value Function Update Magnitude: 0.56158

Collected Steps per Second: 20,808.73591
Overall Steps per Second: 10,324.49501

Timestep Collection Time: 2.40303
Timestep Consumption Time: 2.44021
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.84324

Cumulative Model Updates: 108,752
Cumulative Timesteps: 907,180,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 907180780...
Checkpoint 907180780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,439.32871
Policy Entropy: 1.77500
Value Function Loss: 0.06951

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14557
Policy Update Magnitude: 0.57940
Value Function Update Magnitude: 0.56320

Collected Steps per Second: 20,538.28156
Overall Steps per Second: 10,360.44576

Timestep Collection Time: 2.43477
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.82663

Cumulative Model Updates: 108,758
Cumulative Timesteps: 907,230,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,431.64027
Policy Entropy: 1.78398
Value Function Loss: 0.06823

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.58493
Value Function Update Magnitude: 0.60482

Collected Steps per Second: 20,922.43233
Overall Steps per Second: 10,418.91238

Timestep Collection Time: 2.39093
Timestep Consumption Time: 2.41034
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.80127

Cumulative Model Updates: 108,764
Cumulative Timesteps: 907,280,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 907280810...
Checkpoint 907280810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,731.23261
Policy Entropy: 1.79575
Value Function Loss: 0.07543

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.58955
Value Function Update Magnitude: 0.60059

Collected Steps per Second: 20,081.75645
Overall Steps per Second: 9,980.02498

Timestep Collection Time: 2.49052
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 5.01141

Cumulative Model Updates: 108,770
Cumulative Timesteps: 907,330,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,089.23497
Policy Entropy: 1.79363
Value Function Loss: 0.06480

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.54890

Collected Steps per Second: 21,503.13027
Overall Steps per Second: 10,341.64534

Timestep Collection Time: 2.32664
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.83772

Cumulative Model Updates: 108,776
Cumulative Timesteps: 907,380,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 907380854...
Checkpoint 907380854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,056.03358
Policy Entropy: 1.78739
Value Function Loss: 0.06747

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.52252

Collected Steps per Second: 20,955.36288
Overall Steps per Second: 10,242.03689

Timestep Collection Time: 2.38612
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.88204

Cumulative Model Updates: 108,782
Cumulative Timesteps: 907,430,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,088.51110
Policy Entropy: 1.77877
Value Function Loss: 0.06085

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.52671
Value Function Update Magnitude: 0.59216

Collected Steps per Second: 21,791.06806
Overall Steps per Second: 10,469.98597

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.48153
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.77651

Cumulative Model Updates: 108,788
Cumulative Timesteps: 907,480,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 907480866...
Checkpoint 907480866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,817.91786
Policy Entropy: 1.77613
Value Function Loss: 0.06595

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14421
Policy Update Magnitude: 0.53351
Value Function Update Magnitude: 0.70269

Collected Steps per Second: 20,915.69330
Overall Steps per Second: 10,197.80912

Timestep Collection Time: 2.39189
Timestep Consumption Time: 2.51387
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.90576

Cumulative Model Updates: 108,794
Cumulative Timesteps: 907,530,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,989.97060
Policy Entropy: 1.76671
Value Function Loss: 0.06279

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.49050
Value Function Update Magnitude: 0.68606

Collected Steps per Second: 21,922.38622
Overall Steps per Second: 10,480.00992

Timestep Collection Time: 2.28251
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.77461

Cumulative Model Updates: 108,800
Cumulative Timesteps: 907,580,932

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 907580932...
Checkpoint 907580932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,141.60874
Policy Entropy: 1.75909
Value Function Loss: 0.06864

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15961
Policy Update Magnitude: 0.49056
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 20,580.20392
Overall Steps per Second: 10,053.94412

Timestep Collection Time: 2.43039
Timestep Consumption Time: 2.54457
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.97496

Cumulative Model Updates: 108,806
Cumulative Timesteps: 907,630,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,019.49880
Policy Entropy: 1.76962
Value Function Loss: 0.07328

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15524
Policy Update Magnitude: 0.51985
Value Function Update Magnitude: 0.49775

Collected Steps per Second: 20,264.85888
Overall Steps per Second: 10,090.66100

Timestep Collection Time: 2.46802
Timestep Consumption Time: 2.48845
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.95646

Cumulative Model Updates: 108,812
Cumulative Timesteps: 907,680,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 907680964...
Checkpoint 907680964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,501.90635
Policy Entropy: 1.77408
Value Function Loss: 0.07709

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.56729
Value Function Update Magnitude: 0.59151

Collected Steps per Second: 21,106.87347
Overall Steps per Second: 10,344.23197

Timestep Collection Time: 2.37032
Timestep Consumption Time: 2.46619
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.83651

Cumulative Model Updates: 108,818
Cumulative Timesteps: 907,730,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.29590
Policy Entropy: 1.78177
Value Function Loss: 0.08003

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.14867
Policy Update Magnitude: 0.59237
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 21,814.89458
Overall Steps per Second: 10,416.08393

Timestep Collection Time: 2.29339
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.80315

Cumulative Model Updates: 108,824
Cumulative Timesteps: 907,781,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 907781024...
Checkpoint 907781024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,033.14284
Policy Entropy: 1.78150
Value Function Loss: 0.07578

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.14948
Policy Update Magnitude: 0.58328
Value Function Update Magnitude: 0.70492

Collected Steps per Second: 21,321.91527
Overall Steps per Second: 10,238.77315

Timestep Collection Time: 2.34585
Timestep Consumption Time: 2.53931
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.88516

Cumulative Model Updates: 108,830
Cumulative Timesteps: 907,831,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,969.30504
Policy Entropy: 1.76421
Value Function Loss: 0.07152

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.16731
Policy Update Magnitude: 0.49673
Value Function Update Magnitude: 0.68881

Collected Steps per Second: 21,609.41395
Overall Steps per Second: 10,436.16980

Timestep Collection Time: 2.31436
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.79218

Cumulative Model Updates: 108,836
Cumulative Timesteps: 907,881,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 907881054...
Checkpoint 907881054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,081.10071
Policy Entropy: 1.76766
Value Function Loss: 0.06813

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.47794
Value Function Update Magnitude: 0.67462

Collected Steps per Second: 21,274.58909
Overall Steps per Second: 10,211.42155

Timestep Collection Time: 2.35069
Timestep Consumption Time: 2.54677
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.89746

Cumulative Model Updates: 108,842
Cumulative Timesteps: 907,931,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,924.77575
Policy Entropy: 1.75471
Value Function Loss: 0.06679

Mean KL Divergence: 0.01651
SB3 Clip Fraction: 0.15769
Policy Update Magnitude: 0.52604
Value Function Update Magnitude: 0.67430

Collected Steps per Second: 21,606.91833
Overall Steps per Second: 10,449.71003

Timestep Collection Time: 2.31491
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.78654

Cumulative Model Updates: 108,848
Cumulative Timesteps: 907,981,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 907981082...
Checkpoint 907981082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,433.96829
Policy Entropy: 1.74720
Value Function Loss: 0.07068

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16809
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 21,376.65230
Overall Steps per Second: 10,209.85953

Timestep Collection Time: 2.33919
Timestep Consumption Time: 2.55843
PPO Batch Consumption Time: 0.29828
Total Iteration Time: 4.89762

Cumulative Model Updates: 108,854
Cumulative Timesteps: 908,031,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,798.95851
Policy Entropy: 1.73951
Value Function Loss: 0.07238

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.17366
Policy Update Magnitude: 0.52796
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 21,395.88155
Overall Steps per Second: 10,354.56092

Timestep Collection Time: 2.33821
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.83149

Cumulative Model Updates: 108,860
Cumulative Timesteps: 908,081,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 908081114...
Checkpoint 908081114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,900.49855
Policy Entropy: 1.74176
Value Function Loss: 0.06679

Mean KL Divergence: 0.01766
SB3 Clip Fraction: 0.16690
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.69095

Collected Steps per Second: 21,382.23052
Overall Steps per Second: 10,263.45677

Timestep Collection Time: 2.33923
Timestep Consumption Time: 2.53417
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.87341

Cumulative Model Updates: 108,866
Cumulative Timesteps: 908,131,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,469.84178
Policy Entropy: 1.75157
Value Function Loss: 0.06637

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.57004
Value Function Update Magnitude: 0.67667

Collected Steps per Second: 21,614.24053
Overall Steps per Second: 10,441.01882

Timestep Collection Time: 2.31329
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.78880

Cumulative Model Updates: 108,872
Cumulative Timesteps: 908,181,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 908181132...
Checkpoint 908181132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,541.27707
Policy Entropy: 1.73880
Value Function Loss: 0.07073

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.70931

Collected Steps per Second: 21,457.24078
Overall Steps per Second: 10,258.85582

Timestep Collection Time: 2.33096
Timestep Consumption Time: 2.54444
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.87540

Cumulative Model Updates: 108,878
Cumulative Timesteps: 908,231,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,566.81351
Policy Entropy: 1.73951
Value Function Loss: 0.07488

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.58929
Value Function Update Magnitude: 0.67177

Collected Steps per Second: 21,411.46932
Overall Steps per Second: 10,350.73644

Timestep Collection Time: 2.33697
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.83425

Cumulative Model Updates: 108,884
Cumulative Timesteps: 908,281,186

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 908281186...
Checkpoint 908281186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,012.80745
Policy Entropy: 1.74895
Value Function Loss: 0.07599

Mean KL Divergence: 0.02031
SB3 Clip Fraction: 0.17715
Policy Update Magnitude: 0.54717
Value Function Update Magnitude: 0.50421

Collected Steps per Second: 21,064.16165
Overall Steps per Second: 10,238.57249

Timestep Collection Time: 2.37493
Timestep Consumption Time: 2.51110
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.88603

Cumulative Model Updates: 108,890
Cumulative Timesteps: 908,331,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,964.97334
Policy Entropy: 1.75188
Value Function Loss: 0.07531

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.17318
Policy Update Magnitude: 0.51241
Value Function Update Magnitude: 0.57552

Collected Steps per Second: 20,997.56745
Overall Steps per Second: 10,125.47407

Timestep Collection Time: 2.38256
Timestep Consumption Time: 2.55824
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.94081

Cumulative Model Updates: 108,896
Cumulative Timesteps: 908,381,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 908381240...
Checkpoint 908381240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,638.90892
Policy Entropy: 1.76324
Value Function Loss: 0.07501

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.16700
Policy Update Magnitude: 0.49591
Value Function Update Magnitude: 0.50567

Collected Steps per Second: 21,656.25133
Overall Steps per Second: 10,354.83374

Timestep Collection Time: 2.31028
Timestep Consumption Time: 2.52147
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.83175

Cumulative Model Updates: 108,902
Cumulative Timesteps: 908,431,272

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,297.66253
Policy Entropy: 1.75255
Value Function Loss: 0.07619

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.15803
Policy Update Magnitude: 0.50736
Value Function Update Magnitude: 0.40680

Collected Steps per Second: 21,432.63235
Overall Steps per Second: 10,256.17032

Timestep Collection Time: 2.33392
Timestep Consumption Time: 2.54334
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.87726

Cumulative Model Updates: 108,908
Cumulative Timesteps: 908,481,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 908481294...
Checkpoint 908481294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,436.55634
Policy Entropy: 1.73866
Value Function Loss: 0.07553

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15987
Policy Update Magnitude: 0.51830
Value Function Update Magnitude: 0.34022

Collected Steps per Second: 21,285.89297
Overall Steps per Second: 10,169.77928

Timestep Collection Time: 2.34982
Timestep Consumption Time: 2.56848
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.91830

Cumulative Model Updates: 108,914
Cumulative Timesteps: 908,531,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,820.07668
Policy Entropy: 1.74343
Value Function Loss: 0.07431

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.14677
Policy Update Magnitude: 0.55437
Value Function Update Magnitude: 0.32151

Collected Steps per Second: 20,834.07902
Overall Steps per Second: 10,416.62847

Timestep Collection Time: 2.39991
Timestep Consumption Time: 2.40010
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.80002

Cumulative Model Updates: 108,920
Cumulative Timesteps: 908,581,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 908581312...
Checkpoint 908581312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,612.34139
Policy Entropy: 1.74969
Value Function Loss: 0.08279

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.31518

Collected Steps per Second: 20,748.84052
Overall Steps per Second: 10,299.38921

Timestep Collection Time: 2.40987
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.85485

Cumulative Model Updates: 108,926
Cumulative Timesteps: 908,631,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,701.97113
Policy Entropy: 1.76429
Value Function Loss: 0.08318

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.15794
Policy Update Magnitude: 0.59150
Value Function Update Magnitude: 0.42879

Collected Steps per Second: 20,628.12207
Overall Steps per Second: 10,351.66455

Timestep Collection Time: 2.42455
Timestep Consumption Time: 2.40694
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.83149

Cumulative Model Updates: 108,932
Cumulative Timesteps: 908,681,328

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 908681328...
Checkpoint 908681328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,762.40453
Policy Entropy: 1.77912
Value Function Loss: 0.08202

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.15740
Policy Update Magnitude: 0.58225
Value Function Update Magnitude: 0.52186

Collected Steps per Second: 20,752.64818
Overall Steps per Second: 10,301.39446

Timestep Collection Time: 2.41029
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.85565

Cumulative Model Updates: 108,938
Cumulative Timesteps: 908,731,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,872.06999
Policy Entropy: 1.76547
Value Function Loss: 0.07289

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14805
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.52612

Collected Steps per Second: 20,530.03703
Overall Steps per Second: 10,221.30066

Timestep Collection Time: 2.43594
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.89272

Cumulative Model Updates: 108,944
Cumulative Timesteps: 908,781,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 908781358...
Checkpoint 908781358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,542.66337
Policy Entropy: 1.77280
Value Function Loss: 0.07305

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.48338

Collected Steps per Second: 20,979.98386
Overall Steps per Second: 10,510.55728

Timestep Collection Time: 2.38504
Timestep Consumption Time: 2.37570
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.76074

Cumulative Model Updates: 108,950
Cumulative Timesteps: 908,831,396

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,382.19533
Policy Entropy: 1.77275
Value Function Loss: 0.08044

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.42004

Collected Steps per Second: 20,770.26780
Overall Steps per Second: 10,261.47112

Timestep Collection Time: 2.40738
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.87279

Cumulative Model Updates: 108,956
Cumulative Timesteps: 908,881,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 908881398...
Checkpoint 908881398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,998.02746
Policy Entropy: 1.77203
Value Function Loss: 0.07917

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.47086

Collected Steps per Second: 21,336.05377
Overall Steps per Second: 10,345.67854

Timestep Collection Time: 2.34354
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.83313

Cumulative Model Updates: 108,962
Cumulative Timesteps: 908,931,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,601.90685
Policy Entropy: 1.78111
Value Function Loss: 0.07688

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.54156

Collected Steps per Second: 21,100.15437
Overall Steps per Second: 10,239.96623

Timestep Collection Time: 2.37107
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.88576

Cumulative Model Updates: 108,968
Cumulative Timesteps: 908,981,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 908981430...
Checkpoint 908981430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,400.08248
Policy Entropy: 1.77058
Value Function Loss: 0.06777

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.65215

Collected Steps per Second: 21,507.81979
Overall Steps per Second: 10,394.09287

Timestep Collection Time: 2.32529
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.81158

Cumulative Model Updates: 108,974
Cumulative Timesteps: 909,031,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,687.42833
Policy Entropy: 1.77237
Value Function Loss: 0.06468

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.56610
Value Function Update Magnitude: 0.69638

Collected Steps per Second: 21,107.55168
Overall Steps per Second: 10,158.20342

Timestep Collection Time: 2.36892
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.92233

Cumulative Model Updates: 108,980
Cumulative Timesteps: 909,081,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 909081444...
Checkpoint 909081444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,112.77926
Policy Entropy: 1.75097
Value Function Loss: 0.06345

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.57120
Value Function Update Magnitude: 0.67679

Collected Steps per Second: 21,473.07289
Overall Steps per Second: 10,398.07482

Timestep Collection Time: 2.32906
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.80974

Cumulative Model Updates: 108,986
Cumulative Timesteps: 909,131,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,534.05354
Policy Entropy: 1.75829
Value Function Loss: 0.06646

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.57108
Value Function Update Magnitude: 0.61611

Collected Steps per Second: 21,400.50641
Overall Steps per Second: 10,236.51625

Timestep Collection Time: 2.33705
Timestep Consumption Time: 2.54879
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.88584

Cumulative Model Updates: 108,992
Cumulative Timesteps: 909,181,470

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 909181470...
Checkpoint 909181470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,630.46222
Policy Entropy: 1.76283
Value Function Loss: 0.06912

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.57741
Value Function Update Magnitude: 0.68118

Collected Steps per Second: 21,553.55453
Overall Steps per Second: 10,457.77324

Timestep Collection Time: 2.32073
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.78305

Cumulative Model Updates: 108,998
Cumulative Timesteps: 909,231,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,979.70870
Policy Entropy: 1.75992
Value Function Loss: 0.06536

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.57873
Value Function Update Magnitude: 0.65436

Collected Steps per Second: 21,384.92689
Overall Steps per Second: 10,243.91041

Timestep Collection Time: 2.33912
Timestep Consumption Time: 2.54397
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.88310

Cumulative Model Updates: 109,004
Cumulative Timesteps: 909,281,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 909281512...
Checkpoint 909281512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,827.64249
Policy Entropy: 1.74932
Value Function Loss: 0.06762

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14871
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 21,140.47490
Overall Steps per Second: 10,221.19180

Timestep Collection Time: 2.36598
Timestep Consumption Time: 2.52758
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.89356

Cumulative Model Updates: 109,010
Cumulative Timesteps: 909,331,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,532.43909
Policy Entropy: 1.75516
Value Function Loss: 0.07419

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.47308

Collected Steps per Second: 21,308.04739
Overall Steps per Second: 10,376.14641

Timestep Collection Time: 2.34700
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.81971

Cumulative Model Updates: 109,016
Cumulative Timesteps: 909,381,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 909381540...
Checkpoint 909381540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,160.73936
Policy Entropy: 1.76913
Value Function Loss: 0.07850

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.14083
Policy Update Magnitude: 0.57544
Value Function Update Magnitude: 0.45517

Collected Steps per Second: 21,158.58210
Overall Steps per Second: 10,180.10652

Timestep Collection Time: 2.36424
Timestep Consumption Time: 2.54966
PPO Batch Consumption Time: 0.29870
Total Iteration Time: 4.91390

Cumulative Model Updates: 109,022
Cumulative Timesteps: 909,431,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,568.56551
Policy Entropy: 1.77236
Value Function Loss: 0.07686

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.44643

Collected Steps per Second: 21,465.40390
Overall Steps per Second: 10,357.60984

Timestep Collection Time: 2.33026
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.82930

Cumulative Model Updates: 109,028
Cumulative Timesteps: 909,481,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 909481584...
Checkpoint 909481584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,801.89439
Policy Entropy: 1.76306
Value Function Loss: 0.07757

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.41467

Collected Steps per Second: 21,234.24923
Overall Steps per Second: 10,257.51891

Timestep Collection Time: 2.35469
Timestep Consumption Time: 2.51979
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.87447

Cumulative Model Updates: 109,034
Cumulative Timesteps: 909,531,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,688.06542
Policy Entropy: 1.76057
Value Function Loss: 0.08245

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.60300
Value Function Update Magnitude: 0.40978

Collected Steps per Second: 21,599.39891
Overall Steps per Second: 10,334.27390

Timestep Collection Time: 2.31553
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.83962

Cumulative Model Updates: 109,040
Cumulative Timesteps: 909,581,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 909581598...
Checkpoint 909581598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,872.05305
Policy Entropy: 1.76426
Value Function Loss: 0.08578

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.60497
Value Function Update Magnitude: 0.37427

Collected Steps per Second: 21,399.23941
Overall Steps per Second: 10,261.34073

Timestep Collection Time: 2.33784
Timestep Consumption Time: 2.53755
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.87539

Cumulative Model Updates: 109,046
Cumulative Timesteps: 909,631,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,832.97914
Policy Entropy: 1.76906
Value Function Loss: 0.08502

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.60499
Value Function Update Magnitude: 0.33065

Collected Steps per Second: 21,275.66418
Overall Steps per Second: 10,202.29505

Timestep Collection Time: 2.35020
Timestep Consumption Time: 2.55086
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.90105

Cumulative Model Updates: 109,052
Cumulative Timesteps: 909,681,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 909681628...
Checkpoint 909681628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,900.84124
Policy Entropy: 1.76794
Value Function Loss: 0.08563

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14203
Policy Update Magnitude: 0.58915
Value Function Update Magnitude: 0.32122

Collected Steps per Second: 21,176.27548
Overall Steps per Second: 10,208.88274

Timestep Collection Time: 2.36246
Timestep Consumption Time: 2.53798
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.90044

Cumulative Model Updates: 109,058
Cumulative Timesteps: 909,731,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,803.67333
Policy Entropy: 1.77949
Value Function Loss: 0.08648

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14464
Policy Update Magnitude: 0.58046
Value Function Update Magnitude: 0.31551

Collected Steps per Second: 21,698.62979
Overall Steps per Second: 10,396.46128

Timestep Collection Time: 2.30614
Timestep Consumption Time: 2.50704
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.81318

Cumulative Model Updates: 109,064
Cumulative Timesteps: 909,781,696

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 909781696...
Checkpoint 909781696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,597.63228
Policy Entropy: 1.77024
Value Function Loss: 0.08052

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.17166
Policy Update Magnitude: 0.53463
Value Function Update Magnitude: 0.27639

Collected Steps per Second: 21,368.24346
Overall Steps per Second: 10,239.82998

Timestep Collection Time: 2.34067
Timestep Consumption Time: 2.54379
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.88446

Cumulative Model Updates: 109,070
Cumulative Timesteps: 909,831,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,903.15360
Policy Entropy: 1.76791
Value Function Loss: 0.07548

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17430
Policy Update Magnitude: 0.46961
Value Function Update Magnitude: 0.27355

Collected Steps per Second: 21,325.91527
Overall Steps per Second: 10,323.00705

Timestep Collection Time: 2.34541
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.84529

Cumulative Model Updates: 109,076
Cumulative Timesteps: 909,881,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 909881730...
Checkpoint 909881730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,980.45671
Policy Entropy: 1.77041
Value Function Loss: 0.07764

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15921
Policy Update Magnitude: 0.49733
Value Function Update Magnitude: 0.25854

Collected Steps per Second: 21,235.13903
Overall Steps per Second: 10,227.87896

Timestep Collection Time: 2.35478
Timestep Consumption Time: 2.53421
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.88899

Cumulative Model Updates: 109,082
Cumulative Timesteps: 909,931,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,778.29373
Policy Entropy: 1.77043
Value Function Loss: 0.08570

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.14912
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.29122

Collected Steps per Second: 21,619.78519
Overall Steps per Second: 10,411.48101

Timestep Collection Time: 2.31353
Timestep Consumption Time: 2.49059
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.80412

Cumulative Model Updates: 109,088
Cumulative Timesteps: 909,981,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 909981752...
Checkpoint 909981752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,175.90965
Policy Entropy: 1.78126
Value Function Loss: 0.08894

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.16285
Policy Update Magnitude: 0.59305
Value Function Update Magnitude: 0.31943

Collected Steps per Second: 20,894.70701
Overall Steps per Second: 10,251.88567

Timestep Collection Time: 2.39391
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.87910

Cumulative Model Updates: 109,094
Cumulative Timesteps: 910,031,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,132.64218
Policy Entropy: 1.77548
Value Function Loss: 0.08370

Mean KL Divergence: 0.02187
SB3 Clip Fraction: 0.18606
Policy Update Magnitude: 0.51794
Value Function Update Magnitude: 0.37277

Collected Steps per Second: 21,259.47562
Overall Steps per Second: 10,223.15194

Timestep Collection Time: 2.35321
Timestep Consumption Time: 2.54039
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.89360

Cumulative Model Updates: 109,100
Cumulative Timesteps: 910,081,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 910081800...
Checkpoint 910081800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,560.99177
Policy Entropy: 1.75902
Value Function Loss: 0.08137

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.18910
Policy Update Magnitude: 0.46528
Value Function Update Magnitude: 0.45534

Collected Steps per Second: 21,395.97921
Overall Steps per Second: 10,397.98235

Timestep Collection Time: 2.33792
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.81074

Cumulative Model Updates: 109,106
Cumulative Timesteps: 910,131,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,464.97094
Policy Entropy: 1.75630
Value Function Loss: 0.07730

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.17365
Policy Update Magnitude: 0.50517
Value Function Update Magnitude: 0.49288

Collected Steps per Second: 21,495.32686
Overall Steps per Second: 10,306.31943

Timestep Collection Time: 2.32655
Timestep Consumption Time: 2.52581
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.85236

Cumulative Model Updates: 109,112
Cumulative Timesteps: 910,181,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 910181832...
Checkpoint 910181832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,507.36641
Policy Entropy: 1.76422
Value Function Loss: 0.07643

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.16751
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.50692

Collected Steps per Second: 21,362.69213
Overall Steps per Second: 10,212.77256

Timestep Collection Time: 2.34062
Timestep Consumption Time: 2.55540
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.89603

Cumulative Model Updates: 109,118
Cumulative Timesteps: 910,231,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,656.13690
Policy Entropy: 1.78193
Value Function Loss: 0.07208

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.17342
Policy Update Magnitude: 0.49538
Value Function Update Magnitude: 0.51458

Collected Steps per Second: 21,450.34367
Overall Steps per Second: 10,265.42654

Timestep Collection Time: 2.33124
Timestep Consumption Time: 2.54006
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.87130

Cumulative Model Updates: 109,124
Cumulative Timesteps: 910,281,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910281840...
Checkpoint 910281840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,483.90775
Policy Entropy: 1.77644
Value Function Loss: 0.07529

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.15941
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.40833

Collected Steps per Second: 21,281.48941
Overall Steps per Second: 10,198.98786

Timestep Collection Time: 2.35172
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.90715

Cumulative Model Updates: 109,130
Cumulative Timesteps: 910,331,888

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,515.87632
Policy Entropy: 1.76989
Value Function Loss: 0.07226

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.15187
Policy Update Magnitude: 0.58846
Value Function Update Magnitude: 0.39711

Collected Steps per Second: 21,702.81692
Overall Steps per Second: 10,435.29572

Timestep Collection Time: 2.30505
Timestep Consumption Time: 2.48888
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.79392

Cumulative Model Updates: 109,136
Cumulative Timesteps: 910,381,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 910381914...
Checkpoint 910381914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.10052
Policy Entropy: 1.76016
Value Function Loss: 0.07574

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14611
Policy Update Magnitude: 0.58267
Value Function Update Magnitude: 0.43521

Collected Steps per Second: 21,034.35012
Overall Steps per Second: 10,229.20137

Timestep Collection Time: 2.37744
Timestep Consumption Time: 2.51130
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.88875

Cumulative Model Updates: 109,142
Cumulative Timesteps: 910,431,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,094.33084
Policy Entropy: 1.74618
Value Function Loss: 0.07396

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.58691
Value Function Update Magnitude: 0.53275

Collected Steps per Second: 21,362.26360
Overall Steps per Second: 10,379.43987

Timestep Collection Time: 2.34086
Timestep Consumption Time: 2.47694
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.81779

Cumulative Model Updates: 109,148
Cumulative Timesteps: 910,481,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910481928...
Checkpoint 910481928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,401.95159
Policy Entropy: 1.74953
Value Function Loss: 0.07000

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.58796
Value Function Update Magnitude: 0.64255

Collected Steps per Second: 21,159.65536
Overall Steps per Second: 10,344.49381

Timestep Collection Time: 2.36422
Timestep Consumption Time: 2.47179
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.83600

Cumulative Model Updates: 109,154
Cumulative Timesteps: 910,531,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,969.08273
Policy Entropy: 1.74353
Value Function Loss: 0.07465

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 21,559.48958
Overall Steps per Second: 10,400.25488

Timestep Collection Time: 2.31963
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.80854

Cumulative Model Updates: 109,160
Cumulative Timesteps: 910,581,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 910581964...
Checkpoint 910581964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,040.74451
Policy Entropy: 1.74862
Value Function Loss: 0.07350

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.51183
Value Function Update Magnitude: 0.55434

Collected Steps per Second: 21,013.45277
Overall Steps per Second: 10,196.37463

Timestep Collection Time: 2.37943
Timestep Consumption Time: 2.52428
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.90370

Cumulative Model Updates: 109,166
Cumulative Timesteps: 910,631,964

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,052.58960
Policy Entropy: 1.75021
Value Function Loss: 0.07853

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.16378
Policy Update Magnitude: 0.49625
Value Function Update Magnitude: 0.58321

Collected Steps per Second: 21,340.79628
Overall Steps per Second: 10,288.92153

Timestep Collection Time: 2.34302
Timestep Consumption Time: 2.51677
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.85979

Cumulative Model Updates: 109,172
Cumulative Timesteps: 910,681,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 910681966...
Checkpoint 910681966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,567.50894
Policy Entropy: 1.75367
Value Function Loss: 0.07784

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.15648
Policy Update Magnitude: 0.52135
Value Function Update Magnitude: 0.51610

Collected Steps per Second: 18,869.41633
Overall Steps per Second: 9,616.72621

Timestep Collection Time: 2.65223
Timestep Consumption Time: 2.55183
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 5.20406

Cumulative Model Updates: 109,178
Cumulative Timesteps: 910,732,012

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,853.00953
Policy Entropy: 1.75265
Value Function Loss: 0.08045

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16160
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.43908

Collected Steps per Second: 20,821.69113
Overall Steps per Second: 10,111.60474

Timestep Collection Time: 2.40182
Timestep Consumption Time: 2.54398
PPO Batch Consumption Time: 0.29860
Total Iteration Time: 4.94580

Cumulative Model Updates: 109,184
Cumulative Timesteps: 910,782,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 910782022...
Checkpoint 910782022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,928.73796
Policy Entropy: 1.77109
Value Function Loss: 0.07344

Mean KL Divergence: 0.01814
SB3 Clip Fraction: 0.16770
Policy Update Magnitude: 0.59127
Value Function Update Magnitude: 0.54105

Collected Steps per Second: 17,411.46654
Overall Steps per Second: 9,375.73532

Timestep Collection Time: 2.87339
Timestep Consumption Time: 2.46272
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 5.33611

Cumulative Model Updates: 109,190
Cumulative Timesteps: 910,832,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,573.05506
Policy Entropy: 1.76894
Value Function Loss: 0.07034

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.16144
Policy Update Magnitude: 0.57863
Value Function Update Magnitude: 0.65668

Collected Steps per Second: 19,313.16798
Overall Steps per Second: 9,991.73409

Timestep Collection Time: 2.58943
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 5.00514

Cumulative Model Updates: 109,196
Cumulative Timesteps: 910,882,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 910882062...
Checkpoint 910882062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,194.92044
Policy Entropy: 1.78039
Value Function Loss: 0.07238

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.14888
Policy Update Magnitude: 0.58814
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 20,081.14056
Overall Steps per Second: 10,208.47971

Timestep Collection Time: 2.49020
Timestep Consumption Time: 2.40828
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.89848

Cumulative Model Updates: 109,202
Cumulative Timesteps: 910,932,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,339.12793
Policy Entropy: 1.76863
Value Function Loss: 0.07303

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14964
Policy Update Magnitude: 0.59311
Value Function Update Magnitude: 0.55381

Collected Steps per Second: 20,857.70616
Overall Steps per Second: 10,439.26812

Timestep Collection Time: 2.39902
Timestep Consumption Time: 2.39423
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.79325

Cumulative Model Updates: 109,208
Cumulative Timesteps: 910,982,106

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 910982106...
Checkpoint 910982106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,181.31038
Policy Entropy: 1.76914
Value Function Loss: 0.06872

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14071
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.57283

Collected Steps per Second: 20,634.25484
Overall Steps per Second: 10,166.95551

Timestep Collection Time: 2.42461
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29866
Total Iteration Time: 4.92084

Cumulative Model Updates: 109,214
Cumulative Timesteps: 911,032,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,957.60286
Policy Entropy: 1.75559
Value Function Loss: 0.06787

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.56274

Collected Steps per Second: 20,631.81968
Overall Steps per Second: 10,146.29437

Timestep Collection Time: 2.42470
Timestep Consumption Time: 2.50577
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.93047

Cumulative Model Updates: 109,220
Cumulative Timesteps: 911,082,162

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 911082162...
Checkpoint 911082162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,128.73019
Policy Entropy: 1.74721
Value Function Loss: 0.06875

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.51816
Value Function Update Magnitude: 0.41467

Collected Steps per Second: 18,316.79038
Overall Steps per Second: 9,201.05311

Timestep Collection Time: 2.73061
Timestep Consumption Time: 2.70529
PPO Batch Consumption Time: 0.30777
Total Iteration Time: 5.43590

Cumulative Model Updates: 109,226
Cumulative Timesteps: 911,132,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,213.84024
Policy Entropy: 1.74908
Value Function Loss: 0.07434

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15855
Policy Update Magnitude: 0.52515
Value Function Update Magnitude: 0.39337

Collected Steps per Second: 21,049.99454
Overall Steps per Second: 10,327.72478

Timestep Collection Time: 2.37587
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.84250

Cumulative Model Updates: 109,232
Cumulative Timesteps: 911,182,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911182190...
Checkpoint 911182190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,615.33761
Policy Entropy: 1.75647
Value Function Loss: 0.07705

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.15687
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.44633

Collected Steps per Second: 21,190.15361
Overall Steps per Second: 10,592.54177

Timestep Collection Time: 2.36062
Timestep Consumption Time: 2.36175
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.72238

Cumulative Model Updates: 109,238
Cumulative Timesteps: 911,232,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,091.60779
Policy Entropy: 1.77107
Value Function Loss: 0.07722

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.59613
Value Function Update Magnitude: 0.55096

Collected Steps per Second: 21,657.45562
Overall Steps per Second: 10,439.20304

Timestep Collection Time: 2.30969
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.79175

Cumulative Model Updates: 109,244
Cumulative Timesteps: 911,282,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 911282234...
Checkpoint 911282234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,123.47336
Policy Entropy: 1.75870
Value Function Loss: 0.07716

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.59484
Value Function Update Magnitude: 0.55808

Collected Steps per Second: 20,914.62075
Overall Steps per Second: 10,206.33734

Timestep Collection Time: 2.39144
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.90048

Cumulative Model Updates: 109,250
Cumulative Timesteps: 911,332,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,020.53441
Policy Entropy: 1.75049
Value Function Loss: 0.07120

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.15092
Policy Update Magnitude: 0.58312
Value Function Update Magnitude: 0.56955

Collected Steps per Second: 21,635.30525
Overall Steps per Second: 10,468.27887

Timestep Collection Time: 2.31233
Timestep Consumption Time: 2.46668
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.77901

Cumulative Model Updates: 109,256
Cumulative Timesteps: 911,382,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 911382278...
Checkpoint 911382278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,550.68817
Policy Entropy: 1.73951
Value Function Loss: 0.06559

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.16297
Policy Update Magnitude: 0.52179
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 21,256.31068
Overall Steps per Second: 10,271.68614

Timestep Collection Time: 2.35337
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.87009

Cumulative Model Updates: 109,262
Cumulative Timesteps: 911,432,302

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,347.22142
Policy Entropy: 1.73898
Value Function Loss: 0.06354

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14550
Policy Update Magnitude: 0.51303
Value Function Update Magnitude: 0.46632

Collected Steps per Second: 21,484.58767
Overall Steps per Second: 10,405.11594

Timestep Collection Time: 2.32809
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.80706

Cumulative Model Updates: 109,268
Cumulative Timesteps: 911,482,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911482320...
Checkpoint 911482320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,259.60322
Policy Entropy: 1.74148
Value Function Loss: 0.06785

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.37283

Collected Steps per Second: 21,228.30085
Overall Steps per Second: 10,237.02327

Timestep Collection Time: 2.35667
Timestep Consumption Time: 2.53030
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.88697

Cumulative Model Updates: 109,274
Cumulative Timesteps: 911,532,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,018.62784
Policy Entropy: 1.72854
Value Function Loss: 0.07159

Mean KL Divergence: 0.02057
SB3 Clip Fraction: 0.17905
Policy Update Magnitude: 0.51741
Value Function Update Magnitude: 0.38361

Collected Steps per Second: 21,463.21914
Overall Steps per Second: 10,413.79946

Timestep Collection Time: 2.33050
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.80324

Cumulative Model Updates: 109,280
Cumulative Timesteps: 911,582,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 911582368...
Checkpoint 911582368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,467.27312
Policy Entropy: 1.72021
Value Function Loss: 0.07785

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.17038
Policy Update Magnitude: 0.51955
Value Function Update Magnitude: 0.43754

Collected Steps per Second: 20,997.63320
Overall Steps per Second: 10,317.17781

Timestep Collection Time: 2.38170
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.84726

Cumulative Model Updates: 109,286
Cumulative Timesteps: 911,632,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,291.90179
Policy Entropy: 1.70629
Value Function Loss: 0.07122

Mean KL Divergence: 0.02080
SB3 Clip Fraction: 0.17768
Policy Update Magnitude: 0.50933
Value Function Update Magnitude: 0.40739

Collected Steps per Second: 21,723.26839
Overall Steps per Second: 10,382.24661

Timestep Collection Time: 2.30232
Timestep Consumption Time: 2.51494
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.81726

Cumulative Model Updates: 109,292
Cumulative Timesteps: 911,682,392

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 911682392...
Checkpoint 911682392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,450.00254
Policy Entropy: 1.70559
Value Function Loss: 0.07424

Mean KL Divergence: 0.02282
SB3 Clip Fraction: 0.18574
Policy Update Magnitude: 0.50819
Value Function Update Magnitude: 0.39040

Collected Steps per Second: 21,329.34538
Overall Steps per Second: 10,226.81440

Timestep Collection Time: 2.34653
Timestep Consumption Time: 2.54746
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.89400

Cumulative Model Updates: 109,298
Cumulative Timesteps: 911,732,442

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,108.50586
Policy Entropy: 1.72056
Value Function Loss: 0.07086

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.19150
Policy Update Magnitude: 0.51256
Value Function Update Magnitude: 0.36281

Collected Steps per Second: 21,647.58563
Overall Steps per Second: 10,450.83644

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.47547
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.78603

Cumulative Model Updates: 109,304
Cumulative Timesteps: 911,782,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911782460...
Checkpoint 911782460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,880.66580
Policy Entropy: 1.72501
Value Function Loss: 0.07904

Mean KL Divergence: 0.02284
SB3 Clip Fraction: 0.19089
Policy Update Magnitude: 0.50207
Value Function Update Magnitude: 0.41275

Collected Steps per Second: 21,239.61630
Overall Steps per Second: 10,200.54983

Timestep Collection Time: 2.35484
Timestep Consumption Time: 2.54842
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.90327

Cumulative Model Updates: 109,310
Cumulative Timesteps: 911,832,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,954.97073
Policy Entropy: 1.72751
Value Function Loss: 0.07661

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.16972
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.43451

Collected Steps per Second: 20,821.03071
Overall Steps per Second: 10,386.00005

Timestep Collection Time: 2.40142
Timestep Consumption Time: 2.41275
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.81417

Cumulative Model Updates: 109,316
Cumulative Timesteps: 911,882,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 911882476...
Checkpoint 911882476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,202.84609
Policy Entropy: 1.73560
Value Function Loss: 0.08151

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.16555
Policy Update Magnitude: 0.58845
Value Function Update Magnitude: 0.58553

Collected Steps per Second: 20,590.33843
Overall Steps per Second: 10,395.55552

Timestep Collection Time: 2.42900
Timestep Consumption Time: 2.38209
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.81109

Cumulative Model Updates: 109,322
Cumulative Timesteps: 911,932,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,600.81953
Policy Entropy: 1.73741
Value Function Loss: 0.07949

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.15761
Policy Update Magnitude: 0.60660
Value Function Update Magnitude: 0.69132

Collected Steps per Second: 20,597.75906
Overall Steps per Second: 10,154.21140

Timestep Collection Time: 2.42900
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29939
Total Iteration Time: 4.92722

Cumulative Model Updates: 109,328
Cumulative Timesteps: 911,982,522

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 911982522...
Checkpoint 911982522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,873.91849
Policy Entropy: 1.73347
Value Function Loss: 0.07518

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.14808
Policy Update Magnitude: 0.60551
Value Function Update Magnitude: 0.79780

Collected Steps per Second: 18,803.44291
Overall Steps per Second: 9,485.98448

Timestep Collection Time: 2.65909
Timestep Consumption Time: 2.61185
PPO Batch Consumption Time: 0.31169
Total Iteration Time: 5.27093

Cumulative Model Updates: 109,334
Cumulative Timesteps: 912,032,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,682.78090
Policy Entropy: 1.71842
Value Function Loss: 0.06621

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.58844
Value Function Update Magnitude: 0.67728

Collected Steps per Second: 20,588.62657
Overall Steps per Second: 10,200.25620

Timestep Collection Time: 2.43095
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.90674

Cumulative Model Updates: 109,340
Cumulative Timesteps: 912,082,572

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 912082572...
Checkpoint 912082572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,176.20408
Policy Entropy: 1.70248
Value Function Loss: 0.06535

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.53073

Collected Steps per Second: 20,121.36227
Overall Steps per Second: 9,921.95798

Timestep Collection Time: 2.48542
Timestep Consumption Time: 2.55492
PPO Batch Consumption Time: 0.29974
Total Iteration Time: 5.04034

Cumulative Model Updates: 109,346
Cumulative Timesteps: 912,132,582

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,234.11262
Policy Entropy: 1.69767
Value Function Loss: 0.06634

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.58432
Value Function Update Magnitude: 0.59903

Collected Steps per Second: 20,998.28515
Overall Steps per Second: 10,317.59255

Timestep Collection Time: 2.38172
Timestep Consumption Time: 2.46554
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.84725

Cumulative Model Updates: 109,352
Cumulative Timesteps: 912,182,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 912182594...
Checkpoint 912182594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,297.43239
Policy Entropy: 1.70539
Value Function Loss: 0.06797

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.65643

Collected Steps per Second: 20,928.69833
Overall Steps per Second: 10,073.28077

Timestep Collection Time: 2.38935
Timestep Consumption Time: 2.57487
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 4.96422

Cumulative Model Updates: 109,358
Cumulative Timesteps: 912,232,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,100.48044
Policy Entropy: 1.72673
Value Function Loss: 0.07184

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.14818
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.67995

Collected Steps per Second: 21,391.65732
Overall Steps per Second: 10,096.65382

Timestep Collection Time: 2.33745
Timestep Consumption Time: 2.61488
PPO Batch Consumption Time: 0.30578
Total Iteration Time: 4.95233

Cumulative Model Updates: 109,364
Cumulative Timesteps: 912,282,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 912282602...
Checkpoint 912282602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,532.39060
Policy Entropy: 1.72398
Value Function Loss: 0.06756

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.66737

Collected Steps per Second: 21,136.83712
Overall Steps per Second: 10,208.42615

Timestep Collection Time: 2.36639
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.89968

Cumulative Model Updates: 109,370
Cumulative Timesteps: 912,332,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,155.18064
Policy Entropy: 1.72136
Value Function Loss: 0.06722

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.58563
Value Function Update Magnitude: 0.60634

Collected Steps per Second: 21,264.68391
Overall Steps per Second: 10,140.51703

Timestep Collection Time: 2.35310
Timestep Consumption Time: 2.58136
PPO Batch Consumption Time: 0.30313
Total Iteration Time: 4.93446

Cumulative Model Updates: 109,376
Cumulative Timesteps: 912,382,658

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 912382658...
Checkpoint 912382658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,772.36360
Policy Entropy: 1.72148
Value Function Loss: 0.07193

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.60079
Value Function Update Magnitude: 0.75126

Collected Steps per Second: 20,771.11240
Overall Steps per Second: 10,093.42062

Timestep Collection Time: 2.40892
Timestep Consumption Time: 2.54837
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.95729

Cumulative Model Updates: 109,382
Cumulative Timesteps: 912,432,694

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,143.17648
Policy Entropy: 1.71640
Value Function Loss: 0.06856

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.77218

Collected Steps per Second: 20,467.76205
Overall Steps per Second: 10,072.44891

Timestep Collection Time: 2.44287
Timestep Consumption Time: 2.52117
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.96404

Cumulative Model Updates: 109,388
Cumulative Timesteps: 912,482,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 912482694...
Checkpoint 912482694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,253.69500
Policy Entropy: 1.71472
Value Function Loss: 0.06950

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.15960
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.71564

Collected Steps per Second: 20,948.72999
Overall Steps per Second: 10,308.24843

Timestep Collection Time: 2.38888
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.85475

Cumulative Model Updates: 109,394
Cumulative Timesteps: 912,532,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,196.63410
Policy Entropy: 1.69837
Value Function Loss: 0.06520

Mean KL Divergence: 0.02022
SB3 Clip Fraction: 0.18156
Policy Update Magnitude: 0.52040
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 18,572.51307
Overall Steps per Second: 9,551.17770

Timestep Collection Time: 2.69355
Timestep Consumption Time: 2.54413
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 5.23768

Cumulative Model Updates: 109,400
Cumulative Timesteps: 912,582,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 912582764...
Checkpoint 912582764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,870.13482
Policy Entropy: 1.70243
Value Function Loss: 0.06358

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.16274
Policy Update Magnitude: 0.52667
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 20,934.55516
Overall Steps per Second: 10,309.94350

Timestep Collection Time: 2.38992
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.85279

Cumulative Model Updates: 109,406
Cumulative Timesteps: 912,632,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,824.95981
Policy Entropy: 1.70557
Value Function Loss: 0.06574

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.56879
Value Function Update Magnitude: 0.50752

Collected Steps per Second: 21,557.57208
Overall Steps per Second: 10,403.18087

Timestep Collection Time: 2.32030
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.80814

Cumulative Model Updates: 109,412
Cumulative Timesteps: 912,682,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 912682816...
Checkpoint 912682816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,521.28774
Policy Entropy: 1.70430
Value Function Loss: 0.07135

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15116
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.57599

Collected Steps per Second: 21,273.79359
Overall Steps per Second: 10,232.56744

Timestep Collection Time: 2.35153
Timestep Consumption Time: 2.53737
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.88890

Cumulative Model Updates: 109,418
Cumulative Timesteps: 912,732,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,901.58860
Policy Entropy: 1.70799
Value Function Loss: 0.07450

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.60850
Value Function Update Magnitude: 0.71884

Collected Steps per Second: 21,668.80360
Overall Steps per Second: 10,480.74556

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.46516
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.77447

Cumulative Model Updates: 109,424
Cumulative Timesteps: 912,782,882

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 912782882...
Checkpoint 912782882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,755.58031
Policy Entropy: 1.69334
Value Function Loss: 0.06810

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.59474
Value Function Update Magnitude: 0.69320

Collected Steps per Second: 20,199.17622
Overall Steps per Second: 10,186.68645

Timestep Collection Time: 2.47555
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.90876

Cumulative Model Updates: 109,430
Cumulative Timesteps: 912,832,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,323.76198
Policy Entropy: 1.69211
Value Function Loss: 0.06812

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.58167
Value Function Update Magnitude: 0.69312

Collected Steps per Second: 20,898.14900
Overall Steps per Second: 10,406.46024

Timestep Collection Time: 2.39284
Timestep Consumption Time: 2.41244
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.80528

Cumulative Model Updates: 109,436
Cumulative Timesteps: 912,882,892

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 912882892...
Checkpoint 912882892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,981.47240
Policy Entropy: 1.69628
Value Function Loss: 0.06540

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.73421

Collected Steps per Second: 20,266.46365
Overall Steps per Second: 10,287.91371

Timestep Collection Time: 2.46831
Timestep Consumption Time: 2.39409
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.86240

Cumulative Model Updates: 109,442
Cumulative Timesteps: 912,932,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.14830
Policy Entropy: 1.70056
Value Function Loss: 0.06542

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.58103
Value Function Update Magnitude: 0.73700

Collected Steps per Second: 20,593.55361
Overall Steps per Second: 10,336.01388

Timestep Collection Time: 2.42824
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.83804

Cumulative Model Updates: 109,448
Cumulative Timesteps: 912,982,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 912982922...
Checkpoint 912982922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,710.09378
Policy Entropy: 1.70853
Value Function Loss: 0.06665

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.15709
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.74369

Collected Steps per Second: 20,671.71928
Overall Steps per Second: 10,265.70633

Timestep Collection Time: 2.41934
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.87175

Cumulative Model Updates: 109,454
Cumulative Timesteps: 913,032,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,395.47170
Policy Entropy: 1.70436
Value Function Loss: 0.06459

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.16479
Policy Update Magnitude: 0.52047
Value Function Update Magnitude: 0.74990

Collected Steps per Second: 21,389.38003
Overall Steps per Second: 10,403.76414

Timestep Collection Time: 2.33845
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.80768

Cumulative Model Updates: 109,460
Cumulative Timesteps: 913,082,952

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913082952...
Checkpoint 913082952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,482.75143
Policy Entropy: 1.70019
Value Function Loss: 0.06762

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.16413
Policy Update Magnitude: 0.52844
Value Function Update Magnitude: 0.68113

Collected Steps per Second: 21,127.54383
Overall Steps per Second: 10,279.81651

Timestep Collection Time: 2.36819
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.86721

Cumulative Model Updates: 109,466
Cumulative Timesteps: 913,132,986

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,996.85800
Policy Entropy: 1.70774
Value Function Loss: 0.07287

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.16405
Policy Update Magnitude: 0.54814
Value Function Update Magnitude: 0.54630

Collected Steps per Second: 21,519.89648
Overall Steps per Second: 10,460.41033

Timestep Collection Time: 2.32380
Timestep Consumption Time: 2.45689
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.78069

Cumulative Model Updates: 109,472
Cumulative Timesteps: 913,182,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 913182994...
Checkpoint 913182994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,936.51685
Policy Entropy: 1.69061
Value Function Loss: 0.07400

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.16395
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.50966

Collected Steps per Second: 20,587.91820
Overall Steps per Second: 10,183.09681

Timestep Collection Time: 2.42919
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.91128

Cumulative Model Updates: 109,478
Cumulative Timesteps: 913,233,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,087.01279
Policy Entropy: 1.69047
Value Function Loss: 0.07558

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.60098
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 21,184.63998
Overall Steps per Second: 10,234.34962

Timestep Collection Time: 2.36020
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.88551

Cumulative Model Updates: 109,484
Cumulative Timesteps: 913,283,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 913283006...
Checkpoint 913283006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,345.13954
Policy Entropy: 1.66915
Value Function Loss: 0.07242

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.15343
Policy Update Magnitude: 0.60591
Value Function Update Magnitude: 0.72084

Collected Steps per Second: 21,129.88751
Overall Steps per Second: 10,329.55182

Timestep Collection Time: 2.36698
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.84184

Cumulative Model Updates: 109,490
Cumulative Timesteps: 913,333,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,742.47602
Policy Entropy: 1.67457
Value Function Loss: 0.06993

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.15408
Policy Update Magnitude: 0.60112
Value Function Update Magnitude: 0.70928

Collected Steps per Second: 21,424.87639
Overall Steps per Second: 10,275.00800

Timestep Collection Time: 2.33402
Timestep Consumption Time: 2.53274
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.86676

Cumulative Model Updates: 109,496
Cumulative Timesteps: 913,383,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 913383026...
Checkpoint 913383026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,324.93978
Policy Entropy: 1.67475
Value Function Loss: 0.06621

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14390
Policy Update Magnitude: 0.57850
Value Function Update Magnitude: 0.65322

Collected Steps per Second: 21,071.67962
Overall Steps per Second: 10,183.30250

Timestep Collection Time: 2.37295
Timestep Consumption Time: 2.53725
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.91019

Cumulative Model Updates: 109,502
Cumulative Timesteps: 913,433,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,519.58956
Policy Entropy: 1.68720
Value Function Loss: 0.06878

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 21,911.47335
Overall Steps per Second: 10,332.10338

Timestep Collection Time: 2.28282
Timestep Consumption Time: 2.55840
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.84122

Cumulative Model Updates: 109,508
Cumulative Timesteps: 913,483,048

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 913483048...
Checkpoint 913483048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,247.61972
Policy Entropy: 1.69928
Value Function Loss: 0.07703

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15328
Policy Update Magnitude: 0.58840
Value Function Update Magnitude: 0.57051

Collected Steps per Second: 21,148.41454
Overall Steps per Second: 10,212.68986

Timestep Collection Time: 2.36557
Timestep Consumption Time: 2.53304
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.89861

Cumulative Model Updates: 109,514
Cumulative Timesteps: 913,533,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,451.30716
Policy Entropy: 1.69351
Value Function Loss: 0.07437

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15443
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.49209

Collected Steps per Second: 21,478.63072
Overall Steps per Second: 10,395.35462

Timestep Collection Time: 2.32827
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.81061

Cumulative Model Updates: 109,520
Cumulative Timesteps: 913,583,084

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 913583084...
Checkpoint 913583084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,551.84388
Policy Entropy: 1.68225
Value Function Loss: 0.07445

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.16707
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.53295

Collected Steps per Second: 21,149.56836
Overall Steps per Second: 10,274.83034

Timestep Collection Time: 2.36449
Timestep Consumption Time: 2.50255
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.86704

Cumulative Model Updates: 109,526
Cumulative Timesteps: 913,633,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,997.35449
Policy Entropy: 1.66410
Value Function Loss: 0.06330

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.17134
Policy Update Magnitude: 0.52265
Value Function Update Magnitude: 0.64849

Collected Steps per Second: 21,439.07647
Overall Steps per Second: 10,390.23455

Timestep Collection Time: 2.33303
Timestep Consumption Time: 2.48091
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.81394

Cumulative Model Updates: 109,532
Cumulative Timesteps: 913,683,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 913683110...
Checkpoint 913683110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,749.43666
Policy Entropy: 1.67250
Value Function Loss: 0.06678

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.70367

Collected Steps per Second: 21,100.63226
Overall Steps per Second: 10,246.87556

Timestep Collection Time: 2.37102
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.88246

Cumulative Model Updates: 109,538
Cumulative Timesteps: 913,733,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,103.18642
Policy Entropy: 1.67191
Value Function Loss: 0.06640

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15918
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.77072

Collected Steps per Second: 21,499.87088
Overall Steps per Second: 10,400.28411

Timestep Collection Time: 2.32653
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.80948

Cumulative Model Updates: 109,544
Cumulative Timesteps: 913,783,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 913783160...
Checkpoint 913783160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,291.35994
Policy Entropy: 1.68101
Value Function Loss: 0.06923

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.57548
Value Function Update Magnitude: 0.72075

Collected Steps per Second: 20,814.22464
Overall Steps per Second: 10,230.07296

Timestep Collection Time: 2.40336
Timestep Consumption Time: 2.48654
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.88990

Cumulative Model Updates: 109,550
Cumulative Timesteps: 913,833,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,961.30564
Policy Entropy: 1.67570
Value Function Loss: 0.07592

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.15131
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.58137

Collected Steps per Second: 21,528.70232
Overall Steps per Second: 10,406.68244

Timestep Collection Time: 2.32276
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.80518

Cumulative Model Updates: 109,556
Cumulative Timesteps: 913,883,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 913883190...
Checkpoint 913883190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,096.07139
Policy Entropy: 1.67064
Value Function Loss: 0.07405

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14603
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.51484

Collected Steps per Second: 20,287.10899
Overall Steps per Second: 9,975.28513

Timestep Collection Time: 2.46580
Timestep Consumption Time: 2.54899
PPO Batch Consumption Time: 0.29722
Total Iteration Time: 5.01479

Cumulative Model Updates: 109,562
Cumulative Timesteps: 913,933,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,590.14182
Policy Entropy: 1.65737
Value Function Loss: 0.07182

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.14486
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.51874

Collected Steps per Second: 21,769.96904
Overall Steps per Second: 10,399.73566

Timestep Collection Time: 2.29885
Timestep Consumption Time: 2.51338
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.81224

Cumulative Model Updates: 109,568
Cumulative Timesteps: 913,983,260

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 913983260...
Checkpoint 913983260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,458.08037
Policy Entropy: 1.65930
Value Function Loss: 0.06613

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.54119

Collected Steps per Second: 21,149.30036
Overall Steps per Second: 10,206.57954

Timestep Collection Time: 2.36414
Timestep Consumption Time: 2.53466
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.89880

Cumulative Model Updates: 109,574
Cumulative Timesteps: 914,033,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,728.03214
Policy Entropy: 1.65234
Value Function Loss: 0.06691

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14115
Policy Update Magnitude: 0.57914
Value Function Update Magnitude: 0.53487

Collected Steps per Second: 21,757.91458
Overall Steps per Second: 10,468.20131

Timestep Collection Time: 2.29912
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.77866

Cumulative Model Updates: 109,580
Cumulative Timesteps: 914,083,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914083284...
Checkpoint 914083284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,273.33025
Policy Entropy: 1.65580
Value Function Loss: 0.06833

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.52691

Collected Steps per Second: 21,307.83980
Overall Steps per Second: 10,192.14820

Timestep Collection Time: 2.34768
Timestep Consumption Time: 2.56041
PPO Batch Consumption Time: 0.29852
Total Iteration Time: 4.90809

Cumulative Model Updates: 109,586
Cumulative Timesteps: 914,133,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,775.20639
Policy Entropy: 1.66037
Value Function Loss: 0.07865

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.59147
Value Function Update Magnitude: 0.44978

Collected Steps per Second: 21,757.10335
Overall Steps per Second: 10,468.57078

Timestep Collection Time: 2.29911
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.77830

Cumulative Model Updates: 109,592
Cumulative Timesteps: 914,183,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914183330...
Checkpoint 914183330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,182.69865
Policy Entropy: 1.66223
Value Function Loss: 0.07542

Mean KL Divergence: 0.01563
SB3 Clip Fraction: 0.15313
Policy Update Magnitude: 0.58852
Value Function Update Magnitude: 0.60203

Collected Steps per Second: 20,987.19809
Overall Steps per Second: 10,187.30145

Timestep Collection Time: 2.38317
Timestep Consumption Time: 2.52647
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.90964

Cumulative Model Updates: 109,598
Cumulative Timesteps: 914,233,346

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,071.70192
Policy Entropy: 1.66927
Value Function Loss: 0.07193

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.14885
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.61088

Collected Steps per Second: 21,653.03914
Overall Steps per Second: 10,409.29621

Timestep Collection Time: 2.30988
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.80494

Cumulative Model Updates: 109,604
Cumulative Timesteps: 914,283,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 914283362...
Checkpoint 914283362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,704.14610
Policy Entropy: 1.67089
Value Function Loss: 0.06916

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14419
Policy Update Magnitude: 0.57485
Value Function Update Magnitude: 0.58738

Collected Steps per Second: 21,046.99169
Overall Steps per Second: 10,286.24306

Timestep Collection Time: 2.37668
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.86300

Cumulative Model Updates: 109,610
Cumulative Timesteps: 914,333,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,692.77605
Policy Entropy: 1.66898
Value Function Loss: 0.07201

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.57599
Value Function Update Magnitude: 0.57908

Collected Steps per Second: 21,552.75710
Overall Steps per Second: 10,375.63410

Timestep Collection Time: 2.32007
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.81937

Cumulative Model Updates: 109,616
Cumulative Timesteps: 914,383,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 914383388...
Checkpoint 914383388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,520.87028
Policy Entropy: 1.65964
Value Function Loss: 0.07076

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14243
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.55138

Collected Steps per Second: 21,096.38617
Overall Steps per Second: 10,237.47093

Timestep Collection Time: 2.37093
Timestep Consumption Time: 2.51485
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.88578

Cumulative Model Updates: 109,622
Cumulative Timesteps: 914,433,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,487.56878
Policy Entropy: 1.66372
Value Function Loss: 0.06965

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.58245
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 21,523.73611
Overall Steps per Second: 10,421.31274

Timestep Collection Time: 2.32404
Timestep Consumption Time: 2.47593
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.79997

Cumulative Model Updates: 109,628
Cumulative Timesteps: 914,483,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914483428...
Checkpoint 914483428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,202.79695
Policy Entropy: 1.66366
Value Function Loss: 0.06846

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14316
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.67710

Collected Steps per Second: 21,123.43570
Overall Steps per Second: 10,102.31676

Timestep Collection Time: 2.36799
Timestep Consumption Time: 2.58335
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.95134

Cumulative Model Updates: 109,634
Cumulative Timesteps: 914,533,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,946.99468
Policy Entropy: 1.67357
Value Function Loss: 0.06201

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14564
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.69171

Collected Steps per Second: 21,531.75678
Overall Steps per Second: 10,343.64795

Timestep Collection Time: 2.32308
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.83582

Cumulative Model Updates: 109,640
Cumulative Timesteps: 914,583,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 914583468...
Checkpoint 914583468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,920.52926
Policy Entropy: 1.65669
Value Function Loss: 0.06589

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.57074
Value Function Update Magnitude: 0.66041

Collected Steps per Second: 21,319.04346
Overall Steps per Second: 10,190.65601

Timestep Collection Time: 2.34617
Timestep Consumption Time: 2.56206
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.90822

Cumulative Model Updates: 109,646
Cumulative Timesteps: 914,633,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,822.02647
Policy Entropy: 1.66102
Value Function Loss: 0.06759

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.58087

Collected Steps per Second: 20,320.44300
Overall Steps per Second: 10,275.39804

Timestep Collection Time: 2.46195
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.86872

Cumulative Model Updates: 109,652
Cumulative Timesteps: 914,683,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 914683514...
Checkpoint 914683514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,930.46373
Policy Entropy: 1.66177
Value Function Loss: 0.06686

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.18931
Policy Update Magnitude: 0.49659
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 20,515.71134
Overall Steps per Second: 10,233.06428

Timestep Collection Time: 2.43813
Timestep Consumption Time: 2.44994
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.88808

Cumulative Model Updates: 109,658
Cumulative Timesteps: 914,733,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,708.76357
Policy Entropy: 1.67757
Value Function Loss: 0.07364

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.17446
Policy Update Magnitude: 0.50842
Value Function Update Magnitude: 0.61292

Collected Steps per Second: 20,737.66579
Overall Steps per Second: 10,375.61459

Timestep Collection Time: 2.41165
Timestep Consumption Time: 2.40850
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.82015

Cumulative Model Updates: 109,664
Cumulative Timesteps: 914,783,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 914783546...
Checkpoint 914783546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,131.16458
Policy Entropy: 1.67799
Value Function Loss: 0.07582

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.18008
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.59261

Collected Steps per Second: 20,676.84374
Overall Steps per Second: 10,307.57365

Timestep Collection Time: 2.41874
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.85197

Cumulative Model Updates: 109,670
Cumulative Timesteps: 914,833,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,541.28718
Policy Entropy: 1.66595
Value Function Loss: 0.07300

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.17909
Policy Update Magnitude: 0.49399
Value Function Update Magnitude: 0.64074

Collected Steps per Second: 20,387.22440
Overall Steps per Second: 10,061.36463

Timestep Collection Time: 2.45360
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 4.97169

Cumulative Model Updates: 109,676
Cumulative Timesteps: 914,883,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 914883580...
Checkpoint 914883580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,722.93569
Policy Entropy: 1.65512
Value Function Loss: 0.06482

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.15986
Policy Update Magnitude: 0.53475
Value Function Update Magnitude: 0.66343

Collected Steps per Second: 20,730.75754
Overall Steps per Second: 10,256.30548

Timestep Collection Time: 2.41188
Timestep Consumption Time: 2.46317
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.87505

Cumulative Model Updates: 109,682
Cumulative Timesteps: 914,933,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,259.67005
Policy Entropy: 1.65944
Value Function Loss: 0.06739

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15219
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.58359

Collected Steps per Second: 20,946.20962
Overall Steps per Second: 10,279.83441

Timestep Collection Time: 2.38831
Timestep Consumption Time: 2.47811
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.86642

Cumulative Model Updates: 109,688
Cumulative Timesteps: 914,983,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 914983606...
Checkpoint 914983606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,169.72037
Policy Entropy: 1.66232
Value Function Loss: 0.07592

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.58590
Value Function Update Magnitude: 0.56704

Collected Steps per Second: 21,432.38885
Overall Steps per Second: 10,290.50537

Timestep Collection Time: 2.33385
Timestep Consumption Time: 2.52694
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.86079

Cumulative Model Updates: 109,694
Cumulative Timesteps: 915,033,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,744.22398
Policy Entropy: 1.66105
Value Function Loss: 0.07551

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14785
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.63552

Collected Steps per Second: 21,400.31929
Overall Steps per Second: 10,409.00629

Timestep Collection Time: 2.33800
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.80680

Cumulative Model Updates: 109,700
Cumulative Timesteps: 915,083,660

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 915083660...
Checkpoint 915083660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,983.58645
Policy Entropy: 1.66080
Value Function Loss: 0.06889

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.13781
Policy Update Magnitude: 0.58502
Value Function Update Magnitude: 0.71926

Collected Steps per Second: 21,355.81765
Overall Steps per Second: 10,272.94158

Timestep Collection Time: 2.34128
Timestep Consumption Time: 2.52587
PPO Batch Consumption Time: 0.29735
Total Iteration Time: 4.86716

Cumulative Model Updates: 109,706
Cumulative Timesteps: 915,133,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,610.28009
Policy Entropy: 1.66005
Value Function Loss: 0.06572

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.66651

Collected Steps per Second: 21,422.44247
Overall Steps per Second: 10,371.80892

Timestep Collection Time: 2.33447
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.82172

Cumulative Model Updates: 109,712
Cumulative Timesteps: 915,183,670

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915183670...
Checkpoint 915183670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,018.02370
Policy Entropy: 1.65287
Value Function Loss: 0.06765

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.14546
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.58440

Collected Steps per Second: 20,811.86058
Overall Steps per Second: 10,194.02368

Timestep Collection Time: 2.40382
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.90758

Cumulative Model Updates: 109,718
Cumulative Timesteps: 915,233,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,107.39097
Policy Entropy: 1.64673
Value Function Loss: 0.06849

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.57115

Collected Steps per Second: 21,225.24340
Overall Steps per Second: 10,184.99705

Timestep Collection Time: 2.35710
Timestep Consumption Time: 2.55503
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.91213

Cumulative Model Updates: 109,724
Cumulative Timesteps: 915,283,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 915283728...
Checkpoint 915283728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,827.94563
Policy Entropy: 1.64687
Value Function Loss: 0.06514

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.65574

Collected Steps per Second: 21,561.45162
Overall Steps per Second: 10,456.78051

Timestep Collection Time: 2.32034
Timestep Consumption Time: 2.46411
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.78446

Cumulative Model Updates: 109,730
Cumulative Timesteps: 915,333,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,379.43440
Policy Entropy: 1.64417
Value Function Loss: 0.06495

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14064
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.67458

Collected Steps per Second: 21,292.74602
Overall Steps per Second: 10,206.20538

Timestep Collection Time: 2.34934
Timestep Consumption Time: 2.55199
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.90133

Cumulative Model Updates: 109,736
Cumulative Timesteps: 915,383,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 915383782...
Checkpoint 915383782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,342.95728
Policy Entropy: 1.65429
Value Function Loss: 0.06633

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.68052

Collected Steps per Second: 21,329.43743
Overall Steps per Second: 10,277.52861

Timestep Collection Time: 2.34530
Timestep Consumption Time: 2.52201
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.86732

Cumulative Model Updates: 109,742
Cumulative Timesteps: 915,433,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,805.25565
Policy Entropy: 1.64827
Value Function Loss: 0.07458

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14251
Policy Update Magnitude: 0.58006
Value Function Update Magnitude: 0.72596

Collected Steps per Second: 21,339.86910
Overall Steps per Second: 10,145.76569

Timestep Collection Time: 2.34313
Timestep Consumption Time: 2.58524
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.92836

Cumulative Model Updates: 109,748
Cumulative Timesteps: 915,483,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 915483808...
Checkpoint 915483808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,548.85629
Policy Entropy: 1.65669
Value Function Loss: 0.07518

Mean KL Divergence: 0.01677
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.57705
Value Function Update Magnitude: 0.75164

Collected Steps per Second: 21,114.09768
Overall Steps per Second: 10,345.48420

Timestep Collection Time: 2.36913
Timestep Consumption Time: 2.46603
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.83515

Cumulative Model Updates: 109,754
Cumulative Timesteps: 915,533,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,549.30080
Policy Entropy: 1.65240
Value Function Loss: 0.07596

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.59487
Value Function Update Magnitude: 0.75776

Collected Steps per Second: 21,430.02243
Overall Steps per Second: 10,389.12254

Timestep Collection Time: 2.33336
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.81311

Cumulative Model Updates: 109,760
Cumulative Timesteps: 915,583,834

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 915583834...
Checkpoint 915583834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,116.51529
Policy Entropy: 1.66839
Value Function Loss: 0.07352

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.59315
Value Function Update Magnitude: 0.75535

Collected Steps per Second: 21,140.61128
Overall Steps per Second: 10,273.15810

Timestep Collection Time: 2.36521
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.86725

Cumulative Model Updates: 109,766
Cumulative Timesteps: 915,633,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,959.64469
Policy Entropy: 1.67367
Value Function Loss: 0.07210

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.59438
Value Function Update Magnitude: 0.72843

Collected Steps per Second: 21,424.08962
Overall Steps per Second: 10,377.31255

Timestep Collection Time: 2.33532
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.82129

Cumulative Model Updates: 109,772
Cumulative Timesteps: 915,683,868

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 915683868...
Checkpoint 915683868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,820.30948
Policy Entropy: 1.67644
Value Function Loss: 0.06642

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.59005
Value Function Update Magnitude: 0.70782

Collected Steps per Second: 21,598.17792
Overall Steps per Second: 10,322.75752

Timestep Collection Time: 2.31520
Timestep Consumption Time: 2.52886
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.84405

Cumulative Model Updates: 109,778
Cumulative Timesteps: 915,733,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,151.26623
Policy Entropy: 1.67191
Value Function Loss: 0.06463

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.70030

Collected Steps per Second: 20,562.14626
Overall Steps per Second: 10,345.34185

Timestep Collection Time: 2.43301
Timestep Consumption Time: 2.40279
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.83580

Cumulative Model Updates: 109,784
Cumulative Timesteps: 915,783,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 915783900...
Checkpoint 915783900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,946.30867
Policy Entropy: 1.66931
Value Function Loss: 0.06517

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.57918
Value Function Update Magnitude: 0.62643

Collected Steps per Second: 20,722.75604
Overall Steps per Second: 10,305.52821

Timestep Collection Time: 2.41377
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.85371

Cumulative Model Updates: 109,790
Cumulative Timesteps: 915,833,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,806.69005
Policy Entropy: 1.66470
Value Function Loss: 0.06659

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.58425

Collected Steps per Second: 20,843.77957
Overall Steps per Second: 10,391.43935

Timestep Collection Time: 2.39899
Timestep Consumption Time: 2.41305
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.81204

Cumulative Model Updates: 109,796
Cumulative Timesteps: 915,883,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 915883924...
Checkpoint 915883924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,176.96759
Policy Entropy: 1.67185
Value Function Loss: 0.06424

Mean KL Divergence: 0.02043
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.47682
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 20,532.05375
Overall Steps per Second: 10,227.02557

Timestep Collection Time: 2.43531
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.88920

Cumulative Model Updates: 109,802
Cumulative Timesteps: 915,933,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,018.61481
Policy Entropy: 1.66591
Value Function Loss: 0.06495

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.16393
Policy Update Magnitude: 0.48836
Value Function Update Magnitude: 0.49987

Collected Steps per Second: 21,450.94243
Overall Steps per Second: 10,442.06801

Timestep Collection Time: 2.33137
Timestep Consumption Time: 2.45792
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.78928

Cumulative Model Updates: 109,808
Cumulative Timesteps: 915,983,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915983936...
Checkpoint 915983936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,976.49114
Policy Entropy: 1.66961
Value Function Loss: 0.06669

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.16367
Policy Update Magnitude: 0.49313
Value Function Update Magnitude: 0.40814

Collected Steps per Second: 21,172.42135
Overall Steps per Second: 10,280.42500

Timestep Collection Time: 2.36251
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.86556

Cumulative Model Updates: 109,814
Cumulative Timesteps: 916,033,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,566.46473
Policy Entropy: 1.66063
Value Function Loss: 0.06582

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16088
Policy Update Magnitude: 0.51945
Value Function Update Magnitude: 0.57687

Collected Steps per Second: 21,777.40214
Overall Steps per Second: 10,434.60771

Timestep Collection Time: 2.29651
Timestep Consumption Time: 2.49639
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.79290

Cumulative Model Updates: 109,820
Cumulative Timesteps: 916,083,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 916083968...
Checkpoint 916083968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,381.53460
Policy Entropy: 1.66745
Value Function Loss: 0.06740

Mean KL Divergence: 0.01869
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.53449
Value Function Update Magnitude: 0.63773

Collected Steps per Second: 21,243.70433
Overall Steps per Second: 10,194.47468

Timestep Collection Time: 2.35430
Timestep Consumption Time: 2.55169
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.90599

Cumulative Model Updates: 109,826
Cumulative Timesteps: 916,133,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,172.20836
Policy Entropy: 1.66636
Value Function Loss: 0.06880

Mean KL Divergence: 0.02252
SB3 Clip Fraction: 0.18741
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 21,158.87365
Overall Steps per Second: 10,270.68855

Timestep Collection Time: 2.36411
Timestep Consumption Time: 2.50625
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.87036

Cumulative Model Updates: 109,832
Cumulative Timesteps: 916,184,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916184004...
Checkpoint 916184004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,159.64432
Policy Entropy: 1.67239
Value Function Loss: 0.06667

Mean KL Divergence: 0.01964
SB3 Clip Fraction: 0.17210
Policy Update Magnitude: 0.54617
Value Function Update Magnitude: 0.67985

Collected Steps per Second: 21,381.46410
Overall Steps per Second: 10,390.44189

Timestep Collection Time: 2.34016
Timestep Consumption Time: 2.47542
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.81558

Cumulative Model Updates: 109,838
Cumulative Timesteps: 916,234,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,103.67239
Policy Entropy: 1.67313
Value Function Loss: 0.06333

Mean KL Divergence: 0.01784
SB3 Clip Fraction: 0.16359
Policy Update Magnitude: 0.53580
Value Function Update Magnitude: 0.68686

Collected Steps per Second: 21,567.35293
Overall Steps per Second: 10,408.63243

Timestep Collection Time: 2.31999
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.80716

Cumulative Model Updates: 109,844
Cumulative Timesteps: 916,284,076

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 916284076...
Checkpoint 916284076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,816.88701
Policy Entropy: 1.68765
Value Function Loss: 0.06688

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.17164
Policy Update Magnitude: 0.53060
Value Function Update Magnitude: 0.58874

Collected Steps per Second: 21,182.69257
Overall Steps per Second: 10,338.93106

Timestep Collection Time: 2.36108
Timestep Consumption Time: 2.47637
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.83744

Cumulative Model Updates: 109,850
Cumulative Timesteps: 916,334,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,593.46990
Policy Entropy: 1.69010
Value Function Loss: 0.07085

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.17491
Policy Update Magnitude: 0.51770
Value Function Update Magnitude: 0.56815

Collected Steps per Second: 21,669.95857
Overall Steps per Second: 10,387.38590

Timestep Collection Time: 2.30799
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.81488

Cumulative Model Updates: 109,856
Cumulative Timesteps: 916,384,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 916384104...
Checkpoint 916384104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,619.89535
Policy Entropy: 1.67657
Value Function Loss: 0.06784

Mean KL Divergence: 0.02100
SB3 Clip Fraction: 0.18217
Policy Update Magnitude: 0.52866
Value Function Update Magnitude: 0.68254

Collected Steps per Second: 21,105.42590
Overall Steps per Second: 10,237.29408

Timestep Collection Time: 2.36991
Timestep Consumption Time: 2.51595
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.88586

Cumulative Model Updates: 109,862
Cumulative Timesteps: 916,434,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,873.58119
Policy Entropy: 1.67444
Value Function Loss: 0.06280

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.17119
Policy Update Magnitude: 0.52917
Value Function Update Magnitude: 0.66791

Collected Steps per Second: 21,650.28780
Overall Steps per Second: 10,390.61627

Timestep Collection Time: 2.30953
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.81223

Cumulative Model Updates: 109,868
Cumulative Timesteps: 916,484,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 916484124...
Checkpoint 916484124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,293.96968
Policy Entropy: 1.67617
Value Function Loss: 0.06448

Mean KL Divergence: 0.01810
SB3 Clip Fraction: 0.16617
Policy Update Magnitude: 0.52688
Value Function Update Magnitude: 0.55601

Collected Steps per Second: 21,256.82057
Overall Steps per Second: 10,250.64403

Timestep Collection Time: 2.35219
Timestep Consumption Time: 2.52556
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.87774

Cumulative Model Updates: 109,874
Cumulative Timesteps: 916,534,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,393.65851
Policy Entropy: 1.68459
Value Function Loss: 0.06711

Mean KL Divergence: 0.02114
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.50573
Value Function Update Magnitude: 0.45311

Collected Steps per Second: 21,777.66872
Overall Steps per Second: 10,447.39882

Timestep Collection Time: 2.29676
Timestep Consumption Time: 2.49085
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.78760

Cumulative Model Updates: 109,880
Cumulative Timesteps: 916,584,142

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 916584142...
Checkpoint 916584142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,067.30385
Policy Entropy: 1.69064
Value Function Loss: 0.06807

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.16820
Policy Update Magnitude: 0.50950
Value Function Update Magnitude: 0.49242

Collected Steps per Second: 21,040.64324
Overall Steps per Second: 9,650.74796

Timestep Collection Time: 2.37740
Timestep Consumption Time: 2.80583
PPO Batch Consumption Time: 0.33575
Total Iteration Time: 5.18323

Cumulative Model Updates: 109,886
Cumulative Timesteps: 916,634,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,484.74371
Policy Entropy: 1.70089
Value Function Loss: 0.07317

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.16615
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.63871

Collected Steps per Second: 20,807.04758
Overall Steps per Second: 10,261.41227

Timestep Collection Time: 2.40419
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.87496

Cumulative Model Updates: 109,892
Cumulative Timesteps: 916,684,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 916684188...
Checkpoint 916684188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,646.71292
Policy Entropy: 1.69416
Value Function Loss: 0.07127

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.17689
Policy Update Magnitude: 0.53801
Value Function Update Magnitude: 0.61370

Collected Steps per Second: 21,174.77349
Overall Steps per Second: 10,167.62303

Timestep Collection Time: 2.36139
Timestep Consumption Time: 2.55637
PPO Batch Consumption Time: 0.29955
Total Iteration Time: 4.91777

Cumulative Model Updates: 109,898
Cumulative Timesteps: 916,734,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,934.54734
Policy Entropy: 1.69304
Value Function Loss: 0.07123

Mean KL Divergence: 0.01902
SB3 Clip Fraction: 0.16844
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 20,859.52132
Overall Steps per Second: 9,928.01150

Timestep Collection Time: 2.39900
Timestep Consumption Time: 2.64149
PPO Batch Consumption Time: 0.31238
Total Iteration Time: 5.04049

Cumulative Model Updates: 109,904
Cumulative Timesteps: 916,784,232

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 916784232...
Checkpoint 916784232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,858.21926
Policy Entropy: 1.67668
Value Function Loss: 0.07191

Mean KL Divergence: 0.01894
SB3 Clip Fraction: 0.17349
Policy Update Magnitude: 0.56749
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 19,281.88754
Overall Steps per Second: 9,826.00663

Timestep Collection Time: 2.59342
Timestep Consumption Time: 2.49573
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 5.08915

Cumulative Model Updates: 109,910
Cumulative Timesteps: 916,834,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,349.74873
Policy Entropy: 1.67874
Value Function Loss: 0.07588

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.17550
Policy Update Magnitude: 0.58019
Value Function Update Magnitude: 0.65369

Collected Steps per Second: 18,503.64654
Overall Steps per Second: 9,160.84218

Timestep Collection Time: 2.70444
Timestep Consumption Time: 2.75816
PPO Batch Consumption Time: 0.33650
Total Iteration Time: 5.46260

Cumulative Model Updates: 109,916
Cumulative Timesteps: 916,884,280

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 916884280...
Checkpoint 916884280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,818.43874
Policy Entropy: 1.68076
Value Function Loss: 0.07023

Mean KL Divergence: 0.02054
SB3 Clip Fraction: 0.17791
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.72462

Collected Steps per Second: 19,796.32771
Overall Steps per Second: 9,428.76743

Timestep Collection Time: 2.52653
Timestep Consumption Time: 2.77809
PPO Batch Consumption Time: 0.33129
Total Iteration Time: 5.30462

Cumulative Model Updates: 109,922
Cumulative Timesteps: 916,934,296

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,092.39623
Policy Entropy: 1.68441
Value Function Loss: 0.06134

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16376
Policy Update Magnitude: 0.50966
Value Function Update Magnitude: 0.69814

Collected Steps per Second: 22,028.95375
Overall Steps per Second: 10,424.75359

Timestep Collection Time: 2.27074
Timestep Consumption Time: 2.52765
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.79839

Cumulative Model Updates: 109,928
Cumulative Timesteps: 916,984,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916984318...
Checkpoint 916984318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,991.54150
Policy Entropy: 1.68874
Value Function Loss: 0.06128

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14681
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.66114

Collected Steps per Second: 21,374.25135
Overall Steps per Second: 10,149.90967

Timestep Collection Time: 2.33964
Timestep Consumption Time: 2.58730
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 4.92694

Cumulative Model Updates: 109,934
Cumulative Timesteps: 917,034,326

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,019.11068
Policy Entropy: 1.68786
Value Function Loss: 0.06368

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.14940
Policy Update Magnitude: 0.57004
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 20,581.04396
Overall Steps per Second: 9,930.17687

Timestep Collection Time: 2.43029
Timestep Consumption Time: 2.60668
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 5.03697

Cumulative Model Updates: 109,940
Cumulative Timesteps: 917,084,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 917084344...
Checkpoint 917084344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,912.54259
Policy Entropy: 1.67183
Value Function Loss: 0.06629

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.58121
Value Function Update Magnitude: 0.53672

Collected Steps per Second: 19,900.96605
Overall Steps per Second: 9,857.55828

Timestep Collection Time: 2.51445
Timestep Consumption Time: 2.56186
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 5.07631

Cumulative Model Updates: 109,946
Cumulative Timesteps: 917,134,384

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,349.40771
Policy Entropy: 1.66624
Value Function Loss: 0.06688

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.14701
Policy Update Magnitude: 0.57721
Value Function Update Magnitude: 0.57162

Collected Steps per Second: 21,317.98688
Overall Steps per Second: 10,259.01763

Timestep Collection Time: 2.34638
Timestep Consumption Time: 2.52934
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.87571

Cumulative Model Updates: 109,952
Cumulative Timesteps: 917,184,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 917184404...
Checkpoint 917184404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,103.93066
Policy Entropy: 1.66421
Value Function Loss: 0.06338

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.57514
Value Function Update Magnitude: 0.68178

Collected Steps per Second: 21,342.78746
Overall Steps per Second: 10,402.37438

Timestep Collection Time: 2.34384
Timestep Consumption Time: 2.46507
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.80890

Cumulative Model Updates: 109,958
Cumulative Timesteps: 917,234,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,815.60483
Policy Entropy: 1.67013
Value Function Loss: 0.06244

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.72137

Collected Steps per Second: 20,913.55042
Overall Steps per Second: 10,122.82706

Timestep Collection Time: 2.39309
Timestep Consumption Time: 2.55098
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.94407

Cumulative Model Updates: 109,964
Cumulative Timesteps: 917,284,476

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 917284476...
Checkpoint 917284476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,941.42481
Policy Entropy: 1.66365
Value Function Loss: 0.06311

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.56904
Value Function Update Magnitude: 0.69719

Collected Steps per Second: 20,806.29077
Overall Steps per Second: 10,292.60760

Timestep Collection Time: 2.40408
Timestep Consumption Time: 2.45572
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.85980

Cumulative Model Updates: 109,970
Cumulative Timesteps: 917,334,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,138.73775
Policy Entropy: 1.65445
Value Function Loss: 0.06801

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.14109
Policy Update Magnitude: 0.58853
Value Function Update Magnitude: 0.70920

Collected Steps per Second: 20,725.92956
Overall Steps per Second: 10,175.92764

Timestep Collection Time: 2.41369
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.30172
Total Iteration Time: 4.91611

Cumulative Model Updates: 109,976
Cumulative Timesteps: 917,384,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 917384522...
Checkpoint 917384522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.25952
Policy Entropy: 1.66203
Value Function Loss: 0.06482

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14374
Policy Update Magnitude: 0.58409
Value Function Update Magnitude: 0.72931

Collected Steps per Second: 20,513.94169
Overall Steps per Second: 10,323.38887

Timestep Collection Time: 2.43883
Timestep Consumption Time: 2.40745
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.84628

Cumulative Model Updates: 109,982
Cumulative Timesteps: 917,434,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,764.07950
Policy Entropy: 1.66897
Value Function Loss: 0.06885

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.59328
Value Function Update Magnitude: 0.72229

Collected Steps per Second: 20,668.27989
Overall Steps per Second: 10,386.58884

Timestep Collection Time: 2.41917
Timestep Consumption Time: 2.39473
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.81390

Cumulative Model Updates: 109,988
Cumulative Timesteps: 917,484,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 917484552...
Checkpoint 917484552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,449.79690
Policy Entropy: 1.66503
Value Function Loss: 0.06295

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.59718
Value Function Update Magnitude: 0.73441

Collected Steps per Second: 20,553.63251
Overall Steps per Second: 10,234.30704

Timestep Collection Time: 2.43392
Timestep Consumption Time: 2.45414
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.88807

Cumulative Model Updates: 109,994
Cumulative Timesteps: 917,534,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,472.52444
Policy Entropy: 1.67284
Value Function Loss: 0.06262

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.58800
Value Function Update Magnitude: 0.67998

Collected Steps per Second: 21,427.83057
Overall Steps per Second: 10,265.96729

Timestep Collection Time: 2.33416
Timestep Consumption Time: 2.53786
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.87202

Cumulative Model Updates: 110,000
Cumulative Timesteps: 917,584,594

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 917584594...
Checkpoint 917584594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,122.44746
Policy Entropy: 1.67106
Value Function Loss: 0.06138

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.58684
Value Function Update Magnitude: 0.70957

Collected Steps per Second: 21,364.01737
Overall Steps per Second: 10,451.57976

Timestep Collection Time: 2.34104
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.78531

Cumulative Model Updates: 110,006
Cumulative Timesteps: 917,634,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,170.97355
Policy Entropy: 1.67589
Value Function Loss: 0.05836

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.64778

Collected Steps per Second: 21,037.95337
Overall Steps per Second: 10,139.44688

Timestep Collection Time: 2.37846
Timestep Consumption Time: 2.55652
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.93498

Cumulative Model Updates: 110,012
Cumulative Timesteps: 917,684,646

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 917684646...
Checkpoint 917684646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,003.61937
Policy Entropy: 1.67129
Value Function Loss: 0.06069

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.60647

Collected Steps per Second: 21,460.29641
Overall Steps per Second: 10,296.28127

Timestep Collection Time: 2.33072
Timestep Consumption Time: 2.52715
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.85787

Cumulative Model Updates: 110,018
Cumulative Timesteps: 917,734,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,629.71079
Policy Entropy: 1.67623
Value Function Loss: 0.05916

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.60391

Collected Steps per Second: 21,421.54797
Overall Steps per Second: 10,307.80439

Timestep Collection Time: 2.33503
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.85263

Cumulative Model Updates: 110,024
Cumulative Timesteps: 917,784,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 917784684...
Checkpoint 917784684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,889.18248
Policy Entropy: 1.67207
Value Function Loss: 0.06181

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.45772

Collected Steps per Second: 21,035.91158
Overall Steps per Second: 10,193.83121

Timestep Collection Time: 2.37698
Timestep Consumption Time: 2.52814
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.90512

Cumulative Model Updates: 110,030
Cumulative Timesteps: 917,834,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,500.70143
Policy Entropy: 1.66856
Value Function Loss: 0.06936

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.37938

Collected Steps per Second: 21,564.94995
Overall Steps per Second: 10,403.23238

Timestep Collection Time: 2.31913
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.80735

Cumulative Model Updates: 110,036
Cumulative Timesteps: 917,884,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 917884698...
Checkpoint 917884698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,348.38330
Policy Entropy: 1.68299
Value Function Loss: 0.07178

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14051
Policy Update Magnitude: 0.57034
Value Function Update Magnitude: 0.37523

Collected Steps per Second: 21,289.55480
Overall Steps per Second: 10,253.31736

Timestep Collection Time: 2.34979
Timestep Consumption Time: 2.52922
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.87901

Cumulative Model Updates: 110,042
Cumulative Timesteps: 917,934,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,574.60392
Policy Entropy: 1.68795
Value Function Loss: 0.07252

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.57710
Value Function Update Magnitude: 0.36656

Collected Steps per Second: 21,176.05373
Overall Steps per Second: 10,222.99879

Timestep Collection Time: 2.36220
Timestep Consumption Time: 2.53089
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.89308

Cumulative Model Updates: 110,048
Cumulative Timesteps: 917,984,746

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 917984746...
Checkpoint 917984746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,316.72975
Policy Entropy: 1.71122
Value Function Loss: 0.08085

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.60051
Value Function Update Magnitude: 0.41325

Collected Steps per Second: 21,553.78300
Overall Steps per Second: 10,438.55713

Timestep Collection Time: 2.32071
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.79185

Cumulative Model Updates: 110,054
Cumulative Timesteps: 918,034,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,941.94753
Policy Entropy: 1.71387
Value Function Loss: 0.07930

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.62160
Value Function Update Magnitude: 0.42565

Collected Steps per Second: 21,138.45702
Overall Steps per Second: 10,244.22348

Timestep Collection Time: 2.36649
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.88314

Cumulative Model Updates: 110,060
Cumulative Timesteps: 918,084,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918084790...
Checkpoint 918084790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,611.64616
Policy Entropy: 1.72018
Value Function Loss: 0.07972

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.61576
Value Function Update Magnitude: 0.48852

Collected Steps per Second: 21,540.46289
Overall Steps per Second: 10,458.60631

Timestep Collection Time: 2.32335
Timestep Consumption Time: 2.46180
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.78515

Cumulative Model Updates: 110,066
Cumulative Timesteps: 918,134,836

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,954.00922
Policy Entropy: 1.71164
Value Function Loss: 0.07346

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.14616
Policy Update Magnitude: 0.60685
Value Function Update Magnitude: 0.44367

Collected Steps per Second: 21,387.59211
Overall Steps per Second: 10,366.72379

Timestep Collection Time: 2.33799
Timestep Consumption Time: 2.48552
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.82351

Cumulative Model Updates: 110,072
Cumulative Timesteps: 918,184,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 918184840...
Checkpoint 918184840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,660.42109
Policy Entropy: 1.71569
Value Function Loss: 0.07843

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.60431
Value Function Update Magnitude: 0.39702

Collected Steps per Second: 21,144.69489
Overall Steps per Second: 10,249.31640

Timestep Collection Time: 2.36485
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.87876

Cumulative Model Updates: 110,078
Cumulative Timesteps: 918,234,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,047.09147
Policy Entropy: 1.71575
Value Function Loss: 0.07413

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.60316
Value Function Update Magnitude: 0.38973

Collected Steps per Second: 20,580.26284
Overall Steps per Second: 10,034.98420

Timestep Collection Time: 2.43010
Timestep Consumption Time: 2.55367
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.98376

Cumulative Model Updates: 110,084
Cumulative Timesteps: 918,284,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 918284856...
Checkpoint 918284856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,616.65937
Policy Entropy: 1.70710
Value Function Loss: 0.07531

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14795
Policy Update Magnitude: 0.58427
Value Function Update Magnitude: 0.45429

Collected Steps per Second: 21,190.92004
Overall Steps per Second: 10,206.77663

Timestep Collection Time: 2.35969
Timestep Consumption Time: 2.53941
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.89910

Cumulative Model Updates: 110,090
Cumulative Timesteps: 918,334,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,616.71676
Policy Entropy: 1.70410
Value Function Loss: 0.06957

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14942
Policy Update Magnitude: 0.58464
Value Function Update Magnitude: 0.50979

Collected Steps per Second: 21,248.71613
Overall Steps per Second: 10,369.96448

Timestep Collection Time: 2.35412
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.82374

Cumulative Model Updates: 110,096
Cumulative Timesteps: 918,384,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 918384882...
Checkpoint 918384882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,195.00774
Policy Entropy: 1.70431
Value Function Loss: 0.06767

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.14970
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.48065

Collected Steps per Second: 21,109.21478
Overall Steps per Second: 10,318.14735

Timestep Collection Time: 2.36901
Timestep Consumption Time: 2.47759
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.84661

Cumulative Model Updates: 110,102
Cumulative Timesteps: 918,434,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,804.80166
Policy Entropy: 1.70607
Value Function Loss: 0.06554

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.45528

Collected Steps per Second: 21,613.11012
Overall Steps per Second: 10,406.63306

Timestep Collection Time: 2.31369
Timestep Consumption Time: 2.49152
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.80520

Cumulative Model Updates: 110,108
Cumulative Timesteps: 918,484,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 918484896...
Checkpoint 918484896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,327.04368
Policy Entropy: 1.71453
Value Function Loss: 0.06555

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.57336
Value Function Update Magnitude: 0.38486

Collected Steps per Second: 21,163.75699
Overall Steps per Second: 10,248.64321

Timestep Collection Time: 2.36338
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.88045

Cumulative Model Updates: 110,114
Cumulative Timesteps: 918,534,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,736.38956
Policy Entropy: 1.72810
Value Function Loss: 0.06353

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.38110

Collected Steps per Second: 21,462.79890
Overall Steps per Second: 10,423.07834

Timestep Collection Time: 2.33073
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.79935

Cumulative Model Updates: 110,120
Cumulative Timesteps: 918,584,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918584938...
Checkpoint 918584938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,467.93376
Policy Entropy: 1.73402
Value Function Loss: 0.06679

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.33478

Collected Steps per Second: 20,568.91256
Overall Steps per Second: 10,241.49200

Timestep Collection Time: 2.43124
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.88288

Cumulative Model Updates: 110,126
Cumulative Timesteps: 918,634,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,473.79350
Policy Entropy: 1.74121
Value Function Loss: 0.07470

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.30501

Collected Steps per Second: 20,806.32346
Overall Steps per Second: 10,400.03816

Timestep Collection Time: 2.40360
Timestep Consumption Time: 2.40504
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.80864

Cumulative Model Updates: 110,132
Cumulative Timesteps: 918,684,956

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 918684956...
Checkpoint 918684956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,257.41163
Policy Entropy: 1.73961
Value Function Loss: 0.07944

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.57900
Value Function Update Magnitude: 0.27081

Collected Steps per Second: 20,346.47255
Overall Steps per Second: 10,229.74927

Timestep Collection Time: 2.45831
Timestep Consumption Time: 2.43115
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.88946

Cumulative Model Updates: 110,138
Cumulative Timesteps: 918,734,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,522.13197
Policy Entropy: 1.72508
Value Function Loss: 0.08307

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.58777
Value Function Update Magnitude: 0.30676

Collected Steps per Second: 20,876.13322
Overall Steps per Second: 10,430.21010

Timestep Collection Time: 2.39623
Timestep Consumption Time: 2.39984
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.79607

Cumulative Model Updates: 110,144
Cumulative Timesteps: 918,784,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918784998...
Checkpoint 918784998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,632.91811
Policy Entropy: 1.72337
Value Function Loss: 0.07975

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.31595

Collected Steps per Second: 20,430.83917
Overall Steps per Second: 10,217.08184

Timestep Collection Time: 2.44816
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.89553

Cumulative Model Updates: 110,150
Cumulative Timesteps: 918,835,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,584.96719
Policy Entropy: 1.71722
Value Function Loss: 0.07115

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15489
Policy Update Magnitude: 0.57078
Value Function Update Magnitude: 0.50323

Collected Steps per Second: 21,637.29402
Overall Steps per Second: 10,519.89045

Timestep Collection Time: 2.31138
Timestep Consumption Time: 2.44266
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.75404

Cumulative Model Updates: 110,156
Cumulative Timesteps: 918,885,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 918885028...
Checkpoint 918885028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,638.31737
Policy Entropy: 1.71188
Value Function Loss: 0.06565

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17426
Policy Update Magnitude: 0.48863
Value Function Update Magnitude: 0.56303

Collected Steps per Second: 20,991.18593
Overall Steps per Second: 10,188.13222

Timestep Collection Time: 2.38338
Timestep Consumption Time: 2.52723
PPO Batch Consumption Time: 0.29764
Total Iteration Time: 4.91062

Cumulative Model Updates: 110,162
Cumulative Timesteps: 918,935,058

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,248.51685
Policy Entropy: 1.71574
Value Function Loss: 0.06480

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.48717
Value Function Update Magnitude: 0.49739

Collected Steps per Second: 21,386.52233
Overall Steps per Second: 10,433.84712

Timestep Collection Time: 2.33839
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.79305

Cumulative Model Updates: 110,168
Cumulative Timesteps: 918,985,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 918985068...
Checkpoint 918985068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,742.46315
Policy Entropy: 1.71830
Value Function Loss: 0.06642

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.52537

Collected Steps per Second: 21,227.08941
Overall Steps per Second: 10,249.84620

Timestep Collection Time: 2.35633
Timestep Consumption Time: 2.52355
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.87988

Cumulative Model Updates: 110,174
Cumulative Timesteps: 919,035,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,287.48055
Policy Entropy: 1.72216
Value Function Loss: 0.06643

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.60733

Collected Steps per Second: 21,687.53456
Overall Steps per Second: 10,432.54428

Timestep Collection Time: 2.30630
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.79442

Cumulative Model Updates: 110,180
Cumulative Timesteps: 919,085,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 919085104...
Checkpoint 919085104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,648.95240
Policy Entropy: 1.72967
Value Function Loss: 0.06797

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.55644

Collected Steps per Second: 20,865.06061
Overall Steps per Second: 10,250.59961

Timestep Collection Time: 2.39693
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.87893

Cumulative Model Updates: 110,186
Cumulative Timesteps: 919,135,116

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,445.65571
Policy Entropy: 1.72407
Value Function Loss: 0.06969

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.58878
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 21,529.08223
Overall Steps per Second: 10,430.90181

Timestep Collection Time: 2.32318
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.79498

Cumulative Model Updates: 110,192
Cumulative Timesteps: 919,185,132

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 919185132...
Checkpoint 919185132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,683.77521
Policy Entropy: 1.72612
Value Function Loss: 0.07154

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.59339
Value Function Update Magnitude: 0.56690

Collected Steps per Second: 21,046.74581
Overall Steps per Second: 10,193.28945

Timestep Collection Time: 2.37576
Timestep Consumption Time: 2.52962
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.90538

Cumulative Model Updates: 110,198
Cumulative Timesteps: 919,235,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,341.18714
Policy Entropy: 1.73325
Value Function Loss: 0.07337

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.14850
Policy Update Magnitude: 0.59637
Value Function Update Magnitude: 0.58112

Collected Steps per Second: 21,454.74384
Overall Steps per Second: 10,444.10346

Timestep Collection Time: 2.33133
Timestep Consumption Time: 2.45779
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.78911

Cumulative Model Updates: 110,204
Cumulative Timesteps: 919,285,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 919285152...
Checkpoint 919285152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,412.19169
Policy Entropy: 1.73506
Value Function Loss: 0.06950

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.66745

Collected Steps per Second: 20,286.00740
Overall Steps per Second: 10,014.83607

Timestep Collection Time: 2.46594
Timestep Consumption Time: 2.52905
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.99499

Cumulative Model Updates: 110,210
Cumulative Timesteps: 919,335,176

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,007.22796
Policy Entropy: 1.74253
Value Function Loss: 0.07067

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 21,431.11234
Overall Steps per Second: 10,286.66240

Timestep Collection Time: 2.33352
Timestep Consumption Time: 2.52811
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.86164

Cumulative Model Updates: 110,216
Cumulative Timesteps: 919,385,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 919385186...
Checkpoint 919385186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,041.99698
Policy Entropy: 1.72244
Value Function Loss: 0.07708

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.59805
Value Function Update Magnitude: 0.59225

Collected Steps per Second: 20,922.55892
Overall Steps per Second: 10,172.12513

Timestep Collection Time: 2.39024
Timestep Consumption Time: 2.52613
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.91638

Cumulative Model Updates: 110,222
Cumulative Timesteps: 919,435,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,262.50065
Policy Entropy: 1.73066
Value Function Loss: 0.08187

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.60075
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 21,780.41024
Overall Steps per Second: 10,434.55273

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.79196

Cumulative Model Updates: 110,228
Cumulative Timesteps: 919,485,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 919485198...
Checkpoint 919485198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,789.00739
Policy Entropy: 1.73252
Value Function Loss: 0.07572

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.58445
Value Function Update Magnitude: 0.45187

Collected Steps per Second: 20,943.24388
Overall Steps per Second: 10,257.99636

Timestep Collection Time: 2.38874
Timestep Consumption Time: 2.48823
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.87698

Cumulative Model Updates: 110,234
Cumulative Timesteps: 919,535,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,698.28468
Policy Entropy: 1.73590
Value Function Loss: 0.06746

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.55796
Value Function Update Magnitude: 0.40508

Collected Steps per Second: 21,708.05410
Overall Steps per Second: 10,467.64179

Timestep Collection Time: 2.30421
Timestep Consumption Time: 2.47432
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.77854

Cumulative Model Updates: 110,240
Cumulative Timesteps: 919,585,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 919585246...
Checkpoint 919585246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,857.61255
Policy Entropy: 1.73179
Value Function Loss: 0.05972

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.43215

Collected Steps per Second: 21,305.69194
Overall Steps per Second: 10,210.64415

Timestep Collection Time: 2.34717
Timestep Consumption Time: 2.55047
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.89763

Cumulative Model Updates: 110,246
Cumulative Timesteps: 919,635,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,566.68221
Policy Entropy: 1.73683
Value Function Loss: 0.06395

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.46884

Collected Steps per Second: 21,515.44931
Overall Steps per Second: 10,390.39103

Timestep Collection Time: 2.32540
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.81522

Cumulative Model Updates: 110,252
Cumulative Timesteps: 919,685,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 919685286...
Checkpoint 919685286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,117.74681
Policy Entropy: 1.73470
Value Function Loss: 0.06495

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.54298
Value Function Update Magnitude: 0.48767

Collected Steps per Second: 20,939.91433
Overall Steps per Second: 10,225.70760

Timestep Collection Time: 2.38893
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.89198

Cumulative Model Updates: 110,258
Cumulative Timesteps: 919,735,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,742.86327
Policy Entropy: 1.73151
Value Function Loss: 0.07283

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.17350
Policy Update Magnitude: 0.50051
Value Function Update Magnitude: 0.38946

Collected Steps per Second: 21,517.58800
Overall Steps per Second: 10,395.60157

Timestep Collection Time: 2.32424
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.81088

Cumulative Model Updates: 110,264
Cumulative Timesteps: 919,785,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 919785322...
Checkpoint 919785322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,258.07095
Policy Entropy: 1.74135
Value Function Loss: 0.07485

Mean KL Divergence: 0.02058
SB3 Clip Fraction: 0.17145
Policy Update Magnitude: 0.51433
Value Function Update Magnitude: 0.48376

Collected Steps per Second: 20,982.56222
Overall Steps per Second: 10,309.71210

Timestep Collection Time: 2.38350
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.85096

Cumulative Model Updates: 110,270
Cumulative Timesteps: 919,835,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,835.32621
Policy Entropy: 1.75573
Value Function Loss: 0.06854

Mean KL Divergence: 0.02045
SB3 Clip Fraction: 0.17280
Policy Update Magnitude: 0.52985
Value Function Update Magnitude: 0.53960

Collected Steps per Second: 21,359.87109
Overall Steps per Second: 10,447.88214

Timestep Collection Time: 2.34196
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.78796

Cumulative Model Updates: 110,276
Cumulative Timesteps: 919,885,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919885358...
Checkpoint 919885358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,532.83661
Policy Entropy: 1.76325
Value Function Loss: 0.06436

Mean KL Divergence: 0.02275
SB3 Clip Fraction: 0.17970
Policy Update Magnitude: 0.48730
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 21,354.78344
Overall Steps per Second: 10,182.57339

Timestep Collection Time: 2.34158
Timestep Consumption Time: 2.56916
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.91074

Cumulative Model Updates: 110,282
Cumulative Timesteps: 919,935,362

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,638.19031
Policy Entropy: 1.77052
Value Function Loss: 0.06415

Mean KL Divergence: 0.03455
SB3 Clip Fraction: 0.21678
Policy Update Magnitude: 0.43941
Value Function Update Magnitude: 0.56920

Collected Steps per Second: 21,468.94333
Overall Steps per Second: 10,230.61607

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.55968
PPO Batch Consumption Time: 0.29797
Total Iteration Time: 4.88983

Cumulative Model Updates: 110,288
Cumulative Timesteps: 919,985,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 919985388...
Checkpoint 919985388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,147.97141
Policy Entropy: 1.75670
Value Function Loss: 0.06774

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.16727
Policy Update Magnitude: 0.46607
Value Function Update Magnitude: 0.49796

Collected Steps per Second: 21,187.04897
Overall Steps per Second: 10,356.00999

Timestep Collection Time: 2.36144
Timestep Consumption Time: 2.46976
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.83120

Cumulative Model Updates: 110,294
Cumulative Timesteps: 920,035,420

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,906.95840
Policy Entropy: 1.74749
Value Function Loss: 0.07410

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.16404
Policy Update Magnitude: 0.51866
Value Function Update Magnitude: 0.42131

Collected Steps per Second: 21,525.06687
Overall Steps per Second: 10,420.75198

Timestep Collection Time: 2.32315
Timestep Consumption Time: 2.47554
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.79869

Cumulative Model Updates: 110,300
Cumulative Timesteps: 920,085,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 920085426...
Checkpoint 920085426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,887.80344
Policy Entropy: 1.74533
Value Function Loss: 0.07149

Mean KL Divergence: 0.02093
SB3 Clip Fraction: 0.17530
Policy Update Magnitude: 0.54044
Value Function Update Magnitude: 0.41807

Collected Steps per Second: 20,925.71055
Overall Steps per Second: 10,244.75713

Timestep Collection Time: 2.38950
Timestep Consumption Time: 2.49124
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.88074

Cumulative Model Updates: 110,306
Cumulative Timesteps: 920,135,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,269.81325
Policy Entropy: 1.74616
Value Function Loss: 0.06803

Mean KL Divergence: 0.02244
SB3 Clip Fraction: 0.18247
Policy Update Magnitude: 0.50128
Value Function Update Magnitude: 0.34876

Collected Steps per Second: 20,865.83235
Overall Steps per Second: 10,082.51753

Timestep Collection Time: 2.39732
Timestep Consumption Time: 2.56394
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.96126

Cumulative Model Updates: 110,312
Cumulative Timesteps: 920,185,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 920185450...
Checkpoint 920185450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,354.82191
Policy Entropy: 1.74398
Value Function Loss: 0.06859

Mean KL Divergence: 0.01781
SB3 Clip Fraction: 0.16360
Policy Update Magnitude: 0.46938
Value Function Update Magnitude: 0.45490

Collected Steps per Second: 21,402.41207
Overall Steps per Second: 10,238.85629

Timestep Collection Time: 2.33721
Timestep Consumption Time: 2.54829
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.88551

Cumulative Model Updates: 110,318
Cumulative Timesteps: 920,235,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,094.25586
Policy Entropy: 1.74452
Value Function Loss: 0.07066

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.54117

Collected Steps per Second: 21,335.52563
Overall Steps per Second: 10,343.05285

Timestep Collection Time: 2.34567
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.83861

Cumulative Model Updates: 110,324
Cumulative Timesteps: 920,285,518

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 920285518...
Checkpoint 920285518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,560.79858
Policy Entropy: 1.75214
Value Function Loss: 0.07097

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 20,708.98002
Overall Steps per Second: 10,202.98704

Timestep Collection Time: 2.41451
Timestep Consumption Time: 2.48621
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.90072

Cumulative Model Updates: 110,330
Cumulative Timesteps: 920,335,520

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,391.67403
Policy Entropy: 1.75493
Value Function Loss: 0.07141

Mean KL Divergence: 0.01862
SB3 Clip Fraction: 0.16810
Policy Update Magnitude: 0.48857
Value Function Update Magnitude: 0.56820

Collected Steps per Second: 21,083.09322
Overall Steps per Second: 10,111.06849

Timestep Collection Time: 2.37185
Timestep Consumption Time: 2.57382
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.94567

Cumulative Model Updates: 110,336
Cumulative Timesteps: 920,385,526

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 920385526...
Checkpoint 920385526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,112.87149
Policy Entropy: 1.76007
Value Function Loss: 0.07496

Mean KL Divergence: 0.02672
SB3 Clip Fraction: 0.20373
Policy Update Magnitude: 0.46676
Value Function Update Magnitude: 0.42335

Collected Steps per Second: 21,089.79846
Overall Steps per Second: 10,228.90761

Timestep Collection Time: 2.37081
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.88811

Cumulative Model Updates: 110,342
Cumulative Timesteps: 920,435,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,939.28634
Policy Entropy: 1.77936
Value Function Loss: 0.07281

Mean KL Divergence: 0.02618
SB3 Clip Fraction: 0.20221
Policy Update Magnitude: 0.49726
Value Function Update Magnitude: 0.43725

Collected Steps per Second: 21,424.09329
Overall Steps per Second: 10,371.60861

Timestep Collection Time: 2.33531
Timestep Consumption Time: 2.48862
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.82394

Cumulative Model Updates: 110,348
Cumulative Timesteps: 920,485,558

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 920485558...
Checkpoint 920485558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,956.71168
Policy Entropy: 1.79603
Value Function Loss: 0.07175

Mean KL Divergence: 0.02504
SB3 Clip Fraction: 0.20109
Policy Update Magnitude: 0.51007
Value Function Update Magnitude: 0.56657

Collected Steps per Second: 21,117.72492
Overall Steps per Second: 10,275.46579

Timestep Collection Time: 2.36777
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.86615

Cumulative Model Updates: 110,354
Cumulative Timesteps: 920,535,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,487.81215
Policy Entropy: 1.81545
Value Function Loss: 0.07435

Mean KL Divergence: 0.02226
SB3 Clip Fraction: 0.19273
Policy Update Magnitude: 0.50575
Value Function Update Magnitude: 0.56275

Collected Steps per Second: 21,516.41477
Overall Steps per Second: 10,209.56173

Timestep Collection Time: 2.32502
Timestep Consumption Time: 2.57490
PPO Batch Consumption Time: 0.29743
Total Iteration Time: 4.89992

Cumulative Model Updates: 110,360
Cumulative Timesteps: 920,585,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 920585586...
Checkpoint 920585586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,417.81992
Policy Entropy: 1.82276
Value Function Loss: 0.08619

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.16557
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.40810

Collected Steps per Second: 21,347.37360
Overall Steps per Second: 10,326.74875

Timestep Collection Time: 2.34305
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.84354

Cumulative Model Updates: 110,366
Cumulative Timesteps: 920,635,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,860.59435
Policy Entropy: 1.83659
Value Function Loss: 0.08800

Mean KL Divergence: 0.02118
SB3 Clip Fraction: 0.19017
Policy Update Magnitude: 0.56476
Value Function Update Magnitude: 0.29275

Collected Steps per Second: 21,212.81887
Overall Steps per Second: 10,152.93008

Timestep Collection Time: 2.35725
Timestep Consumption Time: 2.56783
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.92508

Cumulative Model Updates: 110,372
Cumulative Timesteps: 920,685,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 920685608...
Checkpoint 920685608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,841.43186
Policy Entropy: 1.83915
Value Function Loss: 0.08547

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.16808
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.25614

Collected Steps per Second: 21,206.61887
Overall Steps per Second: 10,160.47847

Timestep Collection Time: 2.35823
Timestep Consumption Time: 2.56379
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.92201

Cumulative Model Updates: 110,378
Cumulative Timesteps: 920,735,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,671.47706
Policy Entropy: 1.83185
Value Function Loss: 0.08974

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15575
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.28066

Collected Steps per Second: 21,425.70157
Overall Steps per Second: 10,258.67260

Timestep Collection Time: 2.33411
Timestep Consumption Time: 2.54079
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.87490

Cumulative Model Updates: 110,384
Cumulative Timesteps: 920,785,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 920785628...
Checkpoint 920785628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,391.93231
Policy Entropy: 1.83123
Value Function Loss: 0.10128

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14541
Policy Update Magnitude: 0.60387
Value Function Update Magnitude: 0.24056

Collected Steps per Second: 21,120.58288
Overall Steps per Second: 10,351.78698

Timestep Collection Time: 2.36916
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.83375

Cumulative Model Updates: 110,390
Cumulative Timesteps: 920,835,666

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,181.84936
Policy Entropy: 1.83123
Value Function Loss: 0.10491

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.61807
Value Function Update Magnitude: 0.21100

Collected Steps per Second: 21,556.75185
Overall Steps per Second: 10,295.73547

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.53834
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.85910

Cumulative Model Updates: 110,396
Cumulative Timesteps: 920,885,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 920885694...
Checkpoint 920885694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,997.95741
Policy Entropy: 1.83228
Value Function Loss: 0.09680

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.58629
Value Function Update Magnitude: 0.21609

Collected Steps per Second: 21,376.29563
Overall Steps per Second: 10,380.17322

Timestep Collection Time: 2.33979
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.81842

Cumulative Model Updates: 110,402
Cumulative Timesteps: 920,935,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,574.89277
Policy Entropy: 1.82071
Value Function Loss: 0.09014

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16780
Policy Update Magnitude: 0.53137
Value Function Update Magnitude: 0.22365

Collected Steps per Second: 21,636.08979
Overall Steps per Second: 10,447.92458

Timestep Collection Time: 2.31188
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.78755

Cumulative Model Updates: 110,408
Cumulative Timesteps: 920,985,730

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 920985730...
Checkpoint 920985730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,972.46233
Policy Entropy: 1.82804
Value Function Loss: 0.09159

Mean KL Divergence: 0.01727
SB3 Clip Fraction: 0.16685
Policy Update Magnitude: 0.51476
Value Function Update Magnitude: 0.21583

Collected Steps per Second: 20,700.72599
Overall Steps per Second: 10,302.13838

Timestep Collection Time: 2.41586
Timestep Consumption Time: 2.43847
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.85433

Cumulative Model Updates: 110,414
Cumulative Timesteps: 921,035,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,271.97416
Policy Entropy: 1.83092
Value Function Loss: 0.11145

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.15841
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.19084

Collected Steps per Second: 20,793.18119
Overall Steps per Second: 10,379.69600

Timestep Collection Time: 2.40502
Timestep Consumption Time: 2.41285
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.81787

Cumulative Model Updates: 110,420
Cumulative Timesteps: 921,085,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 921085748...
Checkpoint 921085748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,951.06128
Policy Entropy: 1.85377
Value Function Loss: 0.09556

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.15151
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.19619

Collected Steps per Second: 20,528.02786
Overall Steps per Second: 10,247.14644

Timestep Collection Time: 2.43647
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.88097

Cumulative Model Updates: 110,426
Cumulative Timesteps: 921,135,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,985.21591
Policy Entropy: 1.85920
Value Function Loss: 0.09939

Mean KL Divergence: 0.01631
SB3 Clip Fraction: 0.16321
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.20134

Collected Steps per Second: 20,986.56142
Overall Steps per Second: 10,429.01383

Timestep Collection Time: 2.38305
Timestep Consumption Time: 2.41242
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.79547

Cumulative Model Updates: 110,432
Cumulative Timesteps: 921,185,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 921185776...
Checkpoint 921185776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,615.46712
Policy Entropy: 1.86300
Value Function Loss: 0.09379

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.15840
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.21091

Collected Steps per Second: 20,841.33138
Overall Steps per Second: 10,168.29539

Timestep Collection Time: 2.40033
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 4.91980

Cumulative Model Updates: 110,438
Cumulative Timesteps: 921,235,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,015.24555
Policy Entropy: 1.84402
Value Function Loss: 0.09409

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.15685
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.18295

Collected Steps per Second: 20,898.35175
Overall Steps per Second: 10,168.46712

Timestep Collection Time: 2.39387
Timestep Consumption Time: 2.52604
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.91992

Cumulative Model Updates: 110,444
Cumulative Timesteps: 921,285,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 921285830...
Checkpoint 921285830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,773.54462
Policy Entropy: 1.82449
Value Function Loss: 0.08351

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.21560

Collected Steps per Second: 21,031.07590
Overall Steps per Second: 10,206.63103

Timestep Collection Time: 2.37896
Timestep Consumption Time: 2.52296
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.90191

Cumulative Model Updates: 110,450
Cumulative Timesteps: 921,335,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,236.05059
Policy Entropy: 1.82794
Value Function Loss: 0.08541

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.28508

Collected Steps per Second: 20,979.03154
Overall Steps per Second: 10,336.10822

Timestep Collection Time: 2.38467
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.84012

Cumulative Model Updates: 110,456
Cumulative Timesteps: 921,385,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 921385890...
Checkpoint 921385890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,618.35849
Policy Entropy: 1.83375
Value Function Loss: 0.07303

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.38997

Collected Steps per Second: 21,472.48428
Overall Steps per Second: 10,321.17583

Timestep Collection Time: 2.32968
Timestep Consumption Time: 2.51706
PPO Batch Consumption Time: 0.29858
Total Iteration Time: 4.84673

Cumulative Model Updates: 110,462
Cumulative Timesteps: 921,435,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,331.02243
Policy Entropy: 1.83494
Value Function Loss: 0.07616

Mean KL Divergence: 0.01842
SB3 Clip Fraction: 0.17340
Policy Update Magnitude: 0.52826
Value Function Update Magnitude: 0.52025

Collected Steps per Second: 21,758.14175
Overall Steps per Second: 10,457.05621

Timestep Collection Time: 2.29817
Timestep Consumption Time: 2.48367
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.78184

Cumulative Model Updates: 110,468
Cumulative Timesteps: 921,485,918

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 921485918...
Checkpoint 921485918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,582.16524
Policy Entropy: 1.84815
Value Function Loss: 0.07170

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.16256
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 21,160.75215
Overall Steps per Second: 10,177.43281

Timestep Collection Time: 2.36305
Timestep Consumption Time: 2.55017
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.91322

Cumulative Model Updates: 110,474
Cumulative Timesteps: 921,535,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,065.97895
Policy Entropy: 1.85024
Value Function Loss: 0.07403

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15577
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 21,503.55868
Overall Steps per Second: 10,385.08445

Timestep Collection Time: 2.32603
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.81633

Cumulative Model Updates: 110,480
Cumulative Timesteps: 921,585,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 921585940...
Checkpoint 921585940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,191.64894
Policy Entropy: 1.85504
Value Function Loss: 0.06780

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.56532
Value Function Update Magnitude: 0.69038

Collected Steps per Second: 21,255.98300
Overall Steps per Second: 10,267.87811

Timestep Collection Time: 2.35425
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.87365

Cumulative Model Updates: 110,486
Cumulative Timesteps: 921,635,982

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,890.71497
Policy Entropy: 1.84966
Value Function Loss: 0.07140

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.57327
Value Function Update Magnitude: 0.61638

Collected Steps per Second: 21,640.87831
Overall Steps per Second: 10,498.47747

Timestep Collection Time: 2.31164
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.76507

Cumulative Model Updates: 110,492
Cumulative Timesteps: 921,686,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 921686008...
Checkpoint 921686008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,245.35985
Policy Entropy: 1.83852
Value Function Loss: 0.07059

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.15223
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.61475

Collected Steps per Second: 20,686.57164
Overall Steps per Second: 10,219.75331

Timestep Collection Time: 2.41751
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.89346

Cumulative Model Updates: 110,498
Cumulative Timesteps: 921,736,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,541.86835
Policy Entropy: 1.84557
Value Function Loss: 0.07602

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.59949
Value Function Update Magnitude: 0.56371

Collected Steps per Second: 21,664.08797
Overall Steps per Second: 10,454.65305

Timestep Collection Time: 2.30898
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.78466

Cumulative Model Updates: 110,504
Cumulative Timesteps: 921,786,040

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 921786040...
Checkpoint 921786040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,505.75046
Policy Entropy: 1.83386
Value Function Loss: 0.07017

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.59433
Value Function Update Magnitude: 0.63746

Collected Steps per Second: 21,036.88292
Overall Steps per Second: 10,219.74766

Timestep Collection Time: 2.37801
Timestep Consumption Time: 2.51702
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.89503

Cumulative Model Updates: 110,510
Cumulative Timesteps: 921,836,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,628.32677
Policy Entropy: 1.83609
Value Function Loss: 0.06313

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.58750
Value Function Update Magnitude: 0.63236

Collected Steps per Second: 21,468.13879
Overall Steps per Second: 10,341.20928

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.50840
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.83967

Cumulative Model Updates: 110,516
Cumulative Timesteps: 921,886,114

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 921886114...
Checkpoint 921886114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,509.73254
Policy Entropy: 1.82220
Value Function Loss: 0.05806

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.65102

Collected Steps per Second: 20,691.36882
Overall Steps per Second: 10,226.78880

Timestep Collection Time: 2.41792
Timestep Consumption Time: 2.47414
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.89205

Cumulative Model Updates: 110,522
Cumulative Timesteps: 921,936,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,244.71268
Policy Entropy: 1.81999
Value Function Loss: 0.06611

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.62884

Collected Steps per Second: 21,470.02143
Overall Steps per Second: 10,416.10237

Timestep Collection Time: 2.33023
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.80314

Cumulative Model Updates: 110,528
Cumulative Timesteps: 921,986,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 921986174...
Checkpoint 921986174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,810.80219
Policy Entropy: 1.81691
Value Function Loss: 0.07004

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.14626
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 20,739.28374
Overall Steps per Second: 10,231.23679

Timestep Collection Time: 2.41185
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.88895

Cumulative Model Updates: 110,534
Cumulative Timesteps: 922,036,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,614.91155
Policy Entropy: 1.83119
Value Function Loss: 0.07201

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.56202
Value Function Update Magnitude: 0.68337

Collected Steps per Second: 21,611.87759
Overall Steps per Second: 10,417.56248

Timestep Collection Time: 2.31549
Timestep Consumption Time: 2.48813
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.80362

Cumulative Model Updates: 110,540
Cumulative Timesteps: 922,086,236

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 922086236...
Checkpoint 922086236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,273.41255
Policy Entropy: 1.83287
Value Function Loss: 0.07145

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.71935

Collected Steps per Second: 20,987.03522
Overall Steps per Second: 10,267.45602

Timestep Collection Time: 2.38299
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.87092

Cumulative Model Updates: 110,546
Cumulative Timesteps: 922,136,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,821.66831
Policy Entropy: 1.81955
Value Function Loss: 0.07246

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.59744
Value Function Update Magnitude: 0.67745

Collected Steps per Second: 21,626.33106
Overall Steps per Second: 10,435.94587

Timestep Collection Time: 2.31209
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.79132

Cumulative Model Updates: 110,552
Cumulative Timesteps: 922,186,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 922186250...
Checkpoint 922186250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,311.75820
Policy Entropy: 1.81812
Value Function Loss: 0.07247

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.59413
Value Function Update Magnitude: 0.67287

Collected Steps per Second: 20,175.03883
Overall Steps per Second: 9,916.40797

Timestep Collection Time: 2.47930
Timestep Consumption Time: 2.56486
PPO Batch Consumption Time: 0.29790
Total Iteration Time: 5.04417

Cumulative Model Updates: 110,558
Cumulative Timesteps: 922,236,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,026.92703
Policy Entropy: 1.81229
Value Function Loss: 0.06628

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.69472

Collected Steps per Second: 21,332.29788
Overall Steps per Second: 10,345.19904

Timestep Collection Time: 2.34461
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.83471

Cumulative Model Updates: 110,564
Cumulative Timesteps: 922,286,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 922286286...
Checkpoint 922286286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,512.74173
Policy Entropy: 1.81556
Value Function Loss: 0.06297

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 20,947.50913
Overall Steps per Second: 10,248.68093

Timestep Collection Time: 2.38749
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.87985

Cumulative Model Updates: 110,570
Cumulative Timesteps: 922,336,298

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,377.20191
Policy Entropy: 1.80459
Value Function Loss: 0.06249

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.14424
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.59498

Collected Steps per Second: 21,548.56135
Overall Steps per Second: 10,438.08962

Timestep Collection Time: 2.32090
Timestep Consumption Time: 2.47040
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.79130

Cumulative Model Updates: 110,576
Cumulative Timesteps: 922,386,310

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 922386310...
Checkpoint 922386310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,526.43053
Policy Entropy: 1.81169
Value Function Loss: 0.06253

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.57753
Value Function Update Magnitude: 0.59381

Collected Steps per Second: 20,747.27607
Overall Steps per Second: 10,235.04551

Timestep Collection Time: 2.41092
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.88713

Cumulative Model Updates: 110,582
Cumulative Timesteps: 922,436,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,601.30293
Policy Entropy: 1.80108
Value Function Loss: 0.06557

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.58012
Value Function Update Magnitude: 0.55363

Collected Steps per Second: 21,798.42687
Overall Steps per Second: 10,439.58152

Timestep Collection Time: 2.29466
Timestep Consumption Time: 2.49672
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.79138

Cumulative Model Updates: 110,588
Cumulative Timesteps: 922,486,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 922486350...
Checkpoint 922486350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,745.57429
Policy Entropy: 1.80296
Value Function Loss: 0.06701

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13220
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.57272

Collected Steps per Second: 20,721.52321
Overall Steps per Second: 10,191.68429

Timestep Collection Time: 2.41334
Timestep Consumption Time: 2.49341
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.90675

Cumulative Model Updates: 110,594
Cumulative Timesteps: 922,536,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,009.63729
Policy Entropy: 1.80025
Value Function Loss: 0.07354

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.43784

Collected Steps per Second: 21,141.80628
Overall Steps per Second: 10,204.94600

Timestep Collection Time: 2.36650
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.90272

Cumulative Model Updates: 110,600
Cumulative Timesteps: 922,586,390

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 922586390...
Checkpoint 922586390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,420.23183
Policy Entropy: 1.79469
Value Function Loss: 0.07432

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.33073

Collected Steps per Second: 20,921.94900
Overall Steps per Second: 10,112.62746

Timestep Collection Time: 2.39003
Timestep Consumption Time: 2.55468
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.94471

Cumulative Model Updates: 110,606
Cumulative Timesteps: 922,636,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,567.32909
Policy Entropy: 1.80060
Value Function Loss: 0.07513

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.59521
Value Function Update Magnitude: 0.40012

Collected Steps per Second: 21,590.26037
Overall Steps per Second: 10,381.54481

Timestep Collection Time: 2.31679
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.81817

Cumulative Model Updates: 110,612
Cumulative Timesteps: 922,686,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 922686414...
Checkpoint 922686414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,904.90578
Policy Entropy: 1.79683
Value Function Loss: 0.07804

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.60024
Value Function Update Magnitude: 0.44401

Collected Steps per Second: 20,998.94716
Overall Steps per Second: 10,213.17778

Timestep Collection Time: 2.38250
Timestep Consumption Time: 2.51607
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.89857

Cumulative Model Updates: 110,618
Cumulative Timesteps: 922,736,444

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,010.41384
Policy Entropy: 1.79764
Value Function Loss: 0.08057

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.60084
Value Function Update Magnitude: 0.43018

Collected Steps per Second: 21,361.05410
Overall Steps per Second: 10,396.43081

Timestep Collection Time: 2.34118
Timestep Consumption Time: 2.46913
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.81030

Cumulative Model Updates: 110,624
Cumulative Timesteps: 922,786,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 922786454...
Checkpoint 922786454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,449.99953
Policy Entropy: 1.79324
Value Function Loss: 0.08229

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.59753
Value Function Update Magnitude: 0.37478

Collected Steps per Second: 20,890.43092
Overall Steps per Second: 10,246.79833

Timestep Collection Time: 2.39488
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.88250

Cumulative Model Updates: 110,630
Cumulative Timesteps: 922,836,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,889.26524
Policy Entropy: 1.81414
Value Function Loss: 0.08494

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.60399
Value Function Update Magnitude: 0.29695

Collected Steps per Second: 21,686.42964
Overall Steps per Second: 10,424.83549

Timestep Collection Time: 2.30679
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.79873

Cumulative Model Updates: 110,636
Cumulative Timesteps: 922,886,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 922886510...
Checkpoint 922886510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,906.09349
Policy Entropy: 1.82075
Value Function Loss: 0.08006

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.30802

Collected Steps per Second: 21,377.19592
Overall Steps per Second: 10,273.64321

Timestep Collection Time: 2.33894
Timestep Consumption Time: 2.52788
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.86682

Cumulative Model Updates: 110,642
Cumulative Timesteps: 922,936,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,364.36088
Policy Entropy: 1.81750
Value Function Loss: 0.07201

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.59401
Value Function Update Magnitude: 0.44790

Collected Steps per Second: 20,942.48641
Overall Steps per Second: 10,426.94768

Timestep Collection Time: 2.38854
Timestep Consumption Time: 2.40884
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.79738

Cumulative Model Updates: 110,648
Cumulative Timesteps: 922,986,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 922986532...
Checkpoint 922986532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,580.01741
Policy Entropy: 1.80266
Value Function Loss: 0.06705

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14039
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.39170

Collected Steps per Second: 20,630.59331
Overall Steps per Second: 10,225.82204

Timestep Collection Time: 2.42388
Timestep Consumption Time: 2.46629
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.89017

Cumulative Model Updates: 110,654
Cumulative Timesteps: 923,036,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,628.70435
Policy Entropy: 1.80508
Value Function Loss: 0.06617

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.38501

Collected Steps per Second: 20,923.86439
Overall Steps per Second: 10,418.91298

Timestep Collection Time: 2.38990
Timestep Consumption Time: 2.40964
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.79954

Cumulative Model Updates: 110,660
Cumulative Timesteps: 923,086,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 923086544...
Checkpoint 923086544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,190.89089
Policy Entropy: 1.80229
Value Function Loss: 0.07094

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.57903
Value Function Update Magnitude: 0.50585

Collected Steps per Second: 20,756.68455
Overall Steps per Second: 10,248.37539

Timestep Collection Time: 2.41002
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.88116

Cumulative Model Updates: 110,666
Cumulative Timesteps: 923,136,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,797.79001
Policy Entropy: 1.78858
Value Function Loss: 0.06736

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.54785

Collected Steps per Second: 20,491.74200
Overall Steps per Second: 9,910.00783

Timestep Collection Time: 2.44128
Timestep Consumption Time: 2.60675
PPO Batch Consumption Time: 0.31204
Total Iteration Time: 5.04803

Cumulative Model Updates: 110,672
Cumulative Timesteps: 923,186,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 923186594...
Checkpoint 923186594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,990.09941
Policy Entropy: 1.78353
Value Function Loss: 0.06685

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13875
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.53472

Collected Steps per Second: 21,488.49151
Overall Steps per Second: 10,358.16918

Timestep Collection Time: 2.32785
Timestep Consumption Time: 2.50138
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.82923

Cumulative Model Updates: 110,678
Cumulative Timesteps: 923,236,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,102.46439
Policy Entropy: 1.76749
Value Function Loss: 0.06678

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.53430
Value Function Update Magnitude: 0.52834

Collected Steps per Second: 21,422.52172
Overall Steps per Second: 10,409.90190

Timestep Collection Time: 2.33577
Timestep Consumption Time: 2.47100
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.80677

Cumulative Model Updates: 110,684
Cumulative Timesteps: 923,286,654

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 923286654...
Checkpoint 923286654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,835.76835
Policy Entropy: 1.77995
Value Function Loss: 0.07501

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.56684
Value Function Update Magnitude: 0.49960

Collected Steps per Second: 21,409.92668
Overall Steps per Second: 10,304.70035

Timestep Collection Time: 2.33723
Timestep Consumption Time: 2.51880
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.85604

Cumulative Model Updates: 110,690
Cumulative Timesteps: 923,336,694

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,923.25246
Policy Entropy: 1.77348
Value Function Loss: 0.07866

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.44063

Collected Steps per Second: 21,477.05673
Overall Steps per Second: 10,452.38925

Timestep Collection Time: 2.32872
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.78493

Cumulative Model Updates: 110,696
Cumulative Timesteps: 923,386,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 923386708...
Checkpoint 923386708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,334.65148
Policy Entropy: 1.78409
Value Function Loss: 0.08409

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.46163

Collected Steps per Second: 21,549.23881
Overall Steps per Second: 10,325.54530

Timestep Collection Time: 2.32138
Timestep Consumption Time: 2.52330
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.84468

Cumulative Model Updates: 110,702
Cumulative Timesteps: 923,436,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,800.50869
Policy Entropy: 1.77832
Value Function Loss: 0.07989

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.16042
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.46775

Collected Steps per Second: 21,560.03238
Overall Steps per Second: 10,311.02173

Timestep Collection Time: 2.31957
Timestep Consumption Time: 2.53058
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.85015

Cumulative Model Updates: 110,708
Cumulative Timesteps: 923,486,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923486742...
Checkpoint 923486742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,398.85922
Policy Entropy: 1.79374
Value Function Loss: 0.07268

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.49663

Collected Steps per Second: 21,376.75740
Overall Steps per Second: 10,249.80634

Timestep Collection Time: 2.33918
Timestep Consumption Time: 2.53936
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.87853

Cumulative Model Updates: 110,714
Cumulative Timesteps: 923,536,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,513.55823
Policy Entropy: 1.78431
Value Function Loss: 0.06594

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.64341

Collected Steps per Second: 21,403.21680
Overall Steps per Second: 10,362.30259

Timestep Collection Time: 2.33750
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.82808

Cumulative Model Updates: 110,720
Cumulative Timesteps: 923,586,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 923586776...
Checkpoint 923586776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,214.13676
Policy Entropy: 1.77011
Value Function Loss: 0.06514

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14968
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.68980

Collected Steps per Second: 21,256.51712
Overall Steps per Second: 10,248.88390

Timestep Collection Time: 2.35288
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.87995

Cumulative Model Updates: 110,726
Cumulative Timesteps: 923,636,790

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,026.15972
Policy Entropy: 1.76591
Value Function Loss: 0.06934

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.57969
Value Function Update Magnitude: 0.66730

Collected Steps per Second: 21,405.05431
Overall Steps per Second: 10,358.54315

Timestep Collection Time: 2.33590
Timestep Consumption Time: 2.49104
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.82693

Cumulative Model Updates: 110,732
Cumulative Timesteps: 923,686,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 923686790...
Checkpoint 923686790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,774.59632
Policy Entropy: 1.76254
Value Function Loss: 0.07643

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14330
Policy Update Magnitude: 0.59930
Value Function Update Magnitude: 0.59803

Collected Steps per Second: 20,596.38908
Overall Steps per Second: 10,215.33139

Timestep Collection Time: 2.42771
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.89480

Cumulative Model Updates: 110,738
Cumulative Timesteps: 923,736,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,980.31167
Policy Entropy: 1.77380
Value Function Loss: 0.07289

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14812
Policy Update Magnitude: 0.59043
Value Function Update Magnitude: 0.59373

Collected Steps per Second: 21,123.95580
Overall Steps per Second: 10,181.95402

Timestep Collection Time: 2.36745
Timestep Consumption Time: 2.54418
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.91163

Cumulative Model Updates: 110,744
Cumulative Timesteps: 923,786,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923786802...
Checkpoint 923786802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,117.63205
Policy Entropy: 1.76767
Value Function Loss: 0.06848

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.15201
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 21,590.25909
Overall Steps per Second: 10,455.11899

Timestep Collection Time: 2.31641
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.78349

Cumulative Model Updates: 110,750
Cumulative Timesteps: 923,836,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,191.25654
Policy Entropy: 1.76719
Value Function Loss: 0.06732

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.57716
Value Function Update Magnitude: 0.58486

Collected Steps per Second: 20,902.33959
Overall Steps per Second: 10,108.67359

Timestep Collection Time: 2.39447
Timestep Consumption Time: 2.55672
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.95119

Cumulative Model Updates: 110,756
Cumulative Timesteps: 923,886,864

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 923886864...
Checkpoint 923886864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,850.94983
Policy Entropy: 1.76933
Value Function Loss: 0.06797

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.62103

Collected Steps per Second: 21,376.67970
Overall Steps per Second: 10,221.71860

Timestep Collection Time: 2.34106
Timestep Consumption Time: 2.55479
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.89585

Cumulative Model Updates: 110,762
Cumulative Timesteps: 923,936,908

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,518.99856
Policy Entropy: 1.76548
Value Function Loss: 0.06734

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.58642

Collected Steps per Second: 21,397.67853
Overall Steps per Second: 10,384.37422

Timestep Collection Time: 2.33782
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.81724

Cumulative Model Updates: 110,768
Cumulative Timesteps: 923,986,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 923986932...
Checkpoint 923986932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,327.85000
Policy Entropy: 1.76225
Value Function Loss: 0.06247

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13686
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.56303

Collected Steps per Second: 21,382.39616
Overall Steps per Second: 10,308.54020

Timestep Collection Time: 2.33847
Timestep Consumption Time: 2.51208
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.85054

Cumulative Model Updates: 110,774
Cumulative Timesteps: 924,036,934

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,141.97686
Policy Entropy: 1.76147
Value Function Loss: 0.06015

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.50745
Value Function Update Magnitude: 0.65610

Collected Steps per Second: 20,882.20728
Overall Steps per Second: 10,107.38960

Timestep Collection Time: 2.39477
Timestep Consumption Time: 2.55290
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.94767

Cumulative Model Updates: 110,780
Cumulative Timesteps: 924,086,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 924086942...
Checkpoint 924086942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,377.59173
Policy Entropy: 1.75698
Value Function Loss: 0.06111

Mean KL Divergence: 0.01863
SB3 Clip Fraction: 0.16849
Policy Update Magnitude: 0.47395
Value Function Update Magnitude: 0.68460

Collected Steps per Second: 21,217.65756
Overall Steps per Second: 10,248.45256

Timestep Collection Time: 2.35775
Timestep Consumption Time: 2.52357
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.88132

Cumulative Model Updates: 110,786
Cumulative Timesteps: 924,136,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,601.54016
Policy Entropy: 1.75250
Value Function Loss: 0.06436

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15060
Policy Update Magnitude: 0.50164
Value Function Update Magnitude: 0.66217

Collected Steps per Second: 20,696.09440
Overall Steps per Second: 10,296.28602

Timestep Collection Time: 2.41601
Timestep Consumption Time: 2.44030
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.85631

Cumulative Model Updates: 110,792
Cumulative Timesteps: 924,186,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924186970...
Checkpoint 924186970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,371.85297
Policy Entropy: 1.75312
Value Function Loss: 0.06808

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.56329
Value Function Update Magnitude: 0.69131

Collected Steps per Second: 20,380.48906
Overall Steps per Second: 10,205.34106

Timestep Collection Time: 2.45333
Timestep Consumption Time: 2.44607
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.89940

Cumulative Model Updates: 110,798
Cumulative Timesteps: 924,236,970

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,784.13141
Policy Entropy: 1.75439
Value Function Loss: 0.07156

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.59067
Value Function Update Magnitude: 0.75477

Collected Steps per Second: 21,193.77648
Overall Steps per Second: 10,707.42429

Timestep Collection Time: 2.35928
Timestep Consumption Time: 2.31057
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.66984

Cumulative Model Updates: 110,804
Cumulative Timesteps: 924,286,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924286972...
Checkpoint 924286972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,502.49468
Policy Entropy: 1.76255
Value Function Loss: 0.06989

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16668
Policy Update Magnitude: 0.55220
Value Function Update Magnitude: 0.77078

Collected Steps per Second: 20,816.50646
Overall Steps per Second: 10,358.22187

Timestep Collection Time: 2.40204
Timestep Consumption Time: 2.42524
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.82728

Cumulative Model Updates: 110,810
Cumulative Timesteps: 924,336,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,851.98172
Policy Entropy: 1.76953
Value Function Loss: 0.07580

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.17203
Policy Update Magnitude: 0.50137
Value Function Update Magnitude: 0.67751

Collected Steps per Second: 19,837.39051
Overall Steps per Second: 9,807.51680

Timestep Collection Time: 2.52150
Timestep Consumption Time: 2.57867
PPO Batch Consumption Time: 0.31001
Total Iteration Time: 5.10017

Cumulative Model Updates: 110,816
Cumulative Timesteps: 924,386,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 924386994...
Checkpoint 924386994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,912.60021
Policy Entropy: 1.76268
Value Function Loss: 0.07255

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.16182
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.70471

Collected Steps per Second: 20,864.41558
Overall Steps per Second: 10,531.05939

Timestep Collection Time: 2.39767
Timestep Consumption Time: 2.35266
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.75033

Cumulative Model Updates: 110,822
Cumulative Timesteps: 924,437,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,262.62375
Policy Entropy: 1.75526
Value Function Loss: 0.06865

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15727
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.70621

Collected Steps per Second: 20,857.51733
Overall Steps per Second: 10,244.44345

Timestep Collection Time: 2.39750
Timestep Consumption Time: 2.48378
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.88128

Cumulative Model Updates: 110,828
Cumulative Timesteps: 924,487,026

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 924487026...
Checkpoint 924487026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,846.51428
Policy Entropy: 1.75138
Value Function Loss: 0.06879

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15419
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.53246

Collected Steps per Second: 21,069.22972
Overall Steps per Second: 10,362.39854

Timestep Collection Time: 2.37465
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.82823

Cumulative Model Updates: 110,834
Cumulative Timesteps: 924,537,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,323.36300
Policy Entropy: 1.75746
Value Function Loss: 0.07130

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.57470
Value Function Update Magnitude: 0.39573

Collected Steps per Second: 21,597.80874
Overall Steps per Second: 10,409.77389

Timestep Collection Time: 2.31644
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.80606

Cumulative Model Updates: 110,840
Cumulative Timesteps: 924,587,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 924587088...
Checkpoint 924587088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,807.98930
Policy Entropy: 1.75242
Value Function Loss: 0.07817

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14650
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.32677

Collected Steps per Second: 21,202.88634
Overall Steps per Second: 10,275.61014

Timestep Collection Time: 2.35921
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.86803

Cumulative Model Updates: 110,846
Cumulative Timesteps: 924,637,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,915.67521
Policy Entropy: 1.74744
Value Function Loss: 0.07621

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.37713

Collected Steps per Second: 21,351.45328
Overall Steps per Second: 10,365.42430

Timestep Collection Time: 2.34326
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.82682

Cumulative Model Updates: 110,852
Cumulative Timesteps: 924,687,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 924687142...
Checkpoint 924687142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,667.39579
Policy Entropy: 1.75359
Value Function Loss: 0.06995

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.63322

Collected Steps per Second: 21,292.42481
Overall Steps per Second: 10,321.18475

Timestep Collection Time: 2.34863
Timestep Consumption Time: 2.49655
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.84518

Cumulative Model Updates: 110,858
Cumulative Timesteps: 924,737,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,221.26862
Policy Entropy: 1.76758
Value Function Loss: 0.06838

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14504
Policy Update Magnitude: 0.58597
Value Function Update Magnitude: 0.65816

Collected Steps per Second: 21,686.60676
Overall Steps per Second: 10,435.45032

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.79251

Cumulative Model Updates: 110,864
Cumulative Timesteps: 924,787,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 924787162...
Checkpoint 924787162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,554.79027
Policy Entropy: 1.78012
Value Function Loss: 0.06157

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15534
Policy Update Magnitude: 0.56894
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 21,019.80910
Overall Steps per Second: 10,209.14877

Timestep Collection Time: 2.37976
Timestep Consumption Time: 2.51997
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.89972

Cumulative Model Updates: 110,870
Cumulative Timesteps: 924,837,184

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,455.18242
Policy Entropy: 1.79002
Value Function Loss: 0.06297

Mean KL Divergence: 0.01714
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.55736
Value Function Update Magnitude: 0.53830

Collected Steps per Second: 21,196.41337
Overall Steps per Second: 10,369.26246

Timestep Collection Time: 2.35898
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.82214

Cumulative Model Updates: 110,876
Cumulative Timesteps: 924,887,186

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924887186...
Checkpoint 924887186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,640.17674
Policy Entropy: 1.79590
Value Function Loss: 0.06318

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.56386

Collected Steps per Second: 21,098.95753
Overall Steps per Second: 10,322.81461

Timestep Collection Time: 2.37121
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.84655

Cumulative Model Updates: 110,882
Cumulative Timesteps: 924,937,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,990.92166
Policy Entropy: 1.78992
Value Function Loss: 0.07545

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.48989

Collected Steps per Second: 21,566.30660
Overall Steps per Second: 10,401.68592

Timestep Collection Time: 2.31871
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.80749

Cumulative Model Updates: 110,888
Cumulative Timesteps: 924,987,222

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 924987222...
Checkpoint 924987222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,069.13166
Policy Entropy: 1.79173
Value Function Loss: 0.08193

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.60415
Value Function Update Magnitude: 0.53914

Collected Steps per Second: 21,113.68908
Overall Steps per Second: 10,244.05246

Timestep Collection Time: 2.36974
Timestep Consumption Time: 2.51446
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.88420

Cumulative Model Updates: 110,894
Cumulative Timesteps: 925,037,256

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,708.19106
Policy Entropy: 1.79193
Value Function Loss: 0.07681

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15899
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.62958

Collected Steps per Second: 21,506.85794
Overall Steps per Second: 10,405.44729

Timestep Collection Time: 2.32530
Timestep Consumption Time: 2.48083
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.80614

Cumulative Model Updates: 110,900
Cumulative Timesteps: 925,087,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 925087266...
Checkpoint 925087266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,126.88871
Policy Entropy: 1.79491
Value Function Loss: 0.07023

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.56760
Value Function Update Magnitude: 0.60656

Collected Steps per Second: 20,893.12402
Overall Steps per Second: 10,267.90366

Timestep Collection Time: 2.39342
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.87013

Cumulative Model Updates: 110,906
Cumulative Timesteps: 925,137,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,074.80536
Policy Entropy: 1.79039
Value Function Loss: 0.06837

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14034
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 21,726.15208
Overall Steps per Second: 10,489.70404

Timestep Collection Time: 2.30266
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.76925

Cumulative Model Updates: 110,912
Cumulative Timesteps: 925,187,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 925187300...
Checkpoint 925187300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,217.36506
Policy Entropy: 1.78215
Value Function Loss: 0.06939

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14665
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.64606

Collected Steps per Second: 21,032.28872
Overall Steps per Second: 10,166.38005

Timestep Collection Time: 2.37787
Timestep Consumption Time: 2.54148
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.91935

Cumulative Model Updates: 110,918
Cumulative Timesteps: 925,237,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,309.76623
Policy Entropy: 1.78532
Value Function Loss: 0.07425

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15114
Policy Update Magnitude: 0.57852
Value Function Update Magnitude: 0.56300

Collected Steps per Second: 21,642.20239
Overall Steps per Second: 10,437.13577

Timestep Collection Time: 2.31095
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.79193

Cumulative Model Updates: 110,924
Cumulative Timesteps: 925,287,326

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 925287326...
Checkpoint 925287326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,267.37565
Policy Entropy: 1.78696
Value Function Loss: 0.07243

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.57818
Value Function Update Magnitude: 0.49334

Collected Steps per Second: 21,051.26059
Overall Steps per Second: 10,202.97385

Timestep Collection Time: 2.37553
Timestep Consumption Time: 2.52578
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.90132

Cumulative Model Updates: 110,930
Cumulative Timesteps: 925,337,334

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,063.16918
Policy Entropy: 1.79630
Value Function Loss: 0.07133

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.59667
Value Function Update Magnitude: 0.52523

Collected Steps per Second: 21,355.36317
Overall Steps per Second: 10,394.54914

Timestep Collection Time: 2.34199
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.81156

Cumulative Model Updates: 110,936
Cumulative Timesteps: 925,387,348

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 925387348...
Checkpoint 925387348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,331.92019
Policy Entropy: 1.79933
Value Function Loss: 0.07199

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.58820
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 21,215.17000
Overall Steps per Second: 10,254.93653

Timestep Collection Time: 2.35822
Timestep Consumption Time: 2.52041
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.87863

Cumulative Model Updates: 110,942
Cumulative Timesteps: 925,437,378

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,963.48794
Policy Entropy: 1.79136
Value Function Loss: 0.06661

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.57815
Value Function Update Magnitude: 0.73100

Collected Steps per Second: 20,556.94835
Overall Steps per Second: 10,290.78813

Timestep Collection Time: 2.43256
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.85930

Cumulative Model Updates: 110,948
Cumulative Timesteps: 925,487,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 925487384...
Checkpoint 925487384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,234.92078
Policy Entropy: 1.78887
Value Function Loss: 0.06209

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.57108
Value Function Update Magnitude: 0.66737

Collected Steps per Second: 20,384.17010
Overall Steps per Second: 10,302.49997

Timestep Collection Time: 2.45436
Timestep Consumption Time: 2.40175
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.85610

Cumulative Model Updates: 110,954
Cumulative Timesteps: 925,537,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,889.74578
Policy Entropy: 1.79409
Value Function Loss: 0.06414

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.58850
Value Function Update Magnitude: 0.69423

Collected Steps per Second: 20,783.84305
Overall Steps per Second: 10,307.50185

Timestep Collection Time: 2.40687
Timestep Consumption Time: 2.44629
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.85316

Cumulative Model Updates: 110,960
Cumulative Timesteps: 925,587,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 925587438...
Checkpoint 925587438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,466.50539
Policy Entropy: 1.78671
Value Function Loss: 0.06790

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14336
Policy Update Magnitude: 0.59505
Value Function Update Magnitude: 0.72835

Collected Steps per Second: 20,792.40148
Overall Steps per Second: 10,418.33953

Timestep Collection Time: 2.40588
Timestep Consumption Time: 2.39565
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.80153

Cumulative Model Updates: 110,966
Cumulative Timesteps: 925,637,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,853.43435
Policy Entropy: 1.78508
Value Function Loss: 0.06973

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14848
Policy Update Magnitude: 0.58234
Value Function Update Magnitude: 0.73577

Collected Steps per Second: 20,656.57831
Overall Steps per Second: 10,384.68997

Timestep Collection Time: 2.42092
Timestep Consumption Time: 2.39463
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.81555

Cumulative Model Updates: 110,972
Cumulative Timesteps: 925,687,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 925687470...
Checkpoint 925687470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,009.82841
Policy Entropy: 1.78598
Value Function Loss: 0.06649

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.15155
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.73287

Collected Steps per Second: 20,770.97221
Overall Steps per Second: 10,262.04408

Timestep Collection Time: 2.40778
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.87349

Cumulative Model Updates: 110,978
Cumulative Timesteps: 925,737,482

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,535.17657
Policy Entropy: 1.79734
Value Function Loss: 0.06086

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.16906
Policy Update Magnitude: 0.49593
Value Function Update Magnitude: 0.67873

Collected Steps per Second: 21,384.61835
Overall Steps per Second: 10,448.66659

Timestep Collection Time: 2.33972
Timestep Consumption Time: 2.44883
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.78855

Cumulative Model Updates: 110,984
Cumulative Timesteps: 925,787,516

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 925787516...
Checkpoint 925787516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,461.37982
Policy Entropy: 1.80645
Value Function Loss: 0.06288

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.16233
Policy Update Magnitude: 0.47689
Value Function Update Magnitude: 0.67739

Collected Steps per Second: 21,455.91990
Overall Steps per Second: 10,312.28306

Timestep Collection Time: 2.33176
Timestep Consumption Time: 2.51974
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.85150

Cumulative Model Updates: 110,990
Cumulative Timesteps: 925,837,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,490.71768
Policy Entropy: 1.81438
Value Function Loss: 0.07527

Mean KL Divergence: 0.02519
SB3 Clip Fraction: 0.18967
Policy Update Magnitude: 0.50158
Value Function Update Magnitude: 0.66234

Collected Steps per Second: 21,539.92184
Overall Steps per Second: 10,367.90498

Timestep Collection Time: 2.32239
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.82489

Cumulative Model Updates: 110,996
Cumulative Timesteps: 925,887,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 925887570...
Checkpoint 925887570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,473.76766
Policy Entropy: 1.81040
Value Function Loss: 0.07315

Mean KL Divergence: 0.02101
SB3 Clip Fraction: 0.17998
Policy Update Magnitude: 0.50256
Value Function Update Magnitude: 0.63954

Collected Steps per Second: 21,283.83269
Overall Steps per Second: 10,204.92494

Timestep Collection Time: 2.35023
Timestep Consumption Time: 2.55152
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.90175

Cumulative Model Updates: 111,002
Cumulative Timesteps: 925,937,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,936.71756
Policy Entropy: 1.81115
Value Function Loss: 0.07481

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.16756
Policy Update Magnitude: 0.51604
Value Function Update Magnitude: 0.53972

Collected Steps per Second: 21,179.14731
Overall Steps per Second: 10,187.05321

Timestep Collection Time: 2.36110
Timestep Consumption Time: 2.54768
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.90878

Cumulative Model Updates: 111,008
Cumulative Timesteps: 925,987,598

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 925987598...
Checkpoint 925987598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,189.64447
Policy Entropy: 1.79532
Value Function Loss: 0.06303

Mean KL Divergence: 0.01655
SB3 Clip Fraction: 0.15925
Policy Update Magnitude: 0.50581
Value Function Update Magnitude: 0.67268

Collected Steps per Second: 21,726.36792
Overall Steps per Second: 10,453.92145

Timestep Collection Time: 2.30209
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.78442

Cumulative Model Updates: 111,014
Cumulative Timesteps: 926,037,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,379.63846
Policy Entropy: 1.80248
Value Function Loss: 0.06716

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.16797
Policy Update Magnitude: 0.49804
Value Function Update Magnitude: 0.70555

Collected Steps per Second: 21,412.65397
Overall Steps per Second: 10,280.00205

Timestep Collection Time: 2.33656
Timestep Consumption Time: 2.53036
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.86693

Cumulative Model Updates: 111,020
Cumulative Timesteps: 926,087,646

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 926087646...
Checkpoint 926087646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,900.14256
Policy Entropy: 1.81407
Value Function Loss: 0.07154

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.16225
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.66920

Collected Steps per Second: 21,123.24826
Overall Steps per Second: 10,244.38019

Timestep Collection Time: 2.36753
Timestep Consumption Time: 2.51417
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.88170

Cumulative Model Updates: 111,026
Cumulative Timesteps: 926,137,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,287.16122
Policy Entropy: 1.82342
Value Function Loss: 0.08440

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.61248
Value Function Update Magnitude: 0.54318

Collected Steps per Second: 21,275.05972
Overall Steps per Second: 10,240.34589

Timestep Collection Time: 2.35064
Timestep Consumption Time: 2.53298
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.88362

Cumulative Model Updates: 111,032
Cumulative Timesteps: 926,187,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 926187666...
Checkpoint 926187666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,921.83390
Policy Entropy: 1.81225
Value Function Loss: 0.08229

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.15461
Policy Update Magnitude: 0.61670
Value Function Update Magnitude: 0.50119

Collected Steps per Second: 21,463.35140
Overall Steps per Second: 10,297.17360

Timestep Collection Time: 2.32965
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.85590

Cumulative Model Updates: 111,038
Cumulative Timesteps: 926,237,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,920.50799
Policy Entropy: 1.81331
Value Function Loss: 0.07805

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.56345

Collected Steps per Second: 21,515.57348
Overall Steps per Second: 10,304.45056

Timestep Collection Time: 2.32492
Timestep Consumption Time: 2.52949
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.85441

Cumulative Model Updates: 111,044
Cumulative Timesteps: 926,287,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 926287690...
Checkpoint 926287690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,311.79110
Policy Entropy: 1.83690
Value Function Loss: 0.06976

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.17356
Policy Update Magnitude: 0.53810
Value Function Update Magnitude: 0.62776

Collected Steps per Second: 21,101.97051
Overall Steps per Second: 10,218.92482

Timestep Collection Time: 2.36973
Timestep Consumption Time: 2.52374
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.89347

Cumulative Model Updates: 111,050
Cumulative Timesteps: 926,337,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,644.06630
Policy Entropy: 1.84601
Value Function Loss: 0.06643

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.64096

Collected Steps per Second: 21,496.25748
Overall Steps per Second: 10,285.32532

Timestep Collection Time: 2.32627
Timestep Consumption Time: 2.53561
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.86188

Cumulative Model Updates: 111,056
Cumulative Timesteps: 926,387,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 926387702...
Checkpoint 926387702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,584.03648
Policy Entropy: 1.83183
Value Function Loss: 0.06491

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.15403
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 20,987.62287
Overall Steps per Second: 10,280.96408

Timestep Collection Time: 2.38255
Timestep Consumption Time: 2.48120
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.86375

Cumulative Model Updates: 111,062
Cumulative Timesteps: 926,437,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,788.97426
Policy Entropy: 1.80911
Value Function Loss: 0.07015

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.51241

Collected Steps per Second: 20,649.64660
Overall Steps per Second: 10,221.67079

Timestep Collection Time: 2.42270
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.89431

Cumulative Model Updates: 111,068
Cumulative Timesteps: 926,487,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 926487734...
Checkpoint 926487734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,944.35974
Policy Entropy: 1.80979
Value Function Loss: 0.07528

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.60097
Value Function Update Magnitude: 0.63552

Collected Steps per Second: 20,887.22854
Overall Steps per Second: 10,457.56867

Timestep Collection Time: 2.39620
Timestep Consumption Time: 2.38981
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.78601

Cumulative Model Updates: 111,074
Cumulative Timesteps: 926,537,784

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,819.82040
Policy Entropy: 1.81238
Value Function Loss: 0.07619

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.61013
Value Function Update Magnitude: 0.65060

Collected Steps per Second: 20,540.49181
Overall Steps per Second: 10,184.43409

Timestep Collection Time: 2.43577
Timestep Consumption Time: 2.47682
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.91260

Cumulative Model Updates: 111,080
Cumulative Timesteps: 926,587,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 926587816...
Checkpoint 926587816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,403.69301
Policy Entropy: 1.81911
Value Function Loss: 0.07231

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.59208
Value Function Update Magnitude: 0.51638

Collected Steps per Second: 20,857.17510
Overall Steps per Second: 10,332.44893

Timestep Collection Time: 2.39793
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.84048

Cumulative Model Updates: 111,086
Cumulative Timesteps: 926,637,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,606.40884
Policy Entropy: 1.81413
Value Function Loss: 0.07217

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.43698

Collected Steps per Second: 20,843.30960
Overall Steps per Second: 10,241.93751

Timestep Collection Time: 2.39924
Timestep Consumption Time: 2.48343
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.88267

Cumulative Model Updates: 111,092
Cumulative Timesteps: 926,687,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 926687838...
Checkpoint 926687838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,337.67503
Policy Entropy: 1.81364
Value Function Loss: 0.07401

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.16821
Policy Update Magnitude: 0.53040
Value Function Update Magnitude: 0.43134

Collected Steps per Second: 20,687.51885
Overall Steps per Second: 10,187.40276

Timestep Collection Time: 2.41827
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.91077

Cumulative Model Updates: 111,098
Cumulative Timesteps: 926,737,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,951.71540
Policy Entropy: 1.80488
Value Function Loss: 0.07007

Mean KL Divergence: 0.01805
SB3 Clip Fraction: 0.16314
Policy Update Magnitude: 0.51410
Value Function Update Magnitude: 0.50381

Collected Steps per Second: 20,709.01442
Overall Steps per Second: 9,957.37924

Timestep Collection Time: 2.41528
Timestep Consumption Time: 2.60793
PPO Batch Consumption Time: 0.31086
Total Iteration Time: 5.02321

Cumulative Model Updates: 111,104
Cumulative Timesteps: 926,787,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 926787884...
Checkpoint 926787884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,539.91118
Policy Entropy: 1.81500
Value Function Loss: 0.07628

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.40276

Collected Steps per Second: 21,428.79047
Overall Steps per Second: 10,368.09794

Timestep Collection Time: 2.33480
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.82557

Cumulative Model Updates: 111,110
Cumulative Timesteps: 926,837,916

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,622.35023
Policy Entropy: 1.80978
Value Function Loss: 0.08000

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.59986
Value Function Update Magnitude: 0.36683

Collected Steps per Second: 21,180.27710
Overall Steps per Second: 10,386.75768

Timestep Collection Time: 2.36078
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.81401

Cumulative Model Updates: 111,116
Cumulative Timesteps: 926,887,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 926887918...
Checkpoint 926887918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,175.58036
Policy Entropy: 1.80478
Value Function Loss: 0.07884

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.60237
Value Function Update Magnitude: 0.45114

Collected Steps per Second: 21,327.44410
Overall Steps per Second: 10,231.76720

Timestep Collection Time: 2.34552
Timestep Consumption Time: 2.54356
PPO Batch Consumption Time: 0.30244
Total Iteration Time: 4.88909

Cumulative Model Updates: 111,122
Cumulative Timesteps: 926,937,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,339.53619
Policy Entropy: 1.79959
Value Function Loss: 0.07802

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14230
Policy Update Magnitude: 0.59754
Value Function Update Magnitude: 0.40471

Collected Steps per Second: 18,660.37212
Overall Steps per Second: 9,733.37602

Timestep Collection Time: 2.68033
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 5.13861

Cumulative Model Updates: 111,128
Cumulative Timesteps: 926,987,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 926987958...
Checkpoint 926987958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,097.75641
Policy Entropy: 1.81180
Value Function Loss: 0.07642

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14411
Policy Update Magnitude: 0.59564
Value Function Update Magnitude: 0.36329

Collected Steps per Second: 18,100.62182
Overall Steps per Second: 9,253.04613

Timestep Collection Time: 2.76300
Timestep Consumption Time: 2.64192
PPO Batch Consumption Time: 0.30595
Total Iteration Time: 5.40492

Cumulative Model Updates: 111,134
Cumulative Timesteps: 927,037,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,509.93748
Policy Entropy: 1.82969
Value Function Loss: 0.08104

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.59307
Value Function Update Magnitude: 0.39709

Collected Steps per Second: 21,223.15065
Overall Steps per Second: 10,232.84895

Timestep Collection Time: 2.35752
Timestep Consumption Time: 2.53203
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.88955

Cumulative Model Updates: 111,140
Cumulative Timesteps: 927,088,004

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 927088004...
Checkpoint 927088004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,543.24280
Policy Entropy: 1.84267
Value Function Loss: 0.08447

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.15372
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.49057

Collected Steps per Second: 21,478.16394
Overall Steps per Second: 10,295.30868

Timestep Collection Time: 2.32832
Timestep Consumption Time: 2.52904
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.85736

Cumulative Model Updates: 111,146
Cumulative Timesteps: 927,138,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,811.71688
Policy Entropy: 1.84825
Value Function Loss: 0.08192

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.17828
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.57885

Collected Steps per Second: 21,345.74208
Overall Steps per Second: 10,328.10207

Timestep Collection Time: 2.34295
Timestep Consumption Time: 2.49937
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.84232

Cumulative Model Updates: 111,152
Cumulative Timesteps: 927,188,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 927188024...
Checkpoint 927188024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,801.73382
Policy Entropy: 1.84192
Value Function Loss: 0.08108

Mean KL Divergence: 0.01918
SB3 Clip Fraction: 0.17948
Policy Update Magnitude: 0.55288
Value Function Update Magnitude: 0.64033

Collected Steps per Second: 21,264.71646
Overall Steps per Second: 10,288.31797

Timestep Collection Time: 2.35131
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.85988

Cumulative Model Updates: 111,158
Cumulative Timesteps: 927,238,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,512.38927
Policy Entropy: 1.85059
Value Function Loss: 0.07769

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.18315
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.52359

Collected Steps per Second: 21,503.17005
Overall Steps per Second: 10,405.63738

Timestep Collection Time: 2.32570
Timestep Consumption Time: 2.48035
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.80605

Cumulative Model Updates: 111,164
Cumulative Timesteps: 927,288,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 927288034...
Checkpoint 927288034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,184.09248
Policy Entropy: 1.85234
Value Function Loss: 0.07890

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.17716
Policy Update Magnitude: 0.57329
Value Function Update Magnitude: 0.49518

Collected Steps per Second: 21,457.12286
Overall Steps per Second: 10,272.53794

Timestep Collection Time: 2.33088
Timestep Consumption Time: 2.53783
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.86871

Cumulative Model Updates: 111,170
Cumulative Timesteps: 927,338,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,735.86866
Policy Entropy: 1.86979
Value Function Loss: 0.07576

Mean KL Divergence: 0.02064
SB3 Clip Fraction: 0.18433
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.50067

Collected Steps per Second: 21,624.95430
Overall Steps per Second: 10,373.77704

Timestep Collection Time: 2.31288
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.82139

Cumulative Model Updates: 111,176
Cumulative Timesteps: 927,388,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927388064...
Checkpoint 927388064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,029.35875
Policy Entropy: 1.86718
Value Function Loss: 0.08169

Mean KL Divergence: 0.02111
SB3 Clip Fraction: 0.18596
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.48545

Collected Steps per Second: 21,224.29096
Overall Steps per Second: 10,206.30015

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.54314
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.89893

Cumulative Model Updates: 111,182
Cumulative Timesteps: 927,438,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,344.35749
Policy Entropy: 1.86956
Value Function Loss: 0.07894

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.18027
Policy Update Magnitude: 0.56610
Value Function Update Magnitude: 0.54325

Collected Steps per Second: 21,354.63446
Overall Steps per Second: 10,391.41185

Timestep Collection Time: 2.34254
Timestep Consumption Time: 2.47144
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.81398

Cumulative Model Updates: 111,188
Cumulative Timesteps: 927,488,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 927488088...
Checkpoint 927488088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,918.71697
Policy Entropy: 1.87051
Value Function Loss: 0.07661

Mean KL Divergence: 0.01897
SB3 Clip Fraction: 0.17597
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.44008

Collected Steps per Second: 21,058.10472
Overall Steps per Second: 10,294.48233

Timestep Collection Time: 2.37524
Timestep Consumption Time: 2.48348
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.85872

Cumulative Model Updates: 111,194
Cumulative Timesteps: 927,538,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,618.46516
Policy Entropy: 1.86973
Value Function Loss: 0.07820

Mean KL Divergence: 0.01853
SB3 Clip Fraction: 0.17594
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.39384

Collected Steps per Second: 21,619.63358
Overall Steps per Second: 10,332.43211

Timestep Collection Time: 2.31438
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.84262

Cumulative Model Updates: 111,200
Cumulative Timesteps: 927,588,142

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 927588142...
Checkpoint 927588142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,027.27732
Policy Entropy: 1.87838
Value Function Loss: 0.08515

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.16627
Policy Update Magnitude: 0.59417
Value Function Update Magnitude: 0.39417

Collected Steps per Second: 19,876.05085
Overall Steps per Second: 9,720.19330

Timestep Collection Time: 2.51660
Timestep Consumption Time: 2.62939
PPO Batch Consumption Time: 0.31010
Total Iteration Time: 5.14599

Cumulative Model Updates: 111,206
Cumulative Timesteps: 927,638,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,686.23426
Policy Entropy: 1.88886
Value Function Loss: 0.09062

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.16341
Policy Update Magnitude: 0.62534
Value Function Update Magnitude: 0.37867

Collected Steps per Second: 18,068.04123
Overall Steps per Second: 9,471.37697

Timestep Collection Time: 2.76776
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 5.27991

Cumulative Model Updates: 111,212
Cumulative Timesteps: 927,688,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 927688170...
Checkpoint 927688170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,786.33700
Policy Entropy: 1.88552
Value Function Loss: 0.09722

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.16034
Policy Update Magnitude: 0.63980
Value Function Update Magnitude: 0.36583

Collected Steps per Second: 21,073.81909
Overall Steps per Second: 10,180.16921

Timestep Collection Time: 2.37290
Timestep Consumption Time: 2.53920
PPO Batch Consumption Time: 0.29936
Total Iteration Time: 4.91210

Cumulative Model Updates: 111,218
Cumulative Timesteps: 927,738,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,063.48246
Policy Entropy: 1.88112
Value Function Loss: 0.09358

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.64647
Value Function Update Magnitude: 0.33644

Collected Steps per Second: 21,461.10041
Overall Steps per Second: 10,375.46556

Timestep Collection Time: 2.33045
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.82041

Cumulative Model Updates: 111,224
Cumulative Timesteps: 927,788,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 927788190...
Checkpoint 927788190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,630.42258
Policy Entropy: 1.88210
Value Function Loss: 0.08744

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.62960
Value Function Update Magnitude: 0.39241

Collected Steps per Second: 20,679.17723
Overall Steps per Second: 10,200.58207

Timestep Collection Time: 2.41808
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.90207

Cumulative Model Updates: 111,230
Cumulative Timesteps: 927,838,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,245.89256
Policy Entropy: 1.88097
Value Function Loss: 0.07847

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.61567
Value Function Update Magnitude: 0.48183

Collected Steps per Second: 21,622.65203
Overall Steps per Second: 10,402.79800

Timestep Collection Time: 2.31239
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.80640

Cumulative Model Updates: 111,236
Cumulative Timesteps: 927,888,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 927888194...
Checkpoint 927888194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,911.87394
Policy Entropy: 1.86743
Value Function Loss: 0.08183

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.61545
Value Function Update Magnitude: 0.42160

Collected Steps per Second: 21,146.55316
Overall Steps per Second: 10,264.41353

Timestep Collection Time: 2.36502
Timestep Consumption Time: 2.50735
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.87237

Cumulative Model Updates: 111,242
Cumulative Timesteps: 927,938,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,111.00286
Policy Entropy: 1.85814
Value Function Loss: 0.07759

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13886
Policy Update Magnitude: 0.61487
Value Function Update Magnitude: 0.48901

Collected Steps per Second: 21,786.56828
Overall Steps per Second: 10,663.84310

Timestep Collection Time: 2.29619
Timestep Consumption Time: 2.39499
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.69118

Cumulative Model Updates: 111,248
Cumulative Timesteps: 927,988,232

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 927988232...
Checkpoint 927988232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,422.68111
Policy Entropy: 1.87062
Value Function Loss: 0.07869

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.60558
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 20,238.86655
Overall Steps per Second: 10,142.81115

Timestep Collection Time: 2.47059
Timestep Consumption Time: 2.45920
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.92980

Cumulative Model Updates: 111,254
Cumulative Timesteps: 928,038,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,821.26626
Policy Entropy: 1.87101
Value Function Loss: 0.08147

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.14405
Policy Update Magnitude: 0.59903
Value Function Update Magnitude: 0.55559

Collected Steps per Second: 20,992.43898
Overall Steps per Second: 10,187.45151

Timestep Collection Time: 2.38267
Timestep Consumption Time: 2.52710
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.90977

Cumulative Model Updates: 111,260
Cumulative Timesteps: 928,088,252

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 928088252...
Checkpoint 928088252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,592.33758
Policy Entropy: 1.87042
Value Function Loss: 0.08691

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14794
Policy Update Magnitude: 0.60323
Value Function Update Magnitude: 0.45730

Collected Steps per Second: 20,660.35010
Overall Steps per Second: 10,083.38641

Timestep Collection Time: 2.42222
Timestep Consumption Time: 2.54079
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.96302

Cumulative Model Updates: 111,266
Cumulative Timesteps: 928,138,296

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,947.64589
Policy Entropy: 1.86739
Value Function Loss: 0.08169

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.56983
Value Function Update Magnitude: 0.36618

Collected Steps per Second: 21,534.67377
Overall Steps per Second: 10,422.21514

Timestep Collection Time: 2.32286
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.79956

Cumulative Model Updates: 111,272
Cumulative Timesteps: 928,188,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 928188318...
Checkpoint 928188318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,068.61106
Policy Entropy: 1.86434
Value Function Loss: 0.08136

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.30685

Collected Steps per Second: 20,784.59562
Overall Steps per Second: 10,151.69541

Timestep Collection Time: 2.40582
Timestep Consumption Time: 2.51986
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.92568

Cumulative Model Updates: 111,278
Cumulative Timesteps: 928,238,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,928.85847
Policy Entropy: 1.85277
Value Function Loss: 0.07316

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.42346

Collected Steps per Second: 20,811.39392
Overall Steps per Second: 10,388.02921

Timestep Collection Time: 2.40378
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.81574

Cumulative Model Updates: 111,284
Cumulative Timesteps: 928,288,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 928288348...
Checkpoint 928288348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,808.37582
Policy Entropy: 1.85965
Value Function Loss: 0.07989

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.61434
Value Function Update Magnitude: 0.56917

Collected Steps per Second: 17,934.63606
Overall Steps per Second: 9,467.10179

Timestep Collection Time: 2.78812
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.30090
Total Iteration Time: 5.28187

Cumulative Model Updates: 111,290
Cumulative Timesteps: 928,338,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,550.33668
Policy Entropy: 1.87214
Value Function Loss: 0.07832

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.60772
Value Function Update Magnitude: 0.51216

Collected Steps per Second: 20,944.55004
Overall Steps per Second: 10,425.75690

Timestep Collection Time: 2.38792
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.79716

Cumulative Model Updates: 111,296
Cumulative Timesteps: 928,388,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928388366...
Checkpoint 928388366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,225.01145
Policy Entropy: 1.87322
Value Function Loss: 0.08354

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.57707
Value Function Update Magnitude: 0.47950

Collected Steps per Second: 20,188.25585
Overall Steps per Second: 10,220.64628

Timestep Collection Time: 2.47807
Timestep Consumption Time: 2.41672
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.89480

Cumulative Model Updates: 111,302
Cumulative Timesteps: 928,438,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,995.15942
Policy Entropy: 1.86490
Value Function Loss: 0.08892

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.58744
Value Function Update Magnitude: 0.48429

Collected Steps per Second: 21,016.29702
Overall Steps per Second: 10,291.69940

Timestep Collection Time: 2.37958
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.85926

Cumulative Model Updates: 111,308
Cumulative Timesteps: 928,488,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 928488404...
Checkpoint 928488404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,352.17798
Policy Entropy: 1.85181
Value Function Loss: 0.08636

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14216
Policy Update Magnitude: 0.61628
Value Function Update Magnitude: 0.51893

Collected Steps per Second: 17,607.18497
Overall Steps per Second: 9,494.23954

Timestep Collection Time: 2.84202
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 5.27056

Cumulative Model Updates: 111,314
Cumulative Timesteps: 928,538,444

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,424.74397
Policy Entropy: 1.84965
Value Function Loss: 0.08457

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14480
Policy Update Magnitude: 0.60639
Value Function Update Magnitude: 0.48093

Collected Steps per Second: 20,986.28579
Overall Steps per Second: 10,206.57770

Timestep Collection Time: 2.38346
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.90076

Cumulative Model Updates: 111,320
Cumulative Timesteps: 928,588,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 928588464...
Checkpoint 928588464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,260.33421
Policy Entropy: 1.84609
Value Function Loss: 0.07787

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.60870
Value Function Update Magnitude: 0.43875

Collected Steps per Second: 21,152.86812
Overall Steps per Second: 10,196.23875

Timestep Collection Time: 2.36384
Timestep Consumption Time: 2.54013
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.90397

Cumulative Model Updates: 111,326
Cumulative Timesteps: 928,638,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,593.58131
Policy Entropy: 1.85678
Value Function Loss: 0.07834

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.61086
Value Function Update Magnitude: 0.46812

Collected Steps per Second: 21,375.18355
Overall Steps per Second: 10,381.69937

Timestep Collection Time: 2.33916
Timestep Consumption Time: 2.47701
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.81617

Cumulative Model Updates: 111,332
Cumulative Timesteps: 928,688,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 928688466...
Checkpoint 928688466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,793.15868
Policy Entropy: 1.86162
Value Function Loss: 0.07350

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.60624
Value Function Update Magnitude: 0.49225

Collected Steps per Second: 20,897.81249
Overall Steps per Second: 10,290.24402

Timestep Collection Time: 2.39460
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.86305

Cumulative Model Updates: 111,338
Cumulative Timesteps: 928,738,508

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,339.29443
Policy Entropy: 1.85271
Value Function Loss: 0.07587

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14780
Policy Update Magnitude: 0.60341
Value Function Update Magnitude: 0.51306

Collected Steps per Second: 21,725.19466
Overall Steps per Second: 10,526.40129

Timestep Collection Time: 2.30249
Timestep Consumption Time: 2.44956
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.75205

Cumulative Model Updates: 111,344
Cumulative Timesteps: 928,788,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 928788530...
Checkpoint 928788530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,931.59227
Policy Entropy: 1.83859
Value Function Loss: 0.07574

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 20,838.32539
Overall Steps per Second: 10,133.78862

Timestep Collection Time: 2.40048
Timestep Consumption Time: 2.53568
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.93616

Cumulative Model Updates: 111,350
Cumulative Timesteps: 928,838,552

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,464.06761
Policy Entropy: 1.82970
Value Function Loss: 0.07639

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14727
Policy Update Magnitude: 0.60892
Value Function Update Magnitude: 0.66865

Collected Steps per Second: 19,014.29968
Overall Steps per Second: 9,634.44025

Timestep Collection Time: 2.63139
Timestep Consumption Time: 2.56186
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 5.19324

Cumulative Model Updates: 111,356
Cumulative Timesteps: 928,888,586

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 928888586...
Checkpoint 928888586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,284.72429
Policy Entropy: 1.82655
Value Function Loss: 0.07113

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.60901
Value Function Update Magnitude: 0.70712

Collected Steps per Second: 21,293.09529
Overall Steps per Second: 10,330.28169

Timestep Collection Time: 2.34874
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.84130

Cumulative Model Updates: 111,362
Cumulative Timesteps: 928,938,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,402.34790
Policy Entropy: 1.81471
Value Function Loss: 0.07018

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14507
Policy Update Magnitude: 0.59843
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 21,507.33479
Overall Steps per Second: 10,512.10641

Timestep Collection Time: 2.32683
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.76061

Cumulative Model Updates: 111,368
Cumulative Timesteps: 928,988,642

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 928988642...
Checkpoint 928988642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,388.20145
Policy Entropy: 1.80401
Value Function Loss: 0.07348

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.14532
Policy Update Magnitude: 0.59731
Value Function Update Magnitude: 0.49252

Collected Steps per Second: 21,939.92884
Overall Steps per Second: 10,334.51372

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.56033
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.84029

Cumulative Model Updates: 111,374
Cumulative Timesteps: 929,038,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,717.60746
Policy Entropy: 1.80498
Value Function Loss: 0.07597

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.59942
Value Function Update Magnitude: 0.48113

Collected Steps per Second: 20,296.23050
Overall Steps per Second: 9,954.63712

Timestep Collection Time: 2.46440
Timestep Consumption Time: 2.56019
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 5.02459

Cumulative Model Updates: 111,380
Cumulative Timesteps: 929,088,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 929088682...
Checkpoint 929088682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,074.35326
Policy Entropy: 1.81699
Value Function Loss: 0.08082

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.14257
Policy Update Magnitude: 0.61354
Value Function Update Magnitude: 0.50117

Collected Steps per Second: 20,985.64747
Overall Steps per Second: 9,927.90017

Timestep Collection Time: 2.38363
Timestep Consumption Time: 2.65490
PPO Batch Consumption Time: 0.31277
Total Iteration Time: 5.03853

Cumulative Model Updates: 111,386
Cumulative Timesteps: 929,138,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,831.07746
Policy Entropy: 1.81715
Value Function Loss: 0.07804

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.60869
Value Function Update Magnitude: 0.73023

Collected Steps per Second: 21,836.15416
Overall Steps per Second: 10,788.28860

Timestep Collection Time: 2.28978
Timestep Consumption Time: 2.34487
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.63466

Cumulative Model Updates: 111,392
Cumulative Timesteps: 929,188,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 929188704...
Checkpoint 929188704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,453.30224
Policy Entropy: 1.82497
Value Function Loss: 0.07498

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.60911
Value Function Update Magnitude: 0.75989

Collected Steps per Second: 19,618.14687
Overall Steps per Second: 9,768.49029

Timestep Collection Time: 2.55019
Timestep Consumption Time: 2.57138
PPO Batch Consumption Time: 0.29604
Total Iteration Time: 5.12157

Cumulative Model Updates: 111,398
Cumulative Timesteps: 929,238,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,149.70477
Policy Entropy: 1.81400
Value Function Loss: 0.07248

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14584
Policy Update Magnitude: 0.58617
Value Function Update Magnitude: 0.83727

Collected Steps per Second: 21,135.15952
Overall Steps per Second: 10,200.28499

Timestep Collection Time: 2.36582
Timestep Consumption Time: 2.53620
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.90202

Cumulative Model Updates: 111,404
Cumulative Timesteps: 929,288,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 929288736...
Checkpoint 929288736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,840.13433
Policy Entropy: 1.80190
Value Function Loss: 0.07647

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14899
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.89387

Collected Steps per Second: 18,609.44693
Overall Steps per Second: 9,636.31418

Timestep Collection Time: 2.68842
Timestep Consumption Time: 2.50340
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 5.19182

Cumulative Model Updates: 111,410
Cumulative Timesteps: 929,338,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,835.09307
Policy Entropy: 1.78330
Value Function Loss: 0.07580

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.15982
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.86598

Collected Steps per Second: 20,544.68473
Overall Steps per Second: 10,312.42852

Timestep Collection Time: 2.43430
Timestep Consumption Time: 2.41538
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.84968

Cumulative Model Updates: 111,416
Cumulative Timesteps: 929,388,778

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 929388778...
Checkpoint 929388778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,499.99601
Policy Entropy: 1.78303
Value Function Loss: 0.07426

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.18760
Policy Update Magnitude: 0.52343
Value Function Update Magnitude: 0.76256

Collected Steps per Second: 19,799.08266
Overall Steps per Second: 10,000.47433

Timestep Collection Time: 2.52587
Timestep Consumption Time: 2.47489
PPO Batch Consumption Time: 0.29718
Total Iteration Time: 5.00076

Cumulative Model Updates: 111,422
Cumulative Timesteps: 929,438,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,992.92231
Policy Entropy: 1.78851
Value Function Loss: 0.07241

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.17089
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.76698

Collected Steps per Second: 20,597.01281
Overall Steps per Second: 9,945.12488

Timestep Collection Time: 2.42880
Timestep Consumption Time: 2.60140
PPO Batch Consumption Time: 0.30565
Total Iteration Time: 5.03020

Cumulative Model Updates: 111,428
Cumulative Timesteps: 929,488,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 929488814...
Checkpoint 929488814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,837.95071
Policy Entropy: 1.78306
Value Function Loss: 0.07963

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17167
Policy Update Magnitude: 0.47260
Value Function Update Magnitude: 0.61479

Collected Steps per Second: 20,957.21198
Overall Steps per Second: 10,395.18111

Timestep Collection Time: 2.38600
Timestep Consumption Time: 2.42430
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.81031

Cumulative Model Updates: 111,434
Cumulative Timesteps: 929,538,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,655.27002
Policy Entropy: 1.77608
Value Function Loss: 0.08326

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16525
Policy Update Magnitude: 0.46846
Value Function Update Magnitude: 0.65573

Collected Steps per Second: 20,002.89960
Overall Steps per Second: 9,707.12418

Timestep Collection Time: 2.50104
Timestep Consumption Time: 2.65270
PPO Batch Consumption Time: 0.31342
Total Iteration Time: 5.15374

Cumulative Model Updates: 111,440
Cumulative Timesteps: 929,588,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 929588846...
Checkpoint 929588846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,661.43979
Policy Entropy: 1.78605
Value Function Loss: 0.07980

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14286
Policy Update Magnitude: 0.52770
Value Function Update Magnitude: 0.81849

Collected Steps per Second: 18,505.28714
Overall Steps per Second: 9,599.94693

Timestep Collection Time: 2.70247
Timestep Consumption Time: 2.50693
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 5.20940

Cumulative Model Updates: 111,446
Cumulative Timesteps: 929,638,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,919.18348
Policy Entropy: 1.78018
Value Function Loss: 0.07796

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.17158
Policy Update Magnitude: 0.56518
Value Function Update Magnitude: 0.85755

Collected Steps per Second: 21,645.37114
Overall Steps per Second: 10,403.46217

Timestep Collection Time: 2.31006
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.80628

Cumulative Model Updates: 111,452
Cumulative Timesteps: 929,688,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 929688858...
Checkpoint 929688858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,327.95015
Policy Entropy: 1.79644
Value Function Loss: 0.07199

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.17237
Policy Update Magnitude: 0.51104
Value Function Update Magnitude: 0.89586

Collected Steps per Second: 21,201.95592
Overall Steps per Second: 9,930.61179

Timestep Collection Time: 2.35922
Timestep Consumption Time: 2.67773
PPO Batch Consumption Time: 0.32297
Total Iteration Time: 5.03695

Cumulative Model Updates: 111,458
Cumulative Timesteps: 929,738,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,910.77099
Policy Entropy: 1.78385
Value Function Loss: 0.06972

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.15756
Policy Update Magnitude: 0.49270
Value Function Update Magnitude: 0.83017

Collected Steps per Second: 20,437.67451
Overall Steps per Second: 9,818.86111

Timestep Collection Time: 2.44715
Timestep Consumption Time: 2.64652
PPO Batch Consumption Time: 0.31673
Total Iteration Time: 5.09367

Cumulative Model Updates: 111,464
Cumulative Timesteps: 929,788,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 929788892...
Checkpoint 929788892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,469.08782
Policy Entropy: 1.77864
Value Function Loss: 0.07171

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.16107
Policy Update Magnitude: 0.51500
Value Function Update Magnitude: 0.71476

Collected Steps per Second: 18,864.12409
Overall Steps per Second: 9,674.14039

Timestep Collection Time: 2.65064
Timestep Consumption Time: 2.51798
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 5.16862

Cumulative Model Updates: 111,470
Cumulative Timesteps: 929,838,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,844.98628
Policy Entropy: 1.77571
Value Function Loss: 0.07413

Mean KL Divergence: 0.01573
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.50616
Value Function Update Magnitude: 0.58374

Collected Steps per Second: 21,484.61323
Overall Steps per Second: 10,282.63093

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.53654
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.86490

Cumulative Model Updates: 111,476
Cumulative Timesteps: 929,888,918

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 929888918...
Checkpoint 929888918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,409.69186
Policy Entropy: 1.77613
Value Function Loss: 0.07170

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.16347
Policy Update Magnitude: 0.50329
Value Function Update Magnitude: 0.52228

Collected Steps per Second: 20,998.60783
Overall Steps per Second: 10,090.14532

Timestep Collection Time: 2.38168
Timestep Consumption Time: 2.57484
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 4.95652

Cumulative Model Updates: 111,482
Cumulative Timesteps: 929,938,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,310.64957
Policy Entropy: 1.78691
Value Function Loss: 0.07323

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.51006
Value Function Update Magnitude: 0.46786

Collected Steps per Second: 19,968.58420
Overall Steps per Second: 9,625.39146

Timestep Collection Time: 2.50594
Timestep Consumption Time: 2.69281
PPO Batch Consumption Time: 0.31576
Total Iteration Time: 5.19875

Cumulative Model Updates: 111,488
Cumulative Timesteps: 929,988,970

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 929988970...
Checkpoint 929988970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,966.44644
Policy Entropy: 1.79329
Value Function Loss: 0.07344

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.15255
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.51255

Collected Steps per Second: 21,558.32797
Overall Steps per Second: 10,458.10788

Timestep Collection Time: 2.31938
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.78117

Cumulative Model Updates: 111,494
Cumulative Timesteps: 930,038,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,861.04951
Policy Entropy: 1.79883
Value Function Loss: 0.08303

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.18216
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.45440

Collected Steps per Second: 21,596.46534
Overall Steps per Second: 10,422.35116

Timestep Collection Time: 2.31547
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.79796

Cumulative Model Updates: 111,500
Cumulative Timesteps: 930,088,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 930088978...
Checkpoint 930088978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,620.29135
Policy Entropy: 1.79457
Value Function Loss: 0.08600

Mean KL Divergence: 0.02103
SB3 Clip Fraction: 0.18843
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.41530

Collected Steps per Second: 21,128.06016
Overall Steps per Second: 10,166.04596

Timestep Collection Time: 2.36747
Timestep Consumption Time: 2.55283
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.92030

Cumulative Model Updates: 111,506
Cumulative Timesteps: 930,138,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,066.76735
Policy Entropy: 1.78466
Value Function Loss: 0.09227

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.18548
Policy Update Magnitude: 0.59066
Value Function Update Magnitude: 0.36182

Collected Steps per Second: 21,662.48226
Overall Steps per Second: 10,419.13620

Timestep Collection Time: 2.30897
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.80059

Cumulative Model Updates: 111,512
Cumulative Timesteps: 930,189,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 930189016...
Checkpoint 930189016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,579.21904
Policy Entropy: 1.78349
Value Function Loss: 0.09201

Mean KL Divergence: 0.01969
SB3 Clip Fraction: 0.17697
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.32615

Collected Steps per Second: 21,215.50085
Overall Steps per Second: 10,224.40440

Timestep Collection Time: 2.35762
Timestep Consumption Time: 2.53441
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.89202

Cumulative Model Updates: 111,518
Cumulative Timesteps: 930,239,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,859.29094
Policy Entropy: 1.78815
Value Function Loss: 0.08691

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.18545
Policy Update Magnitude: 0.52595
Value Function Update Magnitude: 0.32468

Collected Steps per Second: 19,205.14816
Overall Steps per Second: 9,699.28475

Timestep Collection Time: 2.60430
Timestep Consumption Time: 2.55237
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 5.15667

Cumulative Model Updates: 111,524
Cumulative Timesteps: 930,289,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 930289050...
Checkpoint 930289050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,068.68031
Policy Entropy: 1.78142
Value Function Loss: 0.08018

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.17800
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.43067

Collected Steps per Second: 21,420.78379
Overall Steps per Second: 10,243.61825

Timestep Collection Time: 2.33484
Timestep Consumption Time: 2.54762
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.88245

Cumulative Model Updates: 111,530
Cumulative Timesteps: 930,339,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,759.16581
Policy Entropy: 1.79193
Value Function Loss: 0.07331

Mean KL Divergence: 0.01659
SB3 Clip Fraction: 0.16365
Policy Update Magnitude: 0.59290
Value Function Update Magnitude: 0.65206

Collected Steps per Second: 21,221.57475
Overall Steps per Second: 10,347.04864

Timestep Collection Time: 2.35647
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.83307

Cumulative Model Updates: 111,536
Cumulative Timesteps: 930,389,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 930389072...
Checkpoint 930389072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,804.75923
Policy Entropy: 1.79029
Value Function Loss: 0.07198

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.60508
Value Function Update Magnitude: 0.67433

Collected Steps per Second: 18,722.70308
Overall Steps per Second: 9,620.82150

Timestep Collection Time: 2.67173
Timestep Consumption Time: 2.52762
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 5.19935

Cumulative Model Updates: 111,542
Cumulative Timesteps: 930,439,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,632.07690
Policy Entropy: 1.78494
Value Function Loss: 0.07554

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.15702
Policy Update Magnitude: 0.60400
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 21,655.59419
Overall Steps per Second: 10,136.10675

Timestep Collection Time: 2.31118
Timestep Consumption Time: 2.62661
PPO Batch Consumption Time: 0.30664
Total Iteration Time: 4.93779

Cumulative Model Updates: 111,548
Cumulative Timesteps: 930,489,144

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 930489144...
Checkpoint 930489144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,476.67930
Policy Entropy: 1.78433
Value Function Loss: 0.07711

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.49253

Collected Steps per Second: 19,183.06043
Overall Steps per Second: 9,761.12887

Timestep Collection Time: 2.60740
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 5.12420

Cumulative Model Updates: 111,554
Cumulative Timesteps: 930,539,162

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,617.93898
Policy Entropy: 1.78278
Value Function Loss: 0.07420

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.59058
Value Function Update Magnitude: 0.47238

Collected Steps per Second: 19,626.44567
Overall Steps per Second: 9,783.15110

Timestep Collection Time: 2.54962
Timestep Consumption Time: 2.56530
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 5.11492

Cumulative Model Updates: 111,560
Cumulative Timesteps: 930,589,202

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 930589202...
Checkpoint 930589202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,950.48353
Policy Entropy: 1.79159
Value Function Loss: 0.07484

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.60057
Value Function Update Magnitude: 0.48167

Collected Steps per Second: 20,810.20920
Overall Steps per Second: 10,163.88110

Timestep Collection Time: 2.40324
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.92056

Cumulative Model Updates: 111,566
Cumulative Timesteps: 930,639,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,924.81626
Policy Entropy: 1.79946
Value Function Loss: 0.07925

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.60303
Value Function Update Magnitude: 0.55321

Collected Steps per Second: 20,960.58628
Overall Steps per Second: 10,072.96943

Timestep Collection Time: 2.38677
Timestep Consumption Time: 2.57979
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.96656

Cumulative Model Updates: 111,572
Cumulative Timesteps: 930,689,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 930689242...
Checkpoint 930689242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,830.26416
Policy Entropy: 1.78976
Value Function Loss: 0.08007

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14664
Policy Update Magnitude: 0.59630
Value Function Update Magnitude: 0.70055

Collected Steps per Second: 20,212.91803
Overall Steps per Second: 10,193.19364

Timestep Collection Time: 2.47367
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.90523

Cumulative Model Updates: 111,578
Cumulative Timesteps: 930,739,242

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,940.99552
Policy Entropy: 1.78646
Value Function Loss: 0.07843

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.60596
Value Function Update Magnitude: 0.72768

Collected Steps per Second: 18,917.17924
Overall Steps per Second: 9,530.25407

Timestep Collection Time: 2.64447
Timestep Consumption Time: 2.60470
PPO Batch Consumption Time: 0.32024
Total Iteration Time: 5.24918

Cumulative Model Updates: 111,584
Cumulative Timesteps: 930,789,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 930789268...
Checkpoint 930789268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,242.50691
Policy Entropy: 1.78348
Value Function Loss: 0.07424

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.61032
Value Function Update Magnitude: 0.65231

Collected Steps per Second: 18,123.50991
Overall Steps per Second: 9,586.99900

Timestep Collection Time: 2.76028
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 5.21811

Cumulative Model Updates: 111,590
Cumulative Timesteps: 930,839,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,695.12681
Policy Entropy: 1.79265
Value Function Loss: 0.07348

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.13845
Policy Update Magnitude: 0.60681
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 20,317.37872
Overall Steps per Second: 10,034.71528

Timestep Collection Time: 2.46203
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.30155
Total Iteration Time: 4.98489

Cumulative Model Updates: 111,596
Cumulative Timesteps: 930,889,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 930889316...
Checkpoint 930889316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,138.46041
Policy Entropy: 1.79536
Value Function Loss: 0.07343

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15079
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.50984

Collected Steps per Second: 20,150.88216
Overall Steps per Second: 9,960.56967

Timestep Collection Time: 2.48138
Timestep Consumption Time: 2.53861
PPO Batch Consumption Time: 0.29878
Total Iteration Time: 5.01999

Cumulative Model Updates: 111,602
Cumulative Timesteps: 930,939,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,442.48059
Policy Entropy: 1.79299
Value Function Loss: 0.07983

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.57489
Value Function Update Magnitude: 0.50925

Collected Steps per Second: 20,977.22441
Overall Steps per Second: 10,250.41179

Timestep Collection Time: 2.38411
Timestep Consumption Time: 2.49491
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.87902

Cumulative Model Updates: 111,608
Cumulative Timesteps: 930,989,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 930989330...
Checkpoint 930989330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,199.78198
Policy Entropy: 1.79479
Value Function Loss: 0.07537

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.46082

Collected Steps per Second: 20,843.52321
Overall Steps per Second: 10,431.08960

Timestep Collection Time: 2.39883
Timestep Consumption Time: 2.39454
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.79336

Cumulative Model Updates: 111,614
Cumulative Timesteps: 931,039,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,424.21075
Policy Entropy: 1.79222
Value Function Loss: 0.07232

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.54083

Collected Steps per Second: 19,608.49052
Overall Steps per Second: 9,926.08278

Timestep Collection Time: 2.55022
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 5.03784

Cumulative Model Updates: 111,620
Cumulative Timesteps: 931,089,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 931089336...
Checkpoint 931089336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,124.30319
Policy Entropy: 1.79155
Value Function Loss: 0.06975

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.14114
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.51632

Collected Steps per Second: 20,512.12379
Overall Steps per Second: 10,100.00222

Timestep Collection Time: 2.43778
Timestep Consumption Time: 2.51311
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.95089

Cumulative Model Updates: 111,626
Cumulative Timesteps: 931,139,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,040.34293
Policy Entropy: 1.78621
Value Function Loss: 0.06723

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.59067

Collected Steps per Second: 20,774.63261
Overall Steps per Second: 9,975.83925

Timestep Collection Time: 2.40823
Timestep Consumption Time: 2.60689
PPO Batch Consumption Time: 0.30380
Total Iteration Time: 5.01512

Cumulative Model Updates: 111,632
Cumulative Timesteps: 931,189,370

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931189370...
Checkpoint 931189370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,828.79985
Policy Entropy: 1.78400
Value Function Loss: 0.06821

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13710
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.56212

Collected Steps per Second: 21,039.82020
Overall Steps per Second: 10,131.56287

Timestep Collection Time: 2.37749
Timestep Consumption Time: 2.55975
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.93724

Cumulative Model Updates: 111,638
Cumulative Timesteps: 931,239,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,399.47610
Policy Entropy: 1.78267
Value Function Loss: 0.06885

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.59556
Value Function Update Magnitude: 0.53414

Collected Steps per Second: 21,178.00930
Overall Steps per Second: 10,224.72084

Timestep Collection Time: 2.36179
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.89187

Cumulative Model Updates: 111,644
Cumulative Timesteps: 931,289,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931289410...
Checkpoint 931289410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,877.96380
Policy Entropy: 1.77198
Value Function Loss: 0.07528

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.60491
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 21,145.02088
Overall Steps per Second: 10,264.71606

Timestep Collection Time: 2.36633
Timestep Consumption Time: 2.50824
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.87456

Cumulative Model Updates: 111,650
Cumulative Timesteps: 931,339,446

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,320.54526
Policy Entropy: 1.77307
Value Function Loss: 0.07406

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.60310
Value Function Update Magnitude: 0.72972

Collected Steps per Second: 20,369.30856
Overall Steps per Second: 10,047.37630

Timestep Collection Time: 2.45546
Timestep Consumption Time: 2.52256
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.97802

Cumulative Model Updates: 111,656
Cumulative Timesteps: 931,389,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 931389462...
Checkpoint 931389462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,320.46937
Policy Entropy: 1.77066
Value Function Loss: 0.07521

Mean KL Divergence: 0.01885
SB3 Clip Fraction: 0.17200
Policy Update Magnitude: 0.53624
Value Function Update Magnitude: 0.82216

Collected Steps per Second: 20,910.11294
Overall Steps per Second: 10,176.05901

Timestep Collection Time: 2.39186
Timestep Consumption Time: 2.52301
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.91487

Cumulative Model Updates: 111,662
Cumulative Timesteps: 931,439,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,290.76260
Policy Entropy: 1.77236
Value Function Loss: 0.07056

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.78792

Collected Steps per Second: 21,040.19411
Overall Steps per Second: 10,052.02101

Timestep Collection Time: 2.37669
Timestep Consumption Time: 2.59803
PPO Batch Consumption Time: 0.30091
Total Iteration Time: 4.97472

Cumulative Model Updates: 111,668
Cumulative Timesteps: 931,489,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 931489482...
Checkpoint 931489482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,598.02598
Policy Entropy: 1.78328
Value Function Loss: 0.07597

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.60659
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 20,880.28925
Overall Steps per Second: 10,146.55172

Timestep Collection Time: 2.39546
Timestep Consumption Time: 2.53409
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.92956

Cumulative Model Updates: 111,674
Cumulative Timesteps: 931,539,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,051.33189
Policy Entropy: 1.78732
Value Function Loss: 0.07376

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.61075
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 21,164.52179
Overall Steps per Second: 10,192.00797

Timestep Collection Time: 2.36320
Timestep Consumption Time: 2.54417
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 4.90737

Cumulative Model Updates: 111,680
Cumulative Timesteps: 931,589,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 931589516...
Checkpoint 931589516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,745.35797
Policy Entropy: 1.79840
Value Function Loss: 0.07799

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14448
Policy Update Magnitude: 0.60987
Value Function Update Magnitude: 0.68878

Collected Steps per Second: 20,987.91735
Overall Steps per Second: 10,097.62137

Timestep Collection Time: 2.38347
Timestep Consumption Time: 2.57057
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.95404

Cumulative Model Updates: 111,686
Cumulative Timesteps: 931,639,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,367.99220
Policy Entropy: 1.78454
Value Function Loss: 0.07361

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14791
Policy Update Magnitude: 0.61389
Value Function Update Magnitude: 0.69562

Collected Steps per Second: 21,088.26371
Overall Steps per Second: 9,911.98220

Timestep Collection Time: 2.37137
Timestep Consumption Time: 2.67384
PPO Batch Consumption Time: 0.31458
Total Iteration Time: 5.04521

Cumulative Model Updates: 111,692
Cumulative Timesteps: 931,689,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 931689548...
Checkpoint 931689548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,596.89676
Policy Entropy: 1.78541
Value Function Loss: 0.06863

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14449
Policy Update Magnitude: 0.60396
Value Function Update Magnitude: 0.73443

Collected Steps per Second: 21,102.79704
Overall Steps per Second: 10,159.31264

Timestep Collection Time: 2.37068
Timestep Consumption Time: 2.55367
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.92435

Cumulative Model Updates: 111,698
Cumulative Timesteps: 931,739,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,754.52483
Policy Entropy: 1.76996
Value Function Loss: 0.06681

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.58415
Value Function Update Magnitude: 0.68269

Collected Steps per Second: 19,310.42476
Overall Steps per Second: 9,647.48289

Timestep Collection Time: 2.59176
Timestep Consumption Time: 2.59591
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 5.18767

Cumulative Model Updates: 111,704
Cumulative Timesteps: 931,789,624

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 931789624...
Checkpoint 931789624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,873.30414
Policy Entropy: 1.76555
Value Function Loss: 0.07655

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.14971
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.55000

Collected Steps per Second: 20,627.80528
Overall Steps per Second: 10,038.41398

Timestep Collection Time: 2.42556
Timestep Consumption Time: 2.55869
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.98425

Cumulative Model Updates: 111,710
Cumulative Timesteps: 931,839,658

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,074.57768
Policy Entropy: 1.76541
Value Function Loss: 0.08287

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.14761
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.63812

Collected Steps per Second: 21,672.90573
Overall Steps per Second: 10,368.23610

Timestep Collection Time: 2.30841
Timestep Consumption Time: 2.51690
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.82531

Cumulative Model Updates: 111,716
Cumulative Timesteps: 931,889,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931889688...
Checkpoint 931889688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,649.51725
Policy Entropy: 1.78157
Value Function Loss: 0.08069

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.58424
Value Function Update Magnitude: 0.66472

Collected Steps per Second: 21,085.48829
Overall Steps per Second: 10,220.26341

Timestep Collection Time: 2.37234
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.89439

Cumulative Model Updates: 111,722
Cumulative Timesteps: 931,939,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,165.21819
Policy Entropy: 1.78642
Value Function Loss: 0.08381

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13718
Policy Update Magnitude: 0.59538
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 20,516.79024
Overall Steps per Second: 10,048.32007

Timestep Collection Time: 2.43742
Timestep Consumption Time: 2.53933
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.97675

Cumulative Model Updates: 111,728
Cumulative Timesteps: 931,989,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 931989718...
Checkpoint 931989718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,944.65281
Policy Entropy: 1.78462
Value Function Loss: 0.08234

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.61516
Value Function Update Magnitude: 0.49752

Collected Steps per Second: 20,651.44821
Overall Steps per Second: 10,143.24257

Timestep Collection Time: 2.42133
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.92978

Cumulative Model Updates: 111,734
Cumulative Timesteps: 932,039,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,551.80470
Policy Entropy: 1.78013
Value Function Loss: 0.07997

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15835
Policy Update Magnitude: 0.59574
Value Function Update Magnitude: 0.46134

Collected Steps per Second: 21,689.83185
Overall Steps per Second: 10,322.92496

Timestep Collection Time: 2.30578
Timestep Consumption Time: 2.53897
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.84475

Cumulative Model Updates: 111,740
Cumulative Timesteps: 932,089,734

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 932089734...
Checkpoint 932089734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,150.06157
Policy Entropy: 1.77172
Value Function Loss: 0.07473

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.17675
Policy Update Magnitude: 0.55913
Value Function Update Magnitude: 0.63796

Collected Steps per Second: 20,757.39640
Overall Steps per Second: 10,306.18785

Timestep Collection Time: 2.40984
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.85359

Cumulative Model Updates: 111,746
Cumulative Timesteps: 932,139,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,162.57262
Policy Entropy: 1.76384
Value Function Loss: 0.06883

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.54181
Value Function Update Magnitude: 0.77068

Collected Steps per Second: 21,213.21705
Overall Steps per Second: 10,161.33837

Timestep Collection Time: 2.35796
Timestep Consumption Time: 2.56462
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.92258

Cumulative Model Updates: 111,752
Cumulative Timesteps: 932,189,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 932189776...
Checkpoint 932189776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,301.35670
Policy Entropy: 1.77086
Value Function Loss: 0.07057

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.70994

Collected Steps per Second: 20,115.43208
Overall Steps per Second: 9,879.26716

Timestep Collection Time: 2.48645
Timestep Consumption Time: 2.57627
PPO Batch Consumption Time: 0.30124
Total Iteration Time: 5.06272

Cumulative Model Updates: 111,758
Cumulative Timesteps: 932,239,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,703.56054
Policy Entropy: 1.76905
Value Function Loss: 0.07130

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.60272
Value Function Update Magnitude: 0.67008

Collected Steps per Second: 21,170.99729
Overall Steps per Second: 10,460.08936

Timestep Collection Time: 2.36210
Timestep Consumption Time: 2.41874
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.78084

Cumulative Model Updates: 111,764
Cumulative Timesteps: 932,289,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 932289800...
Checkpoint 932289800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,717.30999
Policy Entropy: 1.76189
Value Function Loss: 0.06832

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.59492
Value Function Update Magnitude: 0.74485

Collected Steps per Second: 20,510.28028
Overall Steps per Second: 9,800.69323

Timestep Collection Time: 2.43790
Timestep Consumption Time: 2.66398
PPO Batch Consumption Time: 0.31342
Total Iteration Time: 5.10188

Cumulative Model Updates: 111,770
Cumulative Timesteps: 932,339,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,731.23251
Policy Entropy: 1.75018
Value Function Loss: 0.06771

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.58883
Value Function Update Magnitude: 0.62749

Collected Steps per Second: 20,127.51719
Overall Steps per Second: 9,848.30109

Timestep Collection Time: 2.48575
Timestep Consumption Time: 2.59452
PPO Batch Consumption Time: 0.30242
Total Iteration Time: 5.08027

Cumulative Model Updates: 111,776
Cumulative Timesteps: 932,389,834

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 932389834...
Checkpoint 932389834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,005.83237
Policy Entropy: 1.75123
Value Function Loss: 0.06638

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.47846

Collected Steps per Second: 20,388.81008
Overall Steps per Second: 9,831.80992

Timestep Collection Time: 2.45311
Timestep Consumption Time: 2.63405
PPO Batch Consumption Time: 0.31239
Total Iteration Time: 5.08716

Cumulative Model Updates: 111,782
Cumulative Timesteps: 932,439,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,333.40997
Policy Entropy: 1.76739
Value Function Loss: 0.07548

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.39180

Collected Steps per Second: 20,995.12865
Overall Steps per Second: 10,148.47427

Timestep Collection Time: 2.38322
Timestep Consumption Time: 2.54718
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.93040

Cumulative Model Updates: 111,788
Cumulative Timesteps: 932,489,886

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 932489886...
Checkpoint 932489886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,933.04541
Policy Entropy: 1.77283
Value Function Loss: 0.07188

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14348
Policy Update Magnitude: 0.58700
Value Function Update Magnitude: 0.56336

Collected Steps per Second: 20,615.84393
Overall Steps per Second: 10,114.07085

Timestep Collection Time: 2.42610
Timestep Consumption Time: 2.51909
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.94519

Cumulative Model Updates: 111,794
Cumulative Timesteps: 932,539,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,885.20006
Policy Entropy: 1.76846
Value Function Loss: 0.07313

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14891
Policy Update Magnitude: 0.60215
Value Function Update Magnitude: 0.75655

Collected Steps per Second: 21,197.53085
Overall Steps per Second: 10,114.75287

Timestep Collection Time: 2.36027
Timestep Consumption Time: 2.58616
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.94644

Cumulative Model Updates: 111,800
Cumulative Timesteps: 932,589,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 932589934...
Checkpoint 932589934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,812.12278
Policy Entropy: 1.76849
Value Function Loss: 0.06880

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.60300
Value Function Update Magnitude: 0.71082

Collected Steps per Second: 19,877.46561
Overall Steps per Second: 9,830.05667

Timestep Collection Time: 2.51652
Timestep Consumption Time: 2.57216
PPO Batch Consumption Time: 0.29883
Total Iteration Time: 5.08868

Cumulative Model Updates: 111,806
Cumulative Timesteps: 932,639,956

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,538.45121
Policy Entropy: 1.76695
Value Function Loss: 0.07366

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15553
Policy Update Magnitude: 0.59713
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 21,595.69029
Overall Steps per Second: 10,526.85451

Timestep Collection Time: 2.31639
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.75204

Cumulative Model Updates: 111,812
Cumulative Timesteps: 932,689,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 932689980...
Checkpoint 932689980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,644.00002
Policy Entropy: 1.76119
Value Function Loss: 0.07304

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.14656
Policy Update Magnitude: 0.59883
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 20,549.20201
Overall Steps per Second: 10,090.19623

Timestep Collection Time: 2.43387
Timestep Consumption Time: 2.52283
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.95669

Cumulative Model Updates: 111,818
Cumulative Timesteps: 932,739,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,741.96272
Policy Entropy: 1.76520
Value Function Loss: 0.07571

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.60117
Value Function Update Magnitude: 0.65771

Collected Steps per Second: 21,069.72831
Overall Steps per Second: 10,102.68239

Timestep Collection Time: 2.37374
Timestep Consumption Time: 2.57683
PPO Batch Consumption Time: 0.30140
Total Iteration Time: 4.95057

Cumulative Model Updates: 111,824
Cumulative Timesteps: 932,790,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 932790008...
Checkpoint 932790008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,345.47035
Policy Entropy: 1.76810
Value Function Loss: 0.07665

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.15239
Policy Update Magnitude: 0.60667
Value Function Update Magnitude: 0.65424

Collected Steps per Second: 21,007.38458
Overall Steps per Second: 10,194.26478

Timestep Collection Time: 2.38173
Timestep Consumption Time: 2.52632
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.90805

Cumulative Model Updates: 111,830
Cumulative Timesteps: 932,840,042

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,381.89001
Policy Entropy: 1.76797
Value Function Loss: 0.07935

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14898
Policy Update Magnitude: 0.60115
Value Function Update Magnitude: 0.61764

Collected Steps per Second: 19,618.11092
Overall Steps per Second: 9,519.15514

Timestep Collection Time: 2.54938
Timestep Consumption Time: 2.70466
PPO Batch Consumption Time: 0.32264
Total Iteration Time: 5.25404

Cumulative Model Updates: 111,836
Cumulative Timesteps: 932,890,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 932890056...
Checkpoint 932890056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,040.06220
Policy Entropy: 1.75598
Value Function Loss: 0.07977

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.60248
Value Function Update Magnitude: 0.46573

Collected Steps per Second: 19,417.44783
Overall Steps per Second: 9,360.68071

Timestep Collection Time: 2.57521
Timestep Consumption Time: 2.76671
PPO Batch Consumption Time: 0.33358
Total Iteration Time: 5.34192

Cumulative Model Updates: 111,842
Cumulative Timesteps: 932,940,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,376.17022
Policy Entropy: 1.74928
Value Function Loss: 0.07943

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.59289
Value Function Update Magnitude: 0.36590

Collected Steps per Second: 18,953.52872
Overall Steps per Second: 9,311.53358

Timestep Collection Time: 2.63856
Timestep Consumption Time: 2.73220
PPO Batch Consumption Time: 0.33417
Total Iteration Time: 5.37076

Cumulative Model Updates: 111,848
Cumulative Timesteps: 932,990,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 932990070...
Checkpoint 932990070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,361.39377
Policy Entropy: 1.75434
Value Function Loss: 0.07494

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.15047
Policy Update Magnitude: 0.57688
Value Function Update Magnitude: 0.33027

Collected Steps per Second: 18,465.57152
Overall Steps per Second: 9,178.72934

Timestep Collection Time: 2.70991
Timestep Consumption Time: 2.74183
PPO Batch Consumption Time: 0.33357
Total Iteration Time: 5.45173

Cumulative Model Updates: 111,854
Cumulative Timesteps: 933,040,110

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,826.56168
Policy Entropy: 1.76350
Value Function Loss: 0.07981

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.59775
Value Function Update Magnitude: 0.38599

Collected Steps per Second: 18,899.74570
Overall Steps per Second: 9,252.32472

Timestep Collection Time: 2.64681
Timestep Consumption Time: 2.75983
PPO Batch Consumption Time: 0.33582
Total Iteration Time: 5.40664

Cumulative Model Updates: 111,860
Cumulative Timesteps: 933,090,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933090134...
Checkpoint 933090134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,723.03242
Policy Entropy: 1.76685
Value Function Loss: 0.07842

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.59207
Value Function Update Magnitude: 0.37597

Collected Steps per Second: 18,469.03030
Overall Steps per Second: 9,101.75543

Timestep Collection Time: 2.70843
Timestep Consumption Time: 2.78744
PPO Batch Consumption Time: 0.33321
Total Iteration Time: 5.49586

Cumulative Model Updates: 111,866
Cumulative Timesteps: 933,140,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,534.90041
Policy Entropy: 1.76503
Value Function Loss: 0.08094

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.16685
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.37004

Collected Steps per Second: 18,507.84677
Overall Steps per Second: 9,087.13577

Timestep Collection Time: 2.70166
Timestep Consumption Time: 2.80084
PPO Batch Consumption Time: 0.33986
Total Iteration Time: 5.50250

Cumulative Model Updates: 111,872
Cumulative Timesteps: 933,190,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 933190158...
Checkpoint 933190158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,644.50741
Policy Entropy: 1.75841
Value Function Loss: 0.07346

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.53835
Value Function Update Magnitude: 0.39280

Collected Steps per Second: 18,622.85419
Overall Steps per Second: 9,261.98163

Timestep Collection Time: 2.68670
Timestep Consumption Time: 2.71538
PPO Batch Consumption Time: 0.32670
Total Iteration Time: 5.40208

Cumulative Model Updates: 111,878
Cumulative Timesteps: 933,240,192

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,261.47979
Policy Entropy: 1.76130
Value Function Loss: 0.07937

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.44133

Collected Steps per Second: 17,835.64950
Overall Steps per Second: 9,582.72332

Timestep Collection Time: 2.80427
Timestep Consumption Time: 2.41512
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 5.21939

Cumulative Model Updates: 111,884
Cumulative Timesteps: 933,290,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 933290208...
Checkpoint 933290208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,303.35376
Policy Entropy: 1.76553
Value Function Loss: 0.07645

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.13989
Policy Update Magnitude: 0.59458
Value Function Update Magnitude: 0.40021

Collected Steps per Second: 21,381.89303
Overall Steps per Second: 10,173.45159

Timestep Collection Time: 2.33871
Timestep Consumption Time: 2.57663
PPO Batch Consumption Time: 0.30602
Total Iteration Time: 4.91534

Cumulative Model Updates: 111,890
Cumulative Timesteps: 933,340,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,735.40589
Policy Entropy: 1.76558
Value Function Loss: 0.07585

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.59330
Value Function Update Magnitude: 0.46709

Collected Steps per Second: 20,664.63717
Overall Steps per Second: 9,981.70473

Timestep Collection Time: 2.42046
Timestep Consumption Time: 2.59050
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 5.01097

Cumulative Model Updates: 111,896
Cumulative Timesteps: 933,390,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 933390232...
Checkpoint 933390232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,486.88881
Policy Entropy: 1.76131
Value Function Loss: 0.06857

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.57481

Collected Steps per Second: 21,116.07685
Overall Steps per Second: 10,211.01005

Timestep Collection Time: 2.36796
Timestep Consumption Time: 2.52891
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.89687

Cumulative Model Updates: 111,902
Cumulative Timesteps: 933,440,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,033.57634
Policy Entropy: 1.76366
Value Function Loss: 0.06366

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.55636

Collected Steps per Second: 21,039.55878
Overall Steps per Second: 10,084.84828

Timestep Collection Time: 2.37762
Timestep Consumption Time: 2.58270
PPO Batch Consumption Time: 0.30017
Total Iteration Time: 4.96031

Cumulative Model Updates: 111,908
Cumulative Timesteps: 933,490,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933490258...
Checkpoint 933490258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,764.94966
Policy Entropy: 1.77145
Value Function Loss: 0.06717

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.15315
Policy Update Magnitude: 0.55747
Value Function Update Magnitude: 0.47620

Collected Steps per Second: 18,483.79801
Overall Steps per Second: 9,325.90770

Timestep Collection Time: 2.70659
Timestep Consumption Time: 2.65782
PPO Batch Consumption Time: 0.31224
Total Iteration Time: 5.36441

Cumulative Model Updates: 111,914
Cumulative Timesteps: 933,540,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,359.42194
Policy Entropy: 1.78145
Value Function Loss: 0.07210

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.17983
Policy Update Magnitude: 0.52838
Value Function Update Magnitude: 0.54882

Collected Steps per Second: 17,495.19909
Overall Steps per Second: 8,929.56755

Timestep Collection Time: 2.85930
Timestep Consumption Time: 2.74276
PPO Batch Consumption Time: 0.31801
Total Iteration Time: 5.60206

Cumulative Model Updates: 111,920
Cumulative Timesteps: 933,590,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933590310...
Checkpoint 933590310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,067.33330
Policy Entropy: 1.79563
Value Function Loss: 0.07037

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16782
Policy Update Magnitude: 0.51488
Value Function Update Magnitude: 0.50662

Collected Steps per Second: 19,896.05032
Overall Steps per Second: 9,916.80947

Timestep Collection Time: 2.51397
Timestep Consumption Time: 2.52979
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 5.04376

Cumulative Model Updates: 111,926
Cumulative Timesteps: 933,640,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,318.31456
Policy Entropy: 1.78961
Value Function Loss: 0.07195

Mean KL Divergence: 0.01924
SB3 Clip Fraction: 0.16779
Policy Update Magnitude: 0.50677
Value Function Update Magnitude: 0.54806

Collected Steps per Second: 20,380.04374
Overall Steps per Second: 10,036.53219

Timestep Collection Time: 2.45475
Timestep Consumption Time: 2.52984
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.98459

Cumulative Model Updates: 111,932
Cumulative Timesteps: 933,690,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 933690356...
Checkpoint 933690356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,847.43310
Policy Entropy: 1.77953
Value Function Loss: 0.06737

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.15552
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.48494

Collected Steps per Second: 20,802.81571
Overall Steps per Second: 10,156.88623

Timestep Collection Time: 2.40496
Timestep Consumption Time: 2.52076
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.92572

Cumulative Model Updates: 111,938
Cumulative Timesteps: 933,740,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,596.63203
Policy Entropy: 1.77241
Value Function Loss: 0.07602

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.58801
Value Function Update Magnitude: 0.59519

Collected Steps per Second: 20,979.32805
Overall Steps per Second: 10,130.52278

Timestep Collection Time: 2.38435
Timestep Consumption Time: 2.55340
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.93775

Cumulative Model Updates: 111,944
Cumulative Timesteps: 933,790,408

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 933790408...
Checkpoint 933790408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,560.22776
Policy Entropy: 1.77411
Value Function Loss: 0.07232

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.15013
Policy Update Magnitude: 0.59186
Value Function Update Magnitude: 0.58304

Collected Steps per Second: 20,974.94242
Overall Steps per Second: 10,227.30759

Timestep Collection Time: 2.38532
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.89200

Cumulative Model Updates: 111,950
Cumulative Timesteps: 933,840,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,002.48899
Policy Entropy: 1.77538
Value Function Loss: 0.07425

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.57481
Value Function Update Magnitude: 0.68186

Collected Steps per Second: 21,015.67676
Overall Steps per Second: 10,060.18714

Timestep Collection Time: 2.38003
Timestep Consumption Time: 2.59184
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.97188

Cumulative Model Updates: 111,956
Cumulative Timesteps: 933,890,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 933890458...
Checkpoint 933890458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,451.77048
Policy Entropy: 1.76448
Value Function Loss: 0.06928

Mean KL Divergence: 0.01873
SB3 Clip Fraction: 0.17529
Policy Update Magnitude: 0.51955
Value Function Update Magnitude: 0.66565

Collected Steps per Second: 20,150.78174
Overall Steps per Second: 10,223.66980

Timestep Collection Time: 2.48338
Timestep Consumption Time: 2.41134
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.89472

Cumulative Model Updates: 111,962
Cumulative Timesteps: 933,940,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,126.30354
Policy Entropy: 1.76647
Value Function Loss: 0.07403

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.66668

Collected Steps per Second: 20,377.50295
Overall Steps per Second: 10,102.15804

Timestep Collection Time: 2.45594
Timestep Consumption Time: 2.49805
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.95399

Cumulative Model Updates: 111,968
Cumulative Timesteps: 933,990,546

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 933990546...
Checkpoint 933990546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,707.44676
Policy Entropy: 1.75612
Value Function Loss: 0.07571

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14998
Policy Update Magnitude: 0.60254
Value Function Update Magnitude: 0.67238

Collected Steps per Second: 18,568.62063
Overall Steps per Second: 9,692.01547

Timestep Collection Time: 2.69368
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 5.16074

Cumulative Model Updates: 111,974
Cumulative Timesteps: 934,040,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,289.34485
Policy Entropy: 1.77113
Value Function Loss: 0.07509

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15501
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.66487

Collected Steps per Second: 20,341.91411
Overall Steps per Second: 10,252.84441

Timestep Collection Time: 2.45945
Timestep Consumption Time: 2.42017
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.87962

Cumulative Model Updates: 111,980
Cumulative Timesteps: 934,090,594

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 934090594...
Checkpoint 934090594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,058.68756
Policy Entropy: 1.76960
Value Function Loss: 0.07956

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13987
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.49557

Collected Steps per Second: 20,314.38115
Overall Steps per Second: 10,123.98205

Timestep Collection Time: 2.46259
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.94134

Cumulative Model Updates: 111,986
Cumulative Timesteps: 934,140,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,276.19075
Policy Entropy: 1.77730
Value Function Loss: 0.08263

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14948
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.39845

Collected Steps per Second: 20,618.56350
Overall Steps per Second: 10,261.98432

Timestep Collection Time: 2.42529
Timestep Consumption Time: 2.44765
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.87294

Cumulative Model Updates: 111,992
Cumulative Timesteps: 934,190,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 934190626...
Checkpoint 934190626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,421.62821
Policy Entropy: 1.76014
Value Function Loss: 0.08588

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.17728
Policy Update Magnitude: 0.51419
Value Function Update Magnitude: 0.36083

Collected Steps per Second: 19,427.75876
Overall Steps per Second: 9,936.42756

Timestep Collection Time: 2.57508
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 5.03481

Cumulative Model Updates: 111,998
Cumulative Timesteps: 934,240,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,393.27799
Policy Entropy: 1.75648
Value Function Loss: 0.07795

Mean KL Divergence: 0.02018
SB3 Clip Fraction: 0.17827
Policy Update Magnitude: 0.54047
Value Function Update Magnitude: 0.43080

Collected Steps per Second: 21,399.90771
Overall Steps per Second: 10,309.78154

Timestep Collection Time: 2.33730
Timestep Consumption Time: 2.51421
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.85151

Cumulative Model Updates: 112,004
Cumulative Timesteps: 934,290,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 934290672...
Checkpoint 934290672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,110.18451
Policy Entropy: 1.75724
Value Function Loss: 0.07582

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.47156

Collected Steps per Second: 21,492.85760
Overall Steps per Second: 10,374.74670

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.49374
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.82074

Cumulative Model Updates: 112,010
Cumulative Timesteps: 934,340,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,473.94380
Policy Entropy: 1.76608
Value Function Loss: 0.07232

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.59035
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,010.48098
Overall Steps per Second: 10,481.53803

Timestep Collection Time: 2.27255
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77220

Cumulative Model Updates: 112,016
Cumulative Timesteps: 934,390,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 934390706...
Checkpoint 934390706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,141.30606
Policy Entropy: 1.77544
Value Function Loss: 0.07224

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.59370
Value Function Update Magnitude: 0.63901

Collected Steps per Second: 21,476.16542
Overall Steps per Second: 10,564.32255

Timestep Collection Time: 2.32900
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.73462

Cumulative Model Updates: 112,022
Cumulative Timesteps: 934,440,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,447.67517
Policy Entropy: 1.76813
Value Function Loss: 0.07916

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.59517
Value Function Update Magnitude: 0.58535

Collected Steps per Second: 22,122.53257
Overall Steps per Second: 10,504.72787

Timestep Collection Time: 2.26077
Timestep Consumption Time: 2.50032
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.76109

Cumulative Model Updates: 112,028
Cumulative Timesteps: 934,490,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 934490738...
Checkpoint 934490738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,802.79033
Policy Entropy: 1.77422
Value Function Loss: 0.07885

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15636
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.54845

Collected Steps per Second: 21,863.21698
Overall Steps per Second: 10,574.76336

Timestep Collection Time: 2.28759
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.72956

Cumulative Model Updates: 112,034
Cumulative Timesteps: 934,540,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,715.62278
Policy Entropy: 1.75830
Value Function Loss: 0.08324

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14737
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.42207

Collected Steps per Second: 22,155.34982
Overall Steps per Second: 10,542.26491

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.74661

Cumulative Model Updates: 112,040
Cumulative Timesteps: 934,590,792

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 934590792...
Checkpoint 934590792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,343.77050
Policy Entropy: 1.76270
Value Function Loss: 0.07793

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.58383
Value Function Update Magnitude: 0.42140

Collected Steps per Second: 21,872.95444
Overall Steps per Second: 10,584.31685

Timestep Collection Time: 2.28803
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.72832

Cumulative Model Updates: 112,046
Cumulative Timesteps: 934,640,838

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,078.54311
Policy Entropy: 1.77184
Value Function Loss: 0.07668

Mean KL Divergence: 0.01817
SB3 Clip Fraction: 0.17093
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.46893

Collected Steps per Second: 22,134.05997
Overall Steps per Second: 10,507.24744

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.75900

Cumulative Model Updates: 112,052
Cumulative Timesteps: 934,690,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 934690842...
Checkpoint 934690842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,739.89565
Policy Entropy: 1.79711
Value Function Loss: 0.07256

Mean KL Divergence: 0.01883
SB3 Clip Fraction: 0.17365
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.51343

Collected Steps per Second: 21,826.22399
Overall Steps per Second: 10,563.04649

Timestep Collection Time: 2.29174
Timestep Consumption Time: 2.44364
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.73538

Cumulative Model Updates: 112,058
Cumulative Timesteps: 934,740,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,080.15303
Policy Entropy: 1.78839
Value Function Loss: 0.07144

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.16020
Policy Update Magnitude: 0.57390
Value Function Update Magnitude: 0.49590

Collected Steps per Second: 22,219.61534
Overall Steps per Second: 10,528.95357

Timestep Collection Time: 2.25215
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.75280

Cumulative Model Updates: 112,064
Cumulative Timesteps: 934,790,904

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 934790904...
Checkpoint 934790904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,762.81557
Policy Entropy: 1.78609
Value Function Loss: 0.07358

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15605
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.54485

Collected Steps per Second: 21,862.96823
Overall Steps per Second: 10,595.05287

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.43348
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.72164

Cumulative Model Updates: 112,070
Cumulative Timesteps: 934,840,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,560.44948
Policy Entropy: 1.78548
Value Function Loss: 0.07436

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.16020
Policy Update Magnitude: 0.55998
Value Function Update Magnitude: 0.57483

Collected Steps per Second: 22,165.14545
Overall Steps per Second: 10,490.60740

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.76674

Cumulative Model Updates: 112,076
Cumulative Timesteps: 934,890,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 934890936...
Checkpoint 934890936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,033.02933
Policy Entropy: 1.80420
Value Function Loss: 0.07303

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.65004

Collected Steps per Second: 21,823.75375
Overall Steps per Second: 10,401.74326

Timestep Collection Time: 2.29136
Timestep Consumption Time: 2.51611
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.80746

Cumulative Model Updates: 112,082
Cumulative Timesteps: 934,940,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,389.04891
Policy Entropy: 1.80327
Value Function Loss: 0.06713

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.73177

Collected Steps per Second: 22,324.69503
Overall Steps per Second: 10,687.90364

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.67893

Cumulative Model Updates: 112,088
Cumulative Timesteps: 934,990,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 934990950...
Checkpoint 934990950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,119.45153
Policy Entropy: 1.78592
Value Function Loss: 0.06315

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.73507

Collected Steps per Second: 21,816.40545
Overall Steps per Second: 10,591.83139

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.72326

Cumulative Model Updates: 112,094
Cumulative Timesteps: 935,040,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,292.53020
Policy Entropy: 1.77276
Value Function Loss: 0.06815

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14663
Policy Update Magnitude: 0.58058
Value Function Update Magnitude: 0.69707

Collected Steps per Second: 21,916.32607
Overall Steps per Second: 10,602.73297

Timestep Collection Time: 2.28177
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.71652

Cumulative Model Updates: 112,100
Cumulative Timesteps: 935,090,986

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 935090986...
Checkpoint 935090986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,045.44045
Policy Entropy: 1.76101
Value Function Loss: 0.07206

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.17261
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.66086

Collected Steps per Second: 21,924.83733
Overall Steps per Second: 10,625.49990

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.70811

Cumulative Model Updates: 112,106
Cumulative Timesteps: 935,141,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,458.74374
Policy Entropy: 1.76903
Value Function Loss: 0.07195

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.15332
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.76946

Collected Steps per Second: 22,247.11031
Overall Steps per Second: 10,545.14431

Timestep Collection Time: 2.24748
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74152

Cumulative Model Updates: 112,112
Cumulative Timesteps: 935,191,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 935191012...
Checkpoint 935191012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,396.39605
Policy Entropy: 1.77564
Value Function Loss: 0.07526

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.58437
Value Function Update Magnitude: 0.77933

Collected Steps per Second: 22,168.64718
Overall Steps per Second: 10,488.50679

Timestep Collection Time: 2.25553
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.76731

Cumulative Model Updates: 112,118
Cumulative Timesteps: 935,241,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,433.31638
Policy Entropy: 1.77561
Value Function Loss: 0.07411

Mean KL Divergence: 0.02185
SB3 Clip Fraction: 0.18835
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.73957

Collected Steps per Second: 21,935.34792
Overall Steps per Second: 10,444.42307

Timestep Collection Time: 2.27979
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.78801

Cumulative Model Updates: 112,124
Cumulative Timesteps: 935,291,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 935291022...
Checkpoint 935291022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,653.41012
Policy Entropy: 1.77403
Value Function Loss: 0.07134

Mean KL Divergence: 0.02020
SB3 Clip Fraction: 0.17830
Policy Update Magnitude: 0.49663
Value Function Update Magnitude: 0.77980

Collected Steps per Second: 22,019.88691
Overall Steps per Second: 10,618.15985

Timestep Collection Time: 2.27204
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.71174

Cumulative Model Updates: 112,130
Cumulative Timesteps: 935,341,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,128.35351
Policy Entropy: 1.78677
Value Function Loss: 0.07062

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.16389
Policy Update Magnitude: 0.51008
Value Function Update Magnitude: 0.75058

Collected Steps per Second: 22,107.58474
Overall Steps per Second: 10,497.55881

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.76549

Cumulative Model Updates: 112,136
Cumulative Timesteps: 935,391,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 935391078...
Checkpoint 935391078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,714.78254
Policy Entropy: 1.78980
Value Function Loss: 0.06859

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.51492
Value Function Update Magnitude: 0.75339

Collected Steps per Second: 22,065.23117
Overall Steps per Second: 10,634.42992

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70340

Cumulative Model Updates: 112,142
Cumulative Timesteps: 935,441,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,814.45769
Policy Entropy: 1.80452
Value Function Loss: 0.06481

Mean KL Divergence: 0.01673
SB3 Clip Fraction: 0.16197
Policy Update Magnitude: 0.51635
Value Function Update Magnitude: 0.71326

Collected Steps per Second: 21,573.90072
Overall Steps per Second: 10,508.70440

Timestep Collection Time: 2.31984
Timestep Consumption Time: 2.44269
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.76253

Cumulative Model Updates: 112,148
Cumulative Timesteps: 935,491,144

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 935491144...
Checkpoint 935491144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,632.40273
Policy Entropy: 1.80094
Value Function Loss: 0.06744

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.16514
Policy Update Magnitude: 0.50742
Value Function Update Magnitude: 0.66571

Collected Steps per Second: 21,275.23062
Overall Steps per Second: 10,635.65116

Timestep Collection Time: 2.35034
Timestep Consumption Time: 2.35121
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.70155

Cumulative Model Updates: 112,154
Cumulative Timesteps: 935,541,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,991.73078
Policy Entropy: 1.79661
Value Function Loss: 0.07166

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.17096
Policy Update Magnitude: 0.53035
Value Function Update Magnitude: 0.64538

Collected Steps per Second: 21,331.47914
Overall Steps per Second: 10,362.58886

Timestep Collection Time: 2.34424
Timestep Consumption Time: 2.48139
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 4.82563

Cumulative Model Updates: 112,160
Cumulative Timesteps: 935,591,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 935591154...
Checkpoint 935591154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,482.35375
Policy Entropy: 1.79397
Value Function Loss: 0.07327

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.17032
Policy Update Magnitude: 0.51985
Value Function Update Magnitude: 0.56587

Collected Steps per Second: 21,315.05832
Overall Steps per Second: 10,648.29306

Timestep Collection Time: 2.34707
Timestep Consumption Time: 2.35114
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.69822

Cumulative Model Updates: 112,166
Cumulative Timesteps: 935,641,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,544.91303
Policy Entropy: 1.80448
Value Function Loss: 0.07926

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.54625
Value Function Update Magnitude: 0.45411

Collected Steps per Second: 21,289.62212
Overall Steps per Second: 10,448.51621

Timestep Collection Time: 2.34941
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.78709

Cumulative Model Updates: 112,172
Cumulative Timesteps: 935,691,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935691200...
Checkpoint 935691200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,459.25484
Policy Entropy: 1.81557
Value Function Loss: 0.08080

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.37609

Collected Steps per Second: 21,264.62421
Overall Steps per Second: 10,580.95002

Timestep Collection Time: 2.35132
Timestep Consumption Time: 2.37415
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.72547

Cumulative Model Updates: 112,178
Cumulative Timesteps: 935,741,200

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,753.24824
Policy Entropy: 1.82083
Value Function Loss: 0.08826

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15682
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.33686

Collected Steps per Second: 21,785.39962
Overall Steps per Second: 10,527.31660

Timestep Collection Time: 2.29677
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.75297

Cumulative Model Updates: 112,184
Cumulative Timesteps: 935,791,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 935791236...
Checkpoint 935791236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,685.42476
Policy Entropy: 1.82686
Value Function Loss: 0.08333

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.15890
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.31113

Collected Steps per Second: 21,995.87107
Overall Steps per Second: 10,687.00760

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.40581
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.67933

Cumulative Model Updates: 112,190
Cumulative Timesteps: 935,841,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,306.12151
Policy Entropy: 1.83709
Value Function Loss: 0.08549

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.15463
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.30864

Collected Steps per Second: 22,073.22177
Overall Steps per Second: 10,541.70424

Timestep Collection Time: 2.26600
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.74477

Cumulative Model Updates: 112,196
Cumulative Timesteps: 935,891,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935891262...
Checkpoint 935891262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,397.57910
Policy Entropy: 1.82489
Value Function Loss: 0.08101

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.33139

Collected Steps per Second: 22,138.51156
Overall Steps per Second: 10,543.25867

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.48595
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.74635

Cumulative Model Updates: 112,202
Cumulative Timesteps: 935,941,304

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,908.11412
Policy Entropy: 1.82241
Value Function Loss: 0.07925

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.28026

Collected Steps per Second: 22,007.61944
Overall Steps per Second: 10,437.09998

Timestep Collection Time: 2.27321
Timestep Consumption Time: 2.52007
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.79329

Cumulative Model Updates: 112,208
Cumulative Timesteps: 935,991,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 935991332...
Checkpoint 935991332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,742.81276
Policy Entropy: 1.82125
Value Function Loss: 0.07406

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.56534
Value Function Update Magnitude: 0.31117

Collected Steps per Second: 21,937.27091
Overall Steps per Second: 10,669.73571

Timestep Collection Time: 2.28123
Timestep Consumption Time: 2.40904
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.69028

Cumulative Model Updates: 112,214
Cumulative Timesteps: 936,041,376

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,584.12068
Policy Entropy: 1.81427
Value Function Loss: 0.07238

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.26482

Collected Steps per Second: 22,050.36970
Overall Steps per Second: 10,427.83077

Timestep Collection Time: 2.26899
Timestep Consumption Time: 2.52894
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.79793

Cumulative Model Updates: 112,220
Cumulative Timesteps: 936,091,408

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 936091408...
Checkpoint 936091408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,478.23839
Policy Entropy: 1.80619
Value Function Loss: 0.07498

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.36528

Collected Steps per Second: 22,160.59707
Overall Steps per Second: 10,670.38344

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.68737

Cumulative Model Updates: 112,226
Cumulative Timesteps: 936,141,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,653.68474
Policy Entropy: 1.80265
Value Function Loss: 0.07231

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.59237
Value Function Update Magnitude: 0.56038

Collected Steps per Second: 22,307.66884
Overall Steps per Second: 10,621.26049

Timestep Collection Time: 2.24192
Timestep Consumption Time: 2.46675
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.70867

Cumulative Model Updates: 112,232
Cumulative Timesteps: 936,191,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 936191436...
Checkpoint 936191436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,178.95400
Policy Entropy: 1.81316
Value Function Loss: 0.07158

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14173
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.54264

Collected Steps per Second: 21,741.24183
Overall Steps per Second: 10,438.74935

Timestep Collection Time: 2.30014
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.79061

Cumulative Model Updates: 112,238
Cumulative Timesteps: 936,241,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,918.76211
Policy Entropy: 1.80965
Value Function Loss: 0.06625

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15087
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.52532

Collected Steps per Second: 21,812.14479
Overall Steps per Second: 10,452.80655

Timestep Collection Time: 2.29276
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.78436

Cumulative Model Updates: 112,244
Cumulative Timesteps: 936,291,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 936291454...
Checkpoint 936291454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,667.81079
Policy Entropy: 1.81416
Value Function Loss: 0.07033

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.51359
Value Function Update Magnitude: 0.52318

Collected Steps per Second: 21,687.70417
Overall Steps per Second: 10,560.87399

Timestep Collection Time: 2.30647
Timestep Consumption Time: 2.43007
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.73654

Cumulative Model Updates: 112,250
Cumulative Timesteps: 936,341,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,425.84285
Policy Entropy: 1.80825
Value Function Loss: 0.07138

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.16432
Policy Update Magnitude: 0.51442
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 22,191.06830
Overall Steps per Second: 10,553.42968

Timestep Collection Time: 2.25397
Timestep Consumption Time: 2.48553
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.73950

Cumulative Model Updates: 112,256
Cumulative Timesteps: 936,391,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936391494...
Checkpoint 936391494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,184.89344
Policy Entropy: 1.81647
Value Function Loss: 0.07099

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.15387
Policy Update Magnitude: 0.53689
Value Function Update Magnitude: 0.71865

Collected Steps per Second: 21,955.17234
Overall Steps per Second: 10,573.25281

Timestep Collection Time: 2.27883
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.73194

Cumulative Model Updates: 112,262
Cumulative Timesteps: 936,441,526

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,706.12633
Policy Entropy: 1.81479
Value Function Loss: 0.06563

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14161
Policy Update Magnitude: 0.57085
Value Function Update Magnitude: 0.67954

Collected Steps per Second: 22,184.68446
Overall Steps per Second: 10,472.78276

Timestep Collection Time: 2.25462
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.77600

Cumulative Model Updates: 112,268
Cumulative Timesteps: 936,491,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936491544...
Checkpoint 936491544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,664.07187
Policy Entropy: 1.82162
Value Function Loss: 0.06593

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.57319
Value Function Update Magnitude: 0.58297

Collected Steps per Second: 21,917.68626
Overall Steps per Second: 10,583.82744

Timestep Collection Time: 2.28236
Timestep Consumption Time: 2.44410
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.72646

Cumulative Model Updates: 112,274
Cumulative Timesteps: 936,541,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,595.49529
Policy Entropy: 1.82261
Value Function Loss: 0.06019

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14612
Policy Update Magnitude: 0.56394
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 22,233.94930
Overall Steps per Second: 10,558.98817

Timestep Collection Time: 2.25025
Timestep Consumption Time: 2.48808
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.73833

Cumulative Model Updates: 112,280
Cumulative Timesteps: 936,591,600

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 936591600...
Checkpoint 936591600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,519.86248
Policy Entropy: 1.81014
Value Function Loss: 0.07325

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.52437
Value Function Update Magnitude: 0.51149

Collected Steps per Second: 21,966.44713
Overall Steps per Second: 10,599.26263

Timestep Collection Time: 2.27720
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.71938

Cumulative Model Updates: 112,286
Cumulative Timesteps: 936,641,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,692.40916
Policy Entropy: 1.82010
Value Function Loss: 0.07196

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.16970
Policy Update Magnitude: 0.50859
Value Function Update Magnitude: 0.66330

Collected Steps per Second: 22,190.83935
Overall Steps per Second: 10,460.70764

Timestep Collection Time: 2.25381
Timestep Consumption Time: 2.52732
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.78113

Cumulative Model Updates: 112,292
Cumulative Timesteps: 936,691,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 936691636...
Checkpoint 936691636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,960.85491
Policy Entropy: 1.82044
Value Function Loss: 0.07511

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.74717

Collected Steps per Second: 21,847.25265
Overall Steps per Second: 10,569.74561

Timestep Collection Time: 2.29091
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.73521

Cumulative Model Updates: 112,298
Cumulative Timesteps: 936,741,686

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,979.22015
Policy Entropy: 1.82508
Value Function Loss: 0.06870

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.16446
Policy Update Magnitude: 0.56216
Value Function Update Magnitude: 0.74815

Collected Steps per Second: 22,255.18034
Overall Steps per Second: 10,550.88874

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.49386
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.74197

Cumulative Model Updates: 112,304
Cumulative Timesteps: 936,791,718

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 936791718...
Checkpoint 936791718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,984.46050
Policy Entropy: 1.81983
Value Function Loss: 0.07305

Mean KL Divergence: 0.01635
SB3 Clip Fraction: 0.15630
Policy Update Magnitude: 0.55494
Value Function Update Magnitude: 0.69739

Collected Steps per Second: 21,986.33640
Overall Steps per Second: 10,628.32069

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.43134
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.70648

Cumulative Model Updates: 112,310
Cumulative Timesteps: 936,841,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,461.90466
Policy Entropy: 1.81058
Value Function Loss: 0.07298

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.75829

Collected Steps per Second: 21,929.50235
Overall Steps per Second: 10,491.64191

Timestep Collection Time: 2.28003
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.76570

Cumulative Model Updates: 112,316
Cumulative Timesteps: 936,891,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 936891740...
Checkpoint 936891740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,200.55791
Policy Entropy: 1.79798
Value Function Loss: 0.07478

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.15235
Policy Update Magnitude: 0.58457
Value Function Update Magnitude: 0.73086

Collected Steps per Second: 21,521.01800
Overall Steps per Second: 10,526.25331

Timestep Collection Time: 2.32368
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.75079

Cumulative Model Updates: 112,322
Cumulative Timesteps: 936,941,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,546.45830
Policy Entropy: 1.80059
Value Function Loss: 0.06643

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.65521

Collected Steps per Second: 22,034.98545
Overall Steps per Second: 10,545.22739

Timestep Collection Time: 2.26966
Timestep Consumption Time: 2.47296
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.74262

Cumulative Model Updates: 112,328
Cumulative Timesteps: 936,991,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 936991760...
Checkpoint 936991760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,480.84362
Policy Entropy: 1.78749
Value Function Loss: 0.06724

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.62653

Collected Steps per Second: 21,838.49304
Overall Steps per Second: 10,587.20216

Timestep Collection Time: 2.29036
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.72438

Cumulative Model Updates: 112,334
Cumulative Timesteps: 937,041,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,207.18774
Policy Entropy: 1.79180
Value Function Loss: 0.06437

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.65128

Collected Steps per Second: 22,317.65661
Overall Steps per Second: 10,494.12018

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.52561
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.76724

Cumulative Model Updates: 112,340
Cumulative Timesteps: 937,091,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937091806...
Checkpoint 937091806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,544.12148
Policy Entropy: 1.77597
Value Function Loss: 0.06879

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.58512
Value Function Update Magnitude: 0.68984

Collected Steps per Second: 21,743.91711
Overall Steps per Second: 10,557.84670

Timestep Collection Time: 2.29986
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73657

Cumulative Model Updates: 112,346
Cumulative Timesteps: 937,141,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,006.03779
Policy Entropy: 1.78783
Value Function Loss: 0.07650

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.62258

Collected Steps per Second: 21,915.89234
Overall Steps per Second: 10,597.76111

Timestep Collection Time: 2.28172
Timestep Consumption Time: 2.43682
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.71854

Cumulative Model Updates: 112,352
Cumulative Timesteps: 937,191,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 937191820...
Checkpoint 937191820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,810.61289
Policy Entropy: 1.78291
Value Function Loss: 0.07658

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.59964
Value Function Update Magnitude: 0.57224

Collected Steps per Second: 22,047.96318
Overall Steps per Second: 10,640.91057

Timestep Collection Time: 2.26796
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.69922

Cumulative Model Updates: 112,358
Cumulative Timesteps: 937,241,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,591.81363
Policy Entropy: 1.78205
Value Function Loss: 0.07392

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.50706

Collected Steps per Second: 21,961.00300
Overall Steps per Second: 10,433.44010

Timestep Collection Time: 2.27813
Timestep Consumption Time: 2.51703
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.79516

Cumulative Model Updates: 112,364
Cumulative Timesteps: 937,291,854

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 937291854...
Checkpoint 937291854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,824.02007
Policy Entropy: 1.78526
Value Function Loss: 0.07071

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14328
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.43530

Collected Steps per Second: 21,865.48556
Overall Steps per Second: 10,572.60760

Timestep Collection Time: 2.28781
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.73147

Cumulative Model Updates: 112,370
Cumulative Timesteps: 937,341,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,334.13454
Policy Entropy: 1.79172
Value Function Loss: 0.06885

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.43043

Collected Steps per Second: 22,206.39602
Overall Steps per Second: 10,496.57004

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.51367
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.76689

Cumulative Model Updates: 112,376
Cumulative Timesteps: 937,391,914

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 937391914...
Checkpoint 937391914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,648.72487
Policy Entropy: 1.79313
Value Function Loss: 0.06830

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.56820
Value Function Update Magnitude: 0.50576

Collected Steps per Second: 22,001.21326
Overall Steps per Second: 10,639.64541

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.70204

Cumulative Model Updates: 112,382
Cumulative Timesteps: 937,441,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,041.51874
Policy Entropy: 1.78875
Value Function Loss: 0.06573

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.57592
Value Function Update Magnitude: 0.59188

Collected Steps per Second: 22,197.65974
Overall Steps per Second: 10,475.12431

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.52163
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.77493

Cumulative Model Updates: 112,388
Cumulative Timesteps: 937,491,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 937491960...
Checkpoint 937491960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,452.41190
Policy Entropy: 1.78943
Value Function Loss: 0.06819

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.69235

Collected Steps per Second: 21,709.87632
Overall Steps per Second: 10,487.71239

Timestep Collection Time: 2.30365
Timestep Consumption Time: 2.46498
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.76863

Cumulative Model Updates: 112,394
Cumulative Timesteps: 937,541,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,798.01408
Policy Entropy: 1.77242
Value Function Loss: 0.07258

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.59547
Value Function Update Magnitude: 0.68257

Collected Steps per Second: 21,540.05955
Overall Steps per Second: 10,541.31395

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.74381

Cumulative Model Updates: 112,400
Cumulative Timesteps: 937,591,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 937591978...
Checkpoint 937591978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,008.51914
Policy Entropy: 1.78825
Value Function Loss: 0.07306

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.59269
Value Function Update Magnitude: 0.65203

Collected Steps per Second: 21,985.22879
Overall Steps per Second: 10,619.84698

Timestep Collection Time: 2.27471
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.70911

Cumulative Model Updates: 112,406
Cumulative Timesteps: 937,641,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,942.52121
Policy Entropy: 1.78207
Value Function Loss: 0.07170

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.13664
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.62242

Collected Steps per Second: 22,287.36714
Overall Steps per Second: 10,517.78542

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75613

Cumulative Model Updates: 112,412
Cumulative Timesteps: 937,692,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 937692012...
Checkpoint 937692012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,756.17352
Policy Entropy: 1.79246
Value Function Loss: 0.07180

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.58151
Value Function Update Magnitude: 0.70762

Collected Steps per Second: 22,069.75709
Overall Steps per Second: 10,621.35996

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.70975

Cumulative Model Updates: 112,418
Cumulative Timesteps: 937,742,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,528.07699
Policy Entropy: 1.77628
Value Function Loss: 0.06782

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.14402
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.70142

Collected Steps per Second: 22,142.79179
Overall Steps per Second: 10,516.86520

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.75693

Cumulative Model Updates: 112,424
Cumulative Timesteps: 937,792,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937792064...
Checkpoint 937792064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,578.82669
Policy Entropy: 1.77369
Value Function Loss: 0.07009

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.58713
Value Function Update Magnitude: 0.64298

Collected Steps per Second: 21,932.23172
Overall Steps per Second: 10,621.15740

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.42842
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.70871

Cumulative Model Updates: 112,430
Cumulative Timesteps: 937,842,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,986.73537
Policy Entropy: 1.77162
Value Function Loss: 0.06680

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.53314

Collected Steps per Second: 21,660.29875
Overall Steps per Second: 10,439.61994

Timestep Collection Time: 2.30957
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.79194

Cumulative Model Updates: 112,436
Cumulative Timesteps: 937,892,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 937892102...
Checkpoint 937892102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,111.22261
Policy Entropy: 1.77945
Value Function Loss: 0.06638

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.42094

Collected Steps per Second: 21,981.71968
Overall Steps per Second: 10,618.01449

Timestep Collection Time: 2.27644
Timestep Consumption Time: 2.43631
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.71275

Cumulative Model Updates: 112,442
Cumulative Timesteps: 937,942,142

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,353.33719
Policy Entropy: 1.76481
Value Function Loss: 0.06302

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.45630

Collected Steps per Second: 22,014.73264
Overall Steps per Second: 10,499.64747

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.76473

Cumulative Model Updates: 112,448
Cumulative Timesteps: 937,992,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 937992170...
Checkpoint 937992170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,495.74243
Policy Entropy: 1.76043
Value Function Loss: 0.06951

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.52052

Collected Steps per Second: 21,903.99232
Overall Steps per Second: 10,629.87175

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.70636

Cumulative Model Updates: 112,454
Cumulative Timesteps: 938,042,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,544.49722
Policy Entropy: 1.75049
Value Function Loss: 0.06933

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14425
Policy Update Magnitude: 0.58417
Value Function Update Magnitude: 0.56881

Collected Steps per Second: 21,728.07979
Overall Steps per Second: 10,528.14296

Timestep Collection Time: 2.30126
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.74937

Cumulative Model Updates: 112,460
Cumulative Timesteps: 938,092,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938092200...
Checkpoint 938092200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,652.80690
Policy Entropy: 1.75948
Value Function Loss: 0.07039

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.67332

Collected Steps per Second: 21,453.50016
Overall Steps per Second: 10,534.60520

Timestep Collection Time: 2.33127
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.74759

Cumulative Model Updates: 112,466
Cumulative Timesteps: 938,142,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,758.34706
Policy Entropy: 1.75724
Value Function Loss: 0.06564

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.65054

Collected Steps per Second: 21,389.09785
Overall Steps per Second: 10,350.01259

Timestep Collection Time: 2.33764
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.83091

Cumulative Model Updates: 112,472
Cumulative Timesteps: 938,192,214

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 938192214...
Checkpoint 938192214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,127.49464
Policy Entropy: 1.76819
Value Function Loss: 0.07076

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.14335
Policy Update Magnitude: 0.58168
Value Function Update Magnitude: 0.56547

Collected Steps per Second: 21,073.98159
Overall Steps per Second: 10,466.83499

Timestep Collection Time: 2.37278
Timestep Consumption Time: 2.40459
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.77738

Cumulative Model Updates: 112,478
Cumulative Timesteps: 938,242,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,136.02788
Policy Entropy: 1.75990
Value Function Loss: 0.06593

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.62568

Collected Steps per Second: 21,733.87388
Overall Steps per Second: 10,726.65243

Timestep Collection Time: 2.30148
Timestep Consumption Time: 2.36167
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.66315

Cumulative Model Updates: 112,484
Cumulative Timesteps: 938,292,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938292238...
Checkpoint 938292238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,963.13332
Policy Entropy: 1.76826
Value Function Loss: 0.07246

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.50140
Value Function Update Magnitude: 0.60003

Collected Steps per Second: 21,653.24672
Overall Steps per Second: 10,737.24690

Timestep Collection Time: 2.31106
Timestep Consumption Time: 2.34954
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66060

Cumulative Model Updates: 112,490
Cumulative Timesteps: 938,342,280

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,771.43995
Policy Entropy: 1.76070
Value Function Loss: 0.07426

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.70643

Collected Steps per Second: 21,695.76926
Overall Steps per Second: 10,429.90892

Timestep Collection Time: 2.30506
Timestep Consumption Time: 2.48981
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.79486

Cumulative Model Updates: 112,496
Cumulative Timesteps: 938,392,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938392290...
Checkpoint 938392290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,246.83701
Policy Entropy: 1.76152
Value Function Loss: 0.08060

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.14959
Policy Update Magnitude: 0.59947
Value Function Update Magnitude: 0.67612

Collected Steps per Second: 22,030.79368
Overall Steps per Second: 10,600.27137

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.71743

Cumulative Model Updates: 112,502
Cumulative Timesteps: 938,442,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,496.25285
Policy Entropy: 1.75499
Value Function Loss: 0.07670

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.59909
Value Function Update Magnitude: 0.49313

Collected Steps per Second: 22,117.27925
Overall Steps per Second: 10,567.96806

Timestep Collection Time: 2.26104
Timestep Consumption Time: 2.47100
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.73204

Cumulative Model Updates: 112,508
Cumulative Timesteps: 938,492,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 938492304...
Checkpoint 938492304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,524.19826
Policy Entropy: 1.76343
Value Function Loss: 0.07853

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.58985
Value Function Update Magnitude: 0.53656

Collected Steps per Second: 22,060.78552
Overall Steps per Second: 10,535.55839

Timestep Collection Time: 2.26773
Timestep Consumption Time: 2.48076
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.74849

Cumulative Model Updates: 112,514
Cumulative Timesteps: 938,542,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,118.25174
Policy Entropy: 1.76429
Value Function Loss: 0.07143

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13857
Policy Update Magnitude: 0.59369
Value Function Update Magnitude: 0.70854

Collected Steps per Second: 22,525.82287
Overall Steps per Second: 10,598.60971

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71817

Cumulative Model Updates: 112,520
Cumulative Timesteps: 938,592,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 938592338...
Checkpoint 938592338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,530.13714
Policy Entropy: 1.76522
Value Function Loss: 0.07695

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.14618
Policy Update Magnitude: 0.59743
Value Function Update Magnitude: 0.66690

Collected Steps per Second: 22,059.02397
Overall Steps per Second: 10,467.94761

Timestep Collection Time: 2.26710
Timestep Consumption Time: 2.51034
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.77744

Cumulative Model Updates: 112,526
Cumulative Timesteps: 938,642,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,692.70736
Policy Entropy: 1.75122
Value Function Loss: 0.07657

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.59296
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 22,060.81648
Overall Steps per Second: 10,445.66537

Timestep Collection Time: 2.26755
Timestep Consumption Time: 2.52142
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.78897

Cumulative Model Updates: 112,532
Cumulative Timesteps: 938,692,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 938692372...
Checkpoint 938692372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,535.55543
Policy Entropy: 1.74467
Value Function Loss: 0.07720

Mean KL Divergence: 0.01859
SB3 Clip Fraction: 0.16834
Policy Update Magnitude: 0.54969
Value Function Update Magnitude: 0.47630

Collected Steps per Second: 22,055.12609
Overall Steps per Second: 10,710.59594

Timestep Collection Time: 2.26786
Timestep Consumption Time: 2.40209
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.66995

Cumulative Model Updates: 112,538
Cumulative Timesteps: 938,742,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,722.67463
Policy Entropy: 1.73651
Value Function Loss: 0.07033

Mean KL Divergence: 0.01852
SB3 Clip Fraction: 0.16863
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.41870

Collected Steps per Second: 22,286.99997
Overall Steps per Second: 10,541.20467

Timestep Collection Time: 2.24436
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.74519

Cumulative Model Updates: 112,544
Cumulative Timesteps: 938,792,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938792410...
Checkpoint 938792410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,022.47260
Policy Entropy: 1.74158
Value Function Loss: 0.07099

Mean KL Divergence: 0.02034
SB3 Clip Fraction: 0.17930
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.41611

Collected Steps per Second: 22,161.74011
Overall Steps per Second: 10,305.51424

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.59625
PPO Batch Consumption Time: 0.30650
Total Iteration Time: 4.85294

Cumulative Model Updates: 112,550
Cumulative Timesteps: 938,842,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,928.62891
Policy Entropy: 1.74259
Value Function Loss: 0.07226

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16374
Policy Update Magnitude: 0.50117
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 22,172.81535
Overall Steps per Second: 10,530.32881

Timestep Collection Time: 2.25628
Timestep Consumption Time: 2.49457
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.75085

Cumulative Model Updates: 112,556
Cumulative Timesteps: 938,892,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 938892450...
Checkpoint 938892450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,358.92622
Policy Entropy: 1.73002
Value Function Loss: 0.07197

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16240
Policy Update Magnitude: 0.53379
Value Function Update Magnitude: 0.61366

Collected Steps per Second: 21,856.88878
Overall Steps per Second: 10,467.36390

Timestep Collection Time: 2.28779
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.77713

Cumulative Model Updates: 112,562
Cumulative Timesteps: 938,942,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,320.77123
Policy Entropy: 1.73882
Value Function Loss: 0.07006

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.17423
Policy Update Magnitude: 0.51023
Value Function Update Magnitude: 0.56651

Collected Steps per Second: 22,304.61990
Overall Steps per Second: 10,691.03405

Timestep Collection Time: 2.24294
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.67944

Cumulative Model Updates: 112,568
Cumulative Timesteps: 938,992,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 938992482...
Checkpoint 938992482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,831.73892
Policy Entropy: 1.72065
Value Function Loss: 0.07337

Mean KL Divergence: 0.01997
SB3 Clip Fraction: 0.17534
Policy Update Magnitude: 0.52501
Value Function Update Magnitude: 0.48114

Collected Steps per Second: 21,731.44497
Overall Steps per Second: 10,626.73498

Timestep Collection Time: 2.30192
Timestep Consumption Time: 2.40545
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.70737

Cumulative Model Updates: 112,574
Cumulative Timesteps: 939,042,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,272.29878
Policy Entropy: 1.73759
Value Function Loss: 0.07306

Mean KL Divergence: 0.02076
SB3 Clip Fraction: 0.17897
Policy Update Magnitude: 0.52585
Value Function Update Magnitude: 0.55959

Collected Steps per Second: 22,027.81089
Overall Steps per Second: 10,531.81408

Timestep Collection Time: 2.27104
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.74999

Cumulative Model Updates: 112,580
Cumulative Timesteps: 939,092,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 939092532...
Checkpoint 939092532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,888.96228
Policy Entropy: 1.72997
Value Function Loss: 0.07204

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.17039
Policy Update Magnitude: 0.51948
Value Function Update Magnitude: 0.60748

Collected Steps per Second: 21,730.20075
Overall Steps per Second: 10,550.26328

Timestep Collection Time: 2.30131
Timestep Consumption Time: 2.43866
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.73998

Cumulative Model Updates: 112,586
Cumulative Timesteps: 939,142,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,488.55945
Policy Entropy: 1.72747
Value Function Loss: 0.06598

Mean KL Divergence: 0.02138
SB3 Clip Fraction: 0.18283
Policy Update Magnitude: 0.51116
Value Function Update Magnitude: 0.56575

Collected Steps per Second: 22,154.64243
Overall Steps per Second: 10,488.76420

Timestep Collection Time: 2.25695
Timestep Consumption Time: 2.51024
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.76720

Cumulative Model Updates: 112,592
Cumulative Timesteps: 939,192,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 939192542...
Checkpoint 939192542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,869.42010
Policy Entropy: 1.72009
Value Function Loss: 0.06491

Mean KL Divergence: 0.02063
SB3 Clip Fraction: 0.18172
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 21,772.77480
Overall Steps per Second: 10,415.85172

Timestep Collection Time: 2.29672
Timestep Consumption Time: 2.50423
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.80095

Cumulative Model Updates: 112,598
Cumulative Timesteps: 939,242,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,333.39474
Policy Entropy: 1.71562
Value Function Loss: 0.06826

Mean KL Divergence: 0.02047
SB3 Clip Fraction: 0.17706
Policy Update Magnitude: 0.48974
Value Function Update Magnitude: 0.65987

Collected Steps per Second: 22,140.41482
Overall Steps per Second: 10,630.55820

Timestep Collection Time: 2.25886
Timestep Consumption Time: 2.44570
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.70455

Cumulative Model Updates: 112,604
Cumulative Timesteps: 939,292,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 939292560...
Checkpoint 939292560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,188.36764
Policy Entropy: 1.72728
Value Function Loss: 0.07102

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.17620
Policy Update Magnitude: 0.51177
Value Function Update Magnitude: 0.69701

Collected Steps per Second: 21,792.50735
Overall Steps per Second: 10,441.07620

Timestep Collection Time: 2.29565
Timestep Consumption Time: 2.49581
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.79146

Cumulative Model Updates: 112,610
Cumulative Timesteps: 939,342,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,930.29048
Policy Entropy: 1.71196
Value Function Loss: 0.06905

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17228
Policy Update Magnitude: 0.51992
Value Function Update Magnitude: 0.71976

Collected Steps per Second: 22,287.72378
Overall Steps per Second: 10,675.17424

Timestep Collection Time: 2.24375
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.68451

Cumulative Model Updates: 112,616
Cumulative Timesteps: 939,392,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 939392596...
Checkpoint 939392596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,762.24485
Policy Entropy: 1.71608
Value Function Loss: 0.06876

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.16501
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.67838

Collected Steps per Second: 21,837.38595
Overall Steps per Second: 10,457.04652

Timestep Collection Time: 2.29057
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.78338

Cumulative Model Updates: 112,622
Cumulative Timesteps: 939,442,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,499.03667
Policy Entropy: 1.71767
Value Function Loss: 0.06548

Mean KL Divergence: 0.02211
SB3 Clip Fraction: 0.19506
Policy Update Magnitude: 0.52259
Value Function Update Magnitude: 0.54094

Collected Steps per Second: 22,195.47980
Overall Steps per Second: 10,529.68443

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.75000

Cumulative Model Updates: 112,628
Cumulative Timesteps: 939,492,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 939492632...
Checkpoint 939492632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,337.39261
Policy Entropy: 1.72585
Value Function Loss: 0.06641

Mean KL Divergence: 0.01890
SB3 Clip Fraction: 0.17360
Policy Update Magnitude: 0.53286
Value Function Update Magnitude: 0.49685

Collected Steps per Second: 21,995.13641
Overall Steps per Second: 10,361.09662

Timestep Collection Time: 2.27441
Timestep Consumption Time: 2.55384
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.82825

Cumulative Model Updates: 112,634
Cumulative Timesteps: 939,542,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,605.51117
Policy Entropy: 1.73265
Value Function Loss: 0.06576

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.16344
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.51199

Collected Steps per Second: 22,031.67389
Overall Steps per Second: 10,451.42549

Timestep Collection Time: 2.27064
Timestep Consumption Time: 2.51588
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.78652

Cumulative Model Updates: 112,640
Cumulative Timesteps: 939,592,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 939592684...
Checkpoint 939592684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,430.81599
Policy Entropy: 1.72805
Value Function Loss: 0.06877

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.15242
Policy Update Magnitude: 0.57840
Value Function Update Magnitude: 0.51693

Collected Steps per Second: 21,903.65030
Overall Steps per Second: 10,615.96565

Timestep Collection Time: 2.28336
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.71121

Cumulative Model Updates: 112,646
Cumulative Timesteps: 939,642,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,839.35831
Policy Entropy: 1.71852
Value Function Loss: 0.06461

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14783
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.50793

Collected Steps per Second: 21,952.87418
Overall Steps per Second: 10,493.16887

Timestep Collection Time: 2.27988
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.76977

Cumulative Model Updates: 112,652
Cumulative Timesteps: 939,692,748

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 939692748...
Checkpoint 939692748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,519.37258
Policy Entropy: 1.70997
Value Function Loss: 0.06306

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.39790

Collected Steps per Second: 21,829.88703
Overall Steps per Second: 10,594.93439

Timestep Collection Time: 2.29163
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.72169

Cumulative Model Updates: 112,658
Cumulative Timesteps: 939,742,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,617.05767
Policy Entropy: 1.70636
Value Function Loss: 0.06727

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.57139
Value Function Update Magnitude: 0.36844

Collected Steps per Second: 22,256.83348
Overall Steps per Second: 10,512.40313

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.75705

Cumulative Model Updates: 112,664
Cumulative Timesteps: 939,792,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 939792782...
Checkpoint 939792782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,786.14011
Policy Entropy: 1.71348
Value Function Loss: 0.07249

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.29840

Collected Steps per Second: 21,802.40667
Overall Steps per Second: 10,590.08476

Timestep Collection Time: 2.29443
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.72366

Cumulative Model Updates: 112,670
Cumulative Timesteps: 939,842,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,122.25675
Policy Entropy: 1.70595
Value Function Loss: 0.07022

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.57559
Value Function Update Magnitude: 0.35869

Collected Steps per Second: 22,217.28505
Overall Steps per Second: 10,496.80477

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.51436
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.76621

Cumulative Model Updates: 112,676
Cumulative Timesteps: 939,892,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 939892836...
Checkpoint 939892836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,181.42502
Policy Entropy: 1.69760
Value Function Loss: 0.07454

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.31986

Collected Steps per Second: 21,277.59321
Overall Steps per Second: 10,615.53866

Timestep Collection Time: 2.35064
Timestep Consumption Time: 2.36094
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.71158

Cumulative Model Updates: 112,682
Cumulative Timesteps: 939,942,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,946.49235
Policy Entropy: 1.69318
Value Function Loss: 0.07494

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14011
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.22919

Collected Steps per Second: 21,669.79984
Overall Steps per Second: 10,539.96012

Timestep Collection Time: 2.30810
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.74537

Cumulative Model Updates: 112,688
Cumulative Timesteps: 939,992,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 939992868...
Checkpoint 939992868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,573.98474
Policy Entropy: 1.68528
Value Function Loss: 0.07677

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15659
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.23075

Collected Steps per Second: 21,477.87355
Overall Steps per Second: 10,592.37630

Timestep Collection Time: 2.33040
Timestep Consumption Time: 2.39489
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.72529

Cumulative Model Updates: 112,694
Cumulative Timesteps: 940,042,920

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,589.68828
Policy Entropy: 1.69008
Value Function Loss: 0.07021

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.49824
Value Function Update Magnitude: 0.40049

Collected Steps per Second: 21,645.87739
Overall Steps per Second: 10,536.38921

Timestep Collection Time: 2.31185
Timestep Consumption Time: 2.43760
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.74944

Cumulative Model Updates: 112,700
Cumulative Timesteps: 940,092,962

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 940092962...
Checkpoint 940092962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,236.11872
Policy Entropy: 1.69452
Value Function Loss: 0.07288

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.16317
Policy Update Magnitude: 0.51629
Value Function Update Magnitude: 0.49690

Collected Steps per Second: 21,272.11157
Overall Steps per Second: 10,423.36877

Timestep Collection Time: 2.35153
Timestep Consumption Time: 2.44749
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.79902

Cumulative Model Updates: 112,706
Cumulative Timesteps: 940,142,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,653.88919
Policy Entropy: 1.68970
Value Function Loss: 0.07254

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.15937
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 21,968.45545
Overall Steps per Second: 10,425.32257

Timestep Collection Time: 2.27763
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.29789
Total Iteration Time: 4.79947

Cumulative Model Updates: 112,712
Cumulative Timesteps: 940,193,020

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 940193020...
Checkpoint 940193020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,662.38384
Policy Entropy: 1.68285
Value Function Loss: 0.07296

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.59031
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 21,708.00820
Overall Steps per Second: 10,433.28171

Timestep Collection Time: 2.30459
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.79504

Cumulative Model Updates: 112,718
Cumulative Timesteps: 940,243,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,806.33063
Policy Entropy: 1.67923
Value Function Loss: 0.07122

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.58304
Value Function Update Magnitude: 0.61632

Collected Steps per Second: 22,159.40501
Overall Steps per Second: 10,592.45688

Timestep Collection Time: 2.25773
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.72317

Cumulative Model Updates: 112,724
Cumulative Timesteps: 940,293,078

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 940293078...
Checkpoint 940293078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,379.76885
Policy Entropy: 1.67705
Value Function Loss: 0.06885

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.15022
Policy Update Magnitude: 0.56177
Value Function Update Magnitude: 0.50753

Collected Steps per Second: 22,029.34518
Overall Steps per Second: 10,468.27039

Timestep Collection Time: 2.27034
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.77768

Cumulative Model Updates: 112,730
Cumulative Timesteps: 940,343,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,740.49564
Policy Entropy: 1.67691
Value Function Loss: 0.06754

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.16690
Policy Update Magnitude: 0.55322
Value Function Update Magnitude: 0.51731

Collected Steps per Second: 22,246.64327
Overall Steps per Second: 10,506.25786

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.76173

Cumulative Model Updates: 112,736
Cumulative Timesteps: 940,393,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 940393120...
Checkpoint 940393120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,310.77006
Policy Entropy: 1.66791
Value Function Loss: 0.07410

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.18114
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.53494

Collected Steps per Second: 21,817.15452
Overall Steps per Second: 10,617.95018

Timestep Collection Time: 2.29232
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.71014

Cumulative Model Updates: 112,742
Cumulative Timesteps: 940,443,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,702.86724
Policy Entropy: 1.67652
Value Function Loss: 0.07456

Mean KL Divergence: 0.02299
SB3 Clip Fraction: 0.19363
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.47352

Collected Steps per Second: 22,364.73461
Overall Steps per Second: 10,578.89150

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.72734

Cumulative Model Updates: 112,748
Cumulative Timesteps: 940,493,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 940493142...
Checkpoint 940493142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,899.04753
Policy Entropy: 1.68328
Value Function Loss: 0.07461

Mean KL Divergence: 0.02188
SB3 Clip Fraction: 0.18180
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.49004

Collected Steps per Second: 21,866.95797
Overall Steps per Second: 10,441.35489

Timestep Collection Time: 2.28802
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79172

Cumulative Model Updates: 112,754
Cumulative Timesteps: 940,543,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,593.07523
Policy Entropy: 1.68399
Value Function Loss: 0.06859

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.51743

Collected Steps per Second: 22,205.45239
Overall Steps per Second: 10,461.02850

Timestep Collection Time: 2.25206
Timestep Consumption Time: 2.52835
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.78041

Cumulative Model Updates: 112,760
Cumulative Timesteps: 940,593,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 940593182...
Checkpoint 940593182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,573.40522
Policy Entropy: 1.68940
Value Function Loss: 0.06616

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.16918
Policy Update Magnitude: 0.56510
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 21,761.16895
Overall Steps per Second: 10,567.48229

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.73187

Cumulative Model Updates: 112,766
Cumulative Timesteps: 940,643,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,891.08888
Policy Entropy: 1.68312
Value Function Loss: 0.06362

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.17733
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.71342

Collected Steps per Second: 22,080.52889
Overall Steps per Second: 10,510.95340

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.75789

Cumulative Model Updates: 112,772
Cumulative Timesteps: 940,693,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 940693196...
Checkpoint 940693196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,159.45557
Policy Entropy: 1.68764
Value Function Loss: 0.06471

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.16069
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.66662

Collected Steps per Second: 21,812.33344
Overall Steps per Second: 10,579.70194

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.43502
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.72849

Cumulative Model Updates: 112,778
Cumulative Timesteps: 940,743,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,384.85464
Policy Entropy: 1.68314
Value Function Loss: 0.06912

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.58055
Value Function Update Magnitude: 0.58624

Collected Steps per Second: 22,098.20245
Overall Steps per Second: 10,543.13616

Timestep Collection Time: 2.26308
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.74337

Cumulative Model Updates: 112,784
Cumulative Timesteps: 940,793,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 940793232...
Checkpoint 940793232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,587.88339
Policy Entropy: 1.68209
Value Function Loss: 0.06798

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.68580

Collected Steps per Second: 21,644.47547
Overall Steps per Second: 10,393.47755

Timestep Collection Time: 2.31043
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.81148

Cumulative Model Updates: 112,790
Cumulative Timesteps: 940,843,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,546.05840
Policy Entropy: 1.68646
Value Function Loss: 0.06908

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.16328
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.72053

Collected Steps per Second: 22,432.26860
Overall Steps per Second: 10,719.18886

Timestep Collection Time: 2.22965
Timestep Consumption Time: 2.43638
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.66602

Cumulative Model Updates: 112,796
Cumulative Timesteps: 940,893,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 940893256...
Checkpoint 940893256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,185.56465
Policy Entropy: 1.66619
Value Function Loss: 0.06615

Mean KL Divergence: 0.02068
SB3 Clip Fraction: 0.17859
Policy Update Magnitude: 0.49051
Value Function Update Magnitude: 0.64116

Collected Steps per Second: 21,730.60259
Overall Steps per Second: 10,543.83676

Timestep Collection Time: 2.30090
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.74211

Cumulative Model Updates: 112,802
Cumulative Timesteps: 940,943,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,107.96598
Policy Entropy: 1.66779
Value Function Loss: 0.06963

Mean KL Divergence: 0.02626
SB3 Clip Fraction: 0.19912
Policy Update Magnitude: 0.43535
Value Function Update Magnitude: 0.52967

Collected Steps per Second: 22,133.62852
Overall Steps per Second: 10,487.61718

Timestep Collection Time: 2.26018
Timestep Consumption Time: 2.50983
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.77001

Cumulative Model Updates: 112,808
Cumulative Timesteps: 940,993,282

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 940993282...
Checkpoint 940993282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,319.41481
Policy Entropy: 1.67334
Value Function Loss: 0.07550

Mean KL Divergence: 0.01967
SB3 Clip Fraction: 0.16420
Policy Update Magnitude: 0.48125
Value Function Update Magnitude: 0.45881

Collected Steps per Second: 21,377.04260
Overall Steps per Second: 10,326.93983

Timestep Collection Time: 2.34092
Timestep Consumption Time: 2.50485
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.84577

Cumulative Model Updates: 112,814
Cumulative Timesteps: 941,043,324

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,183.25415
Policy Entropy: 1.68686
Value Function Loss: 0.09135

Mean KL Divergence: 0.01797
SB3 Clip Fraction: 0.16929
Policy Update Magnitude: 0.55313
Value Function Update Magnitude: 0.34797

Collected Steps per Second: 22,019.56736
Overall Steps per Second: 10,481.15129

Timestep Collection Time: 2.27216
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77352

Cumulative Model Updates: 112,820
Cumulative Timesteps: 941,093,356

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 941093356...
Checkpoint 941093356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,244.59772
Policy Entropy: 1.70098
Value Function Loss: 0.08862

Mean KL Divergence: 0.02155
SB3 Clip Fraction: 0.19143
Policy Update Magnitude: 0.54126
Value Function Update Magnitude: 0.29603

Collected Steps per Second: 22,037.97981
Overall Steps per Second: 10,503.70099

Timestep Collection Time: 2.26881
Timestep Consumption Time: 2.49142
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.76023

Cumulative Model Updates: 112,826
Cumulative Timesteps: 941,143,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,722.55582
Policy Entropy: 1.70388
Value Function Loss: 0.08369

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.19840
Policy Update Magnitude: 0.52472
Value Function Update Magnitude: 0.30812

Collected Steps per Second: 21,941.27165
Overall Steps per Second: 10,459.57010

Timestep Collection Time: 2.28109
Timestep Consumption Time: 2.50400
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.78509

Cumulative Model Updates: 112,832
Cumulative Timesteps: 941,193,406

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 941193406...
Checkpoint 941193406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,380.17100
Policy Entropy: 1.70615
Value Function Loss: 0.07754

Mean KL Divergence: 0.01957
SB3 Clip Fraction: 0.17694
Policy Update Magnitude: 0.53745
Value Function Update Magnitude: 0.28264

Collected Steps per Second: 21,949.20008
Overall Steps per Second: 10,616.88167

Timestep Collection Time: 2.27872
Timestep Consumption Time: 2.43227
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.71099

Cumulative Model Updates: 112,838
Cumulative Timesteps: 941,243,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,136.99308
Policy Entropy: 1.70198
Value Function Loss: 0.07448

Mean KL Divergence: 0.01977
SB3 Clip Fraction: 0.17740
Policy Update Magnitude: 0.53474
Value Function Update Magnitude: 0.39773

Collected Steps per Second: 22,356.20557
Overall Steps per Second: 10,519.43494

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75691

Cumulative Model Updates: 112,844
Cumulative Timesteps: 941,293,462

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 941293462...
Checkpoint 941293462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,430.30708
Policy Entropy: 1.71994
Value Function Loss: 0.07379

Mean KL Divergence: 0.02002
SB3 Clip Fraction: 0.17913
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.58605

Collected Steps per Second: 21,866.00300
Overall Steps per Second: 10,581.23984

Timestep Collection Time: 2.28684
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.72572

Cumulative Model Updates: 112,850
Cumulative Timesteps: 941,343,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,907.94874
Policy Entropy: 1.72156
Value Function Loss: 0.07475

Mean KL Divergence: 0.01675
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.49437

Collected Steps per Second: 22,510.82602
Overall Steps per Second: 10,577.41629

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.72705

Cumulative Model Updates: 112,856
Cumulative Timesteps: 941,393,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 941393466...
Checkpoint 941393466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,493.54125
Policy Entropy: 1.71338
Value Function Loss: 0.08371

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.15401
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.38534

Collected Steps per Second: 21,912.87882
Overall Steps per Second: 10,516.31861

Timestep Collection Time: 2.28231
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.75566

Cumulative Model Updates: 112,862
Cumulative Timesteps: 941,443,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,162.62391
Policy Entropy: 1.70523
Value Function Loss: 0.08503

Mean KL Divergence: 0.01801
SB3 Clip Fraction: 0.17104
Policy Update Magnitude: 0.51831
Value Function Update Magnitude: 0.33012

Collected Steps per Second: 21,723.44768
Overall Steps per Second: 10,360.18326

Timestep Collection Time: 2.30175
Timestep Consumption Time: 2.52461
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.82636

Cumulative Model Updates: 112,868
Cumulative Timesteps: 941,493,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 941493480...
Checkpoint 941493480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,342.74467
Policy Entropy: 1.71286
Value Function Loss: 0.08327

Mean KL Divergence: 0.01840
SB3 Clip Fraction: 0.17165
Policy Update Magnitude: 0.47745
Value Function Update Magnitude: 0.32035

Collected Steps per Second: 21,226.73861
Overall Steps per Second: 10,313.86110

Timestep Collection Time: 2.35618
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.84920

Cumulative Model Updates: 112,874
Cumulative Timesteps: 941,543,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,998.99376
Policy Entropy: 1.70829
Value Function Loss: 0.08362

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.51820
Value Function Update Magnitude: 0.32416

Collected Steps per Second: 22,323.46992
Overall Steps per Second: 10,526.32199

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.51101
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.75152

Cumulative Model Updates: 112,880
Cumulative Timesteps: 941,593,510

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941593510...
Checkpoint 941593510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,310.37167
Policy Entropy: 1.69906
Value Function Loss: 0.07140

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.26277

Collected Steps per Second: 21,869.23532
Overall Steps per Second: 10,608.26377

Timestep Collection Time: 2.28650
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.71368

Cumulative Model Updates: 112,886
Cumulative Timesteps: 941,643,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,639.79362
Policy Entropy: 1.68905
Value Function Loss: 0.07094

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.25900

Collected Steps per Second: 21,667.71468
Overall Steps per Second: 10,380.44111

Timestep Collection Time: 2.30786
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.81733

Cumulative Model Updates: 112,892
Cumulative Timesteps: 941,693,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 941693520...
Checkpoint 941693520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,344.31711
Policy Entropy: 1.69760
Value Function Loss: 0.06510

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.46343

Collected Steps per Second: 21,493.79467
Overall Steps per Second: 10,537.20115

Timestep Collection Time: 2.32737
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.74737

Cumulative Model Updates: 112,898
Cumulative Timesteps: 941,743,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,668.45698
Policy Entropy: 1.70150
Value Function Loss: 0.06677

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.49589

Collected Steps per Second: 22,176.32675
Overall Steps per Second: 10,575.79333

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.47480
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.73099

Cumulative Model Updates: 112,904
Cumulative Timesteps: 941,793,578

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 941793578...
Checkpoint 941793578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,846.18088
Policy Entropy: 1.70509
Value Function Loss: 0.07100

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.57939
Value Function Update Magnitude: 0.48489

Collected Steps per Second: 21,782.47916
Overall Steps per Second: 10,565.22585

Timestep Collection Time: 2.29579
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.73326

Cumulative Model Updates: 112,910
Cumulative Timesteps: 941,843,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,955.01276
Policy Entropy: 1.70587
Value Function Loss: 0.07000

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14093
Policy Update Magnitude: 0.57983
Value Function Update Magnitude: 0.42492

Collected Steps per Second: 22,229.39825
Overall Steps per Second: 10,490.48854

Timestep Collection Time: 2.25008
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.76794

Cumulative Model Updates: 112,916
Cumulative Timesteps: 941,893,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 941893604...
Checkpoint 941893604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,823.39614
Policy Entropy: 1.71612
Value Function Loss: 0.07165

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.57597
Value Function Update Magnitude: 0.40177

Collected Steps per Second: 21,885.86627
Overall Steps per Second: 10,604.86704

Timestep Collection Time: 2.28586
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.71746

Cumulative Model Updates: 112,922
Cumulative Timesteps: 941,943,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,643.07412
Policy Entropy: 1.71879
Value Function Loss: 0.07275

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.58339
Value Function Update Magnitude: 0.49314

Collected Steps per Second: 22,321.20137
Overall Steps per Second: 10,537.48730

Timestep Collection Time: 2.24002
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.74496

Cumulative Model Updates: 112,928
Cumulative Timesteps: 941,993,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 941993632...
Checkpoint 941993632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,584.51508
Policy Entropy: 1.71622
Value Function Loss: 0.07167

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.51678

Collected Steps per Second: 21,256.30978
Overall Steps per Second: 10,603.48821

Timestep Collection Time: 2.35337
Timestep Consumption Time: 2.36432
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.71769

Cumulative Model Updates: 112,934
Cumulative Timesteps: 942,043,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,660.97868
Policy Entropy: 1.70493
Value Function Loss: 0.07471

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.56986
Value Function Update Magnitude: 0.47612

Collected Steps per Second: 21,592.41049
Overall Steps per Second: 10,529.29539

Timestep Collection Time: 2.31655
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.75056

Cumulative Model Updates: 112,940
Cumulative Timesteps: 942,093,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 942093676...
Checkpoint 942093676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,413.88812
Policy Entropy: 1.69943
Value Function Loss: 0.07151

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.58221
Value Function Update Magnitude: 0.45311

Collected Steps per Second: 21,005.79119
Overall Steps per Second: 10,516.54322

Timestep Collection Time: 2.38058
Timestep Consumption Time: 2.37440
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.75498

Cumulative Model Updates: 112,946
Cumulative Timesteps: 942,143,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,069.51522
Policy Entropy: 1.70231
Value Function Loss: 0.07680

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.15776
Policy Update Magnitude: 0.59917
Value Function Update Magnitude: 0.51976

Collected Steps per Second: 21,336.30869
Overall Steps per Second: 10,517.31444

Timestep Collection Time: 2.34352
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.75426

Cumulative Model Updates: 112,952
Cumulative Timesteps: 942,193,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 942193684...
Checkpoint 942193684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,458.42627
Policy Entropy: 1.69987
Value Function Loss: 0.07871

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.60839
Value Function Update Magnitude: 0.64838

Collected Steps per Second: 21,296.71797
Overall Steps per Second: 10,624.17224

Timestep Collection Time: 2.34778
Timestep Consumption Time: 2.35847
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.70625

Cumulative Model Updates: 112,958
Cumulative Timesteps: 942,243,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,674.39058
Policy Entropy: 1.70741
Value Function Loss: 0.07946

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.15436
Policy Update Magnitude: 0.59621
Value Function Update Magnitude: 0.54265

Collected Steps per Second: 21,665.93420
Overall Steps per Second: 10,444.66162

Timestep Collection Time: 2.30842
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.78847

Cumulative Model Updates: 112,964
Cumulative Timesteps: 942,293,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942293698...
Checkpoint 942293698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,746.94583
Policy Entropy: 1.70581
Value Function Loss: 0.08058

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.14755
Policy Update Magnitude: 0.59508
Value Function Update Magnitude: 0.54013

Collected Steps per Second: 22,028.60115
Overall Steps per Second: 10,704.19727

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.40177
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.67200

Cumulative Model Updates: 112,970
Cumulative Timesteps: 942,343,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,474.27700
Policy Entropy: 1.71649
Value Function Loss: 0.07555

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.60158
Value Function Update Magnitude: 0.68714

Collected Steps per Second: 22,301.99077
Overall Steps per Second: 10,783.71155

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.39477
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63681

Cumulative Model Updates: 112,976
Cumulative Timesteps: 942,393,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 942393710...
Checkpoint 942393710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,311.71225
Policy Entropy: 1.71459
Value Function Loss: 0.06975

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.64172

Collected Steps per Second: 21,745.90949
Overall Steps per Second: 10,634.81101

Timestep Collection Time: 2.29928
Timestep Consumption Time: 2.40226
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.70154

Cumulative Model Updates: 112,982
Cumulative Timesteps: 942,443,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,259.79568
Policy Entropy: 1.71395
Value Function Loss: 0.06810

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.59258

Collected Steps per Second: 22,146.44798
Overall Steps per Second: 10,495.43614

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.76417

Cumulative Model Updates: 112,988
Cumulative Timesteps: 942,493,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 942493712...
Checkpoint 942493712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,202.51830
Policy Entropy: 1.70829
Value Function Loss: 0.07571

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.66208

Collected Steps per Second: 21,994.22998
Overall Steps per Second: 10,672.54938

Timestep Collection Time: 2.27469
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.68773

Cumulative Model Updates: 112,994
Cumulative Timesteps: 942,543,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,649.46889
Policy Entropy: 1.71090
Value Function Loss: 0.07857

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14712
Policy Update Magnitude: 0.58062
Value Function Update Magnitude: 0.65794

Collected Steps per Second: 22,285.71370
Overall Steps per Second: 10,641.01140

Timestep Collection Time: 2.24503
Timestep Consumption Time: 2.45678
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70181

Cumulative Model Updates: 113,000
Cumulative Timesteps: 942,593,774

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 942593774...
Checkpoint 942593774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.01169
Policy Entropy: 1.71779
Value Function Loss: 0.08051

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.60018
Value Function Update Magnitude: 0.61928

Collected Steps per Second: 21,869.35255
Overall Steps per Second: 10,476.38474

Timestep Collection Time: 2.28676
Timestep Consumption Time: 2.48683
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.77359

Cumulative Model Updates: 113,006
Cumulative Timesteps: 942,643,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,626.11303
Policy Entropy: 1.72310
Value Function Loss: 0.07654

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.14863
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.51357

Collected Steps per Second: 21,967.00275
Overall Steps per Second: 10,419.12297

Timestep Collection Time: 2.27614
Timestep Consumption Time: 2.52273
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.79887

Cumulative Model Updates: 113,012
Cumulative Timesteps: 942,693,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 942693784...
Checkpoint 942693784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,394.13369
Policy Entropy: 1.71991
Value Function Loss: 0.07751

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.59083
Value Function Update Magnitude: 0.65404

Collected Steps per Second: 21,788.30906
Overall Steps per Second: 10,561.53684

Timestep Collection Time: 2.29536
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.73530

Cumulative Model Updates: 113,018
Cumulative Timesteps: 942,743,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,981.72513
Policy Entropy: 1.71722
Value Function Loss: 0.07419

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.15053
Policy Update Magnitude: 0.58833
Value Function Update Magnitude: 0.69686

Collected Steps per Second: 21,825.81469
Overall Steps per Second: 10,543.03904

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.74284

Cumulative Model Updates: 113,024
Cumulative Timesteps: 942,793,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 942793800...
Checkpoint 942793800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,741.74091
Policy Entropy: 1.69894
Value Function Loss: 0.07246

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.67576

Collected Steps per Second: 21,763.97320
Overall Steps per Second: 10,605.60363

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.41779
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.71581

Cumulative Model Updates: 113,030
Cumulative Timesteps: 942,843,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,296.24480
Policy Entropy: 1.68793
Value Function Loss: 0.06781

Mean KL Divergence: 0.01672
SB3 Clip Fraction: 0.16364
Policy Update Magnitude: 0.53552
Value Function Update Magnitude: 0.74090

Collected Steps per Second: 22,327.70375
Overall Steps per Second: 10,497.97617

Timestep Collection Time: 2.23955
Timestep Consumption Time: 2.52365
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.76320

Cumulative Model Updates: 113,036
Cumulative Timesteps: 942,893,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 942893818...
Checkpoint 942893818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,960.77206
Policy Entropy: 1.67728
Value Function Loss: 0.07032

Mean KL Divergence: 0.01818
SB3 Clip Fraction: 0.16839
Policy Update Magnitude: 0.47218
Value Function Update Magnitude: 0.75387

Collected Steps per Second: 21,971.09501
Overall Steps per Second: 10,569.58048

Timestep Collection Time: 2.27808
Timestep Consumption Time: 2.45739
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.73548

Cumulative Model Updates: 113,042
Cumulative Timesteps: 942,943,870

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,105.86197
Policy Entropy: 1.67867
Value Function Loss: 0.07570

Mean KL Divergence: 0.01762
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.50789
Value Function Update Magnitude: 0.72517

Collected Steps per Second: 22,143.42065
Overall Steps per Second: 10,539.54450

Timestep Collection Time: 2.26045
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.74916

Cumulative Model Updates: 113,048
Cumulative Timesteps: 942,993,924

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 942993924...
Checkpoint 942993924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,246.19080
Policy Entropy: 1.68297
Value Function Loss: 0.07929

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.16841
Policy Update Magnitude: 0.53291
Value Function Update Magnitude: 0.77788

Collected Steps per Second: 21,668.72400
Overall Steps per Second: 10,554.35901

Timestep Collection Time: 2.30784
Timestep Consumption Time: 2.43029
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.73814

Cumulative Model Updates: 113,054
Cumulative Timesteps: 943,043,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,806.84137
Policy Entropy: 1.68983
Value Function Loss: 0.07625

Mean KL Divergence: 0.01996
SB3 Clip Fraction: 0.18140
Policy Update Magnitude: 0.49988
Value Function Update Magnitude: 0.77266

Collected Steps per Second: 22,109.62307
Overall Steps per Second: 10,511.55933

Timestep Collection Time: 2.26173
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.75724

Cumulative Model Updates: 113,060
Cumulative Timesteps: 943,093,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 943093938...
Checkpoint 943093938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,455.38293
Policy Entropy: 1.69001
Value Function Loss: 0.07544

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.17772
Policy Update Magnitude: 0.48884
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 21,885.46899
Overall Steps per Second: 10,576.81339

Timestep Collection Time: 2.28526
Timestep Consumption Time: 2.44338
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.72865

Cumulative Model Updates: 113,066
Cumulative Timesteps: 943,143,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,739.83350
Policy Entropy: 1.69122
Value Function Loss: 0.07470

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.52586
Value Function Update Magnitude: 0.47048

Collected Steps per Second: 22,271.85179
Overall Steps per Second: 10,530.27163

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.50393
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.74955

Cumulative Model Updates: 113,072
Cumulative Timesteps: 943,193,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 943193966...
Checkpoint 943193966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,590.85614
Policy Entropy: 1.68841
Value Function Loss: 0.07392

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.58502
Value Function Update Magnitude: 0.44358

Collected Steps per Second: 21,846.59032
Overall Steps per Second: 10,587.37156

Timestep Collection Time: 2.28933
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.72393

Cumulative Model Updates: 113,078
Cumulative Timesteps: 943,243,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,189.37714
Policy Entropy: 1.68215
Value Function Loss: 0.07052

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.15631
Policy Update Magnitude: 0.57735
Value Function Update Magnitude: 0.51621

Collected Steps per Second: 22,267.63218
Overall Steps per Second: 10,471.53483

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.52994
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.77580

Cumulative Model Updates: 113,084
Cumulative Timesteps: 943,293,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 943293990...
Checkpoint 943293990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,422.23407
Policy Entropy: 1.67958
Value Function Loss: 0.06863

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17206
Policy Update Magnitude: 0.54349
Value Function Update Magnitude: 0.55290

Collected Steps per Second: 21,865.68778
Overall Steps per Second: 10,585.52842

Timestep Collection Time: 2.28678
Timestep Consumption Time: 2.43684
PPO Batch Consumption Time: 0.27991
Total Iteration Time: 4.72362

Cumulative Model Updates: 113,090
Cumulative Timesteps: 943,343,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,095.06883
Policy Entropy: 1.68031
Value Function Loss: 0.06761

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.16327
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.48312

Collected Steps per Second: 22,339.37523
Overall Steps per Second: 10,560.01741

Timestep Collection Time: 2.23927
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.73711

Cumulative Model Updates: 113,096
Cumulative Timesteps: 943,394,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 943394016...
Checkpoint 943394016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,020.86386
Policy Entropy: 1.69674
Value Function Loss: 0.07454

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.59039
Value Function Update Magnitude: 0.48139

Collected Steps per Second: 21,687.34159
Overall Steps per Second: 10,466.50646

Timestep Collection Time: 2.30669
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.77963

Cumulative Model Updates: 113,102
Cumulative Timesteps: 943,444,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,380.58545
Policy Entropy: 1.69681
Value Function Loss: 0.07498

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.15581
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.51314

Collected Steps per Second: 21,998.51894
Overall Steps per Second: 10,672.31235

Timestep Collection Time: 2.27297
Timestep Consumption Time: 2.41224
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.68521

Cumulative Model Updates: 113,108
Cumulative Timesteps: 943,494,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 943494044...
Checkpoint 943494044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,572.89551
Policy Entropy: 1.70791
Value Function Loss: 0.08062

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17998
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.47819

Collected Steps per Second: 21,957.44826
Overall Steps per Second: 10,630.78032

Timestep Collection Time: 2.27795
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.70502

Cumulative Model Updates: 113,114
Cumulative Timesteps: 943,544,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,909.85844
Policy Entropy: 1.70548
Value Function Loss: 0.07579

Mean KL Divergence: 0.02074
SB3 Clip Fraction: 0.18348
Policy Update Magnitude: 0.50268
Value Function Update Magnitude: 0.49131

Collected Steps per Second: 22,394.77853
Overall Steps per Second: 10,619.05939

Timestep Collection Time: 2.23275
Timestep Consumption Time: 2.47595
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70870

Cumulative Model Updates: 113,120
Cumulative Timesteps: 943,594,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 943594064...
Checkpoint 943594064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,743.67370
Policy Entropy: 1.70438
Value Function Loss: 0.07947

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16806
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.44830

Collected Steps per Second: 21,495.20232
Overall Steps per Second: 10,508.96215

Timestep Collection Time: 2.32703
Timestep Consumption Time: 2.43272
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.75975

Cumulative Model Updates: 113,126
Cumulative Timesteps: 943,644,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,747.88508
Policy Entropy: 1.70406
Value Function Loss: 0.07261

Mean KL Divergence: 0.01802
SB3 Clip Fraction: 0.16750
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.56284

Collected Steps per Second: 20,473.81785
Overall Steps per Second: 10,323.71023

Timestep Collection Time: 2.44244
Timestep Consumption Time: 2.40136
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.84380

Cumulative Model Updates: 113,132
Cumulative Timesteps: 943,694,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 943694090...
Checkpoint 943694090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,597.57769
Policy Entropy: 1.69631
Value Function Loss: 0.07701

Mean KL Divergence: 0.01999
SB3 Clip Fraction: 0.17638
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.74428

Collected Steps per Second: 20,804.80575
Overall Steps per Second: 10,323.08384

Timestep Collection Time: 2.40425
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.84545

Cumulative Model Updates: 113,138
Cumulative Timesteps: 943,744,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,415.54321
Policy Entropy: 1.71759
Value Function Loss: 0.06841

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17583
Policy Update Magnitude: 0.55126
Value Function Update Magnitude: 0.73352

Collected Steps per Second: 21,993.13645
Overall Steps per Second: 10,791.41098

Timestep Collection Time: 2.27480
Timestep Consumption Time: 2.36129
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.63609

Cumulative Model Updates: 113,144
Cumulative Timesteps: 943,794,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 943794140...
Checkpoint 943794140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,871.92012
Policy Entropy: 1.71616
Value Function Loss: 0.06997

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15852
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.61342

Collected Steps per Second: 21,139.28180
Overall Steps per Second: 10,618.19816

Timestep Collection Time: 2.36668
Timestep Consumption Time: 2.34504
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.71172

Cumulative Model Updates: 113,150
Cumulative Timesteps: 943,844,170

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,437.03334
Policy Entropy: 1.72658
Value Function Loss: 0.07374

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.59202
Value Function Update Magnitude: 0.49274

Collected Steps per Second: 21,370.26177
Overall Steps per Second: 10,498.90493

Timestep Collection Time: 2.34073
Timestep Consumption Time: 2.42377
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.76450

Cumulative Model Updates: 113,156
Cumulative Timesteps: 943,894,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 943894192...
Checkpoint 943894192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,028.23193
Policy Entropy: 1.72598
Value Function Loss: 0.08650

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.59678
Value Function Update Magnitude: 0.40526

Collected Steps per Second: 21,861.88716
Overall Steps per Second: 10,627.54809

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.70777

Cumulative Model Updates: 113,162
Cumulative Timesteps: 943,944,224

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,755.92099
Policy Entropy: 1.73966
Value Function Loss: 0.08587

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.16749
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.42435

Collected Steps per Second: 22,057.87737
Overall Steps per Second: 10,524.07495

Timestep Collection Time: 2.26767
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.75291

Cumulative Model Updates: 113,168
Cumulative Timesteps: 943,994,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 943994244...
Checkpoint 943994244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,455.84277
Policy Entropy: 1.75308
Value Function Loss: 0.08119

Mean KL Divergence: 0.02105
SB3 Clip Fraction: 0.18441
Policy Update Magnitude: 0.52635
Value Function Update Magnitude: 0.59257

Collected Steps per Second: 22,076.79954
Overall Steps per Second: 10,618.59911

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.44439
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.70966

Cumulative Model Updates: 113,174
Cumulative Timesteps: 944,044,254

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,639.59294
Policy Entropy: 1.74950
Value Function Loss: 0.07422

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.59382

Collected Steps per Second: 22,342.44847
Overall Steps per Second: 10,416.88661

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.56334
PPO Batch Consumption Time: 0.30556
Total Iteration Time: 4.80239

Cumulative Model Updates: 113,180
Cumulative Timesteps: 944,094,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 944094280...
Checkpoint 944094280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,405.69756
Policy Entropy: 1.74534
Value Function Loss: 0.07765

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.18023
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.54556

Collected Steps per Second: 21,878.93095
Overall Steps per Second: 10,623.23337

Timestep Collection Time: 2.28594
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.70798

Cumulative Model Updates: 113,186
Cumulative Timesteps: 944,144,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,065.04849
Policy Entropy: 1.73786
Value Function Loss: 0.07697

Mean KL Divergence: 0.02025
SB3 Clip Fraction: 0.18300
Policy Update Magnitude: 0.53057
Value Function Update Magnitude: 0.65465

Collected Steps per Second: 21,947.70193
Overall Steps per Second: 10,518.21444

Timestep Collection Time: 2.27942
Timestep Consumption Time: 2.47690
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.75632

Cumulative Model Updates: 113,192
Cumulative Timesteps: 944,194,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 944194322...
Checkpoint 944194322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,898.26996
Policy Entropy: 1.73140
Value Function Loss: 0.07587

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.56159
Value Function Update Magnitude: 0.62253

Collected Steps per Second: 21,903.13380
Overall Steps per Second: 10,565.99552

Timestep Collection Time: 2.28387
Timestep Consumption Time: 2.45056
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.73443

Cumulative Model Updates: 113,198
Cumulative Timesteps: 944,244,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,076.84858
Policy Entropy: 1.72783
Value Function Loss: 0.06920

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.56868
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 21,967.16638
Overall Steps per Second: 10,577.72723

Timestep Collection Time: 2.27785
Timestep Consumption Time: 2.45265
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.73051

Cumulative Model Updates: 113,204
Cumulative Timesteps: 944,294,384

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 944294384...
Checkpoint 944294384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,963.52836
Policy Entropy: 1.71875
Value Function Loss: 0.07068

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.58477
Value Function Update Magnitude: 0.69816

Collected Steps per Second: 21,904.18271
Overall Steps per Second: 10,595.59740

Timestep Collection Time: 2.28331
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.72026

Cumulative Model Updates: 113,210
Cumulative Timesteps: 944,344,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,040.82002
Policy Entropy: 1.72589
Value Function Loss: 0.07007

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15595
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 22,048.43575
Overall Steps per Second: 10,463.52718

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.51107
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.77908

Cumulative Model Updates: 113,216
Cumulative Timesteps: 944,394,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 944394404...
Checkpoint 944394404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,241.42540
Policy Entropy: 1.73288
Value Function Loss: 0.07037

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.63348

Collected Steps per Second: 21,950.37596
Overall Steps per Second: 10,598.41254

Timestep Collection Time: 2.27841
Timestep Consumption Time: 2.44041
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.71882

Cumulative Model Updates: 113,222
Cumulative Timesteps: 944,444,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,358.60831
Policy Entropy: 1.72970
Value Function Loss: 0.06771

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.57024

Collected Steps per Second: 22,415.22654
Overall Steps per Second: 10,532.01394

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.51690
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.74762

Cumulative Model Updates: 113,228
Cumulative Timesteps: 944,494,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 944494418...
Checkpoint 944494418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,646.00297
Policy Entropy: 1.71559
Value Function Loss: 0.06914

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.13613
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.68578

Collected Steps per Second: 21,717.09244
Overall Steps per Second: 10,531.81054

Timestep Collection Time: 2.30353
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.74999

Cumulative Model Updates: 113,234
Cumulative Timesteps: 944,544,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,947.99270
Policy Entropy: 1.71389
Value Function Loss: 0.06806

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.58671
Value Function Update Magnitude: 0.74325

Collected Steps per Second: 21,983.20553
Overall Steps per Second: 10,544.24218

Timestep Collection Time: 2.27474
Timestep Consumption Time: 2.46776
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.74249

Cumulative Model Updates: 113,240
Cumulative Timesteps: 944,594,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 944594450...
Checkpoint 944594450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,153.50451
Policy Entropy: 1.71176
Value Function Loss: 0.06424

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.69724

Collected Steps per Second: 21,487.71428
Overall Steps per Second: 10,545.90235

Timestep Collection Time: 2.32793
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.74326

Cumulative Model Updates: 113,246
Cumulative Timesteps: 944,644,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,781.68329
Policy Entropy: 1.72320
Value Function Loss: 0.06316

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.13965
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,281.10136
Overall Steps per Second: 10,500.30451

Timestep Collection Time: 2.24486
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.76348

Cumulative Model Updates: 113,252
Cumulative Timesteps: 944,694,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 944694490...
Checkpoint 944694490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,836.47424
Policy Entropy: 1.72554
Value Function Loss: 0.05957

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14566
Policy Update Magnitude: 0.54708
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 21,956.74894
Overall Steps per Second: 10,419.75030

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.52188
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.79954

Cumulative Model Updates: 113,258
Cumulative Timesteps: 944,744,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,058.87747
Policy Entropy: 1.72740
Value Function Loss: 0.06033

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.15198
Policy Update Magnitude: 0.54344
Value Function Update Magnitude: 0.65393

Collected Steps per Second: 22,351.86439
Overall Steps per Second: 10,580.05494

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.72814

Cumulative Model Updates: 113,264
Cumulative Timesteps: 944,794,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 944794524...
Checkpoint 944794524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,218.00218
Policy Entropy: 1.72852
Value Function Loss: 0.05586

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.55001
Value Function Update Magnitude: 0.63384

Collected Steps per Second: 21,882.57802
Overall Steps per Second: 10,474.87920

Timestep Collection Time: 2.28593
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.77542

Cumulative Model Updates: 113,270
Cumulative Timesteps: 944,844,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,564.35809
Policy Entropy: 1.72206
Value Function Loss: 0.05989

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.53965

Collected Steps per Second: 22,033.85350
Overall Steps per Second: 10,507.74410

Timestep Collection Time: 2.26978
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.75954

Cumulative Model Updates: 113,276
Cumulative Timesteps: 944,894,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 944894558...
Checkpoint 944894558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,230.77115
Policy Entropy: 1.72115
Value Function Loss: 0.06078

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.55860
Value Function Update Magnitude: 0.47296

Collected Steps per Second: 22,092.23084
Overall Steps per Second: 10,459.40754

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.51725
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.78058

Cumulative Model Updates: 113,282
Cumulative Timesteps: 944,944,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,461.59067
Policy Entropy: 1.71230
Value Function Loss: 0.06911

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.14964
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.52325

Collected Steps per Second: 21,993.77671
Overall Steps per Second: 10,418.06859

Timestep Collection Time: 2.27401
Timestep Consumption Time: 2.52669
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.80070

Cumulative Model Updates: 113,288
Cumulative Timesteps: 944,994,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 944994574...
Checkpoint 944994574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,455.83512
Policy Entropy: 1.72446
Value Function Loss: 0.07029

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15426
Policy Update Magnitude: 0.57696
Value Function Update Magnitude: 0.59839

Collected Steps per Second: 21,926.63358
Overall Steps per Second: 10,619.64247

Timestep Collection Time: 2.28234
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.71240

Cumulative Model Updates: 113,294
Cumulative Timesteps: 945,044,618

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,931.66426
Policy Entropy: 1.73389
Value Function Loss: 0.06889

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14437
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.66311

Collected Steps per Second: 22,107.65117
Overall Steps per Second: 10,460.03058

Timestep Collection Time: 2.26284
Timestep Consumption Time: 2.51975
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.78259

Cumulative Model Updates: 113,300
Cumulative Timesteps: 945,094,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945094644...
Checkpoint 945094644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,479.95498
Policy Entropy: 1.74794
Value Function Loss: 0.06459

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.69939

Collected Steps per Second: 21,963.07417
Overall Steps per Second: 10,627.83824

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.42817
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.70481

Cumulative Model Updates: 113,306
Cumulative Timesteps: 945,144,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,401.32701
Policy Entropy: 1.74775
Value Function Loss: 0.06872

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.67367

Collected Steps per Second: 22,444.18352
Overall Steps per Second: 10,589.68982

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.72214

Cumulative Model Updates: 113,312
Cumulative Timesteps: 945,194,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 945194652...
Checkpoint 945194652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,336.57910
Policy Entropy: 1.75613
Value Function Loss: 0.07839

Mean KL Divergence: 0.01974
SB3 Clip Fraction: 0.17782
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.58915

Collected Steps per Second: 22,080.45621
Overall Steps per Second: 10,526.68163

Timestep Collection Time: 2.26472
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.75040

Cumulative Model Updates: 113,318
Cumulative Timesteps: 945,244,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,608.47829
Policy Entropy: 1.75581
Value Function Loss: 0.07495

Mean KL Divergence: 0.01926
SB3 Clip Fraction: 0.17707
Policy Update Magnitude: 0.50507
Value Function Update Magnitude: 0.60423

Collected Steps per Second: 21,507.21574
Overall Steps per Second: 10,467.11647

Timestep Collection Time: 2.32545
Timestep Consumption Time: 2.45275
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.77820

Cumulative Model Updates: 113,324
Cumulative Timesteps: 945,294,672

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 945294672...
Checkpoint 945294672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,764.30947
Policy Entropy: 1.73982
Value Function Loss: 0.07525

Mean KL Divergence: 0.01988
SB3 Clip Fraction: 0.17593
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.68353

Collected Steps per Second: 21,334.27807
Overall Steps per Second: 10,641.30326

Timestep Collection Time: 2.34505
Timestep Consumption Time: 2.35644
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.70149

Cumulative Model Updates: 113,330
Cumulative Timesteps: 945,344,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,741.84265
Policy Entropy: 1.73019
Value Function Loss: 0.06687

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.17014
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.73377

Collected Steps per Second: 21,487.95432
Overall Steps per Second: 10,372.24475

Timestep Collection Time: 2.32903
Timestep Consumption Time: 2.49597
PPO Batch Consumption Time: 0.30358
Total Iteration Time: 4.82499

Cumulative Model Updates: 113,336
Cumulative Timesteps: 945,394,748

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 945394748...
Checkpoint 945394748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,632.18239
Policy Entropy: 1.71632
Value Function Loss: 0.07453

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.17539
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.73600

Collected Steps per Second: 21,273.12018
Overall Steps per Second: 10,487.19796

Timestep Collection Time: 2.35076
Timestep Consumption Time: 2.41772
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.76848

Cumulative Model Updates: 113,342
Cumulative Timesteps: 945,444,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,950.01958
Policy Entropy: 1.72090
Value Function Loss: 0.07360

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15868
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.76032

Collected Steps per Second: 21,891.46628
Overall Steps per Second: 10,686.17366

Timestep Collection Time: 2.28473
Timestep Consumption Time: 2.39571
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.68044

Cumulative Model Updates: 113,348
Cumulative Timesteps: 945,494,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 945494772...
Checkpoint 945494772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,097.98331
Policy Entropy: 1.71406
Value Function Loss: 0.06986

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.57581
Value Function Update Magnitude: 0.73055

Collected Steps per Second: 21,534.93102
Overall Steps per Second: 10,555.14904

Timestep Collection Time: 2.32199
Timestep Consumption Time: 2.41541
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73740

Cumulative Model Updates: 113,354
Cumulative Timesteps: 945,544,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,428.61670
Policy Entropy: 1.71283
Value Function Loss: 0.06974

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.71357

Collected Steps per Second: 22,056.02447
Overall Steps per Second: 10,541.58027

Timestep Collection Time: 2.26705
Timestep Consumption Time: 2.47627
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.74331

Cumulative Model Updates: 113,360
Cumulative Timesteps: 945,594,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 945594778...
Checkpoint 945594778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,211.74358
Policy Entropy: 1.70634
Value Function Loss: 0.06361

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14143
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.68706

Collected Steps per Second: 21,810.22895
Overall Steps per Second: 10,626.96750

Timestep Collection Time: 2.29360
Timestep Consumption Time: 2.41367
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.70727

Cumulative Model Updates: 113,366
Cumulative Timesteps: 945,644,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,143.62265
Policy Entropy: 1.70576
Value Function Loss: 0.06566

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.56558
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 22,125.36851
Overall Steps per Second: 10,535.67866

Timestep Collection Time: 2.26084
Timestep Consumption Time: 2.48702
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.74787

Cumulative Model Updates: 113,372
Cumulative Timesteps: 945,694,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 945694824...
Checkpoint 945694824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,285.59157
Policy Entropy: 1.70592
Value Function Loss: 0.06404

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.56682
Value Function Update Magnitude: 0.60146

Collected Steps per Second: 21,841.44753
Overall Steps per Second: 10,565.49887

Timestep Collection Time: 2.28941
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.73276

Cumulative Model Updates: 113,378
Cumulative Timesteps: 945,744,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,836.73707
Policy Entropy: 1.72167
Value Function Loss: 0.06658

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.46629

Collected Steps per Second: 22,041.58519
Overall Steps per Second: 10,478.54757

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.50432
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.77375

Cumulative Model Updates: 113,384
Cumulative Timesteps: 945,794,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 945794850...
Checkpoint 945794850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,857.83605
Policy Entropy: 1.72400
Value Function Loss: 0.06765

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13695
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.41974

Collected Steps per Second: 21,929.16196
Overall Steps per Second: 10,608.64935

Timestep Collection Time: 2.28034
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.71370

Cumulative Model Updates: 113,390
Cumulative Timesteps: 945,844,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,160.14076
Policy Entropy: 1.72339
Value Function Loss: 0.07015

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.57170
Value Function Update Magnitude: 0.37673

Collected Steps per Second: 22,478.75900
Overall Steps per Second: 10,569.49579

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.50657
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.73116

Cumulative Model Updates: 113,396
Cumulative Timesteps: 945,894,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 945894862...
Checkpoint 945894862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,022.72851
Policy Entropy: 1.71576
Value Function Loss: 0.06714

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13655
Policy Update Magnitude: 0.56644
Value Function Update Magnitude: 0.44491

Collected Steps per Second: 21,999.16548
Overall Steps per Second: 10,533.76458

Timestep Collection Time: 2.27363
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.74835

Cumulative Model Updates: 113,402
Cumulative Timesteps: 945,944,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,725.65648
Policy Entropy: 1.71512
Value Function Loss: 0.06971

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.41007

Collected Steps per Second: 22,340.22821
Overall Steps per Second: 10,544.15085

Timestep Collection Time: 2.23955
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74500

Cumulative Model Updates: 113,408
Cumulative Timesteps: 945,994,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 945994912...
Checkpoint 945994912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,388.19148
Policy Entropy: 1.72157
Value Function Loss: 0.07427

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.34520

Collected Steps per Second: 21,869.82883
Overall Steps per Second: 10,575.46264

Timestep Collection Time: 2.28708
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.72963

Cumulative Model Updates: 113,414
Cumulative Timesteps: 946,044,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,427.78804
Policy Entropy: 1.73014
Value Function Loss: 0.07381

Mean KL Divergence: 0.01806
SB3 Clip Fraction: 0.17078
Policy Update Magnitude: 0.51611
Value Function Update Magnitude: 0.40140

Collected Steps per Second: 21,922.26825
Overall Steps per Second: 10,245.65190

Timestep Collection Time: 2.28170
Timestep Consumption Time: 2.60037
PPO Batch Consumption Time: 0.30619
Total Iteration Time: 4.88207

Cumulative Model Updates: 113,420
Cumulative Timesteps: 946,094,950

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 946094950...
Checkpoint 946094950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,761.22568
Policy Entropy: 1.73770
Value Function Loss: 0.06970

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14256
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 21,831.90446
Overall Steps per Second: 10,403.08058

Timestep Collection Time: 2.29105
Timestep Consumption Time: 2.51695
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.80800

Cumulative Model Updates: 113,426
Cumulative Timesteps: 946,144,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,846.76716
Policy Entropy: 1.73023
Value Function Loss: 0.06206

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.65025

Collected Steps per Second: 21,994.42733
Overall Steps per Second: 10,446.41483

Timestep Collection Time: 2.27385
Timestep Consumption Time: 2.51363
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.78748

Cumulative Model Updates: 113,432
Cumulative Timesteps: 946,194,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946194980...
Checkpoint 946194980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,016.25630
Policy Entropy: 1.72584
Value Function Loss: 0.06445

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.57658
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 21,885.97724
Overall Steps per Second: 10,607.25326

Timestep Collection Time: 2.28484
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.71432

Cumulative Model Updates: 113,438
Cumulative Timesteps: 946,244,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,748.13698
Policy Entropy: 1.72949
Value Function Loss: 0.06162

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.13742
Policy Update Magnitude: 0.57475
Value Function Update Magnitude: 0.48416

Collected Steps per Second: 22,267.57021
Overall Steps per Second: 10,509.42595

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75801

Cumulative Model Updates: 113,444
Cumulative Timesteps: 946,294,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 946294990...
Checkpoint 946294990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,813.85068
Policy Entropy: 1.73167
Value Function Loss: 0.06281

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.46595

Collected Steps per Second: 21,955.25718
Overall Steps per Second: 10,596.00281

Timestep Collection Time: 2.27873
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.72159

Cumulative Model Updates: 113,450
Cumulative Timesteps: 946,345,020

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,973.63780
Policy Entropy: 1.73230
Value Function Loss: 0.05928

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.46794

Collected Steps per Second: 21,500.55933
Overall Steps per Second: 10,472.57577

Timestep Collection Time: 2.32599
Timestep Consumption Time: 2.44934
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.77533

Cumulative Model Updates: 113,456
Cumulative Timesteps: 946,395,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 946395030...
Checkpoint 946395030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,413.29154
Policy Entropy: 1.72133
Value Function Loss: 0.05858

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.44933

Collected Steps per Second: 21,529.51655
Overall Steps per Second: 10,548.53855

Timestep Collection Time: 2.32388
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.74303

Cumulative Model Updates: 113,462
Cumulative Timesteps: 946,445,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,747.49861
Policy Entropy: 1.71419
Value Function Loss: 0.05655

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.54196
Value Function Update Magnitude: 0.50641

Collected Steps per Second: 22,246.49583
Overall Steps per Second: 10,562.45829

Timestep Collection Time: 2.24862
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.73602

Cumulative Model Updates: 113,468
Cumulative Timesteps: 946,495,086

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 946495086...
Checkpoint 946495086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,716.16986
Policy Entropy: 1.72067
Value Function Loss: 0.05919

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 21,399.92335
Overall Steps per Second: 10,656.32594

Timestep Collection Time: 2.33683
Timestep Consumption Time: 2.35597
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.69280

Cumulative Model Updates: 113,474
Cumulative Timesteps: 946,545,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,777.21952
Policy Entropy: 1.71897
Value Function Loss: 0.06277

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.56277
Value Function Update Magnitude: 0.52188

Collected Steps per Second: 21,478.19943
Overall Steps per Second: 10,491.76635

Timestep Collection Time: 2.32803
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76583

Cumulative Model Updates: 113,480
Cumulative Timesteps: 946,595,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 946595096...
Checkpoint 946595096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,017.37322
Policy Entropy: 1.72126
Value Function Loss: 0.06521

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.15076
Policy Update Magnitude: 0.56306
Value Function Update Magnitude: 0.53282

Collected Steps per Second: 21,450.75493
Overall Steps per Second: 10,575.38670

Timestep Collection Time: 2.33195
Timestep Consumption Time: 2.39809
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.73004

Cumulative Model Updates: 113,486
Cumulative Timesteps: 946,645,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,071.86089
Policy Entropy: 1.72441
Value Function Loss: 0.06537

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.64152

Collected Steps per Second: 20,206.72224
Overall Steps per Second: 10,178.42277

Timestep Collection Time: 2.47690
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.91726

Cumulative Model Updates: 113,492
Cumulative Timesteps: 946,695,168

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 946695168...
Checkpoint 946695168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,090.97064
Policy Entropy: 1.72156
Value Function Loss: 0.06210

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.67246

Collected Steps per Second: 21,381.38709
Overall Steps per Second: 10,549.54559

Timestep Collection Time: 2.33867
Timestep Consumption Time: 2.40125
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73992

Cumulative Model Updates: 113,498
Cumulative Timesteps: 946,745,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,542.78494
Policy Entropy: 1.72262
Value Function Loss: 0.06071

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.65200

Collected Steps per Second: 22,240.06535
Overall Steps per Second: 10,761.51119

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.39857
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.64730

Cumulative Model Updates: 113,504
Cumulative Timesteps: 946,795,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946795184...
Checkpoint 946795184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,346.07964
Policy Entropy: 1.72570
Value Function Loss: 0.05997

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14221
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.64179

Collected Steps per Second: 22,220.63950
Overall Steps per Second: 10,781.86153

Timestep Collection Time: 2.25070
Timestep Consumption Time: 2.38783
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.63853

Cumulative Model Updates: 113,510
Cumulative Timesteps: 946,845,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,856.18600
Policy Entropy: 1.71994
Value Function Loss: 0.05810

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.54807
Value Function Update Magnitude: 0.63310

Collected Steps per Second: 22,431.21581
Overall Steps per Second: 10,790.66244

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.40498
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.63438

Cumulative Model Updates: 113,516
Cumulative Timesteps: 946,895,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 946895204...
Checkpoint 946895204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,366.65350
Policy Entropy: 1.72537
Value Function Loss: 0.06156

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.63854

Collected Steps per Second: 21,959.44990
Overall Steps per Second: 10,611.06563

Timestep Collection Time: 2.27838
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.71508

Cumulative Model Updates: 113,522
Cumulative Timesteps: 946,945,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,740.55993
Policy Entropy: 1.72356
Value Function Loss: 0.06138

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.58709

Collected Steps per Second: 22,132.77141
Overall Steps per Second: 10,521.02527

Timestep Collection Time: 2.26009
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.75448

Cumulative Model Updates: 113,528
Cumulative Timesteps: 946,995,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 946995258...
Checkpoint 946995258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,791.50581
Policy Entropy: 1.73638
Value Function Loss: 0.06437

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.53533

Collected Steps per Second: 22,189.71192
Overall Steps per Second: 10,678.49303

Timestep Collection Time: 2.25474
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.68531

Cumulative Model Updates: 113,534
Cumulative Timesteps: 947,045,290

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,257.10726
Policy Entropy: 1.73191
Value Function Loss: 0.06428

Mean KL Divergence: 0.01690
SB3 Clip Fraction: 0.15950
Policy Update Magnitude: 0.52721
Value Function Update Magnitude: 0.43825

Collected Steps per Second: 22,147.66375
Overall Steps per Second: 10,510.72903

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.75971

Cumulative Model Updates: 113,540
Cumulative Timesteps: 947,095,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 947095318...
Checkpoint 947095318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,073.57624
Policy Entropy: 1.74193
Value Function Loss: 0.07441

Mean KL Divergence: 0.01937
SB3 Clip Fraction: 0.17512
Policy Update Magnitude: 0.49856
Value Function Update Magnitude: 0.51205

Collected Steps per Second: 22,382.76397
Overall Steps per Second: 10,562.27922

Timestep Collection Time: 2.23511
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.73648

Cumulative Model Updates: 113,546
Cumulative Timesteps: 947,145,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,455.31619
Policy Entropy: 1.73565
Value Function Loss: 0.07526

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.18389
Policy Update Magnitude: 0.52708
Value Function Update Magnitude: 0.53471

Collected Steps per Second: 22,558.54037
Overall Steps per Second: 10,596.08493

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.50457
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72307

Cumulative Model Updates: 113,552
Cumulative Timesteps: 947,195,392

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 947195392...
Checkpoint 947195392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,020.41228
Policy Entropy: 1.73372
Value Function Loss: 0.07986

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.18746
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.46261

Collected Steps per Second: 22,491.73505
Overall Steps per Second: 10,631.38586

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.70381

Cumulative Model Updates: 113,558
Cumulative Timesteps: 947,245,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,288.91054
Policy Entropy: 1.72827
Value Function Loss: 0.07175

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.17339
Policy Update Magnitude: 0.55072
Value Function Update Magnitude: 0.45107

Collected Steps per Second: 22,622.07561
Overall Steps per Second: 10,812.07953

Timestep Collection Time: 2.21182
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.62779

Cumulative Model Updates: 113,564
Cumulative Timesteps: 947,295,436

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 947295436...
Checkpoint 947295436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,607.83044
Policy Entropy: 1.74761
Value Function Loss: 0.06823

Mean KL Divergence: 0.01745
SB3 Clip Fraction: 0.16427
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.55973

Collected Steps per Second: 22,188.53700
Overall Steps per Second: 10,595.16119

Timestep Collection Time: 2.25414
Timestep Consumption Time: 2.46651
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.72065

Cumulative Model Updates: 113,570
Cumulative Timesteps: 947,345,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,652.44057
Policy Entropy: 1.75968
Value Function Loss: 0.05922

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.53726
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 21,757.28135
Overall Steps per Second: 10,630.52368

Timestep Collection Time: 2.29992
Timestep Consumption Time: 2.40728
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.70720

Cumulative Model Updates: 113,576
Cumulative Timesteps: 947,395,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 947395492...
Checkpoint 947395492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,464.38724
Policy Entropy: 1.76154
Value Function Loss: 0.05993

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.54599
Value Function Update Magnitude: 0.57717

Collected Steps per Second: 21,610.77018
Overall Steps per Second: 10,588.69720

Timestep Collection Time: 2.31570
Timestep Consumption Time: 2.41047
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.72617

Cumulative Model Updates: 113,582
Cumulative Timesteps: 947,445,536

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,224.92613
Policy Entropy: 1.75108
Value Function Loss: 0.05968

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.50965

Collected Steps per Second: 21,880.38423
Overall Steps per Second: 10,780.93643

Timestep Collection Time: 2.28625
Timestep Consumption Time: 2.35379
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.64004

Cumulative Model Updates: 113,588
Cumulative Timesteps: 947,495,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 947495560...
Checkpoint 947495560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,381.34456
Policy Entropy: 1.75933
Value Function Loss: 0.07044

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.45372

Collected Steps per Second: 21,514.58720
Overall Steps per Second: 10,717.07185

Timestep Collection Time: 2.32521
Timestep Consumption Time: 2.34267
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.66788

Cumulative Model Updates: 113,594
Cumulative Timesteps: 947,545,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,049.56761
Policy Entropy: 1.76099
Value Function Loss: 0.07416

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.13692
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.42306

Collected Steps per Second: 21,737.71144
Overall Steps per Second: 10,759.21351

Timestep Collection Time: 2.30107
Timestep Consumption Time: 2.34797
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.64904

Cumulative Model Updates: 113,600
Cumulative Timesteps: 947,595,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 947595606...
Checkpoint 947595606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,646.67932
Policy Entropy: 1.77241
Value Function Loss: 0.07037

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.56575
Value Function Update Magnitude: 0.40218

Collected Steps per Second: 21,719.43375
Overall Steps per Second: 10,636.59643

Timestep Collection Time: 2.30264
Timestep Consumption Time: 2.39924
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.70188

Cumulative Model Updates: 113,606
Cumulative Timesteps: 947,645,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,088.32244
Policy Entropy: 1.76268
Value Function Loss: 0.06385

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.55987
Value Function Update Magnitude: 0.37447

Collected Steps per Second: 22,314.62361
Overall Steps per Second: 10,572.45174

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.72927

Cumulative Model Updates: 113,612
Cumulative Timesteps: 947,695,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 947695618...
Checkpoint 947695618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,832.91472
Policy Entropy: 1.77054
Value Function Loss: 0.05748

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.55827
Value Function Update Magnitude: 0.50547

Collected Steps per Second: 21,882.80777
Overall Steps per Second: 10,580.21755

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.72788

Cumulative Model Updates: 113,618
Cumulative Timesteps: 947,745,640

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,648.66032
Policy Entropy: 1.75519
Value Function Loss: 0.06047

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.56486
Value Function Update Magnitude: 0.61544

Collected Steps per Second: 22,350.88631
Overall Steps per Second: 10,555.91021

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.73934

Cumulative Model Updates: 113,624
Cumulative Timesteps: 947,795,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 947795668...
Checkpoint 947795668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,903.09588
Policy Entropy: 1.76497
Value Function Loss: 0.05856

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.64787

Collected Steps per Second: 22,203.56386
Overall Steps per Second: 10,558.80644

Timestep Collection Time: 2.25243
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.73652

Cumulative Model Updates: 113,630
Cumulative Timesteps: 947,845,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,490.73584
Policy Entropy: 1.76429
Value Function Loss: 0.06010

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.67366

Collected Steps per Second: 21,929.29563
Overall Steps per Second: 10,422.28903

Timestep Collection Time: 2.28033
Timestep Consumption Time: 2.51766
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.79799

Cumulative Model Updates: 113,636
Cumulative Timesteps: 947,895,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 947895686...
Checkpoint 947895686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,059.56527
Policy Entropy: 1.76787
Value Function Loss: 0.06315

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.65413

Collected Steps per Second: 21,928.25925
Overall Steps per Second: 10,609.28149

Timestep Collection Time: 2.28080
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.71417

Cumulative Model Updates: 113,642
Cumulative Timesteps: 947,945,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,021.18372
Policy Entropy: 1.77213
Value Function Loss: 0.06367

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.58307
Value Function Update Magnitude: 0.69301

Collected Steps per Second: 22,498.97917
Overall Steps per Second: 10,564.67060

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.51114
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.73408

Cumulative Model Updates: 113,648
Cumulative Timesteps: 947,995,714

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 947995714...
Checkpoint 947995714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,214.38923
Policy Entropy: 1.77805
Value Function Loss: 0.06425

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.66915

Collected Steps per Second: 21,721.09381
Overall Steps per Second: 10,552.32839

Timestep Collection Time: 2.30292
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.74038

Cumulative Model Updates: 113,654
Cumulative Timesteps: 948,045,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,426.68189
Policy Entropy: 1.78048
Value Function Loss: 0.05665

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.55909
Value Function Update Magnitude: 0.61227

Collected Steps per Second: 22,352.56702
Overall Steps per Second: 10,542.13100

Timestep Collection Time: 2.23813
Timestep Consumption Time: 2.50740
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.74553

Cumulative Model Updates: 113,660
Cumulative Timesteps: 948,095,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948095764...
Checkpoint 948095764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,095.60782
Policy Entropy: 1.78204
Value Function Loss: 0.05487

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.54653
Value Function Update Magnitude: 0.58303

Collected Steps per Second: 21,970.63625
Overall Steps per Second: 10,571.09614

Timestep Collection Time: 2.27704
Timestep Consumption Time: 2.45549
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.73253

Cumulative Model Updates: 113,666
Cumulative Timesteps: 948,145,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,954.63764
Policy Entropy: 1.76339
Value Function Loss: 0.05335

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12972
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.58411

Collected Steps per Second: 22,334.06517
Overall Steps per Second: 10,568.37283

Timestep Collection Time: 2.23999
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.73375

Cumulative Model Updates: 113,672
Cumulative Timesteps: 948,195,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948195820...
Checkpoint 948195820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,647.68768
Policy Entropy: 1.76026
Value Function Loss: 0.05996

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.56004
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 22,316.48845
Overall Steps per Second: 10,532.58162

Timestep Collection Time: 2.24068
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.74755

Cumulative Model Updates: 113,678
Cumulative Timesteps: 948,245,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,068.06431
Policy Entropy: 1.74382
Value Function Loss: 0.06041

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.56635
Value Function Update Magnitude: 0.63212

Collected Steps per Second: 21,703.79755
Overall Steps per Second: 10,597.96100

Timestep Collection Time: 2.30577
Timestep Consumption Time: 2.41627
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.72204

Cumulative Model Updates: 113,684
Cumulative Timesteps: 948,295,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 948295868...
Checkpoint 948295868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,996.45036
Policy Entropy: 1.74775
Value Function Loss: 0.06077

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14930
Policy Update Magnitude: 0.53407
Value Function Update Magnitude: 0.62424

Collected Steps per Second: 21,771.14677
Overall Steps per Second: 10,626.30423

Timestep Collection Time: 2.29910
Timestep Consumption Time: 2.41129
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71039

Cumulative Model Updates: 113,690
Cumulative Timesteps: 948,345,922

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,895.47082
Policy Entropy: 1.74689
Value Function Loss: 0.06115

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.54339
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 21,807.95993
Overall Steps per Second: 10,734.59267

Timestep Collection Time: 2.29347
Timestep Consumption Time: 2.36585
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.65933

Cumulative Model Updates: 113,696
Cumulative Timesteps: 948,395,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 948395938...
Checkpoint 948395938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,362.35587
Policy Entropy: 1.76087
Value Function Loss: 0.06493

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.59145

Collected Steps per Second: 21,501.34057
Overall Steps per Second: 10,722.48696

Timestep Collection Time: 2.32544
Timestep Consumption Time: 2.33766
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.66310

Cumulative Model Updates: 113,702
Cumulative Timesteps: 948,445,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,112.63921
Policy Entropy: 1.77712
Value Function Loss: 0.06818

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.58406
Value Function Update Magnitude: 0.63883

Collected Steps per Second: 22,070.19506
Overall Steps per Second: 10,811.88568

Timestep Collection Time: 2.26650
Timestep Consumption Time: 2.36008
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.62658

Cumulative Model Updates: 113,708
Cumulative Timesteps: 948,495,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 948495960...
Checkpoint 948495960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,357.37650
Policy Entropy: 1.77072
Value Function Loss: 0.06350

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14776
Policy Update Magnitude: 0.57878
Value Function Update Magnitude: 0.66213

Collected Steps per Second: 21,350.63291
Overall Steps per Second: 10,370.52584

Timestep Collection Time: 2.34204
Timestep Consumption Time: 2.47970
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.82174

Cumulative Model Updates: 113,714
Cumulative Timesteps: 948,545,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,205.86805
Policy Entropy: 1.76169
Value Function Loss: 0.06259

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.58998

Collected Steps per Second: 22,084.04742
Overall Steps per Second: 10,715.45511

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.40294
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.66784

Cumulative Model Updates: 113,720
Cumulative Timesteps: 948,595,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948595982...
Checkpoint 948595982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,955.23871
Policy Entropy: 1.75521
Value Function Loss: 0.06468

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.46019

Collected Steps per Second: 21,813.06624
Overall Steps per Second: 10,666.79337

Timestep Collection Time: 2.29303
Timestep Consumption Time: 2.39610
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.68913

Cumulative Model Updates: 113,726
Cumulative Timesteps: 948,646,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,989.54057
Policy Entropy: 1.75969
Value Function Loss: 0.06194

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.14027
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.53642

Collected Steps per Second: 22,276.22276
Overall Steps per Second: 10,499.06359

Timestep Collection Time: 2.24553
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.76442

Cumulative Model Updates: 113,732
Cumulative Timesteps: 948,696,022

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 948696022...
Checkpoint 948696022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,432.39544
Policy Entropy: 1.76430
Value Function Loss: 0.06449

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.55553
Value Function Update Magnitude: 0.54225

Collected Steps per Second: 22,235.32967
Overall Steps per Second: 10,579.29299

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.72640

Cumulative Model Updates: 113,738
Cumulative Timesteps: 948,746,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,368.79149
Policy Entropy: 1.75619
Value Function Loss: 0.06416

Mean KL Divergence: 0.02744
SB3 Clip Fraction: 0.20795
Policy Update Magnitude: 0.48404
Value Function Update Magnitude: 0.59420

Collected Steps per Second: 22,401.58061
Overall Steps per Second: 10,578.72318

Timestep Collection Time: 2.23225
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72704

Cumulative Model Updates: 113,744
Cumulative Timesteps: 948,796,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 948796030...
Checkpoint 948796030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,398.99599
Policy Entropy: 1.75008
Value Function Loss: 0.06360

Mean KL Divergence: 0.03982
SB3 Clip Fraction: 0.23804
Policy Update Magnitude: 0.41426
Value Function Update Magnitude: 0.53019

Collected Steps per Second: 21,956.21430
Overall Steps per Second: 10,526.56775

Timestep Collection Time: 2.27735
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.75008

Cumulative Model Updates: 113,750
Cumulative Timesteps: 948,846,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,227.54604
Policy Entropy: 1.76150
Value Function Loss: 0.06948

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.17472
Policy Update Magnitude: 0.43976
Value Function Update Magnitude: 0.56751

Collected Steps per Second: 22,523.43335
Overall Steps per Second: 10,566.66001

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.51266
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.73319

Cumulative Model Updates: 113,756
Cumulative Timesteps: 948,896,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 948896046...
Checkpoint 948896046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,808.12514
Policy Entropy: 1.77317
Value Function Loss: 0.06630

Mean KL Divergence: 0.02116
SB3 Clip Fraction: 0.18383
Policy Update Magnitude: 0.51074
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 22,196.49796
Overall Steps per Second: 10,522.57441

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.75169

Cumulative Model Updates: 113,762
Cumulative Timesteps: 948,946,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,386.84596
Policy Entropy: 1.78351
Value Function Loss: 0.07141

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.18095
Policy Update Magnitude: 0.53964
Value Function Update Magnitude: 0.66495

Collected Steps per Second: 22,439.60040
Overall Steps per Second: 10,570.63144

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.73028

Cumulative Model Updates: 113,768
Cumulative Timesteps: 948,996,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 948996048...
Checkpoint 948996048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,807.29547
Policy Entropy: 1.78137
Value Function Loss: 0.06625

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.17408
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.70917

Collected Steps per Second: 22,297.66834
Overall Steps per Second: 10,550.63105

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.74019

Cumulative Model Updates: 113,774
Cumulative Timesteps: 949,046,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,517.36661
Policy Entropy: 1.78685
Value Function Loss: 0.07177

Mean KL Divergence: 0.01721
SB3 Clip Fraction: 0.16696
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.60199

Collected Steps per Second: 22,308.23011
Overall Steps per Second: 10,553.49779

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.73928

Cumulative Model Updates: 113,780
Cumulative Timesteps: 949,096,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 949096076...
Checkpoint 949096076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,279.95854
Policy Entropy: 1.77018
Value Function Loss: 0.07053

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.16270
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.52619

Collected Steps per Second: 22,550.10684
Overall Steps per Second: 10,636.42668

Timestep Collection Time: 2.21826
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.70290

Cumulative Model Updates: 113,786
Cumulative Timesteps: 949,146,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,357.53557
Policy Entropy: 1.77493
Value Function Loss: 0.07393

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.63508

Collected Steps per Second: 22,539.23615
Overall Steps per Second: 10,752.47667

Timestep Collection Time: 2.21915
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.65177

Cumulative Model Updates: 113,792
Cumulative Timesteps: 949,196,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949196116...
Checkpoint 949196116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,978.11834
Policy Entropy: 1.77014
Value Function Loss: 0.06853

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.67132

Collected Steps per Second: 21,403.41824
Overall Steps per Second: 10,673.49178

Timestep Collection Time: 2.33748
Timestep Consumption Time: 2.34984
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.68731

Cumulative Model Updates: 113,798
Cumulative Timesteps: 949,246,146

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,696.00827
Policy Entropy: 1.77384
Value Function Loss: 0.06953

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.15337
Policy Update Magnitude: 0.55961
Value Function Update Magnitude: 0.66940

Collected Steps per Second: 21,727.40236
Overall Steps per Second: 10,559.66321

Timestep Collection Time: 2.30124
Timestep Consumption Time: 2.43376
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73500

Cumulative Model Updates: 113,804
Cumulative Timesteps: 949,296,146

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 949296146...
Checkpoint 949296146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,872.42746
Policy Entropy: 1.77539
Value Function Loss: 0.07164

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 21,506.11906
Overall Steps per Second: 10,514.53890

Timestep Collection Time: 2.32511
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.75570

Cumulative Model Updates: 113,810
Cumulative Timesteps: 949,346,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,861.85375
Policy Entropy: 1.78181
Value Function Loss: 0.07873

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.58105
Value Function Update Magnitude: 0.44513

Collected Steps per Second: 21,740.11807
Overall Steps per Second: 10,590.01298

Timestep Collection Time: 2.30017
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.72200

Cumulative Model Updates: 113,816
Cumulative Timesteps: 949,396,156

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 949396156...
Checkpoint 949396156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,886.77197
Policy Entropy: 1.77968
Value Function Loss: 0.07748

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.58230
Value Function Update Magnitude: 0.36340

Collected Steps per Second: 21,506.23635
Overall Steps per Second: 10,553.43942

Timestep Collection Time: 2.32556
Timestep Consumption Time: 2.41356
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.73912

Cumulative Model Updates: 113,822
Cumulative Timesteps: 949,446,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,059.83596
Policy Entropy: 1.79075
Value Function Loss: 0.08436

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.32766

Collected Steps per Second: 21,836.58004
Overall Steps per Second: 10,477.77111

Timestep Collection Time: 2.29010
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.77277

Cumulative Model Updates: 113,828
Cumulative Timesteps: 949,496,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 949496178...
Checkpoint 949496178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,163.35150
Policy Entropy: 1.78522
Value Function Loss: 0.08114

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.58866
Value Function Update Magnitude: 0.29166

Collected Steps per Second: 22,146.72277
Overall Steps per Second: 10,548.42441

Timestep Collection Time: 2.25794
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.74061

Cumulative Model Updates: 113,834
Cumulative Timesteps: 949,546,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,870.04956
Policy Entropy: 1.79026
Value Function Loss: 0.07915

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14200
Policy Update Magnitude: 0.58259
Value Function Update Magnitude: 0.27627

Collected Steps per Second: 22,565.73427
Overall Steps per Second: 10,679.98684

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68502

Cumulative Model Updates: 113,840
Cumulative Timesteps: 949,596,220

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 949596220...
Checkpoint 949596220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,206.80811
Policy Entropy: 1.77332
Value Function Loss: 0.07592

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15881
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.36240

Collected Steps per Second: 22,199.37265
Overall Steps per Second: 10,594.81876

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.71929

Cumulative Model Updates: 113,846
Cumulative Timesteps: 949,646,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,867.48215
Policy Entropy: 1.78498
Value Function Loss: 0.07490

Mean KL Divergence: 0.01865
SB3 Clip Fraction: 0.16904
Policy Update Magnitude: 0.55969
Value Function Update Magnitude: 0.46744

Collected Steps per Second: 22,560.74259
Overall Steps per Second: 10,730.28297

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.66232

Cumulative Model Updates: 113,852
Cumulative Timesteps: 949,696,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 949696248...
Checkpoint 949696248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,770.16899
Policy Entropy: 1.77966
Value Function Loss: 0.07542

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16960
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.41138

Collected Steps per Second: 21,912.30313
Overall Steps per Second: 10,607.73001

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.71581

Cumulative Model Updates: 113,858
Cumulative Timesteps: 949,746,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,778.68357
Policy Entropy: 1.80676
Value Function Loss: 0.07865

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.57346
Value Function Update Magnitude: 0.42196

Collected Steps per Second: 22,506.34746
Overall Steps per Second: 10,594.54244

Timestep Collection Time: 2.22231
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.72092

Cumulative Model Updates: 113,864
Cumulative Timesteps: 949,796,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 949796288...
Checkpoint 949796288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,856.06819
Policy Entropy: 1.79798
Value Function Loss: 0.07516

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.14724
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.52754

Collected Steps per Second: 21,888.52154
Overall Steps per Second: 10,529.89118

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.74972

Cumulative Model Updates: 113,870
Cumulative Timesteps: 949,846,302

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,501.31966
Policy Entropy: 1.80657
Value Function Loss: 0.07383

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14762
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.55835

Collected Steps per Second: 22,302.50903
Overall Steps per Second: 10,533.12346

Timestep Collection Time: 2.24199
Timestep Consumption Time: 2.50513
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.74712

Cumulative Model Updates: 113,876
Cumulative Timesteps: 949,896,304

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 949896304...
Checkpoint 949896304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,871.56989
Policy Entropy: 1.79148
Value Function Loss: 0.07094

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.17440
Policy Update Magnitude: 0.51710
Value Function Update Magnitude: 0.58780

Collected Steps per Second: 21,929.06132
Overall Steps per Second: 10,620.79849

Timestep Collection Time: 2.28136
Timestep Consumption Time: 2.42902
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.71038

Cumulative Model Updates: 113,882
Cumulative Timesteps: 949,946,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,509.93691
Policy Entropy: 1.79814
Value Function Loss: 0.07253

Mean KL Divergence: 0.01696
SB3 Clip Fraction: 0.16137
Policy Update Magnitude: 0.51161
Value Function Update Magnitude: 0.58575

Collected Steps per Second: 22,481.19257
Overall Steps per Second: 10,749.71547

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.42720
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.65129

Cumulative Model Updates: 113,888
Cumulative Timesteps: 949,996,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 949996332...
Checkpoint 949996332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,404.00624
Policy Entropy: 1.78900
Value Function Loss: 0.07163

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.55431
Value Function Update Magnitude: 0.55905

Collected Steps per Second: 21,764.56041
Overall Steps per Second: 10,442.61866

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.78941

Cumulative Model Updates: 113,894
Cumulative Timesteps: 950,046,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,624.79296
Policy Entropy: 1.78223
Value Function Loss: 0.06804

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.15407
Policy Update Magnitude: 0.57460
Value Function Update Magnitude: 0.53629

Collected Steps per Second: 22,428.41591
Overall Steps per Second: 10,737.41478

Timestep Collection Time: 2.23101
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.66015

Cumulative Model Updates: 113,900
Cumulative Timesteps: 950,096,384

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 950096384...
Checkpoint 950096384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,104.76114
Policy Entropy: 1.78903
Value Function Loss: 0.07080

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.44721

Collected Steps per Second: 21,651.48603
Overall Steps per Second: 10,569.50670

Timestep Collection Time: 2.31070
Timestep Consumption Time: 2.42273
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.73343

Cumulative Model Updates: 113,906
Cumulative Timesteps: 950,146,414

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,177.48985
Policy Entropy: 1.79139
Value Function Loss: 0.07621

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14145
Policy Update Magnitude: 0.59662
Value Function Update Magnitude: 0.58503

Collected Steps per Second: 22,453.00392
Overall Steps per Second: 10,544.81665

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74413

Cumulative Model Updates: 113,912
Cumulative Timesteps: 950,196,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 950196440...
Checkpoint 950196440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,028.44820
Policy Entropy: 1.80297
Value Function Loss: 0.07839

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.15001
Policy Update Magnitude: 0.60280
Value Function Update Magnitude: 0.60385

Collected Steps per Second: 22,018.11724
Overall Steps per Second: 10,669.63514

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.41563
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.68676

Cumulative Model Updates: 113,918
Cumulative Timesteps: 950,246,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,712.08191
Policy Entropy: 1.81627
Value Function Loss: 0.07771

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.59614
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,525.62233
Overall Steps per Second: 10,622.04501

Timestep Collection Time: 2.21969
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.70719

Cumulative Model Updates: 113,924
Cumulative Timesteps: 950,296,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 950296446...
Checkpoint 950296446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,508.74602
Policy Entropy: 1.81621
Value Function Loss: 0.07033

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.16303
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.67962

Collected Steps per Second: 22,255.39591
Overall Steps per Second: 10,554.86065

Timestep Collection Time: 2.24710
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.73810

Cumulative Model Updates: 113,930
Cumulative Timesteps: 950,346,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,624.88592
Policy Entropy: 1.80970
Value Function Loss: 0.06711

Mean KL Divergence: 0.01656
SB3 Clip Fraction: 0.16148
Policy Update Magnitude: 0.52227
Value Function Update Magnitude: 0.73101

Collected Steps per Second: 22,585.64261
Overall Steps per Second: 10,753.60677

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.65295

Cumulative Model Updates: 113,936
Cumulative Timesteps: 950,396,492

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 950396492...
Checkpoint 950396492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,380.89387
Policy Entropy: 1.79490
Value Function Loss: 0.06698

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.68174

Collected Steps per Second: 21,873.71560
Overall Steps per Second: 10,607.49304

Timestep Collection Time: 2.28585
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71365

Cumulative Model Updates: 113,942
Cumulative Timesteps: 950,446,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,632.39707
Policy Entropy: 1.79162
Value Function Loss: 0.06367

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.58064
Value Function Update Magnitude: 0.74230

Collected Steps per Second: 22,345.66401
Overall Steps per Second: 10,539.21418

Timestep Collection Time: 2.23873
Timestep Consumption Time: 2.50792
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74665

Cumulative Model Updates: 113,948
Cumulative Timesteps: 950,496,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 950496518...
Checkpoint 950496518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,694.56141
Policy Entropy: 1.79495
Value Function Loss: 0.06781

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.13959
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.76104

Collected Steps per Second: 21,299.74267
Overall Steps per Second: 10,605.32344

Timestep Collection Time: 2.34745
Timestep Consumption Time: 2.36717
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.71461

Cumulative Model Updates: 113,954
Cumulative Timesteps: 950,546,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,340.89627
Policy Entropy: 1.80066
Value Function Loss: 0.07074

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.14134
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.75800

Collected Steps per Second: 21,679.11521
Overall Steps per Second: 10,582.76812

Timestep Collection Time: 2.30757
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72712

Cumulative Model Updates: 113,960
Cumulative Timesteps: 950,596,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 950596544...
Checkpoint 950596544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,897.78122
Policy Entropy: 1.81277
Value Function Loss: 0.07340

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.75141

Collected Steps per Second: 21,634.51740
Overall Steps per Second: 10,570.60171

Timestep Collection Time: 2.31343
Timestep Consumption Time: 2.42140
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.73483

Cumulative Model Updates: 113,966
Cumulative Timesteps: 950,646,594

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,040.75968
Policy Entropy: 1.79907
Value Function Loss: 0.07522

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14679
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.64922

Collected Steps per Second: 21,800.62304
Overall Steps per Second: 10,792.96283

Timestep Collection Time: 2.29480
Timestep Consumption Time: 2.34045
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.63524

Cumulative Model Updates: 113,972
Cumulative Timesteps: 950,696,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 950696622...
Checkpoint 950696622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,862.07336
Policy Entropy: 1.78712
Value Function Loss: 0.07469

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.15216
Policy Update Magnitude: 0.57285
Value Function Update Magnitude: 0.71365

Collected Steps per Second: 21,517.40558
Overall Steps per Second: 10,448.53866

Timestep Collection Time: 2.32444
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.78689

Cumulative Model Updates: 113,978
Cumulative Timesteps: 950,746,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,216.13515
Policy Entropy: 1.76941
Value Function Loss: 0.07036

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.57421
Value Function Update Magnitude: 0.77925

Collected Steps per Second: 22,588.52071
Overall Steps per Second: 10,749.93651

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.43816
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.65212

Cumulative Model Updates: 113,984
Cumulative Timesteps: 950,796,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 950796648...
Checkpoint 950796648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,799.52285
Policy Entropy: 1.78050
Value Function Loss: 0.06746

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.16656
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.77635

Collected Steps per Second: 22,200.26491
Overall Steps per Second: 10,587.08222

Timestep Collection Time: 2.25286
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72406

Cumulative Model Updates: 113,990
Cumulative Timesteps: 950,846,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,053.76613
Policy Entropy: 1.77256
Value Function Loss: 0.06782

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.15565
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.78607

Collected Steps per Second: 22,133.76663
Overall Steps per Second: 10,530.61199

Timestep Collection Time: 2.25926
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.74863

Cumulative Model Updates: 113,996
Cumulative Timesteps: 950,896,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 950896668...
Checkpoint 950896668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,883.21305
Policy Entropy: 1.77392
Value Function Loss: 0.06954

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.15923
Policy Update Magnitude: 0.58431
Value Function Update Magnitude: 0.77341

Collected Steps per Second: 22,187.15373
Overall Steps per Second: 10,561.16382

Timestep Collection Time: 2.25527
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.73792

Cumulative Model Updates: 114,002
Cumulative Timesteps: 950,946,706

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,802.71046
Policy Entropy: 1.77323
Value Function Loss: 0.06635

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.15108
Policy Update Magnitude: 0.58278
Value Function Update Magnitude: 0.75857

Collected Steps per Second: 22,216.30475
Overall Steps per Second: 10,511.73492

Timestep Collection Time: 2.25096
Timestep Consumption Time: 2.50639
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75735

Cumulative Model Updates: 114,008
Cumulative Timesteps: 950,996,714

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 950996714...
Checkpoint 950996714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,286.82074
Policy Entropy: 1.78001
Value Function Loss: 0.06343

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14593
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.70130

Collected Steps per Second: 22,183.41901
Overall Steps per Second: 10,610.84447

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.71348

Cumulative Model Updates: 114,014
Cumulative Timesteps: 951,046,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.73477
Policy Entropy: 1.78771
Value Function Loss: 0.06364

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.58013
Value Function Update Magnitude: 0.69290

Collected Steps per Second: 22,196.19474
Overall Steps per Second: 10,486.10952

Timestep Collection Time: 2.25471
Timestep Consumption Time: 2.51789
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.77260

Cumulative Model Updates: 114,020
Cumulative Timesteps: 951,096,774

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 951096774...
Checkpoint 951096774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,861.45644
Policy Entropy: 1.78644
Value Function Loss: 0.06745

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.59159
Value Function Update Magnitude: 0.67675

Collected Steps per Second: 22,308.01664
Overall Steps per Second: 10,597.21248

Timestep Collection Time: 2.24197
Timestep Consumption Time: 2.47757
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.71954

Cumulative Model Updates: 114,026
Cumulative Timesteps: 951,146,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,934.73346
Policy Entropy: 1.79021
Value Function Loss: 0.07231

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.17208
Policy Update Magnitude: 0.57911
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 22,214.14146
Overall Steps per Second: 10,487.81572

Timestep Collection Time: 2.25199
Timestep Consumption Time: 2.51793
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.76992

Cumulative Model Updates: 114,032
Cumulative Timesteps: 951,196,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 951196814...
Checkpoint 951196814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,485.49955
Policy Entropy: 1.77926
Value Function Loss: 0.07782

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.66478

Collected Steps per Second: 22,267.24461
Overall Steps per Second: 10,605.66987

Timestep Collection Time: 2.24545
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.71446

Cumulative Model Updates: 114,038
Cumulative Timesteps: 951,246,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,492.64069
Policy Entropy: 1.77753
Value Function Loss: 0.07601

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.57018
Value Function Update Magnitude: 0.74709

Collected Steps per Second: 22,681.00715
Overall Steps per Second: 10,642.78651

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69933

Cumulative Model Updates: 114,044
Cumulative Timesteps: 951,296,828

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 951296828...
Checkpoint 951296828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,335.61679
Policy Entropy: 1.75586
Value Function Loss: 0.07296

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.16897
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.68330

Collected Steps per Second: 21,986.02717
Overall Steps per Second: 10,433.21622

Timestep Collection Time: 2.27545
Timestep Consumption Time: 2.51962
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.79507

Cumulative Model Updates: 114,050
Cumulative Timesteps: 951,346,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,435.46049
Policy Entropy: 1.75398
Value Function Loss: 0.07554

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.17447
Policy Update Magnitude: 0.50781
Value Function Update Magnitude: 0.63047

Collected Steps per Second: 22,555.14722
Overall Steps per Second: 10,621.99086

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.49043
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70722

Cumulative Model Updates: 114,056
Cumulative Timesteps: 951,396,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 951396856...
Checkpoint 951396856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,079.88665
Policy Entropy: 1.75879
Value Function Loss: 0.07270

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.55501
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 22,460.30333
Overall Steps per Second: 10,606.90695

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.71674

Cumulative Model Updates: 114,062
Cumulative Timesteps: 951,446,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,034.44518
Policy Entropy: 1.75894
Value Function Loss: 0.07021

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.59870
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 22,144.98511
Overall Steps per Second: 10,521.03145

Timestep Collection Time: 2.25893
Timestep Consumption Time: 2.49574
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.75467

Cumulative Model Updates: 114,068
Cumulative Timesteps: 951,496,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 951496910...
Checkpoint 951496910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,528.05787
Policy Entropy: 1.75218
Value Function Loss: 0.06807

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.59230
Value Function Update Magnitude: 0.60145

Collected Steps per Second: 22,343.14257
Overall Steps per Second: 10,581.68745

Timestep Collection Time: 2.23800
Timestep Consumption Time: 2.48752
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.72552

Cumulative Model Updates: 114,074
Cumulative Timesteps: 951,546,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,956.24233
Policy Entropy: 1.74318
Value Function Loss: 0.06949

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.15694
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.66828

Collected Steps per Second: 22,791.21899
Overall Steps per Second: 10,836.14766

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.61603

Cumulative Model Updates: 114,080
Cumulative Timesteps: 951,596,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 951596934...
Checkpoint 951596934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,740.58580
Policy Entropy: 1.74392
Value Function Loss: 0.06951

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.58444
Value Function Update Magnitude: 0.69062

Collected Steps per Second: 22,175.35489
Overall Steps per Second: 10,607.03625

Timestep Collection Time: 2.25611
Timestep Consumption Time: 2.46057
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.71668

Cumulative Model Updates: 114,086
Cumulative Timesteps: 951,646,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,282.39173
Policy Entropy: 1.74530
Value Function Loss: 0.06596

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.58920
Value Function Update Magnitude: 0.70519

Collected Steps per Second: 22,132.01021
Overall Steps per Second: 10,472.12453

Timestep Collection Time: 2.26053
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.77745

Cumulative Model Updates: 114,092
Cumulative Timesteps: 951,696,994

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 951696994...
Checkpoint 951696994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,138.07426
Policy Entropy: 1.73544
Value Function Loss: 0.06719

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.58728
Value Function Update Magnitude: 0.66901

Collected Steps per Second: 22,013.74636
Overall Steps per Second: 10,648.72122

Timestep Collection Time: 2.27203
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.69690

Cumulative Model Updates: 114,098
Cumulative Timesteps: 951,747,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,223.63585
Policy Entropy: 1.74768
Value Function Loss: 0.07322

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.59165
Value Function Update Magnitude: 0.55230

Collected Steps per Second: 22,291.10337
Overall Steps per Second: 10,577.76118

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.48415
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.72747

Cumulative Model Updates: 114,104
Cumulative Timesteps: 951,797,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 951797016...
Checkpoint 951797016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,548.26537
Policy Entropy: 1.73898
Value Function Loss: 0.07373

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.59939
Value Function Update Magnitude: 0.54363

Collected Steps per Second: 22,459.11306
Overall Steps per Second: 10,623.79570

Timestep Collection Time: 2.22751
Timestep Consumption Time: 2.48154
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70905

Cumulative Model Updates: 114,110
Cumulative Timesteps: 951,847,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,837.39930
Policy Entropy: 1.75361
Value Function Loss: 0.07781

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14884
Policy Update Magnitude: 0.59548
Value Function Update Magnitude: 0.55884

Collected Steps per Second: 22,310.14474
Overall Steps per Second: 10,706.84785

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67103

Cumulative Model Updates: 114,116
Cumulative Timesteps: 951,897,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 951897056...
Checkpoint 951897056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,690.20397
Policy Entropy: 1.75114
Value Function Loss: 0.07788

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.15080
Policy Update Magnitude: 0.60722
Value Function Update Magnitude: 0.65839

Collected Steps per Second: 22,098.39787
Overall Steps per Second: 10,656.86821

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.69331

Cumulative Model Updates: 114,122
Cumulative Timesteps: 951,947,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,623.65082
Policy Entropy: 1.76844
Value Function Loss: 0.07909

Mean KL Divergence: 0.01972
SB3 Clip Fraction: 0.17556
Policy Update Magnitude: 0.56355
Value Function Update Magnitude: 0.63772

Collected Steps per Second: 21,795.70667
Overall Steps per Second: 10,659.99441

Timestep Collection Time: 2.29467
Timestep Consumption Time: 2.39708
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.69175

Cumulative Model Updates: 114,128
Cumulative Timesteps: 951,997,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 951997086...
Checkpoint 951997086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,015.74469
Policy Entropy: 1.77962
Value Function Loss: 0.07652

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15384
Policy Update Magnitude: 0.55187
Value Function Update Magnitude: 0.61650

Collected Steps per Second: 21,706.98802
Overall Steps per Second: 10,599.52937

Timestep Collection Time: 2.30543
Timestep Consumption Time: 2.41591
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.72134

Cumulative Model Updates: 114,134
Cumulative Timesteps: 952,047,130

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,439.20793
Policy Entropy: 1.79029
Value Function Loss: 0.07155

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.71022

Collected Steps per Second: 21,654.30680
Overall Steps per Second: 10,719.47565

Timestep Collection Time: 2.31039
Timestep Consumption Time: 2.35681
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.66721

Cumulative Model Updates: 114,140
Cumulative Timesteps: 952,097,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952097160...
Checkpoint 952097160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,753.56898
Policy Entropy: 1.79379
Value Function Loss: 0.06926

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.14191
Policy Update Magnitude: 0.58725
Value Function Update Magnitude: 0.63179

Collected Steps per Second: 21,393.51635
Overall Steps per Second: 10,621.89074

Timestep Collection Time: 2.33781
Timestep Consumption Time: 2.37077
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70858

Cumulative Model Updates: 114,146
Cumulative Timesteps: 952,147,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,164.54788
Policy Entropy: 1.79117
Value Function Loss: 0.06638

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.15602
Policy Update Magnitude: 0.56353
Value Function Update Magnitude: 0.47618

Collected Steps per Second: 21,502.00355
Overall Steps per Second: 10,507.39340

Timestep Collection Time: 2.32602
Timestep Consumption Time: 2.43387
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.75989

Cumulative Model Updates: 114,152
Cumulative Timesteps: 952,197,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 952197188...
Checkpoint 952197188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,101.43682
Policy Entropy: 1.79201
Value Function Loss: 0.07149

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.16011
Policy Update Magnitude: 0.53157
Value Function Update Magnitude: 0.42232

Collected Steps per Second: 21,812.97616
Overall Steps per Second: 10,677.19222

Timestep Collection Time: 2.29359
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.68569

Cumulative Model Updates: 114,158
Cumulative Timesteps: 952,247,218

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,982.54852
Policy Entropy: 1.77764
Value Function Loss: 0.07575

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.16912
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.46846

Collected Steps per Second: 22,193.13619
Overall Steps per Second: 10,598.87837

Timestep Collection Time: 2.25385
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.71937

Cumulative Model Updates: 114,164
Cumulative Timesteps: 952,297,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 952297238...
Checkpoint 952297238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,398.75707
Policy Entropy: 1.78498
Value Function Loss: 0.07874

Mean KL Divergence: 0.01662
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.56647

Collected Steps per Second: 22,356.26323
Overall Steps per Second: 10,686.67519

Timestep Collection Time: 2.23678
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.67929

Cumulative Model Updates: 114,170
Cumulative Timesteps: 952,347,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,918.67974
Policy Entropy: 1.77229
Value Function Loss: 0.07207

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.14926
Policy Update Magnitude: 0.60020
Value Function Update Magnitude: 0.48812

Collected Steps per Second: 22,255.62899
Overall Steps per Second: 10,697.05341

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.67867

Cumulative Model Updates: 114,176
Cumulative Timesteps: 952,397,292

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 952397292...
Checkpoint 952397292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,698.22709
Policy Entropy: 1.77572
Value Function Loss: 0.06988

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.14958
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 22,081.31782
Overall Steps per Second: 10,680.22102

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.41835
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.68380

Cumulative Model Updates: 114,182
Cumulative Timesteps: 952,447,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,312.31057
Policy Entropy: 1.78300
Value Function Loss: 0.06971

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.15245
Policy Update Magnitude: 0.56288
Value Function Update Magnitude: 0.67511

Collected Steps per Second: 22,617.25689
Overall Steps per Second: 10,805.91460

Timestep Collection Time: 2.21185
Timestep Consumption Time: 2.41765
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.62950

Cumulative Model Updates: 114,188
Cumulative Timesteps: 952,497,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 952497342...
Checkpoint 952497342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,259.36940
Policy Entropy: 1.79416
Value Function Loss: 0.07015

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.55532
Value Function Update Magnitude: 0.61344

Collected Steps per Second: 22,183.99482
Overall Steps per Second: 10,666.50336

Timestep Collection Time: 2.25487
Timestep Consumption Time: 2.43477
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.68963

Cumulative Model Updates: 114,194
Cumulative Timesteps: 952,547,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,391.17562
Policy Entropy: 1.79852
Value Function Loss: 0.06913

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13881
Policy Update Magnitude: 0.55519
Value Function Update Magnitude: 0.65728

Collected Steps per Second: 22,274.96262
Overall Steps per Second: 10,528.07433

Timestep Collection Time: 2.24521
Timestep Consumption Time: 2.50514
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.75035

Cumulative Model Updates: 114,200
Cumulative Timesteps: 952,597,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 952597376...
Checkpoint 952597376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,347.71627
Policy Entropy: 1.78345
Value Function Loss: 0.07072

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.57564
Value Function Update Magnitude: 0.70641

Collected Steps per Second: 22,375.57327
Overall Steps per Second: 10,574.03856

Timestep Collection Time: 2.23628
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.73216

Cumulative Model Updates: 114,206
Cumulative Timesteps: 952,647,414

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,381.72477
Policy Entropy: 1.78949
Value Function Loss: 0.07331

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.59986
Value Function Update Magnitude: 0.74940

Collected Steps per Second: 22,386.77844
Overall Steps per Second: 10,553.18653

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.73961

Cumulative Model Updates: 114,212
Cumulative Timesteps: 952,697,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 952697432...
Checkpoint 952697432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,466.65941
Policy Entropy: 1.78919
Value Function Loss: 0.07317

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.60310
Value Function Update Magnitude: 0.75867

Collected Steps per Second: 22,327.91828
Overall Steps per Second: 10,490.49624

Timestep Collection Time: 2.24016
Timestep Consumption Time: 2.52778
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.76793

Cumulative Model Updates: 114,218
Cumulative Timesteps: 952,747,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,561.10384
Policy Entropy: 1.78733
Value Function Loss: 0.07184

Mean KL Divergence: 0.01532
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.64828

Collected Steps per Second: 22,152.26604
Overall Steps per Second: 10,486.92981

Timestep Collection Time: 2.25729
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.76822

Cumulative Model Updates: 114,224
Cumulative Timesteps: 952,797,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 952797454...
Checkpoint 952797454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,427.49995
Policy Entropy: 1.78653
Value Function Loss: 0.06983

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.15005
Policy Update Magnitude: 0.57852
Value Function Update Magnitude: 0.73570

Collected Steps per Second: 22,044.64623
Overall Steps per Second: 10,639.79467

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.70009

Cumulative Model Updates: 114,230
Cumulative Timesteps: 952,847,462

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,312.10071
Policy Entropy: 1.80000
Value Function Loss: 0.06676

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.14893
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.76065

Collected Steps per Second: 22,025.78874
Overall Steps per Second: 10,447.04961

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.51728
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.78853

Cumulative Model Updates: 114,236
Cumulative Timesteps: 952,897,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 952897488...
Checkpoint 952897488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,112.32556
Policy Entropy: 1.80028
Value Function Loss: 0.06256

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.14935
Policy Update Magnitude: 0.56635
Value Function Update Magnitude: 0.73688

Collected Steps per Second: 22,080.11753
Overall Steps per Second: 10,626.59234

Timestep Collection Time: 2.26448
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.70518

Cumulative Model Updates: 114,242
Cumulative Timesteps: 952,947,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,546.31037
Policy Entropy: 1.79241
Value Function Loss: 0.06799

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.70978

Collected Steps per Second: 22,293.10967
Overall Steps per Second: 9,741.85562

Timestep Collection Time: 2.24500
Timestep Consumption Time: 2.89242
PPO Batch Consumption Time: 0.35799
Total Iteration Time: 5.13742

Cumulative Model Updates: 114,248
Cumulative Timesteps: 952,997,536

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 952997536...
Checkpoint 952997536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,769.54518
Policy Entropy: 1.78782
Value Function Loss: 0.07347

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.14260
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.65323

Collected Steps per Second: 9,981.13083
Overall Steps per Second: 6,425.56719

Timestep Collection Time: 5.01146
Timestep Consumption Time: 2.77307
PPO Batch Consumption Time: 0.31124
Total Iteration Time: 7.78453

Cumulative Model Updates: 114,254
Cumulative Timesteps: 953,047,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,619.88205
Policy Entropy: 1.78821
Value Function Loss: 0.08081

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.58671
Value Function Update Magnitude: 0.51048

Collected Steps per Second: 20,184.21984
Overall Steps per Second: 10,082.71840

Timestep Collection Time: 2.47867
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.96196

Cumulative Model Updates: 114,260
Cumulative Timesteps: 953,097,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 953097586...
Checkpoint 953097586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,378.21825
Policy Entropy: 1.78794
Value Function Loss: 0.07772

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.59552
Value Function Update Magnitude: 0.45425

Collected Steps per Second: 21,495.35935
Overall Steps per Second: 10,313.86310

Timestep Collection Time: 2.32701
Timestep Consumption Time: 2.52277
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.84978

Cumulative Model Updates: 114,266
Cumulative Timesteps: 953,147,606

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,081.64278
Policy Entropy: 1.78359
Value Function Loss: 0.07310

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.59177
Value Function Update Magnitude: 0.55101

Collected Steps per Second: 20,634.62142
Overall Steps per Second: 10,459.36898

Timestep Collection Time: 2.42486
Timestep Consumption Time: 2.35899
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.78384

Cumulative Model Updates: 114,272
Cumulative Timesteps: 953,197,642

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 953197642...
Checkpoint 953197642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,403.19217
Policy Entropy: 1.78100
Value Function Loss: 0.06497

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14233
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.45471

Collected Steps per Second: 20,979.68537
Overall Steps per Second: 10,533.49822

Timestep Collection Time: 2.38402
Timestep Consumption Time: 2.36426
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.74828

Cumulative Model Updates: 114,278
Cumulative Timesteps: 953,247,658

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,861.48068
Policy Entropy: 1.78669
Value Function Loss: 0.06693

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.36946

Collected Steps per Second: 21,316.09232
Overall Steps per Second: 10,491.85828

Timestep Collection Time: 2.34715
Timestep Consumption Time: 2.42150
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.76865

Cumulative Model Updates: 114,284
Cumulative Timesteps: 953,297,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 953297690...
Checkpoint 953297690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,697.10233
Policy Entropy: 1.79742
Value Function Loss: 0.07039

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.15347
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.30964

Collected Steps per Second: 21,449.12355
Overall Steps per Second: 10,604.16425

Timestep Collection Time: 2.33156
Timestep Consumption Time: 2.38451
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.71607

Cumulative Model Updates: 114,290
Cumulative Timesteps: 953,347,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,176.07797
Policy Entropy: 1.78677
Value Function Loss: 0.07275

Mean KL Divergence: 0.01779
SB3 Clip Fraction: 0.16342
Policy Update Magnitude: 0.49413
Value Function Update Magnitude: 0.36506

Collected Steps per Second: 21,396.19814
Overall Steps per Second: 10,499.84716

Timestep Collection Time: 2.33855
Timestep Consumption Time: 2.42686
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.76540

Cumulative Model Updates: 114,296
Cumulative Timesteps: 953,397,736

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 953397736...
Checkpoint 953397736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,984.45136
Policy Entropy: 1.79122
Value Function Loss: 0.06651

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.14768
Policy Update Magnitude: 0.54800
Value Function Update Magnitude: 0.52725

Collected Steps per Second: 21,987.12718
Overall Steps per Second: 10,669.53179

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.41267
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.68718

Cumulative Model Updates: 114,302
Cumulative Timesteps: 953,447,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,831.97986
Policy Entropy: 1.78444
Value Function Loss: 0.06488

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.57204
Value Function Update Magnitude: 0.60961

Collected Steps per Second: 21,841.20884
Overall Steps per Second: 10,430.37824

Timestep Collection Time: 2.28980
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.79484

Cumulative Model Updates: 114,308
Cumulative Timesteps: 953,497,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 953497758...
Checkpoint 953497758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,755.32686
Policy Entropy: 1.78402
Value Function Loss: 0.06978

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.15126
Policy Update Magnitude: 0.58334
Value Function Update Magnitude: 0.65397

Collected Steps per Second: 21,866.70998
Overall Steps per Second: 10,632.65759

Timestep Collection Time: 2.28667
Timestep Consumption Time: 2.41601
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.70268

Cumulative Model Updates: 114,314
Cumulative Timesteps: 953,547,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,423.77603
Policy Entropy: 1.78666
Value Function Loss: 0.06942

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.59800
Value Function Update Magnitude: 0.69644

Collected Steps per Second: 21,818.33793
Overall Steps per Second: 10,473.60419

Timestep Collection Time: 2.29211
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.77486

Cumulative Model Updates: 114,320
Cumulative Timesteps: 953,597,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 953597770...
Checkpoint 953597770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,672.14022
Policy Entropy: 1.78579
Value Function Loss: 0.06826

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.59984
Value Function Update Magnitude: 0.59410

Collected Steps per Second: 21,500.47494
Overall Steps per Second: 10,369.94218

Timestep Collection Time: 2.32674
Timestep Consumption Time: 2.49740
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.82413

Cumulative Model Updates: 114,326
Cumulative Timesteps: 953,647,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,055.98754
Policy Entropy: 1.77364
Value Function Loss: 0.07073

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.59179
Value Function Update Magnitude: 0.48882

Collected Steps per Second: 21,087.98893
Overall Steps per Second: 10,264.28818

Timestep Collection Time: 2.37140
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.87204

Cumulative Model Updates: 114,332
Cumulative Timesteps: 953,697,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 953697804...
Checkpoint 953697804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,226.62188
Policy Entropy: 1.77885
Value Function Loss: 0.07012

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.13550
Policy Update Magnitude: 0.58840
Value Function Update Magnitude: 0.48574

Collected Steps per Second: 21,440.10999
Overall Steps per Second: 10,305.08220

Timestep Collection Time: 2.33422
Timestep Consumption Time: 2.52222
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.85644

Cumulative Model Updates: 114,338
Cumulative Timesteps: 953,747,850

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,888.37015
Policy Entropy: 1.77999
Value Function Loss: 0.06944

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 21,710.69415
Overall Steps per Second: 10,361.78611

Timestep Collection Time: 2.30301
Timestep Consumption Time: 2.52241
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.82542

Cumulative Model Updates: 114,344
Cumulative Timesteps: 953,797,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 953797850...
Checkpoint 953797850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,020.30079
Policy Entropy: 1.77896
Value Function Loss: 0.06711

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.61397

Collected Steps per Second: 21,660.89378
Overall Steps per Second: 10,572.61971

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.42108
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.72958

Cumulative Model Updates: 114,350
Cumulative Timesteps: 953,847,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,093.12421
Policy Entropy: 1.78443
Value Function Loss: 0.07189

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.58046
Value Function Update Magnitude: 0.56062

Collected Steps per Second: 21,937.75138
Overall Steps per Second: 10,562.53178

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.73580

Cumulative Model Updates: 114,356
Cumulative Timesteps: 953,897,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 953897876...
Checkpoint 953897876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,122.57234
Policy Entropy: 1.79551
Value Function Loss: 0.07444

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.15799
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.54775

Collected Steps per Second: 22,224.97318
Overall Steps per Second: 10,645.96723

Timestep Collection Time: 2.25053
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.69830

Cumulative Model Updates: 114,362
Cumulative Timesteps: 953,947,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,388.13284
Policy Entropy: 1.80450
Value Function Loss: 0.07285

Mean KL Divergence: 0.02214
SB3 Clip Fraction: 0.18845
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.54781

Collected Steps per Second: 21,840.39384
Overall Steps per Second: 10,409.24541

Timestep Collection Time: 2.28970
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.80419

Cumulative Model Updates: 114,368
Cumulative Timesteps: 953,997,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 953997902...
Checkpoint 953997902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,609.07147
Policy Entropy: 1.80601
Value Function Loss: 0.07410

Mean KL Divergence: 0.01833
SB3 Clip Fraction: 0.16944
Policy Update Magnitude: 0.56404
Value Function Update Magnitude: 0.61385

Collected Steps per Second: 22,064.01129
Overall Steps per Second: 10,634.95722

Timestep Collection Time: 2.26849
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.70637

Cumulative Model Updates: 114,374
Cumulative Timesteps: 954,047,954

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,819.09078
Policy Entropy: 1.79700
Value Function Loss: 0.06760

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.17170
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.63671

Collected Steps per Second: 22,118.03351
Overall Steps per Second: 10,445.79520

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.78661

Cumulative Model Updates: 114,380
Cumulative Timesteps: 954,097,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 954097954...
Checkpoint 954097954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,010.83062
Policy Entropy: 1.79348
Value Function Loss: 0.06713

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.16038
Policy Update Magnitude: 0.55690
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 21,975.89365
Overall Steps per Second: 10,575.90694

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.45329
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.72924

Cumulative Model Updates: 114,386
Cumulative Timesteps: 954,147,970

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,003.52775
Policy Entropy: 1.77854
Value Function Loss: 0.07117

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.16621
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.58660

Collected Steps per Second: 22,040.31794
Overall Steps per Second: 10,546.22787

Timestep Collection Time: 2.27002
Timestep Consumption Time: 2.47404
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.74407

Cumulative Model Updates: 114,392
Cumulative Timesteps: 954,198,002

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 954198002...
Checkpoint 954198002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,054.46044
Policy Entropy: 1.77380
Value Function Loss: 0.07579

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.17576
Policy Update Magnitude: 0.49582
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 21,503.17071
Overall Steps per Second: 10,367.34774

Timestep Collection Time: 2.32542
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.82322

Cumulative Model Updates: 114,398
Cumulative Timesteps: 954,248,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,495.26459
Policy Entropy: 1.77270
Value Function Loss: 0.07233

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17214
Policy Update Magnitude: 0.47594
Value Function Update Magnitude: 0.45985

Collected Steps per Second: 21,525.33477
Overall Steps per Second: 10,315.50856

Timestep Collection Time: 2.32322
Timestep Consumption Time: 2.52463
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.84785

Cumulative Model Updates: 114,404
Cumulative Timesteps: 954,298,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 954298014...
Checkpoint 954298014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,509.60147
Policy Entropy: 1.77424
Value Function Loss: 0.06974

Mean KL Divergence: 0.01691
SB3 Clip Fraction: 0.16151
Policy Update Magnitude: 0.48186
Value Function Update Magnitude: 0.44781

Collected Steps per Second: 20,972.33776
Overall Steps per Second: 10,192.75033

Timestep Collection Time: 2.38495
Timestep Consumption Time: 2.52226
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.90721

Cumulative Model Updates: 114,410
Cumulative Timesteps: 954,348,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,819.46991
Policy Entropy: 1.77537
Value Function Loss: 0.07210

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.14588
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.52170

Collected Steps per Second: 21,481.32477
Overall Steps per Second: 10,511.73455

Timestep Collection Time: 2.32788
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.75716

Cumulative Model Updates: 114,416
Cumulative Timesteps: 954,398,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 954398038...
Checkpoint 954398038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,900.61865
Policy Entropy: 1.77340
Value Function Loss: 0.07449

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.58658

Collected Steps per Second: 21,582.59415
Overall Steps per Second: 10,510.10104

Timestep Collection Time: 2.31798
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.75999

Cumulative Model Updates: 114,422
Cumulative Timesteps: 954,448,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,877.74156
Policy Entropy: 1.77084
Value Function Loss: 0.07852

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.17487
Policy Update Magnitude: 0.51514
Value Function Update Magnitude: 0.57240

Collected Steps per Second: 21,782.97163
Overall Steps per Second: 10,482.76681

Timestep Collection Time: 2.29638
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.77183

Cumulative Model Updates: 114,428
Cumulative Timesteps: 954,498,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 954498088...
Checkpoint 954498088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,271.12486
Policy Entropy: 1.78394
Value Function Loss: 0.08116

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.16492
Policy Update Magnitude: 0.53996
Value Function Update Magnitude: 0.67107

Collected Steps per Second: 21,775.70950
Overall Steps per Second: 10,600.64807

Timestep Collection Time: 2.29687
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.71820

Cumulative Model Updates: 114,434
Cumulative Timesteps: 954,548,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,961.22448
Policy Entropy: 1.79318
Value Function Loss: 0.07853

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.18456
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.62322

Collected Steps per Second: 22,056.17678
Overall Steps per Second: 10,516.83849

Timestep Collection Time: 2.26721
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.75485

Cumulative Model Updates: 114,440
Cumulative Timesteps: 954,598,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 954598110...
Checkpoint 954598110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,475.74922
Policy Entropy: 1.79102
Value Function Loss: 0.07451

Mean KL Divergence: 0.02072
SB3 Clip Fraction: 0.17665
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.54038

Collected Steps per Second: 21,886.48955
Overall Steps per Second: 10,578.10783

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.72844

Cumulative Model Updates: 114,446
Cumulative Timesteps: 954,648,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,795.51491
Policy Entropy: 1.80411
Value Function Loss: 0.06900

Mean KL Divergence: 0.01871
SB3 Clip Fraction: 0.17412
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.44224

Collected Steps per Second: 22,292.69145
Overall Steps per Second: 10,507.15464

Timestep Collection Time: 2.24378
Timestep Consumption Time: 2.51678
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.76057

Cumulative Model Updates: 114,452
Cumulative Timesteps: 954,698,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 954698148...
Checkpoint 954698148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,036.51185
Policy Entropy: 1.79891
Value Function Loss: 0.07042

Mean KL Divergence: 0.01913
SB3 Clip Fraction: 0.17274
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.48275

Collected Steps per Second: 21,894.19888
Overall Steps per Second: 10,586.10507

Timestep Collection Time: 2.28417
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.72412

Cumulative Model Updates: 114,458
Cumulative Timesteps: 954,748,158

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,794.89601
Policy Entropy: 1.80711
Value Function Loss: 0.06967

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.18251
Policy Update Magnitude: 0.53292
Value Function Update Magnitude: 0.52176

Collected Steps per Second: 21,773.49453
Overall Steps per Second: 10,597.26907

Timestep Collection Time: 2.29701
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.71952

Cumulative Model Updates: 114,464
Cumulative Timesteps: 954,798,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 954798172...
Checkpoint 954798172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,170.10917
Policy Entropy: 1.80988
Value Function Loss: 0.06911

Mean KL Divergence: 0.01689
SB3 Clip Fraction: 0.16669
Policy Update Magnitude: 0.52416
Value Function Update Magnitude: 0.57326

Collected Steps per Second: 20,947.01721
Overall Steps per Second: 10,538.94946

Timestep Collection Time: 2.38831
Timestep Consumption Time: 2.35865
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.74696

Cumulative Model Updates: 114,470
Cumulative Timesteps: 954,848,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,962.07642
Policy Entropy: 1.80265
Value Function Loss: 0.06902

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.16716
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.61824

Collected Steps per Second: 21,042.18690
Overall Steps per Second: 10,424.78378

Timestep Collection Time: 2.37703
Timestep Consumption Time: 2.42095
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.79799

Cumulative Model Updates: 114,476
Cumulative Timesteps: 954,898,218

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 954898218...
Checkpoint 954898218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,937.04140
Policy Entropy: 1.78652
Value Function Loss: 0.06738

Mean KL Divergence: 0.01639
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.55708
Value Function Update Magnitude: 0.57391

Collected Steps per Second: 20,548.20943
Overall Steps per Second: 10,279.43726

Timestep Collection Time: 2.43408
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.86564

Cumulative Model Updates: 114,482
Cumulative Timesteps: 954,948,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,081.52543
Policy Entropy: 1.77646
Value Function Loss: 0.06741

Mean KL Divergence: 0.01732
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.54489

Collected Steps per Second: 21,173.29266
Overall Steps per Second: 10,490.18979

Timestep Collection Time: 2.36373
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.77093

Cumulative Model Updates: 114,488
Cumulative Timesteps: 954,998,282

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 954998282...
Checkpoint 954998282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,439.01527
Policy Entropy: 1.76147
Value Function Loss: 0.06633

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.15647
Policy Update Magnitude: 0.54449
Value Function Update Magnitude: 0.49808

Collected Steps per Second: 21,100.81797
Overall Steps per Second: 10,322.21161

Timestep Collection Time: 2.37062
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.84605

Cumulative Model Updates: 114,494
Cumulative Timesteps: 955,048,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,058.94846
Policy Entropy: 1.77372
Value Function Loss: 0.06837

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.54266
Value Function Update Magnitude: 0.41988

Collected Steps per Second: 22,027.11350
Overall Steps per Second: 10,680.46847

Timestep Collection Time: 2.27120
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.68406

Cumulative Model Updates: 114,500
Cumulative Timesteps: 955,098,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 955098332...
Checkpoint 955098332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,476.05988
Policy Entropy: 1.77549
Value Function Loss: 0.06721

Mean KL Divergence: 0.01578
SB3 Clip Fraction: 0.15514
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.52674

Collected Steps per Second: 21,835.98388
Overall Steps per Second: 10,605.01939

Timestep Collection Time: 2.29044
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.71607

Cumulative Model Updates: 114,506
Cumulative Timesteps: 955,148,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,136.51265
Policy Entropy: 1.77696
Value Function Loss: 0.06597

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.67153

Collected Steps per Second: 21,714.47934
Overall Steps per Second: 10,516.50583

Timestep Collection Time: 2.30372
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.75671

Cumulative Model Updates: 114,512
Cumulative Timesteps: 955,198,370

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 955198370...
Checkpoint 955198370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,077.44538
Policy Entropy: 1.78320
Value Function Loss: 0.06707

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.14878
Policy Update Magnitude: 0.57746
Value Function Update Magnitude: 0.65012

Collected Steps per Second: 21,829.92157
Overall Steps per Second: 10,579.65088

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.43591
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.72662

Cumulative Model Updates: 114,518
Cumulative Timesteps: 955,248,376

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,530.06664
Policy Entropy: 1.80280
Value Function Loss: 0.06684

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.14368
Policy Update Magnitude: 0.58577
Value Function Update Magnitude: 0.68640

Collected Steps per Second: 22,109.36482
Overall Steps per Second: 10,532.71033

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.74731

Cumulative Model Updates: 114,524
Cumulative Timesteps: 955,298,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 955298378...
Checkpoint 955298378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,121.61413
Policy Entropy: 1.81418
Value Function Loss: 0.06380

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.69343

Collected Steps per Second: 21,271.98289
Overall Steps per Second: 10,282.97408

Timestep Collection Time: 2.35051
Timestep Consumption Time: 2.51190
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.86241

Cumulative Model Updates: 114,530
Cumulative Timesteps: 955,348,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,619.61596
Policy Entropy: 1.81003
Value Function Loss: 0.06933

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.14627
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 21,802.85103
Overall Steps per Second: 10,373.25965

Timestep Collection Time: 2.29456
Timestep Consumption Time: 2.52822
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.82278

Cumulative Model Updates: 114,536
Cumulative Timesteps: 955,398,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 955398406...
Checkpoint 955398406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,575.18587
Policy Entropy: 1.79248
Value Function Loss: 0.06782

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.57981
Value Function Update Magnitude: 0.62448

Collected Steps per Second: 21,497.52909
Overall Steps per Second: 10,350.21590

Timestep Collection Time: 2.32641
Timestep Consumption Time: 2.50557
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.83198

Cumulative Model Updates: 114,542
Cumulative Timesteps: 955,448,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,200.92904
Policy Entropy: 1.78908
Value Function Loss: 0.06575

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.61958

Collected Steps per Second: 21,639.63421
Overall Steps per Second: 10,360.61188

Timestep Collection Time: 2.31178
Timestep Consumption Time: 2.51670
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.82848

Cumulative Model Updates: 114,548
Cumulative Timesteps: 955,498,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 955498444...
Checkpoint 955498444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,497.41134
Policy Entropy: 1.79552
Value Function Loss: 0.06145

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.14037
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.54348

Collected Steps per Second: 21,437.89734
Overall Steps per Second: 10,346.34014

Timestep Collection Time: 2.33344
Timestep Consumption Time: 2.50151
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.83495

Cumulative Model Updates: 114,554
Cumulative Timesteps: 955,548,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,340.28650
Policy Entropy: 1.79156
Value Function Loss: 0.06350

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14158
Policy Update Magnitude: 0.56746
Value Function Update Magnitude: 0.48467

Collected Steps per Second: 22,028.94395
Overall Steps per Second: 10,465.05456

Timestep Collection Time: 2.27083
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.78010

Cumulative Model Updates: 114,560
Cumulative Timesteps: 955,598,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 955598492...
Checkpoint 955598492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,337.60332
Policy Entropy: 1.79788
Value Function Loss: 0.06359

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.57316
Value Function Update Magnitude: 0.43857

Collected Steps per Second: 21,775.07463
Overall Steps per Second: 10,495.41796

Timestep Collection Time: 2.29776
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.76722

Cumulative Model Updates: 114,566
Cumulative Timesteps: 955,648,526

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,678.74961
Policy Entropy: 1.79616
Value Function Loss: 0.06329

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.50930

Collected Steps per Second: 21,648.03175
Overall Steps per Second: 10,392.67518

Timestep Collection Time: 2.30968
Timestep Consumption Time: 2.50140
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.81108

Cumulative Model Updates: 114,572
Cumulative Timesteps: 955,698,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 955698526...
Checkpoint 955698526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,324.46209
Policy Entropy: 1.79561
Value Function Loss: 0.06631

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.54216

Collected Steps per Second: 21,856.47691
Overall Steps per Second: 10,578.27315

Timestep Collection Time: 2.28765
Timestep Consumption Time: 2.43902
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.72667

Cumulative Model Updates: 114,578
Cumulative Timesteps: 955,748,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,849.54420
Policy Entropy: 1.79906
Value Function Loss: 0.07089

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.16246
Policy Update Magnitude: 0.52430
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 21,384.62679
Overall Steps per Second: 10,510.51499

Timestep Collection Time: 2.33832
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.75752

Cumulative Model Updates: 114,584
Cumulative Timesteps: 955,798,530

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 955798530...
Checkpoint 955798530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,554.87100
Policy Entropy: 1.79349
Value Function Loss: 0.06749

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.15681
Policy Update Magnitude: 0.49811
Value Function Update Magnitude: 0.72676

Collected Steps per Second: 21,323.97112
Overall Steps per Second: 10,624.76489

Timestep Collection Time: 2.34600
Timestep Consumption Time: 2.36244
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.70843

Cumulative Model Updates: 114,590
Cumulative Timesteps: 955,848,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,312.05684
Policy Entropy: 1.79300
Value Function Loss: 0.06046

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.50808
Value Function Update Magnitude: 0.71770

Collected Steps per Second: 20,741.96523
Overall Steps per Second: 10,450.71650

Timestep Collection Time: 2.41154
Timestep Consumption Time: 2.37474
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.78627

Cumulative Model Updates: 114,596
Cumulative Timesteps: 955,898,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 955898576...
Checkpoint 955898576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,911.91818
Policy Entropy: 1.78177
Value Function Loss: 0.05974

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.60090

Collected Steps per Second: 21,424.21199
Overall Steps per Second: 10,414.35678

Timestep Collection Time: 2.33483
Timestep Consumption Time: 2.46834
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.80318

Cumulative Model Updates: 114,602
Cumulative Timesteps: 955,948,598

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,584.31980
Policy Entropy: 1.77734
Value Function Loss: 0.06541

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.17453
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.48997

Collected Steps per Second: 21,644.03505
Overall Steps per Second: 10,445.66441

Timestep Collection Time: 2.31020
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.78687

Cumulative Model Updates: 114,608
Cumulative Timesteps: 955,998,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 955998600...
Checkpoint 955998600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,747.91111
Policy Entropy: 1.78096
Value Function Loss: 0.07049

Mean KL Divergence: 0.01955
SB3 Clip Fraction: 0.17937
Policy Update Magnitude: 0.47644
Value Function Update Magnitude: 0.57105

Collected Steps per Second: 21,446.81777
Overall Steps per Second: 10,491.90984

Timestep Collection Time: 2.33135
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.76558

Cumulative Model Updates: 114,614
Cumulative Timesteps: 956,048,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,330.41251
Policy Entropy: 1.78216
Value Function Loss: 0.07473

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.50398
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 21,604.32639
Overall Steps per Second: 10,412.09693

Timestep Collection Time: 2.31528
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.80403

Cumulative Model Updates: 114,620
Cumulative Timesteps: 956,098,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956098620...
Checkpoint 956098620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,266.93852
Policy Entropy: 1.78456
Value Function Loss: 0.07448

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.53324

Collected Steps per Second: 21,455.10759
Overall Steps per Second: 10,336.63630

Timestep Collection Time: 2.33194
Timestep Consumption Time: 2.50832
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.84026

Cumulative Model Updates: 114,626
Cumulative Timesteps: 956,148,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,395.68387
Policy Entropy: 1.78304
Value Function Loss: 0.07287

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.15293
Policy Update Magnitude: 0.57234
Value Function Update Magnitude: 0.55971

Collected Steps per Second: 22,016.85095
Overall Steps per Second: 10,416.17795

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.53025
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.80215

Cumulative Model Updates: 114,632
Cumulative Timesteps: 956,198,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956198672...
Checkpoint 956198672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,621.94102
Policy Entropy: 1.79546
Value Function Loss: 0.06489

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.65879

Collected Steps per Second: 21,794.20349
Overall Steps per Second: 10,559.57759

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.73617

Cumulative Model Updates: 114,638
Cumulative Timesteps: 956,248,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,424.57959
Policy Entropy: 1.79209
Value Function Loss: 0.06498

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.57491
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 21,855.22604
Overall Steps per Second: 10,460.81137

Timestep Collection Time: 2.28833
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.78089

Cumulative Model Updates: 114,644
Cumulative Timesteps: 956,298,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 956298696...
Checkpoint 956298696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,330.18405
Policy Entropy: 1.78941
Value Function Loss: 0.07190

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.58638
Value Function Update Magnitude: 0.54992

Collected Steps per Second: 21,750.94309
Overall Steps per Second: 10,539.11338

Timestep Collection Time: 2.29875
Timestep Consumption Time: 2.44548
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.74423

Cumulative Model Updates: 114,650
Cumulative Timesteps: 956,348,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,360.29454
Policy Entropy: 1.78367
Value Function Loss: 0.07195

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.59017
Value Function Update Magnitude: 0.54641

Collected Steps per Second: 21,793.68370
Overall Steps per Second: 10,545.90237

Timestep Collection Time: 2.29489
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.74251

Cumulative Model Updates: 114,656
Cumulative Timesteps: 956,398,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 956398710...
Checkpoint 956398710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,875.01720
Policy Entropy: 1.78916
Value Function Loss: 0.07031

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.63209

Collected Steps per Second: 22,014.53649
Overall Steps per Second: 10,617.07442

Timestep Collection Time: 2.27223
Timestep Consumption Time: 2.43924
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.71147

Cumulative Model Updates: 114,662
Cumulative Timesteps: 956,448,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,538.41307
Policy Entropy: 1.76832
Value Function Loss: 0.06855

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.57245
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 21,632.94197
Overall Steps per Second: 10,500.61056

Timestep Collection Time: 2.31203
Timestep Consumption Time: 2.45112
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.76315

Cumulative Model Updates: 114,668
Cumulative Timesteps: 956,498,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 956498748...
Checkpoint 956498748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,360.74966
Policy Entropy: 1.77645
Value Function Loss: 0.06793

Mean KL Divergence: 0.01473
SB3 Clip Fraction: 0.14913
Policy Update Magnitude: 0.57564
Value Function Update Magnitude: 0.60366

Collected Steps per Second: 21,509.41665
Overall Steps per Second: 10,532.79630

Timestep Collection Time: 2.32549
Timestep Consumption Time: 2.42348
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.74898

Cumulative Model Updates: 114,674
Cumulative Timesteps: 956,548,768

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,116.43797
Policy Entropy: 1.75214
Value Function Loss: 0.06312

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.63955

Collected Steps per Second: 22,026.27067
Overall Steps per Second: 10,624.65957

Timestep Collection Time: 2.27038
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.70679

Cumulative Model Updates: 114,680
Cumulative Timesteps: 956,598,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 956598776...
Checkpoint 956598776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,979.43875
Policy Entropy: 1.75353
Value Function Loss: 0.06444

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.14994
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.68203

Collected Steps per Second: 21,558.86780
Overall Steps per Second: 10,494.16567

Timestep Collection Time: 2.31970
Timestep Consumption Time: 2.44581
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.76551

Cumulative Model Updates: 114,686
Cumulative Timesteps: 956,648,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,324.71139
Policy Entropy: 1.74319
Value Function Loss: 0.06510

Mean KL Divergence: 0.02016
SB3 Clip Fraction: 0.17823
Policy Update Magnitude: 0.51345
Value Function Update Magnitude: 0.69552

Collected Steps per Second: 21,547.87771
Overall Steps per Second: 10,465.63364

Timestep Collection Time: 2.32079
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.77831

Cumulative Model Updates: 114,692
Cumulative Timesteps: 956,698,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 956698794...
Checkpoint 956698794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,769.38303
Policy Entropy: 1.75749
Value Function Loss: 0.07100

Mean KL Divergence: 0.01992
SB3 Clip Fraction: 0.17404
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.71000

Collected Steps per Second: 21,442.20080
Overall Steps per Second: 10,304.31889

Timestep Collection Time: 2.33325
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.85525

Cumulative Model Updates: 114,698
Cumulative Timesteps: 956,748,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,616.61327
Policy Entropy: 1.76277
Value Function Loss: 0.07217

Mean KL Divergence: 0.01982
SB3 Clip Fraction: 0.17247
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.73783

Collected Steps per Second: 21,323.42049
Overall Steps per Second: 10,352.50807

Timestep Collection Time: 2.34578
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.83168

Cumulative Model Updates: 114,704
Cumulative Timesteps: 956,798,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956798844...
Checkpoint 956798844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,163.51853
Policy Entropy: 1.76286
Value Function Loss: 0.07584

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.17624
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.69527

Collected Steps per Second: 21,813.85427
Overall Steps per Second: 10,450.65590

Timestep Collection Time: 2.29212
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.78439

Cumulative Model Updates: 114,710
Cumulative Timesteps: 956,848,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,326.34200
Policy Entropy: 1.75262
Value Function Loss: 0.07483

Mean KL Divergence: 0.01978
SB3 Clip Fraction: 0.17634
Policy Update Magnitude: 0.51599
Value Function Update Magnitude: 0.62678

Collected Steps per Second: 22,460.28891
Overall Steps per Second: 10,715.28949

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.66810

Cumulative Model Updates: 114,716
Cumulative Timesteps: 956,898,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 956898864...
Checkpoint 956898864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,949.08379
Policy Entropy: 1.74855
Value Function Loss: 0.07632

Mean KL Divergence: 0.01854
SB3 Clip Fraction: 0.17278
Policy Update Magnitude: 0.49259
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 21,474.85856
Overall Steps per Second: 10,313.99661

Timestep Collection Time: 2.32905
Timestep Consumption Time: 2.52028
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.84933

Cumulative Model Updates: 114,722
Cumulative Timesteps: 956,948,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,049.26091
Policy Entropy: 1.73617
Value Function Loss: 0.06603

Mean KL Divergence: 0.01841
SB3 Clip Fraction: 0.16938
Policy Update Magnitude: 0.49736
Value Function Update Magnitude: 0.58734

Collected Steps per Second: 22,017.10575
Overall Steps per Second: 10,545.15812

Timestep Collection Time: 2.27232
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.74436

Cumulative Model Updates: 114,728
Cumulative Timesteps: 956,998,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 956998910...
Checkpoint 956998910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,559.59785
Policy Entropy: 1.73958
Value Function Loss: 0.06333

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.45042

Collected Steps per Second: 22,215.19304
Overall Steps per Second: 10,550.92085

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.74139

Cumulative Model Updates: 114,734
Cumulative Timesteps: 957,048,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,773.76017
Policy Entropy: 1.73401
Value Function Loss: 0.06138

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13838
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.37165

Collected Steps per Second: 21,513.24940
Overall Steps per Second: 10,539.25481

Timestep Collection Time: 2.32452
Timestep Consumption Time: 2.42041
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.74493

Cumulative Model Updates: 114,740
Cumulative Timesteps: 957,098,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 957098944...
Checkpoint 957098944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,986.33280
Policy Entropy: 1.73126
Value Function Loss: 0.06861

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.44085

Collected Steps per Second: 21,021.97566
Overall Steps per Second: 10,461.19169

Timestep Collection Time: 2.38065
Timestep Consumption Time: 2.40332
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.78397

Cumulative Model Updates: 114,746
Cumulative Timesteps: 957,148,990

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,488.98266
Policy Entropy: 1.72264
Value Function Loss: 0.06948

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.55703

Collected Steps per Second: 21,338.52790
Overall Steps per Second: 10,451.47724

Timestep Collection Time: 2.34440
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.78650

Cumulative Model Updates: 114,752
Cumulative Timesteps: 957,199,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 957199016...
Checkpoint 957199016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,635.07004
Policy Entropy: 1.72591
Value Function Loss: 0.07077

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.59369
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 20,871.65791
Overall Steps per Second: 10,388.35166

Timestep Collection Time: 2.39674
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.81539

Cumulative Model Updates: 114,758
Cumulative Timesteps: 957,249,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,725.72452
Policy Entropy: 1.72387
Value Function Loss: 0.07070

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.58273
Value Function Update Magnitude: 0.55373

Collected Steps per Second: 21,372.90499
Overall Steps per Second: 10,333.74237

Timestep Collection Time: 2.34091
Timestep Consumption Time: 2.50071
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.84161

Cumulative Model Updates: 114,764
Cumulative Timesteps: 957,299,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 957299072...
Checkpoint 957299072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,952.72457
Policy Entropy: 1.72960
Value Function Loss: 0.06966

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.57732

Collected Steps per Second: 21,689.73845
Overall Steps per Second: 10,610.59603

Timestep Collection Time: 2.30551
Timestep Consumption Time: 2.40732
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.71284

Cumulative Model Updates: 114,770
Cumulative Timesteps: 957,349,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,600.15720
Policy Entropy: 1.72804
Value Function Loss: 0.07006

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.14671
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.53252

Collected Steps per Second: 22,220.72274
Overall Steps per Second: 10,505.25792

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.76162

Cumulative Model Updates: 114,776
Cumulative Timesteps: 957,399,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 957399100...
Checkpoint 957399100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,070.17111
Policy Entropy: 1.72658
Value Function Loss: 0.06953

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.59269
Value Function Update Magnitude: 0.56410

Collected Steps per Second: 21,714.63624
Overall Steps per Second: 10,623.41361

Timestep Collection Time: 2.30480
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.71110

Cumulative Model Updates: 114,782
Cumulative Timesteps: 957,449,148

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,888.61884
Policy Entropy: 1.71991
Value Function Loss: 0.06629

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.58551
Value Function Update Magnitude: 0.63837

Collected Steps per Second: 22,275.90565
Overall Steps per Second: 10,544.30900

Timestep Collection Time: 2.24539
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.74360

Cumulative Model Updates: 114,788
Cumulative Timesteps: 957,499,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 957499166...
Checkpoint 957499166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,995.76696
Policy Entropy: 1.70511
Value Function Loss: 0.06634

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.58661
Value Function Update Magnitude: 0.65080

Collected Steps per Second: 21,913.40892
Overall Steps per Second: 10,452.05646

Timestep Collection Time: 2.28280
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.78604

Cumulative Model Updates: 114,794
Cumulative Timesteps: 957,549,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,929.31737
Policy Entropy: 1.71252
Value Function Loss: 0.06914

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.68920

Collected Steps per Second: 22,035.44856
Overall Steps per Second: 10,462.29793

Timestep Collection Time: 2.26962
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.78021

Cumulative Model Updates: 114,800
Cumulative Timesteps: 957,599,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 957599202...
Checkpoint 957599202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,037.80094
Policy Entropy: 1.72352
Value Function Loss: 0.07455

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.15430
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.67396

Collected Steps per Second: 21,489.43888
Overall Steps per Second: 10,421.73195

Timestep Collection Time: 2.32738
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.79901

Cumulative Model Updates: 114,806
Cumulative Timesteps: 957,649,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,925.27508
Policy Entropy: 1.74022
Value Function Loss: 0.07428

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.16141
Policy Update Magnitude: 0.59061
Value Function Update Magnitude: 0.67333

Collected Steps per Second: 22,411.99445
Overall Steps per Second: 10,696.84704

Timestep Collection Time: 2.23175
Timestep Consumption Time: 2.44421
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.67596

Cumulative Model Updates: 114,812
Cumulative Timesteps: 957,699,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 957699234...
Checkpoint 957699234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,151.43312
Policy Entropy: 1.74446
Value Function Loss: 0.07510

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.18508
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.72532

Collected Steps per Second: 21,211.56946
Overall Steps per Second: 10,360.41856

Timestep Collection Time: 2.35777
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.82722

Cumulative Model Updates: 114,818
Cumulative Timesteps: 957,749,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,703.70246
Policy Entropy: 1.74502
Value Function Loss: 0.06613

Mean KL Divergence: 0.02037
SB3 Clip Fraction: 0.17628
Policy Update Magnitude: 0.48172
Value Function Update Magnitude: 0.73308

Collected Steps per Second: 22,067.10673
Overall Steps per Second: 10,504.48624

Timestep Collection Time: 2.26681
Timestep Consumption Time: 2.49515
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.76197

Cumulative Model Updates: 114,824
Cumulative Timesteps: 957,799,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 957799268...
Checkpoint 957799268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,442.64335
Policy Entropy: 1.73687
Value Function Loss: 0.06571

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14139
Policy Update Magnitude: 0.52355
Value Function Update Magnitude: 0.66171

Collected Steps per Second: 21,736.71600
Overall Steps per Second: 10,463.05500

Timestep Collection Time: 2.30228
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.78292

Cumulative Model Updates: 114,830
Cumulative Timesteps: 957,849,312

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,757.70546
Policy Entropy: 1.73188
Value Function Loss: 0.06410

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.57674

Collected Steps per Second: 21,999.34835
Overall Steps per Second: 10,417.77880

Timestep Collection Time: 2.27361
Timestep Consumption Time: 2.52760
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.80122

Cumulative Model Updates: 114,836
Cumulative Timesteps: 957,899,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 957899330...
Checkpoint 957899330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,620.48948
Policy Entropy: 1.72043
Value Function Loss: 0.06665

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.57601
Value Function Update Magnitude: 0.57501

Collected Steps per Second: 21,848.36924
Overall Steps per Second: 10,377.15719

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.53048
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.81962

Cumulative Model Updates: 114,842
Cumulative Timesteps: 957,949,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,772.63847
Policy Entropy: 1.72430
Value Function Loss: 0.06729

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.58215

Collected Steps per Second: 22,273.20988
Overall Steps per Second: 10,662.54658

Timestep Collection Time: 2.24512
Timestep Consumption Time: 2.44476
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.68987

Cumulative Model Updates: 114,848
Cumulative Timesteps: 957,999,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 957999350...
Checkpoint 957999350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,132.71109
Policy Entropy: 1.71075
Value Function Loss: 0.06235

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.58335
Value Function Update Magnitude: 0.54082

Collected Steps per Second: 21,853.44450
Overall Steps per Second: 10,611.39071

Timestep Collection Time: 2.28925
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.71456

Cumulative Model Updates: 114,854
Cumulative Timesteps: 958,049,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,876.63478
Policy Entropy: 1.70663
Value Function Loss: 0.06591

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14057
Policy Update Magnitude: 0.57767
Value Function Update Magnitude: 0.50557

Collected Steps per Second: 22,333.73012
Overall Steps per Second: 10,531.89014

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74901

Cumulative Model Updates: 114,860
Cumulative Timesteps: 958,099,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 958099394...
Checkpoint 958099394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,994.40943
Policy Entropy: 1.71205
Value Function Loss: 0.06315

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.50128

Collected Steps per Second: 21,791.06711
Overall Steps per Second: 10,549.18362

Timestep Collection Time: 2.29498
Timestep Consumption Time: 2.44567
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.74065

Cumulative Model Updates: 114,866
Cumulative Timesteps: 958,149,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,748.87108
Policy Entropy: 1.72028
Value Function Loss: 0.06678

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.50217

Collected Steps per Second: 22,247.40227
Overall Steps per Second: 10,566.82659

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.48463
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.73236

Cumulative Model Updates: 114,872
Cumulative Timesteps: 958,199,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 958199410...
Checkpoint 958199410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,388.49308
Policy Entropy: 1.71468
Value Function Loss: 0.06473

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.58675
Value Function Update Magnitude: 0.55273

Collected Steps per Second: 21,970.22656
Overall Steps per Second: 10,461.08807

Timestep Collection Time: 2.27663
Timestep Consumption Time: 2.50471
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.78134

Cumulative Model Updates: 114,878
Cumulative Timesteps: 958,249,428

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,901.27386
Policy Entropy: 1.71098
Value Function Loss: 0.06581

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.14589
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.46027

Collected Steps per Second: 21,038.96836
Overall Steps per Second: 10,193.58706

Timestep Collection Time: 2.37749
Timestep Consumption Time: 2.52951
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.90701

Cumulative Model Updates: 114,884
Cumulative Timesteps: 958,299,448

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 958299448...
Checkpoint 958299448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,552.32377
Policy Entropy: 1.71434
Value Function Loss: 0.07063

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14474
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.40001

Collected Steps per Second: 21,470.45396
Overall Steps per Second: 10,566.53484

Timestep Collection Time: 2.32971
Timestep Consumption Time: 2.40410
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.73381

Cumulative Model Updates: 114,890
Cumulative Timesteps: 958,349,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,860.17663
Policy Entropy: 1.71655
Value Function Loss: 0.07448

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.44694

Collected Steps per Second: 21,789.75022
Overall Steps per Second: 10,574.65388

Timestep Collection Time: 2.29512
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.72923

Cumulative Model Updates: 114,896
Cumulative Timesteps: 958,399,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 958399478...
Checkpoint 958399478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,368.72152
Policy Entropy: 1.72169
Value Function Loss: 0.07264

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.59222
Value Function Update Magnitude: 0.41791

Collected Steps per Second: 20,795.27031
Overall Steps per Second: 10,151.85256

Timestep Collection Time: 2.40632
Timestep Consumption Time: 2.52283
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.92915

Cumulative Model Updates: 114,902
Cumulative Timesteps: 958,449,518

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,914.55323
Policy Entropy: 1.72233
Value Function Loss: 0.07320

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.38910

Collected Steps per Second: 21,602.91375
Overall Steps per Second: 10,508.08359

Timestep Collection Time: 2.31589
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.76110

Cumulative Model Updates: 114,908
Cumulative Timesteps: 958,499,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 958499548...
Checkpoint 958499548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,808.94462
Policy Entropy: 1.72988
Value Function Loss: 0.06998

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.15299
Policy Update Magnitude: 0.56840
Value Function Update Magnitude: 0.54393

Collected Steps per Second: 21,767.93151
Overall Steps per Second: 10,515.68703

Timestep Collection Time: 2.29898
Timestep Consumption Time: 2.46001
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.75899

Cumulative Model Updates: 114,914
Cumulative Timesteps: 958,549,592

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,494.54394
Policy Entropy: 1.72232
Value Function Loss: 0.06435

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.16699
Policy Update Magnitude: 0.53666
Value Function Update Magnitude: 0.65175

Collected Steps per Second: 21,973.17649
Overall Steps per Second: 10,592.65225

Timestep Collection Time: 2.27696
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.72327

Cumulative Model Updates: 114,920
Cumulative Timesteps: 958,599,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 958599624...
Checkpoint 958599624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,245.53320
Policy Entropy: 1.72287
Value Function Loss: 0.06449

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.15181
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.66268

Collected Steps per Second: 21,689.03384
Overall Steps per Second: 10,535.24927

Timestep Collection Time: 2.30559
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.74654

Cumulative Model Updates: 114,926
Cumulative Timesteps: 958,649,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,571.15898
Policy Entropy: 1.72660
Value Function Loss: 0.06491

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.57766
Value Function Update Magnitude: 0.67814

Collected Steps per Second: 21,228.84895
Overall Steps per Second: 10,429.08268

Timestep Collection Time: 2.35698
Timestep Consumption Time: 2.44076
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.79774

Cumulative Model Updates: 114,932
Cumulative Timesteps: 958,699,666

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 958699666...
Checkpoint 958699666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,674.75022
Policy Entropy: 1.71945
Value Function Loss: 0.06654

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.69642

Collected Steps per Second: 21,227.21345
Overall Steps per Second: 10,271.68234

Timestep Collection Time: 2.35566
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.86814

Cumulative Model Updates: 114,938
Cumulative Timesteps: 958,749,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,136.34946
Policy Entropy: 1.70982
Value Function Loss: 0.06325

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.59058
Value Function Update Magnitude: 0.64253

Collected Steps per Second: 21,631.11049
Overall Steps per Second: 10,531.37621

Timestep Collection Time: 2.31167
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.74810

Cumulative Model Updates: 114,944
Cumulative Timesteps: 958,799,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 958799674...
Checkpoint 958799674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,447.02703
Policy Entropy: 1.71143
Value Function Loss: 0.06445

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.14239
Policy Update Magnitude: 0.58328
Value Function Update Magnitude: 0.65591

Collected Steps per Second: 21,570.80035
Overall Steps per Second: 10,528.86577

Timestep Collection Time: 2.31795
Timestep Consumption Time: 2.43090
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.74885

Cumulative Model Updates: 114,950
Cumulative Timesteps: 958,849,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,134.63557
Policy Entropy: 1.71318
Value Function Loss: 0.06459

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.57838
Value Function Update Magnitude: 0.67790

Collected Steps per Second: 22,299.35495
Overall Steps per Second: 10,400.10312

Timestep Collection Time: 2.24320
Timestep Consumption Time: 2.56656
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.80976

Cumulative Model Updates: 114,956
Cumulative Timesteps: 958,899,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 958899696...
Checkpoint 958899696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,424.06175
Policy Entropy: 1.71315
Value Function Loss: 0.06641

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.57631
Value Function Update Magnitude: 0.66373

Collected Steps per Second: 21,476.57625
Overall Steps per Second: 10,346.56289

Timestep Collection Time: 2.32840
Timestep Consumption Time: 2.50471
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.83310

Cumulative Model Updates: 114,962
Cumulative Timesteps: 958,949,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,644.58121
Policy Entropy: 1.71589
Value Function Loss: 0.06349

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.71205

Collected Steps per Second: 21,547.85574
Overall Steps per Second: 10,498.27280

Timestep Collection Time: 2.32042
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.76269

Cumulative Model Updates: 114,968
Cumulative Timesteps: 958,999,702

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 958999702...
Checkpoint 958999702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,164.92299
Policy Entropy: 1.70988
Value Function Loss: 0.05717

Mean KL Divergence: 0.01665
SB3 Clip Fraction: 0.15787
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.68149

Collected Steps per Second: 21,262.45870
Overall Steps per Second: 10,515.84617

Timestep Collection Time: 2.35175
Timestep Consumption Time: 2.40336
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.75511

Cumulative Model Updates: 114,974
Cumulative Timesteps: 959,049,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,280.63608
Policy Entropy: 1.70865
Value Function Loss: 0.06069

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17331
Policy Update Magnitude: 0.51689
Value Function Update Magnitude: 0.65750

Collected Steps per Second: 21,705.57065
Overall Steps per Second: 10,513.32877

Timestep Collection Time: 2.30374
Timestep Consumption Time: 2.45251
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.75625

Cumulative Model Updates: 114,980
Cumulative Timesteps: 959,099,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 959099710...
Checkpoint 959099710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,294.34628
Policy Entropy: 1.71469
Value Function Loss: 0.06094

Mean KL Divergence: 0.01876
SB3 Clip Fraction: 0.16972
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.66229

Collected Steps per Second: 20,996.72952
Overall Steps per Second: 10,544.33996

Timestep Collection Time: 2.38323
Timestep Consumption Time: 2.36245
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.74567

Cumulative Model Updates: 114,986
Cumulative Timesteps: 959,149,750

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,585.52749
Policy Entropy: 1.72620
Value Function Loss: 0.05893

Mean KL Divergence: 0.01939
SB3 Clip Fraction: 0.17411
Policy Update Magnitude: 0.54839
Value Function Update Magnitude: 0.62006

Collected Steps per Second: 21,443.40554
Overall Steps per Second: 10,515.23959

Timestep Collection Time: 2.33256
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.75672

Cumulative Model Updates: 114,992
Cumulative Timesteps: 959,199,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 959199768...
Checkpoint 959199768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,970.56566
Policy Entropy: 1.72933
Value Function Loss: 0.05833

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.55535
Value Function Update Magnitude: 0.57556

Collected Steps per Second: 21,530.91701
Overall Steps per Second: 10,590.20225

Timestep Collection Time: 2.32233
Timestep Consumption Time: 2.39920
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.72153

Cumulative Model Updates: 114,998
Cumulative Timesteps: 959,249,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,287.41239
Policy Entropy: 1.71962
Value Function Loss: 0.06856

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.16210
Policy Update Magnitude: 0.57919
Value Function Update Magnitude: 0.62909

Collected Steps per Second: 21,558.91569
Overall Steps per Second: 10,567.14514

Timestep Collection Time: 2.32043
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.73411

Cumulative Model Updates: 115,004
Cumulative Timesteps: 959,299,796

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 959299796...
Checkpoint 959299796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,266.67382
Policy Entropy: 1.70250
Value Function Loss: 0.06884

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.58888
Value Function Update Magnitude: 0.69816

Collected Steps per Second: 21,467.03599
Overall Steps per Second: 10,556.71477

Timestep Collection Time: 2.33046
Timestep Consumption Time: 2.40852
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.73897

Cumulative Model Updates: 115,010
Cumulative Timesteps: 959,349,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,774.03910
Policy Entropy: 1.68836
Value Function Loss: 0.07153

Mean KL Divergence: 0.01645
SB3 Clip Fraction: 0.16027
Policy Update Magnitude: 0.59666
Value Function Update Magnitude: 0.65492

Collected Steps per Second: 22,033.65997
Overall Steps per Second: 10,568.34926

Timestep Collection Time: 2.27143
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.73565

Cumulative Model Updates: 115,016
Cumulative Timesteps: 959,399,872

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 959399872...
Checkpoint 959399872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,362.69395
Policy Entropy: 1.69237
Value Function Loss: 0.06413

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.15287
Policy Update Magnitude: 0.59009
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 22,095.79851
Overall Steps per Second: 10,594.74331

Timestep Collection Time: 2.26324
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.72008

Cumulative Model Updates: 115,022
Cumulative Timesteps: 959,449,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,509.36503
Policy Entropy: 1.69179
Value Function Loss: 0.06146

Mean KL Divergence: 0.01509
SB3 Clip Fraction: 0.15361
Policy Update Magnitude: 0.57686
Value Function Update Magnitude: 0.59521

Collected Steps per Second: 22,207.69155
Overall Steps per Second: 10,468.63157

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.52591
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.77847

Cumulative Model Updates: 115,028
Cumulative Timesteps: 959,499,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 959499904...
Checkpoint 959499904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,270.57202
Policy Entropy: 1.69238
Value Function Loss: 0.06269

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.14927
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.57663

Collected Steps per Second: 21,535.85624
Overall Steps per Second: 10,347.18024

Timestep Collection Time: 2.32320
Timestep Consumption Time: 2.51213
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.83533

Cumulative Model Updates: 115,034
Cumulative Timesteps: 959,549,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,717.02777
Policy Entropy: 1.68615
Value Function Loss: 0.06303

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.15538
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.46831

Collected Steps per Second: 22,368.51512
Overall Steps per Second: 10,694.84698

Timestep Collection Time: 2.23672
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.67814

Cumulative Model Updates: 115,040
Cumulative Timesteps: 959,599,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 959599968...
Checkpoint 959599968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,559.42934
Policy Entropy: 1.69728
Value Function Loss: 0.06790

Mean KL Divergence: 0.01702
SB3 Clip Fraction: 0.16222
Policy Update Magnitude: 0.57936
Value Function Update Magnitude: 0.52549

Collected Steps per Second: 21,679.07769
Overall Steps per Second: 10,562.72022

Timestep Collection Time: 2.30674
Timestep Consumption Time: 2.42765
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.73439

Cumulative Model Updates: 115,046
Cumulative Timesteps: 959,649,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,171.52678
Policy Entropy: 1.69626
Value Function Loss: 0.06134

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.16277
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.58984

Collected Steps per Second: 22,080.87410
Overall Steps per Second: 10,514.41766

Timestep Collection Time: 2.26558
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.75785

Cumulative Model Updates: 115,052
Cumulative Timesteps: 959,700,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 959700002...
Checkpoint 959700002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,994.62537
Policy Entropy: 1.70106
Value Function Loss: 0.06104

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.57247

Collected Steps per Second: 21,470.84196
Overall Steps per Second: 10,354.49960

Timestep Collection Time: 2.32967
Timestep Consumption Time: 2.50108
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.83075

Cumulative Model Updates: 115,058
Cumulative Timesteps: 959,750,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,954.88764
Policy Entropy: 1.69065
Value Function Loss: 0.06358

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14189
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.47579

Collected Steps per Second: 21,726.89937
Overall Steps per Second: 10,401.47731

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.80970

Cumulative Model Updates: 115,064
Cumulative Timesteps: 959,800,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 959800050...
Checkpoint 959800050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,780.69853
Policy Entropy: 1.68708
Value Function Loss: 0.06560

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.14897
Policy Update Magnitude: 0.58848
Value Function Update Magnitude: 0.45031

Collected Steps per Second: 20,716.00232
Overall Steps per Second: 10,495.44223

Timestep Collection Time: 2.41494
Timestep Consumption Time: 2.35170
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.76664

Cumulative Model Updates: 115,070
Cumulative Timesteps: 959,850,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,541.23219
Policy Entropy: 1.68352
Value Function Loss: 0.06686

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.15133
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.40222

Collected Steps per Second: 21,140.35344
Overall Steps per Second: 10,510.20909

Timestep Collection Time: 2.36609
Timestep Consumption Time: 2.39309
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.75918

Cumulative Model Updates: 115,076
Cumulative Timesteps: 959,900,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 959900098...
Checkpoint 959900098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,900.54233
Policy Entropy: 1.68054
Value Function Loss: 0.06674

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.57415
Value Function Update Magnitude: 0.36901

Collected Steps per Second: 20,717.41836
Overall Steps per Second: 10,330.30204

Timestep Collection Time: 2.41468
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.84265

Cumulative Model Updates: 115,082
Cumulative Timesteps: 959,950,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,444.95361
Policy Entropy: 1.68523
Value Function Loss: 0.06949

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.15490
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.44930

Collected Steps per Second: 21,512.36372
Overall Steps per Second: 10,547.82998

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.41742
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.74297

Cumulative Model Updates: 115,088
Cumulative Timesteps: 960,000,152

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 960000152...
Checkpoint 960000152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,983.17392
Policy Entropy: 1.68827
Value Function Loss: 0.06874

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.16760
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.44741

Collected Steps per Second: 21,138.09033
Overall Steps per Second: 10,382.29012

Timestep Collection Time: 2.36682
Timestep Consumption Time: 2.45197
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.81878

Cumulative Model Updates: 115,094
Cumulative Timesteps: 960,050,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,787.24232
Policy Entropy: 1.69822
Value Function Loss: 0.06601

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.16925
Policy Update Magnitude: 0.49791
Value Function Update Magnitude: 0.54491

Collected Steps per Second: 22,055.38829
Overall Steps per Second: 10,465.41777

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.77974

Cumulative Model Updates: 115,100
Cumulative Timesteps: 960,100,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 960100204...
Checkpoint 960100204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,327.38689
Policy Entropy: 1.70427
Value Function Loss: 0.06112

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.50014
Value Function Update Magnitude: 0.63359

Collected Steps per Second: 21,952.64344
Overall Steps per Second: 10,667.32355

Timestep Collection Time: 2.27881
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.68965

Cumulative Model Updates: 115,106
Cumulative Timesteps: 960,150,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,155.72147
Policy Entropy: 1.71282
Value Function Loss: 0.06079

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.16677
Policy Update Magnitude: 0.51454
Value Function Update Magnitude: 0.55498

Collected Steps per Second: 22,111.24478
Overall Steps per Second: 10,371.53812

Timestep Collection Time: 2.26328
Timestep Consumption Time: 2.56185
PPO Batch Consumption Time: 0.30792
Total Iteration Time: 4.82513

Cumulative Model Updates: 115,112
Cumulative Timesteps: 960,200,274

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 960200274...
Checkpoint 960200274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,237.66209
Policy Entropy: 1.72499
Value Function Loss: 0.06666

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.16188
Policy Update Magnitude: 0.53789
Value Function Update Magnitude: 0.41873

Collected Steps per Second: 21,733.80422
Overall Steps per Second: 10,368.51100

Timestep Collection Time: 2.30158
Timestep Consumption Time: 2.52284
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.82442

Cumulative Model Updates: 115,118
Cumulative Timesteps: 960,250,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,383.73951
Policy Entropy: 1.72617
Value Function Loss: 0.06931

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.15202
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.49370

Collected Steps per Second: 22,246.26626
Overall Steps per Second: 10,545.64255

Timestep Collection Time: 2.24847
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.74319

Cumulative Model Updates: 115,124
Cumulative Timesteps: 960,300,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 960300316...
Checkpoint 960300316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,279.27204
Policy Entropy: 1.72614
Value Function Loss: 0.06605

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.58705
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 22,000.77815
Overall Steps per Second: 10,502.25429

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.76126

Cumulative Model Updates: 115,130
Cumulative Timesteps: 960,350,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,786.00736
Policy Entropy: 1.71358
Value Function Loss: 0.06109

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.58547
Value Function Update Magnitude: 0.56102

Collected Steps per Second: 21,980.54040
Overall Steps per Second: 10,440.30038

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.51480
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.78990

Cumulative Model Updates: 115,136
Cumulative Timesteps: 960,400,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 960400328...
Checkpoint 960400328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,436.42710
Policy Entropy: 1.72153
Value Function Loss: 0.06290

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.15125
Policy Update Magnitude: 0.57942
Value Function Update Magnitude: 0.61171

Collected Steps per Second: 21,609.53169
Overall Steps per Second: 10,562.34500

Timestep Collection Time: 2.31490
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.73607

Cumulative Model Updates: 115,142
Cumulative Timesteps: 960,450,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,736.33966
Policy Entropy: 1.72090
Value Function Loss: 0.06044

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.59046

Collected Steps per Second: 22,070.60246
Overall Steps per Second: 10,487.78801

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.50329
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.76993

Cumulative Model Updates: 115,148
Cumulative Timesteps: 960,500,378

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 960500378...
Checkpoint 960500378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,191.03666
Policy Entropy: 1.72228
Value Function Loss: 0.06327

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.61644

Collected Steps per Second: 21,443.90811
Overall Steps per Second: 10,138.09664

Timestep Collection Time: 2.33176
Timestep Consumption Time: 2.60033
PPO Batch Consumption Time: 0.29839
Total Iteration Time: 4.93209

Cumulative Model Updates: 115,154
Cumulative Timesteps: 960,550,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,970.84873
Policy Entropy: 1.71090
Value Function Loss: 0.06208

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14163
Policy Update Magnitude: 0.58845
Value Function Update Magnitude: 0.58644

Collected Steps per Second: 22,173.36775
Overall Steps per Second: 10,581.42963

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.72677

Cumulative Model Updates: 115,160
Cumulative Timesteps: 960,600,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 960600396...
Checkpoint 960600396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,083.11958
Policy Entropy: 1.71508
Value Function Loss: 0.06035

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.14275
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.49184

Collected Steps per Second: 22,012.60878
Overall Steps per Second: 10,608.85600

Timestep Collection Time: 2.27261
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.71549

Cumulative Model Updates: 115,166
Cumulative Timesteps: 960,650,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,995.20771
Policy Entropy: 1.71595
Value Function Loss: 0.05775

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.46981

Collected Steps per Second: 22,151.34277
Overall Steps per Second: 10,457.59407

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.52492
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.78294

Cumulative Model Updates: 115,172
Cumulative Timesteps: 960,700,440

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 960700440...
Checkpoint 960700440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,993.22934
Policy Entropy: 1.72512
Value Function Loss: 0.06212

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13770
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.38468

Collected Steps per Second: 21,747.85898
Overall Steps per Second: 10,566.03981

Timestep Collection Time: 2.30055
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.73517

Cumulative Model Updates: 115,178
Cumulative Timesteps: 960,750,472

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,982.18354
Policy Entropy: 1.73031
Value Function Loss: 0.06545

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.34053

Collected Steps per Second: 21,843.14637
Overall Steps per Second: 10,598.25768

Timestep Collection Time: 2.29005
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.71983

Cumulative Model Updates: 115,184
Cumulative Timesteps: 960,800,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 960800494...
Checkpoint 960800494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,776.64104
Policy Entropy: 1.74078
Value Function Loss: 0.06778

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.58541
Value Function Update Magnitude: 0.37621

Collected Steps per Second: 21,704.75784
Overall Steps per Second: 10,376.58773

Timestep Collection Time: 2.30429
Timestep Consumption Time: 2.51560
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.81989

Cumulative Model Updates: 115,190
Cumulative Timesteps: 960,850,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,005.07896
Policy Entropy: 1.73715
Value Function Loss: 0.06464

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.59203
Value Function Update Magnitude: 0.35810

Collected Steps per Second: 22,253.28507
Overall Steps per Second: 10,559.46297

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.73566

Cumulative Model Updates: 115,196
Cumulative Timesteps: 960,900,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 960900514...
Checkpoint 960900514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,230.82261
Policy Entropy: 1.73661
Value Function Loss: 0.06778

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15829
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.32636

Collected Steps per Second: 21,575.42341
Overall Steps per Second: 10,365.29544

Timestep Collection Time: 2.31856
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.82610

Cumulative Model Updates: 115,202
Cumulative Timesteps: 960,950,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,743.28805
Policy Entropy: 1.74167
Value Function Loss: 0.06918

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.17474
Policy Update Magnitude: 0.50505
Value Function Update Magnitude: 0.31539

Collected Steps per Second: 21,501.61069
Overall Steps per Second: 10,414.36964

Timestep Collection Time: 2.32606
Timestep Consumption Time: 2.47634
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.80240

Cumulative Model Updates: 115,208
Cumulative Timesteps: 961,000,552

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 961000552...
Checkpoint 961000552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,405.29552
Policy Entropy: 1.74123
Value Function Loss: 0.07255

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.56118
Value Function Update Magnitude: 0.32154

Collected Steps per Second: 21,034.20427
Overall Steps per Second: 10,552.16131

Timestep Collection Time: 2.37908
Timestep Consumption Time: 2.36327
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.74235

Cumulative Model Updates: 115,214
Cumulative Timesteps: 961,050,594

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,679.98906
Policy Entropy: 1.73408
Value Function Loss: 0.07093

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14323
Policy Update Magnitude: 0.59001
Value Function Update Magnitude: 0.36304

Collected Steps per Second: 21,354.76343
Overall Steps per Second: 10,512.16932

Timestep Collection Time: 2.34327
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.76020

Cumulative Model Updates: 115,220
Cumulative Timesteps: 961,100,634

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 961100634...
Checkpoint 961100634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,334.38556
Policy Entropy: 1.74235
Value Function Loss: 0.07411

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.59610
Value Function Update Magnitude: 0.33759

Collected Steps per Second: 21,247.50310
Overall Steps per Second: 10,597.85047

Timestep Collection Time: 2.35557
Timestep Consumption Time: 2.36708
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.72266

Cumulative Model Updates: 115,226
Cumulative Timesteps: 961,150,684

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,105.69232
Policy Entropy: 1.74390
Value Function Loss: 0.08094

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.15168
Policy Update Magnitude: 0.60455
Value Function Update Magnitude: 0.30911

Collected Steps per Second: 21,452.73258
Overall Steps per Second: 10,540.81866

Timestep Collection Time: 2.33099
Timestep Consumption Time: 2.41305
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.74403

Cumulative Model Updates: 115,232
Cumulative Timesteps: 961,200,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 961200690...
Checkpoint 961200690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,298.94646
Policy Entropy: 1.75099
Value Function Loss: 0.07767

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.15999
Policy Update Magnitude: 0.59880
Value Function Update Magnitude: 0.45590

Collected Steps per Second: 21,239.30933
Overall Steps per Second: 10,361.31379

Timestep Collection Time: 2.35497
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.82738

Cumulative Model Updates: 115,238
Cumulative Timesteps: 961,250,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,038.68259
Policy Entropy: 1.75439
Value Function Loss: 0.07211

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.17390
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.43789

Collected Steps per Second: 22,190.55411
Overall Steps per Second: 10,704.57534

Timestep Collection Time: 2.25393
Timestep Consumption Time: 2.41846
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.67239

Cumulative Model Updates: 115,244
Cumulative Timesteps: 961,300,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 961300724...
Checkpoint 961300724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,218.62647
Policy Entropy: 1.74657
Value Function Loss: 0.06558

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.47338

Collected Steps per Second: 21,353.72511
Overall Steps per Second: 10,392.15276

Timestep Collection Time: 2.34301
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.81440

Cumulative Model Updates: 115,250
Cumulative Timesteps: 961,350,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,611.30083
Policy Entropy: 1.76296
Value Function Loss: 0.07092

Mean KL Divergence: 0.01694
SB3 Clip Fraction: 0.16498
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.47469

Collected Steps per Second: 21,936.41859
Overall Steps per Second: 10,655.19322

Timestep Collection Time: 2.28077
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.69555

Cumulative Model Updates: 115,256
Cumulative Timesteps: 961,400,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 961400788...
Checkpoint 961400788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,975.88443
Policy Entropy: 1.75826
Value Function Loss: 0.06884

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.15470
Policy Update Magnitude: 0.59017
Value Function Update Magnitude: 0.57490

Collected Steps per Second: 21,403.08952
Overall Steps per Second: 10,326.26940

Timestep Collection Time: 2.33667
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.84318

Cumulative Model Updates: 115,262
Cumulative Timesteps: 961,450,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,098.61849
Policy Entropy: 1.77468
Value Function Loss: 0.06793

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.14939
Policy Update Magnitude: 0.58975
Value Function Update Magnitude: 0.51125

Collected Steps per Second: 21,892.93754
Overall Steps per Second: 10,233.57265

Timestep Collection Time: 2.28430
Timestep Consumption Time: 2.60256
PPO Batch Consumption Time: 0.30794
Total Iteration Time: 4.88686

Cumulative Model Updates: 115,268
Cumulative Timesteps: 961,500,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961500810...
Checkpoint 961500810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,965.70165
Policy Entropy: 1.75453
Value Function Loss: 0.06325

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.15333
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.50791

Collected Steps per Second: 21,563.76137
Overall Steps per Second: 10,285.95992

Timestep Collection Time: 2.32075
Timestep Consumption Time: 2.54453
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.86527

Cumulative Model Updates: 115,274
Cumulative Timesteps: 961,550,854

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,837.36341
Policy Entropy: 1.75000
Value Function Loss: 0.06291

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.14716
Policy Update Magnitude: 0.57701
Value Function Update Magnitude: 0.51265

Collected Steps per Second: 22,037.88061
Overall Steps per Second: 10,535.91268

Timestep Collection Time: 2.27000
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.74814

Cumulative Model Updates: 115,280
Cumulative Timesteps: 961,600,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 961600880...
Checkpoint 961600880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,617.80203
Policy Entropy: 1.73838
Value Function Loss: 0.06660

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.59276
Value Function Update Magnitude: 0.44278

Collected Steps per Second: 21,912.32521
Overall Steps per Second: 10,560.99011

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.45376
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.73668

Cumulative Model Updates: 115,286
Cumulative Timesteps: 961,650,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,870.54199
Policy Entropy: 1.74918
Value Function Loss: 0.06959

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.59359
Value Function Update Magnitude: 0.37841

Collected Steps per Second: 22,270.83500
Overall Steps per Second: 10,551.19239

Timestep Collection Time: 2.24509
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.73880

Cumulative Model Updates: 115,292
Cumulative Timesteps: 961,700,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 961700904...
Checkpoint 961700904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,783.01585
Policy Entropy: 1.74650
Value Function Loss: 0.07185

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.58813
Value Function Update Magnitude: 0.36136

Collected Steps per Second: 21,681.25691
Overall Steps per Second: 10,546.16796

Timestep Collection Time: 2.30642
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.74163

Cumulative Model Updates: 115,298
Cumulative Timesteps: 961,750,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,309.48024
Policy Entropy: 1.74779
Value Function Loss: 0.06682

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14484
Policy Update Magnitude: 0.58045
Value Function Update Magnitude: 0.39316

Collected Steps per Second: 22,038.19260
Overall Steps per Second: 10,537.04011

Timestep Collection Time: 2.26915
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.74592

Cumulative Model Updates: 115,304
Cumulative Timesteps: 961,800,918

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 961800918...
Checkpoint 961800918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,649.31375
Policy Entropy: 1.73866
Value Function Loss: 0.06645

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.37299

Collected Steps per Second: 21,582.94586
Overall Steps per Second: 10,399.00776

Timestep Collection Time: 2.31720
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.80930

Cumulative Model Updates: 115,310
Cumulative Timesteps: 961,850,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,703.82836
Policy Entropy: 1.74261
Value Function Loss: 0.06916

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.18527
Policy Update Magnitude: 0.52065
Value Function Update Magnitude: 0.35360

Collected Steps per Second: 21,975.87584
Overall Steps per Second: 10,613.95126

Timestep Collection Time: 2.27550
Timestep Consumption Time: 2.43585
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.71135

Cumulative Model Updates: 115,316
Cumulative Timesteps: 961,900,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 961900936...
Checkpoint 961900936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,075.97346
Policy Entropy: 1.75259
Value Function Loss: 0.07633

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.56790
Value Function Update Magnitude: 0.32643

Collected Steps per Second: 21,474.93480
Overall Steps per Second: 10,318.58779

Timestep Collection Time: 2.32895
Timestep Consumption Time: 2.51803
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.84698

Cumulative Model Updates: 115,322
Cumulative Timesteps: 961,950,950

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,807.23249
Policy Entropy: 1.76426
Value Function Loss: 0.07845

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.16050
Policy Update Magnitude: 0.58374
Value Function Update Magnitude: 0.31896

Collected Steps per Second: 21,937.01308
Overall Steps per Second: 10,438.65234

Timestep Collection Time: 2.28007
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.79161

Cumulative Model Updates: 115,328
Cumulative Timesteps: 962,000,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 962000968...
Checkpoint 962000968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,041.72488
Policy Entropy: 1.77468
Value Function Loss: 0.07663

Mean KL Divergence: 0.01830
SB3 Clip Fraction: 0.17478
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.34202

Collected Steps per Second: 21,287.52064
Overall Steps per Second: 10,290.26252

Timestep Collection Time: 2.35067
Timestep Consumption Time: 2.51218
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.86285

Cumulative Model Updates: 115,334
Cumulative Timesteps: 962,051,008

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,191.55500
Policy Entropy: 1.77294
Value Function Loss: 0.07334

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.58093
Value Function Update Magnitude: 0.45235

Collected Steps per Second: 21,804.96827
Overall Steps per Second: 10,369.65881

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.53012
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.82446

Cumulative Model Updates: 115,340
Cumulative Timesteps: 962,101,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 962101036...
Checkpoint 962101036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,310.30772
Policy Entropy: 1.77390
Value Function Loss: 0.07054

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.14728
Policy Update Magnitude: 0.60748
Value Function Update Magnitude: 0.48932

Collected Steps per Second: 20,941.25870
Overall Steps per Second: 10,051.29860

Timestep Collection Time: 2.38811
Timestep Consumption Time: 2.58737
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 4.97548

Cumulative Model Updates: 115,346
Cumulative Timesteps: 962,151,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,269.80859
Policy Entropy: 1.76638
Value Function Loss: 0.07269

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.15104
Policy Update Magnitude: 0.60643
Value Function Update Magnitude: 0.41699

Collected Steps per Second: 21,888.52522
Overall Steps per Second: 10,490.79742

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.76684

Cumulative Model Updates: 115,352
Cumulative Timesteps: 962,201,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 962201054...
Checkpoint 962201054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,785.72538
Policy Entropy: 1.77230
Value Function Loss: 0.07294

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14583
Policy Update Magnitude: 0.60652
Value Function Update Magnitude: 0.39576

Collected Steps per Second: 21,409.72689
Overall Steps per Second: 10,329.65567

Timestep Collection Time: 2.33539
Timestep Consumption Time: 2.50505
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.84043

Cumulative Model Updates: 115,358
Cumulative Timesteps: 962,251,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,430.83102
Policy Entropy: 1.77638
Value Function Loss: 0.06829

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.59868
Value Function Update Magnitude: 0.50685

Collected Steps per Second: 22,291.05532
Overall Steps per Second: 10,456.01124

Timestep Collection Time: 2.24521
Timestep Consumption Time: 2.54132
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.78653

Cumulative Model Updates: 115,364
Cumulative Timesteps: 962,301,102

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 962301102...
Checkpoint 962301102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,185.25385
Policy Entropy: 1.78267
Value Function Loss: 0.06706

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.14636
Policy Update Magnitude: 0.58880
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 21,683.54441
Overall Steps per Second: 10,532.81452

Timestep Collection Time: 2.30673
Timestep Consumption Time: 2.44205
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.74878

Cumulative Model Updates: 115,370
Cumulative Timesteps: 962,351,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,595.58459
Policy Entropy: 1.78107
Value Function Loss: 0.06690

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.14660
Policy Update Magnitude: 0.59340
Value Function Update Magnitude: 0.59901

Collected Steps per Second: 22,048.51246
Overall Steps per Second: 10,561.79565

Timestep Collection Time: 2.26891
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.73651

Cumulative Model Updates: 115,376
Cumulative Timesteps: 962,401,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 962401146...
Checkpoint 962401146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,964.43322
Policy Entropy: 1.78253
Value Function Loss: 0.06888

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.59827
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 20,804.12984
Overall Steps per Second: 10,210.15080

Timestep Collection Time: 2.40347
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.89728

Cumulative Model Updates: 115,382
Cumulative Timesteps: 962,451,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,120.34071
Policy Entropy: 1.77001
Value Function Loss: 0.06812

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.60213
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 21,644.13659
Overall Steps per Second: 10,529.95977

Timestep Collection Time: 2.31111
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.75045

Cumulative Model Updates: 115,388
Cumulative Timesteps: 962,501,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 962501170...
Checkpoint 962501170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,418.88321
Policy Entropy: 1.76567
Value Function Loss: 0.06812

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14836
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.46402

Collected Steps per Second: 21,653.90634
Overall Steps per Second: 10,550.33794

Timestep Collection Time: 2.31099
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.74317

Cumulative Model Updates: 115,394
Cumulative Timesteps: 962,551,212

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,386.93158
Policy Entropy: 1.77209
Value Function Loss: 0.08387

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.15141
Policy Update Magnitude: 0.57486
Value Function Update Magnitude: 0.38076

Collected Steps per Second: 21,882.97193
Overall Steps per Second: 10,478.26504

Timestep Collection Time: 2.28689
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.77598

Cumulative Model Updates: 115,400
Cumulative Timesteps: 962,601,256

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 962601256...
Checkpoint 962601256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,774.96810
Policy Entropy: 1.77804
Value Function Loss: 0.08432

Mean KL Divergence: 0.01910
SB3 Clip Fraction: 0.17522
Policy Update Magnitude: 0.53102
Value Function Update Magnitude: 0.33284

Collected Steps per Second: 21,664.06874
Overall Steps per Second: 10,351.08931

Timestep Collection Time: 2.30972
Timestep Consumption Time: 2.52436
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.83408

Cumulative Model Updates: 115,406
Cumulative Timesteps: 962,651,294

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,532.40565
Policy Entropy: 1.79403
Value Function Loss: 0.08877

Mean KL Divergence: 0.02028
SB3 Clip Fraction: 0.17470
Policy Update Magnitude: 0.52169
Value Function Update Magnitude: 0.30133

Collected Steps per Second: 21,696.26949
Overall Steps per Second: 10,685.36708

Timestep Collection Time: 2.30528
Timestep Consumption Time: 2.37551
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.68079

Cumulative Model Updates: 115,412
Cumulative Timesteps: 962,701,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 962701310...
Checkpoint 962701310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,467.32568
Policy Entropy: 1.79304
Value Function Loss: 0.08202

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.15686
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 20,986.93367
Overall Steps per Second: 10,370.41938

Timestep Collection Time: 2.38415
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.82488

Cumulative Model Updates: 115,418
Cumulative Timesteps: 962,751,346

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,119.28940
Policy Entropy: 1.77738
Value Function Loss: 0.08299

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.35268

Collected Steps per Second: 21,585.19344
Overall Steps per Second: 10,392.34370

Timestep Collection Time: 2.31742
Timestep Consumption Time: 2.49593
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.81335

Cumulative Model Updates: 115,424
Cumulative Timesteps: 962,801,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 962801368...
Checkpoint 962801368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,024.65961
Policy Entropy: 1.77546
Value Function Loss: 0.08078

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.59319
Value Function Update Magnitude: 0.32263

Collected Steps per Second: 21,504.82347
Overall Steps per Second: 10,573.49712

Timestep Collection Time: 2.32608
Timestep Consumption Time: 2.40480
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.73089

Cumulative Model Updates: 115,430
Cumulative Timesteps: 962,851,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,618.93075
Policy Entropy: 1.77695
Value Function Loss: 0.08390

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.59656
Value Function Update Magnitude: 0.29134

Collected Steps per Second: 21,946.35719
Overall Steps per Second: 10,517.60336

Timestep Collection Time: 2.27965
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.75679

Cumulative Model Updates: 115,436
Cumulative Timesteps: 962,901,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 962901420...
Checkpoint 962901420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,805.97492
Policy Entropy: 1.78528
Value Function Loss: 0.07609

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.59123
Value Function Update Magnitude: 0.27324

Collected Steps per Second: 21,664.06445
Overall Steps per Second: 10,587.02446

Timestep Collection Time: 2.30797
Timestep Consumption Time: 2.41479
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.72276

Cumulative Model Updates: 115,442
Cumulative Timesteps: 962,951,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,919.84180
Policy Entropy: 1.79060
Value Function Loss: 0.06847

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.14219
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.36199

Collected Steps per Second: 21,651.30407
Overall Steps per Second: 10,515.51368

Timestep Collection Time: 2.31044
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.75716

Cumulative Model Updates: 115,448
Cumulative Timesteps: 963,001,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 963001444...
Checkpoint 963001444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,860.97760
Policy Entropy: 1.78391
Value Function Loss: 0.06670

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.14525
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.38811

Collected Steps per Second: 21,420.91988
Overall Steps per Second: 10,333.34626

Timestep Collection Time: 2.33529
Timestep Consumption Time: 2.50574
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.84103

Cumulative Model Updates: 115,454
Cumulative Timesteps: 963,051,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,923.50166
Policy Entropy: 1.78039
Value Function Loss: 0.07068

Mean KL Divergence: 0.01660
SB3 Clip Fraction: 0.16146
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.34985

Collected Steps per Second: 21,840.85142
Overall Steps per Second: 10,429.13329

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.79522

Cumulative Model Updates: 115,460
Cumulative Timesteps: 963,101,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 963101478...
Checkpoint 963101478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,998.91367
Policy Entropy: 1.77476
Value Function Loss: 0.07539

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.34920

Collected Steps per Second: 21,635.67447
Overall Steps per Second: 10,526.54287

Timestep Collection Time: 2.31174
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.75142

Cumulative Model Updates: 115,466
Cumulative Timesteps: 963,151,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,053.67336
Policy Entropy: 1.77757
Value Function Loss: 0.07112

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.16847
Policy Update Magnitude: 0.57448
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 22,354.18237
Overall Steps per Second: 10,445.92376

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.55116
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.78905

Cumulative Model Updates: 115,472
Cumulative Timesteps: 963,201,520

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 963201520...
Checkpoint 963201520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,734.33534
Policy Entropy: 1.79616
Value Function Loss: 0.06720

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.16868
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.34711

Collected Steps per Second: 21,969.80967
Overall Steps per Second: 10,534.86236

Timestep Collection Time: 2.27667
Timestep Consumption Time: 2.47119
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.74786

Cumulative Model Updates: 115,478
Cumulative Timesteps: 963,251,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,855.98866
Policy Entropy: 1.79173
Value Function Loss: 0.06328

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.15822
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.45249

Collected Steps per Second: 22,091.53248
Overall Steps per Second: 10,525.12365

Timestep Collection Time: 2.26494
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.75396

Cumulative Model Updates: 115,484
Cumulative Timesteps: 963,301,574

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 963301574...
Checkpoint 963301574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,465.45446
Policy Entropy: 1.79209
Value Function Loss: 0.06324

Mean KL Divergence: 0.01743
SB3 Clip Fraction: 0.16561
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.45440

Collected Steps per Second: 21,634.71019
Overall Steps per Second: 10,389.21814

Timestep Collection Time: 2.31240
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.81538

Cumulative Model Updates: 115,490
Cumulative Timesteps: 963,351,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,041.95915
Policy Entropy: 1.79672
Value Function Loss: 0.06691

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15767
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.44602

Collected Steps per Second: 22,216.54769
Overall Steps per Second: 10,676.78883

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.68474

Cumulative Model Updates: 115,496
Cumulative Timesteps: 963,401,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 963401620...
Checkpoint 963401620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,972.75262
Policy Entropy: 1.78900
Value Function Loss: 0.06424

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.15953
Policy Update Magnitude: 0.58153
Value Function Update Magnitude: 0.63065

Collected Steps per Second: 21,817.49839
Overall Steps per Second: 10,476.58643

Timestep Collection Time: 2.29220
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.77350

Cumulative Model Updates: 115,502
Cumulative Timesteps: 963,451,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,789.47633
Policy Entropy: 1.78431
Value Function Loss: 0.06164

Mean KL Divergence: 0.01590
SB3 Clip Fraction: 0.15457
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.67103

Collected Steps per Second: 21,933.41809
Overall Steps per Second: 10,465.89424

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.77933

Cumulative Model Updates: 115,508
Cumulative Timesteps: 963,501,650

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963501650...
Checkpoint 963501650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,309.76002
Policy Entropy: 1.76579
Value Function Loss: 0.06584

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.15208
Policy Update Magnitude: 0.56956
Value Function Update Magnitude: 0.63636

Collected Steps per Second: 21,526.91684
Overall Steps per Second: 10,397.11892

Timestep Collection Time: 2.32490
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.81364

Cumulative Model Updates: 115,514
Cumulative Timesteps: 963,551,698

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,241.82120
Policy Entropy: 1.77015
Value Function Loss: 0.06671

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.17439
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.55396

Collected Steps per Second: 20,997.31584
Overall Steps per Second: 10,538.61273

Timestep Collection Time: 2.38249
Timestep Consumption Time: 2.36443
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.74692

Cumulative Model Updates: 115,520
Cumulative Timesteps: 963,601,724

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 963601724...
Checkpoint 963601724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,389.55435
Policy Entropy: 1.77048
Value Function Loss: 0.07096

Mean KL Divergence: 0.01827
SB3 Clip Fraction: 0.16920
Policy Update Magnitude: 0.50063
Value Function Update Magnitude: 0.48932

Collected Steps per Second: 20,761.21207
Overall Steps per Second: 10,512.39433

Timestep Collection Time: 2.40969
Timestep Consumption Time: 2.34927
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.75895

Cumulative Model Updates: 115,526
Cumulative Timesteps: 963,651,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,732.66251
Policy Entropy: 1.76632
Value Function Loss: 0.06375

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.15176
Policy Update Magnitude: 0.51859
Value Function Update Magnitude: 0.52626

Collected Steps per Second: 21,065.23818
Overall Steps per Second: 10,558.49588

Timestep Collection Time: 2.37453
Timestep Consumption Time: 2.36289
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.73742

Cumulative Model Updates: 115,532
Cumulative Timesteps: 963,701,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963701772...
Checkpoint 963701772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,042.72250
Policy Entropy: 1.77113
Value Function Loss: 0.06917

Mean KL Divergence: 0.01746
SB3 Clip Fraction: 0.16436
Policy Update Magnitude: 0.52355
Value Function Update Magnitude: 0.40095

Collected Steps per Second: 20,778.77737
Overall Steps per Second: 10,497.10693

Timestep Collection Time: 2.40640
Timestep Consumption Time: 2.35701
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.76341

Cumulative Model Updates: 115,538
Cumulative Timesteps: 963,751,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,582.82657
Policy Entropy: 1.78247
Value Function Loss: 0.06608

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.16602
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.34627

Collected Steps per Second: 21,439.78393
Overall Steps per Second: 10,538.82114

Timestep Collection Time: 2.33305
Timestep Consumption Time: 2.41322
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.74626

Cumulative Model Updates: 115,544
Cumulative Timesteps: 963,801,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963801794...
Checkpoint 963801794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,380.42940
Policy Entropy: 1.77610
Value Function Loss: 0.07285

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.16972
Policy Update Magnitude: 0.56461
Value Function Update Magnitude: 0.35035

Collected Steps per Second: 21,502.81665
Overall Steps per Second: 10,551.33676

Timestep Collection Time: 2.32723
Timestep Consumption Time: 2.41549
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.74272

Cumulative Model Updates: 115,550
Cumulative Timesteps: 963,851,836

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,381.79395
Policy Entropy: 1.78513
Value Function Loss: 0.06744

Mean KL Divergence: 0.01900
SB3 Clip Fraction: 0.17579
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.46369

Collected Steps per Second: 21,864.16336
Overall Steps per Second: 10,532.17505

Timestep Collection Time: 2.28813
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.75002

Cumulative Model Updates: 115,556
Cumulative Timesteps: 963,901,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 963901864...
Checkpoint 963901864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,706.80985
Policy Entropy: 1.78674
Value Function Loss: 0.06384

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.52977

Collected Steps per Second: 21,676.75869
Overall Steps per Second: 10,608.76422

Timestep Collection Time: 2.30745
Timestep Consumption Time: 2.40733
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.71478

Cumulative Model Updates: 115,562
Cumulative Timesteps: 963,951,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,020.27624
Policy Entropy: 1.78781
Value Function Loss: 0.06201

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.15459
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.58239

Collected Steps per Second: 22,106.03389
Overall Steps per Second: 10,521.80271

Timestep Collection Time: 2.26183
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.75204

Cumulative Model Updates: 115,568
Cumulative Timesteps: 964,001,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 964001882...
Checkpoint 964001882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,738.46470
Policy Entropy: 1.78494
Value Function Loss: 0.06180

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.58322
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 21,764.81335
Overall Steps per Second: 10,591.81704

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.72402

Cumulative Model Updates: 115,574
Cumulative Timesteps: 964,051,918

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,415.38075
Policy Entropy: 1.78251
Value Function Loss: 0.06423

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.58658
Value Function Update Magnitude: 0.62684

Collected Steps per Second: 22,022.34951
Overall Steps per Second: 10,412.61382

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.53216
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.80321

Cumulative Model Updates: 115,580
Cumulative Timesteps: 964,101,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 964101932...
Checkpoint 964101932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,475.33375
Policy Entropy: 1.78494
Value Function Loss: 0.06720

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.14223
Policy Update Magnitude: 0.59110
Value Function Update Magnitude: 0.50933

Collected Steps per Second: 21,262.57180
Overall Steps per Second: 10,145.86852

Timestep Collection Time: 2.35221
Timestep Consumption Time: 2.57729
PPO Batch Consumption Time: 0.30377
Total Iteration Time: 4.92949

Cumulative Model Updates: 115,586
Cumulative Timesteps: 964,151,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,765.51923
Policy Entropy: 1.77270
Value Function Loss: 0.06930

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.59241
Value Function Update Magnitude: 0.44078

Collected Steps per Second: 21,471.22071
Overall Steps per Second: 10,369.75137

Timestep Collection Time: 2.32982
Timestep Consumption Time: 2.49421
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.82403

Cumulative Model Updates: 115,592
Cumulative Timesteps: 964,201,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 964201970...
Checkpoint 964201970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,422.61096
Policy Entropy: 1.77336
Value Function Loss: 0.07263

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13948
Policy Update Magnitude: 0.59620
Value Function Update Magnitude: 0.41346

Collected Steps per Second: 21,527.57065
Overall Steps per Second: 10,435.13756

Timestep Collection Time: 2.32279
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.79189

Cumulative Model Updates: 115,598
Cumulative Timesteps: 964,251,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,581.80092
Policy Entropy: 1.76168
Value Function Loss: 0.06983

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.59457
Value Function Update Magnitude: 0.41345

Collected Steps per Second: 21,564.67347
Overall Steps per Second: 10,407.27804

Timestep Collection Time: 2.31889
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.80491

Cumulative Model Updates: 115,604
Cumulative Timesteps: 964,301,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 964301980...
Checkpoint 964301980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,210.41686
Policy Entropy: 1.76841
Value Function Loss: 0.06569

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.58817
Value Function Update Magnitude: 0.54811

Collected Steps per Second: 21,306.32067
Overall Steps per Second: 10,284.64404

Timestep Collection Time: 2.34691
Timestep Consumption Time: 2.51510
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.86201

Cumulative Model Updates: 115,610
Cumulative Timesteps: 964,351,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,999.50815
Policy Entropy: 1.75894
Value Function Loss: 0.06013

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.62628

Collected Steps per Second: 21,811.42997
Overall Steps per Second: 10,402.07992

Timestep Collection Time: 2.29357
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.80923

Cumulative Model Updates: 115,616
Cumulative Timesteps: 964,402,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 964402010...
Checkpoint 964402010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,468.41738
Policy Entropy: 1.76027
Value Function Loss: 0.05944

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.57765

Collected Steps per Second: 21,947.08381
Overall Steps per Second: 10,585.51413

Timestep Collection Time: 2.27884
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.72476

Cumulative Model Updates: 115,622
Cumulative Timesteps: 964,452,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,451.29482
Policy Entropy: 1.75706
Value Function Loss: 0.05908

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.13483
Policy Update Magnitude: 0.57867
Value Function Update Magnitude: 0.53878

Collected Steps per Second: 21,918.15254
Overall Steps per Second: 10,411.95218

Timestep Collection Time: 2.28204
Timestep Consumption Time: 2.52187
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.80390

Cumulative Model Updates: 115,628
Cumulative Timesteps: 964,502,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 964502042...
Checkpoint 964502042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,601.94822
Policy Entropy: 1.76362
Value Function Loss: 0.06234

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.57832
Value Function Update Magnitude: 0.50095

Collected Steps per Second: 21,711.80005
Overall Steps per Second: 10,417.86280

Timestep Collection Time: 2.30409
Timestep Consumption Time: 2.49785
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.80194

Cumulative Model Updates: 115,634
Cumulative Timesteps: 964,552,068

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,240.37879
Policy Entropy: 1.76769
Value Function Loss: 0.06657

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.58997
Value Function Update Magnitude: 0.50832

Collected Steps per Second: 22,225.60648
Overall Steps per Second: 10,538.55239

Timestep Collection Time: 2.25029
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.74581

Cumulative Model Updates: 115,640
Cumulative Timesteps: 964,602,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 964602082...
Checkpoint 964602082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,413.57403
Policy Entropy: 1.76777
Value Function Loss: 0.06912

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.13956
Policy Update Magnitude: 0.59120
Value Function Update Magnitude: 0.46217

Collected Steps per Second: 21,266.95540
Overall Steps per Second: 10,435.04298

Timestep Collection Time: 2.35182
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.79308

Cumulative Model Updates: 115,646
Cumulative Timesteps: 964,652,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,676.71496
Policy Entropy: 1.76305
Value Function Loss: 0.07056

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14154
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.43719

Collected Steps per Second: 21,562.82544
Overall Steps per Second: 10,499.17538

Timestep Collection Time: 2.31955
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.76380

Cumulative Model Updates: 115,652
Cumulative Timesteps: 964,702,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 964702114...
Checkpoint 964702114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,123.57626
Policy Entropy: 1.75799
Value Function Loss: 0.06346

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.57191
Value Function Update Magnitude: 0.56932

Collected Steps per Second: 21,220.57877
Overall Steps per Second: 10,541.77710

Timestep Collection Time: 2.35658
Timestep Consumption Time: 2.38721
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.74379

Cumulative Model Updates: 115,658
Cumulative Timesteps: 964,752,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,473.99068
Policy Entropy: 1.75535
Value Function Loss: 0.06544

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.58047
Value Function Update Magnitude: 0.57338

Collected Steps per Second: 20,994.26184
Overall Steps per Second: 10,394.25958

Timestep Collection Time: 2.38198
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.81112

Cumulative Model Updates: 115,664
Cumulative Timesteps: 964,802,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 964802130...
Checkpoint 964802130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,284.27941
Policy Entropy: 1.74850
Value Function Loss: 0.06460

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.58204
Value Function Update Magnitude: 0.56886

Collected Steps per Second: 20,722.27969
Overall Steps per Second: 10,385.99409

Timestep Collection Time: 2.41392
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.81629

Cumulative Model Updates: 115,670
Cumulative Timesteps: 964,852,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,130.05799
Policy Entropy: 1.74793
Value Function Loss: 0.06069

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.57558

Collected Steps per Second: 21,817.46087
Overall Steps per Second: 10,471.52661

Timestep Collection Time: 2.29293
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.77734

Cumulative Model Updates: 115,676
Cumulative Timesteps: 964,902,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 964902178...
Checkpoint 964902178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,721.63543
Policy Entropy: 1.75524
Value Function Loss: 0.06080

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.56543
Value Function Update Magnitude: 0.63036

Collected Steps per Second: 21,490.69233
Overall Steps per Second: 10,543.91583

Timestep Collection Time: 2.32789
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.74473

Cumulative Model Updates: 115,682
Cumulative Timesteps: 964,952,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,281.66875
Policy Entropy: 1.76539
Value Function Loss: 0.06079

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 21,954.44882
Overall Steps per Second: 10,457.36115

Timestep Collection Time: 2.27890
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.78438

Cumulative Model Updates: 115,688
Cumulative Timesteps: 965,002,238

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 965002238...
Checkpoint 965002238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,024.06472
Policy Entropy: 1.76034
Value Function Loss: 0.06507

Mean KL Divergence: 0.01744
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.48858

Collected Steps per Second: 21,867.15796
Overall Steps per Second: 10,560.65149

Timestep Collection Time: 2.28699
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.73550

Cumulative Model Updates: 115,694
Cumulative Timesteps: 965,052,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,497.79635
Policy Entropy: 1.75293
Value Function Loss: 0.06421

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.17545
Policy Update Magnitude: 0.52476
Value Function Update Magnitude: 0.40054

Collected Steps per Second: 22,181.92342
Overall Steps per Second: 10,501.04057

Timestep Collection Time: 2.25598
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.76543

Cumulative Model Updates: 115,700
Cumulative Timesteps: 965,102,290

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 965102290...
Checkpoint 965102290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,544.92045
Policy Entropy: 1.74104
Value Function Loss: 0.06366

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.18260
Policy Update Magnitude: 0.50839
Value Function Update Magnitude: 0.36421

Collected Steps per Second: 21,790.23567
Overall Steps per Second: 10,567.36206

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.73212

Cumulative Model Updates: 115,706
Cumulative Timesteps: 965,152,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,551.07175
Policy Entropy: 1.74407
Value Function Loss: 0.06297

Mean KL Divergence: 0.01959
SB3 Clip Fraction: 0.17944
Policy Update Magnitude: 0.46188
Value Function Update Magnitude: 0.39341

Collected Steps per Second: 22,102.87835
Overall Steps per Second: 10,565.73784

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.47092
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.73379

Cumulative Model Updates: 115,712
Cumulative Timesteps: 965,202,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 965202312...
Checkpoint 965202312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,623.83760
Policy Entropy: 1.75447
Value Function Loss: 0.06217

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.17015
Policy Update Magnitude: 0.46293
Value Function Update Magnitude: 0.50339

Collected Steps per Second: 21,440.85696
Overall Steps per Second: 10,366.22829

Timestep Collection Time: 2.33312
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.82567

Cumulative Model Updates: 115,718
Cumulative Timesteps: 965,252,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,842.76886
Policy Entropy: 1.75058
Value Function Loss: 0.06836

Mean KL Divergence: 0.01584
SB3 Clip Fraction: 0.15691
Policy Update Magnitude: 0.51201
Value Function Update Magnitude: 0.59995

Collected Steps per Second: 22,080.93735
Overall Steps per Second: 10,641.82470

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.69863

Cumulative Model Updates: 115,724
Cumulative Timesteps: 965,302,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 965302338...
Checkpoint 965302338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,934.98805
Policy Entropy: 1.74846
Value Function Loss: 0.07076

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.16361
Policy Update Magnitude: 0.56885
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 21,514.39140
Overall Steps per Second: 10,335.95938

Timestep Collection Time: 2.32514
Timestep Consumption Time: 2.51466
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.83980

Cumulative Model Updates: 115,730
Cumulative Timesteps: 965,352,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,470.24419
Policy Entropy: 1.74114
Value Function Loss: 0.07730

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.18099
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.57063

Collected Steps per Second: 21,741.01540
Overall Steps per Second: 10,156.19654

Timestep Collection Time: 2.30081
Timestep Consumption Time: 2.62446
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 4.92527

Cumulative Model Updates: 115,736
Cumulative Timesteps: 965,402,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 965402384...
Checkpoint 965402384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,356.00234
Policy Entropy: 1.75926
Value Function Loss: 0.07040

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.18605
Policy Update Magnitude: 0.53218
Value Function Update Magnitude: 0.64146

Collected Steps per Second: 21,749.05379
Overall Steps per Second: 10,441.83044

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.79111

Cumulative Model Updates: 115,742
Cumulative Timesteps: 965,452,412

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,326.72700
Policy Entropy: 1.75251
Value Function Loss: 0.07301

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.55926

Collected Steps per Second: 22,176.10078
Overall Steps per Second: 10,465.59125

Timestep Collection Time: 2.25684
Timestep Consumption Time: 2.52530
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.78215

Cumulative Model Updates: 115,748
Cumulative Timesteps: 965,502,460

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 965502460...
Checkpoint 965502460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,512.18925
Policy Entropy: 1.74887
Value Function Loss: 0.07251

Mean KL Divergence: 0.01611
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.60739
Value Function Update Magnitude: 0.55595

Collected Steps per Second: 21,732.85115
Overall Steps per Second: 10,532.81530

Timestep Collection Time: 2.30122
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.74821

Cumulative Model Updates: 115,754
Cumulative Timesteps: 965,552,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,451.66382
Policy Entropy: 1.74491
Value Function Loss: 0.07595

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.15818
Policy Update Magnitude: 0.61560
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 22,244.90345
Overall Steps per Second: 10,586.71167

Timestep Collection Time: 2.24807
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.72366

Cumulative Model Updates: 115,760
Cumulative Timesteps: 965,602,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 965602480...
Checkpoint 965602480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,269.14649
Policy Entropy: 1.75024
Value Function Loss: 0.07674

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.15719
Policy Update Magnitude: 0.61012
Value Function Update Magnitude: 0.53336

Collected Steps per Second: 22,206.45129
Overall Steps per Second: 10,606.99015

Timestep Collection Time: 2.25295
Timestep Consumption Time: 2.46375
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.71670

Cumulative Model Updates: 115,766
Cumulative Timesteps: 965,652,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,886.36773
Policy Entropy: 1.74940
Value Function Loss: 0.06916

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,527.64804
Overall Steps per Second: 10,615.54502

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71290

Cumulative Model Updates: 115,772
Cumulative Timesteps: 965,702,540

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 965702540...
Checkpoint 965702540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,373.74774
Policy Entropy: 1.74478
Value Function Loss: 0.06723

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.57741
Value Function Update Magnitude: 0.51385

Collected Steps per Second: 22,412.96223
Overall Steps per Second: 10,583.24501

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72596

Cumulative Model Updates: 115,778
Cumulative Timesteps: 965,752,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,363.58642
Policy Entropy: 1.74739
Value Function Loss: 0.06697

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.58597
Value Function Update Magnitude: 0.41112

Collected Steps per Second: 22,279.87826
Overall Steps per Second: 10,703.36238

Timestep Collection Time: 2.24427
Timestep Consumption Time: 2.42735
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.67162

Cumulative Model Updates: 115,784
Cumulative Timesteps: 965,802,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 965802558...
Checkpoint 965802558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,393.79216
Policy Entropy: 1.74661
Value Function Loss: 0.06571

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.59174
Value Function Update Magnitude: 0.47589

Collected Steps per Second: 22,045.12039
Overall Steps per Second: 10,662.78677

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.42190
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.69071

Cumulative Model Updates: 115,790
Cumulative Timesteps: 965,852,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,422.47351
Policy Entropy: 1.74428
Value Function Loss: 0.06855

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.59501
Value Function Update Magnitude: 0.52732

Collected Steps per Second: 21,812.63103
Overall Steps per Second: 10,591.58068

Timestep Collection Time: 2.29353
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.72337

Cumulative Model Updates: 115,796
Cumulative Timesteps: 965,902,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 965902602...
Checkpoint 965902602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,707.91224
Policy Entropy: 1.74131
Value Function Loss: 0.06876

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.60052
Value Function Update Magnitude: 0.66667

Collected Steps per Second: 21,805.45697
Overall Steps per Second: 10,564.69509

Timestep Collection Time: 2.29438
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.73558

Cumulative Model Updates: 115,802
Cumulative Timesteps: 965,952,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,713.25802
Policy Entropy: 1.75179
Value Function Loss: 0.06701

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.15062
Policy Update Magnitude: 0.60006
Value Function Update Magnitude: 0.69888

Collected Steps per Second: 21,707.82894
Overall Steps per Second: 10,478.68155

Timestep Collection Time: 2.30424
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.77350

Cumulative Model Updates: 115,808
Cumulative Timesteps: 966,002,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 966002652...
Checkpoint 966002652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,631.15075
Policy Entropy: 1.75670
Value Function Loss: 0.06336

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.15199
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 21,554.88655
Overall Steps per Second: 10,542.01952

Timestep Collection Time: 2.32049
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.74463

Cumulative Model Updates: 115,814
Cumulative Timesteps: 966,052,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,299.78746
Policy Entropy: 1.75069
Value Function Loss: 0.06446

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.15281
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.60042

Collected Steps per Second: 21,513.27924
Overall Steps per Second: 10,494.56349

Timestep Collection Time: 2.32554
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.76723

Cumulative Model Updates: 115,820
Cumulative Timesteps: 966,102,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 966102700...
Checkpoint 966102700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,093.21431
Policy Entropy: 1.74586
Value Function Loss: 0.06664

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.16063
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.61871

Collected Steps per Second: 21,790.83897
Overall Steps per Second: 10,587.07447

Timestep Collection Time: 2.29463
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.72293

Cumulative Model Updates: 115,826
Cumulative Timesteps: 966,152,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,451.99825
Policy Entropy: 1.73779
Value Function Loss: 0.07021

Mean KL Divergence: 0.01889
SB3 Clip Fraction: 0.17621
Policy Update Magnitude: 0.52253
Value Function Update Magnitude: 0.55564

Collected Steps per Second: 20,529.96930
Overall Steps per Second: 10,084.24253

Timestep Collection Time: 2.43576
Timestep Consumption Time: 2.52307
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.95883

Cumulative Model Updates: 115,832
Cumulative Timesteps: 966,202,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 966202708...
Checkpoint 966202708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,185.56136
Policy Entropy: 1.74100
Value Function Loss: 0.06872

Mean KL Divergence: 0.01789
SB3 Clip Fraction: 0.17019
Policy Update Magnitude: 0.48850
Value Function Update Magnitude: 0.64335

Collected Steps per Second: 21,635.10516
Overall Steps per Second: 10,432.87114

Timestep Collection Time: 2.31217
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.79484

Cumulative Model Updates: 115,838
Cumulative Timesteps: 966,252,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,600.65791
Policy Entropy: 1.74995
Value Function Loss: 0.07169

Mean KL Divergence: 0.01813
SB3 Clip Fraction: 0.16790
Policy Update Magnitude: 0.46990
Value Function Update Magnitude: 0.56283

Collected Steps per Second: 21,935.91755
Overall Steps per Second: 10,607.63324

Timestep Collection Time: 2.27937
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.71359

Cumulative Model Updates: 115,844
Cumulative Timesteps: 966,302,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 966302732...
Checkpoint 966302732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,353.51785
Policy Entropy: 1.75177
Value Function Loss: 0.06771

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.15996
Policy Update Magnitude: 0.50790
Value Function Update Magnitude: 0.59385

Collected Steps per Second: 21,965.37737
Overall Steps per Second: 10,640.67306

Timestep Collection Time: 2.27713
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70064

Cumulative Model Updates: 115,850
Cumulative Timesteps: 966,352,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,430.12994
Policy Entropy: 1.74062
Value Function Loss: 0.07062

Mean KL Divergence: 0.01785
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.48461
Value Function Update Magnitude: 0.59990

Collected Steps per Second: 22,166.57980
Overall Steps per Second: 10,571.04476

Timestep Collection Time: 2.25691
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.73255

Cumulative Model Updates: 115,856
Cumulative Timesteps: 966,402,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 966402778...
Checkpoint 966402778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,401.25187
Policy Entropy: 1.74227
Value Function Loss: 0.07479

Mean KL Divergence: 0.01848
SB3 Clip Fraction: 0.16841
Policy Update Magnitude: 0.49366
Value Function Update Magnitude: 0.51608

Collected Steps per Second: 22,153.17640
Overall Steps per Second: 10,550.99050

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.48228
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.73965

Cumulative Model Updates: 115,862
Cumulative Timesteps: 966,452,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,119.62453
Policy Entropy: 1.73962
Value Function Loss: 0.07512

Mean KL Divergence: 0.01880
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.50753
Value Function Update Magnitude: 0.52763

Collected Steps per Second: 21,748.16068
Overall Steps per Second: 10,576.62524

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.42962
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.72986

Cumulative Model Updates: 115,868
Cumulative Timesteps: 966,502,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 966502812...
Checkpoint 966502812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,189.48531
Policy Entropy: 1.75878
Value Function Loss: 0.07193

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.17536
Policy Update Magnitude: 0.50591
Value Function Update Magnitude: 0.69013

Collected Steps per Second: 21,642.78380
Overall Steps per Second: 10,548.94953

Timestep Collection Time: 2.31070
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74076

Cumulative Model Updates: 115,874
Cumulative Timesteps: 966,552,822

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,313.83355
Policy Entropy: 1.75920
Value Function Loss: 0.06625

Mean KL Divergence: 0.01770
SB3 Clip Fraction: 0.16835
Policy Update Magnitude: 0.53388
Value Function Update Magnitude: 0.77658

Collected Steps per Second: 21,405.08900
Overall Steps per Second: 10,475.32192

Timestep Collection Time: 2.33664
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.77465

Cumulative Model Updates: 115,880
Cumulative Timesteps: 966,602,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 966602838...
Checkpoint 966602838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,465.51937
Policy Entropy: 1.76742
Value Function Loss: 0.06494

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.16705
Policy Update Magnitude: 0.56954
Value Function Update Magnitude: 0.70187

Collected Steps per Second: 21,584.35146
Overall Steps per Second: 10,657.36299

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.37614
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.69366

Cumulative Model Updates: 115,886
Cumulative Timesteps: 966,652,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,423.18825
Policy Entropy: 1.75634
Value Function Loss: 0.06499

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.16575
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.61366

Collected Steps per Second: 21,178.28891
Overall Steps per Second: 10,438.81692

Timestep Collection Time: 2.36119
Timestep Consumption Time: 2.42920
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.79039

Cumulative Model Updates: 115,892
Cumulative Timesteps: 966,702,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 966702866...
Checkpoint 966702866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,414.75314
Policy Entropy: 1.75197
Value Function Loss: 0.06321

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.15055
Policy Update Magnitude: 0.59810
Value Function Update Magnitude: 0.67670

Collected Steps per Second: 21,816.68748
Overall Steps per Second: 10,628.03370

Timestep Collection Time: 2.29228
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.70548

Cumulative Model Updates: 115,898
Cumulative Timesteps: 966,752,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,593.19952
Policy Entropy: 1.73260
Value Function Loss: 0.06244

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.14465
Policy Update Magnitude: 0.59934
Value Function Update Magnitude: 0.61358

Collected Steps per Second: 21,724.05705
Overall Steps per Second: 10,444.22356

Timestep Collection Time: 2.30279
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.78982

Cumulative Model Updates: 115,904
Cumulative Timesteps: 966,802,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 966802902...
Checkpoint 966802902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,139.96294
Policy Entropy: 1.73624
Value Function Loss: 0.06714

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.60008
Value Function Update Magnitude: 0.49732

Collected Steps per Second: 21,791.85447
Overall Steps per Second: 10,612.34522

Timestep Collection Time: 2.29563
Timestep Consumption Time: 2.41832
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.71394

Cumulative Model Updates: 115,910
Cumulative Timesteps: 966,852,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,553.17156
Policy Entropy: 1.73304
Value Function Loss: 0.06930

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.59752
Value Function Update Magnitude: 0.64728

Collected Steps per Second: 22,255.07802
Overall Steps per Second: 10,474.14882

Timestep Collection Time: 2.24767
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.77576

Cumulative Model Updates: 115,916
Cumulative Timesteps: 966,902,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 966902950...
Checkpoint 966902950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,268.57408
Policy Entropy: 1.75184
Value Function Loss: 0.07625

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.15445
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.72094

Collected Steps per Second: 21,970.32210
Overall Steps per Second: 10,601.83370

Timestep Collection Time: 2.27662
Timestep Consumption Time: 2.44125
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.71786

Cumulative Model Updates: 115,922
Cumulative Timesteps: 966,952,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,878.39457
Policy Entropy: 1.75179
Value Function Loss: 0.07403

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.15027
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.65216

Collected Steps per Second: 22,296.79348
Overall Steps per Second: 10,525.91710

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.50891
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.75246

Cumulative Model Updates: 115,928
Cumulative Timesteps: 967,002,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 967002992...
Checkpoint 967002992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,937.38339
Policy Entropy: 1.76071
Value Function Loss: 0.06950

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.15203
Policy Update Magnitude: 0.57451
Value Function Update Magnitude: 0.66136

Collected Steps per Second: 22,372.43068
Overall Steps per Second: 10,631.47184

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.70321

Cumulative Model Updates: 115,934
Cumulative Timesteps: 967,052,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,816.53326
Policy Entropy: 1.75310
Value Function Loss: 0.06196

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.57363
Value Function Update Magnitude: 0.64594

Collected Steps per Second: 22,257.81257
Overall Steps per Second: 10,522.64806

Timestep Collection Time: 2.24730
Timestep Consumption Time: 2.50626
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75356

Cumulative Model Updates: 115,940
Cumulative Timesteps: 967,103,014

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 967103014...
Checkpoint 967103014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,383.68503
Policy Entropy: 1.75313
Value Function Loss: 0.06087

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.58354

Collected Steps per Second: 22,200.12290
Overall Steps per Second: 10,563.49741

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.48183
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.73480

Cumulative Model Updates: 115,946
Cumulative Timesteps: 967,153,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,995.37650
Policy Entropy: 1.75542
Value Function Loss: 0.06035

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.13862
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.53510

Collected Steps per Second: 22,037.98361
Overall Steps per Second: 10,541.19894

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.74652

Cumulative Model Updates: 115,952
Cumulative Timesteps: 967,203,064

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 967203064...
Checkpoint 967203064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,895.32915
Policy Entropy: 1.74884
Value Function Loss: 0.06103

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.57784
Value Function Update Magnitude: 0.51917

Collected Steps per Second: 21,692.78093
Overall Steps per Second: 10,560.17360

Timestep Collection Time: 2.30639
Timestep Consumption Time: 2.43141
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.73780

Cumulative Model Updates: 115,958
Cumulative Timesteps: 967,253,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,371.60851
Policy Entropy: 1.74220
Value Function Loss: 0.06467

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.14772
Policy Update Magnitude: 0.57799
Value Function Update Magnitude: 0.49693

Collected Steps per Second: 21,860.05536
Overall Steps per Second: 10,430.45073

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.50768
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.79615

Cumulative Model Updates: 115,964
Cumulative Timesteps: 967,303,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 967303122...
Checkpoint 967303122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,614.95299
Policy Entropy: 1.74406
Value Function Loss: 0.06518

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.51398
Value Function Update Magnitude: 0.54277

Collected Steps per Second: 21,925.50012
Overall Steps per Second: 10,609.94069

Timestep Collection Time: 2.28100
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.71369

Cumulative Model Updates: 115,970
Cumulative Timesteps: 967,353,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,748.57834
Policy Entropy: 1.74391
Value Function Loss: 0.06756

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.14067
Policy Update Magnitude: 0.51994
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 22,146.64031
Overall Steps per Second: 10,533.27007

Timestep Collection Time: 2.25786
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.74724

Cumulative Model Updates: 115,976
Cumulative Timesteps: 967,403,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 967403138...
Checkpoint 967403138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,298.57822
Policy Entropy: 1.74860
Value Function Loss: 0.06492

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.58429
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 22,220.37909
Overall Steps per Second: 10,606.85940

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.71563

Cumulative Model Updates: 115,982
Cumulative Timesteps: 967,453,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,381.29669
Policy Entropy: 1.74772
Value Function Loss: 0.06928

Mean KL Divergence: 0.01892
SB3 Clip Fraction: 0.17264
Policy Update Magnitude: 0.58963
Value Function Update Magnitude: 0.57328

Collected Steps per Second: 22,339.92416
Overall Steps per Second: 10,525.16309

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.75223

Cumulative Model Updates: 115,988
Cumulative Timesteps: 967,503,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 967503174...
Checkpoint 967503174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,681.74938
Policy Entropy: 1.75378
Value Function Loss: 0.06952

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.17617
Policy Update Magnitude: 0.53084
Value Function Update Magnitude: 0.64731

Collected Steps per Second: 22,167.26084
Overall Steps per Second: 10,557.57699

Timestep Collection Time: 2.25738
Timestep Consumption Time: 2.48234
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73972

Cumulative Model Updates: 115,994
Cumulative Timesteps: 967,553,214

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,244.30508
Policy Entropy: 1.75798
Value Function Loss: 0.06626

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.15777
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.69119

Collected Steps per Second: 22,123.78134
Overall Steps per Second: 10,448.99050

Timestep Collection Time: 2.26218
Timestep Consumption Time: 2.52756
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.78975

Cumulative Model Updates: 116,000
Cumulative Timesteps: 967,603,262

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 967603262...
Checkpoint 967603262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,382.06851
Policy Entropy: 1.76005
Value Function Loss: 0.06548

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.60206

Collected Steps per Second: 22,228.76619
Overall Steps per Second: 10,706.28729

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.67239

Cumulative Model Updates: 116,006
Cumulative Timesteps: 967,653,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,405.24045
Policy Entropy: 1.76903
Value Function Loss: 0.06189

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.56039
Value Function Update Magnitude: 0.61049

Collected Steps per Second: 22,076.34416
Overall Steps per Second: 10,458.04108

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.51715
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.78292

Cumulative Model Updates: 116,012
Cumulative Timesteps: 967,703,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 967703306...
Checkpoint 967703306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,951.30006
Policy Entropy: 1.76834
Value Function Loss: 0.06666

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.14302
Policy Update Magnitude: 0.58099
Value Function Update Magnitude: 0.64954

Collected Steps per Second: 21,819.99910
Overall Steps per Second: 10,655.29375

Timestep Collection Time: 2.29193
Timestep Consumption Time: 2.40151
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.69344

Cumulative Model Updates: 116,018
Cumulative Timesteps: 967,753,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,692.26715
Policy Entropy: 1.77420
Value Function Loss: 0.06328

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.59635
Value Function Update Magnitude: 0.58252

Collected Steps per Second: 21,947.89715
Overall Steps per Second: 10,454.88860

Timestep Collection Time: 2.27931
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.78494

Cumulative Model Updates: 116,024
Cumulative Timesteps: 967,803,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 967803342...
Checkpoint 967803342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,551.86494
Policy Entropy: 1.76296
Value Function Loss: 0.06542

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.58889
Value Function Update Magnitude: 0.50300

Collected Steps per Second: 21,872.48998
Overall Steps per Second: 10,557.87462

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.73732

Cumulative Model Updates: 116,030
Cumulative Timesteps: 967,853,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,938.43015
Policy Entropy: 1.75560
Value Function Loss: 0.06741

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.58829
Value Function Update Magnitude: 0.43160

Collected Steps per Second: 22,087.88058
Overall Steps per Second: 10,459.56592

Timestep Collection Time: 2.26441
Timestep Consumption Time: 2.51743
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.78184

Cumulative Model Updates: 116,036
Cumulative Timesteps: 967,903,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 967903374...
Checkpoint 967903374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,707.04819
Policy Entropy: 1.75088
Value Function Loss: 0.08085

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.59584
Value Function Update Magnitude: 0.34233

Collected Steps per Second: 21,576.16062
Overall Steps per Second: 10,392.66275

Timestep Collection Time: 2.31811
Timestep Consumption Time: 2.49451
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.81263

Cumulative Model Updates: 116,042
Cumulative Timesteps: 967,953,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,641.41531
Policy Entropy: 1.74751
Value Function Loss: 0.08195

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.14310
Policy Update Magnitude: 0.58187
Value Function Update Magnitude: 0.28749

Collected Steps per Second: 22,222.88477
Overall Steps per Second: 10,664.22260

Timestep Collection Time: 2.25056
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.68989

Cumulative Model Updates: 116,048
Cumulative Timesteps: 968,003,404

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 968003404...
Checkpoint 968003404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,060.66187
Policy Entropy: 1.74354
Value Function Loss: 0.08085

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.14119
Policy Update Magnitude: 0.60008
Value Function Update Magnitude: 0.32061

Collected Steps per Second: 22,028.60936
Overall Steps per Second: 10,649.38988

Timestep Collection Time: 2.27077
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.69717

Cumulative Model Updates: 116,054
Cumulative Timesteps: 968,053,426

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,473.23527
Policy Entropy: 1.74942
Value Function Loss: 0.07807

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.58980
Value Function Update Magnitude: 0.33124

Collected Steps per Second: 21,464.60642
Overall Steps per Second: 10,488.17794

Timestep Collection Time: 2.33025
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.76899

Cumulative Model Updates: 116,060
Cumulative Timesteps: 968,103,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 968103444...
Checkpoint 968103444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,173.39425
Policy Entropy: 1.75546
Value Function Loss: 0.07531

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.18762
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.36323

Collected Steps per Second: 21,630.82623
Overall Steps per Second: 10,562.63254

Timestep Collection Time: 2.31189
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.73443

Cumulative Model Updates: 116,066
Cumulative Timesteps: 968,153,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,146.17202
Policy Entropy: 1.76317
Value Function Loss: 0.06897

Mean KL Divergence: 0.02106
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.51127
Value Function Update Magnitude: 0.43894

Collected Steps per Second: 21,627.04736
Overall Steps per Second: 10,550.01745

Timestep Collection Time: 2.31210
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.73971

Cumulative Model Updates: 116,072
Cumulative Timesteps: 968,203,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 968203456...
Checkpoint 968203456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,816.07722
Policy Entropy: 1.75574
Value Function Loss: 0.06483

Mean KL Divergence: 0.02285
SB3 Clip Fraction: 0.18530
Policy Update Magnitude: 0.48040
Value Function Update Magnitude: 0.47700

Collected Steps per Second: 21,745.88368
Overall Steps per Second: 10,546.50644

Timestep Collection Time: 2.30002
Timestep Consumption Time: 2.44240
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.74242

Cumulative Model Updates: 116,078
Cumulative Timesteps: 968,253,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,556.61266
Policy Entropy: 1.75527
Value Function Loss: 0.06759

Mean KL Divergence: 0.03198
SB3 Clip Fraction: 0.22041
Policy Update Magnitude: 0.43659
Value Function Update Magnitude: 0.44587

Collected Steps per Second: 22,166.45853
Overall Steps per Second: 10,540.61280

Timestep Collection Time: 2.25710
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.74659

Cumulative Model Updates: 116,084
Cumulative Timesteps: 968,303,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 968303504...
Checkpoint 968303504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,572.87985
Policy Entropy: 1.76390
Value Function Loss: 0.07100

Mean KL Divergence: 0.01953
SB3 Clip Fraction: 0.16479
Policy Update Magnitude: 0.51667
Value Function Update Magnitude: 0.41380

Collected Steps per Second: 22,155.46967
Overall Steps per Second: 10,621.83453

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.45139
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.70898

Cumulative Model Updates: 116,090
Cumulative Timesteps: 968,353,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,175.90129
Policy Entropy: 1.76075
Value Function Loss: 0.06714

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.15250
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.51707

Collected Steps per Second: 22,108.95102
Overall Steps per Second: 10,467.87207

Timestep Collection Time: 2.26261
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.77881

Cumulative Model Updates: 116,096
Cumulative Timesteps: 968,403,546

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 968403546...
Checkpoint 968403546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,040.98240
Policy Entropy: 1.75152
Value Function Loss: 0.06472

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.14743
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.39890

Collected Steps per Second: 21,807.42841
Overall Steps per Second: 10,598.44469

Timestep Collection Time: 2.29353
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71918

Cumulative Model Updates: 116,102
Cumulative Timesteps: 968,453,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,480.81714
Policy Entropy: 1.74742
Value Function Loss: 0.06903

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.15268
Policy Update Magnitude: 0.59256
Value Function Update Magnitude: 0.40403

Collected Steps per Second: 22,305.20353
Overall Steps per Second: 10,510.21348

Timestep Collection Time: 2.24163
Timestep Consumption Time: 2.51565
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.75728

Cumulative Model Updates: 116,108
Cumulative Timesteps: 968,503,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968503562...
Checkpoint 968503562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,810.21073
Policy Entropy: 1.73908
Value Function Loss: 0.07034

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.15342
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.36756

Collected Steps per Second: 22,096.64390
Overall Steps per Second: 10,684.34277

Timestep Collection Time: 2.26306
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.68031

Cumulative Model Updates: 116,114
Cumulative Timesteps: 968,553,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,861.89385
Policy Entropy: 1.73849
Value Function Loss: 0.07121

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.42085

Collected Steps per Second: 21,064.82102
Overall Steps per Second: 10,411.73769

Timestep Collection Time: 2.37410
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.80323

Cumulative Model Updates: 116,120
Cumulative Timesteps: 968,603,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 968603578...
Checkpoint 968603578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,033.79223
Policy Entropy: 1.74073
Value Function Loss: 0.07608

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.14293
Policy Update Magnitude: 0.59064
Value Function Update Magnitude: 0.47803

Collected Steps per Second: 20,953.14007
Overall Steps per Second: 10,567.04835

Timestep Collection Time: 2.38800
Timestep Consumption Time: 2.34710
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.73510

Cumulative Model Updates: 116,126
Cumulative Timesteps: 968,653,614

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,743.38991
Policy Entropy: 1.74952
Value Function Loss: 0.07614

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.15697
Policy Update Magnitude: 0.61004
Value Function Update Magnitude: 0.47741

Collected Steps per Second: 21,054.75676
Overall Steps per Second: 10,562.93790

Timestep Collection Time: 2.37552
Timestep Consumption Time: 2.35953
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.73505

Cumulative Model Updates: 116,132
Cumulative Timesteps: 968,703,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 968703630...
Checkpoint 968703630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,134.66473
Policy Entropy: 1.76677
Value Function Loss: 0.08045

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.59414
Value Function Update Magnitude: 0.36385

Collected Steps per Second: 20,719.98124
Overall Steps per Second: 10,483.72796

Timestep Collection Time: 2.41390
Timestep Consumption Time: 2.35692
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.77082

Cumulative Model Updates: 116,138
Cumulative Timesteps: 968,753,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,271.92309
Policy Entropy: 1.75497
Value Function Loss: 0.07115

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.28097

Collected Steps per Second: 21,508.84413
Overall Steps per Second: 10,488.78647

Timestep Collection Time: 2.32556
Timestep Consumption Time: 2.44335
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.76890

Cumulative Model Updates: 116,144
Cumulative Timesteps: 968,803,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 968803666...
Checkpoint 968803666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,061.18135
Policy Entropy: 1.75245
Value Function Loss: 0.08145

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.24580

Collected Steps per Second: 21,764.67691
Overall Steps per Second: 10,612.84118

Timestep Collection Time: 2.29794
Timestep Consumption Time: 2.41465
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.71259

Cumulative Model Updates: 116,150
Cumulative Timesteps: 968,853,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,193.25675
Policy Entropy: 1.73772
Value Function Loss: 0.09154

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.23161

Collected Steps per Second: 22,206.25178
Overall Steps per Second: 10,521.65496

Timestep Collection Time: 2.25180
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.75248

Cumulative Model Updates: 116,156
Cumulative Timesteps: 968,903,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 968903684...
Checkpoint 968903684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,516.59924
Policy Entropy: 1.76029
Value Function Loss: 0.09626

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.61978
Value Function Update Magnitude: 0.24347

Collected Steps per Second: 22,012.58664
Overall Steps per Second: 10,636.73726

Timestep Collection Time: 2.27215
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.70219

Cumulative Model Updates: 116,162
Cumulative Timesteps: 968,953,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,989.08355
Policy Entropy: 1.75770
Value Function Loss: 0.08733

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.29295

Collected Steps per Second: 22,203.86645
Overall Steps per Second: 10,583.85730

Timestep Collection Time: 2.25312
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.72682

Cumulative Model Updates: 116,168
Cumulative Timesteps: 969,003,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 969003728...
Checkpoint 969003728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,576.73796
Policy Entropy: 1.76051
Value Function Loss: 0.07732

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.17759
Policy Update Magnitude: 0.52821
Value Function Update Magnitude: 0.40984

Collected Steps per Second: 22,054.64781
Overall Steps per Second: 10,525.81128

Timestep Collection Time: 2.26837
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.75289

Cumulative Model Updates: 116,174
Cumulative Timesteps: 969,053,756

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,433.80290
Policy Entropy: 1.74788
Value Function Loss: 0.07136

Mean KL Divergence: 0.01663
SB3 Clip Fraction: 0.16598
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.54279

Collected Steps per Second: 22,249.93143
Overall Steps per Second: 10,499.22684

Timestep Collection Time: 2.24747
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76283

Cumulative Model Updates: 116,180
Cumulative Timesteps: 969,103,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 969103762...
Checkpoint 969103762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,534.90633
Policy Entropy: 1.75504
Value Function Loss: 0.07057

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.16284
Policy Update Magnitude: 0.58610
Value Function Update Magnitude: 0.46019

Collected Steps per Second: 21,757.76520
Overall Steps per Second: 10,559.05550

Timestep Collection Time: 2.29877
Timestep Consumption Time: 2.43802
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.73679

Cumulative Model Updates: 116,186
Cumulative Timesteps: 969,153,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,899.28098
Policy Entropy: 1.74329
Value Function Loss: 0.06645

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.16192
Policy Update Magnitude: 0.57421
Value Function Update Magnitude: 0.37226

Collected Steps per Second: 22,183.14761
Overall Steps per Second: 10,486.94563

Timestep Collection Time: 2.25477
Timestep Consumption Time: 2.51477
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.76955

Cumulative Model Updates: 116,192
Cumulative Timesteps: 969,203,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 969203796...
Checkpoint 969203796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,037.95472
Policy Entropy: 1.73128
Value Function Loss: 0.07238

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.14923
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.31408

Collected Steps per Second: 21,366.48820
Overall Steps per Second: 10,309.30278

Timestep Collection Time: 2.34114
Timestep Consumption Time: 2.51098
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.85212

Cumulative Model Updates: 116,198
Cumulative Timesteps: 969,253,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,328.54580
Policy Entropy: 1.72961
Value Function Loss: 0.07385

Mean KL Divergence: 0.01410
SB3 Clip Fraction: 0.14606
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.26037

Collected Steps per Second: 22,673.01112
Overall Steps per Second: 10,737.22652

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.65856

Cumulative Model Updates: 116,204
Cumulative Timesteps: 969,303,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 969303838...
Checkpoint 969303838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,493.94499
Policy Entropy: 1.72193
Value Function Loss: 0.08086

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.15672
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.25384

Collected Steps per Second: 22,169.46437
Overall Steps per Second: 10,630.27667

Timestep Collection Time: 2.25635
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70562

Cumulative Model Updates: 116,210
Cumulative Timesteps: 969,353,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,102.73586
Policy Entropy: 1.73770
Value Function Loss: 0.07858

Mean KL Divergence: 0.02186
SB3 Clip Fraction: 0.18774
Policy Update Magnitude: 0.50200
Value Function Update Magnitude: 0.26717

Collected Steps per Second: 22,355.34874
Overall Steps per Second: 10,535.81729

Timestep Collection Time: 2.23687
Timestep Consumption Time: 2.50942
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.74629

Cumulative Model Updates: 116,216
Cumulative Timesteps: 969,403,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 969403866...
Checkpoint 969403866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,171.61130
Policy Entropy: 1.73759
Value Function Loss: 0.07143

Mean KL Divergence: 0.01749
SB3 Clip Fraction: 0.16640
Policy Update Magnitude: 0.54279
Value Function Update Magnitude: 0.44796

Collected Steps per Second: 21,779.40814
Overall Steps per Second: 10,571.99571

Timestep Collection Time: 2.29575
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.72948

Cumulative Model Updates: 116,222
Cumulative Timesteps: 969,453,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,270.96363
Policy Entropy: 1.76108
Value Function Loss: 0.06450

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.16179
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.51958

Collected Steps per Second: 22,401.44172
Overall Steps per Second: 10,548.51742

Timestep Collection Time: 2.23245
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.74095

Cumulative Model Updates: 116,228
Cumulative Timesteps: 969,503,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 969503876...
Checkpoint 969503876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,597.43683
Policy Entropy: 1.75620
Value Function Loss: 0.05725

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15784
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.54121

Collected Steps per Second: 21,933.47964
Overall Steps per Second: 10,574.69247

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.44963
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.73016

Cumulative Model Updates: 116,234
Cumulative Timesteps: 969,553,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,215.92619
Policy Entropy: 1.76650
Value Function Loss: 0.05966

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.52467

Collected Steps per Second: 22,061.31983
Overall Steps per Second: 10,486.61817

Timestep Collection Time: 2.26659
Timestep Consumption Time: 2.50177
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.76836

Cumulative Model Updates: 116,240
Cumulative Timesteps: 969,603,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 969603900...
Checkpoint 969603900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,374.64944
Policy Entropy: 1.75879
Value Function Loss: 0.06380

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.58503
Value Function Update Magnitude: 0.42754

Collected Steps per Second: 21,608.54638
Overall Steps per Second: 10,562.31188

Timestep Collection Time: 2.31492
Timestep Consumption Time: 2.42098
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.73589

Cumulative Model Updates: 116,246
Cumulative Timesteps: 969,653,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,879.38569
Policy Entropy: 1.76858
Value Function Loss: 0.06481

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.58270
Value Function Update Magnitude: 0.39794

Collected Steps per Second: 21,689.18929
Overall Steps per Second: 10,515.99352

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.45152
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.75885

Cumulative Model Updates: 116,252
Cumulative Timesteps: 969,703,966

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 969703966...
Checkpoint 969703966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,358.44651
Policy Entropy: 1.76504
Value Function Loss: 0.07760

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.59504
Value Function Update Magnitude: 0.33233

Collected Steps per Second: 21,548.40523
Overall Steps per Second: 10,374.56882

Timestep Collection Time: 2.32082
Timestep Consumption Time: 2.49962
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.82044

Cumulative Model Updates: 116,258
Cumulative Timesteps: 969,753,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,348.30450
Policy Entropy: 1.77668
Value Function Loss: 0.08522

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.14962
Policy Update Magnitude: 0.59389
Value Function Update Magnitude: 0.27320

Collected Steps per Second: 22,271.32025
Overall Steps per Second: 10,652.00106

Timestep Collection Time: 2.24594
Timestep Consumption Time: 2.44989
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69583

Cumulative Model Updates: 116,264
Cumulative Timesteps: 969,803,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 969803996...
Checkpoint 969803996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,952.20538
Policy Entropy: 1.77219
Value Function Loss: 0.07990

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.14669
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.24518

Collected Steps per Second: 21,835.17039
Overall Steps per Second: 10,618.05020

Timestep Collection Time: 2.29117
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.71160

Cumulative Model Updates: 116,270
Cumulative Timesteps: 969,854,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,535.38767
Policy Entropy: 1.76908
Value Function Loss: 0.06605

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.14576
Policy Update Magnitude: 0.57898
Value Function Update Magnitude: 0.27067

Collected Steps per Second: 22,381.11219
Overall Steps per Second: 10,552.52784

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.74161

Cumulative Model Updates: 116,276
Cumulative Timesteps: 969,904,060

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 969904060...
Checkpoint 969904060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,890.13127
Policy Entropy: 1.75588
Value Function Loss: 0.05657

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.37059

Collected Steps per Second: 21,650.60090
Overall Steps per Second: 10,337.24214

Timestep Collection Time: 2.30950
Timestep Consumption Time: 2.52758
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.83707

Cumulative Model Updates: 116,282
Cumulative Timesteps: 969,954,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,020.15115
Policy Entropy: 1.75233
Value Function Loss: 0.05782

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.14463
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.46259

Collected Steps per Second: 22,462.37005
Overall Steps per Second: 10,728.38702

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.43488
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.66109

Cumulative Model Updates: 116,288
Cumulative Timesteps: 970,004,068

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 970004068...
Checkpoint 970004068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,989.10890
Policy Entropy: 1.74681
Value Function Loss: 0.06062

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.56419
Value Function Update Magnitude: 0.43909

Collected Steps per Second: 22,156.71577
Overall Steps per Second: 10,708.55434

Timestep Collection Time: 2.25728
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.67047

Cumulative Model Updates: 116,294
Cumulative Timesteps: 970,054,082

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,911.98540
Policy Entropy: 1.74245
Value Function Loss: 0.06438

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.42301

Collected Steps per Second: 22,250.25965
Overall Steps per Second: 10,559.06969

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.48949
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.73792

Cumulative Model Updates: 116,300
Cumulative Timesteps: 970,104,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 970104110...
Checkpoint 970104110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,518.65273
Policy Entropy: 1.74885
Value Function Loss: 0.06769

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.57972
Value Function Update Magnitude: 0.32136

Collected Steps per Second: 21,004.50943
Overall Steps per Second: 10,555.69805

Timestep Collection Time: 2.38196
Timestep Consumption Time: 2.35785
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.73981

Cumulative Model Updates: 116,306
Cumulative Timesteps: 970,154,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,347.41160
Policy Entropy: 1.75664
Value Function Loss: 0.06399

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 21,379.83037
Overall Steps per Second: 10,499.84241

Timestep Collection Time: 2.33968
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76407

Cumulative Model Updates: 116,312
Cumulative Timesteps: 970,204,164

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 970204164...
Checkpoint 970204164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,328.64442
Policy Entropy: 1.76139
Value Function Loss: 0.05852

Mean KL Divergence: 0.01907
SB3 Clip Fraction: 0.17558
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.46991

Collected Steps per Second: 21,000.55317
Overall Steps per Second: 9,807.01027

Timestep Collection Time: 2.38098
Timestep Consumption Time: 2.71761
PPO Batch Consumption Time: 0.33900
Total Iteration Time: 5.09860

Cumulative Model Updates: 116,318
Cumulative Timesteps: 970,254,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,230.65188
Policy Entropy: 1.75897
Value Function Loss: 0.05684

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.51763
Value Function Update Magnitude: 0.44706

Collected Steps per Second: 9,909.22806
Overall Steps per Second: 6,526.71305

Timestep Collection Time: 5.04943
Timestep Consumption Time: 2.61691
PPO Batch Consumption Time: 0.30693
Total Iteration Time: 7.66634

Cumulative Model Updates: 116,324
Cumulative Timesteps: 970,304,202

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 970304202...
Checkpoint 970304202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,812.80842
Policy Entropy: 1.76205
Value Function Loss: 0.05915

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.17648
Policy Update Magnitude: 0.52619
Value Function Update Magnitude: 0.38120

Collected Steps per Second: 15,987.64519
Overall Steps per Second: 8,822.42689

Timestep Collection Time: 3.12792
Timestep Consumption Time: 2.54037
PPO Batch Consumption Time: 0.30582
Total Iteration Time: 5.66828

Cumulative Model Updates: 116,330
Cumulative Timesteps: 970,354,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,550.25080
Policy Entropy: 1.76361
Value Function Loss: 0.05632

Mean KL Divergence: 0.01850
SB3 Clip Fraction: 0.17163
Policy Update Magnitude: 0.47200
Value Function Update Magnitude: 0.44096

Collected Steps per Second: 18,782.35127
Overall Steps per Second: 9,655.41148

Timestep Collection Time: 2.66346
Timestep Consumption Time: 2.51768
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 5.18114

Cumulative Model Updates: 116,336
Cumulative Timesteps: 970,404,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 970404236...
Checkpoint 970404236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,872.41137
Policy Entropy: 1.75916
Value Function Loss: 0.05283

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.50956
Value Function Update Magnitude: 0.59835

Collected Steps per Second: 19,026.61204
Overall Steps per Second: 9,333.20516

Timestep Collection Time: 2.62905
Timestep Consumption Time: 2.73052
PPO Batch Consumption Time: 0.32368
Total Iteration Time: 5.35957

Cumulative Model Updates: 116,342
Cumulative Timesteps: 970,454,258

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,484.03431
Policy Entropy: 1.75209
Value Function Loss: 0.05058

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.63593

Collected Steps per Second: 19,365.44910
Overall Steps per Second: 9,864.82838

Timestep Collection Time: 2.58243
Timestep Consumption Time: 2.48709
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 5.06953

Cumulative Model Updates: 116,348
Cumulative Timesteps: 970,504,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 970504268...
Checkpoint 970504268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,521.10764
Policy Entropy: 1.75534
Value Function Loss: 0.05720

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.62660

Collected Steps per Second: 20,282.31029
Overall Steps per Second: 10,003.07895

Timestep Collection Time: 2.46520
Timestep Consumption Time: 2.53326
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.99846

Cumulative Model Updates: 116,354
Cumulative Timesteps: 970,554,268

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,359.34662
Policy Entropy: 1.75465
Value Function Loss: 0.06397

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.14128
Policy Update Magnitude: 0.58324
Value Function Update Magnitude: 0.49500

Collected Steps per Second: 19,487.89244
Overall Steps per Second: 9,526.14268

Timestep Collection Time: 2.56641
Timestep Consumption Time: 2.68377
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 5.25018

Cumulative Model Updates: 116,360
Cumulative Timesteps: 970,604,282

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 970604282...
Checkpoint 970604282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,611.80696
Policy Entropy: 1.75871
Value Function Loss: 0.06760

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.59171
Value Function Update Magnitude: 0.46630

Collected Steps per Second: 18,890.55160
Overall Steps per Second: 9,727.20377

Timestep Collection Time: 2.64736
Timestep Consumption Time: 2.49390
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 5.14125

Cumulative Model Updates: 116,366
Cumulative Timesteps: 970,654,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,618.86222
Policy Entropy: 1.74793
Value Function Loss: 0.06342

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.14711
Policy Update Magnitude: 0.58498
Value Function Update Magnitude: 0.62983

Collected Steps per Second: 18,913.22804
Overall Steps per Second: 9,744.39941

Timestep Collection Time: 2.64534
Timestep Consumption Time: 2.48909
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 5.13444

Cumulative Model Updates: 116,372
Cumulative Timesteps: 970,704,324

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 970704324...
Checkpoint 970704324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,716.59645
Policy Entropy: 1.75456
Value Function Loss: 0.06251

Mean KL Divergence: 0.02089
SB3 Clip Fraction: 0.18593
Policy Update Magnitude: 0.52889
Value Function Update Magnitude: 0.66959

Collected Steps per Second: 17,748.05582
Overall Steps per Second: 9,072.91479

Timestep Collection Time: 2.81800
Timestep Consumption Time: 2.69445
PPO Batch Consumption Time: 0.30473
Total Iteration Time: 5.51245

Cumulative Model Updates: 116,378
Cumulative Timesteps: 970,754,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,083.85965
Policy Entropy: 1.77071
Value Function Loss: 0.06126

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.17545
Policy Update Magnitude: 0.55023
Value Function Update Magnitude: 0.71398

Collected Steps per Second: 17,986.80177
Overall Steps per Second: 9,262.02668

Timestep Collection Time: 2.78037
Timestep Consumption Time: 2.61909
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 5.39947

Cumulative Model Updates: 116,384
Cumulative Timesteps: 970,804,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 970804348...
Checkpoint 970804348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,900.48335
Policy Entropy: 1.78444
Value Function Loss: 0.06121

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.17904
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.66223

Collected Steps per Second: 16,610.99726
Overall Steps per Second: 8,943.48484

Timestep Collection Time: 3.01138
Timestep Consumption Time: 2.58174
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 5.59312

Cumulative Model Updates: 116,390
Cumulative Timesteps: 970,854,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,128.56366
Policy Entropy: 1.78673
Value Function Loss: 0.06628

Mean KL Divergence: 0.01676
SB3 Clip Fraction: 0.16114
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.51030

Collected Steps per Second: 13,895.34055
Overall Steps per Second: 7,041.38697

Timestep Collection Time: 3.60178
Timestep Consumption Time: 3.50591
PPO Batch Consumption Time: 0.46002
Total Iteration Time: 7.10769

Cumulative Model Updates: 116,396
Cumulative Timesteps: 970,904,418

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 970904418...


LEARNING LOOP ENCOUNTERED AN ERROR
Traceback (most recent call last):
  File "d:\RLRL\.venv\lib\site-packages\rlgym_ppo\learner.py", line 225, in learn
    self._learn()
  File "d:\RLRL\.venv\lib\site-packages\rlgym_ppo\learner.py", line 325, in _learn
    self.save(self.agent.cumulative_timesteps)
  File "d:\RLRL\.venv\lib\site-packages\rlgym_ppo\learner.py", line 410, in save
    shutil.rmtree(
  File "C:\Users\joalb\AppData\Local\Programs\Python\Python39\lib\shutil.py", line 749, in rmtree
    return _rmtree_unsafe(path, onerror)
  File "C:\Users\joalb\AppData\Local\Programs\Python\Python39\lib\shutil.py", line 631, in _rmtree_unsafe
    onerror(os.rmdir, path, sys.exc_info())
  File "C:\Users\joalb\AppData\Local\Programs\Python\Python39\lib\shutil.py", line 629, in _rmtree_unsafe
    os.rmdir(path)
PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'data\\checkpoints\\rlgym-ppo-run\\970404236'

Saving checkpoint 970904418...
FAILED TO SAVE ON EXIT
