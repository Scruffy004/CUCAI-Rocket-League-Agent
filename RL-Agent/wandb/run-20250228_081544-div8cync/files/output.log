Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.28720
Policy Entropy: 4.17884
Value Function Loss: 0.04177

Mean KL Divergence: 0.00033
SB3 Clip Fraction: 0.00143
Policy Update Magnitude: 0.26140
Value Function Update Magnitude: 0.27097

Collected Steps per Second: 18,590.79114
Overall Steps per Second: 11,844.97862

Timestep Collection Time: 2.69176
Timestep Consumption Time: 1.53298
PPO Batch Consumption Time: 0.34559
Total Iteration Time: 4.22474

Cumulative Model Updates: 146,314
Cumulative Timesteps: 1,220,061,540

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185.40719
Policy Entropy: 4.01803
Value Function Loss: 0.03768

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04331
Policy Update Magnitude: 0.72361
Value Function Update Magnitude: 0.65582

Collected Steps per Second: 21,184.38271
Overall Steps per Second: 11,402.52909

Timestep Collection Time: 2.36061
Timestep Consumption Time: 2.02509
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 4.38569

Cumulative Model Updates: 146,318
Cumulative Timesteps: 1,220,111,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1220111548...
Checkpoint 1220111548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.48307
Policy Entropy: 3.93721
Value Function Loss: 0.03037

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 1.06083
Value Function Update Magnitude: 0.99935

Collected Steps per Second: 21,122.55119
Overall Steps per Second: 10,372.15801

Timestep Collection Time: 2.36913
Timestep Consumption Time: 2.45552
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.82465

Cumulative Model Updates: 146,324
Cumulative Timesteps: 1,220,161,590

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06021
Policy Entropy: 3.79427
Value Function Loss: 0.02223

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.87842
Value Function Update Magnitude: 0.84963

Collected Steps per Second: 21,513.68443
Overall Steps per Second: 10,471.34884

Timestep Collection Time: 2.32550
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.77780

Cumulative Model Updates: 146,330
Cumulative Timesteps: 1,220,211,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1220211620...
Checkpoint 1220211620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06021
Policy Entropy: 3.76084
Value Function Loss: 0.01502

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.70225
Value Function Update Magnitude: 0.58880

Collected Steps per Second: 21,298.82835
Overall Steps per Second: 10,607.61559

Timestep Collection Time: 2.34896
Timestep Consumption Time: 2.36747
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.71642

Cumulative Model Updates: 146,336
Cumulative Timesteps: 1,220,261,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06021
Policy Entropy: 3.74817
Value Function Loss: 0.01351

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.59308
Value Function Update Magnitude: 0.40863

Collected Steps per Second: 20,744.01078
Overall Steps per Second: 10,475.46243

Timestep Collection Time: 2.41130
Timestep Consumption Time: 2.36367
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.77497

Cumulative Model Updates: 146,342
Cumulative Timesteps: 1,220,311,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1220311670...
Checkpoint 1220311670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,217.64587
Policy Entropy: 3.74334
Value Function Loss: 0.01576

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07562
Policy Update Magnitude: 0.61299
Value Function Update Magnitude: 0.41038

Collected Steps per Second: 20,918.17811
Overall Steps per Second: 10,540.89076

Timestep Collection Time: 2.39093
Timestep Consumption Time: 2.35383
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.74476

Cumulative Model Updates: 146,348
Cumulative Timesteps: 1,220,361,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,871.78848
Policy Entropy: 3.76079
Value Function Loss: 0.01592

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07996
Policy Update Magnitude: 0.62284
Value Function Update Magnitude: 0.43159

Collected Steps per Second: 21,340.10974
Overall Steps per Second: 10,491.68173

Timestep Collection Time: 2.34366
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.76701

Cumulative Model Updates: 146,354
Cumulative Timesteps: 1,220,411,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1220411698...
Checkpoint 1220411698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 592.70402
Policy Entropy: 3.79409
Value Function Loss: 0.01597

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.58194
Value Function Update Magnitude: 0.55921

Collected Steps per Second: 21,273.91396
Overall Steps per Second: 10,233.31906

Timestep Collection Time: 2.35077
Timestep Consumption Time: 2.53621
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.88698

Cumulative Model Updates: 146,360
Cumulative Timesteps: 1,220,461,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,839.70918
Policy Entropy: 3.79175
Value Function Loss: 0.01621

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08215
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.64357

Collected Steps per Second: 21,772.03754
Overall Steps per Second: 10,534.06931

Timestep Collection Time: 2.29744
Timestep Consumption Time: 2.45096
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.74840

Cumulative Model Updates: 146,366
Cumulative Timesteps: 1,220,511,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1220511728...
Checkpoint 1220511728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.30084
Policy Entropy: 3.77341
Value Function Loss: 0.01474

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.59793
Value Function Update Magnitude: 0.69467

Collected Steps per Second: 21,946.03699
Overall Steps per Second: 10,650.57228

Timestep Collection Time: 2.27895
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.69590

Cumulative Model Updates: 146,372
Cumulative Timesteps: 1,220,561,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.30084
Policy Entropy: 3.74727
Value Function Loss: 0.01421

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.56877
Value Function Update Magnitude: 0.58544

Collected Steps per Second: 22,145.33803
Overall Steps per Second: 10,483.78330

Timestep Collection Time: 2.25890
Timestep Consumption Time: 2.51266
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.77156

Cumulative Model Updates: 146,378
Cumulative Timesteps: 1,220,611,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1220611766...
Checkpoint 1220611766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,744.30084
Policy Entropy: 3.77058
Value Function Loss: 0.01138

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.20421
Policy Update Magnitude: 0.45055
Value Function Update Magnitude: 0.44577

Collected Steps per Second: 22,590.86524
Overall Steps per Second: 10,576.74387

Timestep Collection Time: 2.21364
Timestep Consumption Time: 2.51447
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.72811

Cumulative Model Updates: 146,384
Cumulative Timesteps: 1,220,661,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,440.38165
Policy Entropy: 3.76597
Value Function Loss: 0.01208

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.18396
Policy Update Magnitude: 0.34088
Value Function Update Magnitude: 0.37012

Collected Steps per Second: 22,604.37654
Overall Steps per Second: 10,761.93821

Timestep Collection Time: 2.21249
Timestep Consumption Time: 2.43463
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.64712

Cumulative Model Updates: 146,390
Cumulative Timesteps: 1,220,711,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1220711786...
Checkpoint 1220711786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,122.50978
Policy Entropy: 3.78004
Value Function Loss: 0.01096

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.16121
Policy Update Magnitude: 0.29859
Value Function Update Magnitude: 0.45311

Collected Steps per Second: 22,290.60556
Overall Steps per Second: 10,527.94310

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.74984

Cumulative Model Updates: 146,396
Cumulative Timesteps: 1,220,761,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,630.89286
Policy Entropy: 3.73544
Value Function Loss: 0.01323

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.34818
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,204.75386
Overall Steps per Second: 10,640.26561

Timestep Collection Time: 2.25258
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.70082

Cumulative Model Updates: 146,402
Cumulative Timesteps: 1,220,811,810

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1220811810...
Checkpoint 1220811810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,777.90460
Policy Entropy: 3.75086
Value Function Loss: 0.01806

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.14010
Policy Update Magnitude: 0.40103
Value Function Update Magnitude: 0.57221

Collected Steps per Second: 21,223.78138
Overall Steps per Second: 10,618.98306

Timestep Collection Time: 2.35651
Timestep Consumption Time: 2.35336
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.70987

Cumulative Model Updates: 146,408
Cumulative Timesteps: 1,220,861,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,465.49439
Policy Entropy: 3.75242
Value Function Loss: 0.01936

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14527
Policy Update Magnitude: 0.42661
Value Function Update Magnitude: 0.54451

Collected Steps per Second: 20,948.07379
Overall Steps per Second: 10,495.66844

Timestep Collection Time: 2.38685
Timestep Consumption Time: 2.37702
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.76387

Cumulative Model Updates: 146,414
Cumulative Timesteps: 1,220,911,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1220911824...
Checkpoint 1220911824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,748.28685
Policy Entropy: 3.75557
Value Function Loss: 0.02051

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14804
Policy Update Magnitude: 0.41835
Value Function Update Magnitude: 0.52218

Collected Steps per Second: 21,196.56350
Overall Steps per Second: 10,568.11215

Timestep Collection Time: 2.36104
Timestep Consumption Time: 2.37452
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.73557

Cumulative Model Updates: 146,420
Cumulative Timesteps: 1,220,961,870

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,583.65820
Policy Entropy: 3.75620
Value Function Loss: 0.01916

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.43181
Value Function Update Magnitude: 0.44465

Collected Steps per Second: 21,174.35494
Overall Steps per Second: 10,458.00415

Timestep Collection Time: 2.36324
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.78485

Cumulative Model Updates: 146,426
Cumulative Timesteps: 1,221,011,910

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1221011910...
Checkpoint 1221011910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,040.79758
Policy Entropy: 3.75143
Value Function Loss: 0.02142

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14271
Policy Update Magnitude: 0.46001
Value Function Update Magnitude: 0.57006

Collected Steps per Second: 21,999.67968
Overall Steps per Second: 10,659.78953

Timestep Collection Time: 2.27394
Timestep Consumption Time: 2.41902
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.69296

Cumulative Model Updates: 146,432
Cumulative Timesteps: 1,221,061,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,435.18381
Policy Entropy: 3.77048
Value Function Loss: 0.02144

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.73279

Collected Steps per Second: 22,180.91582
Overall Steps per Second: 10,571.64282

Timestep Collection Time: 2.25464
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.73058

Cumulative Model Updates: 146,438
Cumulative Timesteps: 1,221,111,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1221111946...
Checkpoint 1221111946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,059.00834
Policy Entropy: 3.77044
Value Function Loss: 0.02299

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.48664
Value Function Update Magnitude: 0.71068

Collected Steps per Second: 22,243.69777
Overall Steps per Second: 10,562.87111

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.73356

Cumulative Model Updates: 146,444
Cumulative Timesteps: 1,221,161,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,930.16472
Policy Entropy: 3.74582
Value Function Loss: 0.02218

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.48084
Value Function Update Magnitude: 0.59087

Collected Steps per Second: 22,004.08842
Overall Steps per Second: 10,481.90201

Timestep Collection Time: 2.27340
Timestep Consumption Time: 2.49902
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.77242

Cumulative Model Updates: 146,450
Cumulative Timesteps: 1,221,211,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1221211970...
Checkpoint 1221211970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,317.20475
Policy Entropy: 3.73515
Value Function Loss: 0.02371

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13673
Policy Update Magnitude: 0.48388
Value Function Update Magnitude: 0.51939

Collected Steps per Second: 22,418.99072
Overall Steps per Second: 10,714.40715

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.66755

Cumulative Model Updates: 146,456
Cumulative Timesteps: 1,221,261,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,752.77885
Policy Entropy: 3.73472
Value Function Loss: 0.02483

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.47975
Value Function Update Magnitude: 0.51751

Collected Steps per Second: 22,272.77540
Overall Steps per Second: 10,468.00047

Timestep Collection Time: 2.24507
Timestep Consumption Time: 2.53177
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.77684

Cumulative Model Updates: 146,462
Cumulative Timesteps: 1,221,311,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1221311984...
Checkpoint 1221311984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,611.32740
Policy Entropy: 3.75734
Value Function Loss: 0.02558

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.51979
Value Function Update Magnitude: 0.49788

Collected Steps per Second: 22,339.14166
Overall Steps per Second: 10,543.71313

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.74501

Cumulative Model Updates: 146,468
Cumulative Timesteps: 1,221,362,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,166.63027
Policy Entropy: 3.77142
Value Function Loss: 0.02414

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.51953
Value Function Update Magnitude: 0.57267

Collected Steps per Second: 22,033.92488
Overall Steps per Second: 10,290.99184

Timestep Collection Time: 2.27050
Timestep Consumption Time: 2.59084
PPO Batch Consumption Time: 0.30403
Total Iteration Time: 4.86134

Cumulative Model Updates: 146,474
Cumulative Timesteps: 1,221,412,042

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221412042...
Checkpoint 1221412042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,624.89208
Policy Entropy: 3.77986
Value Function Loss: 0.02734

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.50928
Value Function Update Magnitude: 0.73450

Collected Steps per Second: 21,828.35388
Overall Steps per Second: 10,369.96881

Timestep Collection Time: 2.29234
Timestep Consumption Time: 2.53294
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.82528

Cumulative Model Updates: 146,480
Cumulative Timesteps: 1,221,462,080

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.60392
Policy Entropy: 3.80128
Value Function Loss: 0.02625

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.52282
Value Function Update Magnitude: 0.65822

Collected Steps per Second: 21,177.36387
Overall Steps per Second: 10,375.17930

Timestep Collection Time: 2.36167
Timestep Consumption Time: 2.45887
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.82054

Cumulative Model Updates: 146,486
Cumulative Timesteps: 1,221,512,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1221512094...
Checkpoint 1221512094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.56614
Policy Entropy: 3.78985
Value Function Loss: 0.02879

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.67130

Collected Steps per Second: 21,853.89284
Overall Steps per Second: 10,398.55694

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.80951

Cumulative Model Updates: 146,492
Cumulative Timesteps: 1,221,562,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,106.93903
Policy Entropy: 3.79875
Value Function Loss: 0.02600

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.59935
Value Function Update Magnitude: 0.77229

Collected Steps per Second: 22,127.62502
Overall Steps per Second: 10,539.60622

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.74667

Cumulative Model Updates: 146,498
Cumulative Timesteps: 1,221,612,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1221612134...
Checkpoint 1221612134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,286.86832
Policy Entropy: 3.78941
Value Function Loss: 0.02854

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.60150
Value Function Update Magnitude: 0.85084

Collected Steps per Second: 22,283.24499
Overall Steps per Second: 10,459.87897

Timestep Collection Time: 2.24474
Timestep Consumption Time: 2.53735
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.78208

Cumulative Model Updates: 146,504
Cumulative Timesteps: 1,221,662,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,859.34913
Policy Entropy: 3.80296
Value Function Loss: 0.02459

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.87150

Collected Steps per Second: 21,167.15091
Overall Steps per Second: 10,336.11298

Timestep Collection Time: 2.36272
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.83857

Cumulative Model Updates: 146,510
Cumulative Timesteps: 1,221,712,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1221712166...
Checkpoint 1221712166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,319.28893
Policy Entropy: 3.79601
Value Function Loss: 0.02627

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.54508
Value Function Update Magnitude: 0.82975

Collected Steps per Second: 22,051.51864
Overall Steps per Second: 10,502.82341

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.76253

Cumulative Model Updates: 146,516
Cumulative Timesteps: 1,221,762,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,082.34363
Policy Entropy: 3.78091
Value Function Loss: 0.02251

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.54581
Value Function Update Magnitude: 0.78697

Collected Steps per Second: 22,605.17122
Overall Steps per Second: 10,769.82441

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.64613

Cumulative Model Updates: 146,522
Cumulative Timesteps: 1,221,812,224

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1221812224...
Checkpoint 1221812224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,776.33413
Policy Entropy: 3.76431
Value Function Loss: 0.02181

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.51438
Value Function Update Magnitude: 0.70595

Collected Steps per Second: 22,210.15361
Overall Steps per Second: 10,664.03510

Timestep Collection Time: 2.25212
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.69053

Cumulative Model Updates: 146,528
Cumulative Timesteps: 1,221,862,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,728.32886
Policy Entropy: 3.74613
Value Function Loss: 0.01944

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.51804
Value Function Update Magnitude: 0.66454

Collected Steps per Second: 22,334.13402
Overall Steps per Second: 10,562.10788

Timestep Collection Time: 2.23944
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.73542

Cumulative Model Updates: 146,534
Cumulative Timesteps: 1,221,912,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1221912260...
Checkpoint 1221912260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,728.32886
Policy Entropy: 3.73411
Value Function Loss: 0.02130

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.48842
Value Function Update Magnitude: 0.54651

Collected Steps per Second: 22,141.06742
Overall Steps per Second: 10,493.68747

Timestep Collection Time: 2.25933
Timestep Consumption Time: 2.50773
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.76706

Cumulative Model Updates: 146,540
Cumulative Timesteps: 1,221,962,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,946.40414
Policy Entropy: 3.75242
Value Function Loss: 0.02172

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.48285
Value Function Update Magnitude: 0.51753

Collected Steps per Second: 20,741.09955
Overall Steps per Second: 10,142.97653

Timestep Collection Time: 2.41289
Timestep Consumption Time: 2.52116
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.93405

Cumulative Model Updates: 146,546
Cumulative Timesteps: 1,222,012,330

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1222012330...
Checkpoint 1222012330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,382.48361
Policy Entropy: 3.78454
Value Function Loss: 0.02351

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.51728
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 21,862.76128
Overall Steps per Second: 10,410.80471

Timestep Collection Time: 2.28800
Timestep Consumption Time: 2.51682
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.80482

Cumulative Model Updates: 146,552
Cumulative Timesteps: 1,222,062,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.30386
Policy Entropy: 3.81627
Value Function Loss: 0.02158

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.53252
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 22,022.82855
Overall Steps per Second: 10,455.12007

Timestep Collection Time: 2.27101
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.78368

Cumulative Model Updates: 146,558
Cumulative Timesteps: 1,222,112,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1222112366...
Checkpoint 1222112366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.27388
Policy Entropy: 3.79829
Value Function Loss: 0.02008

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.49049
Value Function Update Magnitude: 0.57786

Collected Steps per Second: 21,618.73721
Overall Steps per Second: 10,316.23010

Timestep Collection Time: 2.31327
Timestep Consumption Time: 2.53443
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.84770

Cumulative Model Updates: 146,564
Cumulative Timesteps: 1,222,162,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.27388
Policy Entropy: 3.76396
Value Function Loss: 0.01614

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.43172
Value Function Update Magnitude: 0.47934

Collected Steps per Second: 22,660.22836
Overall Steps per Second: 10,556.02590

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.53113
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.73853

Cumulative Model Updates: 146,570
Cumulative Timesteps: 1,222,212,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1222212396...
Checkpoint 1222212396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.27388
Policy Entropy: 3.73688
Value Function Loss: 0.01442

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.14111
Policy Update Magnitude: 0.41564
Value Function Update Magnitude: 0.46983

Collected Steps per Second: 21,543.85300
Overall Steps per Second: 10,549.83176

Timestep Collection Time: 2.32270
Timestep Consumption Time: 2.42050
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.74320

Cumulative Model Updates: 146,576
Cumulative Timesteps: 1,222,262,436

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,493.11685
Policy Entropy: 3.74401
Value Function Loss: 0.01439

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13810
Policy Update Magnitude: 0.39457
Value Function Update Magnitude: 0.44507

Collected Steps per Second: 21,796.90479
Overall Steps per Second: 10,601.45019

Timestep Collection Time: 2.29427
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.71709

Cumulative Model Updates: 146,582
Cumulative Timesteps: 1,222,312,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1222312444...
Checkpoint 1222312444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,443.35256
Policy Entropy: 3.75157
Value Function Loss: 0.01562

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.38242
Value Function Update Magnitude: 0.41353

Collected Steps per Second: 21,690.26747
Overall Steps per Second: 10,567.36054

Timestep Collection Time: 2.30712
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73552

Cumulative Model Updates: 146,588
Cumulative Timesteps: 1,222,362,486

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,955.48715
Policy Entropy: 3.74878
Value Function Loss: 0.01700

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.39252
Value Function Update Magnitude: 0.41704

Collected Steps per Second: 22,000.22092
Overall Steps per Second: 10,492.33276

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.76653

Cumulative Model Updates: 146,594
Cumulative Timesteps: 1,222,412,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1222412498...
Checkpoint 1222412498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,364.24574
Policy Entropy: 3.74693
Value Function Loss: 0.01778

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13708
Policy Update Magnitude: 0.40696
Value Function Update Magnitude: 0.44737

Collected Steps per Second: 21,783.31357
Overall Steps per Second: 10,538.96544

Timestep Collection Time: 2.29598
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.74563

Cumulative Model Updates: 146,600
Cumulative Timesteps: 1,222,462,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,526.55430
Policy Entropy: 3.73841
Value Function Loss: 0.01958

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.39099
Value Function Update Magnitude: 0.44631

Collected Steps per Second: 22,388.90002
Overall Steps per Second: 10,608.67760

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.71557

Cumulative Model Updates: 146,606
Cumulative Timesteps: 1,222,512,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1222512538...
Checkpoint 1222512538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,708.37610
Policy Entropy: 3.75276
Value Function Loss: 0.01793

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.40003
Value Function Update Magnitude: 0.45844

Collected Steps per Second: 22,037.95082
Overall Steps per Second: 10,472.17507

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.77570

Cumulative Model Updates: 146,612
Cumulative Timesteps: 1,222,562,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,490.26903
Policy Entropy: 3.75669
Value Function Loss: 0.01764

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.39599
Value Function Update Magnitude: 0.49246

Collected Steps per Second: 21,919.94045
Overall Steps per Second: 10,469.37817

Timestep Collection Time: 2.28148
Timestep Consumption Time: 2.49530
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.77679

Cumulative Model Updates: 146,618
Cumulative Timesteps: 1,222,612,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1222612560...
Checkpoint 1222612560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,704.04903
Policy Entropy: 3.76254
Value Function Loss: 0.01819

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.42418
Value Function Update Magnitude: 0.66035

Collected Steps per Second: 21,937.34399
Overall Steps per Second: 10,599.11064

Timestep Collection Time: 2.27977
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.71851

Cumulative Model Updates: 146,624
Cumulative Timesteps: 1,222,662,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,029.03841
Policy Entropy: 3.76074
Value Function Loss: 0.02196

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.49522
Value Function Update Magnitude: 0.76469

Collected Steps per Second: 22,109.99870
Overall Steps per Second: 10,385.89815

Timestep Collection Time: 2.26269
Timestep Consumption Time: 2.55423
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.81692

Cumulative Model Updates: 146,630
Cumulative Timesteps: 1,222,712,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1222712600...
Checkpoint 1222712600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,930.19560
Policy Entropy: 3.76347
Value Function Loss: 0.02250

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13768
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.79166

Collected Steps per Second: 22,208.43406
Overall Steps per Second: 10,324.42762

Timestep Collection Time: 2.25266
Timestep Consumption Time: 2.59294
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.84560

Cumulative Model Updates: 146,636
Cumulative Timesteps: 1,222,762,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,620.44785
Policy Entropy: 3.75933
Value Function Loss: 0.02008

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.51281
Value Function Update Magnitude: 0.75277

Collected Steps per Second: 22,667.84224
Overall Steps per Second: 10,636.61126

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.70225

Cumulative Model Updates: 146,642
Cumulative Timesteps: 1,222,812,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1222812644...
Checkpoint 1222812644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,806.48242
Policy Entropy: 3.73810
Value Function Loss: 0.01920

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.14364
Policy Update Magnitude: 0.44956
Value Function Update Magnitude: 0.65377

Collected Steps per Second: 21,605.48001
Overall Steps per Second: 10,547.41510

Timestep Collection Time: 2.31478
Timestep Consumption Time: 2.42685
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74164

Cumulative Model Updates: 146,648
Cumulative Timesteps: 1,222,862,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,806.48242
Policy Entropy: 3.72783
Value Function Loss: 0.01703

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.41617
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 21,816.07408
Overall Steps per Second: 10,715.05083

Timestep Collection Time: 2.29216
Timestep Consumption Time: 2.37473
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.66689

Cumulative Model Updates: 146,654
Cumulative Timesteps: 1,222,912,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1222912662...
Checkpoint 1222912662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,896.04277
Policy Entropy: 3.73193
Value Function Loss: 0.01652

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.41773
Value Function Update Magnitude: 0.49978

Collected Steps per Second: 21,518.56461
Overall Steps per Second: 10,640.76983

Timestep Collection Time: 2.32367
Timestep Consumption Time: 2.37543
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.69910

Cumulative Model Updates: 146,660
Cumulative Timesteps: 1,222,962,664

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,878.25215
Policy Entropy: 3.74038
Value Function Loss: 0.01575

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.42718
Value Function Update Magnitude: 0.47212

Collected Steps per Second: 21,811.08711
Overall Steps per Second: 10,536.03023

Timestep Collection Time: 2.29241
Timestep Consumption Time: 2.45321
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.74562

Cumulative Model Updates: 146,666
Cumulative Timesteps: 1,223,012,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1223012664...
Checkpoint 1223012664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091.25480
Policy Entropy: 3.74939
Value Function Loss: 0.01824

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.43509
Value Function Update Magnitude: 0.58612

Collected Steps per Second: 22,279.06564
Overall Steps per Second: 10,645.86685

Timestep Collection Time: 2.24453
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.69722

Cumulative Model Updates: 146,672
Cumulative Timesteps: 1,223,062,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,652.65832
Policy Entropy: 3.74981
Value Function Loss: 0.01986

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.45201
Value Function Update Magnitude: 0.69121

Collected Steps per Second: 21,874.30019
Overall Steps per Second: 10,454.83442

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.49729
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.78362

Cumulative Model Updates: 146,678
Cumulative Timesteps: 1,223,112,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1223112682...
Checkpoint 1223112682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,809.53023
Policy Entropy: 3.75687
Value Function Loss: 0.01941

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.46790
Value Function Update Magnitude: 0.70568

Collected Steps per Second: 21,557.64107
Overall Steps per Second: 10,275.63553

Timestep Collection Time: 2.32020
Timestep Consumption Time: 2.54743
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.86763

Cumulative Model Updates: 146,684
Cumulative Timesteps: 1,223,162,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,886.37465
Policy Entropy: 3.74550
Value Function Loss: 0.01863

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.44815
Value Function Update Magnitude: 0.55300

Collected Steps per Second: 22,112.60779
Overall Steps per Second: 10,430.78648

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.79734

Cumulative Model Updates: 146,690
Cumulative Timesteps: 1,223,212,740

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1223212740...
Checkpoint 1223212740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,684.21092
Policy Entropy: 3.74274
Value Function Loss: 0.02043

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.42611
Value Function Update Magnitude: 0.44269

Collected Steps per Second: 22,158.97766
Overall Steps per Second: 10,637.58790

Timestep Collection Time: 2.25723
Timestep Consumption Time: 2.44477
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.70201

Cumulative Model Updates: 146,696
Cumulative Timesteps: 1,223,262,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,355.60150
Policy Entropy: 3.72721
Value Function Loss: 0.02163

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13488
Policy Update Magnitude: 0.43915
Value Function Update Magnitude: 0.40340

Collected Steps per Second: 22,534.15045
Overall Steps per Second: 10,428.81540

Timestep Collection Time: 2.21992
Timestep Consumption Time: 2.57679
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.79671

Cumulative Model Updates: 146,702
Cumulative Timesteps: 1,223,312,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1223312782...
Checkpoint 1223312782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,720.74107
Policy Entropy: 3.73750
Value Function Loss: 0.01988

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.48434
Value Function Update Magnitude: 0.51887

Collected Steps per Second: 22,268.04168
Overall Steps per Second: 10,566.31743

Timestep Collection Time: 2.24582
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.73296

Cumulative Model Updates: 146,708
Cumulative Timesteps: 1,223,362,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,720.74107
Policy Entropy: 3.72103
Value Function Loss: 0.01692

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.47218
Value Function Update Magnitude: 0.59400

Collected Steps per Second: 22,339.20263
Overall Steps per Second: 10,330.48931

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.60234
PPO Batch Consumption Time: 0.30689
Total Iteration Time: 4.84101

Cumulative Model Updates: 146,714
Cumulative Timesteps: 1,223,412,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1223412802...
Checkpoint 1223412802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,720.74107
Policy Entropy: 3.73916
Value Function Loss: 0.01424

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.41653
Value Function Update Magnitude: 0.57027

Collected Steps per Second: 22,466.90054
Overall Steps per Second: 10,603.00791

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.71640

Cumulative Model Updates: 146,720
Cumulative Timesteps: 1,223,462,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,720.74107
Policy Entropy: 3.72772
Value Function Loss: 0.01216

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.36492
Value Function Update Magnitude: 0.47334

Collected Steps per Second: 22,182.79108
Overall Steps per Second: 10,673.71549

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.68534

Cumulative Model Updates: 146,726
Cumulative Timesteps: 1,223,512,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1223512820...
Checkpoint 1223512820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,720.74107
Policy Entropy: 3.73076
Value Function Loss: 0.01378

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.35543
Value Function Update Magnitude: 0.37717

Collected Steps per Second: 21,796.17115
Overall Steps per Second: 10,629.52532

Timestep Collection Time: 2.29462
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.70520

Cumulative Model Updates: 146,732
Cumulative Timesteps: 1,223,562,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,822.27941
Policy Entropy: 3.72935
Value Function Loss: 0.01591

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.38119
Value Function Update Magnitude: 0.34172

Collected Steps per Second: 21,727.01449
Overall Steps per Second: 10,564.52775

Timestep Collection Time: 2.30257
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.73547

Cumulative Model Updates: 146,738
Cumulative Timesteps: 1,223,612,862

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1223612862...
Checkpoint 1223612862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,822.27941
Policy Entropy: 3.72930
Value Function Loss: 0.01507

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.39241
Value Function Update Magnitude: 0.37432

Collected Steps per Second: 21,434.71975
Overall Steps per Second: 10,536.69391

Timestep Collection Time: 2.33350
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.74703

Cumulative Model Updates: 146,744
Cumulative Timesteps: 1,223,662,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73836
Value Function Loss: 0.01523

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.38753
Value Function Update Magnitude: 0.41168

Collected Steps per Second: 22,074.28086
Overall Steps per Second: 10,519.81424

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.48935
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.75579

Cumulative Model Updates: 146,750
Cumulative Timesteps: 1,223,712,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1223712910...
Checkpoint 1223712910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73841
Value Function Loss: 0.01544

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.43025
Value Function Update Magnitude: 0.43795

Collected Steps per Second: 21,870.72294
Overall Steps per Second: 10,534.74410

Timestep Collection Time: 2.28698
Timestep Consumption Time: 2.46092
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.74791

Cumulative Model Updates: 146,756
Cumulative Timesteps: 1,223,762,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73586
Value Function Loss: 0.01477

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.45636
Value Function Update Magnitude: 0.43032

Collected Steps per Second: 22,185.46576
Overall Steps per Second: 10,498.46201

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.76432

Cumulative Model Updates: 146,762
Cumulative Timesteps: 1,223,812,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1223812946...
Checkpoint 1223812946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73846
Value Function Loss: 0.01485

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.45792
Value Function Update Magnitude: 0.42007

Collected Steps per Second: 22,206.08072
Overall Steps per Second: 10,543.88923

Timestep Collection Time: 2.25272
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.74436

Cumulative Model Updates: 146,768
Cumulative Timesteps: 1,223,862,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73620
Value Function Loss: 0.01488

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.43253
Value Function Update Magnitude: 0.37357

Collected Steps per Second: 21,311.13153
Overall Steps per Second: 10,326.63647

Timestep Collection Time: 2.34835
Timestep Consumption Time: 2.49795
PPO Batch Consumption Time: 0.28827
Total Iteration Time: 4.84630

Cumulative Model Updates: 146,774
Cumulative Timesteps: 1,223,913,016

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1223913016...
Checkpoint 1223913016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.74162
Value Function Loss: 0.01558

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.43699
Value Function Update Magnitude: 0.37134

Collected Steps per Second: 22,178.88740
Overall Steps per Second: 10,534.32888

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.74658

Cumulative Model Updates: 146,780
Cumulative Timesteps: 1,223,963,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.72784
Value Function Loss: 0.01413

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.40368
Value Function Update Magnitude: 0.38186

Collected Steps per Second: 22,393.12980
Overall Steps per Second: 10,572.01391

Timestep Collection Time: 2.23435
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.73268

Cumulative Model Updates: 146,786
Cumulative Timesteps: 1,224,013,052

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1224013052...
Checkpoint 1224013052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73633
Value Function Loss: 0.01414

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.37144
Value Function Update Magnitude: 0.35791

Collected Steps per Second: 21,140.33557
Overall Steps per Second: 10,273.93828

Timestep Collection Time: 2.36609
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.30391
Total Iteration Time: 4.86863

Cumulative Model Updates: 146,792
Cumulative Timesteps: 1,224,063,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.72871
Value Function Loss: 0.01358

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.36725
Value Function Update Magnitude: 0.32886

Collected Steps per Second: 21,710.16577
Overall Steps per Second: 10,661.73748

Timestep Collection Time: 2.30408
Timestep Consumption Time: 2.38765
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.69173

Cumulative Model Updates: 146,798
Cumulative Timesteps: 1,224,113,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1224113094...
Checkpoint 1224113094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73812
Value Function Loss: 0.01464

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.40055
Value Function Update Magnitude: 0.36872

Collected Steps per Second: 21,820.26828
Overall Steps per Second: 10,630.93593

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.70476

Cumulative Model Updates: 146,804
Cumulative Timesteps: 1,224,163,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,975.26889
Policy Entropy: 3.73170
Value Function Loss: 0.01281

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.42340
Value Function Update Magnitude: 0.44431

Collected Steps per Second: 22,644.22937
Overall Steps per Second: 10,810.39618

Timestep Collection Time: 2.20816
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.62536

Cumulative Model Updates: 146,810
Cumulative Timesteps: 1,224,213,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1224213112...
Checkpoint 1224213112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,257.20478
Policy Entropy: 3.73501
Value Function Loss: 0.01408

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.42348
Value Function Update Magnitude: 0.44840

Collected Steps per Second: 22,142.47487
Overall Steps per Second: 10,692.12910

Timestep Collection Time: 2.25810
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.67634

Cumulative Model Updates: 146,816
Cumulative Timesteps: 1,224,263,112

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,794.97840
Policy Entropy: 3.74692
Value Function Loss: 0.01356

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.43171
Value Function Update Magnitude: 0.48234

Collected Steps per Second: 22,762.10105
Overall Steps per Second: 10,655.01546

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.69413

Cumulative Model Updates: 146,822
Cumulative Timesteps: 1,224,313,128

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1224313128...
Checkpoint 1224313128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,015.21598
Policy Entropy: 3.74747
Value Function Loss: 0.01743

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.42110
Value Function Update Magnitude: 0.45624

Collected Steps per Second: 22,453.74992
Overall Steps per Second: 10,609.72708

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.71360

Cumulative Model Updates: 146,828
Cumulative Timesteps: 1,224,363,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,053.06461
Policy Entropy: 3.75660
Value Function Loss: 0.01750

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.40621
Value Function Update Magnitude: 0.36441

Collected Steps per Second: 22,490.78598
Overall Steps per Second: 10,727.83452

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.66282

Cumulative Model Updates: 146,834
Cumulative Timesteps: 1,224,413,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1224413160...
Checkpoint 1224413160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,747.16636
Policy Entropy: 3.73921
Value Function Loss: 0.02236

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.45716
Value Function Update Magnitude: 0.32811

Collected Steps per Second: 21,383.09352
Overall Steps per Second: 10,314.45878

Timestep Collection Time: 2.33858
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.84815

Cumulative Model Updates: 146,840
Cumulative Timesteps: 1,224,463,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,719.51257
Policy Entropy: 3.74159
Value Function Loss: 0.02118

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.39879

Collected Steps per Second: 22,079.80402
Overall Steps per Second: 10,501.74167

Timestep Collection Time: 2.26569
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.76359

Cumulative Model Updates: 146,846
Cumulative Timesteps: 1,224,513,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1224513192...
Checkpoint 1224513192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,978.28394
Policy Entropy: 3.74226
Value Function Loss: 0.02166

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.49576
Value Function Update Magnitude: 0.45905

Collected Steps per Second: 21,993.12932
Overall Steps per Second: 10,488.27126

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.76837

Cumulative Model Updates: 146,852
Cumulative Timesteps: 1,224,563,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,279.28200
Policy Entropy: 3.74956
Value Function Loss: 0.01840

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13941
Policy Update Magnitude: 0.45581
Value Function Update Magnitude: 0.45629

Collected Steps per Second: 22,670.36376
Overall Steps per Second: 10,518.29859

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.54851
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.75438

Cumulative Model Updates: 146,858
Cumulative Timesteps: 1,224,613,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1224613212...
Checkpoint 1224613212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,880.72490
Policy Entropy: 3.74555
Value Function Loss: 0.01722

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.40862
Value Function Update Magnitude: 0.47710

Collected Steps per Second: 22,256.21043
Overall Steps per Second: 10,558.81239

Timestep Collection Time: 2.24692
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.73614

Cumulative Model Updates: 146,864
Cumulative Timesteps: 1,224,663,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,506.33482
Policy Entropy: 3.73580
Value Function Loss: 0.01606

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.42503
Value Function Update Magnitude: 0.50415

Collected Steps per Second: 22,257.60233
Overall Steps per Second: 10,471.56945

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.77598

Cumulative Model Updates: 146,870
Cumulative Timesteps: 1,224,713,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1224713232...
Checkpoint 1224713232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,506.33482
Policy Entropy: 3.71579
Value Function Loss: 0.01889

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.50427
Value Function Update Magnitude: 0.57415

Collected Steps per Second: 22,376.53496
Overall Steps per Second: 10,598.98374

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.71819

Cumulative Model Updates: 146,876
Cumulative Timesteps: 1,224,763,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,506.33482
Policy Entropy: 3.70458
Value Function Loss: 0.01804

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.65189

Collected Steps per Second: 22,819.03740
Overall Steps per Second: 10,627.71914

Timestep Collection Time: 2.19343
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.70957

Cumulative Model Updates: 146,882
Cumulative Timesteps: 1,224,813,292

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1224813292...
Checkpoint 1224813292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,506.33482
Policy Entropy: 3.70705
Value Function Loss: 0.01654

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.55513

Collected Steps per Second: 22,447.61972
Overall Steps per Second: 10,549.91678

Timestep Collection Time: 2.22874
Timestep Consumption Time: 2.51347
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.74222

Cumulative Model Updates: 146,888
Cumulative Timesteps: 1,224,863,322

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,506.33482
Policy Entropy: 3.72200
Value Function Loss: 0.01445

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.48345
Value Function Update Magnitude: 0.44134

Collected Steps per Second: 22,588.77517
Overall Steps per Second: 10,635.93771

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.70217

Cumulative Model Updates: 146,894
Cumulative Timesteps: 1,224,913,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1224913334...
Checkpoint 1224913334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,267.15377
Policy Entropy: 3.73153
Value Function Loss: 0.01504

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.40967
Value Function Update Magnitude: 0.34047

Collected Steps per Second: 22,123.44856
Overall Steps per Second: 10,446.20705

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.52729
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.78815

Cumulative Model Updates: 146,900
Cumulative Timesteps: 1,224,963,352

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,596.76246
Policy Entropy: 3.73308
Value Function Loss: 0.01461

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.39168
Value Function Update Magnitude: 0.32736

Collected Steps per Second: 22,100.88725
Overall Steps per Second: 10,448.83246

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78886

Cumulative Model Updates: 146,906
Cumulative Timesteps: 1,225,013,390

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1225013390...
Checkpoint 1225013390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,781.89296
Policy Entropy: 3.73945
Value Function Loss: 0.01430

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.36591
Value Function Update Magnitude: 0.33506

Collected Steps per Second: 21,715.60487
Overall Steps per Second: 10,573.54426

Timestep Collection Time: 2.30277
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.72935

Cumulative Model Updates: 146,912
Cumulative Timesteps: 1,225,063,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,781.89296
Policy Entropy: 3.74447
Value Function Loss: 0.01381

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.37093
Value Function Update Magnitude: 0.30372

Collected Steps per Second: 22,119.27642
Overall Steps per Second: 10,503.81878

Timestep Collection Time: 2.26156
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.76246

Cumulative Model Updates: 146,918
Cumulative Timesteps: 1,225,113,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225113420...
Checkpoint 1225113420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,337.11808
Policy Entropy: 3.72866
Value Function Loss: 0.01591

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.44074
Value Function Update Magnitude: 0.38188

Collected Steps per Second: 21,953.17321
Overall Steps per Second: 10,597.56899

Timestep Collection Time: 2.27849
Timestep Consumption Time: 2.44146
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.71995

Cumulative Model Updates: 146,924
Cumulative Timesteps: 1,225,163,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,499.59510
Policy Entropy: 3.72232
Value Function Loss: 0.01708

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13558
Policy Update Magnitude: 0.52240
Value Function Update Magnitude: 0.42703

Collected Steps per Second: 21,769.58093
Overall Steps per Second: 10,530.28546

Timestep Collection Time: 2.29789
Timestep Consumption Time: 2.45260
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.75049

Cumulative Model Updates: 146,930
Cumulative Timesteps: 1,225,213,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1225213464...
Checkpoint 1225213464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,006.78556
Policy Entropy: 3.71448
Value Function Loss: 0.01967

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.42099

Collected Steps per Second: 21,446.42190
Overall Steps per Second: 10,647.40597

Timestep Collection Time: 2.33167
Timestep Consumption Time: 2.36487
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.69654

Cumulative Model Updates: 146,936
Cumulative Timesteps: 1,225,263,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,983.21019
Policy Entropy: 3.71688
Value Function Loss: 0.02071

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.52228
Value Function Update Magnitude: 0.42406

Collected Steps per Second: 21,840.84311
Overall Steps per Second: 10,604.13434

Timestep Collection Time: 2.28966
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.71590

Cumulative Model Updates: 146,942
Cumulative Timesteps: 1,225,313,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1225313478...
Checkpoint 1225313478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,983.21019
Policy Entropy: 3.70729
Value Function Loss: 0.01999

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.49081
Value Function Update Magnitude: 0.46325

Collected Steps per Second: 21,684.95827
Overall Steps per Second: 10,477.15442

Timestep Collection Time: 2.30750
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.77592

Cumulative Model Updates: 146,948
Cumulative Timesteps: 1,225,363,516

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,983.21019
Policy Entropy: 3.71408
Value Function Loss: 0.01637

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.14142
Policy Update Magnitude: 0.45612
Value Function Update Magnitude: 0.44216

Collected Steps per Second: 22,497.72117
Overall Steps per Second: 10,782.65068

Timestep Collection Time: 2.22307
Timestep Consumption Time: 2.41531
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.63838

Cumulative Model Updates: 146,954
Cumulative Timesteps: 1,225,413,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1225413530...
Checkpoint 1225413530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,983.21019
Policy Entropy: 3.70560
Value Function Loss: 0.01684

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.14319
Policy Update Magnitude: 0.40508
Value Function Update Magnitude: 0.37198

Collected Steps per Second: 22,245.89038
Overall Steps per Second: 10,735.49240

Timestep Collection Time: 2.24869
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.65968

Cumulative Model Updates: 146,960
Cumulative Timesteps: 1,225,463,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,983.21019
Policy Entropy: 3.71358
Value Function Loss: 0.01628

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14443
Policy Update Magnitude: 0.39812
Value Function Update Magnitude: 0.34950

Collected Steps per Second: 22,432.23381
Overall Steps per Second: 10,540.02597

Timestep Collection Time: 2.22956
Timestep Consumption Time: 2.51559
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74515

Cumulative Model Updates: 146,966
Cumulative Timesteps: 1,225,513,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1225513568...
Checkpoint 1225513568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,524.60422
Policy Entropy: 3.71667
Value Function Loss: 0.01872

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14535
Policy Update Magnitude: 0.44626
Value Function Update Magnitude: 0.44207

Collected Steps per Second: 22,197.16913
Overall Steps per Second: 10,586.55178

Timestep Collection Time: 2.25317
Timestep Consumption Time: 2.47113
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.72430

Cumulative Model Updates: 146,972
Cumulative Timesteps: 1,225,563,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,628.73684
Policy Entropy: 3.73911
Value Function Loss: 0.01574

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.48207
Value Function Update Magnitude: 0.48532

Collected Steps per Second: 21,913.79418
Overall Steps per Second: 10,492.67237

Timestep Collection Time: 2.28295
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.76790

Cumulative Model Updates: 146,978
Cumulative Timesteps: 1,225,613,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1225613610...
Checkpoint 1225613610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,359.32800
Policy Entropy: 3.74113
Value Function Loss: 0.01593

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.50604
Value Function Update Magnitude: 0.56031

Collected Steps per Second: 22,130.30059
Overall Steps per Second: 10,655.38746

Timestep Collection Time: 2.26115
Timestep Consumption Time: 2.43506
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.69622

Cumulative Model Updates: 146,984
Cumulative Timesteps: 1,225,663,650

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,925.50836
Policy Entropy: 3.74814
Value Function Loss: 0.01586

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.50226
Value Function Update Magnitude: 0.60101

Collected Steps per Second: 22,192.17189
Overall Steps per Second: 10,458.05774

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.52927
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.78349

Cumulative Model Updates: 146,990
Cumulative Timesteps: 1,225,713,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1225713676...
Checkpoint 1225713676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,061.96614
Policy Entropy: 3.73508
Value Function Loss: 0.01721

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.50955
Value Function Update Magnitude: 0.60718

Collected Steps per Second: 22,281.73283
Overall Steps per Second: 10,601.06437

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.47360
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.71858

Cumulative Model Updates: 146,996
Cumulative Timesteps: 1,225,763,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,061.96614
Policy Entropy: 3.73085
Value Function Loss: 0.01749

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14179
Policy Update Magnitude: 0.51418
Value Function Update Magnitude: 0.55314

Collected Steps per Second: 22,513.81255
Overall Steps per Second: 10,471.09152

Timestep Collection Time: 2.22175
Timestep Consumption Time: 2.55521
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.77696

Cumulative Model Updates: 147,002
Cumulative Timesteps: 1,225,813,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1225813718...
Checkpoint 1225813718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,061.96614
Policy Entropy: 3.72463
Value Function Loss: 0.01710

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.51049
Value Function Update Magnitude: 0.53857

Collected Steps per Second: 22,449.44654
Overall Steps per Second: 10,614.14099

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.71070

Cumulative Model Updates: 147,008
Cumulative Timesteps: 1,225,863,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,061.96614
Policy Entropy: 3.72461
Value Function Loss: 0.01547

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.51404
Value Function Update Magnitude: 0.58731

Collected Steps per Second: 22,610.39021
Overall Steps per Second: 10,551.84477

Timestep Collection Time: 2.21199
Timestep Consumption Time: 2.52784
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.73983

Cumulative Model Updates: 147,014
Cumulative Timesteps: 1,225,913,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1225913732...
Checkpoint 1225913732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,894.87772
Policy Entropy: 3.74280
Value Function Loss: 0.01710

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.49239
Value Function Update Magnitude: 0.56804

Collected Steps per Second: 22,369.72747
Overall Steps per Second: 10,544.53539

Timestep Collection Time: 2.23552
Timestep Consumption Time: 2.50703
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.74255

Cumulative Model Updates: 147,020
Cumulative Timesteps: 1,225,963,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,986.87788
Policy Entropy: 3.75544
Value Function Loss: 0.01910

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 22,854.91806
Overall Steps per Second: 10,830.13479

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.61804

Cumulative Model Updates: 147,026
Cumulative Timesteps: 1,226,013,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1226013754...
Checkpoint 1226013754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76310
Value Function Loss: 0.01770

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.67372

Collected Steps per Second: 22,058.86600
Overall Steps per Second: 10,672.72928

Timestep Collection Time: 2.26775
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.68709

Cumulative Model Updates: 147,032
Cumulative Timesteps: 1,226,063,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76023
Value Function Loss: 0.01493

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.09178
Policy Update Magnitude: 0.62454
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,037.06981
Overall Steps per Second: 10,498.90311

Timestep Collection Time: 2.27054
Timestep Consumption Time: 2.49529
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.76583

Cumulative Model Updates: 147,038
Cumulative Timesteps: 1,226,113,814

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1226113814...
Checkpoint 1226113814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.73754
Value Function Loss: 0.01341

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.60285
Value Function Update Magnitude: 0.54966

Collected Steps per Second: 21,757.67352
Overall Steps per Second: 10,571.05356

Timestep Collection Time: 2.29841
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.73065

Cumulative Model Updates: 147,044
Cumulative Timesteps: 1,226,163,822

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.75109
Value Function Loss: 0.01179

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.47917

Collected Steps per Second: 22,312.38852
Overall Steps per Second: 10,558.01053

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.73650

Cumulative Model Updates: 147,050
Cumulative Timesteps: 1,226,213,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1226213830...
Checkpoint 1226213830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.74442
Value Function Loss: 0.01279

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06356
Policy Update Magnitude: 0.56976
Value Function Update Magnitude: 0.41115

Collected Steps per Second: 22,117.68598
Overall Steps per Second: 10,621.82900

Timestep Collection Time: 2.26199
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.71011

Cumulative Model Updates: 147,056
Cumulative Timesteps: 1,226,263,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76553
Value Function Loss: 0.01099

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05470
Policy Update Magnitude: 0.54351
Value Function Update Magnitude: 0.37650

Collected Steps per Second: 21,657.25838
Overall Steps per Second: 10,489.49692

Timestep Collection Time: 2.30906
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.76744

Cumulative Model Updates: 147,062
Cumulative Timesteps: 1,226,313,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1226313868...
Checkpoint 1226313868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76634
Value Function Loss: 0.01015

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04715
Policy Update Magnitude: 0.49468
Value Function Update Magnitude: 0.34743

Collected Steps per Second: 21,610.16556
Overall Steps per Second: 10,597.12346

Timestep Collection Time: 2.31484
Timestep Consumption Time: 2.40569
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.72053

Cumulative Model Updates: 147,068
Cumulative Timesteps: 1,226,363,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76899
Value Function Loss: 0.00957

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06484
Policy Update Magnitude: 0.45223
Value Function Update Magnitude: 0.27049

Collected Steps per Second: 21,784.49255
Overall Steps per Second: 10,614.51300

Timestep Collection Time: 2.29650
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.71317

Cumulative Model Updates: 147,074
Cumulative Timesteps: 1,226,413,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1226413920...
Checkpoint 1226413920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.75953
Value Function Loss: 0.00903

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.42197
Value Function Update Magnitude: 0.24078

Collected Steps per Second: 21,495.00598
Overall Steps per Second: 10,547.88905

Timestep Collection Time: 2.32715
Timestep Consumption Time: 2.41523
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.74237

Cumulative Model Updates: 147,080
Cumulative Timesteps: 1,226,463,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.75188
Value Function Loss: 0.01028

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05494
Policy Update Magnitude: 0.46536
Value Function Update Magnitude: 0.27690

Collected Steps per Second: 22,448.22661
Overall Steps per Second: 10,758.62343

Timestep Collection Time: 2.22788
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.64855

Cumulative Model Updates: 147,086
Cumulative Timesteps: 1,226,513,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1226513954...
Checkpoint 1226513954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76265
Value Function Loss: 0.00967

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06448
Policy Update Magnitude: 0.51285
Value Function Update Magnitude: 0.32208

Collected Steps per Second: 21,938.38061
Overall Steps per Second: 10,460.99262

Timestep Collection Time: 2.28011
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.78176

Cumulative Model Updates: 147,092
Cumulative Timesteps: 1,226,563,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76791
Value Function Loss: 0.01016

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.49249
Value Function Update Magnitude: 0.37890

Collected Steps per Second: 22,278.61677
Overall Steps per Second: 10,690.09315

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.67929

Cumulative Model Updates: 147,098
Cumulative Timesteps: 1,226,613,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1226613998...
Checkpoint 1226613998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.76578
Value Function Loss: 0.01129

Mean KL Divergence: 0.01807
SB3 Clip Fraction: 0.20921
Policy Update Magnitude: 0.42621
Value Function Update Magnitude: 0.37871

Collected Steps per Second: 21,320.32289
Overall Steps per Second: 10,131.99242

Timestep Collection Time: 2.34593
Timestep Consumption Time: 2.59051
PPO Batch Consumption Time: 0.30564
Total Iteration Time: 4.93644

Cumulative Model Updates: 147,104
Cumulative Timesteps: 1,226,664,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,840.76031
Policy Entropy: 3.75898
Value Function Loss: 0.01380

Mean KL Divergence: 0.01538
SB3 Clip Fraction: 0.17986
Policy Update Magnitude: 0.44949
Value Function Update Magnitude: 0.44972

Collected Steps per Second: 21,630.68335
Overall Steps per Second: 10,509.35606

Timestep Collection Time: 2.31255
Timestep Consumption Time: 2.44721
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.75976

Cumulative Model Updates: 147,110
Cumulative Timesteps: 1,226,714,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1226714036...
Checkpoint 1226714036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 242,729.00583
Policy Entropy: 3.76378
Value Function Loss: 0.01571

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.50181
Value Function Update Magnitude: 0.45023

Collected Steps per Second: 21,402.33309
Overall Steps per Second: 10,281.15483

Timestep Collection Time: 2.33619
Timestep Consumption Time: 2.52707
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.86327

Cumulative Model Updates: 147,116
Cumulative Timesteps: 1,226,764,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 129,001.53320
Policy Entropy: 3.77013
Value Function Loss: 0.01817

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.62870
Value Function Update Magnitude: 0.49805

Collected Steps per Second: 22,611.38178
Overall Steps per Second: 10,457.76833

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.57078
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.78286

Cumulative Model Updates: 147,122
Cumulative Timesteps: 1,226,814,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1226814054...
Checkpoint 1226814054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,668.87869
Policy Entropy: 3.76349
Value Function Loss: 0.01948

Mean KL Divergence: 0.02075
SB3 Clip Fraction: 0.23797
Policy Update Magnitude: 0.64833
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 21,627.50664
Overall Steps per Second: 10,598.94691

Timestep Collection Time: 2.31206
Timestep Consumption Time: 2.40577
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.71783

Cumulative Model Updates: 147,128
Cumulative Timesteps: 1,226,864,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,659.87406
Policy Entropy: 3.75548
Value Function Loss: 0.02708

Mean KL Divergence: 0.02437
SB3 Clip Fraction: 0.24982
Policy Update Magnitude: 0.52639
Value Function Update Magnitude: 0.54890

Collected Steps per Second: 21,711.96416
Overall Steps per Second: 10,551.15195

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.74147

Cumulative Model Updates: 147,134
Cumulative Timesteps: 1,226,914,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1226914086...
Checkpoint 1226914086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,764.12914
Policy Entropy: 3.80064
Value Function Loss: 0.07167

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16535
Policy Update Magnitude: 0.59227
Value Function Update Magnitude: 0.42228

Collected Steps per Second: 21,671.70252
Overall Steps per Second: 10,567.80962

Timestep Collection Time: 2.30762
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.73230

Cumulative Model Updates: 147,140
Cumulative Timesteps: 1,226,964,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,680.06675
Policy Entropy: 3.81006
Value Function Loss: 0.03390

Mean KL Divergence: 0.02179
SB3 Clip Fraction: 0.23641
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.36944

Collected Steps per Second: 21,845.67623
Overall Steps per Second: 10,639.55970

Timestep Collection Time: 2.28997
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.70189

Cumulative Model Updates: 147,146
Cumulative Timesteps: 1,227,014,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1227014122...
Checkpoint 1227014122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,776.59581
Policy Entropy: 3.82798
Value Function Loss: 0.04256

Mean KL Divergence: 0.01408
SB3 Clip Fraction: 0.17625
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.35250

Collected Steps per Second: 21,475.80569
Overall Steps per Second: 10,460.59303

Timestep Collection Time: 2.32867
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.78080

Cumulative Model Updates: 147,152
Cumulative Timesteps: 1,227,064,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,166.04137
Policy Entropy: 3.76058
Value Function Loss: 0.03225

Mean KL Divergence: 0.02367
SB3 Clip Fraction: 0.26903
Policy Update Magnitude: 0.47214
Value Function Update Magnitude: 0.34658

Collected Steps per Second: 22,546.08029
Overall Steps per Second: 10,629.30355

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.70699

Cumulative Model Updates: 147,158
Cumulative Timesteps: 1,227,114,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1227114164...
Checkpoint 1227114164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,994.13387
Policy Entropy: 3.73079
Value Function Loss: 0.03318

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.20344
Policy Update Magnitude: 0.53755
Value Function Update Magnitude: 0.40130

Collected Steps per Second: 21,957.20260
Overall Steps per Second: 10,540.62716

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.74507

Cumulative Model Updates: 147,164
Cumulative Timesteps: 1,227,164,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,658.32436
Policy Entropy: 3.70382
Value Function Loss: 0.03275

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.18078
Policy Update Magnitude: 0.67633
Value Function Update Magnitude: 0.51740

Collected Steps per Second: 22,338.33152
Overall Steps per Second: 10,534.87128

Timestep Collection Time: 2.23875
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74709

Cumulative Model Updates: 147,170
Cumulative Timesteps: 1,227,214,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1227214190...
Checkpoint 1227214190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839,076.60414
Policy Entropy: 3.70674
Value Function Loss: 0.04094

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15578
Policy Update Magnitude: 0.65088
Value Function Update Magnitude: 0.56019

Collected Steps per Second: 21,917.43888
Overall Steps per Second: 10,634.73052

Timestep Collection Time: 2.28174
Timestep Consumption Time: 2.42077
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.70252

Cumulative Model Updates: 147,176
Cumulative Timesteps: 1,227,264,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,410.96603
Policy Entropy: 3.75123
Value Function Loss: 0.04120

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.73003
Value Function Update Magnitude: 0.56382

Collected Steps per Second: 22,178.39301
Overall Steps per Second: 10,286.22486

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.60726
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 4.86243

Cumulative Model Updates: 147,182
Cumulative Timesteps: 1,227,314,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1227314216...
Checkpoint 1227314216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 450.76111
Policy Entropy: 3.74598
Value Function Loss: 0.04062

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15580
Policy Update Magnitude: 0.75563
Value Function Update Magnitude: 0.57059

Collected Steps per Second: 21,893.45619
Overall Steps per Second: 10,412.24173

Timestep Collection Time: 2.28516
Timestep Consumption Time: 2.51976
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.80492

Cumulative Model Updates: 147,188
Cumulative Timesteps: 1,227,364,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,602.52839
Policy Entropy: 3.78441
Value Function Loss: 0.02900

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14029
Policy Update Magnitude: 0.66802
Value Function Update Magnitude: 0.58200

Collected Steps per Second: 22,199.66570
Overall Steps per Second: 10,494.17149

Timestep Collection Time: 2.25301
Timestep Consumption Time: 2.51307
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.76607

Cumulative Model Updates: 147,194
Cumulative Timesteps: 1,227,414,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1227414262...
Checkpoint 1227414262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,759.48472
Policy Entropy: 3.74118
Value Function Loss: 0.02967

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.62426
Value Function Update Magnitude: 0.53735

Collected Steps per Second: 22,385.20386
Overall Steps per Second: 10,494.84511

Timestep Collection Time: 2.23371
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.76443

Cumulative Model Updates: 147,200
Cumulative Timesteps: 1,227,464,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,654.01496
Policy Entropy: 3.76776
Value Function Loss: 0.02837

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.61439
Value Function Update Magnitude: 0.48451

Collected Steps per Second: 22,390.39579
Overall Steps per Second: 10,507.90607

Timestep Collection Time: 2.23489
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.76213

Cumulative Model Updates: 147,206
Cumulative Timesteps: 1,227,514,304

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1227514304...
Checkpoint 1227514304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,958.25686
Policy Entropy: 3.77720
Value Function Loss: 0.03008

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.60203
Value Function Update Magnitude: 0.45980

Collected Steps per Second: 22,502.97809
Overall Steps per Second: 10,576.52529

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.50652
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.72934

Cumulative Model Updates: 147,212
Cumulative Timesteps: 1,227,564,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,333.60016
Policy Entropy: 3.78882
Value Function Loss: 0.02503

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.60597
Value Function Update Magnitude: 0.46920

Collected Steps per Second: 22,380.75693
Overall Steps per Second: 10,527.01769

Timestep Collection Time: 2.23469
Timestep Consumption Time: 2.51633
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.75101

Cumulative Model Updates: 147,218
Cumulative Timesteps: 1,227,614,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1227614338...
Checkpoint 1227614338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,667.94573
Policy Entropy: 3.76491
Value Function Loss: 0.02371

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15140
Policy Update Magnitude: 0.56558
Value Function Update Magnitude: 0.49673

Collected Steps per Second: 22,357.95856
Overall Steps per Second: 10,591.85736

Timestep Collection Time: 2.23679
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.72155

Cumulative Model Updates: 147,224
Cumulative Timesteps: 1,227,664,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,667.94573
Policy Entropy: 3.74065
Value Function Loss: 0.02011

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15873
Policy Update Magnitude: 0.48292
Value Function Update Magnitude: 0.52014

Collected Steps per Second: 22,497.86600
Overall Steps per Second: 10,580.36674

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.72630

Cumulative Model Updates: 147,230
Cumulative Timesteps: 1,227,714,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1227714354...
Checkpoint 1227714354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490,568.38786
Policy Entropy: 3.74178
Value Function Loss: 0.01990

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13712
Policy Update Magnitude: 0.44694
Value Function Update Magnitude: 0.50868

Collected Steps per Second: 22,460.97137
Overall Steps per Second: 10,552.37460

Timestep Collection Time: 2.22608
Timestep Consumption Time: 2.51219
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73827

Cumulative Model Updates: 147,236
Cumulative Timesteps: 1,227,764,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,239.47168
Policy Entropy: 3.75571
Value Function Loss: 0.02148

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.48953
Value Function Update Magnitude: 0.46472

Collected Steps per Second: 22,133.48848
Overall Steps per Second: 10,450.69800

Timestep Collection Time: 2.26019
Timestep Consumption Time: 2.52666
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.78686

Cumulative Model Updates: 147,242
Cumulative Timesteps: 1,227,814,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1227814380...
Checkpoint 1227814380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,186.13520
Policy Entropy: 3.76164
Value Function Loss: 0.02218

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14401
Policy Update Magnitude: 0.52017
Value Function Update Magnitude: 0.63413

Collected Steps per Second: 22,026.15041
Overall Steps per Second: 10,638.67193

Timestep Collection Time: 2.27066
Timestep Consumption Time: 2.43049
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.70115

Cumulative Model Updates: 147,248
Cumulative Timesteps: 1,227,864,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,204.32974
Policy Entropy: 3.77043
Value Function Loss: 0.02201

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.51497
Value Function Update Magnitude: 0.72054

Collected Steps per Second: 22,555.96615
Overall Steps per Second: 10,576.79501

Timestep Collection Time: 2.21760
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.72922

Cumulative Model Updates: 147,254
Cumulative Timesteps: 1,227,914,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1227914414...
Checkpoint 1227914414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,405.24966
Policy Entropy: 3.75021
Value Function Loss: 0.02130

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.50857
Value Function Update Magnitude: 0.73159

Collected Steps per Second: 21,916.12065
Overall Steps per Second: 10,350.10761

Timestep Collection Time: 2.28261
Timestep Consumption Time: 2.55077
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.83338

Cumulative Model Updates: 147,260
Cumulative Timesteps: 1,227,964,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,286.74507
Policy Entropy: 3.75016
Value Function Loss: 0.02117

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.52733
Value Function Update Magnitude: 0.64849

Collected Steps per Second: 22,529.66389
Overall Steps per Second: 10,561.46339

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.51530
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.73495

Cumulative Model Updates: 147,266
Cumulative Timesteps: 1,228,014,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1228014448...
Checkpoint 1228014448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265,324.09678
Policy Entropy: 3.75128
Value Function Loss: 0.02501

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.52838
Value Function Update Magnitude: 0.61321

Collected Steps per Second: 22,352.33666
Overall Steps per Second: 10,705.46464

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.67051

Cumulative Model Updates: 147,272
Cumulative Timesteps: 1,228,064,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,790.15620
Policy Entropy: 3.75884
Value Function Loss: 0.02439

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.54181

Collected Steps per Second: 22,846.53188
Overall Steps per Second: 10,807.17562

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.62804

Cumulative Model Updates: 147,278
Cumulative Timesteps: 1,228,114,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1228114464...
Checkpoint 1228114464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,216.01411
Policy Entropy: 3.75808
Value Function Loss: 0.02451

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.50397
Value Function Update Magnitude: 0.49479

Collected Steps per Second: 22,463.54591
Overall Steps per Second: 10,742.26495

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.42965
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.65637

Cumulative Model Updates: 147,284
Cumulative Timesteps: 1,228,164,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,704.35555
Policy Entropy: 3.75727
Value Function Loss: 0.01952

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.45441
Value Function Update Magnitude: 0.48207

Collected Steps per Second: 22,369.52281
Overall Steps per Second: 10,870.10065

Timestep Collection Time: 2.23733
Timestep Consumption Time: 2.36686
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.60419

Cumulative Model Updates: 147,290
Cumulative Timesteps: 1,228,214,532

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1228214532...
Checkpoint 1228214532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,343.91337
Policy Entropy: 3.76028
Value Function Loss: 0.01972

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.41850
Value Function Update Magnitude: 0.43254

Collected Steps per Second: 21,656.05129
Overall Steps per Second: 10,672.59458

Timestep Collection Time: 2.30901
Timestep Consumption Time: 2.37626
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.68527

Cumulative Model Updates: 147,296
Cumulative Timesteps: 1,228,264,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,820.33750
Policy Entropy: 3.77245
Value Function Loss: 0.01838

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.41127
Value Function Update Magnitude: 0.36132

Collected Steps per Second: 21,556.46377
Overall Steps per Second: 10,520.05735

Timestep Collection Time: 2.31949
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.75283

Cumulative Model Updates: 147,302
Cumulative Timesteps: 1,228,314,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1228314536...
Checkpoint 1228314536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.77351
Value Function Loss: 0.01832

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.40490
Value Function Update Magnitude: 0.34462

Collected Steps per Second: 21,361.79476
Overall Steps per Second: 10,552.68595

Timestep Collection Time: 2.34063
Timestep Consumption Time: 2.39750
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.73813

Cumulative Model Updates: 147,308
Cumulative Timesteps: 1,228,364,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.76623
Value Function Loss: 0.01677

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.37517
Value Function Update Magnitude: 0.37589

Collected Steps per Second: 21,787.76821
Overall Steps per Second: 10,445.00278

Timestep Collection Time: 2.29505
Timestep Consumption Time: 2.49231
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.78736

Cumulative Model Updates: 147,314
Cumulative Timesteps: 1,228,414,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1228414540...
Checkpoint 1228414540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.76192
Value Function Loss: 0.01630

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.38261
Value Function Update Magnitude: 0.35556

Collected Steps per Second: 21,644.58221
Overall Steps per Second: 10,602.27189

Timestep Collection Time: 2.31014
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.71616

Cumulative Model Updates: 147,320
Cumulative Timesteps: 1,228,464,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.74514
Value Function Loss: 0.01600

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.41065
Value Function Update Magnitude: 0.36245

Collected Steps per Second: 22,134.90636
Overall Steps per Second: 10,482.69853

Timestep Collection Time: 2.25969
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.77148

Cumulative Model Updates: 147,326
Cumulative Timesteps: 1,228,514,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1228514560...
Checkpoint 1228514560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.73801
Value Function Loss: 0.01595

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13905
Policy Update Magnitude: 0.40495
Value Function Update Magnitude: 0.34324

Collected Steps per Second: 22,294.12274
Overall Steps per Second: 10,562.49968

Timestep Collection Time: 2.24319
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.73467

Cumulative Model Updates: 147,332
Cumulative Timesteps: 1,228,564,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.72739
Value Function Loss: 0.01627

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14574
Policy Update Magnitude: 0.38181
Value Function Update Magnitude: 0.27935

Collected Steps per Second: 22,713.02312
Overall Steps per Second: 10,604.09086

Timestep Collection Time: 2.20261
Timestep Consumption Time: 2.51519
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.71780

Cumulative Model Updates: 147,338
Cumulative Timesteps: 1,228,614,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1228614598...
Checkpoint 1228614598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.36330
Policy Entropy: 3.73214
Value Function Loss: 0.01756

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.41119
Value Function Update Magnitude: 0.24773

Collected Steps per Second: 21,791.40321
Overall Steps per Second: 10,566.58216

Timestep Collection Time: 2.29540
Timestep Consumption Time: 2.43839
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.73379

Cumulative Model Updates: 147,344
Cumulative Timesteps: 1,228,664,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,781.38787
Policy Entropy: 3.73984
Value Function Loss: 0.01753

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.43267
Value Function Update Magnitude: 0.26939

Collected Steps per Second: 22,203.68364
Overall Steps per Second: 10,491.01710

Timestep Collection Time: 2.25296
Timestep Consumption Time: 2.51531
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.76827

Cumulative Model Updates: 147,350
Cumulative Timesteps: 1,228,714,642

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1228714642...
Checkpoint 1228714642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,832.44733
Policy Entropy: 3.73987
Value Function Loss: 0.01865

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.43078
Value Function Update Magnitude: 0.29065

Collected Steps per Second: 22,116.97030
Overall Steps per Second: 10,641.01711

Timestep Collection Time: 2.26080
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.69899

Cumulative Model Updates: 147,356
Cumulative Timesteps: 1,228,764,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,832.44733
Policy Entropy: 3.73118
Value Function Loss: 0.01743

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.43433
Value Function Update Magnitude: 0.30986

Collected Steps per Second: 22,733.86500
Overall Steps per Second: 10,772.86798

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.44251
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.64240

Cumulative Model Updates: 147,362
Cumulative Timesteps: 1,228,814,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1228814656...
Checkpoint 1228814656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,722.91321
Policy Entropy: 3.72946
Value Function Loss: 0.02076

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.44994
Value Function Update Magnitude: 0.34738

Collected Steps per Second: 21,187.73851
Overall Steps per Second: 10,470.02793

Timestep Collection Time: 2.36052
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.77687

Cumulative Model Updates: 147,368
Cumulative Timesteps: 1,228,864,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,025.44742
Policy Entropy: 3.74958
Value Function Loss: 0.01987

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.51008
Value Function Update Magnitude: 0.54614

Collected Steps per Second: 21,684.83775
Overall Steps per Second: 10,675.79398

Timestep Collection Time: 2.30622
Timestep Consumption Time: 2.37821
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.68443

Cumulative Model Updates: 147,374
Cumulative Timesteps: 1,228,914,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1228914680...
Checkpoint 1228914680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,514.45552
Policy Entropy: 3.75609
Value Function Loss: 0.02734

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.58386
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 20,898.62674
Overall Steps per Second: 10,396.39526

Timestep Collection Time: 2.39279
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.80994

Cumulative Model Updates: 147,380
Cumulative Timesteps: 1,228,964,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,115.37062
Policy Entropy: 3.74757
Value Function Loss: 0.02704

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12965
Policy Update Magnitude: 0.64482
Value Function Update Magnitude: 0.63051

Collected Steps per Second: 21,433.58528
Overall Steps per Second: 10,680.36505

Timestep Collection Time: 2.33353
Timestep Consumption Time: 2.34945
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.68299

Cumulative Model Updates: 147,386
Cumulative Timesteps: 1,229,014,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1229014702...
Checkpoint 1229014702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,763.08960
Policy Entropy: 3.73830
Value Function Loss: 0.02906

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.63854
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 21,402.46556
Overall Steps per Second: 10,392.69375

Timestep Collection Time: 2.33749
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.81377

Cumulative Model Updates: 147,392
Cumulative Timesteps: 1,229,064,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,042.44077
Policy Entropy: 3.75458
Value Function Loss: 0.02383

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.61318
Value Function Update Magnitude: 0.54109

Collected Steps per Second: 22,458.34061
Overall Steps per Second: 10,766.16202

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.41880
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.64604

Cumulative Model Updates: 147,398
Cumulative Timesteps: 1,229,114,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1229114750...
Checkpoint 1229114750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,292.90406
Policy Entropy: 3.75389
Value Function Loss: 0.02134

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.51291

Collected Steps per Second: 22,510.76521
Overall Steps per Second: 10,605.63185

Timestep Collection Time: 2.22116
Timestep Consumption Time: 2.49332
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.71448

Cumulative Model Updates: 147,404
Cumulative Timesteps: 1,229,164,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,659.75330
Policy Entropy: 3.75582
Value Function Loss: 0.01830

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13406
Policy Update Magnitude: 0.47734
Value Function Update Magnitude: 0.52424

Collected Steps per Second: 22,876.04773
Overall Steps per Second: 10,664.31003

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.69097

Cumulative Model Updates: 147,410
Cumulative Timesteps: 1,229,214,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1229214776...
Checkpoint 1229214776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,945.73931
Policy Entropy: 3.74606
Value Function Loss: 0.02002

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.45656
Value Function Update Magnitude: 0.50753

Collected Steps per Second: 22,650.10175
Overall Steps per Second: 10,640.13373

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.70126

Cumulative Model Updates: 147,416
Cumulative Timesteps: 1,229,264,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,622.71579
Policy Entropy: 3.76124
Value Function Loss: 0.01902

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.49537

Collected Steps per Second: 23,082.57334
Overall Steps per Second: 10,729.41549

Timestep Collection Time: 2.16614
Timestep Consumption Time: 2.49395
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.66009

Cumulative Model Updates: 147,422
Cumulative Timesteps: 1,229,314,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1229314798...
Checkpoint 1229314798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,057.65035
Policy Entropy: 3.73756
Value Function Loss: 0.02420

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.49406
Value Function Update Magnitude: 0.49349

Collected Steps per Second: 22,513.94803
Overall Steps per Second: 10,610.50959

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.71514

Cumulative Model Updates: 147,428
Cumulative Timesteps: 1,229,364,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,284.93881
Policy Entropy: 3.75925
Value Function Loss: 0.02313

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.53499
Value Function Update Magnitude: 0.51086

Collected Steps per Second: 21,771.12208
Overall Steps per Second: 10,513.17982

Timestep Collection Time: 2.29781
Timestep Consumption Time: 2.46059
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.75841

Cumulative Model Updates: 147,434
Cumulative Timesteps: 1,229,414,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1229414854...
Checkpoint 1229414854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,210.89888
Policy Entropy: 3.76871
Value Function Loss: 0.02716

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.52790
Value Function Update Magnitude: 0.60676

Collected Steps per Second: 22,246.24147
Overall Steps per Second: 10,704.98522

Timestep Collection Time: 2.24829
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.67222

Cumulative Model Updates: 147,440
Cumulative Timesteps: 1,229,464,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,066.33133
Policy Entropy: 3.79430
Value Function Loss: 0.02384

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.51540
Value Function Update Magnitude: 0.59537

Collected Steps per Second: 22,158.18939
Overall Steps per Second: 10,488.74053

Timestep Collection Time: 2.25686
Timestep Consumption Time: 2.51092
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.76778

Cumulative Model Updates: 147,446
Cumulative Timesteps: 1,229,514,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1229514878...
Checkpoint 1229514878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,005.83390
Policy Entropy: 3.78200
Value Function Loss: 0.02244

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.48421
Value Function Update Magnitude: 0.65587

Collected Steps per Second: 21,968.28336
Overall Steps per Second: 10,520.08380

Timestep Collection Time: 2.27710
Timestep Consumption Time: 2.47799
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.75510

Cumulative Model Updates: 147,452
Cumulative Timesteps: 1,229,564,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.33606
Policy Entropy: 3.76068
Value Function Loss: 0.01992

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14136
Policy Update Magnitude: 0.45499
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 21,993.97150
Overall Steps per Second: 10,483.72279

Timestep Collection Time: 2.27490
Timestep Consumption Time: 2.49765
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.77254

Cumulative Model Updates: 147,458
Cumulative Timesteps: 1,229,614,936

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1229614936...
Checkpoint 1229614936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.33606
Policy Entropy: 3.75265
Value Function Loss: 0.01693

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.43906
Value Function Update Magnitude: 0.58040

Collected Steps per Second: 22,120.98578
Overall Steps per Second: 10,666.59112

Timestep Collection Time: 2.26030
Timestep Consumption Time: 2.42724
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.68753

Cumulative Model Updates: 147,464
Cumulative Timesteps: 1,229,664,936

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.33606
Policy Entropy: 3.74756
Value Function Loss: 0.01483

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.40620
Value Function Update Magnitude: 0.47063

Collected Steps per Second: 22,749.70702
Overall Steps per Second: 10,576.11187

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.53132
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.73047

Cumulative Model Updates: 147,470
Cumulative Timesteps: 1,229,714,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1229714966...
Checkpoint 1229714966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,737.09304
Policy Entropy: 3.75918
Value Function Loss: 0.01374

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.40093
Value Function Update Magnitude: 0.48543

Collected Steps per Second: 22,674.64947
Overall Steps per Second: 10,580.80031

Timestep Collection Time: 2.20608
Timestep Consumption Time: 2.52154
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.72762

Cumulative Model Updates: 147,476
Cumulative Timesteps: 1,229,764,988

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,395.52234
Policy Entropy: 3.75380
Value Function Loss: 0.01399

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.40619
Value Function Update Magnitude: 0.52758

Collected Steps per Second: 22,428.44198
Overall Steps per Second: 10,657.13654

Timestep Collection Time: 2.23038
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.69394

Cumulative Model Updates: 147,482
Cumulative Timesteps: 1,229,815,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1229815012...
Checkpoint 1229815012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,395.52234
Policy Entropy: 3.75759
Value Function Loss: 0.01421

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.44409
Value Function Update Magnitude: 0.56839

Collected Steps per Second: 22,363.88691
Overall Steps per Second: 10,715.62233

Timestep Collection Time: 2.23602
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.66664

Cumulative Model Updates: 147,488
Cumulative Timesteps: 1,229,865,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,276.48995
Policy Entropy: 3.74838
Value Function Loss: 0.01440

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13269
Policy Update Magnitude: 0.45701
Value Function Update Magnitude: 0.62305

Collected Steps per Second: 22,799.85729
Overall Steps per Second: 10,639.22312

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.50820
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.70260

Cumulative Model Updates: 147,494
Cumulative Timesteps: 1,229,915,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1229915050...
Checkpoint 1229915050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,543.52618
Policy Entropy: 3.73396
Value Function Loss: 0.01898

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.51584
Value Function Update Magnitude: 0.64446

Collected Steps per Second: 22,564.82684
Overall Steps per Second: 10,605.88521

Timestep Collection Time: 2.21646
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.71568

Cumulative Model Updates: 147,500
Cumulative Timesteps: 1,229,965,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,572.35512
Policy Entropy: 3.75236
Value Function Loss: 0.02189

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.60328

Collected Steps per Second: 22,564.54394
Overall Steps per Second: 10,777.31259

Timestep Collection Time: 2.21728
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.64234

Cumulative Model Updates: 147,506
Cumulative Timesteps: 1,230,015,096

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1230015096...
Checkpoint 1230015096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,807.67887
Policy Entropy: 3.75602
Value Function Loss: 0.02179

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 21,949.55745
Overall Steps per Second: 10,665.08681

Timestep Collection Time: 2.27868
Timestep Consumption Time: 2.41102
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.68969

Cumulative Model Updates: 147,512
Cumulative Timesteps: 1,230,065,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,794.87747
Policy Entropy: 3.76031
Value Function Loss: 0.01998

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.54743

Collected Steps per Second: 22,536.83149
Overall Steps per Second: 10,631.49120

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.70564

Cumulative Model Updates: 147,518
Cumulative Timesteps: 1,230,115,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1230115140...
Checkpoint 1230115140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,604.87347
Policy Entropy: 3.75196
Value Function Loss: 0.02317

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.50321
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 21,797.59918
Overall Steps per Second: 10,488.85072

Timestep Collection Time: 2.29383
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.76697

Cumulative Model Updates: 147,524
Cumulative Timesteps: 1,230,165,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,936.84958
Policy Entropy: 3.75979
Value Function Loss: 0.02525

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 21,866.63694
Overall Steps per Second: 10,651.89055

Timestep Collection Time: 2.28778
Timestep Consumption Time: 2.40867
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.69644

Cumulative Model Updates: 147,530
Cumulative Timesteps: 1,230,215,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1230215166...
Checkpoint 1230215166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,581.43142
Policy Entropy: 3.77036
Value Function Loss: 0.02526

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13077
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.84635

Collected Steps per Second: 21,544.23377
Overall Steps per Second: 10,512.45031

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75684

Cumulative Model Updates: 147,536
Cumulative Timesteps: 1,230,265,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,909.06447
Policy Entropy: 3.77106
Value Function Loss: 0.02181

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.88549

Collected Steps per Second: 22,135.35030
Overall Steps per Second: 10,755.68224

Timestep Collection Time: 2.26019
Timestep Consumption Time: 2.39131
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.65149

Cumulative Model Updates: 147,542
Cumulative Timesteps: 1,230,315,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1230315202...
Checkpoint 1230315202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,877.42820
Policy Entropy: 3.77422
Value Function Loss: 0.01891

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.51872
Value Function Update Magnitude: 0.79682

Collected Steps per Second: 21,456.98081
Overall Steps per Second: 10,344.40085

Timestep Collection Time: 2.33155
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.83624

Cumulative Model Updates: 147,548
Cumulative Timesteps: 1,230,365,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,801.11486
Policy Entropy: 3.76943
Value Function Loss: 0.02143

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.50257
Value Function Update Magnitude: 0.60636

Collected Steps per Second: 22,807.01099
Overall Steps per Second: 10,850.18292

Timestep Collection Time: 2.19371
Timestep Consumption Time: 2.41746
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.61117

Cumulative Model Updates: 147,554
Cumulative Timesteps: 1,230,415,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1230415262...
Checkpoint 1230415262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,592.09228
Policy Entropy: 3.78080
Value Function Loss: 0.02427

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.52775
Value Function Update Magnitude: 0.55778

Collected Steps per Second: 22,220.88369
Overall Steps per Second: 10,652.02265

Timestep Collection Time: 2.25122
Timestep Consumption Time: 2.44498
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.69620

Cumulative Model Updates: 147,560
Cumulative Timesteps: 1,230,465,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,304.03651
Policy Entropy: 3.76947
Value Function Loss: 0.02334

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13529
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.56501

Collected Steps per Second: 22,503.96276
Overall Steps per Second: 10,602.54909

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.49442
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.71660

Cumulative Model Updates: 147,566
Cumulative Timesteps: 1,230,515,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1230515294...
Checkpoint 1230515294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,564.89142
Policy Entropy: 3.77374
Value Function Loss: 0.02415

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.50909
Value Function Update Magnitude: 0.66213

Collected Steps per Second: 22,461.06953
Overall Steps per Second: 10,561.13133

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.73491

Cumulative Model Updates: 147,572
Cumulative Timesteps: 1,230,565,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,854.41490
Policy Entropy: 3.74787
Value Function Loss: 0.02198

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.71565

Collected Steps per Second: 22,285.10660
Overall Steps per Second: 10,594.68327

Timestep Collection Time: 2.24419
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.72048

Cumulative Model Updates: 147,578
Cumulative Timesteps: 1,230,615,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1230615312...
Checkpoint 1230615312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,351.67719
Policy Entropy: 3.75125
Value Function Loss: 0.02208

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.69468

Collected Steps per Second: 21,769.96660
Overall Steps per Second: 10,442.17661

Timestep Collection Time: 2.29812
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.79115

Cumulative Model Updates: 147,584
Cumulative Timesteps: 1,230,665,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,257.84928
Policy Entropy: 3.72855
Value Function Loss: 0.02120

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.69141

Collected Steps per Second: 22,324.62299
Overall Steps per Second: 10,540.99861

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.74604

Cumulative Model Updates: 147,590
Cumulative Timesteps: 1,230,715,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1230715370...
Checkpoint 1230715370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,060.61982
Policy Entropy: 3.74340
Value Function Loss: 0.02088

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.69432

Collected Steps per Second: 22,154.94163
Overall Steps per Second: 10,547.68784

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.74284

Cumulative Model Updates: 147,596
Cumulative Timesteps: 1,230,765,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,941.23341
Policy Entropy: 3.74077
Value Function Loss: 0.02160

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.74930

Collected Steps per Second: 22,281.63179
Overall Steps per Second: 10,520.56680

Timestep Collection Time: 2.24517
Timestep Consumption Time: 2.50990
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.75507

Cumulative Model Updates: 147,602
Cumulative Timesteps: 1,230,815,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1230815422...
Checkpoint 1230815422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,183.18744
Policy Entropy: 3.75349
Value Function Loss: 0.02399

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.63727

Collected Steps per Second: 22,081.13385
Overall Steps per Second: 10,612.27027

Timestep Collection Time: 2.26646
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.71586

Cumulative Model Updates: 147,608
Cumulative Timesteps: 1,230,865,468

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,411.32136
Policy Entropy: 3.75102
Value Function Loss: 0.02448

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.52285
Value Function Update Magnitude: 0.55202

Collected Steps per Second: 22,663.44807
Overall Steps per Second: 10,612.93430

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.71349

Cumulative Model Updates: 147,614
Cumulative Timesteps: 1,230,915,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1230915492...
Checkpoint 1230915492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,898.28744
Policy Entropy: 3.76384
Value Function Loss: 0.02590

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.51997
Value Function Update Magnitude: 0.51247

Collected Steps per Second: 22,623.49543
Overall Steps per Second: 10,650.55588

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.48659
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.69853

Cumulative Model Updates: 147,620
Cumulative Timesteps: 1,230,965,534

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,509.80638
Policy Entropy: 3.76783
Value Function Loss: 0.02507

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.55364
Value Function Update Magnitude: 0.52799

Collected Steps per Second: 22,506.89529
Overall Steps per Second: 10,760.57716

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.42534
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.64715

Cumulative Model Updates: 147,626
Cumulative Timesteps: 1,231,015,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1231015540...
Checkpoint 1231015540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,037.60702
Policy Entropy: 3.76531
Value Function Loss: 0.02395

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14731
Policy Update Magnitude: 0.57285
Value Function Update Magnitude: 0.55156

Collected Steps per Second: 22,351.24258
Overall Steps per Second: 10,575.77147

Timestep Collection Time: 2.23791
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.72968

Cumulative Model Updates: 147,632
Cumulative Timesteps: 1,231,065,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,687.91500
Policy Entropy: 3.75625
Value Function Loss: 0.02385

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 22,521.10205
Overall Steps per Second: 10,622.71133

Timestep Collection Time: 2.22138
Timestep Consumption Time: 2.48815
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.70953

Cumulative Model Updates: 147,638
Cumulative Timesteps: 1,231,115,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1231115588...
Checkpoint 1231115588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,906.46129
Policy Entropy: 3.77667
Value Function Loss: 0.02175

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.64586

Collected Steps per Second: 22,702.33414
Overall Steps per Second: 10,674.07086

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.48203
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68462

Cumulative Model Updates: 147,644
Cumulative Timesteps: 1,231,165,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,465.70620
Policy Entropy: 3.76272
Value Function Loss: 0.02085

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.52192
Value Function Update Magnitude: 0.65947

Collected Steps per Second: 22,290.70767
Overall Steps per Second: 10,700.72020

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67296

Cumulative Model Updates: 147,650
Cumulative Timesteps: 1,231,215,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1231215596...
Checkpoint 1231215596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.53072
Policy Entropy: 3.77036
Value Function Loss: 0.01920

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.48405
Value Function Update Magnitude: 0.60835

Collected Steps per Second: 22,061.05484
Overall Steps per Second: 10,708.82492

Timestep Collection Time: 2.26753
Timestep Consumption Time: 2.40376
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.67129

Cumulative Model Updates: 147,656
Cumulative Timesteps: 1,231,265,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,784.70141
Policy Entropy: 3.74204
Value Function Loss: 0.01735

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.43795
Value Function Update Magnitude: 0.56377

Collected Steps per Second: 21,202.86674
Overall Steps per Second: 10,406.79248

Timestep Collection Time: 2.35893
Timestep Consumption Time: 2.44717
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.80609

Cumulative Model Updates: 147,662
Cumulative Timesteps: 1,231,315,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1231315636...
Checkpoint 1231315636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,472.13343
Policy Entropy: 3.74425
Value Function Loss: 0.01730

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.42258
Value Function Update Magnitude: 0.47532

Collected Steps per Second: 21,374.12223
Overall Steps per Second: 10,608.75463

Timestep Collection Time: 2.34106
Timestep Consumption Time: 2.37562
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.71667

Cumulative Model Updates: 147,668
Cumulative Timesteps: 1,231,365,674

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,850.26263
Policy Entropy: 3.75076
Value Function Loss: 0.01625

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.43021
Value Function Update Magnitude: 0.43941

Collected Steps per Second: 22,133.41667
Overall Steps per Second: 10,473.28977

Timestep Collection Time: 2.25912
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.77424

Cumulative Model Updates: 147,674
Cumulative Timesteps: 1,231,415,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1231415676...
Checkpoint 1231415676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,043.88457
Policy Entropy: 3.76783
Value Function Loss: 0.01694

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.43377
Value Function Update Magnitude: 0.54427

Collected Steps per Second: 21,929.83514
Overall Steps per Second: 10,563.95726

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.27929
Total Iteration Time: 4.73383

Cumulative Model Updates: 147,680
Cumulative Timesteps: 1,231,465,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,166.04075
Policy Entropy: 3.76363
Value Function Loss: 0.01851

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.44279
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 22,748.56386
Overall Steps per Second: 10,720.60146

Timestep Collection Time: 2.19820
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.66448

Cumulative Model Updates: 147,686
Cumulative Timesteps: 1,231,515,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1231515690...
Checkpoint 1231515690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,144.00335
Policy Entropy: 3.75421
Value Function Loss: 0.01881

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.46995
Value Function Update Magnitude: 0.65113

Collected Steps per Second: 22,904.45664
Overall Steps per Second: 10,882.11545

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59874

Cumulative Model Updates: 147,692
Cumulative Timesteps: 1,231,565,734

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,947.75268
Policy Entropy: 3.74743
Value Function Loss: 0.02074

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.48691
Value Function Update Magnitude: 0.68582

Collected Steps per Second: 22,912.39272
Overall Steps per Second: 10,706.66379

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.48836
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.67111

Cumulative Model Updates: 147,698
Cumulative Timesteps: 1,231,615,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1231615746...
Checkpoint 1231615746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,312.19817
Policy Entropy: 3.75184
Value Function Loss: 0.02053

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.50052
Value Function Update Magnitude: 0.73127

Collected Steps per Second: 22,819.50108
Overall Steps per Second: 10,850.95319

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.41727
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.60881

Cumulative Model Updates: 147,704
Cumulative Timesteps: 1,231,665,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,613.39636
Policy Entropy: 3.74651
Value Function Loss: 0.02062

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.49106
Value Function Update Magnitude: 0.69548

Collected Steps per Second: 22,228.39431
Overall Steps per Second: 10,483.28814

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.52073
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.77064

Cumulative Model Updates: 147,710
Cumulative Timesteps: 1,231,715,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1231715768...
Checkpoint 1231715768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,982.15037
Policy Entropy: 3.74998
Value Function Loss: 0.01844

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.45755
Value Function Update Magnitude: 0.61375

Collected Steps per Second: 22,433.95949
Overall Steps per Second: 10,644.91262

Timestep Collection Time: 2.22992
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.69952

Cumulative Model Updates: 147,716
Cumulative Timesteps: 1,231,765,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,827.34565
Policy Entropy: 3.75229
Value Function Loss: 0.01882

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.42957
Value Function Update Magnitude: 0.59982

Collected Steps per Second: 22,847.27323
Overall Steps per Second: 10,816.80998

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.62262

Cumulative Model Updates: 147,722
Cumulative Timesteps: 1,231,815,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1231815796...
Checkpoint 1231815796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,418.15016
Policy Entropy: 3.76598
Value Function Loss: 0.01948

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.42943
Value Function Update Magnitude: 0.59036

Collected Steps per Second: 22,011.94650
Overall Steps per Second: 10,635.67267

Timestep Collection Time: 2.27149
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70116

Cumulative Model Updates: 147,728
Cumulative Timesteps: 1,231,865,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,369.93856
Policy Entropy: 3.75970
Value Function Loss: 0.01961

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.47322
Value Function Update Magnitude: 0.69625

Collected Steps per Second: 22,668.35577
Overall Steps per Second: 10,524.51102

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.54622
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.75290

Cumulative Model Updates: 147,734
Cumulative Timesteps: 1,231,915,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1231915818...
Checkpoint 1231915818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,819.57741
Policy Entropy: 3.74758
Value Function Loss: 0.02099

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13364
Policy Update Magnitude: 0.51713
Value Function Update Magnitude: 0.78269

Collected Steps per Second: 22,750.14537
Overall Steps per Second: 10,573.41471

Timestep Collection Time: 2.19814
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.72960

Cumulative Model Updates: 147,740
Cumulative Timesteps: 1,231,965,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.74414
Value Function Loss: 0.02153

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.52643
Value Function Update Magnitude: 0.74565

Collected Steps per Second: 22,874.81277
Overall Steps per Second: 10,702.36472

Timestep Collection Time: 2.18651
Timestep Consumption Time: 2.48685
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.67336

Cumulative Model Updates: 147,746
Cumulative Timesteps: 1,232,015,842

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1232015842...
Checkpoint 1232015842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.72686
Value Function Loss: 0.01826

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.50188
Value Function Update Magnitude: 0.66850

Collected Steps per Second: 22,592.97142
Overall Steps per Second: 10,629.15969

Timestep Collection Time: 2.21405
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.70611

Cumulative Model Updates: 147,752
Cumulative Timesteps: 1,232,065,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.72479
Value Function Loss: 0.01612

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.46102
Value Function Update Magnitude: 0.55069

Collected Steps per Second: 22,813.06987
Overall Steps per Second: 10,762.65308

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.45515
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.64792

Cumulative Model Updates: 147,758
Cumulative Timesteps: 1,232,115,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1232115888...
Checkpoint 1232115888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.73280
Value Function Loss: 0.01538

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13670
Policy Update Magnitude: 0.43657
Value Function Update Magnitude: 0.38694

Collected Steps per Second: 22,582.14159
Overall Steps per Second: 10,648.09566

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.69830

Cumulative Model Updates: 147,764
Cumulative Timesteps: 1,232,165,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.73722
Value Function Loss: 0.01463

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.44530
Value Function Update Magnitude: 0.34822

Collected Steps per Second: 23,130.03438
Overall Steps per Second: 10,880.16446

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.43490
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.59754

Cumulative Model Updates: 147,770
Cumulative Timesteps: 1,232,215,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1232215938...
Checkpoint 1232215938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.72278
Value Function Loss: 0.01630

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.45833
Value Function Update Magnitude: 0.41368

Collected Steps per Second: 21,452.43873
Overall Steps per Second: 10,391.17569

Timestep Collection Time: 2.33092
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.81216

Cumulative Model Updates: 147,776
Cumulative Timesteps: 1,232,265,942

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,788.30167
Policy Entropy: 3.71318
Value Function Loss: 0.01619

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14492
Policy Update Magnitude: 0.50076
Value Function Update Magnitude: 0.46904

Collected Steps per Second: 21,582.68537
Overall Steps per Second: 10,681.92482

Timestep Collection Time: 2.31686
Timestep Consumption Time: 2.36432
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.68118

Cumulative Model Updates: 147,782
Cumulative Timesteps: 1,232,315,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1232315946...
Checkpoint 1232315946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,395.47115
Policy Entropy: 3.72089
Value Function Loss: 0.01671

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14960
Policy Update Magnitude: 0.48890
Value Function Update Magnitude: 0.55523

Collected Steps per Second: 21,055.10411
Overall Steps per Second: 10,575.28086

Timestep Collection Time: 2.37558
Timestep Consumption Time: 2.35413
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.72971

Cumulative Model Updates: 147,788
Cumulative Timesteps: 1,232,365,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,601.87478
Policy Entropy: 3.75064
Value Function Loss: 0.01643

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.46777
Value Function Update Magnitude: 0.60144

Collected Steps per Second: 21,790.70044
Overall Steps per Second: 10,641.21739

Timestep Collection Time: 2.29511
Timestep Consumption Time: 2.40473
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.69984

Cumulative Model Updates: 147,794
Cumulative Timesteps: 1,232,415,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1232415976...
Checkpoint 1232415976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,652.96165
Policy Entropy: 3.76070
Value Function Loss: 0.01836

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.48616
Value Function Update Magnitude: 0.66428

Collected Steps per Second: 22,015.39660
Overall Steps per Second: 10,566.57189

Timestep Collection Time: 2.27168
Timestep Consumption Time: 2.46136
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.73304

Cumulative Model Updates: 147,800
Cumulative Timesteps: 1,232,465,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,272.77758
Policy Entropy: 3.77682
Value Function Loss: 0.01997

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.51987
Value Function Update Magnitude: 0.79074

Collected Steps per Second: 22,807.41703
Overall Steps per Second: 10,819.65881

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.42992
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.62307

Cumulative Model Updates: 147,806
Cumulative Timesteps: 1,232,516,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1232516008...
Checkpoint 1232516008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,469.14628
Policy Entropy: 3.77143
Value Function Loss: 0.02250

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.85810

Collected Steps per Second: 22,256.35716
Overall Steps per Second: 10,737.18706

Timestep Collection Time: 2.24664
Timestep Consumption Time: 2.41026
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.65690

Cumulative Model Updates: 147,812
Cumulative Timesteps: 1,232,566,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,395.12771
Policy Entropy: 3.76557
Value Function Loss: 0.02348

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.63656
Value Function Update Magnitude: 0.81424

Collected Steps per Second: 22,255.59311
Overall Steps per Second: 10,551.25400

Timestep Collection Time: 2.24833
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.74237

Cumulative Model Updates: 147,818
Cumulative Timesteps: 1,232,616,048

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1232616048...
Checkpoint 1232616048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,334.83991
Policy Entropy: 3.74913
Value Function Loss: 0.02575

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.65232
Value Function Update Magnitude: 0.73216

Collected Steps per Second: 22,713.57240
Overall Steps per Second: 10,637.23179

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.70404

Cumulative Model Updates: 147,824
Cumulative Timesteps: 1,232,666,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.74486
Value Function Loss: 0.02418

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.63706
Value Function Update Magnitude: 0.77913

Collected Steps per Second: 22,779.83912
Overall Steps per Second: 10,787.57005

Timestep Collection Time: 2.19536
Timestep Consumption Time: 2.44053
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63589

Cumulative Model Updates: 147,830
Cumulative Timesteps: 1,232,716,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1232716096...
Checkpoint 1232716096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.73790
Value Function Loss: 0.02378

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.59789
Value Function Update Magnitude: 0.79310

Collected Steps per Second: 22,545.34248
Overall Steps per Second: 10,634.77403

Timestep Collection Time: 2.21811
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.70231

Cumulative Model Updates: 147,836
Cumulative Timesteps: 1,232,766,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.73289
Value Function Loss: 0.02176

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.58279

Collected Steps per Second: 22,280.05662
Overall Steps per Second: 10,499.79300

Timestep Collection Time: 2.24434
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.76238

Cumulative Model Updates: 147,842
Cumulative Timesteps: 1,232,816,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1232816108...
Checkpoint 1232816108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.72218
Value Function Loss: 0.02193

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13663
Policy Update Magnitude: 0.49883
Value Function Update Magnitude: 0.39616

Collected Steps per Second: 22,094.27713
Overall Steps per Second: 10,586.76315

Timestep Collection Time: 2.26321
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.72326

Cumulative Model Updates: 147,848
Cumulative Timesteps: 1,232,866,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.73568
Value Function Loss: 0.01730

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.44362
Value Function Update Magnitude: 0.32557

Collected Steps per Second: 21,888.31662
Overall Steps per Second: 10,446.86777

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.78670

Cumulative Model Updates: 147,854
Cumulative Timesteps: 1,232,916,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1232916118...
Checkpoint 1232916118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,214.92505
Policy Entropy: 3.74121
Value Function Loss: 0.01949

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12063
Policy Update Magnitude: 0.50869
Value Function Update Magnitude: 0.35931

Collected Steps per Second: 21,974.37404
Overall Steps per Second: 10,620.76958

Timestep Collection Time: 2.27556
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.70813

Cumulative Model Updates: 147,860
Cumulative Timesteps: 1,232,966,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,611.04040
Policy Entropy: 3.75237
Value Function Loss: 0.02067

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.53007

Collected Steps per Second: 22,342.88899
Overall Steps per Second: 10,514.46771

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.51771
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.75573

Cumulative Model Updates: 147,866
Cumulative Timesteps: 1,233,016,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1233016126...
Checkpoint 1233016126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,125.11023
Policy Entropy: 3.73549
Value Function Loss: 0.02406

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.60000
Value Function Update Magnitude: 0.64343

Collected Steps per Second: 22,607.45354
Overall Steps per Second: 10,627.67600

Timestep Collection Time: 2.21263
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.70677

Cumulative Model Updates: 147,872
Cumulative Timesteps: 1,233,066,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,403.63381
Policy Entropy: 3.74689
Value Function Loss: 0.02316

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.63436
Value Function Update Magnitude: 0.68787

Collected Steps per Second: 21,839.14716
Overall Steps per Second: 10,625.40892

Timestep Collection Time: 2.29029
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.70740

Cumulative Model Updates: 147,878
Cumulative Timesteps: 1,233,116,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1233116166...
Checkpoint 1233116166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,019.14309
Policy Entropy: 3.74490
Value Function Loss: 0.02449

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.64737
Value Function Update Magnitude: 0.77972

Collected Steps per Second: 22,156.99218
Overall Steps per Second: 10,842.00518

Timestep Collection Time: 2.25762
Timestep Consumption Time: 2.35611
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.61372

Cumulative Model Updates: 147,884
Cumulative Timesteps: 1,233,166,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,503.65820
Policy Entropy: 3.76371
Value Function Loss: 0.02252

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.59849
Value Function Update Magnitude: 0.59985

Collected Steps per Second: 21,915.94598
Overall Steps per Second: 10,650.68027

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.69472

Cumulative Model Updates: 147,890
Cumulative Timesteps: 1,233,216,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1233216190...
Checkpoint 1233216190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,949.70531
Policy Entropy: 3.75085
Value Function Loss: 0.02312

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13976
Policy Update Magnitude: 0.57600
Value Function Update Magnitude: 0.49047

Collected Steps per Second: 22,099.73356
Overall Steps per Second: 10,525.52778

Timestep Collection Time: 2.26365
Timestep Consumption Time: 2.48918
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.75283

Cumulative Model Updates: 147,896
Cumulative Timesteps: 1,233,266,216

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,697.72296
Policy Entropy: 3.75940
Value Function Loss: 0.01982

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.52528

Collected Steps per Second: 22,358.19620
Overall Steps per Second: 10,643.25508

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.70044

Cumulative Model Updates: 147,902
Cumulative Timesteps: 1,233,316,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1233316244...
Checkpoint 1233316244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,038.16818
Policy Entropy: 3.75614
Value Function Loss: 0.02203

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.63564
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 22,476.91165
Overall Steps per Second: 10,578.26481

Timestep Collection Time: 2.22673
Timestep Consumption Time: 2.50467
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.73140

Cumulative Model Updates: 147,908
Cumulative Timesteps: 1,233,366,294

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,255.73004
Policy Entropy: 3.78385
Value Function Loss: 0.01994

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.75066
Value Function Update Magnitude: 0.70001

Collected Steps per Second: 22,337.82294
Overall Steps per Second: 10,767.70205

Timestep Collection Time: 2.23836
Timestep Consumption Time: 2.40516
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.64352

Cumulative Model Updates: 147,914
Cumulative Timesteps: 1,233,416,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1233416294...
Checkpoint 1233416294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,090.67075
Policy Entropy: 3.78052
Value Function Loss: 0.02030

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 0.80586
Value Function Update Magnitude: 0.77865

Collected Steps per Second: 22,072.59427
Overall Steps per Second: 10,643.70336

Timestep Collection Time: 2.26589
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.69893

Cumulative Model Updates: 147,920
Cumulative Timesteps: 1,233,466,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,338.32740
Policy Entropy: 3.81331
Value Function Loss: 0.01737

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.73133
Value Function Update Magnitude: 0.72426

Collected Steps per Second: 22,135.42548
Overall Steps per Second: 10,465.82396

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.51934
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.77879

Cumulative Model Updates: 147,926
Cumulative Timesteps: 1,233,516,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1233516322...
Checkpoint 1233516322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,533.20256
Policy Entropy: 3.81538
Value Function Loss: 0.01543

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.65480
Value Function Update Magnitude: 0.73198

Collected Steps per Second: 22,165.94689
Overall Steps per Second: 10,637.64898

Timestep Collection Time: 2.25652
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.70198

Cumulative Model Updates: 147,932
Cumulative Timesteps: 1,233,566,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271,523.95480
Policy Entropy: 3.82431
Value Function Loss: 0.01391

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.61409
Value Function Update Magnitude: 0.65553

Collected Steps per Second: 22,884.96076
Overall Steps per Second: 10,585.29168

Timestep Collection Time: 2.18589
Timestep Consumption Time: 2.53991
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.72580

Cumulative Model Updates: 147,938
Cumulative Timesteps: 1,233,616,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1233616364...
Checkpoint 1233616364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,136.93666
Policy Entropy: 3.81254
Value Function Loss: 0.01555

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11011
Policy Update Magnitude: 0.66224
Value Function Update Magnitude: 0.75962

Collected Steps per Second: 22,738.69250
Overall Steps per Second: 10,632.27917

Timestep Collection Time: 2.19933
Timestep Consumption Time: 2.50427
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70360

Cumulative Model Updates: 147,944
Cumulative Timesteps: 1,233,666,374

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,169.20030
Policy Entropy: 3.81431
Value Function Loss: 0.01582

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.67672
Value Function Update Magnitude: 0.85459

Collected Steps per Second: 23,053.00555
Overall Steps per Second: 10,770.87467

Timestep Collection Time: 2.16909
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.64252

Cumulative Model Updates: 147,950
Cumulative Timesteps: 1,233,716,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1233716378...
Checkpoint 1233716378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,717.58625
Policy Entropy: 3.81194
Value Function Loss: 0.01872

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.66740
Value Function Update Magnitude: 0.83667

Collected Steps per Second: 22,915.45870
Overall Steps per Second: 10,649.07684

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69768

Cumulative Model Updates: 147,956
Cumulative Timesteps: 1,233,766,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,717.02651
Policy Entropy: 3.80594
Value Function Loss: 0.01779

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.62301
Value Function Update Magnitude: 0.73777

Collected Steps per Second: 22,818.18912
Overall Steps per Second: 10,838.84247

Timestep Collection Time: 2.19237
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.61544

Cumulative Model Updates: 147,962
Cumulative Timesteps: 1,233,816,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1233816430...
Checkpoint 1233816430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.89185
Policy Entropy: 3.80996
Value Function Loss: 0.01734

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.52788
Value Function Update Magnitude: 0.64523

Collected Steps per Second: 22,865.63416
Overall Steps per Second: 10,764.33932

Timestep Collection Time: 2.18765
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.64701

Cumulative Model Updates: 147,968
Cumulative Timesteps: 1,233,866,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,741.31266
Policy Entropy: 3.82536
Value Function Loss: 0.01727

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.21834
Policy Update Magnitude: 0.43539
Value Function Update Magnitude: 0.56862

Collected Steps per Second: 22,396.72129
Overall Steps per Second: 10,587.85756

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.72636

Cumulative Model Updates: 147,974
Cumulative Timesteps: 1,233,916,494

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1233916494...
Checkpoint 1233916494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,211.26273
Policy Entropy: 3.81909
Value Function Loss: 0.01497

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18818
Policy Update Magnitude: 0.42165
Value Function Update Magnitude: 0.63041

Collected Steps per Second: 22,014.63129
Overall Steps per Second: 10,504.67859

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.76416

Cumulative Model Updates: 147,980
Cumulative Timesteps: 1,233,966,540

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,583.09728
Policy Entropy: 3.79021
Value Function Loss: 0.01945

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.16500
Policy Update Magnitude: 0.48830
Value Function Update Magnitude: 0.70894

Collected Steps per Second: 21,990.14214
Overall Steps per Second: 10,485.76846

Timestep Collection Time: 2.27575
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.77256

Cumulative Model Updates: 147,986
Cumulative Timesteps: 1,234,016,584

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1234016584...
Checkpoint 1234016584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,012.32224
Policy Entropy: 3.75123
Value Function Loss: 0.02656

Mean KL Divergence: 0.01796
SB3 Clip Fraction: 0.21058
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.78764

Collected Steps per Second: 21,712.63120
Overall Steps per Second: 10,565.92698

Timestep Collection Time: 2.30400
Timestep Consumption Time: 2.43065
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.73465

Cumulative Model Updates: 147,992
Cumulative Timesteps: 1,234,066,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,508.97856
Policy Entropy: 3.77345
Value Function Loss: 0.03330

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.20030
Policy Update Magnitude: 0.66522
Value Function Update Magnitude: 0.83247

Collected Steps per Second: 22,634.38789
Overall Steps per Second: 10,524.14018

Timestep Collection Time: 2.20982
Timestep Consumption Time: 2.54287
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.75269

Cumulative Model Updates: 147,998
Cumulative Timesteps: 1,234,116,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1234116628...
Checkpoint 1234116628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,678.38363
Policy Entropy: 3.83488
Value Function Loss: 0.03625

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.77779
Value Function Update Magnitude: 0.81199

Collected Steps per Second: 22,469.48116
Overall Steps per Second: 10,605.27054

Timestep Collection Time: 2.22595
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.71615

Cumulative Model Updates: 148,004
Cumulative Timesteps: 1,234,166,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,047.23722
Policy Entropy: 3.86891
Value Function Loss: 0.03808

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.15649
Policy Update Magnitude: 0.78780
Value Function Update Magnitude: 0.80464

Collected Steps per Second: 22,703.63497
Overall Steps per Second: 10,659.35418

Timestep Collection Time: 2.20352
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.69334

Cumulative Model Updates: 148,010
Cumulative Timesteps: 1,234,216,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1234216672...
Checkpoint 1234216672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,413.20194
Policy Entropy: 3.89248
Value Function Loss: 0.03688

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.88235
Value Function Update Magnitude: 0.73945

Collected Steps per Second: 22,366.36099
Overall Steps per Second: 10,588.94788

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72379

Cumulative Model Updates: 148,016
Cumulative Timesteps: 1,234,266,692

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.59919
Policy Entropy: 3.87452
Value Function Loss: 0.03073

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.80063
Value Function Update Magnitude: 0.74435

Collected Steps per Second: 22,720.90900
Overall Steps per Second: 10,785.58224

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63897

Cumulative Model Updates: 148,022
Cumulative Timesteps: 1,234,316,726

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1234316726...
Checkpoint 1234316726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,013.92881
Policy Entropy: 3.86456
Value Function Loss: 0.02677

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.82838
Value Function Update Magnitude: 0.83273

Collected Steps per Second: 22,761.35565
Overall Steps per Second: 10,643.35537

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.50236
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70021

Cumulative Model Updates: 148,028
Cumulative Timesteps: 1,234,366,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339.55564
Policy Entropy: 3.85799
Value Function Loss: 0.02132

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08471
Policy Update Magnitude: 0.81145
Value Function Update Magnitude: 0.95060

Collected Steps per Second: 22,180.42590
Overall Steps per Second: 10,476.39462

Timestep Collection Time: 2.25469
Timestep Consumption Time: 2.51890
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.77359

Cumulative Model Updates: 148,034
Cumulative Timesteps: 1,234,416,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1234416762...
Checkpoint 1234416762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109.14404
Policy Entropy: 3.82246
Value Function Loss: 0.01916

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07442
Policy Update Magnitude: 0.76399
Value Function Update Magnitude: 0.91069

Collected Steps per Second: 22,126.80962
Overall Steps per Second: 10,701.27134

Timestep Collection Time: 2.26033
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.67365

Cumulative Model Updates: 148,040
Cumulative Timesteps: 1,234,466,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,596.88725
Policy Entropy: 3.79275
Value Function Loss: 0.01801

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.67835
Value Function Update Magnitude: 0.84652

Collected Steps per Second: 21,347.53066
Overall Steps per Second: 10,464.11754

Timestep Collection Time: 2.34350
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.78091

Cumulative Model Updates: 148,046
Cumulative Timesteps: 1,234,516,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1234516804...
Checkpoint 1234516804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,115.88844
Policy Entropy: 3.79110
Value Function Loss: 0.01740

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07637
Policy Update Magnitude: 0.64025
Value Function Update Magnitude: 0.83486

Collected Steps per Second: 21,558.60895
Overall Steps per Second: 10,572.70884

Timestep Collection Time: 2.31926
Timestep Consumption Time: 2.40990
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.72916

Cumulative Model Updates: 148,052
Cumulative Timesteps: 1,234,566,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,920.82542
Policy Entropy: 3.80109
Value Function Loss: 0.01746

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.07159
Policy Update Magnitude: 0.65262
Value Function Update Magnitude: 0.80674

Collected Steps per Second: 21,936.88676
Overall Steps per Second: 10,660.91355

Timestep Collection Time: 2.28018
Timestep Consumption Time: 2.41173
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.69191

Cumulative Model Updates: 148,058
Cumulative Timesteps: 1,234,616,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1234616824...
Checkpoint 1234616824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,805.09469
Policy Entropy: 3.81204
Value Function Loss: 0.01481

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06709
Policy Update Magnitude: 0.62650
Value Function Update Magnitude: 0.71738

Collected Steps per Second: 21,967.24885
Overall Steps per Second: 10,419.82170

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.52243
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.79855

Cumulative Model Updates: 148,064
Cumulative Timesteps: 1,234,666,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,439.87506
Policy Entropy: 3.80859
Value Function Loss: 0.01476

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05582
Policy Update Magnitude: 0.62654
Value Function Update Magnitude: 0.66700

Collected Steps per Second: 22,839.92713
Overall Steps per Second: 10,827.97395

Timestep Collection Time: 2.19002
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.61952

Cumulative Model Updates: 148,070
Cumulative Timesteps: 1,234,716,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1234716844...
Checkpoint 1234716844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,530.83394
Policy Entropy: 3.82479
Value Function Loss: 0.01294

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04836
Policy Update Magnitude: 0.62196
Value Function Update Magnitude: 0.67279

Collected Steps per Second: 21,582.84871
Overall Steps per Second: 10,432.76029

Timestep Collection Time: 2.31675
Timestep Consumption Time: 2.47604
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.79279

Cumulative Model Updates: 148,076
Cumulative Timesteps: 1,234,766,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.09160
Policy Entropy: 3.81140
Value Function Loss: 0.01559

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06648
Policy Update Magnitude: 0.59767
Value Function Update Magnitude: 0.70094

Collected Steps per Second: 22,969.75137
Overall Steps per Second: 10,754.23095

Timestep Collection Time: 2.17782
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.65156

Cumulative Model Updates: 148,082
Cumulative Timesteps: 1,234,816,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1234816870...
Checkpoint 1234816870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.40484
Policy Entropy: 3.81172
Value Function Loss: 0.01464

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.59938
Value Function Update Magnitude: 0.76056

Collected Steps per Second: 22,453.04450
Overall Steps per Second: 10,645.44186

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.47037
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.69760

Cumulative Model Updates: 148,088
Cumulative Timesteps: 1,234,866,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.40484
Policy Entropy: 3.78626
Value Function Loss: 0.01336

Mean KL Divergence: 0.00603
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 0.59759
Value Function Update Magnitude: 0.73954

Collected Steps per Second: 22,552.35762
Overall Steps per Second: 10,634.54840

Timestep Collection Time: 2.21760
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.70279

Cumulative Model Updates: 148,094
Cumulative Timesteps: 1,234,916,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1234916890...
Checkpoint 1234916890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.40484
Policy Entropy: 3.79307
Value Function Loss: 0.01134

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05400
Policy Update Magnitude: 0.56121
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,476.45630
Overall Steps per Second: 10,624.02252

Timestep Collection Time: 2.22535
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.70801

Cumulative Model Updates: 148,100
Cumulative Timesteps: 1,234,966,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,352.40484
Policy Entropy: 3.77353
Value Function Loss: 0.01034

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04898
Policy Update Magnitude: 0.52233
Value Function Update Magnitude: 0.50561

Collected Steps per Second: 21,858.48003
Overall Steps per Second: 10,487.31087

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.77243

Cumulative Model Updates: 148,106
Cumulative Timesteps: 1,235,016,958

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1235016958...
Checkpoint 1235016958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,027.17017
Policy Entropy: 3.77103
Value Function Loss: 0.01117

Mean KL Divergence: 0.01707
SB3 Clip Fraction: 0.20682
Policy Update Magnitude: 0.42327
Value Function Update Magnitude: 0.43729

Collected Steps per Second: 21,858.94826
Overall Steps per Second: 10,462.11808

Timestep Collection Time: 2.28867
Timestep Consumption Time: 2.49315
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.78182

Cumulative Model Updates: 148,112
Cumulative Timesteps: 1,235,066,986

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,974.15421
Policy Entropy: 3.80326
Value Function Loss: 0.02265

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.18407
Policy Update Magnitude: 0.37804
Value Function Update Magnitude: 0.49036

Collected Steps per Second: 21,783.85321
Overall Steps per Second: 10,445.98726

Timestep Collection Time: 2.29574
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.78748

Cumulative Model Updates: 148,118
Cumulative Timesteps: 1,235,116,996

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1235116996...
Checkpoint 1235116996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,014.42883
Policy Entropy: 3.83794
Value Function Loss: 0.03297

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14733
Policy Update Magnitude: 0.44923
Value Function Update Magnitude: 0.50983

Collected Steps per Second: 22,045.46507
Overall Steps per Second: 10,657.87406

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.69437

Cumulative Model Updates: 148,124
Cumulative Timesteps: 1,235,167,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,005.37791
Policy Entropy: 3.87423
Value Function Loss: 0.03858

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.51984
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,110.86366
Overall Steps per Second: 10,462.75480

Timestep Collection Time: 2.26160
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.77943

Cumulative Model Updates: 148,130
Cumulative Timesteps: 1,235,217,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1235217034...
Checkpoint 1235217034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,846.79342
Policy Entropy: 3.89837
Value Function Loss: 0.03643

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.58954
Value Function Update Magnitude: 0.68462

Collected Steps per Second: 22,380.75068
Overall Steps per Second: 10,565.11630

Timestep Collection Time: 2.23522
Timestep Consumption Time: 2.49979
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.73502

Cumulative Model Updates: 148,136
Cumulative Timesteps: 1,235,267,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,384.50381
Policy Entropy: 3.88547
Value Function Loss: 0.03197

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.67642
Value Function Update Magnitude: 0.76177

Collected Steps per Second: 22,690.84343
Overall Steps per Second: 10,637.65446

Timestep Collection Time: 2.20371
Timestep Consumption Time: 2.49695
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70066

Cumulative Model Updates: 148,142
Cumulative Timesteps: 1,235,317,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1235317064...
Checkpoint 1235317064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,172.28674
Policy Entropy: 3.85950
Value Function Loss: 0.03133

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.61067
Value Function Update Magnitude: 0.77755

Collected Steps per Second: 22,658.71945
Overall Steps per Second: 10,673.47693

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.47795
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.68470

Cumulative Model Updates: 148,148
Cumulative Timesteps: 1,235,367,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.01352
Policy Entropy: 3.83126
Value Function Loss: 0.02969

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.60694
Value Function Update Magnitude: 0.79819

Collected Steps per Second: 23,047.73771
Overall Steps per Second: 10,735.38020

Timestep Collection Time: 2.16984
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.65843

Cumulative Model Updates: 148,154
Cumulative Timesteps: 1,235,417,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1235417076...
Checkpoint 1235417076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,360.84438
Policy Entropy: 3.81244
Value Function Loss: 0.03116

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14500
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.75989

Collected Steps per Second: 21,646.25566
Overall Steps per Second: 10,380.17139

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.50721
PPO Batch Consumption Time: 0.30522
Total Iteration Time: 4.81726

Cumulative Model Updates: 148,160
Cumulative Timesteps: 1,235,467,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,449.17940
Policy Entropy: 3.82972
Value Function Loss: 0.03070

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.53242
Value Function Update Magnitude: 0.84123

Collected Steps per Second: 21,157.72976
Overall Steps per Second: 10,469.00397

Timestep Collection Time: 2.36453
Timestep Consumption Time: 2.41415
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.77868

Cumulative Model Updates: 148,166
Cumulative Timesteps: 1,235,517,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1235517108...
Checkpoint 1235517108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,705.09980
Policy Entropy: 3.84164
Value Function Loss: 0.03444

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.49657
Value Function Update Magnitude: 0.72254

Collected Steps per Second: 21,641.60183
Overall Steps per Second: 10,592.41193

Timestep Collection Time: 2.31083
Timestep Consumption Time: 2.41048
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72130

Cumulative Model Updates: 148,172
Cumulative Timesteps: 1,235,567,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.38978
Policy Entropy: 3.84826
Value Function Loss: 0.02821

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.46343
Value Function Update Magnitude: 0.70457

Collected Steps per Second: 22,245.02555
Overall Steps per Second: 10,803.01396

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.38150
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.63000

Cumulative Model Updates: 148,178
Cumulative Timesteps: 1,235,617,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1235617136...
Checkpoint 1235617136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,479.88660
Policy Entropy: 3.81321
Value Function Loss: 0.02545

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.45038
Value Function Update Magnitude: 0.78287

Collected Steps per Second: 21,597.22318
Overall Steps per Second: 10,615.68738

Timestep Collection Time: 2.31641
Timestep Consumption Time: 2.39624
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.71265

Cumulative Model Updates: 148,184
Cumulative Timesteps: 1,235,667,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,533.08617
Policy Entropy: 3.78683
Value Function Loss: 0.02059

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.44158
Value Function Update Magnitude: 0.72853

Collected Steps per Second: 21,948.17085
Overall Steps per Second: 10,614.01531

Timestep Collection Time: 2.27937
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.71339

Cumulative Model Updates: 148,190
Cumulative Timesteps: 1,235,717,192

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1235717192...
Checkpoint 1235717192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,828.44875
Policy Entropy: 3.77166
Value Function Loss: 0.02139

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.14062
Policy Update Magnitude: 0.44492
Value Function Update Magnitude: 0.72310

Collected Steps per Second: 22,125.68075
Overall Steps per Second: 10,842.89702

Timestep Collection Time: 2.26199
Timestep Consumption Time: 2.35375
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.61574

Cumulative Model Updates: 148,196
Cumulative Timesteps: 1,235,767,240

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,413.18900
Policy Entropy: 3.76824
Value Function Loss: 0.01948

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14203
Policy Update Magnitude: 0.45852
Value Function Update Magnitude: 0.77702

Collected Steps per Second: 22,267.37078
Overall Steps per Second: 10,556.96552

Timestep Collection Time: 2.24607
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.73754

Cumulative Model Updates: 148,202
Cumulative Timesteps: 1,235,817,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1235817254...
Checkpoint 1235817254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,509.70040
Policy Entropy: 3.75835
Value Function Loss: 0.02257

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.14389
Policy Update Magnitude: 0.46084
Value Function Update Magnitude: 0.74948

Collected Steps per Second: 22,497.07149
Overall Steps per Second: 10,639.25597

Timestep Collection Time: 2.22331
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.70127

Cumulative Model Updates: 148,208
Cumulative Timesteps: 1,235,867,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,631.11292
Policy Entropy: 3.76522
Value Function Loss: 0.02244

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.48017
Value Function Update Magnitude: 0.71374

Collected Steps per Second: 22,961.34510
Overall Steps per Second: 10,917.05082

Timestep Collection Time: 2.17827
Timestep Consumption Time: 2.40319
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.58146

Cumulative Model Updates: 148,214
Cumulative Timesteps: 1,235,917,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1235917288...
Checkpoint 1235917288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.18049
Policy Entropy: 3.76280
Value Function Loss: 0.02355

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.46001
Value Function Update Magnitude: 0.66750

Collected Steps per Second: 22,707.70982
Overall Steps per Second: 10,605.01044

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.51336
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71570

Cumulative Model Updates: 148,220
Cumulative Timesteps: 1,235,967,298

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,356.14634
Policy Entropy: 3.76625
Value Function Loss: 0.01857

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.44687
Value Function Update Magnitude: 0.65421

Collected Steps per Second: 22,383.62411
Overall Steps per Second: 10,554.05541

Timestep Collection Time: 2.23413
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73827

Cumulative Model Updates: 148,226
Cumulative Timesteps: 1,236,017,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1236017306...
Checkpoint 1236017306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,234.89607
Policy Entropy: 3.75246
Value Function Loss: 0.01712

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.40140
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 21,948.81541
Overall Steps per Second: 10,576.42242

Timestep Collection Time: 2.27903
Timestep Consumption Time: 2.45055
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.72958

Cumulative Model Updates: 148,232
Cumulative Timesteps: 1,236,067,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,399.20189
Policy Entropy: 3.76967
Value Function Loss: 0.01456

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13717
Policy Update Magnitude: 0.35849
Value Function Update Magnitude: 0.57045

Collected Steps per Second: 22,192.31192
Overall Steps per Second: 10,519.90374

Timestep Collection Time: 2.25303
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.75290

Cumulative Model Updates: 148,238
Cumulative Timesteps: 1,236,117,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1236117328...
Checkpoint 1236117328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,201.89651
Policy Entropy: 3.76937
Value Function Loss: 0.01528

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.33374
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 21,950.44437
Overall Steps per Second: 10,576.62948

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.45082
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.72986

Cumulative Model Updates: 148,244
Cumulative Timesteps: 1,236,167,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,233.22263
Policy Entropy: 3.78883
Value Function Loss: 0.01498

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.38908
Value Function Update Magnitude: 0.55694

Collected Steps per Second: 22,440.21930
Overall Steps per Second: 10,568.63959

Timestep Collection Time: 2.22912
Timestep Consumption Time: 2.50394
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.73306

Cumulative Model Updates: 148,250
Cumulative Timesteps: 1,236,217,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1236217376...
Checkpoint 1236217376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,714.38960
Policy Entropy: 3.78295
Value Function Loss: 0.01525

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.40527
Value Function Update Magnitude: 0.58714

Collected Steps per Second: 22,478.34141
Overall Steps per Second: 10,559.64938

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.51145
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.73652

Cumulative Model Updates: 148,256
Cumulative Timesteps: 1,236,267,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,524.50246
Policy Entropy: 3.76222
Value Function Loss: 0.01714

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.42618
Value Function Update Magnitude: 0.66239

Collected Steps per Second: 23,169.60041
Overall Steps per Second: 10,904.87663

Timestep Collection Time: 2.15800
Timestep Consumption Time: 2.42710
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.58510

Cumulative Model Updates: 148,262
Cumulative Timesteps: 1,236,317,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1236317392...
Checkpoint 1236317392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,422.84290
Policy Entropy: 3.76578
Value Function Loss: 0.01840

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.46144
Value Function Update Magnitude: 0.71662

Collected Steps per Second: 22,711.09625
Overall Steps per Second: 10,659.76271

Timestep Collection Time: 2.20227
Timestep Consumption Time: 2.48977
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69204

Cumulative Model Updates: 148,268
Cumulative Timesteps: 1,236,367,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,227.23392
Policy Entropy: 3.75238
Value Function Loss: 0.02004

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.47057
Value Function Update Magnitude: 0.71085

Collected Steps per Second: 22,355.48148
Overall Steps per Second: 10,859.19582

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.36866
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.60605

Cumulative Model Updates: 148,274
Cumulative Timesteps: 1,236,417,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1236417426...
Checkpoint 1236417426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 187,532.58195
Policy Entropy: 3.76979
Value Function Loss: 0.02171

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.46425
Value Function Update Magnitude: 0.58594

Collected Steps per Second: 22,084.88541
Overall Steps per Second: 10,694.71318

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.67764

Cumulative Model Updates: 148,280
Cumulative Timesteps: 1,236,467,452

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,753.22388
Policy Entropy: 3.77195
Value Function Loss: 0.01965

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.46430
Value Function Update Magnitude: 0.52863

Collected Steps per Second: 22,307.42823
Overall Steps per Second: 10,855.17914

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.36478
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.60628

Cumulative Model Updates: 148,286
Cumulative Timesteps: 1,236,517,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1236517454...
Checkpoint 1236517454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,717.39535
Policy Entropy: 3.78684
Value Function Loss: 0.02554

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.46563
Value Function Update Magnitude: 0.58110

Collected Steps per Second: 21,867.92504
Overall Steps per Second: 10,651.31193

Timestep Collection Time: 2.28773
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.69689

Cumulative Model Updates: 148,292
Cumulative Timesteps: 1,236,567,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,075.27766
Policy Entropy: 3.78591
Value Function Loss: 0.02390

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.52262
Value Function Update Magnitude: 0.58299

Collected Steps per Second: 21,716.90837
Overall Steps per Second: 10,631.00907

Timestep Collection Time: 2.30235
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.70322

Cumulative Model Updates: 148,298
Cumulative Timesteps: 1,236,617,482

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1236617482...
Checkpoint 1236617482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,851.64872
Policy Entropy: 3.79012
Value Function Loss: 0.02752

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12245
Policy Update Magnitude: 0.53013
Value Function Update Magnitude: 0.58410

Collected Steps per Second: 21,637.73003
Overall Steps per Second: 10,439.44851

Timestep Collection Time: 2.31096
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.78991

Cumulative Model Updates: 148,304
Cumulative Timesteps: 1,236,667,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,842.37509
Policy Entropy: 3.80305
Value Function Loss: 0.02171

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.52375
Value Function Update Magnitude: 0.56049

Collected Steps per Second: 22,312.70426
Overall Steps per Second: 10,572.93824

Timestep Collection Time: 2.24204
Timestep Consumption Time: 2.48947
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.73151

Cumulative Model Updates: 148,310
Cumulative Timesteps: 1,236,717,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1236717512...
Checkpoint 1236717512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,809.23232
Policy Entropy: 3.79301
Value Function Loss: 0.02519

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.51162
Value Function Update Magnitude: 0.57295

Collected Steps per Second: 22,501.83244
Overall Steps per Second: 10,593.14202

Timestep Collection Time: 2.22231
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.72060

Cumulative Model Updates: 148,316
Cumulative Timesteps: 1,236,767,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,857.67885
Policy Entropy: 3.80373
Value Function Loss: 0.02361

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.51233
Value Function Update Magnitude: 0.59493

Collected Steps per Second: 22,856.68637
Overall Steps per Second: 10,783.98543

Timestep Collection Time: 2.18816
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.63780

Cumulative Model Updates: 148,322
Cumulative Timesteps: 1,236,817,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1236817532...
Checkpoint 1236817532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.25684
Policy Entropy: 3.78982
Value Function Loss: 0.02365

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.52796
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,631.36710
Overall Steps per Second: 10,704.15519

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.46324
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.67389

Cumulative Model Updates: 148,328
Cumulative Timesteps: 1,236,867,562

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,003.39001
Policy Entropy: 3.80399
Value Function Loss: 0.02230

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 0.76251

Collected Steps per Second: 22,731.68008
Overall Steps per Second: 10,669.29344

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68691

Cumulative Model Updates: 148,334
Cumulative Timesteps: 1,236,917,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1236917568...
Checkpoint 1236917568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,990.52575
Policy Entropy: 3.80884
Value Function Loss: 0.02272

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.59907
Value Function Update Magnitude: 0.73967

Collected Steps per Second: 22,564.40328
Overall Steps per Second: 10,744.99068

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.43784
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.65408

Cumulative Model Updates: 148,340
Cumulative Timesteps: 1,236,967,576

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,866.92452
Policy Entropy: 3.78853
Value Function Loss: 0.02185

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.59325
Value Function Update Magnitude: 0.74610

Collected Steps per Second: 22,650.37463
Overall Steps per Second: 10,616.78710

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.71065

Cumulative Model Updates: 148,346
Cumulative Timesteps: 1,237,017,588

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1237017588...
Checkpoint 1237017588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,765.14758
Policy Entropy: 3.78362
Value Function Loss: 0.02075

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.57566
Value Function Update Magnitude: 0.76367

Collected Steps per Second: 21,911.82755
Overall Steps per Second: 10,648.82567

Timestep Collection Time: 2.28242
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.27568
Total Iteration Time: 4.69648

Cumulative Model Updates: 148,352
Cumulative Timesteps: 1,237,067,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,446.73028
Policy Entropy: 3.76467
Value Function Loss: 0.02072

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.52878
Value Function Update Magnitude: 0.80324

Collected Steps per Second: 22,270.28773
Overall Steps per Second: 10,514.09864

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.51088
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.75647

Cumulative Model Updates: 148,358
Cumulative Timesteps: 1,237,117,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1237117610...
Checkpoint 1237117610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,675.90553
Policy Entropy: 3.77681
Value Function Loss: 0.01899

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14472
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.88776

Collected Steps per Second: 22,240.02558
Overall Steps per Second: 10,506.26961

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.76211

Cumulative Model Updates: 148,364
Cumulative Timesteps: 1,237,167,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,089.61765
Policy Entropy: 3.77547
Value Function Loss: 0.01859

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.83552

Collected Steps per Second: 22,073.31543
Overall Steps per Second: 10,513.81516

Timestep Collection Time: 2.26618
Timestep Consumption Time: 2.49156
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.75774

Cumulative Model Updates: 148,370
Cumulative Timesteps: 1,237,217,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1237217664...
Checkpoint 1237217664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,227.53232
Policy Entropy: 3.78404
Value Function Loss: 0.01637

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.52573
Value Function Update Magnitude: 0.72848

Collected Steps per Second: 22,667.90343
Overall Steps per Second: 10,625.40925

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.49994
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.70570

Cumulative Model Updates: 148,376
Cumulative Timesteps: 1,237,267,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,227.53232
Policy Entropy: 3.75582
Value Function Loss: 0.01953

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.49249
Value Function Update Magnitude: 0.62555

Collected Steps per Second: 22,716.60275
Overall Steps per Second: 10,648.67188

Timestep Collection Time: 2.20244
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.69843

Cumulative Model Updates: 148,382
Cumulative Timesteps: 1,237,317,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1237317696...
Checkpoint 1237317696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,868.52095
Policy Entropy: 3.75453
Value Function Loss: 0.02287

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.56902

Collected Steps per Second: 22,802.22928
Overall Steps per Second: 10,784.71597

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.44381
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.63693

Cumulative Model Updates: 148,388
Cumulative Timesteps: 1,237,367,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,164.60162
Policy Entropy: 3.73303
Value Function Loss: 0.02928

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14040
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.54883

Collected Steps per Second: 22,122.71627
Overall Steps per Second: 10,683.74563

Timestep Collection Time: 2.26211
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68412

Cumulative Model Updates: 148,394
Cumulative Timesteps: 1,237,417,748

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1237417748...
Checkpoint 1237417748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,379.67500
Policy Entropy: 3.74838
Value Function Loss: 0.02733

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.51546

Collected Steps per Second: 22,010.21208
Overall Steps per Second: 10,709.06345

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.39900
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.67230

Cumulative Model Updates: 148,400
Cumulative Timesteps: 1,237,467,784

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,781.98875
Policy Entropy: 3.75166
Value Function Loss: 0.02454

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.50753

Collected Steps per Second: 21,849.23061
Overall Steps per Second: 10,673.58292

Timestep Collection Time: 2.28841
Timestep Consumption Time: 2.39605
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.68446

Cumulative Model Updates: 148,406
Cumulative Timesteps: 1,237,517,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1237517784...
Checkpoint 1237517784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,080.85934
Policy Entropy: 3.76140
Value Function Loss: 0.02409

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.49209
Value Function Update Magnitude: 0.43847

Collected Steps per Second: 22,302.87311
Overall Steps per Second: 10,685.27664

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.43796
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.68027

Cumulative Model Updates: 148,412
Cumulative Timesteps: 1,237,567,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,467.95647
Policy Entropy: 3.75624
Value Function Loss: 0.02318

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.46069
Value Function Update Magnitude: 0.41236

Collected Steps per Second: 22,386.49507
Overall Steps per Second: 10,673.04512

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.68695

Cumulative Model Updates: 148,418
Cumulative Timesteps: 1,237,617,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1237617818...
Checkpoint 1237617818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,120.77519
Policy Entropy: 3.75837
Value Function Loss: 0.02135

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.43860
Value Function Update Magnitude: 0.40603

Collected Steps per Second: 22,696.49498
Overall Steps per Second: 10,840.61329

Timestep Collection Time: 2.20378
Timestep Consumption Time: 2.41017
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.61395

Cumulative Model Updates: 148,424
Cumulative Timesteps: 1,237,667,836

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,932.86392
Policy Entropy: 3.75870
Value Function Loss: 0.02241

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.43185
Value Function Update Magnitude: 0.44339

Collected Steps per Second: 22,490.79027
Overall Steps per Second: 10,520.06555

Timestep Collection Time: 2.22384
Timestep Consumption Time: 2.53050
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.75434

Cumulative Model Updates: 148,430
Cumulative Timesteps: 1,237,717,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1237717852...
Checkpoint 1237717852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,141.25661
Policy Entropy: 3.78686
Value Function Loss: 0.02244

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.49199
Value Function Update Magnitude: 0.56305

Collected Steps per Second: 22,777.68803
Overall Steps per Second: 10,595.10187

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.52403
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71916

Cumulative Model Updates: 148,436
Cumulative Timesteps: 1,237,767,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,879.70544
Policy Entropy: 3.78236
Value Function Loss: 0.02456

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13309
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.67062

Collected Steps per Second: 22,821.15252
Overall Steps per Second: 10,840.56158

Timestep Collection Time: 2.19183
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.61415

Cumulative Model Updates: 148,442
Cumulative Timesteps: 1,237,817,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1237817872...
Checkpoint 1237817872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,186.62416
Policy Entropy: 3.78476
Value Function Loss: 0.02414

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.80373

Collected Steps per Second: 22,496.41594
Overall Steps per Second: 10,792.62192

Timestep Collection Time: 2.22373
Timestep Consumption Time: 2.41147
PPO Batch Consumption Time: 0.27601
Total Iteration Time: 4.63520

Cumulative Model Updates: 148,448
Cumulative Timesteps: 1,237,867,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,271.13187
Policy Entropy: 3.78010
Value Function Loss: 0.02739

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.74797

Collected Steps per Second: 22,472.75912
Overall Steps per Second: 10,750.98640

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.65297

Cumulative Model Updates: 148,454
Cumulative Timesteps: 1,237,917,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1237917922...
Checkpoint 1237917922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,335.24639
Policy Entropy: 3.79202
Value Function Loss: 0.03134

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.63168

Collected Steps per Second: 22,614.05469
Overall Steps per Second: 10,728.12056

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.66214

Cumulative Model Updates: 148,460
Cumulative Timesteps: 1,237,967,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,688.64652
Policy Entropy: 3.81123
Value Function Loss: 0.02852

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.54560

Collected Steps per Second: 22,638.23276
Overall Steps per Second: 10,823.22473

Timestep Collection Time: 2.20909
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.62062

Cumulative Model Updates: 148,466
Cumulative Timesteps: 1,238,017,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1238017948...
Checkpoint 1238017948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.91546
Policy Entropy: 3.80527
Value Function Loss: 0.02477

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.51773
Value Function Update Magnitude: 0.51552

Collected Steps per Second: 22,077.77091
Overall Steps per Second: 10,670.86811

Timestep Collection Time: 2.26545
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.68715

Cumulative Model Updates: 148,472
Cumulative Timesteps: 1,238,067,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.91546
Policy Entropy: 3.78676
Value Function Loss: 0.02006

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.45765
Value Function Update Magnitude: 0.51090

Collected Steps per Second: 22,146.25910
Overall Steps per Second: 10,486.81361

Timestep Collection Time: 2.25826
Timestep Consumption Time: 2.51078
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.76904

Cumulative Model Updates: 148,478
Cumulative Timesteps: 1,238,117,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1238117976...
Checkpoint 1238117976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,968.59683
Policy Entropy: 3.75159
Value Function Loss: 0.01954

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13208
Policy Update Magnitude: 0.43859
Value Function Update Magnitude: 0.50972

Collected Steps per Second: 22,381.02357
Overall Steps per Second: 10,615.92552

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.47676
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.71160

Cumulative Model Updates: 148,484
Cumulative Timesteps: 1,238,167,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,968.59683
Policy Entropy: 3.73173
Value Function Loss: 0.01774

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.45360
Value Function Update Magnitude: 0.44055

Collected Steps per Second: 22,334.81406
Overall Steps per Second: 10,553.74970

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.73993

Cumulative Model Updates: 148,490
Cumulative Timesteps: 1,238,218,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1238218018...
Checkpoint 1238218018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,444.89672
Policy Entropy: 3.76333
Value Function Loss: 0.01945

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.44810
Value Function Update Magnitude: 0.40174

Collected Steps per Second: 22,861.23080
Overall Steps per Second: 10,610.01588

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.52633
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.71422

Cumulative Model Updates: 148,496
Cumulative Timesteps: 1,238,268,036

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,927.91562
Policy Entropy: 3.76614
Value Function Loss: 0.01766

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.43486
Value Function Update Magnitude: 0.48041

Collected Steps per Second: 22,780.17035
Overall Steps per Second: 10,774.62368

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.64053

Cumulative Model Updates: 148,502
Cumulative Timesteps: 1,238,318,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1238318036...
Checkpoint 1238318036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,337.04095
Policy Entropy: 3.76485
Value Function Loss: 0.02210

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12891
Policy Update Magnitude: 0.45490
Value Function Update Magnitude: 0.53912

Collected Steps per Second: 22,468.98701
Overall Steps per Second: 10,727.37955

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.66321

Cumulative Model Updates: 148,508
Cumulative Timesteps: 1,238,368,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,037.35333
Policy Entropy: 3.75661
Value Function Loss: 0.02314

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.50198
Value Function Update Magnitude: 0.64404

Collected Steps per Second: 22,724.18628
Overall Steps per Second: 10,641.49869

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.70159

Cumulative Model Updates: 148,514
Cumulative Timesteps: 1,238,418,092

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1238418092...
Checkpoint 1238418092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,480.29020
Policy Entropy: 3.75934
Value Function Loss: 0.03035

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.53482
Value Function Update Magnitude: 0.55415

Collected Steps per Second: 22,858.55344
Overall Steps per Second: 10,857.01905

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.41814
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.60568

Cumulative Model Updates: 148,520
Cumulative Timesteps: 1,238,468,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.02155
Policy Entropy: 3.78874
Value Function Loss: 0.02754

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.55018
Value Function Update Magnitude: 0.51994

Collected Steps per Second: 22,810.57733
Overall Steps per Second: 10,674.07125

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.68481

Cumulative Model Updates: 148,526
Cumulative Timesteps: 1,238,518,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1238518102...
Checkpoint 1238518102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,600.76803
Policy Entropy: 3.80926
Value Function Loss: 0.03015

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.49487

Collected Steps per Second: 22,653.82974
Overall Steps per Second: 10,654.16859

Timestep Collection Time: 2.20731
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69337

Cumulative Model Updates: 148,532
Cumulative Timesteps: 1,238,568,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,696.49669
Policy Entropy: 3.80595
Value Function Loss: 0.02638

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.49084

Collected Steps per Second: 22,670.61761
Overall Steps per Second: 10,806.21659

Timestep Collection Time: 2.20673
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.27604
Total Iteration Time: 4.62956

Cumulative Model Updates: 148,538
Cumulative Timesteps: 1,238,618,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1238618134...
Checkpoint 1238618134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,104.35479
Policy Entropy: 3.78756
Value Function Loss: 0.03236

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.50275

Collected Steps per Second: 22,011.72365
Overall Steps per Second: 10,674.81000

Timestep Collection Time: 2.27197
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.68486

Cumulative Model Updates: 148,544
Cumulative Timesteps: 1,238,668,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,374.66503
Policy Entropy: 3.78830
Value Function Loss: 0.02814

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.54500

Collected Steps per Second: 21,967.18746
Overall Steps per Second: 10,452.43231

Timestep Collection Time: 2.27721
Timestep Consumption Time: 2.50866
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.78587

Cumulative Model Updates: 148,550
Cumulative Timesteps: 1,238,718,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1238718168...
Checkpoint 1238718168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.07725
Policy Entropy: 3.78506
Value Function Loss: 0.02572

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.51503
Value Function Update Magnitude: 0.57251

Collected Steps per Second: 22,580.81323
Overall Steps per Second: 10,586.52628

Timestep Collection Time: 2.21498
Timestep Consumption Time: 2.50952
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.72450

Cumulative Model Updates: 148,556
Cumulative Timesteps: 1,238,768,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,657.61712
Policy Entropy: 3.76945
Value Function Loss: 0.01749

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.44971
Value Function Update Magnitude: 0.49239

Collected Steps per Second: 22,819.67035
Overall Steps per Second: 10,603.44541

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.52476
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.71620

Cumulative Model Updates: 148,562
Cumulative Timesteps: 1,238,818,192

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1238818192...
Checkpoint 1238818192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,356.47382
Policy Entropy: 3.74581
Value Function Loss: 0.01722

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.40801
Value Function Update Magnitude: 0.49818

Collected Steps per Second: 22,994.55706
Overall Steps per Second: 10,836.35132

Timestep Collection Time: 2.17565
Timestep Consumption Time: 2.44104
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.61668

Cumulative Model Updates: 148,568
Cumulative Timesteps: 1,238,868,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,120.35532
Policy Entropy: 3.74970
Value Function Loss: 0.01650

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.42374
Value Function Update Magnitude: 0.52401

Collected Steps per Second: 23,014.15723
Overall Steps per Second: 10,729.55506

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.48894
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.66282

Cumulative Model Updates: 148,574
Cumulative Timesteps: 1,238,918,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1238918250...
Checkpoint 1238918250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,120.35532
Policy Entropy: 3.76239
Value Function Loss: 0.01447

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.39674
Value Function Update Magnitude: 0.47012

Collected Steps per Second: 22,838.35032
Overall Steps per Second: 10,806.45782

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.44029
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.63205

Cumulative Model Updates: 148,580
Cumulative Timesteps: 1,238,968,306

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,198.82017
Policy Entropy: 3.75039
Value Function Loss: 0.01459

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.38253
Value Function Update Magnitude: 0.40692

Collected Steps per Second: 22,734.91170
Overall Steps per Second: 10,606.49270

Timestep Collection Time: 2.20014
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71598

Cumulative Model Updates: 148,586
Cumulative Timesteps: 1,239,018,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1239018326...
Checkpoint 1239018326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,198.82017
Policy Entropy: 3.74456
Value Function Loss: 0.01293

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.39275
Value Function Update Magnitude: 0.38979

Collected Steps per Second: 22,969.65132
Overall Steps per Second: 10,723.41973

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.66549

Cumulative Model Updates: 148,592
Cumulative Timesteps: 1,239,068,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,996.24539
Policy Entropy: 3.74020
Value Function Loss: 0.01500

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.39796
Value Function Update Magnitude: 0.45323

Collected Steps per Second: 21,886.27993
Overall Steps per Second: 10,495.37097

Timestep Collection Time: 2.28481
Timestep Consumption Time: 2.47977
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.76458

Cumulative Model Updates: 148,598
Cumulative Timesteps: 1,239,118,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1239118362...
Checkpoint 1239118362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,403.75381
Policy Entropy: 3.74959
Value Function Loss: 0.01530

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.50687

Collected Steps per Second: 22,440.75819
Overall Steps per Second: 10,635.00705

Timestep Collection Time: 2.22880
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.70296

Cumulative Model Updates: 148,604
Cumulative Timesteps: 1,239,168,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,784.02209
Policy Entropy: 3.75252
Value Function Loss: 0.01861

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13871
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.62091

Collected Steps per Second: 22,351.09482
Overall Steps per Second: 10,698.82396

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.43785
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.67621

Cumulative Model Updates: 148,610
Cumulative Timesteps: 1,239,218,408

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1239218408...
Checkpoint 1239218408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,632.62243
Policy Entropy: 3.77573
Value Function Loss: 0.01952

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.60043
Value Function Update Magnitude: 0.77169

Collected Steps per Second: 22,715.48725
Overall Steps per Second: 10,763.09741

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.64662

Cumulative Model Updates: 148,616
Cumulative Timesteps: 1,239,268,420

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,260.84531
Policy Entropy: 3.79580
Value Function Loss: 0.01765

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14991
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.82638

Collected Steps per Second: 22,642.20215
Overall Steps per Second: 10,755.61530

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.44184
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.65134

Cumulative Model Updates: 148,622
Cumulative Timesteps: 1,239,318,448

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1239318448...
Checkpoint 1239318448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,326.64719
Policy Entropy: 3.77070
Value Function Loss: 0.02324

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17154
Policy Update Magnitude: 0.53781
Value Function Update Magnitude: 0.75634

Collected Steps per Second: 22,601.76784
Overall Steps per Second: 10,778.97947

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.42673
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.63921

Cumulative Model Updates: 148,628
Cumulative Timesteps: 1,239,368,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,347.30445
Policy Entropy: 3.77414
Value Function Loss: 0.02607

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.19793
Policy Update Magnitude: 0.62384
Value Function Update Magnitude: 0.56473

Collected Steps per Second: 22,984.38761
Overall Steps per Second: 10,881.82834

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.42068
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.59721

Cumulative Model Updates: 148,634
Cumulative Timesteps: 1,239,418,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1239418480...
Checkpoint 1239418480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,637.55993
Policy Entropy: 3.75703
Value Function Loss: 0.02389

Mean KL Divergence: 0.01886
SB3 Clip Fraction: 0.21192
Policy Update Magnitude: 0.60637
Value Function Update Magnitude: 0.56252

Collected Steps per Second: 22,778.64587
Overall Steps per Second: 10,663.61161

Timestep Collection Time: 2.19530
Timestep Consumption Time: 2.49410
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.68941

Cumulative Model Updates: 148,640
Cumulative Timesteps: 1,239,468,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,253.44897
Policy Entropy: 3.76685
Value Function Loss: 0.02621

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.19077
Policy Update Magnitude: 0.65907
Value Function Update Magnitude: 0.76979

Collected Steps per Second: 22,786.44113
Overall Steps per Second: 10,804.46646

Timestep Collection Time: 2.19543
Timestep Consumption Time: 2.43469
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.63012

Cumulative Model Updates: 148,646
Cumulative Timesteps: 1,239,518,512

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1239518512...
Checkpoint 1239518512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,289.70601
Policy Entropy: 3.78681
Value Function Loss: 0.03495

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.74880
Value Function Update Magnitude: 0.89864

Collected Steps per Second: 22,128.82185
Overall Steps per Second: 10,680.17539

Timestep Collection Time: 2.26085
Timestep Consumption Time: 2.42353
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.68438

Cumulative Model Updates: 148,652
Cumulative Timesteps: 1,239,568,542

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.79686
Policy Entropy: 3.81658
Value Function Loss: 0.04108

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.84325
Value Function Update Magnitude: 0.76812

Collected Steps per Second: 22,304.76708
Overall Steps per Second: 10,536.60485

Timestep Collection Time: 2.24293
Timestep Consumption Time: 2.50509
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.74802

Cumulative Model Updates: 148,658
Cumulative Timesteps: 1,239,618,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1239618570...
Checkpoint 1239618570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224.24675
Policy Entropy: 3.90252
Value Function Loss: 0.03726

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 1.11338
Value Function Update Magnitude: 0.87144

Collected Steps per Second: 22,203.09879
Overall Steps per Second: 10,604.49748

Timestep Collection Time: 2.25320
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.71762

Cumulative Model Updates: 148,664
Cumulative Timesteps: 1,239,668,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.18164
Policy Entropy: 3.91240
Value Function Loss: 0.03254

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08746
Policy Update Magnitude: 1.13011
Value Function Update Magnitude: 0.98380

Collected Steps per Second: 22,311.76069
Overall Steps per Second: 10,616.64001

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.71147

Cumulative Model Updates: 148,670
Cumulative Timesteps: 1,239,718,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1239718618...
Checkpoint 1239718618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,231.12671
Policy Entropy: 3.88412
Value Function Loss: 0.02865

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07068
Policy Update Magnitude: 0.97319
Value Function Update Magnitude: 0.89196

Collected Steps per Second: 22,756.69807
Overall Steps per Second: 10,680.59517

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.68289

Cumulative Model Updates: 148,676
Cumulative Timesteps: 1,239,768,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,758.25419
Policy Entropy: 3.81530
Value Function Loss: 0.02315

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.10497
Policy Update Magnitude: 0.80532
Value Function Update Magnitude: 0.80180

Collected Steps per Second: 22,854.87365
Overall Steps per Second: 10,679.35289

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68212

Cumulative Model Updates: 148,682
Cumulative Timesteps: 1,239,818,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1239818636...
Checkpoint 1239818636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,950.45305
Policy Entropy: 3.79268
Value Function Loss: 0.01826

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14382
Policy Update Magnitude: 0.57917
Value Function Update Magnitude: 0.75738

Collected Steps per Second: 22,933.99014
Overall Steps per Second: 10,680.62373

Timestep Collection Time: 2.18122
Timestep Consumption Time: 2.50240
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.68362

Cumulative Model Updates: 148,688
Cumulative Timesteps: 1,239,868,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,631.77490
Policy Entropy: 3.79910
Value Function Loss: 0.01635

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.50510
Value Function Update Magnitude: 0.69984

Collected Steps per Second: 22,641.94089
Overall Steps per Second: 10,754.23934

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.44211
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.65137

Cumulative Model Updates: 148,694
Cumulative Timesteps: 1,239,918,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1239918682...
Checkpoint 1239918682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,036.11783
Policy Entropy: 3.80490
Value Function Loss: 0.01784

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07948
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.71295

Collected Steps per Second: 22,794.06419
Overall Steps per Second: 10,815.03279

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.43003
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.62393

Cumulative Model Updates: 148,700
Cumulative Timesteps: 1,239,968,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,204.77322
Policy Entropy: 3.78502
Value Function Loss: 0.01955

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.70011
Value Function Update Magnitude: 0.77254

Collected Steps per Second: 22,563.53766
Overall Steps per Second: 10,658.88158

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.47555
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.69205

Cumulative Model Updates: 148,706
Cumulative Timesteps: 1,240,018,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1240018702...
Checkpoint 1240018702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,332.25112
Policy Entropy: 3.79013
Value Function Loss: 0.02297

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08166
Policy Update Magnitude: 0.78912
Value Function Update Magnitude: 0.81985

Collected Steps per Second: 22,377.28498
Overall Steps per Second: 10,641.77866

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.46484
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.69997

Cumulative Model Updates: 148,712
Cumulative Timesteps: 1,240,068,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,879.07234
Policy Entropy: 3.78204
Value Function Loss: 0.02261

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16953
Policy Update Magnitude: 0.77195
Value Function Update Magnitude: 0.84382

Collected Steps per Second: 22,195.86724
Overall Steps per Second: 10,658.71911

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.69343

Cumulative Model Updates: 148,718
Cumulative Timesteps: 1,240,118,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1240118744...
Checkpoint 1240118744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,166.16920
Policy Entropy: 3.78725
Value Function Loss: 0.03997

Mean KL Divergence: 0.02601
SB3 Clip Fraction: 0.25948
Policy Update Magnitude: 0.58268
Value Function Update Magnitude: 0.67169

Collected Steps per Second: 22,191.40822
Overall Steps per Second: 10,716.53144

Timestep Collection Time: 2.25366
Timestep Consumption Time: 2.41314
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.66681

Cumulative Model Updates: 148,724
Cumulative Timesteps: 1,240,168,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,273.18666
Policy Entropy: 3.78849
Value Function Loss: 0.04482

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.23239
Policy Update Magnitude: 0.60068
Value Function Update Magnitude: 0.48128

Collected Steps per Second: 22,667.15806
Overall Steps per Second: 10,847.59957

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.40483
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61190

Cumulative Model Updates: 148,730
Cumulative Timesteps: 1,240,218,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1240218784...
Checkpoint 1240218784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,367.74472
Policy Entropy: 3.82686
Value Function Loss: 0.05533

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15228
Policy Update Magnitude: 0.63696
Value Function Update Magnitude: 0.45808

Collected Steps per Second: 22,385.28526
Overall Steps per Second: 10,707.16211

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.27604
Total Iteration Time: 4.67089

Cumulative Model Updates: 148,736
Cumulative Timesteps: 1,240,268,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,304.52274
Policy Entropy: 3.88577
Value Function Loss: 0.05194

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.81442
Value Function Update Magnitude: 0.56276

Collected Steps per Second: 22,300.56104
Overall Steps per Second: 10,742.24692

Timestep Collection Time: 2.24353
Timestep Consumption Time: 2.41397
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.65750

Cumulative Model Updates: 148,742
Cumulative Timesteps: 1,240,318,828

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1240318828...
Checkpoint 1240318828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,801.67956
Policy Entropy: 3.93435
Value Function Loss: 0.04915

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 1.03990
Value Function Update Magnitude: 0.61698

Collected Steps per Second: 22,662.74476
Overall Steps per Second: 10,726.71546

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.66387

Cumulative Model Updates: 148,748
Cumulative Timesteps: 1,240,368,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.33047
Policy Entropy: 3.91576
Value Function Loss: 0.04308

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 1.10035
Value Function Update Magnitude: 0.71206

Collected Steps per Second: 22,737.22217
Overall Steps per Second: 10,945.55322

Timestep Collection Time: 2.19930
Timestep Consumption Time: 2.36931
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.56861

Cumulative Model Updates: 148,754
Cumulative Timesteps: 1,240,418,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1240418862...
Checkpoint 1240418862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.70737
Policy Entropy: 3.91421
Value Function Loss: 0.03875

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 1.00133
Value Function Update Magnitude: 0.91002

Collected Steps per Second: 22,343.86451
Overall Steps per Second: 10,788.70395

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.39797
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.63689

Cumulative Model Updates: 148,760
Cumulative Timesteps: 1,240,468,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,170.50418
Policy Entropy: 3.90083
Value Function Loss: 0.03629

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.89036
Value Function Update Magnitude: 0.89790

Collected Steps per Second: 22,167.75623
Overall Steps per Second: 10,763.09055

Timestep Collection Time: 2.25625
Timestep Consumption Time: 2.39074
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.64699

Cumulative Model Updates: 148,766
Cumulative Timesteps: 1,240,518,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1240518904...
Checkpoint 1240518904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.28660
Policy Entropy: 3.90342
Value Function Loss: 0.03026

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14456
Policy Update Magnitude: 0.72635
Value Function Update Magnitude: 0.76854

Collected Steps per Second: 21,408.19561
Overall Steps per Second: 10,709.44875

Timestep Collection Time: 2.33705
Timestep Consumption Time: 2.33471
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.67176

Cumulative Model Updates: 148,772
Cumulative Timesteps: 1,240,568,936

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,172.48671
Policy Entropy: 3.85643
Value Function Loss: 0.02889

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.75992

Collected Steps per Second: 21,839.62070
Overall Steps per Second: 10,786.99389

Timestep Collection Time: 2.29079
Timestep Consumption Time: 2.34720
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.63799

Cumulative Model Updates: 148,778
Cumulative Timesteps: 1,240,618,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1240618966...
Checkpoint 1240618966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,011.24011
Policy Entropy: 3.82390
Value Function Loss: 0.02612

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.51161
Value Function Update Magnitude: 0.79441

Collected Steps per Second: 21,499.46825
Overall Steps per Second: 10,706.91143

Timestep Collection Time: 2.32741
Timestep Consumption Time: 2.34602
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.67343

Cumulative Model Updates: 148,784
Cumulative Timesteps: 1,240,669,004

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,812.19322
Policy Entropy: 3.81232
Value Function Loss: 0.03041

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.50534
Value Function Update Magnitude: 0.71116

Collected Steps per Second: 21,850.83493
Overall Steps per Second: 10,653.06746

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.40563
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69423

Cumulative Model Updates: 148,790
Cumulative Timesteps: 1,240,719,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1240719012...
Checkpoint 1240719012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.92051
Policy Entropy: 3.83983
Value Function Loss: 0.02820

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.51082
Value Function Update Magnitude: 0.57333

Collected Steps per Second: 22,026.24835
Overall Steps per Second: 10,772.57242

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.37168
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64197

Cumulative Model Updates: 148,796
Cumulative Timesteps: 1,240,769,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,342.42672
Policy Entropy: 3.81775
Value Function Loss: 0.03099

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.49599
Value Function Update Magnitude: 0.53373

Collected Steps per Second: 22,323.03918
Overall Steps per Second: 10,795.69792

Timestep Collection Time: 2.24100
Timestep Consumption Time: 2.39288
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.63388

Cumulative Model Updates: 148,802
Cumulative Timesteps: 1,240,819,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1240819044...
Checkpoint 1240819044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,414.10991
Policy Entropy: 3.82324
Value Function Loss: 0.03344

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.46712

Collected Steps per Second: 22,055.37246
Overall Steps per Second: 10,588.81153

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.72234

Cumulative Model Updates: 148,808
Cumulative Timesteps: 1,240,869,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.48350
Policy Entropy: 3.82706
Value Function Loss: 0.03959

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.52172

Collected Steps per Second: 22,533.88912
Overall Steps per Second: 10,731.86119

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28436
Total Iteration Time: 4.66145

Cumulative Model Updates: 148,814
Cumulative Timesteps: 1,240,919,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1240919074...
Checkpoint 1240919074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.64717
Policy Entropy: 3.84378
Value Function Loss: 0.03097

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.57924
Value Function Update Magnitude: 0.59093

Collected Steps per Second: 22,615.14413
Overall Steps per Second: 10,668.82470

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68674

Cumulative Model Updates: 148,820
Cumulative Timesteps: 1,240,969,076

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,824.96687
Policy Entropy: 3.83146
Value Function Loss: 0.03867

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11203
Policy Update Magnitude: 0.59279
Value Function Update Magnitude: 0.52356

Collected Steps per Second: 21,743.14548
Overall Steps per Second: 10,459.98769

Timestep Collection Time: 2.30059
Timestep Consumption Time: 2.48164
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.78222

Cumulative Model Updates: 148,826
Cumulative Timesteps: 1,241,019,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1241019098...
Checkpoint 1241019098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.40344
Policy Entropy: 3.84237
Value Function Loss: 0.03445

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11931
Policy Update Magnitude: 0.60229
Value Function Update Magnitude: 0.45556

Collected Steps per Second: 22,501.77244
Overall Steps per Second: 10,649.57151

Timestep Collection Time: 2.22391
Timestep Consumption Time: 2.47505
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69897

Cumulative Model Updates: 148,832
Cumulative Timesteps: 1,241,069,140

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,163.00771
Policy Entropy: 3.80265
Value Function Loss: 0.03795

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.49385

Collected Steps per Second: 22,218.58674
Overall Steps per Second: 10,624.56851

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.45669
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.70796

Cumulative Model Updates: 148,838
Cumulative Timesteps: 1,241,119,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1241119160...
Checkpoint 1241119160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.88894
Policy Entropy: 3.81291
Value Function Loss: 0.03158

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.50229

Collected Steps per Second: 21,785.79206
Overall Steps per Second: 10,499.36732

Timestep Collection Time: 2.29590
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.76391

Cumulative Model Updates: 148,844
Cumulative Timesteps: 1,241,169,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,099.52456
Policy Entropy: 3.79221
Value Function Loss: 0.03368

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.56792

Collected Steps per Second: 22,311.95751
Overall Steps per Second: 10,746.41966

Timestep Collection Time: 2.24203
Timestep Consumption Time: 2.41292
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.65495

Cumulative Model Updates: 148,850
Cumulative Timesteps: 1,241,219,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1241219202...
Checkpoint 1241219202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,017.85453
Policy Entropy: 3.82709
Value Function Loss: 0.03075

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.59993
Value Function Update Magnitude: 0.63451

Collected Steps per Second: 22,390.65851
Overall Steps per Second: 10,799.29128

Timestep Collection Time: 2.23495
Timestep Consumption Time: 2.39887
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.63382

Cumulative Model Updates: 148,856
Cumulative Timesteps: 1,241,269,244

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.61796
Policy Entropy: 3.81325
Value Function Loss: 0.03229

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.56048
Value Function Update Magnitude: 0.78737

Collected Steps per Second: 22,441.60196
Overall Steps per Second: 10,486.16750

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.54099
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.76971

Cumulative Model Updates: 148,862
Cumulative Timesteps: 1,241,319,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1241319260...
Checkpoint 1241319260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,112.26103
Policy Entropy: 3.80490
Value Function Loss: 0.02861

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.76407

Collected Steps per Second: 22,745.44374
Overall Steps per Second: 10,655.88791

Timestep Collection Time: 2.19868
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.69318

Cumulative Model Updates: 148,868
Cumulative Timesteps: 1,241,369,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,641.07692
Policy Entropy: 3.78799
Value Function Loss: 0.02984

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.47827
Value Function Update Magnitude: 0.65089

Collected Steps per Second: 22,617.38376
Overall Steps per Second: 10,763.26465

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.43533
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.64655

Cumulative Model Updates: 148,874
Cumulative Timesteps: 1,241,419,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1241419282...
Checkpoint 1241419282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.29611
Policy Entropy: 3.80753
Value Function Loss: 0.02687

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.48474
Value Function Update Magnitude: 0.59677

Collected Steps per Second: 22,635.26729
Overall Steps per Second: 10,667.45898

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.68771

Cumulative Model Updates: 148,880
Cumulative Timesteps: 1,241,469,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.97056
Policy Entropy: 3.79936
Value Function Loss: 0.02518

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.48768
Value Function Update Magnitude: 0.65733

Collected Steps per Second: 22,774.83310
Overall Steps per Second: 10,872.86289

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.40397
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60008

Cumulative Model Updates: 148,886
Cumulative Timesteps: 1,241,519,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1241519304...
Checkpoint 1241519304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.44870
Policy Entropy: 3.77159
Value Function Loss: 0.02441

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.47996
Value Function Update Magnitude: 0.68292

Collected Steps per Second: 22,483.34536
Overall Steps per Second: 10,666.69987

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.68974

Cumulative Model Updates: 148,892
Cumulative Timesteps: 1,241,569,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,985.13271
Policy Entropy: 3.75234
Value Function Loss: 0.02143

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.44703
Value Function Update Magnitude: 0.64293

Collected Steps per Second: 22,373.87793
Overall Steps per Second: 10,556.83371

Timestep Collection Time: 2.23511
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.73703

Cumulative Model Updates: 148,898
Cumulative Timesteps: 1,241,619,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1241619336...
Checkpoint 1241619336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,985.13271
Policy Entropy: 3.73497
Value Function Loss: 0.02027

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.42562
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 22,460.39590
Overall Steps per Second: 10,602.13766

Timestep Collection Time: 2.22685
Timestep Consumption Time: 2.49069
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.71754

Cumulative Model Updates: 148,904
Cumulative Timesteps: 1,241,669,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,231.01588
Policy Entropy: 3.74744
Value Function Loss: 0.01808

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.40608
Value Function Update Magnitude: 0.46083

Collected Steps per Second: 22,292.31988
Overall Steps per Second: 10,552.54247

Timestep Collection Time: 2.24382
Timestep Consumption Time: 2.49627
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.74009

Cumulative Model Updates: 148,910
Cumulative Timesteps: 1,241,719,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1241719372...
Checkpoint 1241719372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,346.86976
Policy Entropy: 3.73463
Value Function Loss: 0.02166

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.39192
Value Function Update Magnitude: 0.38940

Collected Steps per Second: 22,306.03167
Overall Steps per Second: 10,508.19602

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.75857

Cumulative Model Updates: 148,916
Cumulative Timesteps: 1,241,769,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,837.76417
Policy Entropy: 3.75667
Value Function Loss: 0.02427

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.43733
Value Function Update Magnitude: 0.56987

Collected Steps per Second: 22,535.13106
Overall Steps per Second: 10,579.18679

Timestep Collection Time: 2.21965
Timestep Consumption Time: 2.50851
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.72815

Cumulative Model Updates: 148,922
Cumulative Timesteps: 1,241,819,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1241819396...
Checkpoint 1241819396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,621.29123
Policy Entropy: 3.76783
Value Function Loss: 0.02789

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.47313
Value Function Update Magnitude: 0.70814

Collected Steps per Second: 22,586.78771
Overall Steps per Second: 10,641.93295

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.70065

Cumulative Model Updates: 148,928
Cumulative Timesteps: 1,241,869,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,692.41204
Policy Entropy: 3.79704
Value Function Loss: 0.02785

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.48850
Value Function Update Magnitude: 0.78251

Collected Steps per Second: 22,543.01835
Overall Steps per Second: 10,741.41702

Timestep Collection Time: 2.21843
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65581

Cumulative Model Updates: 148,934
Cumulative Timesteps: 1,241,919,430

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1241919430...
Checkpoint 1241919430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,287.04217
Policy Entropy: 3.79819
Value Function Loss: 0.02500

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.48403
Value Function Update Magnitude: 0.80277

Collected Steps per Second: 22,686.98201
Overall Steps per Second: 10,647.92357

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69819

Cumulative Model Updates: 148,940
Cumulative Timesteps: 1,241,969,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,004.48509
Policy Entropy: 3.80184
Value Function Loss: 0.02245

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12270
Policy Update Magnitude: 0.47460
Value Function Update Magnitude: 0.79493

Collected Steps per Second: 22,665.06742
Overall Steps per Second: 10,816.85913

Timestep Collection Time: 2.20604
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.62241

Cumulative Model Updates: 148,946
Cumulative Timesteps: 1,242,019,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1242019456...
Checkpoint 1242019456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,167.88664
Policy Entropy: 3.79182
Value Function Loss: 0.02053

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.47254
Value Function Update Magnitude: 0.84159

Collected Steps per Second: 22,548.31881
Overall Steps per Second: 10,796.88132

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.41476
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.63337

Cumulative Model Updates: 148,952
Cumulative Timesteps: 1,242,069,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,786.24924
Policy Entropy: 3.78510
Value Function Loss: 0.01946

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.48059
Value Function Update Magnitude: 0.84161

Collected Steps per Second: 21,825.56488
Overall Steps per Second: 10,419.74485

Timestep Collection Time: 2.29282
Timestep Consumption Time: 2.50980
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.80261

Cumulative Model Updates: 148,958
Cumulative Timesteps: 1,242,119,524

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1242119524...
Checkpoint 1242119524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,501.63329
Policy Entropy: 3.76313
Value Function Loss: 0.02058

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.48166
Value Function Update Magnitude: 0.79274

Collected Steps per Second: 22,335.89625
Overall Steps per Second: 10,640.61071

Timestep Collection Time: 2.23944
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.70086

Cumulative Model Updates: 148,964
Cumulative Timesteps: 1,242,169,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,435.35425
Policy Entropy: 3.76113
Value Function Loss: 0.02094

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.50767
Value Function Update Magnitude: 0.74385

Collected Steps per Second: 22,284.51270
Overall Steps per Second: 10,559.03331

Timestep Collection Time: 2.24479
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.73755

Cumulative Model Updates: 148,970
Cumulative Timesteps: 1,242,219,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1242219568...
Checkpoint 1242219568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,214.03771
Policy Entropy: 3.72913
Value Function Loss: 0.02428

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.53389
Value Function Update Magnitude: 0.72609

Collected Steps per Second: 22,474.68465
Overall Steps per Second: 10,606.82147

Timestep Collection Time: 2.22651
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.71772

Cumulative Model Updates: 148,976
Cumulative Timesteps: 1,242,269,608

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,176.41891
Policy Entropy: 3.73556
Value Function Loss: 0.02273

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13837
Policy Update Magnitude: 0.54279
Value Function Update Magnitude: 0.74457

Collected Steps per Second: 21,563.65173
Overall Steps per Second: 10,539.43283

Timestep Collection Time: 2.32076
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.74826

Cumulative Model Updates: 148,982
Cumulative Timesteps: 1,242,319,652

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1242319652...
Checkpoint 1242319652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,721.82882
Policy Entropy: 3.70934
Value Function Loss: 0.03267

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15070
Policy Update Magnitude: 0.52812
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 21,897.26904
Overall Steps per Second: 10,491.32630

Timestep Collection Time: 2.28348
Timestep Consumption Time: 2.48255
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.76603

Cumulative Model Updates: 148,988
Cumulative Timesteps: 1,242,369,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,867.41601
Policy Entropy: 3.73350
Value Function Loss: 0.02863

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.52965
Value Function Update Magnitude: 0.44007

Collected Steps per Second: 21,952.63321
Overall Steps per Second: 10,788.67893

Timestep Collection Time: 2.27772
Timestep Consumption Time: 2.35695
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.63467

Cumulative Model Updates: 148,994
Cumulative Timesteps: 1,242,419,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1242419656...
Checkpoint 1242419656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,687.01422
Policy Entropy: 3.73922
Value Function Loss: 0.02801

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13385
Policy Update Magnitude: 0.53460
Value Function Update Magnitude: 0.36774

Collected Steps per Second: 22,036.18974
Overall Steps per Second: 10,700.90889

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.40495
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.67530

Cumulative Model Updates: 149,000
Cumulative Timesteps: 1,242,469,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,694.49517
Policy Entropy: 3.76045
Value Function Loss: 0.02356

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.50779
Value Function Update Magnitude: 0.35057

Collected Steps per Second: 22,722.98462
Overall Steps per Second: 10,856.81489

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.40633
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.60798

Cumulative Model Updates: 149,006
Cumulative Timesteps: 1,242,519,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1242519714...
Checkpoint 1242519714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,659.63381
Policy Entropy: 3.74224
Value Function Loss: 0.02556

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.49916
Value Function Update Magnitude: 0.34572

Collected Steps per Second: 22,693.87075
Overall Steps per Second: 10,727.56798

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.66108

Cumulative Model Updates: 149,012
Cumulative Timesteps: 1,242,569,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,399.98494
Policy Entropy: 3.74831
Value Function Loss: 0.02203

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.49332
Value Function Update Magnitude: 0.43677

Collected Steps per Second: 22,698.32539
Overall Steps per Second: 10,668.22075

Timestep Collection Time: 2.20298
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.68719

Cumulative Model Updates: 149,018
Cumulative Timesteps: 1,242,619,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1242619720...
Checkpoint 1242619720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,877.69283
Policy Entropy: 3.72716
Value Function Loss: 0.02381

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.50248
Value Function Update Magnitude: 0.50045

Collected Steps per Second: 21,926.20828
Overall Steps per Second: 10,430.75789

Timestep Collection Time: 2.28074
Timestep Consumption Time: 2.51354
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.79428

Cumulative Model Updates: 149,024
Cumulative Timesteps: 1,242,669,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,982.26829
Policy Entropy: 3.74054
Value Function Loss: 0.02095

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.50617
Value Function Update Magnitude: 0.51982

Collected Steps per Second: 22,275.18158
Overall Steps per Second: 10,551.02419

Timestep Collection Time: 2.24474
Timestep Consumption Time: 2.49433
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.73907

Cumulative Model Updates: 149,030
Cumulative Timesteps: 1,242,719,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1242719730...
Checkpoint 1242719730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,937.79063
Policy Entropy: 3.72439
Value Function Loss: 0.02170

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.48901
Value Function Update Magnitude: 0.62529

Collected Steps per Second: 22,123.07382
Overall Steps per Second: 10,534.47064

Timestep Collection Time: 2.26099
Timestep Consumption Time: 2.48723
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.74822

Cumulative Model Updates: 149,036
Cumulative Timesteps: 1,242,769,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,828.01927
Policy Entropy: 3.76749
Value Function Loss: 0.02106

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.49877
Value Function Update Magnitude: 0.55814

Collected Steps per Second: 22,033.88135
Overall Steps per Second: 10,472.60745

Timestep Collection Time: 2.26987
Timestep Consumption Time: 2.50583
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.77570

Cumulative Model Updates: 149,042
Cumulative Timesteps: 1,242,819,764

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1242819764...
Checkpoint 1242819764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,914.83437
Policy Entropy: 3.77595
Value Function Loss: 0.02656

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.51225
Value Function Update Magnitude: 0.48749

Collected Steps per Second: 22,505.67468
Overall Steps per Second: 10,653.50742

Timestep Collection Time: 2.22246
Timestep Consumption Time: 2.47252
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.69498

Cumulative Model Updates: 149,048
Cumulative Timesteps: 1,242,869,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,848.17527
Policy Entropy: 3.78735
Value Function Loss: 0.02749

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.45415

Collected Steps per Second: 22,043.54510
Overall Steps per Second: 10,296.00511

Timestep Collection Time: 2.26978
Timestep Consumption Time: 2.58977
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.85955

Cumulative Model Updates: 149,054
Cumulative Timesteps: 1,242,919,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1242919816...
Checkpoint 1242919816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,590.07768
Policy Entropy: 3.76616
Value Function Loss: 0.02819

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.54277

Collected Steps per Second: 22,513.10628
Overall Steps per Second: 10,720.91441

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.66565

Cumulative Model Updates: 149,060
Cumulative Timesteps: 1,242,969,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,886.42240
Policy Entropy: 3.75552
Value Function Loss: 0.02755

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.52977

Collected Steps per Second: 22,170.73925
Overall Steps per Second: 10,777.89251

Timestep Collection Time: 2.25568
Timestep Consumption Time: 2.38438
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.64005

Cumulative Model Updates: 149,066
Cumulative Timesteps: 1,243,019,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1243019846...
Checkpoint 1243019846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,886.42240
Policy Entropy: 3.74885
Value Function Loss: 0.02158

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.50016

Collected Steps per Second: 21,873.23745
Overall Steps per Second: 10,782.83387

Timestep Collection Time: 2.28700
Timestep Consumption Time: 2.35223
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63923

Cumulative Model Updates: 149,072
Cumulative Timesteps: 1,243,069,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,321.28525
Policy Entropy: 3.74277
Value Function Loss: 0.02200

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.45173

Collected Steps per Second: 21,913.26205
Overall Steps per Second: 10,631.70621

Timestep Collection Time: 2.28282
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.70517

Cumulative Model Updates: 149,078
Cumulative Timesteps: 1,243,119,894

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1243119894...
Checkpoint 1243119894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,572.91604
Policy Entropy: 3.73944
Value Function Loss: 0.01834

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.45044

Collected Steps per Second: 21,905.70337
Overall Steps per Second: 10,512.21631

Timestep Collection Time: 2.28397
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.75941

Cumulative Model Updates: 149,084
Cumulative Timesteps: 1,243,169,926

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,572.91604
Policy Entropy: 3.73776
Value Function Loss: 0.02032

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.48172
Value Function Update Magnitude: 0.48960

Collected Steps per Second: 22,393.88700
Overall Steps per Second: 10,647.07410

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69838

Cumulative Model Updates: 149,090
Cumulative Timesteps: 1,243,219,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1243219950...
Checkpoint 1243219950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,074.93756
Policy Entropy: 3.73644
Value Function Loss: 0.02001

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.51125

Collected Steps per Second: 22,102.30305
Overall Steps per Second: 10,587.04773

Timestep Collection Time: 2.26293
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.72426

Cumulative Model Updates: 149,096
Cumulative Timesteps: 1,243,269,966

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,041.51911
Policy Entropy: 3.73894
Value Function Loss: 0.02233

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.49554
Value Function Update Magnitude: 0.50849

Collected Steps per Second: 21,926.31365
Overall Steps per Second: 10,477.55976

Timestep Collection Time: 2.28173
Timestep Consumption Time: 2.49323
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.77497

Cumulative Model Updates: 149,102
Cumulative Timesteps: 1,243,319,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1243319996...
Checkpoint 1243319996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,414.26985
Policy Entropy: 3.74456
Value Function Loss: 0.02323

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.48024

Collected Steps per Second: 22,289.46520
Overall Steps per Second: 10,542.43448

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.50202
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.74748

Cumulative Model Updates: 149,108
Cumulative Timesteps: 1,243,370,046

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,900.26531
Policy Entropy: 3.74254
Value Function Loss: 0.02314

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.53460
Value Function Update Magnitude: 0.47978

Collected Steps per Second: 22,841.79213
Overall Steps per Second: 10,608.70793

Timestep Collection Time: 2.18897
Timestep Consumption Time: 2.52414
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.71311

Cumulative Model Updates: 149,114
Cumulative Timesteps: 1,243,420,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1243420046...
Checkpoint 1243420046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,900.26531
Policy Entropy: 3.73819
Value Function Loss: 0.02026

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13700
Policy Update Magnitude: 0.48125
Value Function Update Magnitude: 0.48112

Collected Steps per Second: 22,575.01928
Overall Steps per Second: 10,613.78110

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.49652
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.71180

Cumulative Model Updates: 149,120
Cumulative Timesteps: 1,243,470,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,900.26531
Policy Entropy: 3.73501
Value Function Loss: 0.01944

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.46122
Value Function Update Magnitude: 0.47456

Collected Steps per Second: 22,519.11167
Overall Steps per Second: 10,727.41765

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.44169
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.66300

Cumulative Model Updates: 149,126
Cumulative Timesteps: 1,243,520,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1243520078...
Checkpoint 1243520078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.73913
Value Function Loss: 0.01729

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.46690
Value Function Update Magnitude: 0.51532

Collected Steps per Second: 22,784.13826
Overall Steps per Second: 10,655.51322

Timestep Collection Time: 2.19565
Timestep Consumption Time: 2.49920
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.69485

Cumulative Model Updates: 149,132
Cumulative Timesteps: 1,243,570,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.73317
Value Function Loss: 0.01956

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.46645
Value Function Update Magnitude: 0.46396

Collected Steps per Second: 22,773.66601
Overall Steps per Second: 10,826.06313

Timestep Collection Time: 2.19561
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.61867

Cumulative Model Updates: 149,138
Cumulative Timesteps: 1,243,620,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1243620106...
Checkpoint 1243620106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.72724
Value Function Loss: 0.01709

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.42891
Value Function Update Magnitude: 0.39023

Collected Steps per Second: 22,448.94122
Overall Steps per Second: 10,773.18338

Timestep Collection Time: 2.22861
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.64394

Cumulative Model Updates: 149,144
Cumulative Timesteps: 1,243,670,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.72312
Value Function Loss: 0.01593

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.42502
Value Function Update Magnitude: 0.35964

Collected Steps per Second: 22,550.06712
Overall Steps per Second: 10,786.39042

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.41818
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.63547

Cumulative Model Updates: 149,150
Cumulative Timesteps: 1,243,720,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1243720136...
Checkpoint 1243720136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.73098
Value Function Loss: 0.01755

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.43783
Value Function Update Magnitude: 0.36303

Collected Steps per Second: 22,091.55302
Overall Steps per Second: 10,655.46624

Timestep Collection Time: 2.26439
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.69468

Cumulative Model Updates: 149,156
Cumulative Timesteps: 1,243,770,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,838.24199
Policy Entropy: 3.72884
Value Function Loss: 0.02016

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.47447
Value Function Update Magnitude: 0.37790

Collected Steps per Second: 22,230.06351
Overall Steps per Second: 10,517.14047

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.75624

Cumulative Model Updates: 149,162
Cumulative Timesteps: 1,243,820,182

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1243820182...
Checkpoint 1243820182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,623.98695
Policy Entropy: 3.72396
Value Function Loss: 0.02109

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.49255
Value Function Update Magnitude: 0.29556

Collected Steps per Second: 21,995.44991
Overall Steps per Second: 10,658.23849

Timestep Collection Time: 2.27411
Timestep Consumption Time: 2.41898
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.69308

Cumulative Model Updates: 149,168
Cumulative Timesteps: 1,243,870,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,623.98695
Policy Entropy: 3.73256
Value Function Loss: 0.02200

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.49218
Value Function Update Magnitude: 0.28689

Collected Steps per Second: 21,628.06468
Overall Steps per Second: 10,570.68708

Timestep Collection Time: 2.31181
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.73006

Cumulative Model Updates: 149,174
Cumulative Timesteps: 1,243,920,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1243920202...
Checkpoint 1243920202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,123.06649
Policy Entropy: 3.73980
Value Function Loss: 0.02144

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.51169
Value Function Update Magnitude: 0.36580

Collected Steps per Second: 21,930.23302
Overall Steps per Second: 10,597.69069

Timestep Collection Time: 2.28178
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.72178

Cumulative Model Updates: 149,180
Cumulative Timesteps: 1,243,970,242

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,123.06649
Policy Entropy: 3.74615
Value Function Loss: 0.01913

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.52642
Value Function Update Magnitude: 0.44566

Collected Steps per Second: 22,076.34514
Overall Steps per Second: 10,845.20908

Timestep Collection Time: 2.26577
Timestep Consumption Time: 2.34640
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.61217

Cumulative Model Updates: 149,186
Cumulative Timesteps: 1,244,020,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1244020262...
Checkpoint 1244020262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275,821.29982
Policy Entropy: 3.73833
Value Function Loss: 0.01776

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.48098
Value Function Update Magnitude: 0.38686

Collected Steps per Second: 22,178.57504
Overall Steps per Second: 10,612.35859

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.45824
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.71375

Cumulative Model Updates: 149,192
Cumulative Timesteps: 1,244,070,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,727.17460
Policy Entropy: 3.76014
Value Function Loss: 0.01783

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.43479
Value Function Update Magnitude: 0.33120

Collected Steps per Second: 22,460.88843
Overall Steps per Second: 10,802.40755

Timestep Collection Time: 2.22707
Timestep Consumption Time: 2.40356
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.63063

Cumulative Model Updates: 149,198
Cumulative Timesteps: 1,244,120,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1244120308...
Checkpoint 1244120308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,212.68979
Policy Entropy: 3.74756
Value Function Loss: 0.02417

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.45379
Value Function Update Magnitude: 0.31410

Collected Steps per Second: 22,856.65102
Overall Steps per Second: 10,722.06542

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.47722
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.66608

Cumulative Model Updates: 149,204
Cumulative Timesteps: 1,244,170,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,339.37102
Policy Entropy: 3.77038
Value Function Loss: 0.02241

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.49765
Value Function Update Magnitude: 0.44778

Collected Steps per Second: 22,761.57111
Overall Steps per Second: 10,852.07906

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.61091

Cumulative Model Updates: 149,210
Cumulative Timesteps: 1,244,220,376

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1244220376...
Checkpoint 1244220376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,035.31916
Policy Entropy: 3.77048
Value Function Loss: 0.02489

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.49709
Value Function Update Magnitude: 0.64444

Collected Steps per Second: 21,883.78984
Overall Steps per Second: 10,645.27166

Timestep Collection Time: 2.28598
Timestep Consumption Time: 2.41338
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.69936

Cumulative Model Updates: 149,216
Cumulative Timesteps: 1,244,270,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,215.39028
Policy Entropy: 3.77943
Value Function Loss: 0.02676

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.52302
Value Function Update Magnitude: 0.56512

Collected Steps per Second: 22,246.59083
Overall Steps per Second: 10,524.42747

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.75332

Cumulative Model Updates: 149,222
Cumulative Timesteps: 1,244,320,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1244320428...
Checkpoint 1244320428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,969.35289
Policy Entropy: 3.77295
Value Function Loss: 0.02321

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.51170
Value Function Update Magnitude: 0.51179

Collected Steps per Second: 22,223.85606
Overall Steps per Second: 10,720.15846

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.66654

Cumulative Model Updates: 149,228
Cumulative Timesteps: 1,244,370,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,942.94764
Policy Entropy: 3.75132
Value Function Loss: 0.02405

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.50423
Value Function Update Magnitude: 0.53087

Collected Steps per Second: 22,337.19040
Overall Steps per Second: 10,612.83208

Timestep Collection Time: 2.23967
Timestep Consumption Time: 2.47424
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.71392

Cumulative Model Updates: 149,234
Cumulative Timesteps: 1,244,420,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1244420482...
Checkpoint 1244420482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,930.27909
Policy Entropy: 3.76148
Value Function Loss: 0.02100

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.61211

Collected Steps per Second: 22,011.30718
Overall Steps per Second: 10,484.38113

Timestep Collection Time: 2.27247
Timestep Consumption Time: 2.49844
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.77091

Cumulative Model Updates: 149,240
Cumulative Timesteps: 1,244,470,502

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,714.92679
Policy Entropy: 3.74806
Value Function Loss: 0.02626

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.61680

Collected Steps per Second: 22,648.76357
Overall Steps per Second: 10,556.70386

Timestep Collection Time: 2.20886
Timestep Consumption Time: 2.53012
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.73898

Cumulative Model Updates: 149,246
Cumulative Timesteps: 1,244,520,530

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1244520530...
Checkpoint 1244520530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,192.70809
Policy Entropy: 3.77346
Value Function Loss: 0.02322

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.65497
Value Function Update Magnitude: 0.58472

Collected Steps per Second: 22,664.92909
Overall Steps per Second: 10,792.43013

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.63436

Cumulative Model Updates: 149,252
Cumulative Timesteps: 1,244,570,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,515.17545
Policy Entropy: 3.75391
Value Function Loss: 0.03089

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.62682
Value Function Update Magnitude: 0.55527

Collected Steps per Second: 22,854.05069
Overall Steps per Second: 10,643.97586

Timestep Collection Time: 2.18876
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.69956

Cumulative Model Updates: 149,258
Cumulative Timesteps: 1,244,620,568

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1244620568...
Checkpoint 1244620568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,065.01154
Policy Entropy: 3.77138
Value Function Loss: 0.02628

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.61746
Value Function Update Magnitude: 0.48547

Collected Steps per Second: 22,742.43159
Overall Steps per Second: 10,661.16016

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.68992

Cumulative Model Updates: 149,264
Cumulative Timesteps: 1,244,670,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,080.33611
Policy Entropy: 3.78766
Value Function Loss: 0.03048

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13996
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.45903

Collected Steps per Second: 22,717.26135
Overall Steps per Second: 10,788.45639

Timestep Collection Time: 2.20159
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.63588

Cumulative Model Updates: 149,270
Cumulative Timesteps: 1,244,720,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1244720582...
Checkpoint 1244720582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,235.04526
Policy Entropy: 3.80359
Value Function Loss: 0.02603

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.56877
Value Function Update Magnitude: 0.56565

Collected Steps per Second: 22,528.25959
Overall Steps per Second: 10,653.74705

Timestep Collection Time: 2.22121
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.69694

Cumulative Model Updates: 149,276
Cumulative Timesteps: 1,244,770,622

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,565.07729
Policy Entropy: 3.78457
Value Function Loss: 0.02620

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.60702
Value Function Update Magnitude: 0.67465

Collected Steps per Second: 22,417.19000
Overall Steps per Second: 10,471.13226

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.54460
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77503

Cumulative Model Updates: 149,282
Cumulative Timesteps: 1,244,820,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1244820622...
Checkpoint 1244820622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,955.32014
Policy Entropy: 3.74873
Value Function Loss: 0.02785

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.59636

Collected Steps per Second: 22,113.97214
Overall Steps per Second: 10,700.20049

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.41305
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.67524

Cumulative Model Updates: 149,288
Cumulative Timesteps: 1,244,870,648

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,713.28273
Policy Entropy: 3.74044
Value Function Loss: 0.02872

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14296
Policy Update Magnitude: 0.52831
Value Function Update Magnitude: 0.52018

Collected Steps per Second: 22,332.47185
Overall Steps per Second: 10,579.26187

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.72679

Cumulative Model Updates: 149,294
Cumulative Timesteps: 1,244,920,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1244920654...
Checkpoint 1244920654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,756.94004
Policy Entropy: 3.72467
Value Function Loss: 0.02866

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.45382

Collected Steps per Second: 22,598.37496
Overall Steps per Second: 10,561.50926

Timestep Collection Time: 2.21379
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.73682

Cumulative Model Updates: 149,300
Cumulative Timesteps: 1,244,970,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,711.76545
Policy Entropy: 3.73203
Value Function Loss: 0.02784

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.60071
Value Function Update Magnitude: 0.44613

Collected Steps per Second: 22,990.83633
Overall Steps per Second: 10,808.42319

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.45369
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.63065

Cumulative Model Updates: 149,306
Cumulative Timesteps: 1,245,020,732

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1245020732...
Checkpoint 1245020732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,096.08565
Policy Entropy: 3.74743
Value Function Loss: 0.02832

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.65318
Value Function Update Magnitude: 0.59900

Collected Steps per Second: 22,445.67448
Overall Steps per Second: 10,619.23448

Timestep Collection Time: 2.22778
Timestep Consumption Time: 2.48104
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.70881

Cumulative Model Updates: 149,312
Cumulative Timesteps: 1,245,070,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,499.29924
Policy Entropy: 3.78975
Value Function Loss: 0.03151

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.70811
Value Function Update Magnitude: 0.86840

Collected Steps per Second: 22,509.53453
Overall Steps per Second: 10,598.85232

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.49711
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.71919

Cumulative Model Updates: 149,318
Cumulative Timesteps: 1,245,120,754

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1245120754...
Checkpoint 1245120754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,632.16624
Policy Entropy: 3.79334
Value Function Loss: 0.02942

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13637
Policy Update Magnitude: 0.69160
Value Function Update Magnitude: 0.68996

Collected Steps per Second: 22,845.05730
Overall Steps per Second: 10,846.05119

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.61182

Cumulative Model Updates: 149,324
Cumulative Timesteps: 1,245,170,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,823.98165
Policy Entropy: 3.80164
Value Function Loss: 0.02573

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.68112
Value Function Update Magnitude: 0.59736

Collected Steps per Second: 22,618.39594
Overall Steps per Second: 10,593.59577

Timestep Collection Time: 2.21094
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.72059

Cumulative Model Updates: 149,330
Cumulative Timesteps: 1,245,220,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1245220782...
Checkpoint 1245220782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,921.39416
Policy Entropy: 3.76622
Value Function Loss: 0.02336

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.62296
Value Function Update Magnitude: 0.56655

Collected Steps per Second: 22,750.64434
Overall Steps per Second: 10,646.57110

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.69729

Cumulative Model Updates: 149,336
Cumulative Timesteps: 1,245,270,792

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,455.57489
Policy Entropy: 3.76186
Value Function Loss: 0.02409

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15530
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.53797

Collected Steps per Second: 22,037.76236
Overall Steps per Second: 10,467.49918

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.50826
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.77745

Cumulative Model Updates: 149,342
Cumulative Timesteps: 1,245,320,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1245320800...
Checkpoint 1245320800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,455.57489
Policy Entropy: 3.73893
Value Function Loss: 0.02312

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14756
Policy Update Magnitude: 0.57331
Value Function Update Magnitude: 0.52589

Collected Steps per Second: 21,881.65142
Overall Steps per Second: 10,571.16341

Timestep Collection Time: 2.28602
Timestep Consumption Time: 2.44590
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.73193

Cumulative Model Updates: 149,348
Cumulative Timesteps: 1,245,370,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,875.65348
Policy Entropy: 3.74132
Value Function Loss: 0.02886

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.53192
Value Function Update Magnitude: 0.41449

Collected Steps per Second: 22,290.26550
Overall Steps per Second: 10,530.00174

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.50581
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.74948

Cumulative Model Updates: 149,354
Cumulative Timesteps: 1,245,420,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1245420834...
Checkpoint 1245420834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,144.46060
Policy Entropy: 3.74140
Value Function Loss: 0.02609

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.51240
Value Function Update Magnitude: 0.41354

Collected Steps per Second: 22,219.76383
Overall Steps per Second: 10,592.97151

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.72124

Cumulative Model Updates: 149,360
Cumulative Timesteps: 1,245,470,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,170.89346
Policy Entropy: 3.74175
Value Function Loss: 0.02379

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.49082
Value Function Update Magnitude: 0.49970

Collected Steps per Second: 22,439.44100
Overall Steps per Second: 10,535.83597

Timestep Collection Time: 2.22822
Timestep Consumption Time: 2.51749
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.74571

Cumulative Model Updates: 149,366
Cumulative Timesteps: 1,245,520,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1245520846...
Checkpoint 1245520846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,170.89346
Policy Entropy: 3.73809
Value Function Loss: 0.02067

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.48893
Value Function Update Magnitude: 0.44474

Collected Steps per Second: 22,912.01667
Overall Steps per Second: 10,623.66484

Timestep Collection Time: 2.18392
Timestep Consumption Time: 2.52613
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.71005

Cumulative Model Updates: 149,372
Cumulative Timesteps: 1,245,570,884

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,170.89346
Policy Entropy: 3.73257
Value Function Loss: 0.01872

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.48568
Value Function Update Magnitude: 0.45363

Collected Steps per Second: 22,856.51942
Overall Steps per Second: 10,804.04904

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.63049

Cumulative Model Updates: 149,378
Cumulative Timesteps: 1,245,620,912

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1245620912...
Checkpoint 1245620912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,514.05580
Policy Entropy: 3.72180
Value Function Loss: 0.01854

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.48634
Value Function Update Magnitude: 0.51635

Collected Steps per Second: 22,536.09683
Overall Steps per Second: 10,680.88917

Timestep Collection Time: 2.21902
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.68201

Cumulative Model Updates: 149,384
Cumulative Timesteps: 1,245,670,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,549.94559
Policy Entropy: 3.73201
Value Function Loss: 0.01824

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.49419
Value Function Update Magnitude: 0.48507

Collected Steps per Second: 22,500.29771
Overall Steps per Second: 10,623.06803

Timestep Collection Time: 2.22450
Timestep Consumption Time: 2.48713
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.71163

Cumulative Model Updates: 149,390
Cumulative Timesteps: 1,245,720,972

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1245720972...
Checkpoint 1245720972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,549.94559
Policy Entropy: 3.73055
Value Function Loss: 0.01743

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13313
Policy Update Magnitude: 0.46525
Value Function Update Magnitude: 0.40478

Collected Steps per Second: 22,821.27772
Overall Steps per Second: 10,858.83999

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.60454

Cumulative Model Updates: 149,396
Cumulative Timesteps: 1,245,770,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,873.37468
Policy Entropy: 3.73455
Value Function Loss: 0.01969

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14562
Policy Update Magnitude: 0.50372
Value Function Update Magnitude: 0.40701

Collected Steps per Second: 22,675.50559
Overall Steps per Second: 10,661.67595

Timestep Collection Time: 2.20511
Timestep Consumption Time: 2.48477
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.68988

Cumulative Model Updates: 149,402
Cumulative Timesteps: 1,245,820,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1245820974...
Checkpoint 1245820974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,367.12691
Policy Entropy: 3.73606
Value Function Loss: 0.02198

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.60263

Collected Steps per Second: 22,284.33305
Overall Steps per Second: 10,551.96819

Timestep Collection Time: 2.24445
Timestep Consumption Time: 2.49552
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.73997

Cumulative Model Updates: 149,408
Cumulative Timesteps: 1,245,870,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,828.97306
Policy Entropy: 3.74102
Value Function Loss: 0.02463

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.15171
Policy Update Magnitude: 0.61776
Value Function Update Magnitude: 0.60368

Collected Steps per Second: 21,972.90419
Overall Steps per Second: 10,454.04404

Timestep Collection Time: 2.27562
Timestep Consumption Time: 2.50741
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.78303

Cumulative Model Updates: 149,414
Cumulative Timesteps: 1,245,920,992

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1245920992...
Checkpoint 1245920992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,633.52711
Policy Entropy: 3.74783
Value Function Loss: 0.02270

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.60777
Value Function Update Magnitude: 0.51462

Collected Steps per Second: 22,217.52711
Overall Steps per Second: 10,568.31571

Timestep Collection Time: 2.25057
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.73131

Cumulative Model Updates: 149,420
Cumulative Timesteps: 1,245,970,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,762.58667
Policy Entropy: 3.74700
Value Function Loss: 0.02173

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.49218

Collected Steps per Second: 21,813.91459
Overall Steps per Second: 10,466.31769

Timestep Collection Time: 2.29248
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.77799

Cumulative Model Updates: 149,426
Cumulative Timesteps: 1,246,021,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1246021002...
Checkpoint 1246021002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,189.43006
Policy Entropy: 3.74430
Value Function Loss: 0.01997

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.47480

Collected Steps per Second: 22,072.66617
Overall Steps per Second: 10,650.74066

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.69545

Cumulative Model Updates: 149,432
Cumulative Timesteps: 1,246,071,012

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,448.31351
Policy Entropy: 3.73465
Value Function Loss: 0.02566

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.47242

Collected Steps per Second: 22,399.90111
Overall Steps per Second: 10,467.57316

Timestep Collection Time: 2.23287
Timestep Consumption Time: 2.54532
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.77818

Cumulative Model Updates: 149,438
Cumulative Timesteps: 1,246,121,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1246121028...
Checkpoint 1246121028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,584.53811
Policy Entropy: 3.74017
Value Function Loss: 0.02381

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.59364

Collected Steps per Second: 22,465.09669
Overall Steps per Second: 10,584.32049

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.72454

Cumulative Model Updates: 149,444
Cumulative Timesteps: 1,246,171,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,790.07596
Policy Entropy: 3.75465
Value Function Loss: 0.02681

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14036
Policy Update Magnitude: 0.60287
Value Function Update Magnitude: 0.74777

Collected Steps per Second: 22,678.25265
Overall Steps per Second: 10,709.15029

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.46415
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.66890

Cumulative Model Updates: 149,450
Cumulative Timesteps: 1,246,221,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1246221034...
Checkpoint 1246221034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,563.18977
Policy Entropy: 3.78677
Value Function Loss: 0.02367

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.60094
Value Function Update Magnitude: 0.76471

Collected Steps per Second: 22,821.61113
Overall Steps per Second: 10,830.79374

Timestep Collection Time: 2.19117
Timestep Consumption Time: 2.42585
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.61702

Cumulative Model Updates: 149,456
Cumulative Timesteps: 1,246,271,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,682.20339
Policy Entropy: 3.79935
Value Function Loss: 0.02444

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.57153
Value Function Update Magnitude: 0.62919

Collected Steps per Second: 22,462.16958
Overall Steps per Second: 10,605.55474

Timestep Collection Time: 2.22677
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.71621

Cumulative Model Updates: 149,462
Cumulative Timesteps: 1,246,321,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1246321058...
Checkpoint 1246321058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.09688
Policy Entropy: 3.80868
Value Function Loss: 0.02128

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11631
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.55915

Collected Steps per Second: 22,304.64772
Overall Steps per Second: 10,510.93300

Timestep Collection Time: 2.24267
Timestep Consumption Time: 2.51637
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.75904

Cumulative Model Updates: 149,468
Cumulative Timesteps: 1,246,371,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,915.57027
Policy Entropy: 3.78956
Value Function Loss: 0.02399

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.52313
Value Function Update Magnitude: 0.62497

Collected Steps per Second: 22,659.20749
Overall Steps per Second: 10,851.09745

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.40151
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60838

Cumulative Model Updates: 149,474
Cumulative Timesteps: 1,246,421,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1246421086...
Checkpoint 1246421086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,045.32101
Policy Entropy: 3.76938
Value Function Loss: 0.02229

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.52295
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 21,696.13374
Overall Steps per Second: 10,755.47668

Timestep Collection Time: 2.30594
Timestep Consumption Time: 2.34564
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.65158

Cumulative Model Updates: 149,480
Cumulative Timesteps: 1,246,471,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268,003.04109
Policy Entropy: 3.75196
Value Function Loss: 0.02709

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.53816
Value Function Update Magnitude: 0.57065

Collected Steps per Second: 21,753.72813
Overall Steps per Second: 10,646.25606

Timestep Collection Time: 2.29846
Timestep Consumption Time: 2.39803
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.69649

Cumulative Model Updates: 149,486
Cumulative Timesteps: 1,246,521,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1246521116...
Checkpoint 1246521116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,971.52039
Policy Entropy: 3.76139
Value Function Loss: 0.02590

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.60280
Value Function Update Magnitude: 0.60977

Collected Steps per Second: 21,409.61703
Overall Steps per Second: 10,507.42883

Timestep Collection Time: 2.33549
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.75873

Cumulative Model Updates: 149,492
Cumulative Timesteps: 1,246,571,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,862.50521
Policy Entropy: 3.77662
Value Function Loss: 0.03009

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.64615
Value Function Update Magnitude: 0.63703

Collected Steps per Second: 21,442.11656
Overall Steps per Second: 10,585.79406

Timestep Collection Time: 2.33205
Timestep Consumption Time: 2.39164
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.72369

Cumulative Model Updates: 149,498
Cumulative Timesteps: 1,246,621,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1246621122...
Checkpoint 1246621122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,869.89632
Policy Entropy: 3.78418
Value Function Loss: 0.02613

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12892
Policy Update Magnitude: 0.61283
Value Function Update Magnitude: 0.55511

Collected Steps per Second: 21,661.71577
Overall Steps per Second: 10,569.97788

Timestep Collection Time: 2.30840
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.73076

Cumulative Model Updates: 149,504
Cumulative Timesteps: 1,246,671,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,869.89632
Policy Entropy: 3.75826
Value Function Loss: 0.02346

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.54462
Value Function Update Magnitude: 0.49245

Collected Steps per Second: 22,091.22230
Overall Steps per Second: 10,627.29396

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.70712

Cumulative Model Updates: 149,510
Cumulative Timesteps: 1,246,721,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1246721150...
Checkpoint 1246721150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,595.76575
Policy Entropy: 3.76334
Value Function Loss: 0.01984

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.48012
Value Function Update Magnitude: 0.41891

Collected Steps per Second: 22,490.29729
Overall Steps per Second: 10,707.57666

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.67146

Cumulative Model Updates: 149,516
Cumulative Timesteps: 1,246,771,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,124.98255
Policy Entropy: 3.77298
Value Function Loss: 0.01947

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.48387
Value Function Update Magnitude: 0.43157

Collected Steps per Second: 22,874.22318
Overall Steps per Second: 10,900.74753

Timestep Collection Time: 2.18718
Timestep Consumption Time: 2.40242
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.58959

Cumulative Model Updates: 149,522
Cumulative Timesteps: 1,246,821,200

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1246821200...
Checkpoint 1246821200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,726.87579
Policy Entropy: 3.76961
Value Function Loss: 0.01950

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.49487
Value Function Update Magnitude: 0.48175

Collected Steps per Second: 22,928.67315
Overall Steps per Second: 10,673.17938

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68614

Cumulative Model Updates: 149,528
Cumulative Timesteps: 1,246,871,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,822.23784
Policy Entropy: 3.76812
Value Function Loss: 0.01842

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.53719

Collected Steps per Second: 21,915.76318
Overall Steps per Second: 10,482.63570

Timestep Collection Time: 2.28338
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.77380

Cumulative Model Updates: 149,534
Cumulative Timesteps: 1,246,921,258

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1246921258...
Checkpoint 1246921258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,822.23784
Policy Entropy: 3.73421
Value Function Loss: 0.01745

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14637
Policy Update Magnitude: 0.48985
Value Function Update Magnitude: 0.56366

Collected Steps per Second: 22,099.71018
Overall Steps per Second: 10,675.97792

Timestep Collection Time: 2.26320
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.68491

Cumulative Model Updates: 149,540
Cumulative Timesteps: 1,246,971,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,195.71454
Policy Entropy: 3.74461
Value Function Loss: 0.01929

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.50539

Collected Steps per Second: 22,472.09898
Overall Steps per Second: 10,626.06749

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.70541

Cumulative Model Updates: 149,546
Cumulative Timesteps: 1,247,021,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247021274...
Checkpoint 1247021274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,751.36988
Policy Entropy: 3.73155
Value Function Loss: 0.01979

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.47820

Collected Steps per Second: 22,447.76072
Overall Steps per Second: 10,560.31584

Timestep Collection Time: 2.22873
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.73755

Cumulative Model Updates: 149,552
Cumulative Timesteps: 1,247,071,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,751.36988
Policy Entropy: 3.74237
Value Function Loss: 0.02140

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13936
Policy Update Magnitude: 0.51871
Value Function Update Magnitude: 0.50236

Collected Steps per Second: 22,926.80997
Overall Steps per Second: 10,758.43341

Timestep Collection Time: 2.18085
Timestep Consumption Time: 2.46666
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.64752

Cumulative Model Updates: 149,558
Cumulative Timesteps: 1,247,121,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247121304...
Checkpoint 1247121304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,428.04675
Policy Entropy: 3.73458
Value Function Loss: 0.02233

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.50322
Value Function Update Magnitude: 0.54554

Collected Steps per Second: 22,232.58710
Overall Steps per Second: 10,707.30749

Timestep Collection Time: 2.25012
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.67214

Cumulative Model Updates: 149,564
Cumulative Timesteps: 1,247,171,330

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,089.18606
Policy Entropy: 3.73884
Value Function Loss: 0.02172

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.49510
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 22,320.18880
Overall Steps per Second: 10,913.31479

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.34293
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.58449

Cumulative Model Updates: 149,570
Cumulative Timesteps: 1,247,221,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1247221362...
Checkpoint 1247221362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,089.18606
Policy Entropy: 3.73839
Value Function Loss: 0.02070

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.51661
Value Function Update Magnitude: 0.62654

Collected Steps per Second: 21,935.32120
Overall Steps per Second: 10,584.10677

Timestep Collection Time: 2.27970
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.72463

Cumulative Model Updates: 149,576
Cumulative Timesteps: 1,247,271,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.23874
Policy Entropy: 3.73663
Value Function Loss: 0.02001

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.53782

Collected Steps per Second: 22,815.91974
Overall Steps per Second: 10,885.11718

Timestep Collection Time: 2.19189
Timestep Consumption Time: 2.40246
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.59435

Cumulative Model Updates: 149,582
Cumulative Timesteps: 1,247,321,378

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1247321378...
Checkpoint 1247321378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.23874
Policy Entropy: 3.72775
Value Function Loss: 0.01924

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.49118
Value Function Update Magnitude: 0.53722

Collected Steps per Second: 22,310.28839
Overall Steps per Second: 10,646.22623

Timestep Collection Time: 2.24193
Timestep Consumption Time: 2.45627
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69819

Cumulative Model Updates: 149,588
Cumulative Timesteps: 1,247,371,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.23874
Policy Entropy: 3.70948
Value Function Loss: 0.02305

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.52408
Value Function Update Magnitude: 0.49322

Collected Steps per Second: 22,409.24681
Overall Steps per Second: 10,571.82941

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.49833
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.72955

Cumulative Model Updates: 149,594
Cumulative Timesteps: 1,247,421,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247421396...
Checkpoint 1247421396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,749.23874
Policy Entropy: 3.71523
Value Function Loss: 0.02065

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.59231

Collected Steps per Second: 22,131.70720
Overall Steps per Second: 10,559.41125

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.73587

Cumulative Model Updates: 149,600
Cumulative Timesteps: 1,247,471,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,979.04473
Policy Entropy: 3.73361
Value Function Loss: 0.02207

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12820
Policy Update Magnitude: 0.53078
Value Function Update Magnitude: 0.65211

Collected Steps per Second: 21,883.70148
Overall Steps per Second: 10,434.64747

Timestep Collection Time: 2.28517
Timestep Consumption Time: 2.50732
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.79250

Cumulative Model Updates: 149,606
Cumulative Timesteps: 1,247,521,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1247521412...
Checkpoint 1247521412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,622.15575
Policy Entropy: 3.74818
Value Function Loss: 0.01850

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.53261
Value Function Update Magnitude: 0.70450

Collected Steps per Second: 22,145.02895
Overall Steps per Second: 10,698.93499

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27595
Total Iteration Time: 4.67523

Cumulative Model Updates: 149,612
Cumulative Timesteps: 1,247,571,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,622.15575
Policy Entropy: 3.75459
Value Function Loss: 0.01815

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.67734

Collected Steps per Second: 22,222.15901
Overall Steps per Second: 10,452.76289

Timestep Collection Time: 2.25001
Timestep Consumption Time: 2.53342
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.78342

Cumulative Model Updates: 149,618
Cumulative Timesteps: 1,247,621,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247621432...
Checkpoint 1247621432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,186.76424
Policy Entropy: 3.74730
Value Function Loss: 0.01609

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.48726
Value Function Update Magnitude: 0.64350

Collected Steps per Second: 22,672.75443
Overall Steps per Second: 10,661.36616

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.69208

Cumulative Model Updates: 149,624
Cumulative Timesteps: 1,247,671,456

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,683.68804
Policy Entropy: 3.75410
Value Function Loss: 0.01811

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.48713
Value Function Update Magnitude: 0.65038

Collected Steps per Second: 21,775.96853
Overall Steps per Second: 10,758.94286

Timestep Collection Time: 2.29648
Timestep Consumption Time: 2.35156
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.64804

Cumulative Model Updates: 149,630
Cumulative Timesteps: 1,247,721,464

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1247721464...
Checkpoint 1247721464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,933.96221
Policy Entropy: 3.76560
Value Function Loss: 0.01945

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.67156

Collected Steps per Second: 21,842.65096
Overall Steps per Second: 10,696.38008

Timestep Collection Time: 2.28919
Timestep Consumption Time: 2.38547
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.67467

Cumulative Model Updates: 149,636
Cumulative Timesteps: 1,247,771,466

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,106.60065
Policy Entropy: 3.75856
Value Function Loss: 0.02032

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.61584
Value Function Update Magnitude: 0.72892

Collected Steps per Second: 21,934.89257
Overall Steps per Second: 10,678.46532

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.40381
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.68419

Cumulative Model Updates: 149,642
Cumulative Timesteps: 1,247,821,486

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1247821486...
Checkpoint 1247821486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,958.92603
Policy Entropy: 3.75219
Value Function Loss: 0.02071

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.61306
Value Function Update Magnitude: 0.74924

Collected Steps per Second: 21,708.04695
Overall Steps per Second: 10,463.38002

Timestep Collection Time: 2.30375
Timestep Consumption Time: 2.47577
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.77953

Cumulative Model Updates: 149,648
Cumulative Timesteps: 1,247,871,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,208.98807
Policy Entropy: 3.74543
Value Function Loss: 0.02033

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12625
Policy Update Magnitude: 0.60577
Value Function Update Magnitude: 0.75096

Collected Steps per Second: 22,526.19977
Overall Steps per Second: 10,765.37627

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.42488
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.64452

Cumulative Model Updates: 149,654
Cumulative Timesteps: 1,247,921,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1247921496...
Checkpoint 1247921496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,435.90142
Policy Entropy: 3.75586
Value Function Loss: 0.01911

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.56611
Value Function Update Magnitude: 0.73144

Collected Steps per Second: 21,897.27409
Overall Steps per Second: 10,688.43239

Timestep Collection Time: 2.28458
Timestep Consumption Time: 2.39581
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.68039

Cumulative Model Updates: 149,660
Cumulative Timesteps: 1,247,971,522

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,502.01999
Policy Entropy: 3.76674
Value Function Loss: 0.01828

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.52901
Value Function Update Magnitude: 0.67233

Collected Steps per Second: 22,346.49348
Overall Steps per Second: 10,566.93920

Timestep Collection Time: 2.23883
Timestep Consumption Time: 2.49575
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73458

Cumulative Model Updates: 149,666
Cumulative Timesteps: 1,248,021,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1248021552...
Checkpoint 1248021552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,961.78445
Policy Entropy: 3.76692
Value Function Loss: 0.01913

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 22,278.65491
Overall Steps per Second: 10,597.96787

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.72034

Cumulative Model Updates: 149,672
Cumulative Timesteps: 1,248,071,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,120.30040
Policy Entropy: 3.76848
Value Function Loss: 0.02123

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.52970
Value Function Update Magnitude: 0.67933

Collected Steps per Second: 22,372.22313
Overall Steps per Second: 10,564.57363

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.73488

Cumulative Model Updates: 149,678
Cumulative Timesteps: 1,248,121,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1248121600...
Checkpoint 1248121600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,995.32886
Policy Entropy: 3.75661
Value Function Loss: 0.01970

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.52519
Value Function Update Magnitude: 0.57700

Collected Steps per Second: 22,773.50374
Overall Steps per Second: 10,538.44311

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.55033
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.74700

Cumulative Model Updates: 149,684
Cumulative Timesteps: 1,248,171,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,760.15868
Policy Entropy: 3.74843
Value Function Loss: 0.02202

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.59224

Collected Steps per Second: 22,573.42966
Overall Steps per Second: 10,606.43184

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.49973
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.71525

Cumulative Model Updates: 149,690
Cumulative Timesteps: 1,248,221,638

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1248221638...
Checkpoint 1248221638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,538.79374
Policy Entropy: 3.74984
Value Function Loss: 0.02345

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.58408
Value Function Update Magnitude: 0.54572

Collected Steps per Second: 22,752.66267
Overall Steps per Second: 10,816.81676

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.62280

Cumulative Model Updates: 149,696
Cumulative Timesteps: 1,248,271,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,817.03937
Policy Entropy: 3.75012
Value Function Loss: 0.02935

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.64634
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 22,671.99253
Overall Steps per Second: 10,638.82343

Timestep Collection Time: 2.20554
Timestep Consumption Time: 2.49460
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70014

Cumulative Model Updates: 149,702
Cumulative Timesteps: 1,248,321,646

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1248321646...
Checkpoint 1248321646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,998.47081
Policy Entropy: 3.75607
Value Function Loss: 0.02877

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.67732
Value Function Update Magnitude: 0.57282

Collected Steps per Second: 22,118.31182
Overall Steps per Second: 10,749.22674

Timestep Collection Time: 2.26075
Timestep Consumption Time: 2.39112
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.65187

Cumulative Model Updates: 149,708
Cumulative Timesteps: 1,248,371,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,087.35102
Policy Entropy: 3.75613
Value Function Loss: 0.02619

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.64225
Value Function Update Magnitude: 0.53004

Collected Steps per Second: 21,972.87251
Overall Steps per Second: 10,725.33416

Timestep Collection Time: 2.27699
Timestep Consumption Time: 2.38785
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.66484

Cumulative Model Updates: 149,714
Cumulative Timesteps: 1,248,421,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1248421682...
Checkpoint 1248421682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,723.98559
Policy Entropy: 3.75496
Value Function Loss: 0.02254

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.58163
Value Function Update Magnitude: 0.45496

Collected Steps per Second: 21,733.94358
Overall Steps per Second: 10,646.03301

Timestep Collection Time: 2.30055
Timestep Consumption Time: 2.39604
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.69659

Cumulative Model Updates: 149,720
Cumulative Timesteps: 1,248,471,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,380.28608
Policy Entropy: 3.75594
Value Function Loss: 0.02166

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11958
Policy Update Magnitude: 0.59857
Value Function Update Magnitude: 0.42623

Collected Steps per Second: 21,391.87965
Overall Steps per Second: 10,417.92800

Timestep Collection Time: 2.33752
Timestep Consumption Time: 2.46228
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.79980

Cumulative Model Updates: 149,726
Cumulative Timesteps: 1,248,521,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1248521686...
Checkpoint 1248521686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,861.13511
Policy Entropy: 3.74941
Value Function Loss: 0.02240

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.63323
Value Function Update Magnitude: 0.45958

Collected Steps per Second: 21,875.84280
Overall Steps per Second: 10,645.90266

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.41131
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.69721

Cumulative Model Updates: 149,732
Cumulative Timesteps: 1,248,571,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,759.99784
Policy Entropy: 3.76046
Value Function Loss: 0.02043

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14427
Policy Update Magnitude: 0.61640
Value Function Update Magnitude: 0.56445

Collected Steps per Second: 22,302.50418
Overall Steps per Second: 10,645.05284

Timestep Collection Time: 2.24307
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.69946

Cumulative Model Updates: 149,738
Cumulative Timesteps: 1,248,621,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1248621718...
Checkpoint 1248621718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,357.13255
Policy Entropy: 3.76164
Value Function Loss: 0.02155

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13867
Policy Update Magnitude: 0.59586
Value Function Update Magnitude: 0.54776

Collected Steps per Second: 21,822.98635
Overall Steps per Second: 10,459.95903

Timestep Collection Time: 2.29208
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.78205

Cumulative Model Updates: 149,744
Cumulative Timesteps: 1,248,671,738

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,633.48064
Policy Entropy: 3.76212
Value Function Loss: 0.02141

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.50559

Collected Steps per Second: 22,655.62735
Overall Steps per Second: 10,578.96465

Timestep Collection Time: 2.20819
Timestep Consumption Time: 2.52081
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.72901

Cumulative Model Updates: 149,750
Cumulative Timesteps: 1,248,721,766

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1248721766...
Checkpoint 1248721766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,781.78807
Policy Entropy: 3.75858
Value Function Loss: 0.02189

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.58670
Value Function Update Magnitude: 0.57464

Collected Steps per Second: 22,531.53618
Overall Steps per Second: 10,514.29859

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.53774
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.75809

Cumulative Model Updates: 149,756
Cumulative Timesteps: 1,248,771,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,781.78807
Policy Entropy: 3.75444
Value Function Loss: 0.01920

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.65131

Collected Steps per Second: 22,773.65886
Overall Steps per Second: 10,804.69775

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.43365
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.63058

Cumulative Model Updates: 149,762
Cumulative Timesteps: 1,248,821,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1248821826...
Checkpoint 1248821826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,781.78807
Policy Entropy: 3.73334
Value Function Loss: 0.01828

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.51046
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 22,450.93654
Overall Steps per Second: 10,724.13602

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.66443

Cumulative Model Updates: 149,768
Cumulative Timesteps: 1,248,871,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,781.78807
Policy Entropy: 3.72370
Value Function Loss: 0.01872

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12824
Policy Update Magnitude: 0.49360
Value Function Update Magnitude: 0.47896

Collected Steps per Second: 22,661.98663
Overall Steps per Second: 10,658.31896

Timestep Collection Time: 2.20634
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69117

Cumulative Model Updates: 149,774
Cumulative Timesteps: 1,248,921,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1248921848...
Checkpoint 1248921848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,605.17149
Policy Entropy: 3.73555
Value Function Loss: 0.01966

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.47612
Value Function Update Magnitude: 0.41344

Collected Steps per Second: 22,234.12745
Overall Steps per Second: 10,545.45296

Timestep Collection Time: 2.24924
Timestep Consumption Time: 2.49308
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.74233

Cumulative Model Updates: 149,780
Cumulative Timesteps: 1,248,971,858

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,569.39855
Policy Entropy: 3.75615
Value Function Loss: 0.01966

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.45691
Value Function Update Magnitude: 0.42007

Collected Steps per Second: 22,606.66052
Overall Steps per Second: 10,781.15516

Timestep Collection Time: 2.21218
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.63865

Cumulative Model Updates: 149,786
Cumulative Timesteps: 1,249,021,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1249021868...
Checkpoint 1249021868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,569.39855
Policy Entropy: 3.75864
Value Function Loss: 0.01921

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.46741
Value Function Update Magnitude: 0.41501

Collected Steps per Second: 21,944.40814
Overall Steps per Second: 10,653.38193

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.69391

Cumulative Model Updates: 149,792
Cumulative Timesteps: 1,249,071,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,074.62263
Policy Entropy: 3.73260
Value Function Loss: 0.02285

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.50656
Value Function Update Magnitude: 0.40386

Collected Steps per Second: 22,211.98906
Overall Steps per Second: 10,529.05513

Timestep Collection Time: 2.25194
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.75066

Cumulative Model Updates: 149,798
Cumulative Timesteps: 1,249,121,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1249121894...
Checkpoint 1249121894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,123.95747
Policy Entropy: 3.75092
Value Function Loss: 0.02148

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.57169
Value Function Update Magnitude: 0.47691

Collected Steps per Second: 21,771.11789
Overall Steps per Second: 10,592.11961

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.72049

Cumulative Model Updates: 149,804
Cumulative Timesteps: 1,249,171,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,962.14691
Policy Entropy: 3.74632
Value Function Loss: 0.02671

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.49658

Collected Steps per Second: 21,510.11557
Overall Steps per Second: 10,534.81334

Timestep Collection Time: 2.32514
Timestep Consumption Time: 2.42236
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.74750

Cumulative Model Updates: 149,810
Cumulative Timesteps: 1,249,221,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1249221908...
Checkpoint 1249221908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,165.52859
Policy Entropy: 3.77036
Value Function Loss: 0.02254

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12693
Policy Update Magnitude: 0.53952
Value Function Update Magnitude: 0.58206

Collected Steps per Second: 21,606.94017
Overall Steps per Second: 10,579.30826

Timestep Collection Time: 2.31555
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.72923

Cumulative Model Updates: 149,816
Cumulative Timesteps: 1,249,271,940

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,192.60990
Policy Entropy: 3.74283
Value Function Loss: 0.02655

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.59467

Collected Steps per Second: 21,910.71356
Overall Steps per Second: 10,419.54617

Timestep Collection Time: 2.28318
Timestep Consumption Time: 2.51799
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.80117

Cumulative Model Updates: 149,822
Cumulative Timesteps: 1,249,321,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1249321966...
Checkpoint 1249321966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,192.60990
Policy Entropy: 3.73202
Value Function Loss: 0.02271

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.59543
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 21,736.11412
Overall Steps per Second: 10,578.48740

Timestep Collection Time: 2.30198
Timestep Consumption Time: 2.42800
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.72998

Cumulative Model Updates: 149,828
Cumulative Timesteps: 1,249,372,002

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312,631.34914
Policy Entropy: 3.72742
Value Function Loss: 0.02402

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.59973
Value Function Update Magnitude: 0.54829

Collected Steps per Second: 22,497.79187
Overall Steps per Second: 10,663.92902

Timestep Collection Time: 2.22360
Timestep Consumption Time: 2.46755
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69114

Cumulative Model Updates: 149,834
Cumulative Timesteps: 1,249,422,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1249422028...
Checkpoint 1249422028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,470.69004
Policy Entropy: 3.75090
Value Function Loss: 0.02435

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.49604

Collected Steps per Second: 22,800.04401
Overall Steps per Second: 10,721.52465

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.47093
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.66426

Cumulative Model Updates: 149,840
Cumulative Timesteps: 1,249,472,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,569.27070
Policy Entropy: 3.77427
Value Function Loss: 0.02841

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13407
Policy Update Magnitude: 0.61611
Value Function Update Magnitude: 0.54157

Collected Steps per Second: 22,710.68265
Overall Steps per Second: 10,677.09864

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.68498

Cumulative Model Updates: 149,846
Cumulative Timesteps: 1,249,522,058

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1249522058...
Checkpoint 1249522058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.85876
Policy Entropy: 3.77255
Value Function Loss: 0.02909

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.65364
Value Function Update Magnitude: 0.57163

Collected Steps per Second: 22,559.62452
Overall Steps per Second: 10,627.32554

Timestep Collection Time: 2.21759
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.70749

Cumulative Model Updates: 149,852
Cumulative Timesteps: 1,249,572,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,609.61262
Policy Entropy: 3.77312
Value Function Loss: 0.03220

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.66428
Value Function Update Magnitude: 0.53614

Collected Steps per Second: 22,020.57340
Overall Steps per Second: 10,513.84394

Timestep Collection Time: 2.27133
Timestep Consumption Time: 2.48583
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.75716

Cumulative Model Updates: 149,858
Cumulative Timesteps: 1,249,622,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1249622102...
Checkpoint 1249622102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,836.99337
Policy Entropy: 3.77010
Value Function Loss: 0.02649

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14018
Policy Update Magnitude: 0.64588
Value Function Update Magnitude: 0.56230

Collected Steps per Second: 22,254.02414
Overall Steps per Second: 10,616.68539

Timestep Collection Time: 2.24696
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.70994

Cumulative Model Updates: 149,864
Cumulative Timesteps: 1,249,672,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,330.05525
Policy Entropy: 3.76349
Value Function Loss: 0.02955

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14311
Policy Update Magnitude: 0.64991
Value Function Update Magnitude: 0.51491

Collected Steps per Second: 22,290.72234
Overall Steps per Second: 10,509.17546

Timestep Collection Time: 2.24318
Timestep Consumption Time: 2.51476
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.75794

Cumulative Model Updates: 149,870
Cumulative Timesteps: 1,249,722,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1249722108...
Checkpoint 1249722108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,658.64834
Policy Entropy: 3.76846
Value Function Loss: 0.02234

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.65601
Value Function Update Magnitude: 0.56076

Collected Steps per Second: 22,118.59928
Overall Steps per Second: 10,561.21556

Timestep Collection Time: 2.26190
Timestep Consumption Time: 2.47525
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.73714

Cumulative Model Updates: 149,876
Cumulative Timesteps: 1,249,772,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,034.05609
Policy Entropy: 3.77867
Value Function Loss: 0.02002

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.17772
Policy Update Magnitude: 0.61597
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,622.53655
Overall Steps per Second: 10,583.17641

Timestep Collection Time: 2.21019
Timestep Consumption Time: 2.51429
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.72448

Cumulative Model Updates: 149,882
Cumulative Timesteps: 1,249,822,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1249822138...
Checkpoint 1249822138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,887.90278
Policy Entropy: 3.80975
Value Function Loss: 0.01614

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.57626
Value Function Update Magnitude: 0.65265

Collected Steps per Second: 22,544.88761
Overall Steps per Second: 10,574.14258

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.73003

Cumulative Model Updates: 149,888
Cumulative Timesteps: 1,249,872,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,055.92295
Policy Entropy: 3.79339
Value Function Loss: 0.01676

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.67782

Collected Steps per Second: 22,976.10783
Overall Steps per Second: 10,621.50183

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.53227
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.70932

Cumulative Model Updates: 149,894
Cumulative Timesteps: 1,249,922,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1249922174...
Checkpoint 1249922174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,318.18361
Policy Entropy: 3.78286
Value Function Loss: 0.01714

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.18634
Policy Update Magnitude: 0.53262
Value Function Update Magnitude: 0.65983

Collected Steps per Second: 22,207.87820
Overall Steps per Second: 10,518.95811

Timestep Collection Time: 2.25289
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.75636

Cumulative Model Updates: 149,900
Cumulative Timesteps: 1,249,972,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.04724
Policy Entropy: 3.78945
Value Function Loss: 0.01797

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.17379
Policy Update Magnitude: 0.46549
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 22,810.71965
Overall Steps per Second: 10,805.92124

Timestep Collection Time: 2.19230
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.62783

Cumulative Model Updates: 149,906
Cumulative Timesteps: 1,250,022,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1250022214...
Checkpoint 1250022214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,056.30037
Policy Entropy: 3.80313
Value Function Loss: 0.01962

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.44347
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 22,716.35228
Overall Steps per Second: 10,646.93268

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69882

Cumulative Model Updates: 149,912
Cumulative Timesteps: 1,250,072,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,130.74556
Policy Entropy: 3.78176
Value Function Loss: 0.02088

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.66776

Collected Steps per Second: 22,556.13592
Overall Steps per Second: 10,636.73547

Timestep Collection Time: 2.21678
Timestep Consumption Time: 2.48410
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.70088

Cumulative Model Updates: 149,918
Cumulative Timesteps: 1,250,122,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1250122244...
Checkpoint 1250122244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,747.95310
Policy Entropy: 3.75842
Value Function Loss: 0.02125

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.48171
Value Function Update Magnitude: 0.62476

Collected Steps per Second: 22,728.97486
Overall Steps per Second: 10,707.48347

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.67094

Cumulative Model Updates: 149,924
Cumulative Timesteps: 1,250,172,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,747.95310
Policy Entropy: 3.74587
Value Function Loss: 0.01844

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14104
Policy Update Magnitude: 0.44719
Value Function Update Magnitude: 0.49940

Collected Steps per Second: 22,027.86994
Overall Steps per Second: 10,652.06114

Timestep Collection Time: 2.27121
Timestep Consumption Time: 2.42553
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.69674

Cumulative Model Updates: 149,930
Cumulative Timesteps: 1,250,222,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1250222288...
Checkpoint 1250222288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,747.95310
Policy Entropy: 3.73533
Value Function Loss: 0.01557

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.43088
Value Function Update Magnitude: 0.42462

Collected Steps per Second: 22,072.24078
Overall Steps per Second: 10,655.72529

Timestep Collection Time: 2.26601
Timestep Consumption Time: 2.42780
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.69381

Cumulative Model Updates: 149,936
Cumulative Timesteps: 1,250,272,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,747.95310
Policy Entropy: 3.74721
Value Function Loss: 0.01402

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13902
Policy Update Magnitude: 0.46845
Value Function Update Magnitude: 0.41022

Collected Steps per Second: 22,128.34742
Overall Steps per Second: 10,494.82636

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.76578

Cumulative Model Updates: 149,942
Cumulative Timesteps: 1,250,322,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1250322320...
Checkpoint 1250322320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,394.12976
Policy Entropy: 3.76627
Value Function Loss: 0.01262

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.45774
Value Function Update Magnitude: 0.41692

Collected Steps per Second: 22,551.09435
Overall Steps per Second: 10,618.34386

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.49324
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.71185

Cumulative Model Updates: 149,948
Cumulative Timesteps: 1,250,372,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245,431.82215
Policy Entropy: 3.78318
Value Function Loss: 0.01395

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.16742
Policy Update Magnitude: 0.45858
Value Function Update Magnitude: 0.50060

Collected Steps per Second: 22,860.07718
Overall Steps per Second: 10,813.34585

Timestep Collection Time: 2.18809
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.62577

Cumulative Model Updates: 149,954
Cumulative Timesteps: 1,250,422,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1250422372...
Checkpoint 1250422372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347,175.42584
Policy Entropy: 3.78013
Value Function Loss: 0.01705

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15233
Policy Update Magnitude: 0.50067
Value Function Update Magnitude: 0.66007

Collected Steps per Second: 22,024.77485
Overall Steps per Second: 10,752.00272

Timestep Collection Time: 2.27062
Timestep Consumption Time: 2.38060
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.65123

Cumulative Model Updates: 149,960
Cumulative Timesteps: 1,250,472,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,053.02586
Policy Entropy: 3.75513
Value Function Loss: 0.01793

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.76751

Collected Steps per Second: 22,486.29574
Overall Steps per Second: 10,810.10700

Timestep Collection Time: 2.22491
Timestep Consumption Time: 2.40317
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.62808

Cumulative Model Updates: 149,966
Cumulative Timesteps: 1,250,522,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1250522412...
Checkpoint 1250522412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,180.71292
Policy Entropy: 3.74105
Value Function Loss: 0.01853

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.57401
Value Function Update Magnitude: 0.81744

Collected Steps per Second: 21,363.13525
Overall Steps per Second: 10,657.31507

Timestep Collection Time: 2.34179
Timestep Consumption Time: 2.35245
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.69424

Cumulative Model Updates: 149,972
Cumulative Timesteps: 1,250,572,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,496.50328
Policy Entropy: 3.73706
Value Function Loss: 0.01582

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.59113
Value Function Update Magnitude: 0.79937

Collected Steps per Second: 21,472.63897
Overall Steps per Second: 10,586.71450

Timestep Collection Time: 2.32985
Timestep Consumption Time: 2.39570
PPO Batch Consumption Time: 0.27546
Total Iteration Time: 4.72555

Cumulative Model Updates: 149,978
Cumulative Timesteps: 1,250,622,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1250622468...
Checkpoint 1250622468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,410.19080
Policy Entropy: 3.75243
Value Function Loss: 0.01714

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.53423
Value Function Update Magnitude: 0.77030

Collected Steps per Second: 21,967.48784
Overall Steps per Second: 10,588.78623

Timestep Collection Time: 2.27664
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.72311

Cumulative Model Updates: 149,984
Cumulative Timesteps: 1,250,672,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,071.86700
Policy Entropy: 3.76206
Value Function Loss: 0.01526

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.71072

Collected Steps per Second: 22,585.06925
Overall Steps per Second: 10,831.70451

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.40300
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.61756

Cumulative Model Updates: 149,990
Cumulative Timesteps: 1,250,722,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1250722496...
Checkpoint 1250722496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,384.88439
Policy Entropy: 3.75555
Value Function Loss: 0.01878

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.51690
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 21,660.15078
Overall Steps per Second: 10,427.05455

Timestep Collection Time: 2.30913
Timestep Consumption Time: 2.48763
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.79675

Cumulative Model Updates: 149,996
Cumulative Timesteps: 1,250,772,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,925.33662
Policy Entropy: 3.76010
Value Function Loss: 0.01688

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.67968

Collected Steps per Second: 22,537.57836
Overall Steps per Second: 10,777.92860

Timestep Collection Time: 2.22011
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.27569
Total Iteration Time: 4.64245

Cumulative Model Updates: 150,002
Cumulative Timesteps: 1,250,822,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1250822548...
Checkpoint 1250822548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.75262
Value Function Loss: 0.01688

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06833
Policy Update Magnitude: 0.65676
Value Function Update Magnitude: 0.71531

Collected Steps per Second: 22,004.36030
Overall Steps per Second: 10,658.76151

Timestep Collection Time: 2.27246
Timestep Consumption Time: 2.41889
PPO Batch Consumption Time: 0.27511
Total Iteration Time: 4.69135

Cumulative Model Updates: 150,008
Cumulative Timesteps: 1,250,872,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.76827
Value Function Loss: 0.01319

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.60834
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 23,135.97216
Overall Steps per Second: 10,864.81617

Timestep Collection Time: 2.16235
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.60459

Cumulative Model Updates: 150,014
Cumulative Timesteps: 1,250,922,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1250922580...
Checkpoint 1250922580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.76110
Value Function Loss: 0.01144

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.47774
Value Function Update Magnitude: 0.54986

Collected Steps per Second: 22,546.97440
Overall Steps per Second: 10,590.48898

Timestep Collection Time: 2.21901
Timestep Consumption Time: 2.50523
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.72424

Cumulative Model Updates: 150,020
Cumulative Timesteps: 1,250,972,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.76488
Value Function Loss: 0.01031

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07713
Policy Update Magnitude: 0.43617
Value Function Update Magnitude: 0.47683

Collected Steps per Second: 22,760.90009
Overall Steps per Second: 10,671.51623

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68649

Cumulative Model Updates: 150,026
Cumulative Timesteps: 1,251,022,624

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1251022624...
Checkpoint 1251022624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.74990
Value Function Loss: 0.01071

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05310
Policy Update Magnitude: 0.49895
Value Function Update Magnitude: 0.38115

Collected Steps per Second: 21,837.39955
Overall Steps per Second: 10,808.07467

Timestep Collection Time: 2.28974
Timestep Consumption Time: 2.33661
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62636

Cumulative Model Updates: 150,032
Cumulative Timesteps: 1,251,072,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,796.17941
Policy Entropy: 3.74140
Value Function Loss: 0.01158

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04326
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.44579

Collected Steps per Second: 22,039.41205
Overall Steps per Second: 10,666.78248

Timestep Collection Time: 2.26894
Timestep Consumption Time: 2.41908
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.68801

Cumulative Model Updates: 150,038
Cumulative Timesteps: 1,251,122,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1251122632...
Checkpoint 1251122632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,979.65297
Policy Entropy: 3.76843
Value Function Loss: 0.01175

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.53183

Collected Steps per Second: 21,607.44460
Overall Steps per Second: 10,580.04644

Timestep Collection Time: 2.31513
Timestep Consumption Time: 2.41302
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.72815

Cumulative Model Updates: 150,044
Cumulative Timesteps: 1,251,172,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,773.72811
Policy Entropy: 3.78233
Value Function Loss: 0.01289

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.62116
Value Function Update Magnitude: 0.61195

Collected Steps per Second: 21,721.83463
Overall Steps per Second: 10,476.12439

Timestep Collection Time: 2.30202
Timestep Consumption Time: 2.47112
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.77314

Cumulative Model Updates: 150,050
Cumulative Timesteps: 1,251,222,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1251222660...
Checkpoint 1251222660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,554.84760
Policy Entropy: 3.79388
Value Function Loss: 0.01454

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.60519
Value Function Update Magnitude: 0.68423

Collected Steps per Second: 21,864.63060
Overall Steps per Second: 10,568.66090

Timestep Collection Time: 2.28744
Timestep Consumption Time: 2.44485
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.73229

Cumulative Model Updates: 150,056
Cumulative Timesteps: 1,251,272,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,303.56559
Policy Entropy: 3.78732
Value Function Loss: 0.01586

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.54245
Value Function Update Magnitude: 0.72624

Collected Steps per Second: 21,967.21317
Overall Steps per Second: 10,538.17151

Timestep Collection Time: 2.27694
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.74636

Cumulative Model Updates: 150,062
Cumulative Timesteps: 1,251,322,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1251322692...
Checkpoint 1251322692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,363.77679
Policy Entropy: 3.78636
Value Function Loss: 0.01874

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.50756
Value Function Update Magnitude: 0.78439

Collected Steps per Second: 21,729.95960
Overall Steps per Second: 10,602.92197

Timestep Collection Time: 2.30125
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.27582
Total Iteration Time: 4.71625

Cumulative Model Updates: 150,068
Cumulative Timesteps: 1,251,372,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,778.76098
Policy Entropy: 3.77662
Value Function Loss: 0.01873

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.80116

Collected Steps per Second: 22,149.27597
Overall Steps per Second: 10,476.97487

Timestep Collection Time: 2.25822
Timestep Consumption Time: 2.51587
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.77409

Cumulative Model Updates: 150,074
Cumulative Timesteps: 1,251,422,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1251422716...
Checkpoint 1251422716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346,047.22228
Policy Entropy: 3.74651
Value Function Loss: 0.02252

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15335
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.72849

Collected Steps per Second: 22,346.20809
Overall Steps per Second: 10,549.60998

Timestep Collection Time: 2.23984
Timestep Consumption Time: 2.50460
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.74444

Cumulative Model Updates: 150,080
Cumulative Timesteps: 1,251,472,768

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,043.47788
Policy Entropy: 3.72624
Value Function Loss: 0.02238

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.16040
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.66839

Collected Steps per Second: 22,166.25765
Overall Steps per Second: 10,502.06209

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.50669
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.76364

Cumulative Model Updates: 150,086
Cumulative Timesteps: 1,251,522,796

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1251522796...
Checkpoint 1251522796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,507.70444
Policy Entropy: 3.74066
Value Function Loss: 0.02405

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15572
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.61497

Collected Steps per Second: 22,173.52887
Overall Steps per Second: 10,611.23505

Timestep Collection Time: 2.25602
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.71425

Cumulative Model Updates: 150,092
Cumulative Timesteps: 1,251,572,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,286.87187
Policy Entropy: 3.76557
Value Function Loss: 0.02117

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.52848
Value Function Update Magnitude: 0.51234

Collected Steps per Second: 22,444.90892
Overall Steps per Second: 10,624.60969

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.47878
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.70681

Cumulative Model Updates: 150,098
Cumulative Timesteps: 1,251,622,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1251622828...
Checkpoint 1251622828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,490.49055
Policy Entropy: 3.77280
Value Function Loss: 0.02021

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.49150
Value Function Update Magnitude: 0.54745

Collected Steps per Second: 22,054.67549
Overall Steps per Second: 10,845.99875

Timestep Collection Time: 2.26755
Timestep Consumption Time: 2.34337
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.61092

Cumulative Model Updates: 150,104
Cumulative Timesteps: 1,251,672,838

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,926.67655
Policy Entropy: 3.76535
Value Function Loss: 0.01999

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.47464
Value Function Update Magnitude: 0.51825

Collected Steps per Second: 21,956.68572
Overall Steps per Second: 10,661.84751

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.69149

Cumulative Model Updates: 150,110
Cumulative Timesteps: 1,251,722,858

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1251722858...
Checkpoint 1251722858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,057.13621
Policy Entropy: 3.75136
Value Function Loss: 0.02010

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14240
Policy Update Magnitude: 0.48051
Value Function Update Magnitude: 0.53605

Collected Steps per Second: 21,418.58483
Overall Steps per Second: 10,536.92154

Timestep Collection Time: 2.33470
Timestep Consumption Time: 2.41109
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.74579

Cumulative Model Updates: 150,116
Cumulative Timesteps: 1,251,772,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,890.99327
Policy Entropy: 3.73546
Value Function Loss: 0.02003

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.45824
Value Function Update Magnitude: 0.52375

Collected Steps per Second: 21,733.28534
Overall Steps per Second: 10,456.78821

Timestep Collection Time: 2.30145
Timestep Consumption Time: 2.48186
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.78330

Cumulative Model Updates: 150,122
Cumulative Timesteps: 1,251,822,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1251822882...
Checkpoint 1251822882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,853.01997
Policy Entropy: 3.74472
Value Function Loss: 0.01753

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14670
Policy Update Magnitude: 0.40863
Value Function Update Magnitude: 0.52887

Collected Steps per Second: 22,020.68900
Overall Steps per Second: 10,601.15667

Timestep Collection Time: 2.27141
Timestep Consumption Time: 2.44675
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.71816

Cumulative Model Updates: 150,128
Cumulative Timesteps: 1,251,872,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,440.23415
Policy Entropy: 3.73348
Value Function Loss: 0.01707

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.36999
Value Function Update Magnitude: 0.43964

Collected Steps per Second: 22,232.56543
Overall Steps per Second: 10,594.70981

Timestep Collection Time: 2.25075
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.72311

Cumulative Model Updates: 150,134
Cumulative Timesteps: 1,251,922,940

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1251922940...
Checkpoint 1251922940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,440.23415
Policy Entropy: 3.73395
Value Function Loss: 0.01671

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14356
Policy Update Magnitude: 0.34654
Value Function Update Magnitude: 0.37244

Collected Steps per Second: 22,148.28436
Overall Steps per Second: 10,529.97542

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.74854

Cumulative Model Updates: 150,140
Cumulative Timesteps: 1,251,972,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,078.39083
Policy Entropy: 3.72870
Value Function Loss: 0.01909

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14388
Policy Update Magnitude: 0.38624
Value Function Update Magnitude: 0.36805

Collected Steps per Second: 22,539.98415
Overall Steps per Second: 10,481.85292

Timestep Collection Time: 2.22005
Timestep Consumption Time: 2.55391
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.77397

Cumulative Model Updates: 150,146
Cumulative Timesteps: 1,252,022,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1252022982...
Checkpoint 1252022982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690,968.79662
Policy Entropy: 3.75005
Value Function Loss: 0.02206

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13392
Policy Update Magnitude: 0.44241
Value Function Update Magnitude: 0.43578

Collected Steps per Second: 22,112.60817
Overall Steps per Second: 10,659.57495

Timestep Collection Time: 2.26206
Timestep Consumption Time: 2.43044
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.69249

Cumulative Model Updates: 150,152
Cumulative Timesteps: 1,252,073,002

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,073.58117
Policy Entropy: 3.76652
Value Function Loss: 0.02175

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.47378
Value Function Update Magnitude: 0.49491

Collected Steps per Second: 22,783.06166
Overall Steps per Second: 10,811.94812

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.62636

Cumulative Model Updates: 150,158
Cumulative Timesteps: 1,252,123,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1252123022...
Checkpoint 1252123022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,073.58117
Policy Entropy: 3.75749
Value Function Loss: 0.02090

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13046
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.49769

Collected Steps per Second: 22,232.29226
Overall Steps per Second: 10,694.93429

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.42749
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.67773

Cumulative Model Updates: 150,164
Cumulative Timesteps: 1,252,173,050

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,073.58117
Policy Entropy: 3.74234
Value Function Loss: 0.01701

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.46176
Value Function Update Magnitude: 0.42979

Collected Steps per Second: 22,777.00642
Overall Steps per Second: 10,856.81301

Timestep Collection Time: 2.19643
Timestep Consumption Time: 2.41156
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.60798

Cumulative Model Updates: 150,170
Cumulative Timesteps: 1,252,223,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1252223078...
Checkpoint 1252223078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,073.58117
Policy Entropy: 3.73657
Value Function Loss: 0.01685

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.43905
Value Function Update Magnitude: 0.37903

Collected Steps per Second: 21,577.81508
Overall Steps per Second: 10,702.55608

Timestep Collection Time: 2.31840
Timestep Consumption Time: 2.35581
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.67421

Cumulative Model Updates: 150,176
Cumulative Timesteps: 1,252,273,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,073.58117
Policy Entropy: 3.74760
Value Function Loss: 0.01426

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14404
Policy Update Magnitude: 0.43803
Value Function Update Magnitude: 0.37049

Collected Steps per Second: 21,746.02818
Overall Steps per Second: 10,621.25352

Timestep Collection Time: 2.30037
Timestep Consumption Time: 2.40943
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.70980

Cumulative Model Updates: 150,182
Cumulative Timesteps: 1,252,323,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1252323128...
Checkpoint 1252323128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 445,348.13672
Policy Entropy: 3.73932
Value Function Loss: 0.01740

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.42922
Value Function Update Magnitude: 0.42116

Collected Steps per Second: 21,245.72651
Overall Steps per Second: 10,489.04040

Timestep Collection Time: 2.35454
Timestep Consumption Time: 2.41462
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.76917

Cumulative Model Updates: 150,188
Cumulative Timesteps: 1,252,373,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360,735.91066
Policy Entropy: 3.74264
Value Function Loss: 0.01735

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14342
Policy Update Magnitude: 0.45268
Value Function Update Magnitude: 0.45519

Collected Steps per Second: 21,654.58111
Overall Steps per Second: 10,445.36582

Timestep Collection Time: 2.30953
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.78796

Cumulative Model Updates: 150,194
Cumulative Timesteps: 1,252,423,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1252423164...
Checkpoint 1252423164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,477.98551
Policy Entropy: 3.73736
Value Function Loss: 0.01841

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.47357
Value Function Update Magnitude: 0.42120

Collected Steps per Second: 21,831.58008
Overall Steps per Second: 10,664.07982

Timestep Collection Time: 2.29072
Timestep Consumption Time: 2.39886
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.68957

Cumulative Model Updates: 150,200
Cumulative Timesteps: 1,252,473,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,469.72771
Policy Entropy: 3.73070
Value Function Loss: 0.01755

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.45975
Value Function Update Magnitude: 0.40695

Collected Steps per Second: 22,372.47564
Overall Steps per Second: 10,787.32920

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.40047
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.63562

Cumulative Model Updates: 150,206
Cumulative Timesteps: 1,252,523,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1252523180...
Checkpoint 1252523180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,969.03860
Policy Entropy: 3.73945
Value Function Loss: 0.01946

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.47203
Value Function Update Magnitude: 0.46653

Collected Steps per Second: 21,686.63104
Overall Steps per Second: 10,360.83125

Timestep Collection Time: 2.30686
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.82857

Cumulative Model Updates: 150,212
Cumulative Timesteps: 1,252,573,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,966.47959
Policy Entropy: 3.75355
Value Function Loss: 0.02179

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.50603
Value Function Update Magnitude: 0.56446

Collected Steps per Second: 22,801.33262
Overall Steps per Second: 10,794.10433

Timestep Collection Time: 2.19417
Timestep Consumption Time: 2.44077
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.63494

Cumulative Model Updates: 150,218
Cumulative Timesteps: 1,252,623,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1252623238...
Checkpoint 1252623238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,071.45865
Policy Entropy: 3.76998
Value Function Loss: 0.02342

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.52604
Value Function Update Magnitude: 0.57078

Collected Steps per Second: 22,572.39171
Overall Steps per Second: 10,690.35790

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.67936

Cumulative Model Updates: 150,224
Cumulative Timesteps: 1,252,673,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,205.33814
Policy Entropy: 3.77104
Value Function Loss: 0.02357

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.74891

Collected Steps per Second: 22,768.15960
Overall Steps per Second: 10,811.70049

Timestep Collection Time: 2.19614
Timestep Consumption Time: 2.42867
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.62480

Cumulative Model Updates: 150,230
Cumulative Timesteps: 1,252,723,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1252723264...
Checkpoint 1252723264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,982.07301
Policy Entropy: 3.78484
Value Function Loss: 0.02598

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.65126
Value Function Update Magnitude: 0.77760

Collected Steps per Second: 22,256.82417
Overall Steps per Second: 10,693.80285

Timestep Collection Time: 2.24695
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67654

Cumulative Model Updates: 150,236
Cumulative Timesteps: 1,252,773,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,660.63750
Policy Entropy: 3.77427
Value Function Loss: 0.02717

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.63184
Value Function Update Magnitude: 0.65219

Collected Steps per Second: 22,723.28408
Overall Steps per Second: 10,687.50672

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67873

Cumulative Model Updates: 150,242
Cumulative Timesteps: 1,252,823,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1252823278...
Checkpoint 1252823278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,962.26892
Policy Entropy: 3.77175
Value Function Loss: 0.02569

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.56255

Collected Steps per Second: 22,798.42246
Overall Steps per Second: 10,832.19086

Timestep Collection Time: 2.19313
Timestep Consumption Time: 2.42274
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.61587

Cumulative Model Updates: 150,248
Cumulative Timesteps: 1,252,873,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,300.74200
Policy Entropy: 3.77230
Value Function Loss: 0.02117

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.50698
Value Function Update Magnitude: 0.51854

Collected Steps per Second: 22,530.11254
Overall Steps per Second: 10,578.21798

Timestep Collection Time: 2.22049
Timestep Consumption Time: 2.50885
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72934

Cumulative Model Updates: 150,254
Cumulative Timesteps: 1,252,923,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1252923306...
Checkpoint 1252923306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,080.68000
Policy Entropy: 3.77085
Value Function Loss: 0.02065

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.53576
Value Function Update Magnitude: 0.55144

Collected Steps per Second: 22,101.88463
Overall Steps per Second: 10,612.38450

Timestep Collection Time: 2.26243
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.71185

Cumulative Model Updates: 150,260
Cumulative Timesteps: 1,252,973,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,971.42042
Policy Entropy: 3.75846
Value Function Loss: 0.02046

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.69917

Collected Steps per Second: 22,529.72134
Overall Steps per Second: 10,625.79208

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.48783
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.70854

Cumulative Model Updates: 150,266
Cumulative Timesteps: 1,253,023,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1253023342...
Checkpoint 1253023342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,971.42042
Policy Entropy: 3.74715
Value Function Loss: 0.02075

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.84954

Collected Steps per Second: 22,376.17975
Overall Steps per Second: 10,595.44198

Timestep Collection Time: 2.23523
Timestep Consumption Time: 2.48529
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.72052

Cumulative Model Updates: 150,272
Cumulative Timesteps: 1,253,073,358

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,803.50982
Policy Entropy: 3.74582
Value Function Loss: 0.01968

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.83703

Collected Steps per Second: 22,847.30431
Overall Steps per Second: 10,713.28202

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.66916

Cumulative Model Updates: 150,278
Cumulative Timesteps: 1,253,123,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1253123380...
Checkpoint 1253123380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 126,308.41522
Policy Entropy: 3.75878
Value Function Loss: 0.01982

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.51572
Value Function Update Magnitude: 0.82541

Collected Steps per Second: 22,706.96512
Overall Steps per Second: 10,647.04046

Timestep Collection Time: 2.20294
Timestep Consumption Time: 2.49527
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69821

Cumulative Model Updates: 150,284
Cumulative Timesteps: 1,253,173,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 584,369.76738
Policy Entropy: 3.76103
Value Function Loss: 0.01959

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.52339
Value Function Update Magnitude: 0.76623

Collected Steps per Second: 22,963.76196
Overall Steps per Second: 10,865.58513

Timestep Collection Time: 2.17865
Timestep Consumption Time: 2.42580
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.60445

Cumulative Model Updates: 150,290
Cumulative Timesteps: 1,253,223,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1253223432...
Checkpoint 1253223432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,330.93966
Policy Entropy: 3.77409
Value Function Loss: 0.02284

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.65779

Collected Steps per Second: 22,814.61372
Overall Steps per Second: 10,720.96898

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.66506

Cumulative Model Updates: 150,296
Cumulative Timesteps: 1,253,273,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,860.80654
Policy Entropy: 3.78100
Value Function Loss: 0.02122

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.71250

Collected Steps per Second: 23,133.81993
Overall Steps per Second: 10,878.04476

Timestep Collection Time: 2.16324
Timestep Consumption Time: 2.43722
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.60046

Cumulative Model Updates: 150,302
Cumulative Timesteps: 1,253,323,490

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1253323490...
Checkpoint 1253323490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 470,356.15295
Policy Entropy: 3.75940
Value Function Loss: 0.02191

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.81065

Collected Steps per Second: 22,582.67807
Overall Steps per Second: 10,663.32923

Timestep Collection Time: 2.21453
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.68990

Cumulative Model Updates: 150,308
Cumulative Timesteps: 1,253,373,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273,608.44981
Policy Entropy: 3.74377
Value Function Loss: 0.02200

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.53884
Value Function Update Magnitude: 0.69610

Collected Steps per Second: 21,857.39179
Overall Steps per Second: 10,497.99706

Timestep Collection Time: 2.28975
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.76739

Cumulative Model Updates: 150,314
Cumulative Timesteps: 1,253,423,548

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1253423548...
Checkpoint 1253423548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,414.15612
Policy Entropy: 3.73411
Value Function Loss: 0.02113

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.53568
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,181.97360
Overall Steps per Second: 10,704.04176

Timestep Collection Time: 2.25498
Timestep Consumption Time: 2.41802
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.67300

Cumulative Model Updates: 150,320
Cumulative Timesteps: 1,253,473,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,957.31135
Policy Entropy: 3.74241
Value Function Loss: 0.01921

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.53677
Value Function Update Magnitude: 0.52043

Collected Steps per Second: 22,374.23762
Overall Steps per Second: 10,589.73475

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.72344

Cumulative Model Updates: 150,326
Cumulative Timesteps: 1,253,523,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1253523588...
Checkpoint 1253523588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,264.91070
Policy Entropy: 3.75105
Value Function Loss: 0.02159

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.51337

Collected Steps per Second: 22,207.30052
Overall Steps per Second: 10,490.05342

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.51551
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.76756

Cumulative Model Updates: 150,332
Cumulative Timesteps: 1,253,573,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,880.24992
Policy Entropy: 3.75854
Value Function Loss: 0.02211

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.49014

Collected Steps per Second: 22,868.24807
Overall Steps per Second: 10,824.51296

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.62007

Cumulative Model Updates: 150,338
Cumulative Timesteps: 1,253,623,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1253623610...
Checkpoint 1253623610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,916.73091
Policy Entropy: 3.74627
Value Function Loss: 0.02464

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.57923
Value Function Update Magnitude: 0.46912

Collected Steps per Second: 22,511.00623
Overall Steps per Second: 10,668.83714

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.46689
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68936

Cumulative Model Updates: 150,344
Cumulative Timesteps: 1,253,673,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,916.73091
Policy Entropy: 3.74822
Value Function Loss: 0.02529

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.37269

Collected Steps per Second: 22,170.18579
Overall Steps per Second: 10,835.78629

Timestep Collection Time: 2.25564
Timestep Consumption Time: 2.35944
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.61508

Cumulative Model Updates: 150,350
Cumulative Timesteps: 1,253,723,648

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1253723648...
Checkpoint 1253723648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,252.55890
Policy Entropy: 3.73850
Value Function Loss: 0.01999

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.36877

Collected Steps per Second: 21,786.92036
Overall Steps per Second: 10,678.59005

Timestep Collection Time: 2.29578
Timestep Consumption Time: 2.38817
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.68395

Cumulative Model Updates: 150,356
Cumulative Timesteps: 1,253,773,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,663.51311
Policy Entropy: 3.74698
Value Function Loss: 0.01791

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.45372
Value Function Update Magnitude: 0.50535

Collected Steps per Second: 21,960.20271
Overall Steps per Second: 10,493.31546

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.76723

Cumulative Model Updates: 150,362
Cumulative Timesteps: 1,253,823,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1253823690...
Checkpoint 1253823690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,976.85680
Policy Entropy: 3.76554
Value Function Loss: 0.01618

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.44196
Value Function Update Magnitude: 0.54239

Collected Steps per Second: 22,456.22932
Overall Steps per Second: 10,631.32515

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.47752
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.70496

Cumulative Model Updates: 150,368
Cumulative Timesteps: 1,253,873,710

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,976.85680
Policy Entropy: 3.74522
Value Function Loss: 0.01794

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.45543
Value Function Update Magnitude: 0.45307

Collected Steps per Second: 22,061.66191
Overall Steps per Second: 10,544.22472

Timestep Collection Time: 2.26647
Timestep Consumption Time: 2.47566
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.74212

Cumulative Model Updates: 150,374
Cumulative Timesteps: 1,253,923,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1253923712...
Checkpoint 1253923712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,013.99133
Policy Entropy: 3.74565
Value Function Loss: 0.01851

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.47609
Value Function Update Magnitude: 0.46426

Collected Steps per Second: 22,212.55048
Overall Steps per Second: 10,514.65988

Timestep Collection Time: 2.25215
Timestep Consumption Time: 2.50559
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.75774

Cumulative Model Updates: 150,380
Cumulative Timesteps: 1,253,973,738

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,100.98387
Policy Entropy: 3.73326
Value Function Loss: 0.02122

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.49451
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 22,355.26965
Overall Steps per Second: 10,546.69088

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.50512
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.74253

Cumulative Model Updates: 150,386
Cumulative Timesteps: 1,254,023,756

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1254023756...
Checkpoint 1254023756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,986.01356
Policy Entropy: 3.76243
Value Function Loss: 0.02180

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.70506

Collected Steps per Second: 22,015.34383
Overall Steps per Second: 10,559.51092

Timestep Collection Time: 2.27160
Timestep Consumption Time: 2.46442
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.73601

Cumulative Model Updates: 150,392
Cumulative Timesteps: 1,254,073,766

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,140.68431
Policy Entropy: 3.76992
Value Function Loss: 0.02287

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.65414

Collected Steps per Second: 22,531.67041
Overall Steps per Second: 10,541.17733

Timestep Collection Time: 2.22052
Timestep Consumption Time: 2.52582
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.74634

Cumulative Model Updates: 150,398
Cumulative Timesteps: 1,254,123,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1254123798...
Checkpoint 1254123798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,140.68431
Policy Entropy: 3.76268
Value Function Loss: 0.02087

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.54711

Collected Steps per Second: 22,769.45391
Overall Steps per Second: 10,528.44591

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.55332
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.74942

Cumulative Model Updates: 150,404
Cumulative Timesteps: 1,254,173,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,140.68431
Policy Entropy: 3.75508
Value Function Loss: 0.01743

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.45574

Collected Steps per Second: 23,048.80991
Overall Steps per Second: 10,821.56499

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62040

Cumulative Model Updates: 150,410
Cumulative Timesteps: 1,254,223,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1254223802...
Checkpoint 1254223802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228,227.18542
Policy Entropy: 3.75543
Value Function Loss: 0.01798

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.44150
Value Function Update Magnitude: 0.39295

Collected Steps per Second: 22,420.54142
Overall Steps per Second: 10,724.88324

Timestep Collection Time: 2.23019
Timestep Consumption Time: 2.43205
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.66224

Cumulative Model Updates: 150,416
Cumulative Timesteps: 1,254,273,804

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,903.22465
Policy Entropy: 3.77534
Value Function Loss: 0.01717

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.45220
Value Function Update Magnitude: 0.43206

Collected Steps per Second: 22,940.29349
Overall Steps per Second: 10,842.46998

Timestep Collection Time: 2.17992
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.61223

Cumulative Model Updates: 150,422
Cumulative Timesteps: 1,254,323,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1254323812...
Checkpoint 1254323812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,397.16958
Policy Entropy: 3.77862
Value Function Loss: 0.01820

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.50122
Value Function Update Magnitude: 0.53354

Collected Steps per Second: 21,002.09857
Overall Steps per Second: 10,282.49878

Timestep Collection Time: 2.38148
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.86419

Cumulative Model Updates: 150,428
Cumulative Timesteps: 1,254,373,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.77623
Value Function Loss: 0.01805

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.50208
Value Function Update Magnitude: 0.51374

Collected Steps per Second: 22,394.02859
Overall Steps per Second: 10,588.51167

Timestep Collection Time: 2.23310
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.72285

Cumulative Model Updates: 150,434
Cumulative Timesteps: 1,254,423,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1254423836...
Checkpoint 1254423836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.76587
Value Function Loss: 0.01651

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.47180
Value Function Update Magnitude: 0.53382

Collected Steps per Second: 22,136.11912
Overall Steps per Second: 10,531.04774

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.49001
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.74957

Cumulative Model Updates: 150,440
Cumulative Timesteps: 1,254,473,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.74875
Value Function Loss: 0.01681

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.42870
Value Function Update Magnitude: 0.49946

Collected Steps per Second: 22,844.24400
Overall Steps per Second: 10,811.65263

Timestep Collection Time: 2.18987
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.62704

Cumulative Model Updates: 150,446
Cumulative Timesteps: 1,254,523,880

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1254523880...
Checkpoint 1254523880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.74612
Value Function Loss: 0.01492

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.41765
Value Function Update Magnitude: 0.44262

Collected Steps per Second: 21,704.92164
Overall Steps per Second: 10,678.43981

Timestep Collection Time: 2.30445
Timestep Consumption Time: 2.37956
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.68402

Cumulative Model Updates: 150,452
Cumulative Timesteps: 1,254,573,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.73913
Value Function Loss: 0.01755

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12787
Policy Update Magnitude: 0.42461
Value Function Update Magnitude: 0.39385

Collected Steps per Second: 21,995.90480
Overall Steps per Second: 10,704.14328

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.39938
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.67389

Cumulative Model Updates: 150,458
Cumulative Timesteps: 1,254,623,928

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1254623928...
Checkpoint 1254623928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,873.72017
Policy Entropy: 3.74174
Value Function Loss: 0.01862

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.45979
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 22,195.57042
Overall Steps per Second: 10,873.78479

Timestep Collection Time: 2.25342
Timestep Consumption Time: 2.34626
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.59969

Cumulative Model Updates: 150,464
Cumulative Timesteps: 1,254,673,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,860.00796
Policy Entropy: 3.74570
Value Function Loss: 0.01847

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.50417
Value Function Update Magnitude: 0.42811

Collected Steps per Second: 22,251.62711
Overall Steps per Second: 10,588.07552

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.72418

Cumulative Model Updates: 150,470
Cumulative Timesteps: 1,254,723,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1254723964...
Checkpoint 1254723964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,114.05576
Policy Entropy: 3.74551
Value Function Loss: 0.01771

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.52916
Value Function Update Magnitude: 0.61718

Collected Steps per Second: 22,472.71028
Overall Steps per Second: 10,652.56587

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.69821

Cumulative Model Updates: 150,476
Cumulative Timesteps: 1,254,774,012

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,114.05576
Policy Entropy: 3.73280
Value Function Loss: 0.01578

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.49705
Value Function Update Magnitude: 0.59667

Collected Steps per Second: 22,764.40636
Overall Steps per Second: 10,850.93582

Timestep Collection Time: 2.19808
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.27505
Total Iteration Time: 4.61140

Cumulative Model Updates: 150,482
Cumulative Timesteps: 1,254,824,050

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1254824050...
Checkpoint 1254824050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,999.08822
Policy Entropy: 3.72407
Value Function Loss: 0.02044

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.46335
Value Function Update Magnitude: 0.51156

Collected Steps per Second: 22,184.34567
Overall Steps per Second: 10,610.43962

Timestep Collection Time: 2.25510
Timestep Consumption Time: 2.45988
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.71498

Cumulative Model Updates: 150,488
Cumulative Timesteps: 1,254,874,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,179.70896
Policy Entropy: 3.73903
Value Function Loss: 0.01909

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.50644
Value Function Update Magnitude: 0.53647

Collected Steps per Second: 22,236.29506
Overall Steps per Second: 10,537.23688

Timestep Collection Time: 2.24957
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.74716

Cumulative Model Updates: 150,494
Cumulative Timesteps: 1,254,924,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1254924100...
Checkpoint 1254924100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,175.14359
Policy Entropy: 3.74917
Value Function Loss: 0.01903

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.51345
Value Function Update Magnitude: 0.58147

Collected Steps per Second: 22,285.02953
Overall Steps per Second: 10,525.32411

Timestep Collection Time: 2.24447
Timestep Consumption Time: 2.50769
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.75216

Cumulative Model Updates: 150,500
Cumulative Timesteps: 1,254,974,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,175.14359
Policy Entropy: 3.75465
Value Function Loss: 0.01554

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.45958
Value Function Update Magnitude: 0.46886

Collected Steps per Second: 22,283.70523
Overall Steps per Second: 10,546.76016

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74402

Cumulative Model Updates: 150,506
Cumulative Timesteps: 1,255,024,152

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1255024152...
Checkpoint 1255024152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,175.14359
Policy Entropy: 3.73899
Value Function Loss: 0.01705

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.45467
Value Function Update Magnitude: 0.49535

Collected Steps per Second: 22,254.83715
Overall Steps per Second: 10,563.39218

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.73617

Cumulative Model Updates: 150,512
Cumulative Timesteps: 1,255,074,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.73635
Value Function Loss: 0.01713

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13357
Policy Update Magnitude: 0.50454
Value Function Update Magnitude: 0.68226

Collected Steps per Second: 22,844.23827
Overall Steps per Second: 10,665.18506

Timestep Collection Time: 2.18979
Timestep Consumption Time: 2.50062
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.69040

Cumulative Model Updates: 150,518
Cumulative Timesteps: 1,255,124,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1255124206...
Checkpoint 1255124206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.73909
Value Function Loss: 0.01824

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.50261
Value Function Update Magnitude: 0.61166

Collected Steps per Second: 22,488.78630
Overall Steps per Second: 10,778.40716

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.41615
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.64002

Cumulative Model Updates: 150,524
Cumulative Timesteps: 1,255,174,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.73273
Value Function Loss: 0.01838

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.48706
Value Function Update Magnitude: 0.46714

Collected Steps per Second: 22,838.60648
Overall Steps per Second: 10,695.24047

Timestep Collection Time: 2.18936
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.67516

Cumulative Model Updates: 150,530
Cumulative Timesteps: 1,255,224,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1255224220...
Checkpoint 1255224220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.73548
Value Function Loss: 0.01843

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.49743
Value Function Update Magnitude: 0.45509

Collected Steps per Second: 22,614.42091
Overall Steps per Second: 10,691.48805

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.46672
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.67868

Cumulative Model Updates: 150,536
Cumulative Timesteps: 1,255,274,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.72954
Value Function Loss: 0.01839

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.43764

Collected Steps per Second: 22,055.07631
Overall Steps per Second: 10,703.19041

Timestep Collection Time: 2.26796
Timestep Consumption Time: 2.40541
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.67337

Cumulative Model Updates: 150,542
Cumulative Timesteps: 1,255,324,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1255324262...
Checkpoint 1255324262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.73219
Value Function Loss: 0.01655

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.47559
Value Function Update Magnitude: 0.35988

Collected Steps per Second: 21,843.76676
Overall Steps per Second: 10,671.13981

Timestep Collection Time: 2.28990
Timestep Consumption Time: 2.39751
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.68741

Cumulative Model Updates: 150,548
Cumulative Timesteps: 1,255,374,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,963.18050
Policy Entropy: 3.72918
Value Function Loss: 0.01500

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.41545
Value Function Update Magnitude: 0.30630

Collected Steps per Second: 21,520.89481
Overall Steps per Second: 10,449.02149

Timestep Collection Time: 2.32397
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.78648

Cumulative Model Updates: 150,554
Cumulative Timesteps: 1,255,424,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1255424296...
Checkpoint 1255424296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,359.73477
Policy Entropy: 3.73959
Value Function Loss: 0.01595

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12746
Policy Update Magnitude: 0.37555
Value Function Update Magnitude: 0.30093

Collected Steps per Second: 22,237.90407
Overall Steps per Second: 10,640.03278

Timestep Collection Time: 2.25030
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.70318

Cumulative Model Updates: 150,560
Cumulative Timesteps: 1,255,474,338

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.68700
Policy Entropy: 3.75213
Value Function Loss: 0.01730

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12807
Policy Update Magnitude: 0.42026
Value Function Update Magnitude: 0.39003

Collected Steps per Second: 22,141.24125
Overall Steps per Second: 10,593.49524

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.72044

Cumulative Model Updates: 150,566
Cumulative Timesteps: 1,255,524,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1255524344...
Checkpoint 1255524344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.68700
Policy Entropy: 3.74068
Value Function Loss: 0.01824

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.46474
Value Function Update Magnitude: 0.44266

Collected Steps per Second: 22,452.32148
Overall Steps per Second: 10,579.59578

Timestep Collection Time: 2.22739
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.72702

Cumulative Model Updates: 150,572
Cumulative Timesteps: 1,255,574,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,924.68700
Policy Entropy: 3.74848
Value Function Loss: 0.01554

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.47189
Value Function Update Magnitude: 0.49679

Collected Steps per Second: 22,280.35772
Overall Steps per Second: 10,554.40401

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.73812

Cumulative Model Updates: 150,578
Cumulative Timesteps: 1,255,624,362

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1255624362...
Checkpoint 1255624362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,230.18102
Policy Entropy: 3.72918
Value Function Loss: 0.01506

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.42325
Value Function Update Magnitude: 0.44968

Collected Steps per Second: 22,626.67626
Overall Steps per Second: 10,589.78902

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.72436

Cumulative Model Updates: 150,584
Cumulative Timesteps: 1,255,674,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 367,927.95510
Policy Entropy: 3.74155
Value Function Loss: 0.01434

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.39715
Value Function Update Magnitude: 0.47910

Collected Steps per Second: 23,303.12013
Overall Steps per Second: 10,675.07775

Timestep Collection Time: 2.14624
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.68512

Cumulative Model Updates: 150,590
Cumulative Timesteps: 1,255,724,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1255724406...
Checkpoint 1255724406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,155.39026
Policy Entropy: 3.72695
Value Function Loss: 0.01462

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13027
Policy Update Magnitude: 0.41529
Value Function Update Magnitude: 0.59775

Collected Steps per Second: 22,572.03501
Overall Steps per Second: 10,714.80307

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.66793

Cumulative Model Updates: 150,596
Cumulative Timesteps: 1,255,774,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,286.21554
Policy Entropy: 3.75444
Value Function Loss: 0.01515

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.41272
Value Function Update Magnitude: 0.66000

Collected Steps per Second: 23,206.74322
Overall Steps per Second: 10,952.43558

Timestep Collection Time: 2.15541
Timestep Consumption Time: 2.41161
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.56702

Cumulative Model Updates: 150,602
Cumulative Timesteps: 1,255,824,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1255824442...
Checkpoint 1255824442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,185.56835
Policy Entropy: 3.76714
Value Function Loss: 0.01802

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.46416
Value Function Update Magnitude: 0.77627

Collected Steps per Second: 22,019.96264
Overall Steps per Second: 10,653.85500

Timestep Collection Time: 2.27139
Timestep Consumption Time: 2.42325
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69464

Cumulative Model Updates: 150,608
Cumulative Timesteps: 1,255,874,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,600.48828
Policy Entropy: 3.77731
Value Function Loss: 0.01834

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.52033
Value Function Update Magnitude: 0.88445

Collected Steps per Second: 22,296.10557
Overall Steps per Second: 10,885.50396

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.35072
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.59326

Cumulative Model Updates: 150,614
Cumulative Timesteps: 1,255,924,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1255924458...
Checkpoint 1255924458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,236.16423
Policy Entropy: 3.77727
Value Function Loss: 0.01836

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12698
Policy Update Magnitude: 0.51872
Value Function Update Magnitude: 0.88226

Collected Steps per Second: 21,414.30063
Overall Steps per Second: 10,599.16238

Timestep Collection Time: 2.33489
Timestep Consumption Time: 2.38247
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.71735

Cumulative Model Updates: 150,620
Cumulative Timesteps: 1,255,974,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,144.93378
Policy Entropy: 3.76020
Value Function Loss: 0.01535

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13512
Policy Update Magnitude: 0.47566
Value Function Update Magnitude: 0.77837

Collected Steps per Second: 21,923.80633
Overall Steps per Second: 10,515.87140

Timestep Collection Time: 2.28072
Timestep Consumption Time: 2.47419
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.75491

Cumulative Model Updates: 150,626
Cumulative Timesteps: 1,256,024,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1256024460...
Checkpoint 1256024460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,144.93378
Policy Entropy: 3.74702
Value Function Loss: 0.01420

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.44592
Value Function Update Magnitude: 0.70460

Collected Steps per Second: 22,266.38686
Overall Steps per Second: 10,576.82357

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.72732

Cumulative Model Updates: 150,632
Cumulative Timesteps: 1,256,074,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,918.10772
Policy Entropy: 3.74150
Value Function Loss: 0.01404

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13548
Policy Update Magnitude: 0.42300
Value Function Update Magnitude: 0.64572

Collected Steps per Second: 22,300.99287
Overall Steps per Second: 10,609.25969

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.71437

Cumulative Model Updates: 150,638
Cumulative Timesteps: 1,256,124,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1256124476...
Checkpoint 1256124476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,066.66160
Policy Entropy: 3.75830
Value Function Loss: 0.01362

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.44482
Value Function Update Magnitude: 0.59534

Collected Steps per Second: 22,262.27962
Overall Steps per Second: 10,495.15841

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.51845
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.76467

Cumulative Model Updates: 150,644
Cumulative Timesteps: 1,256,174,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,038.21006
Policy Entropy: 3.76166
Value Function Loss: 0.01463

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.43260
Value Function Update Magnitude: 0.56470

Collected Steps per Second: 23,125.61121
Overall Steps per Second: 10,828.12810

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.45560
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.61779

Cumulative Model Updates: 150,650
Cumulative Timesteps: 1,256,224,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1256224484...
Checkpoint 1256224484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,283.03639
Policy Entropy: 3.76814
Value Function Loss: 0.01482

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.42375
Value Function Update Magnitude: 0.50607

Collected Steps per Second: 21,467.25171
Overall Steps per Second: 10,382.30248

Timestep Collection Time: 2.32932
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.81627

Cumulative Model Updates: 150,656
Cumulative Timesteps: 1,256,274,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,283.58458
Policy Entropy: 3.76169
Value Function Loss: 0.01617

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.46892
Value Function Update Magnitude: 0.50130

Collected Steps per Second: 22,228.93915
Overall Steps per Second: 10,679.82378

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.43425
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.68528

Cumulative Model Updates: 150,662
Cumulative Timesteps: 1,256,324,526

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1256324526...
Checkpoint 1256324526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 479,979.76266
Policy Entropy: 3.75445
Value Function Loss: 0.01745

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.51013
Value Function Update Magnitude: 0.50177

Collected Steps per Second: 21,767.98398
Overall Steps per Second: 10,446.32052

Timestep Collection Time: 2.29796
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.78848

Cumulative Model Updates: 150,668
Cumulative Timesteps: 1,256,374,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,368.15158
Policy Entropy: 3.75152
Value Function Loss: 0.01733

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.50486
Value Function Update Magnitude: 0.48488

Collected Steps per Second: 22,236.19793
Overall Steps per Second: 10,678.97422

Timestep Collection Time: 2.24993
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.68491

Cumulative Model Updates: 150,674
Cumulative Timesteps: 1,256,424,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1256424578...
Checkpoint 1256424578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,084.32307
Policy Entropy: 3.74915
Value Function Loss: 0.01814

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.46781
Value Function Update Magnitude: 0.41212

Collected Steps per Second: 22,611.76923
Overall Steps per Second: 10,704.65788

Timestep Collection Time: 2.21150
Timestep Consumption Time: 2.45992
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.67142

Cumulative Model Updates: 150,680
Cumulative Timesteps: 1,256,474,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,084.32307
Policy Entropy: 3.75414
Value Function Loss: 0.01469

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.43458
Value Function Update Magnitude: 0.43454

Collected Steps per Second: 23,057.27033
Overall Steps per Second: 10,833.35421

Timestep Collection Time: 2.16955
Timestep Consumption Time: 2.44804
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.61759

Cumulative Model Updates: 150,686
Cumulative Timesteps: 1,256,524,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1256524608...
Checkpoint 1256524608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,552.69563
Policy Entropy: 3.74080
Value Function Loss: 0.01569

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.42243
Value Function Update Magnitude: 0.45399

Collected Steps per Second: 22,502.92117
Overall Steps per Second: 10,722.80798

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.66501

Cumulative Model Updates: 150,692
Cumulative Timesteps: 1,256,574,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,585.37617
Policy Entropy: 3.74686
Value Function Loss: 0.01592

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.45233
Value Function Update Magnitude: 0.44099

Collected Steps per Second: 22,866.74626
Overall Steps per Second: 10,841.74064

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.61236

Cumulative Model Updates: 150,698
Cumulative Timesteps: 1,256,624,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1256624636...
Checkpoint 1256624636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,410.84186
Policy Entropy: 3.74839
Value Function Loss: 0.01714

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12929
Policy Update Magnitude: 0.47300
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 22,660.36347
Overall Steps per Second: 10,707.81891

Timestep Collection Time: 2.20658
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.66967

Cumulative Model Updates: 150,704
Cumulative Timesteps: 1,256,674,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,979.57489
Policy Entropy: 3.78226
Value Function Loss: 0.01631

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.51098
Value Function Update Magnitude: 0.66432

Collected Steps per Second: 22,483.85701
Overall Steps per Second: 10,594.51073

Timestep Collection Time: 2.22426
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.72037

Cumulative Model Updates: 150,710
Cumulative Timesteps: 1,256,724,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1256724648...
Checkpoint 1256724648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,897.56490
Policy Entropy: 3.77532
Value Function Loss: 0.01668

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.49773
Value Function Update Magnitude: 0.58795

Collected Steps per Second: 22,381.54638
Overall Steps per Second: 10,576.79532

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.72809

Cumulative Model Updates: 150,716
Cumulative Timesteps: 1,256,774,656

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,589.33538
Policy Entropy: 3.77615
Value Function Loss: 0.01500

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13216
Policy Update Magnitude: 0.47126
Value Function Update Magnitude: 0.51642

Collected Steps per Second: 22,273.46952
Overall Steps per Second: 10,729.76405

Timestep Collection Time: 2.24545
Timestep Consumption Time: 2.41579
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.66124

Cumulative Model Updates: 150,722
Cumulative Timesteps: 1,256,824,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1256824670...
Checkpoint 1256824670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,746.68901
Policy Entropy: 3.74550
Value Function Loss: 0.01652

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.46118
Value Function Update Magnitude: 0.51021

Collected Steps per Second: 21,883.36737
Overall Steps per Second: 10,496.28027

Timestep Collection Time: 2.28649
Timestep Consumption Time: 2.48054
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.76702

Cumulative Model Updates: 150,728
Cumulative Timesteps: 1,256,874,706

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,956.39832
Policy Entropy: 3.75776
Value Function Loss: 0.02088

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.50341

Collected Steps per Second: 22,659.82498
Overall Steps per Second: 10,675.80062

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.68780

Cumulative Model Updates: 150,734
Cumulative Timesteps: 1,256,924,752

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1256924752...
Checkpoint 1256924752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,019.37410
Policy Entropy: 3.76015
Value Function Loss: 0.02132

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.51150
Value Function Update Magnitude: 0.44369

Collected Steps per Second: 22,414.17540
Overall Steps per Second: 10,702.70602

Timestep Collection Time: 2.23109
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.67246

Cumulative Model Updates: 150,740
Cumulative Timesteps: 1,256,974,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,019.37410
Policy Entropy: 3.74706
Value Function Loss: 0.02177

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.51954
Value Function Update Magnitude: 0.46329

Collected Steps per Second: 22,992.82085
Overall Steps per Second: 10,830.68828

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.61780

Cumulative Model Updates: 150,746
Cumulative Timesteps: 1,257,024,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1257024774...
Checkpoint 1257024774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,745.44373
Policy Entropy: 3.74668
Value Function Loss: 0.01908

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.51784
Value Function Update Magnitude: 0.49219

Collected Steps per Second: 22,709.44650
Overall Steps per Second: 10,645.83906

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69930

Cumulative Model Updates: 150,752
Cumulative Timesteps: 1,257,074,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,590.73068
Policy Entropy: 3.73344
Value Function Loss: 0.01998

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13141
Policy Update Magnitude: 0.49420
Value Function Update Magnitude: 0.47628

Collected Steps per Second: 22,572.34999
Overall Steps per Second: 10,631.27064

Timestep Collection Time: 2.21625
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.70555

Cumulative Model Updates: 150,758
Cumulative Timesteps: 1,257,124,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1257124828...
Checkpoint 1257124828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,357.96601
Policy Entropy: 3.76284
Value Function Loss: 0.01837

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.47188
Value Function Update Magnitude: 0.45614

Collected Steps per Second: 22,609.11787
Overall Steps per Second: 10,674.40443

Timestep Collection Time: 2.21318
Timestep Consumption Time: 2.47448
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.68766

Cumulative Model Updates: 150,764
Cumulative Timesteps: 1,257,174,866

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,191.72057
Policy Entropy: 3.74739
Value Function Loss: 0.02056

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.47304
Value Function Update Magnitude: 0.48981

Collected Steps per Second: 22,799.14546
Overall Steps per Second: 10,751.58575

Timestep Collection Time: 2.19403
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.65252

Cumulative Model Updates: 150,770
Cumulative Timesteps: 1,257,224,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1257224888...
Checkpoint 1257224888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,876.26006
Policy Entropy: 3.75166
Value Function Loss: 0.02039

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.54460
Value Function Update Magnitude: 0.52836

Collected Steps per Second: 22,626.17894
Overall Steps per Second: 10,615.96399

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.50156
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.71271

Cumulative Model Updates: 150,776
Cumulative Timesteps: 1,257,274,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,468.84245
Policy Entropy: 3.75747
Value Function Loss: 0.02185

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.69978

Collected Steps per Second: 22,072.03514
Overall Steps per Second: 10,472.00817

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.77597

Cumulative Model Updates: 150,782
Cumulative Timesteps: 1,257,324,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1257324932...
Checkpoint 1257324932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,789.17950
Policy Entropy: 3.76664
Value Function Loss: 0.02179

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12578
Policy Update Magnitude: 0.54997
Value Function Update Magnitude: 0.66324

Collected Steps per Second: 22,189.85456
Overall Steps per Second: 10,608.76256

Timestep Collection Time: 2.25355
Timestep Consumption Time: 2.46010
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.71365

Cumulative Model Updates: 150,788
Cumulative Timesteps: 1,257,374,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904,269.03477
Policy Entropy: 3.76396
Value Function Loss: 0.02406

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.55125
Value Function Update Magnitude: 0.69024

Collected Steps per Second: 22,219.66688
Overall Steps per Second: 10,495.72597

Timestep Collection Time: 2.25062
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.76461

Cumulative Model Updates: 150,794
Cumulative Timesteps: 1,257,424,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1257424946...
Checkpoint 1257424946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,135.93179
Policy Entropy: 3.77023
Value Function Loss: 0.02383

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11887
Policy Update Magnitude: 0.59743
Value Function Update Magnitude: 0.79689

Collected Steps per Second: 22,204.10178
Overall Steps per Second: 10,620.39186

Timestep Collection Time: 2.25283
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.71000

Cumulative Model Updates: 150,800
Cumulative Timesteps: 1,257,474,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,148.78281
Policy Entropy: 3.77957
Value Function Loss: 0.02605

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.62385
Value Function Update Magnitude: 0.89108

Collected Steps per Second: 22,433.18881
Overall Steps per Second: 10,514.42334

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.52764
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.75746

Cumulative Model Updates: 150,806
Cumulative Timesteps: 1,257,524,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1257524990...
Checkpoint 1257524990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,859.30903
Policy Entropy: 3.78448
Value Function Loss: 0.02788

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.67942
Value Function Update Magnitude: 0.73817

Collected Steps per Second: 22,496.47739
Overall Steps per Second: 10,559.24915

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.51302
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.73594

Cumulative Model Updates: 150,812
Cumulative Timesteps: 1,257,574,998

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,464.65728
Policy Entropy: 3.79202
Value Function Loss: 0.02672

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.64687
Value Function Update Magnitude: 0.74186

Collected Steps per Second: 21,798.69463
Overall Steps per Second: 10,486.80684

Timestep Collection Time: 2.29555
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.77171

Cumulative Model Updates: 150,818
Cumulative Timesteps: 1,257,625,038

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1257625038...
Checkpoint 1257625038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.39292
Policy Entropy: 3.78056
Value Function Loss: 0.02569

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.61267
Value Function Update Magnitude: 0.68297

Collected Steps per Second: 22,121.79738
Overall Steps per Second: 10,648.73215

Timestep Collection Time: 2.26049
Timestep Consumption Time: 2.43547
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.69596

Cumulative Model Updates: 150,824
Cumulative Timesteps: 1,257,675,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,093.25565
Policy Entropy: 3.77655
Value Function Loss: 0.02174

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.70301

Collected Steps per Second: 22,632.57052
Overall Steps per Second: 10,798.57237

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.42113
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63043

Cumulative Model Updates: 150,830
Cumulative Timesteps: 1,257,725,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1257725046...
Checkpoint 1257725046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,684.13766
Policy Entropy: 3.74870
Value Function Loss: 0.02248

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.64282

Collected Steps per Second: 21,564.99444
Overall Steps per Second: 10,675.31201

Timestep Collection Time: 2.31867
Timestep Consumption Time: 2.36523
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.68389

Cumulative Model Updates: 150,836
Cumulative Timesteps: 1,257,775,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,076.58038
Policy Entropy: 3.75693
Value Function Loss: 0.02072

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.50573
Value Function Update Magnitude: 0.60139

Collected Steps per Second: 21,930.43214
Overall Steps per Second: 10,648.73976

Timestep Collection Time: 2.28112
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.69783

Cumulative Model Updates: 150,842
Cumulative Timesteps: 1,257,825,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1257825074...
Checkpoint 1257825074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,027.40907
Policy Entropy: 3.76521
Value Function Loss: 0.02372

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.47454
Value Function Update Magnitude: 0.52266

Collected Steps per Second: 21,441.08590
Overall Steps per Second: 10,524.10369

Timestep Collection Time: 2.33216
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.75138

Cumulative Model Updates: 150,848
Cumulative Timesteps: 1,257,875,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,917.86545
Policy Entropy: 3.78628
Value Function Loss: 0.02303

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.50504
Value Function Update Magnitude: 0.48096

Collected Steps per Second: 21,543.04063
Overall Steps per Second: 10,565.27874

Timestep Collection Time: 2.32233
Timestep Consumption Time: 2.41299
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.73532

Cumulative Model Updates: 150,854
Cumulative Timesteps: 1,257,925,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1257925108...
Checkpoint 1257925108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,908.64872
Policy Entropy: 3.79095
Value Function Loss: 0.02492

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13597
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.62858

Collected Steps per Second: 21,501.64322
Overall Steps per Second: 10,496.96795

Timestep Collection Time: 2.32559
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.76366

Cumulative Model Updates: 150,860
Cumulative Timesteps: 1,257,975,112

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,397.57076
Policy Entropy: 3.78604
Value Function Loss: 0.02517

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.54134
Value Function Update Magnitude: 0.65756

Collected Steps per Second: 22,053.57716
Overall Steps per Second: 10,526.90868

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.75277

Cumulative Model Updates: 150,866
Cumulative Timesteps: 1,258,025,144

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1258025144...
Checkpoint 1258025144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,505.14209
Policy Entropy: 3.76624
Value Function Loss: 0.02561

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.65367

Collected Steps per Second: 22,547.80147
Overall Steps per Second: 10,558.14689

Timestep Collection Time: 2.21778
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.73625

Cumulative Model Updates: 150,872
Cumulative Timesteps: 1,258,075,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,901.39822
Policy Entropy: 3.75617
Value Function Loss: 0.02334

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13596
Policy Update Magnitude: 0.57016
Value Function Update Magnitude: 0.71907

Collected Steps per Second: 22,681.77824
Overall Steps per Second: 10,656.99387

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.69175

Cumulative Model Updates: 150,878
Cumulative Timesteps: 1,258,125,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1258125150...
Checkpoint 1258125150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,733.74720
Policy Entropy: 3.76696
Value Function Loss: 0.02305

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.71027

Collected Steps per Second: 21,515.46926
Overall Steps per Second: 10,472.74324

Timestep Collection Time: 2.32549
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.77754

Cumulative Model Updates: 150,884
Cumulative Timesteps: 1,258,175,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,502.19541
Policy Entropy: 3.77692
Value Function Loss: 0.02143

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.50239
Value Function Update Magnitude: 0.56585

Collected Steps per Second: 22,632.96767
Overall Steps per Second: 10,657.43642

Timestep Collection Time: 2.20934
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.69194

Cumulative Model Updates: 150,890
Cumulative Timesteps: 1,258,225,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1258225188...
Checkpoint 1258225188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,693.87892
Policy Entropy: 3.77979
Value Function Loss: 0.02108

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.52010
Value Function Update Magnitude: 0.50513

Collected Steps per Second: 22,403.74700
Overall Steps per Second: 10,635.07354

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.70293

Cumulative Model Updates: 150,896
Cumulative Timesteps: 1,258,275,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,693.87892
Policy Entropy: 3.76178
Value Function Loss: 0.01861

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.53309

Collected Steps per Second: 22,770.91540
Overall Steps per Second: 10,701.23787

Timestep Collection Time: 2.19666
Timestep Consumption Time: 2.47756
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.67423

Cumulative Model Updates: 150,902
Cumulative Timesteps: 1,258,325,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1258325224...
Checkpoint 1258325224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,166.59526
Policy Entropy: 3.74326
Value Function Loss: 0.02174

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.53489
Value Function Update Magnitude: 0.47345

Collected Steps per Second: 22,474.78502
Overall Steps per Second: 10,651.76206

Timestep Collection Time: 2.22694
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.69875

Cumulative Model Updates: 150,908
Cumulative Timesteps: 1,258,375,274

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,045.85010
Policy Entropy: 3.74063
Value Function Loss: 0.02166

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.46231

Collected Steps per Second: 22,158.65935
Overall Steps per Second: 10,523.87653

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.49584
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.75338

Cumulative Model Updates: 150,914
Cumulative Timesteps: 1,258,425,298

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1258425298...
Checkpoint 1258425298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,305.83133
Policy Entropy: 3.75687
Value Function Loss: 0.03047

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.56763
Value Function Update Magnitude: 0.47139

Collected Steps per Second: 21,901.22777
Overall Steps per Second: 10,601.67920

Timestep Collection Time: 2.28426
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.71888

Cumulative Model Updates: 150,920
Cumulative Timesteps: 1,258,475,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,717.95518
Policy Entropy: 3.78821
Value Function Loss: 0.03052

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13023
Policy Update Magnitude: 0.60507
Value Function Update Magnitude: 0.54998

Collected Steps per Second: 22,409.30283
Overall Steps per Second: 10,653.17151

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.46380
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.69644

Cumulative Model Updates: 150,926
Cumulative Timesteps: 1,258,525,358

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1258525358...
Checkpoint 1258525358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.42359
Policy Entropy: 3.77285
Value Function Loss: 0.03206

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.57336

Collected Steps per Second: 21,395.06408
Overall Steps per Second: 10,524.08345

Timestep Collection Time: 2.33802
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.75310

Cumulative Model Updates: 150,932
Cumulative Timesteps: 1,258,575,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,294.42359
Policy Entropy: 3.76655
Value Function Loss: 0.02385

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.49958

Collected Steps per Second: 21,561.69880
Overall Steps per Second: 10,720.41465

Timestep Collection Time: 2.32032
Timestep Consumption Time: 2.34648
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.66680

Cumulative Model Updates: 150,938
Cumulative Timesteps: 1,258,625,410

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1258625410...
Checkpoint 1258625410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333,873.62037
Policy Entropy: 3.74251
Value Function Loss: 0.02245

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.50033
Value Function Update Magnitude: 0.43047

Collected Steps per Second: 21,701.89286
Overall Steps per Second: 10,449.88517

Timestep Collection Time: 2.30459
Timestep Consumption Time: 2.48149
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.78608

Cumulative Model Updates: 150,944
Cumulative Timesteps: 1,258,675,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,691.98616
Policy Entropy: 3.75793
Value Function Loss: 0.02039

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.49595
Value Function Update Magnitude: 0.50305

Collected Steps per Second: 22,614.75905
Overall Steps per Second: 10,743.70892

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.44343
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.65482

Cumulative Model Updates: 150,950
Cumulative Timesteps: 1,258,725,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1258725434...
Checkpoint 1258725434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,526.17232
Policy Entropy: 3.75968
Value Function Loss: 0.02205

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.52855
Value Function Update Magnitude: 0.63112

Collected Steps per Second: 22,375.67270
Overall Steps per Second: 10,598.66233

Timestep Collection Time: 2.23555
Timestep Consumption Time: 2.48410
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.71965

Cumulative Model Updates: 150,956
Cumulative Timesteps: 1,258,775,456

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 201,148.82758
Policy Entropy: 3.75156
Value Function Loss: 0.02091

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.54491
Value Function Update Magnitude: 0.68545

Collected Steps per Second: 22,696.00080
Overall Steps per Second: 10,842.70214

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.61232

Cumulative Model Updates: 150,962
Cumulative Timesteps: 1,258,825,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1258825466...
Checkpoint 1258825466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,148.82758
Policy Entropy: 3.75405
Value Function Loss: 0.01949

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14080
Policy Update Magnitude: 0.51286
Value Function Update Magnitude: 0.69967

Collected Steps per Second: 22,673.80804
Overall Steps per Second: 10,773.55244

Timestep Collection Time: 2.20536
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.64137

Cumulative Model Updates: 150,968
Cumulative Timesteps: 1,258,875,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,496.19893
Policy Entropy: 3.74412
Value Function Loss: 0.01717

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14026
Policy Update Magnitude: 0.47270
Value Function Update Magnitude: 0.61805

Collected Steps per Second: 22,680.35777
Overall Steps per Second: 10,793.01306

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.42895
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.63429

Cumulative Model Updates: 150,974
Cumulative Timesteps: 1,258,925,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1258925488...
Checkpoint 1258925488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,476.51802
Policy Entropy: 3.75978
Value Function Loss: 0.01853

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.44942
Value Function Update Magnitude: 0.55932

Collected Steps per Second: 22,313.45884
Overall Steps per Second: 10,716.61948

Timestep Collection Time: 2.24286
Timestep Consumption Time: 2.42708
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.66994

Cumulative Model Updates: 150,980
Cumulative Timesteps: 1,258,975,534

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,549.84692
Policy Entropy: 3.77087
Value Function Loss: 0.01979

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.52631
Value Function Update Magnitude: 0.45866

Collected Steps per Second: 22,141.97142
Overall Steps per Second: 10,517.82961

Timestep Collection Time: 2.25870
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.75497

Cumulative Model Updates: 150,986
Cumulative Timesteps: 1,259,025,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1259025546...
Checkpoint 1259025546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,774.14994
Policy Entropy: 3.78120
Value Function Loss: 0.02063

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.39833

Collected Steps per Second: 22,046.34059
Overall Steps per Second: 10,621.13603

Timestep Collection Time: 2.26904
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.70985

Cumulative Model Updates: 150,992
Cumulative Timesteps: 1,259,075,570

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,750.50515
Policy Entropy: 3.78805
Value Function Loss: 0.02311

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.40911

Collected Steps per Second: 21,908.09240
Overall Steps per Second: 10,422.81012

Timestep Collection Time: 2.28409
Timestep Consumption Time: 2.51692
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.80101

Cumulative Model Updates: 150,998
Cumulative Timesteps: 1,259,125,610

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1259125610...
Checkpoint 1259125610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,649.89974
Policy Entropy: 3.79862
Value Function Loss: 0.02442

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.46673

Collected Steps per Second: 21,861.25490
Overall Steps per Second: 10,569.44267

Timestep Collection Time: 2.28788
Timestep Consumption Time: 2.44425
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.73213

Cumulative Model Updates: 151,004
Cumulative Timesteps: 1,259,175,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.23656
Policy Entropy: 3.80899
Value Function Loss: 0.02519

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.60043
Value Function Update Magnitude: 0.43174

Collected Steps per Second: 22,672.01602
Overall Steps per Second: 10,620.14809

Timestep Collection Time: 2.20545
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.70822

Cumulative Model Updates: 151,010
Cumulative Timesteps: 1,259,225,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1259225628...
Checkpoint 1259225628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,900.62975
Policy Entropy: 3.82223
Value Function Loss: 0.02418

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.63482
Value Function Update Magnitude: 0.44436

Collected Steps per Second: 22,429.70609
Overall Steps per Second: 10,560.22556

Timestep Collection Time: 2.23052
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.73759

Cumulative Model Updates: 151,016
Cumulative Timesteps: 1,259,275,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,353.37558
Policy Entropy: 3.81283
Value Function Loss: 0.02352

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.68267
Value Function Update Magnitude: 0.52507

Collected Steps per Second: 22,772.86514
Overall Steps per Second: 10,812.08889

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.62686

Cumulative Model Updates: 151,022
Cumulative Timesteps: 1,259,325,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1259325684...
Checkpoint 1259325684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,353.37558
Policy Entropy: 3.79668
Value Function Loss: 0.01875

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.72465
Value Function Update Magnitude: 0.51260

Collected Steps per Second: 22,556.74557
Overall Steps per Second: 10,756.11882

Timestep Collection Time: 2.21796
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.65131

Cumulative Model Updates: 151,028
Cumulative Timesteps: 1,259,375,714

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,282.62569
Policy Entropy: 3.79497
Value Function Loss: 0.01532

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07487
Policy Update Magnitude: 0.67514
Value Function Update Magnitude: 0.48336

Collected Steps per Second: 22,483.11632
Overall Steps per Second: 10,655.63095

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69573

Cumulative Model Updates: 151,034
Cumulative Timesteps: 1,259,425,750

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1259425750...
Checkpoint 1259425750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,349.83476
Policy Entropy: 3.79634
Value Function Loss: 0.01432

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.65382
Value Function Update Magnitude: 0.50070

Collected Steps per Second: 21,532.81617
Overall Steps per Second: 10,565.18724

Timestep Collection Time: 2.32250
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.73347

Cumulative Model Updates: 151,040
Cumulative Timesteps: 1,259,475,760

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,791.88220
Policy Entropy: 3.79992
Value Function Loss: 0.01403

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.65008
Value Function Update Magnitude: 0.53840

Collected Steps per Second: 21,824.97389
Overall Steps per Second: 10,768.75740

Timestep Collection Time: 2.29123
Timestep Consumption Time: 2.35239
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.64362

Cumulative Model Updates: 151,046
Cumulative Timesteps: 1,259,525,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1259525766...
Checkpoint 1259525766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,325.61353
Policy Entropy: 3.80012
Value Function Loss: 0.01282

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.58929
Value Function Update Magnitude: 0.56687

Collected Steps per Second: 21,630.34651
Overall Steps per Second: 10,590.53113

Timestep Collection Time: 2.31286
Timestep Consumption Time: 2.41098
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.72384

Cumulative Model Updates: 151,052
Cumulative Timesteps: 1,259,575,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,169.59934
Policy Entropy: 3.76545
Value Function Loss: 0.01148

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08631
Policy Update Magnitude: 0.55145
Value Function Update Magnitude: 0.49984

Collected Steps per Second: 22,098.14926
Overall Steps per Second: 10,566.33530

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.47086
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.73485

Cumulative Model Updates: 151,058
Cumulative Timesteps: 1,259,625,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1259625824...
Checkpoint 1259625824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,000.52629
Policy Entropy: 3.77243
Value Function Loss: 0.01036

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08381
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.44018

Collected Steps per Second: 22,431.63636
Overall Steps per Second: 10,650.94430

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.46730
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69799

Cumulative Model Updates: 151,064
Cumulative Timesteps: 1,259,675,862

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,674.48991
Policy Entropy: 3.75244
Value Function Loss: 0.01134

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.47357
Value Function Update Magnitude: 0.49416

Collected Steps per Second: 22,903.06563
Overall Steps per Second: 10,769.61817

Timestep Collection Time: 2.18503
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.64678

Cumulative Model Updates: 151,070
Cumulative Timesteps: 1,259,725,906

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1259725906...
Checkpoint 1259725906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,256.24807
Policy Entropy: 3.77970
Value Function Loss: 0.01141

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07552
Policy Update Magnitude: 0.44641
Value Function Update Magnitude: 0.56528

Collected Steps per Second: 22,749.48123
Overall Steps per Second: 10,683.17576

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.68138

Cumulative Model Updates: 151,076
Cumulative Timesteps: 1,259,775,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,415.33759
Policy Entropy: 3.75650
Value Function Loss: 0.01343

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.52707
Value Function Update Magnitude: 0.57818

Collected Steps per Second: 22,656.34783
Overall Steps per Second: 10,626.09681

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.70634

Cumulative Model Updates: 151,082
Cumulative Timesteps: 1,259,825,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1259825928...
Checkpoint 1259825928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,880.69923
Policy Entropy: 3.72802
Value Function Loss: 0.02369

Mean KL Divergence: 0.02343
SB3 Clip Fraction: 0.23629
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.51600

Collected Steps per Second: 22,516.79229
Overall Steps per Second: 10,623.01871

Timestep Collection Time: 2.22190
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70958

Cumulative Model Updates: 151,088
Cumulative Timesteps: 1,259,875,958

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 436,430.46182
Policy Entropy: 3.75773
Value Function Loss: 0.03652

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.18913
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.48518

Collected Steps per Second: 22,772.89744
Overall Steps per Second: 10,810.71895

Timestep Collection Time: 2.19568
Timestep Consumption Time: 2.42954
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.62522

Cumulative Model Updates: 151,094
Cumulative Timesteps: 1,259,925,960

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1259925960...
Checkpoint 1259925960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,043.67480
Policy Entropy: 3.74765
Value Function Loss: 0.04028

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.83114
Value Function Update Magnitude: 0.47949

Collected Steps per Second: 22,726.48291
Overall Steps per Second: 10,621.18407

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.71021

Cumulative Model Updates: 151,100
Cumulative Timesteps: 1,259,975,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,410.79776
Policy Entropy: 3.72423
Value Function Loss: 0.03779

Mean KL Divergence: 0.01768
SB3 Clip Fraction: 0.20270
Policy Update Magnitude: 0.82183
Value Function Update Magnitude: 0.48679

Collected Steps per Second: 22,108.84760
Overall Steps per Second: 10,477.21649

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.77398

Cumulative Model Updates: 151,106
Cumulative Timesteps: 1,260,026,006

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1260026006...
Checkpoint 1260026006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,618.13031
Policy Entropy: 3.74453
Value Function Loss: 0.02708

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.17160
Policy Update Magnitude: 0.74875
Value Function Update Magnitude: 0.59296

Collected Steps per Second: 20,384.75647
Overall Steps per Second: 10,183.32344

Timestep Collection Time: 2.45350
Timestep Consumption Time: 2.45786
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.91136

Cumulative Model Updates: 151,112
Cumulative Timesteps: 1,260,076,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 500,243.49743
Policy Entropy: 3.73715
Value Function Loss: 0.03186

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.15905
Policy Update Magnitude: 0.80404
Value Function Update Magnitude: 0.56568

Collected Steps per Second: 22,051.84834
Overall Steps per Second: 10,470.55004

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.50862
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.77664

Cumulative Model Updates: 151,118
Cumulative Timesteps: 1,260,126,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1260126034...
Checkpoint 1260126034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,614.50938
Policy Entropy: 3.79196
Value Function Loss: 0.02788

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16446
Policy Update Magnitude: 0.77428
Value Function Update Magnitude: 0.46221

Collected Steps per Second: 22,142.54968
Overall Steps per Second: 10,697.78251

Timestep Collection Time: 2.25972
Timestep Consumption Time: 2.41751
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.67723

Cumulative Model Updates: 151,124
Cumulative Timesteps: 1,260,176,070

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,610.22629
Policy Entropy: 3.77426
Value Function Loss: 0.03534

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.71672
Value Function Update Magnitude: 0.50280

Collected Steps per Second: 22,146.78345
Overall Steps per Second: 10,518.67334

Timestep Collection Time: 2.25775
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.75364

Cumulative Model Updates: 151,130
Cumulative Timesteps: 1,260,226,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260226072...
Checkpoint 1260226072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,861.11122
Policy Entropy: 3.77363
Value Function Loss: 0.03648

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.76185
Value Function Update Magnitude: 0.62675

Collected Steps per Second: 22,229.63032
Overall Steps per Second: 10,528.00940

Timestep Collection Time: 2.24979
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75038

Cumulative Model Updates: 151,136
Cumulative Timesteps: 1,260,276,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,086.68148
Policy Entropy: 3.77874
Value Function Loss: 0.03742

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.81633
Value Function Update Magnitude: 0.66347

Collected Steps per Second: 22,632.81237
Overall Steps per Second: 10,536.82830

Timestep Collection Time: 2.21033
Timestep Consumption Time: 2.53740
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.74773

Cumulative Model Updates: 151,142
Cumulative Timesteps: 1,260,326,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1260326110...
Checkpoint 1260326110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.71608
Policy Entropy: 3.79507
Value Function Loss: 0.03053

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07431
Policy Update Magnitude: 0.84089
Value Function Update Magnitude: 0.63421

Collected Steps per Second: 22,597.83251
Overall Steps per Second: 10,623.09797

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.49452
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.70748

Cumulative Model Updates: 151,148
Cumulative Timesteps: 1,260,376,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.71608
Policy Entropy: 3.79155
Value Function Loss: 0.02086

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07502
Policy Update Magnitude: 0.75574
Value Function Update Magnitude: 0.58224

Collected Steps per Second: 21,711.52015
Overall Steps per Second: 10,768.73920

Timestep Collection Time: 2.30302
Timestep Consumption Time: 2.34024
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.64325

Cumulative Model Updates: 151,154
Cumulative Timesteps: 1,260,426,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260426120...
Checkpoint 1260426120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214.71608
Policy Entropy: 3.75594
Value Function Loss: 0.01748

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.64730
Value Function Update Magnitude: 0.45034

Collected Steps per Second: 21,665.87247
Overall Steps per Second: 10,751.55244

Timestep Collection Time: 2.30778
Timestep Consumption Time: 2.34271
PPO Batch Consumption Time: 0.27617
Total Iteration Time: 4.65049

Cumulative Model Updates: 151,160
Cumulative Timesteps: 1,260,476,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214.71608
Policy Entropy: 3.75296
Value Function Loss: 0.01433

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06435
Policy Update Magnitude: 0.57419
Value Function Update Magnitude: 0.33567

Collected Steps per Second: 21,969.75922
Overall Steps per Second: 10,805.58967

Timestep Collection Time: 2.27713
Timestep Consumption Time: 2.35270
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.62983

Cumulative Model Updates: 151,166
Cumulative Timesteps: 1,260,526,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1260526148...
Checkpoint 1260526148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,377.62608
Policy Entropy: 3.76665
Value Function Loss: 0.01640

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.51880
Value Function Update Magnitude: 0.33286

Collected Steps per Second: 21,952.74147
Overall Steps per Second: 10,658.43542

Timestep Collection Time: 2.27835
Timestep Consumption Time: 2.41427
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.69262

Cumulative Model Updates: 151,172
Cumulative Timesteps: 1,260,576,164

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,987.43702
Policy Entropy: 3.76368
Value Function Loss: 0.01881

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.19733
Policy Update Magnitude: 0.46307
Value Function Update Magnitude: 0.41505

Collected Steps per Second: 22,037.40692
Overall Steps per Second: 10,519.39469

Timestep Collection Time: 2.26923
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.75389

Cumulative Model Updates: 151,178
Cumulative Timesteps: 1,260,626,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1260626172...
Checkpoint 1260626172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,703.09808
Policy Entropy: 3.77956
Value Function Loss: 0.02063

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.22594
Policy Update Magnitude: 0.46801
Value Function Update Magnitude: 0.48570

Collected Steps per Second: 22,112.03333
Overall Steps per Second: 10,619.64553

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.71089

Cumulative Model Updates: 151,184
Cumulative Timesteps: 1,260,676,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,842.29366
Policy Entropy: 3.76823
Value Function Loss: 0.01901

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.19299
Policy Update Magnitude: 0.44824
Value Function Update Magnitude: 0.51144

Collected Steps per Second: 22,053.85654
Overall Steps per Second: 10,449.91603

Timestep Collection Time: 2.26836
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.78722

Cumulative Model Updates: 151,190
Cumulative Timesteps: 1,260,726,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1260726226...
Checkpoint 1260726226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,700.26481
Policy Entropy: 3.77009
Value Function Loss: 0.01846

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16242
Policy Update Magnitude: 0.42101
Value Function Update Magnitude: 0.45372

Collected Steps per Second: 21,836.62360
Overall Steps per Second: 10,582.14962

Timestep Collection Time: 2.29037
Timestep Consumption Time: 2.43589
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.72626

Cumulative Model Updates: 151,196
Cumulative Timesteps: 1,260,776,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,700.26481
Policy Entropy: 3.75842
Value Function Loss: 0.01941

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14278
Policy Update Magnitude: 0.40159
Value Function Update Magnitude: 0.36794

Collected Steps per Second: 22,133.20113
Overall Steps per Second: 10,593.75427

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.27569
Total Iteration Time: 4.71995

Cumulative Model Updates: 151,202
Cumulative Timesteps: 1,260,826,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1260826242...
Checkpoint 1260826242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,700.26481
Policy Entropy: 3.75425
Value Function Loss: 0.02043

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14188
Policy Update Magnitude: 0.41728
Value Function Update Magnitude: 0.31819

Collected Steps per Second: 22,674.32999
Overall Steps per Second: 10,603.36850

Timestep Collection Time: 2.20637
Timestep Consumption Time: 2.51175
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.71812

Cumulative Model Updates: 151,208
Cumulative Timesteps: 1,260,876,270

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784,191.82925
Policy Entropy: 3.75810
Value Function Loss: 0.02063

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14031
Policy Update Magnitude: 0.43649
Value Function Update Magnitude: 0.34506

Collected Steps per Second: 22,677.97569
Overall Steps per Second: 10,772.84859

Timestep Collection Time: 2.20505
Timestep Consumption Time: 2.43681
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.64185

Cumulative Model Updates: 151,214
Cumulative Timesteps: 1,260,926,276

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1260926276...
Checkpoint 1260926276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,199.73624
Policy Entropy: 3.74290
Value Function Loss: 0.02358

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.45349
Value Function Update Magnitude: 0.33599

Collected Steps per Second: 22,533.27861
Overall Steps per Second: 10,789.08474

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.41537
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.63431

Cumulative Model Updates: 151,220
Cumulative Timesteps: 1,260,976,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,983.09461
Policy Entropy: 3.75830
Value Function Loss: 0.02174

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13455
Policy Update Magnitude: 0.46069
Value Function Update Magnitude: 0.41832

Collected Steps per Second: 22,725.25384
Overall Steps per Second: 10,797.94653

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.63181

Cumulative Model Updates: 151,226
Cumulative Timesteps: 1,261,026,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1261026290...
Checkpoint 1261026290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,990.81573
Policy Entropy: 3.74565
Value Function Loss: 0.02131

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.44770
Value Function Update Magnitude: 0.42998

Collected Steps per Second: 22,814.33876
Overall Steps per Second: 10,676.51743

Timestep Collection Time: 2.19178
Timestep Consumption Time: 2.49177
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.68355

Cumulative Model Updates: 151,232
Cumulative Timesteps: 1,261,076,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,990.81573
Policy Entropy: 3.74955
Value Function Loss: 0.01690

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.43068
Value Function Update Magnitude: 0.41635

Collected Steps per Second: 22,371.71084
Overall Steps per Second: 10,543.12168

Timestep Collection Time: 2.23595
Timestep Consumption Time: 2.50857
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.74452

Cumulative Model Updates: 151,238
Cumulative Timesteps: 1,261,126,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1261126316...
Checkpoint 1261126316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290,230.13740
Policy Entropy: 3.73736
Value Function Loss: 0.01790

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.43819
Value Function Update Magnitude: 0.41086

Collected Steps per Second: 22,090.06495
Overall Steps per Second: 10,560.85371

Timestep Collection Time: 2.26446
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.73655

Cumulative Model Updates: 151,244
Cumulative Timesteps: 1,261,176,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,718.83627
Policy Entropy: 3.75532
Value Function Loss: 0.01600

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.45020
Value Function Update Magnitude: 0.48789

Collected Steps per Second: 22,197.26383
Overall Steps per Second: 10,559.03770

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.48454
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.73869

Cumulative Model Updates: 151,250
Cumulative Timesteps: 1,261,226,374

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1261226374...
Checkpoint 1261226374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,797.53692
Policy Entropy: 3.75485
Value Function Loss: 0.01762

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.44310
Value Function Update Magnitude: 0.48557

Collected Steps per Second: 22,254.43189
Overall Steps per Second: 10,552.04525

Timestep Collection Time: 2.24701
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.73899

Cumulative Model Updates: 151,256
Cumulative Timesteps: 1,261,276,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,112.41554
Policy Entropy: 3.77439
Value Function Loss: 0.01649

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.42885
Value Function Update Magnitude: 0.45192

Collected Steps per Second: 22,595.22841
Overall Steps per Second: 10,586.58089

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.51020
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.72315

Cumulative Model Updates: 151,262
Cumulative Timesteps: 1,261,326,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1261326382...
Checkpoint 1261326382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,443.37234
Policy Entropy: 3.75561
Value Function Loss: 0.01690

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.42400
Value Function Update Magnitude: 0.43295

Collected Steps per Second: 22,626.18575
Overall Steps per Second: 10,594.65351

Timestep Collection Time: 2.21160
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72314

Cumulative Model Updates: 151,268
Cumulative Timesteps: 1,261,376,422

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,212.16467
Policy Entropy: 3.75544
Value Function Loss: 0.01653

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.42957
Value Function Update Magnitude: 0.43102

Collected Steps per Second: 22,650.92551
Overall Steps per Second: 10,768.45241

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.64431

Cumulative Model Updates: 151,274
Cumulative Timesteps: 1,261,426,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1261426434...
Checkpoint 1261426434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,708.94816
Policy Entropy: 3.75348
Value Function Loss: 0.01836

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.45849
Value Function Update Magnitude: 0.45503

Collected Steps per Second: 21,906.15240
Overall Steps per Second: 10,687.01843

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.39659
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.67951

Cumulative Model Updates: 151,280
Cumulative Timesteps: 1,261,476,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,110.17143
Policy Entropy: 3.76766
Value Function Loss: 0.01936

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.48131
Value Function Update Magnitude: 0.45610

Collected Steps per Second: 21,968.61416
Overall Steps per Second: 10,803.23668

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.35264
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62898

Cumulative Model Updates: 151,286
Cumulative Timesteps: 1,261,526,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1261526452...
Checkpoint 1261526452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,848.87232
Policy Entropy: 3.77457
Value Function Loss: 0.01922

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.46902
Value Function Update Magnitude: 0.42841

Collected Steps per Second: 21,791.66552
Overall Steps per Second: 10,777.71512

Timestep Collection Time: 2.29482
Timestep Consumption Time: 2.34512
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.63994

Cumulative Model Updates: 151,292
Cumulative Timesteps: 1,261,576,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.31530
Policy Entropy: 3.76411
Value Function Loss: 0.01790

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.45283
Value Function Update Magnitude: 0.39811

Collected Steps per Second: 21,969.09270
Overall Steps per Second: 10,803.38286

Timestep Collection Time: 2.27674
Timestep Consumption Time: 2.35310
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.62985

Cumulative Model Updates: 151,298
Cumulative Timesteps: 1,261,626,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1261626478...
Checkpoint 1261626478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.18928
Policy Entropy: 3.75897
Value Function Loss: 0.01626

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.42894
Value Function Update Magnitude: 0.38526

Collected Steps per Second: 21,552.55446
Overall Steps per Second: 10,600.20784

Timestep Collection Time: 2.32047
Timestep Consumption Time: 2.39755
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.71802

Cumulative Model Updates: 151,304
Cumulative Timesteps: 1,261,676,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 812.18928
Policy Entropy: 3.75070
Value Function Loss: 0.01515

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.40068
Value Function Update Magnitude: 0.33850

Collected Steps per Second: 22,225.44918
Overall Steps per Second: 10,570.61207

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.73180

Cumulative Model Updates: 151,310
Cumulative Timesteps: 1,261,726,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1261726508...
Checkpoint 1261726508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,791.07109
Policy Entropy: 3.75248
Value Function Loss: 0.01559

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.39951
Value Function Update Magnitude: 0.40466

Collected Steps per Second: 22,353.82605
Overall Steps per Second: 10,595.99730

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71914

Cumulative Model Updates: 151,316
Cumulative Timesteps: 1,261,776,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,364.92687
Policy Entropy: 3.76338
Value Function Loss: 0.01770

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.44753
Value Function Update Magnitude: 0.55389

Collected Steps per Second: 22,011.17326
Overall Steps per Second: 10,467.98371

Timestep Collection Time: 2.27230
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.77800

Cumulative Model Updates: 151,322
Cumulative Timesteps: 1,261,826,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1261826528...
Checkpoint 1261826528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,668.60661
Policy Entropy: 3.76191
Value Function Loss: 0.02040

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.51074
Value Function Update Magnitude: 0.71867

Collected Steps per Second: 21,730.37670
Overall Steps per Second: 10,564.97417

Timestep Collection Time: 2.30212
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.73508

Cumulative Model Updates: 151,328
Cumulative Timesteps: 1,261,876,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380,068.38302
Policy Entropy: 3.75089
Value Function Loss: 0.02254

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.71277

Collected Steps per Second: 22,320.45910
Overall Steps per Second: 10,543.83936

Timestep Collection Time: 2.24028
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.74248

Cumulative Model Updates: 151,334
Cumulative Timesteps: 1,261,926,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1261926558...
Checkpoint 1261926558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,309.21666
Policy Entropy: 3.74814
Value Function Loss: 0.02180

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.52534
Value Function Update Magnitude: 0.74719

Collected Steps per Second: 21,627.72016
Overall Steps per Second: 10,252.86238

Timestep Collection Time: 2.31194
Timestep Consumption Time: 2.56494
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.87688

Cumulative Model Updates: 151,340
Cumulative Timesteps: 1,261,976,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,238.77280
Policy Entropy: 3.73913
Value Function Loss: 0.01952

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.53999
Value Function Update Magnitude: 0.77590

Collected Steps per Second: 22,714.44776
Overall Steps per Second: 10,784.58328

Timestep Collection Time: 2.20344
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.64088

Cumulative Model Updates: 151,346
Cumulative Timesteps: 1,262,026,610

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1262026610...
Checkpoint 1262026610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,869.22090
Policy Entropy: 3.74509
Value Function Loss: 0.01767

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13737
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.72582

Collected Steps per Second: 22,603.05645
Overall Steps per Second: 10,699.83497

Timestep Collection Time: 2.21271
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.67428

Cumulative Model Updates: 151,352
Cumulative Timesteps: 1,262,076,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,327.95407
Policy Entropy: 3.74250
Value Function Loss: 0.01794

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.51616
Value Function Update Magnitude: 0.67559

Collected Steps per Second: 22,599.63890
Overall Steps per Second: 10,667.96041

Timestep Collection Time: 2.21331
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68881

Cumulative Model Updates: 151,358
Cumulative Timesteps: 1,262,126,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1262126644...
Checkpoint 1262126644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,656.43676
Policy Entropy: 3.77655
Value Function Loss: 0.01949

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.52822
Value Function Update Magnitude: 0.69094

Collected Steps per Second: 22,718.28975
Overall Steps per Second: 10,827.21096

Timestep Collection Time: 2.20113
Timestep Consumption Time: 2.41741
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.61855

Cumulative Model Updates: 151,364
Cumulative Timesteps: 1,262,176,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,048.02084
Policy Entropy: 3.78582
Value Function Loss: 0.02077

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.51433
Value Function Update Magnitude: 0.76057

Collected Steps per Second: 22,284.56751
Overall Steps per Second: 10,552.45945

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.73823

Cumulative Model Updates: 151,370
Cumulative Timesteps: 1,262,226,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1262226650...
Checkpoint 1262226650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,357.28973
Policy Entropy: 3.78623
Value Function Loss: 0.01875

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.45220
Value Function Update Magnitude: 0.74719

Collected Steps per Second: 22,227.07445
Overall Steps per Second: 10,532.04144

Timestep Collection Time: 2.24960
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.74761

Cumulative Model Updates: 151,376
Cumulative Timesteps: 1,262,276,652

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,819.69463
Policy Entropy: 3.76371
Value Function Loss: 0.01565

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.39811
Value Function Update Magnitude: 0.70387

Collected Steps per Second: 22,085.66423
Overall Steps per Second: 10,505.10536

Timestep Collection Time: 2.26409
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.75997

Cumulative Model Updates: 151,382
Cumulative Timesteps: 1,262,326,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1262326656...
Checkpoint 1262326656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,534.79363
Policy Entropy: 3.74805
Value Function Loss: 0.01639

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.38886
Value Function Update Magnitude: 0.66430

Collected Steps per Second: 21,975.73098
Overall Steps per Second: 10,619.96436

Timestep Collection Time: 2.27551
Timestep Consumption Time: 2.43317
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.70868

Cumulative Model Updates: 151,388
Cumulative Timesteps: 1,262,376,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,241.22940
Policy Entropy: 3.76358
Value Function Loss: 0.01592

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.40578
Value Function Update Magnitude: 0.66374

Collected Steps per Second: 21,971.27684
Overall Steps per Second: 10,658.68681

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.41628
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.69289

Cumulative Model Updates: 151,394
Cumulative Timesteps: 1,262,426,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1262426682...
Checkpoint 1262426682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.63837
Policy Entropy: 3.75929
Value Function Loss: 0.01906

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.45113
Value Function Update Magnitude: 0.66580

Collected Steps per Second: 22,016.13110
Overall Steps per Second: 10,836.10326

Timestep Collection Time: 2.27115
Timestep Consumption Time: 2.34324
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61439

Cumulative Model Updates: 151,400
Cumulative Timesteps: 1,262,476,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,845.62003
Policy Entropy: 3.77453
Value Function Loss: 0.01781

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.73224

Collected Steps per Second: 21,927.73177
Overall Steps per Second: 10,667.27241

Timestep Collection Time: 2.28122
Timestep Consumption Time: 2.40808
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.68930

Cumulative Model Updates: 151,406
Cumulative Timesteps: 1,262,526,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1262526706...
Checkpoint 1262526706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,663.87395
Policy Entropy: 3.76598
Value Function Loss: 0.02027

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.50850
Value Function Update Magnitude: 0.73523

Collected Steps per Second: 22,108.59608
Overall Steps per Second: 10,849.13480

Timestep Collection Time: 2.26247
Timestep Consumption Time: 2.34804
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.61051

Cumulative Model Updates: 151,412
Cumulative Timesteps: 1,262,576,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,350.15526
Policy Entropy: 3.76752
Value Function Loss: 0.01855

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.70275

Collected Steps per Second: 21,837.98820
Overall Steps per Second: 10,589.01233

Timestep Collection Time: 2.29179
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.72641

Cumulative Model Updates: 151,418
Cumulative Timesteps: 1,262,626,774

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1262626774...
Checkpoint 1262626774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360,875.96556
Policy Entropy: 3.74308
Value Function Loss: 0.02042

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.50921
Value Function Update Magnitude: 0.60410

Collected Steps per Second: 22,641.56952
Overall Steps per Second: 10,696.27035

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.46867
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.67920

Cumulative Model Updates: 151,424
Cumulative Timesteps: 1,262,676,824

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360,875.96556
Policy Entropy: 3.73404
Value Function Loss: 0.01683

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.51556
Value Function Update Magnitude: 0.56245

Collected Steps per Second: 21,794.64222
Overall Steps per Second: 10,416.14698

Timestep Collection Time: 2.29524
Timestep Consumption Time: 2.50730
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.80254

Cumulative Model Updates: 151,430
Cumulative Timesteps: 1,262,726,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1262726848...
Checkpoint 1262726848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,049.81485
Policy Entropy: 3.71618
Value Function Loss: 0.02283

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.55106
Value Function Update Magnitude: 0.51683

Collected Steps per Second: 22,135.90212
Overall Steps per Second: 10,633.26791

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.70373

Cumulative Model Updates: 151,436
Cumulative Timesteps: 1,262,776,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,643.60713
Policy Entropy: 3.75344
Value Function Loss: 0.02267

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.62206
Value Function Update Magnitude: 0.63904

Collected Steps per Second: 22,122.90654
Overall Steps per Second: 10,515.41555

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.75702

Cumulative Model Updates: 151,442
Cumulative Timesteps: 1,262,826,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1262826886...
Checkpoint 1262826886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,684.44300
Policy Entropy: 3.75621
Value Function Loss: 0.02648

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.61466
Value Function Update Magnitude: 0.87474

Collected Steps per Second: 22,209.40070
Overall Steps per Second: 10,552.70839

Timestep Collection Time: 2.25229
Timestep Consumption Time: 2.48792
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.74020

Cumulative Model Updates: 151,448
Cumulative Timesteps: 1,262,876,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,756.98703
Policy Entropy: 3.78891
Value Function Loss: 0.02215

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.60915
Value Function Update Magnitude: 0.89185

Collected Steps per Second: 22,082.55966
Overall Steps per Second: 10,452.39693

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.78589

Cumulative Model Updates: 151,454
Cumulative Timesteps: 1,262,926,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1262926932...
Checkpoint 1262926932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.72163
Policy Entropy: 3.77327
Value Function Loss: 0.02120

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.80181

Collected Steps per Second: 22,864.05099
Overall Steps per Second: 10,637.91693

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.70280

Cumulative Model Updates: 151,460
Cumulative Timesteps: 1,262,976,960

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,728.49914
Policy Entropy: 3.78780
Value Function Loss: 0.02039

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.55500
Value Function Update Magnitude: 0.64906

Collected Steps per Second: 22,450.89960
Overall Steps per Second: 10,605.15881

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.48910
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.71752

Cumulative Model Updates: 151,466
Cumulative Timesteps: 1,263,026,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1263026990...
Checkpoint 1263026990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,651.00674
Policy Entropy: 3.77515
Value Function Loss: 0.02097

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.54313
Value Function Update Magnitude: 0.61156

Collected Steps per Second: 22,809.96453
Overall Steps per Second: 10,880.94849

Timestep Collection Time: 2.19273
Timestep Consumption Time: 2.40393
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59666

Cumulative Model Updates: 151,472
Cumulative Timesteps: 1,263,077,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,745.47483
Policy Entropy: 3.78521
Value Function Loss: 0.02081

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.64057

Collected Steps per Second: 22,852.88266
Overall Steps per Second: 10,672.01716

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.68871

Cumulative Model Updates: 151,478
Cumulative Timesteps: 1,263,127,044

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1263127044...
Checkpoint 1263127044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,335.73152
Policy Entropy: 3.79313
Value Function Loss: 0.01847

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.52267
Value Function Update Magnitude: 0.74402

Collected Steps per Second: 22,855.10190
Overall Steps per Second: 10,713.18994

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.48143
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67088

Cumulative Model Updates: 151,484
Cumulative Timesteps: 1,263,177,084

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 493,437.87607
Policy Entropy: 3.78577
Value Function Loss: 0.01750

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.49256
Value Function Update Magnitude: 0.83088

Collected Steps per Second: 22,616.64751
Overall Steps per Second: 10,730.65111

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.44879
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.65955

Cumulative Model Updates: 151,490
Cumulative Timesteps: 1,263,227,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1263227084...
Checkpoint 1263227084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,204.67868
Policy Entropy: 3.77983
Value Function Loss: 0.01792

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.51730
Value Function Update Magnitude: 0.84630

Collected Steps per Second: 21,949.59477
Overall Steps per Second: 10,675.96389

Timestep Collection Time: 2.27804
Timestep Consumption Time: 2.40557
PPO Batch Consumption Time: 0.27548
Total Iteration Time: 4.68361

Cumulative Model Updates: 151,496
Cumulative Timesteps: 1,263,277,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,604.74657
Policy Entropy: 3.76019
Value Function Loss: 0.01735

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.48651
Value Function Update Magnitude: 0.77633

Collected Steps per Second: 22,419.26700
Overall Steps per Second: 10,772.05142

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64443

Cumulative Model Updates: 151,502
Cumulative Timesteps: 1,263,327,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1263327116...
Checkpoint 1263327116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,008.40980
Policy Entropy: 3.77126
Value Function Loss: 0.01913

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.48384
Value Function Update Magnitude: 0.74398

Collected Steps per Second: 21,322.66683
Overall Steps per Second: 10,642.42301

Timestep Collection Time: 2.34624
Timestep Consumption Time: 2.35457
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.70081

Cumulative Model Updates: 151,508
Cumulative Timesteps: 1,263,377,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,509.41633
Policy Entropy: 3.75645
Value Function Loss: 0.01916

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.74641

Collected Steps per Second: 21,457.89313
Overall Steps per Second: 10,540.03849

Timestep Collection Time: 2.33033
Timestep Consumption Time: 2.41386
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.74420

Cumulative Model Updates: 151,514
Cumulative Timesteps: 1,263,427,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1263427148...
Checkpoint 1263427148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,655.05888
Policy Entropy: 3.76795
Value Function Loss: 0.02262

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12413
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.77627

Collected Steps per Second: 21,814.50024
Overall Steps per Second: 10,645.82848

Timestep Collection Time: 2.29270
Timestep Consumption Time: 2.40530
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.69799

Cumulative Model Updates: 151,520
Cumulative Timesteps: 1,263,477,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,176.86148
Policy Entropy: 3.78573
Value Function Loss: 0.02172

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.72526

Collected Steps per Second: 22,102.57090
Overall Steps per Second: 10,827.94894

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.35682
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62027

Cumulative Model Updates: 151,526
Cumulative Timesteps: 1,263,527,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1263527190...
Checkpoint 1263527190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,308.10164
Policy Entropy: 3.81389
Value Function Loss: 0.02250

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.58240
Value Function Update Magnitude: 0.72822

Collected Steps per Second: 21,850.81793
Overall Steps per Second: 10,632.55338

Timestep Collection Time: 2.28898
Timestep Consumption Time: 2.41507
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.70404

Cumulative Model Updates: 151,532
Cumulative Timesteps: 1,263,577,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.24064
Policy Entropy: 3.80142
Value Function Loss: 0.01868

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.56448
Value Function Update Magnitude: 0.72437

Collected Steps per Second: 22,732.61282
Overall Steps per Second: 10,764.19892

Timestep Collection Time: 2.19948
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.64503

Cumulative Model Updates: 151,538
Cumulative Timesteps: 1,263,627,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1263627206...
Checkpoint 1263627206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.24064
Policy Entropy: 3.76505
Value Function Loss: 0.01723

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13305
Policy Update Magnitude: 0.52603
Value Function Update Magnitude: 0.65268

Collected Steps per Second: 22,507.84467
Overall Steps per Second: 10,821.45957

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.39948
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.62137

Cumulative Model Updates: 151,544
Cumulative Timesteps: 1,263,677,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,252.24064
Policy Entropy: 3.72801
Value Function Loss: 0.01706

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.48678
Value Function Update Magnitude: 0.53351

Collected Steps per Second: 22,344.86059
Overall Steps per Second: 10,553.04557

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.50172
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74062

Cumulative Model Updates: 151,550
Cumulative Timesteps: 1,263,727,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1263727244...
Checkpoint 1263727244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,324.16592
Policy Entropy: 3.74726
Value Function Loss: 0.01790

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.48090
Value Function Update Magnitude: 0.46349

Collected Steps per Second: 22,255.70206
Overall Steps per Second: 10,585.59372

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.72642

Cumulative Model Updates: 151,556
Cumulative Timesteps: 1,263,777,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,968.86812
Policy Entropy: 3.75297
Value Function Loss: 0.01904

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.46130
Value Function Update Magnitude: 0.47356

Collected Steps per Second: 22,061.89592
Overall Steps per Second: 10,494.14143

Timestep Collection Time: 2.26735
Timestep Consumption Time: 2.49931
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76666

Cumulative Model Updates: 151,562
Cumulative Timesteps: 1,263,827,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1263827298...
Checkpoint 1263827298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,119.62174
Policy Entropy: 3.76416
Value Function Loss: 0.01875

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.45202
Value Function Update Magnitude: 0.50211

Collected Steps per Second: 21,942.68823
Overall Steps per Second: 10,507.67486

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.75976

Cumulative Model Updates: 151,568
Cumulative Timesteps: 1,263,877,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,119.62174
Policy Entropy: 3.74351
Value Function Loss: 0.01588

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.46363
Value Function Update Magnitude: 0.51399

Collected Steps per Second: 22,343.50321
Overall Steps per Second: 10,518.41097

Timestep Collection Time: 2.23815
Timestep Consumption Time: 2.51619
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.75433

Cumulative Model Updates: 151,574
Cumulative Timesteps: 1,263,927,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1263927320...
Checkpoint 1263927320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,785.17417
Policy Entropy: 3.73808
Value Function Loss: 0.01687

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.43051
Value Function Update Magnitude: 0.49083

Collected Steps per Second: 22,399.64808
Overall Steps per Second: 10,618.22764

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.47690
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.70926

Cumulative Model Updates: 151,580
Cumulative Timesteps: 1,263,977,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245,243.22354
Policy Entropy: 3.73981
Value Function Loss: 0.01576

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.41834
Value Function Update Magnitude: 0.50583

Collected Steps per Second: 22,690.64790
Overall Steps per Second: 10,540.41892

Timestep Collection Time: 2.20417
Timestep Consumption Time: 2.54080
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74497

Cumulative Model Updates: 151,586
Cumulative Timesteps: 1,264,027,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1264027338...
Checkpoint 1264027338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316,260.09900
Policy Entropy: 3.72331
Value Function Loss: 0.02143

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.44552
Value Function Update Magnitude: 0.50660

Collected Steps per Second: 22,946.20966
Overall Steps per Second: 10,705.20180

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.49291
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.67306

Cumulative Model Updates: 151,592
Cumulative Timesteps: 1,264,077,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,008.47932
Policy Entropy: 3.74739
Value Function Loss: 0.02348

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.53296
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,822.77230
Overall Steps per Second: 10,848.43900

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.41961
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.61172

Cumulative Model Updates: 151,598
Cumulative Timesteps: 1,264,127,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1264127394...
Checkpoint 1264127394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,237.03321
Policy Entropy: 3.74523
Value Function Loss: 0.02523

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.75709

Collected Steps per Second: 22,778.43632
Overall Steps per Second: 10,691.02044

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.48226
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.67776

Cumulative Model Updates: 151,604
Cumulative Timesteps: 1,264,177,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,237.03321
Policy Entropy: 3.76463
Value Function Loss: 0.01976

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.69767

Collected Steps per Second: 22,693.13939
Overall Steps per Second: 10,785.21125

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.63783

Cumulative Model Updates: 151,610
Cumulative Timesteps: 1,264,227,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1264227424...
Checkpoint 1264227424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,588.64476
Policy Entropy: 3.74423
Value Function Loss: 0.01928

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.49010
Value Function Update Magnitude: 0.58497

Collected Steps per Second: 22,507.66673
Overall Steps per Second: 10,682.12061

Timestep Collection Time: 2.22227
Timestep Consumption Time: 2.46014
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.68240

Cumulative Model Updates: 151,616
Cumulative Timesteps: 1,264,277,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 440,109.66439
Policy Entropy: 3.76042
Value Function Loss: 0.01713

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.51819
Value Function Update Magnitude: 0.64231

Collected Steps per Second: 21,923.15701
Overall Steps per Second: 10,452.80170

Timestep Collection Time: 2.28161
Timestep Consumption Time: 2.50371
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.78532

Cumulative Model Updates: 151,622
Cumulative Timesteps: 1,264,327,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1264327462...
Checkpoint 1264327462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,743.94622
Policy Entropy: 3.76286
Value Function Loss: 0.01941

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13940
Policy Update Magnitude: 0.54016
Value Function Update Magnitude: 0.78453

Collected Steps per Second: 22,238.78731
Overall Steps per Second: 10,612.39914

Timestep Collection Time: 2.24850
Timestep Consumption Time: 2.46334
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.71185

Cumulative Model Updates: 151,628
Cumulative Timesteps: 1,264,377,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,747.12413
Policy Entropy: 3.75979
Value Function Loss: 0.01611

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.51951
Value Function Update Magnitude: 0.73658

Collected Steps per Second: 21,455.74825
Overall Steps per Second: 10,521.68559

Timestep Collection Time: 2.33206
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.75551

Cumulative Model Updates: 151,634
Cumulative Timesteps: 1,264,427,502

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1264427502...
Checkpoint 1264427502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,203.75311
Policy Entropy: 3.75286
Value Function Loss: 0.01712

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.52699
Value Function Update Magnitude: 0.68382

Collected Steps per Second: 21,694.49892
Overall Steps per Second: 10,625.32651

Timestep Collection Time: 2.30584
Timestep Consumption Time: 2.40216
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.70800

Cumulative Model Updates: 151,640
Cumulative Timesteps: 1,264,477,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,602.57598
Policy Entropy: 3.75027
Value Function Loss: 0.01549

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.66496

Collected Steps per Second: 21,707.76804
Overall Steps per Second: 10,578.09109

Timestep Collection Time: 2.30378
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.72770

Cumulative Model Updates: 151,646
Cumulative Timesteps: 1,264,527,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1264527536...
Checkpoint 1264527536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,602.57598
Policy Entropy: 3.76680
Value Function Loss: 0.01524

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.52068
Value Function Update Magnitude: 0.67908

Collected Steps per Second: 22,582.30311
Overall Steps per Second: 10,610.03568

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.71384

Cumulative Model Updates: 151,652
Cumulative Timesteps: 1,264,577,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,602.57598
Policy Entropy: 3.73946
Value Function Loss: 0.01430

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.45929
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 22,794.94283
Overall Steps per Second: 10,777.64319

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.44733
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.64220

Cumulative Model Updates: 151,658
Cumulative Timesteps: 1,264,627,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1264627582...
Checkpoint 1264627582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,037.03960
Policy Entropy: 3.74214
Value Function Loss: 0.01617

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13972
Policy Update Magnitude: 0.45254
Value Function Update Magnitude: 0.54786

Collected Steps per Second: 22,671.65358
Overall Steps per Second: 10,711.58709

Timestep Collection Time: 2.20628
Timestep Consumption Time: 2.46343
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.66971

Cumulative Model Updates: 151,664
Cumulative Timesteps: 1,264,677,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,533.19012
Policy Entropy: 3.72832
Value Function Loss: 0.01735

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.46320
Value Function Update Magnitude: 0.65897

Collected Steps per Second: 22,487.36676
Overall Steps per Second: 10,760.89173

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.64813

Cumulative Model Updates: 151,670
Cumulative Timesteps: 1,264,727,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1264727620...
Checkpoint 1264727620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.76101
Value Function Loss: 0.01699

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.69651

Collected Steps per Second: 22,695.76470
Overall Steps per Second: 10,705.76735

Timestep Collection Time: 2.20341
Timestep Consumption Time: 2.46772
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.67113

Cumulative Model Updates: 151,676
Cumulative Timesteps: 1,264,777,628

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.76268
Value Function Loss: 0.01535

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.47258
Value Function Update Magnitude: 0.67432

Collected Steps per Second: 22,716.67217
Overall Steps per Second: 10,827.92280

Timestep Collection Time: 2.20164
Timestep Consumption Time: 2.41734
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.61898

Cumulative Model Updates: 151,682
Cumulative Timesteps: 1,264,827,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1264827642...
Checkpoint 1264827642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.76192
Value Function Loss: 0.01340

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13821
Policy Update Magnitude: 0.43867
Value Function Update Magnitude: 0.59048

Collected Steps per Second: 22,265.99183
Overall Steps per Second: 10,735.02995

Timestep Collection Time: 2.24621
Timestep Consumption Time: 2.41275
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.65895

Cumulative Model Updates: 151,688
Cumulative Timesteps: 1,264,877,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.73974
Value Function Loss: 0.01459

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.41804
Value Function Update Magnitude: 0.51944

Collected Steps per Second: 22,512.68218
Overall Steps per Second: 10,619.05782

Timestep Collection Time: 2.22150
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.70965

Cumulative Model Updates: 151,694
Cumulative Timesteps: 1,264,927,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1264927668...
Checkpoint 1264927668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.73640
Value Function Loss: 0.01729

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.45628
Value Function Update Magnitude: 0.45554

Collected Steps per Second: 22,166.15842
Overall Steps per Second: 10,510.56621

Timestep Collection Time: 2.25596
Timestep Consumption Time: 2.50173
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.75769

Cumulative Model Updates: 151,700
Cumulative Timesteps: 1,264,977,674

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,722.01135
Policy Entropy: 3.73051
Value Function Loss: 0.01800

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.48551
Value Function Update Magnitude: 0.43382

Collected Steps per Second: 22,214.18627
Overall Steps per Second: 10,588.57991

Timestep Collection Time: 2.25099
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.72245

Cumulative Model Updates: 151,706
Cumulative Timesteps: 1,265,027,678

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1265027678...
Checkpoint 1265027678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,577.10425
Policy Entropy: 3.74365
Value Function Loss: 0.01883

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.49021
Value Function Update Magnitude: 0.47380

Collected Steps per Second: 22,395.04160
Overall Steps per Second: 10,583.09999

Timestep Collection Time: 2.23317
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.72565

Cumulative Model Updates: 151,712
Cumulative Timesteps: 1,265,077,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,577.10425
Policy Entropy: 3.75281
Value Function Loss: 0.01764

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.48065
Value Function Update Magnitude: 0.43797

Collected Steps per Second: 23,157.18905
Overall Steps per Second: 10,772.82322

Timestep Collection Time: 2.16019
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.64354

Cumulative Model Updates: 151,718
Cumulative Timesteps: 1,265,127,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1265127714...
Checkpoint 1265127714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,375.01326
Policy Entropy: 3.75717
Value Function Loss: 0.02102

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.44191
Value Function Update Magnitude: 0.34794

Collected Steps per Second: 21,489.89440
Overall Steps per Second: 10,580.14758

Timestep Collection Time: 2.32751
Timestep Consumption Time: 2.40002
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.72753

Cumulative Model Updates: 151,724
Cumulative Timesteps: 1,265,177,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,037.05386
Policy Entropy: 3.75635
Value Function Loss: 0.01829

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.47357
Value Function Update Magnitude: 0.34945

Collected Steps per Second: 22,033.51447
Overall Steps per Second: 10,694.26574

Timestep Collection Time: 2.26927
Timestep Consumption Time: 2.40613
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.67540

Cumulative Model Updates: 151,730
Cumulative Timesteps: 1,265,227,732

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1265227732...
Checkpoint 1265227732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,910.09236
Policy Entropy: 3.76130
Value Function Loss: 0.01986

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.49627
Value Function Update Magnitude: 0.38567

Collected Steps per Second: 22,309.56898
Overall Steps per Second: 10,870.35971

Timestep Collection Time: 2.24182
Timestep Consumption Time: 2.35913
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.60095

Cumulative Model Updates: 151,736
Cumulative Timesteps: 1,265,277,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,615.11864
Policy Entropy: 3.76018
Value Function Loss: 0.01719

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.51164
Value Function Update Magnitude: 0.43938

Collected Steps per Second: 22,414.70667
Overall Steps per Second: 10,654.90013

Timestep Collection Time: 2.23130
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.69399

Cumulative Model Updates: 151,742
Cumulative Timesteps: 1,265,327,760

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1265327760...
Checkpoint 1265327760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,615.11864
Policy Entropy: 3.75878
Value Function Loss: 0.01703

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13773
Policy Update Magnitude: 0.53260
Value Function Update Magnitude: 0.48187

Collected Steps per Second: 22,721.13246
Overall Steps per Second: 10,841.33713

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.41244
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.61401

Cumulative Model Updates: 151,748
Cumulative Timesteps: 1,265,377,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,011.74957
Policy Entropy: 3.73876
Value Function Loss: 0.01749

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.54628
Value Function Update Magnitude: 0.47896

Collected Steps per Second: 22,080.00593
Overall Steps per Second: 10,537.70407

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.74809

Cumulative Model Updates: 151,754
Cumulative Timesteps: 1,265,427,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1265427816...
Checkpoint 1265427816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,161.45702
Policy Entropy: 3.73730
Value Function Loss: 0.01854

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.53545
Value Function Update Magnitude: 0.53061

Collected Steps per Second: 22,225.57896
Overall Steps per Second: 10,711.01941

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.41901
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.66921

Cumulative Model Updates: 151,760
Cumulative Timesteps: 1,265,477,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,145.44274
Policy Entropy: 3.73739
Value Function Loss: 0.01849

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.50269
Value Function Update Magnitude: 0.52658

Collected Steps per Second: 22,151.44786
Overall Steps per Second: 10,484.68644

Timestep Collection Time: 2.25863
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.77191

Cumulative Model Updates: 151,766
Cumulative Timesteps: 1,265,527,860

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1265527860...
Checkpoint 1265527860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,145.44274
Policy Entropy: 3.74422
Value Function Loss: 0.01603

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.46893
Value Function Update Magnitude: 0.49365

Collected Steps per Second: 22,359.37990
Overall Steps per Second: 10,542.16312

Timestep Collection Time: 2.23718
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.74495

Cumulative Model Updates: 151,772
Cumulative Timesteps: 1,265,577,882

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,145.44274
Policy Entropy: 3.73249
Value Function Loss: 0.01600

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.42182
Value Function Update Magnitude: 0.40364

Collected Steps per Second: 22,525.17225
Overall Steps per Second: 10,527.40754

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.53027
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.75046

Cumulative Model Updates: 151,778
Cumulative Timesteps: 1,265,627,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1265627892...
Checkpoint 1265627892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,145.44274
Policy Entropy: 3.74672
Value Function Loss: 0.01466

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.41026
Value Function Update Magnitude: 0.36035

Collected Steps per Second: 22,708.53546
Overall Steps per Second: 10,632.51223

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.70369

Cumulative Model Updates: 151,784
Cumulative Timesteps: 1,265,677,904

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,145.44274
Policy Entropy: 3.74092
Value Function Loss: 0.01702

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.39500
Value Function Update Magnitude: 0.35399

Collected Steps per Second: 22,820.81648
Overall Steps per Second: 10,846.35703

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.41915
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61040

Cumulative Model Updates: 151,790
Cumulative Timesteps: 1,265,727,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1265727910...
Checkpoint 1265727910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,290.26785
Policy Entropy: 3.77049
Value Function Loss: 0.01875

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.47755
Value Function Update Magnitude: 0.45177

Collected Steps per Second: 21,896.84866
Overall Steps per Second: 10,577.08984

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.44455
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.72871

Cumulative Model Updates: 151,796
Cumulative Timesteps: 1,265,777,926

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,401.47949
Policy Entropy: 3.76693
Value Function Loss: 0.01960

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.58071

Collected Steps per Second: 21,560.68169
Overall Steps per Second: 10,530.59503

Timestep Collection Time: 2.31913
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.74826

Cumulative Model Updates: 151,802
Cumulative Timesteps: 1,265,827,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1265827928...
Checkpoint 1265827928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,293.27190
Policy Entropy: 3.80217
Value Function Loss: 0.01925

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.52920
Value Function Update Magnitude: 0.61139

Collected Steps per Second: 21,822.91602
Overall Steps per Second: 10,621.03741

Timestep Collection Time: 2.29172
Timestep Consumption Time: 2.41705
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70877

Cumulative Model Updates: 151,808
Cumulative Timesteps: 1,265,877,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,543.01344
Policy Entropy: 3.78152
Value Function Loss: 0.01920

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.51560
Value Function Update Magnitude: 0.66362

Collected Steps per Second: 21,852.02440
Overall Steps per Second: 10,440.91736

Timestep Collection Time: 2.28839
Timestep Consumption Time: 2.50103
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.78943

Cumulative Model Updates: 151,814
Cumulative Timesteps: 1,265,927,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1265927946...
Checkpoint 1265927946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,269.85220
Policy Entropy: 3.77219
Value Function Loss: 0.01984

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.55677
Value Function Update Magnitude: 0.69918

Collected Steps per Second: 22,351.60881
Overall Steps per Second: 10,654.41172

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.45611
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.69327

Cumulative Model Updates: 151,820
Cumulative Timesteps: 1,265,977,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,143.28167
Policy Entropy: 3.76658
Value Function Loss: 0.01926

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.53489
Value Function Update Magnitude: 0.70934

Collected Steps per Second: 21,912.83206
Overall Steps per Second: 10,510.53853

Timestep Collection Time: 2.28222
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.75808

Cumulative Model Updates: 151,826
Cumulative Timesteps: 1,266,027,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1266027960...
Checkpoint 1266027960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,878.68169
Policy Entropy: 3.75725
Value Function Loss: 0.02102

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.52343
Value Function Update Magnitude: 0.56621

Collected Steps per Second: 22,262.98566
Overall Steps per Second: 10,571.10854

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.48439
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.73063

Cumulative Model Updates: 151,832
Cumulative Timesteps: 1,266,077,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 438,199.25064
Policy Entropy: 3.75517
Value Function Loss: 0.02013

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.55343
Value Function Update Magnitude: 0.54601

Collected Steps per Second: 22,015.31221
Overall Steps per Second: 10,447.08472

Timestep Collection Time: 2.27187
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.78756

Cumulative Model Updates: 151,838
Cumulative Timesteps: 1,266,127,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1266127984...
Checkpoint 1266127984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,768.07755
Policy Entropy: 3.74920
Value Function Loss: 0.02422

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.57914
Value Function Update Magnitude: 0.59721

Collected Steps per Second: 22,012.76056
Overall Steps per Second: 10,619.33574

Timestep Collection Time: 2.27286
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.71141

Cumulative Model Updates: 151,844
Cumulative Timesteps: 1,266,178,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,366.70372
Policy Entropy: 3.77002
Value Function Loss: 0.02628

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.59950
Value Function Update Magnitude: 0.65553

Collected Steps per Second: 22,455.05688
Overall Steps per Second: 10,556.62958

Timestep Collection Time: 2.22703
Timestep Consumption Time: 2.51009
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.73712

Cumulative Model Updates: 151,850
Cumulative Timesteps: 1,266,228,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1266228024...
Checkpoint 1266228024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,655.72172
Policy Entropy: 3.78715
Value Function Loss: 0.02956

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.65070
Value Function Update Magnitude: 0.73938

Collected Steps per Second: 22,600.59420
Overall Steps per Second: 10,627.60058

Timestep Collection Time: 2.21251
Timestep Consumption Time: 2.49260
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70511

Cumulative Model Updates: 151,856
Cumulative Timesteps: 1,266,278,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,595.83568
Policy Entropy: 3.78474
Value Function Loss: 0.02774

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.66641
Value Function Update Magnitude: 0.76421

Collected Steps per Second: 22,732.35839
Overall Steps per Second: 10,801.34550

Timestep Collection Time: 2.20004
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.63016

Cumulative Model Updates: 151,862
Cumulative Timesteps: 1,266,328,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1266328040...
Checkpoint 1266328040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.05117
Policy Entropy: 3.77529
Value Function Loss: 0.02407

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.62724
Value Function Update Magnitude: 0.79051

Collected Steps per Second: 22,794.16939
Overall Steps per Second: 10,673.65911

Timestep Collection Time: 2.19416
Timestep Consumption Time: 2.49158
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68574

Cumulative Model Updates: 151,868
Cumulative Timesteps: 1,266,378,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.28760
Policy Entropy: 3.75886
Value Function Loss: 0.02010

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.59778
Value Function Update Magnitude: 0.73219

Collected Steps per Second: 21,868.51493
Overall Steps per Second: 10,647.77854

Timestep Collection Time: 2.28703
Timestep Consumption Time: 2.41010
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.69713

Cumulative Model Updates: 151,874
Cumulative Timesteps: 1,266,428,068

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1266428068...
Checkpoint 1266428068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,180.40329
Policy Entropy: 3.74439
Value Function Loss: 0.02015

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.64155

Collected Steps per Second: 21,401.63786
Overall Steps per Second: 10,496.35964

Timestep Collection Time: 2.33739
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.76584

Cumulative Model Updates: 151,880
Cumulative Timesteps: 1,266,478,092

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,697.83299
Policy Entropy: 3.74997
Value Function Loss: 0.02387

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.52491
Value Function Update Magnitude: 0.46316

Collected Steps per Second: 21,526.30229
Overall Steps per Second: 10,543.77742

Timestep Collection Time: 2.32330
Timestep Consumption Time: 2.41997
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.74327

Cumulative Model Updates: 151,886
Cumulative Timesteps: 1,266,528,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1266528104...
Checkpoint 1266528104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,967.78667
Policy Entropy: 3.75532
Value Function Loss: 0.02165

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.50690
Value Function Update Magnitude: 0.35370

Collected Steps per Second: 21,766.54486
Overall Steps per Second: 10,554.65040

Timestep Collection Time: 2.29830
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.73971

Cumulative Model Updates: 151,892
Cumulative Timesteps: 1,266,578,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,777.65430
Policy Entropy: 3.76067
Value Function Loss: 0.01896

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.48277
Value Function Update Magnitude: 0.32998

Collected Steps per Second: 22,136.07407
Overall Steps per Second: 10,584.31692

Timestep Collection Time: 2.26011
Timestep Consumption Time: 2.46669
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.72680

Cumulative Model Updates: 151,898
Cumulative Timesteps: 1,266,628,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1266628160...
Checkpoint 1266628160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 453,322.63289
Policy Entropy: 3.75986
Value Function Loss: 0.01699

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.45985
Value Function Update Magnitude: 0.48194

Collected Steps per Second: 22,170.33280
Overall Steps per Second: 10,581.39854

Timestep Collection Time: 2.25527
Timestep Consumption Time: 2.47001
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.72527

Cumulative Model Updates: 151,904
Cumulative Timesteps: 1,266,678,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,474.33737
Policy Entropy: 3.74681
Value Function Loss: 0.01980

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.48803
Value Function Update Magnitude: 0.61904

Collected Steps per Second: 22,870.62095
Overall Steps per Second: 10,781.92077

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.63906

Cumulative Model Updates: 151,910
Cumulative Timesteps: 1,266,728,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1266728178...
Checkpoint 1266728178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,474.33737
Policy Entropy: 3.74847
Value Function Loss: 0.01780

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.74529

Collected Steps per Second: 22,685.32848
Overall Steps per Second: 10,585.32586

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.52056
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.72560

Cumulative Model Updates: 151,916
Cumulative Timesteps: 1,266,778,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,474.33737
Policy Entropy: 3.74627
Value Function Loss: 0.01655

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14013
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.68738

Collected Steps per Second: 22,471.98383
Overall Steps per Second: 10,570.81022

Timestep Collection Time: 2.22526
Timestep Consumption Time: 2.50531
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.73057

Cumulative Model Updates: 151,922
Cumulative Timesteps: 1,266,828,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1266828206...
Checkpoint 1266828206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,794.97906
Policy Entropy: 3.75452
Value Function Loss: 0.01619

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.49572
Value Function Update Magnitude: 0.57623

Collected Steps per Second: 22,783.31349
Overall Steps per Second: 10,645.42281

Timestep Collection Time: 2.19564
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.69911

Cumulative Model Updates: 151,928
Cumulative Timesteps: 1,266,878,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,377.41233
Policy Entropy: 3.75750
Value Function Loss: 0.01567

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14048
Policy Update Magnitude: 0.48033
Value Function Update Magnitude: 0.58267

Collected Steps per Second: 22,987.71233
Overall Steps per Second: 10,840.24795

Timestep Collection Time: 2.17595
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.61429

Cumulative Model Updates: 151,934
Cumulative Timesteps: 1,266,928,250

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1266928250...
Checkpoint 1266928250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,377.41233
Policy Entropy: 3.76513
Value Function Loss: 0.01648

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.45349
Value Function Update Magnitude: 0.56547

Collected Steps per Second: 22,650.62578
Overall Steps per Second: 10,696.14528

Timestep Collection Time: 2.20868
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.67720

Cumulative Model Updates: 151,940
Cumulative Timesteps: 1,266,978,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,377.41233
Policy Entropy: 3.75437
Value Function Loss: 0.01492

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.42603
Value Function Update Magnitude: 0.58371

Collected Steps per Second: 22,432.22705
Overall Steps per Second: 10,609.69262

Timestep Collection Time: 2.22929
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.71343

Cumulative Model Updates: 151,946
Cumulative Timesteps: 1,267,028,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1267028286...
Checkpoint 1267028286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,737.38213
Policy Entropy: 3.75795
Value Function Loss: 0.01602

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.42124
Value Function Update Magnitude: 0.55406

Collected Steps per Second: 22,316.32790
Overall Steps per Second: 10,561.12096

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.73454

Cumulative Model Updates: 151,952
Cumulative Timesteps: 1,267,078,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,893.03460
Policy Entropy: 3.76839
Value Function Loss: 0.01637

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.42692
Value Function Update Magnitude: 0.51942

Collected Steps per Second: 22,286.64012
Overall Steps per Second: 10,707.95083

Timestep Collection Time: 2.24386
Timestep Consumption Time: 2.42632
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.67017

Cumulative Model Updates: 151,958
Cumulative Timesteps: 1,267,128,296

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1267128296...
Checkpoint 1267128296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355,410.57089
Policy Entropy: 3.76377
Value Function Loss: 0.02061

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.46529
Value Function Update Magnitude: 0.47709

Collected Steps per Second: 22,308.06173
Overall Steps per Second: 10,670.75116

Timestep Collection Time: 2.24152
Timestep Consumption Time: 2.44456
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.68608

Cumulative Model Updates: 151,964
Cumulative Timesteps: 1,267,178,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,927.22014
Policy Entropy: 3.75450
Value Function Loss: 0.01907

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.47626
Value Function Update Magnitude: 0.53403

Collected Steps per Second: 22,341.83199
Overall Steps per Second: 10,523.44306

Timestep Collection Time: 2.23921
Timestep Consumption Time: 2.51475
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.75396

Cumulative Model Updates: 151,970
Cumulative Timesteps: 1,267,228,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1267228328...
Checkpoint 1267228328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,599.72823
Policy Entropy: 3.75291
Value Function Loss: 0.02055

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.45537
Value Function Update Magnitude: 0.49808

Collected Steps per Second: 22,578.97700
Overall Steps per Second: 10,656.96636

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.69439

Cumulative Model Updates: 151,976
Cumulative Timesteps: 1,267,278,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,807.28351
Policy Entropy: 3.76301
Value Function Loss: 0.01785

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13360
Policy Update Magnitude: 0.45947
Value Function Update Magnitude: 0.43927

Collected Steps per Second: 22,756.66771
Overall Steps per Second: 10,806.50368

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62740

Cumulative Model Updates: 151,982
Cumulative Timesteps: 1,267,328,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1267328362...
Checkpoint 1267328362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,807.28351
Policy Entropy: 3.75346
Value Function Loss: 0.01950

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.45181
Value Function Update Magnitude: 0.40990

Collected Steps per Second: 22,594.07865
Overall Steps per Second: 10,696.89220

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.67631

Cumulative Model Updates: 151,988
Cumulative Timesteps: 1,267,378,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,605.86878
Policy Entropy: 3.76726
Value Function Loss: 0.01642

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13290
Policy Update Magnitude: 0.44314
Value Function Update Magnitude: 0.38289

Collected Steps per Second: 22,744.52962
Overall Steps per Second: 10,705.24889

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.47257
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.67117

Cumulative Model Updates: 151,994
Cumulative Timesteps: 1,267,428,390

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1267428390...
Checkpoint 1267428390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,808.14561
Policy Entropy: 3.77286
Value Function Loss: 0.01785

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.42429
Value Function Update Magnitude: 0.38867

Collected Steps per Second: 22,491.25205
Overall Steps per Second: 10,774.81788

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.64082

Cumulative Model Updates: 152,000
Cumulative Timesteps: 1,267,478,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,808.14561
Policy Entropy: 3.76646
Value Function Loss: 0.01665

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.44862
Value Function Update Magnitude: 0.40922

Collected Steps per Second: 22,548.55485
Overall Steps per Second: 10,599.51709

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.50006
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71776

Cumulative Model Updates: 152,006
Cumulative Timesteps: 1,267,528,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1267528400...
Checkpoint 1267528400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,033.29226
Policy Entropy: 3.75409
Value Function Loss: 0.01757

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.46967
Value Function Update Magnitude: 0.39707

Collected Steps per Second: 22,093.46539
Overall Steps per Second: 10,571.30801

Timestep Collection Time: 2.26384
Timestep Consumption Time: 2.46746
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.73130

Cumulative Model Updates: 152,012
Cumulative Timesteps: 1,267,578,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,033.29226
Policy Entropy: 3.74927
Value Function Loss: 0.01659

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.47898
Value Function Update Magnitude: 0.41198

Collected Steps per Second: 22,162.30716
Overall Steps per Second: 10,482.03812

Timestep Collection Time: 2.25608
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.77006

Cumulative Model Updates: 152,018
Cumulative Timesteps: 1,267,628,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1267628416...
Checkpoint 1267628416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,462.07784
Policy Entropy: 3.76102
Value Function Loss: 0.01720

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.50453
Value Function Update Magnitude: 0.49095

Collected Steps per Second: 22,109.49026
Overall Steps per Second: 10,610.76603

Timestep Collection Time: 2.26391
Timestep Consumption Time: 2.45337
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.71728

Cumulative Model Updates: 152,024
Cumulative Timesteps: 1,267,678,470

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,918.53197
Policy Entropy: 3.76304
Value Function Loss: 0.01721

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.52374
Value Function Update Magnitude: 0.57519

Collected Steps per Second: 21,595.86929
Overall Steps per Second: 10,555.97362

Timestep Collection Time: 2.31637
Timestep Consumption Time: 2.42256
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.73893

Cumulative Model Updates: 152,030
Cumulative Timesteps: 1,267,728,494

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1267728494...
Checkpoint 1267728494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,339.48726
Policy Entropy: 3.77228
Value Function Loss: 0.01672

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.54728
Value Function Update Magnitude: 0.60732

Collected Steps per Second: 22,246.31298
Overall Steps per Second: 10,560.49804

Timestep Collection Time: 2.24927
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.73822

Cumulative Model Updates: 152,036
Cumulative Timesteps: 1,267,778,532

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,448.65871
Policy Entropy: 3.77088
Value Function Loss: 0.01593

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.55482

Collected Steps per Second: 22,461.25008
Overall Steps per Second: 10,498.96378

Timestep Collection Time: 2.22695
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.76428

Cumulative Model Updates: 152,042
Cumulative Timesteps: 1,267,828,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1267828552...
Checkpoint 1267828552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329,474.05943
Policy Entropy: 3.75831
Value Function Loss: 0.01565

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14498
Policy Update Magnitude: 0.52683
Value Function Update Magnitude: 0.53460

Collected Steps per Second: 22,598.73122
Overall Steps per Second: 10,587.41621

Timestep Collection Time: 2.21375
Timestep Consumption Time: 2.51148
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72523

Cumulative Model Updates: 152,048
Cumulative Timesteps: 1,267,878,580

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,882.59649
Policy Entropy: 3.75056
Value Function Loss: 0.01666

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.51504
Value Function Update Magnitude: 0.59066

Collected Steps per Second: 22,505.90937
Overall Steps per Second: 10,601.32666

Timestep Collection Time: 2.22173
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.71658

Cumulative Model Updates: 152,054
Cumulative Timesteps: 1,267,928,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1267928582...
Checkpoint 1267928582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,164.12234
Policy Entropy: 3.76225
Value Function Loss: 0.01699

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.64208

Collected Steps per Second: 22,535.47124
Overall Steps per Second: 10,629.71112

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70455

Cumulative Model Updates: 152,060
Cumulative Timesteps: 1,267,978,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,466.79019
Policy Entropy: 3.77067
Value Function Loss: 0.01906

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.53917
Value Function Update Magnitude: 0.69491

Collected Steps per Second: 22,180.10086
Overall Steps per Second: 10,708.44205

Timestep Collection Time: 2.25454
Timestep Consumption Time: 2.41523
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.66977

Cumulative Model Updates: 152,066
Cumulative Timesteps: 1,268,028,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1268028596...
Checkpoint 1268028596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,632.78435
Policy Entropy: 3.76629
Value Function Loss: 0.01916

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.60442

Collected Steps per Second: 22,726.40217
Overall Steps per Second: 10,748.02710

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.45272
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.65351

Cumulative Model Updates: 152,072
Cumulative Timesteps: 1,268,078,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,632.78435
Policy Entropy: 3.74782
Value Function Loss: 0.01776

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.16392
Policy Update Magnitude: 0.56975
Value Function Update Magnitude: 0.57242

Collected Steps per Second: 22,402.23340
Overall Steps per Second: 10,601.21698

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.48462
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.71663

Cumulative Model Updates: 152,078
Cumulative Timesteps: 1,268,128,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1268128614...
Checkpoint 1268128614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,595.69506
Policy Entropy: 3.73752
Value Function Loss: 0.01691

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.51523
Value Function Update Magnitude: 0.50562

Collected Steps per Second: 22,468.95128
Overall Steps per Second: 10,664.59563

Timestep Collection Time: 2.22529
Timestep Consumption Time: 2.46312
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.68841

Cumulative Model Updates: 152,084
Cumulative Timesteps: 1,268,178,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,595.69506
Policy Entropy: 3.75187
Value Function Loss: 0.01401

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14966
Policy Update Magnitude: 0.44317
Value Function Update Magnitude: 0.45088

Collected Steps per Second: 21,597.55890
Overall Steps per Second: 10,705.86169

Timestep Collection Time: 2.31656
Timestep Consumption Time: 2.35677
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.67333

Cumulative Model Updates: 152,090
Cumulative Timesteps: 1,268,228,646

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1268228646...
Checkpoint 1268228646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,858.15398
Policy Entropy: 3.75737
Value Function Loss: 0.01546

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14744
Policy Update Magnitude: 0.45371
Value Function Update Magnitude: 0.44072

Collected Steps per Second: 21,897.20351
Overall Steps per Second: 10,721.96677

Timestep Collection Time: 2.28468
Timestep Consumption Time: 2.38126
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.66593

Cumulative Model Updates: 152,096
Cumulative Timesteps: 1,268,278,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,983.25826
Policy Entropy: 3.77231
Value Function Loss: 0.01394

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12213
Policy Update Magnitude: 0.47735
Value Function Update Magnitude: 0.50074

Collected Steps per Second: 22,347.01078
Overall Steps per Second: 10,859.35616

Timestep Collection Time: 2.23788
Timestep Consumption Time: 2.36736
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.60525

Cumulative Model Updates: 152,102
Cumulative Timesteps: 1,268,328,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1268328684...
Checkpoint 1268328684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,139.24030
Policy Entropy: 3.75891
Value Function Loss: 0.02489

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.50601
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 21,821.27827
Overall Steps per Second: 10,642.20308

Timestep Collection Time: 2.29189
Timestep Consumption Time: 2.40751
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.69940

Cumulative Model Updates: 152,108
Cumulative Timesteps: 1,268,378,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,520.39326
Policy Entropy: 3.76831
Value Function Loss: 0.02580

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16107
Policy Update Magnitude: 0.61267
Value Function Update Magnitude: 0.78182

Collected Steps per Second: 22,791.67231
Overall Steps per Second: 10,859.74949

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.41143
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.60618

Cumulative Model Updates: 152,114
Cumulative Timesteps: 1,268,428,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1268428718...
Checkpoint 1268428718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,702.06858
Policy Entropy: 3.75218
Value Function Loss: 0.03147

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15557
Policy Update Magnitude: 0.70100
Value Function Update Magnitude: 0.87468

Collected Steps per Second: 22,458.10804
Overall Steps per Second: 10,687.51556

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.45267
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.67967

Cumulative Model Updates: 152,120
Cumulative Timesteps: 1,268,478,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,566.99207
Policy Entropy: 3.79509
Value Function Loss: 0.02523

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.77347
Value Function Update Magnitude: 0.87033

Collected Steps per Second: 22,644.67961
Overall Steps per Second: 10,868.42927

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.39303
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.60158

Cumulative Model Updates: 152,126
Cumulative Timesteps: 1,268,528,744

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1268528744...
Checkpoint 1268528744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,404.91979
Policy Entropy: 3.79576
Value Function Loss: 0.02276

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.80521
Value Function Update Magnitude: 0.94918

Collected Steps per Second: 22,249.00706
Overall Steps per Second: 10,690.85687

Timestep Collection Time: 2.24837
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.67914

Cumulative Model Updates: 152,132
Cumulative Timesteps: 1,268,578,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,646.05632
Policy Entropy: 3.81800
Value Function Loss: 0.01887

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06890
Policy Update Magnitude: 0.84206
Value Function Update Magnitude: 0.90583

Collected Steps per Second: 22,036.85700
Overall Steps per Second: 10,482.49741

Timestep Collection Time: 2.26893
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.76986

Cumulative Model Updates: 152,138
Cumulative Timesteps: 1,268,628,768

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1268628768...
Checkpoint 1268628768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,723.35307
Policy Entropy: 3.78796
Value Function Loss: 0.01643

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.77408
Value Function Update Magnitude: 0.81493

Collected Steps per Second: 21,598.28240
Overall Steps per Second: 10,528.65659

Timestep Collection Time: 2.31620
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.75141

Cumulative Model Updates: 152,144
Cumulative Timesteps: 1,268,678,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,788.10181
Policy Entropy: 3.77580
Value Function Loss: 0.01511

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.67892
Value Function Update Magnitude: 0.65139

Collected Steps per Second: 22,216.76743
Overall Steps per Second: 10,505.93870

Timestep Collection Time: 2.25082
Timestep Consumption Time: 2.50896
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.75978

Cumulative Model Updates: 152,150
Cumulative Timesteps: 1,268,728,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1268728800...
Checkpoint 1268728800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,970.97645
Policy Entropy: 3.77801
Value Function Loss: 0.01342

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09514
Policy Update Magnitude: 0.61888
Value Function Update Magnitude: 0.57424

Collected Steps per Second: 22,210.66130
Overall Steps per Second: 10,694.16354

Timestep Collection Time: 2.25126
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.67563

Cumulative Model Updates: 152,156
Cumulative Timesteps: 1,268,778,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,821.45609
Policy Entropy: 3.77361
Value Function Loss: 0.01357

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13009
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.59576

Collected Steps per Second: 22,567.00621
Overall Steps per Second: 10,548.25243

Timestep Collection Time: 2.21607
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.74107

Cumulative Model Updates: 152,162
Cumulative Timesteps: 1,268,828,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1268828812...
Checkpoint 1268828812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,063.44731
Policy Entropy: 3.78775
Value Function Loss: 0.01259

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.16209
Policy Update Magnitude: 0.52474
Value Function Update Magnitude: 0.63066

Collected Steps per Second: 22,695.68701
Overall Steps per Second: 10,676.19145

Timestep Collection Time: 2.20403
Timestep Consumption Time: 2.48135
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.68538

Cumulative Model Updates: 152,168
Cumulative Timesteps: 1,268,878,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,156.84681
Policy Entropy: 3.80198
Value Function Loss: 0.01260

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16854
Policy Update Magnitude: 0.44748
Value Function Update Magnitude: 0.69542

Collected Steps per Second: 22,900.72770
Overall Steps per Second: 10,742.46055

Timestep Collection Time: 2.18351
Timestep Consumption Time: 2.47129
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.65480

Cumulative Model Updates: 152,174
Cumulative Timesteps: 1,268,928,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1268928838...
Checkpoint 1268928838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,120.70701
Policy Entropy: 3.80218
Value Function Loss: 0.01251

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14315
Policy Update Magnitude: 0.40578
Value Function Update Magnitude: 0.65173

Collected Steps per Second: 22,836.70863
Overall Steps per Second: 10,668.02920

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.69009

Cumulative Model Updates: 152,180
Cumulative Timesteps: 1,268,978,872

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,856.75856
Policy Entropy: 3.77689
Value Function Loss: 0.01221

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.36789
Value Function Update Magnitude: 0.58483

Collected Steps per Second: 22,858.68166
Overall Steps per Second: 10,841.69652

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.42680
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.61625

Cumulative Model Updates: 152,186
Cumulative Timesteps: 1,269,028,920

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1269028920...
Checkpoint 1269028920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,128.77259
Policy Entropy: 3.75139
Value Function Loss: 0.01207

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14455
Policy Update Magnitude: 0.34715
Value Function Update Magnitude: 0.51994

Collected Steps per Second: 22,513.09499
Overall Steps per Second: 10,715.96665

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.66873

Cumulative Model Updates: 152,192
Cumulative Timesteps: 1,269,078,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,786.56645
Policy Entropy: 3.73602
Value Function Loss: 0.01305

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14750
Policy Update Magnitude: 0.36042
Value Function Update Magnitude: 0.50022

Collected Steps per Second: 22,472.50765
Overall Steps per Second: 10,638.24042

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.70303

Cumulative Model Updates: 152,198
Cumulative Timesteps: 1,269,128,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1269128982...
Checkpoint 1269128982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,417.60139
Policy Entropy: 3.74661
Value Function Loss: 0.01422

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.40157
Value Function Update Magnitude: 0.54297

Collected Steps per Second: 22,085.58839
Overall Steps per Second: 10,519.73364

Timestep Collection Time: 2.26510
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.75544

Cumulative Model Updates: 152,204
Cumulative Timesteps: 1,269,179,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343,932.71587
Policy Entropy: 3.75320
Value Function Loss: 0.01609

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.44275
Value Function Update Magnitude: 0.56323

Collected Steps per Second: 22,496.74249
Overall Steps per Second: 10,759.64140

Timestep Collection Time: 2.22263
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.64718

Cumulative Model Updates: 152,210
Cumulative Timesteps: 1,269,229,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1269229010...
Checkpoint 1269229010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,085.09721
Policy Entropy: 3.76622
Value Function Loss: 0.01498

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.45648
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 21,988.45558
Overall Steps per Second: 10,632.46392

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.43002
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.70521

Cumulative Model Updates: 152,216
Cumulative Timesteps: 1,269,279,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,085.09721
Policy Entropy: 3.74721
Value Function Loss: 0.01693

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.44529
Value Function Update Magnitude: 0.57204

Collected Steps per Second: 21,969.88307
Overall Steps per Second: 10,518.06272

Timestep Collection Time: 2.27803
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.75829

Cumulative Model Updates: 152,222
Cumulative Timesteps: 1,269,329,086

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1269329086...
Checkpoint 1269329086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,085.09721
Policy Entropy: 3.73897
Value Function Loss: 0.01729

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.44640
Value Function Update Magnitude: 0.47940

Collected Steps per Second: 22,463.75373
Overall Steps per Second: 10,705.24355

Timestep Collection Time: 2.22670
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.67248

Cumulative Model Updates: 152,228
Cumulative Timesteps: 1,269,379,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,450.29227
Policy Entropy: 3.73963
Value Function Loss: 0.01930

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.47794
Value Function Update Magnitude: 0.47181

Collected Steps per Second: 22,595.19138
Overall Steps per Second: 10,784.14552

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.42484
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.63885

Cumulative Model Updates: 152,234
Cumulative Timesteps: 1,269,429,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1269429132...
Checkpoint 1269429132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,889.97902
Policy Entropy: 3.75141
Value Function Loss: 0.01970

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.46356
Value Function Update Magnitude: 0.42171

Collected Steps per Second: 22,278.72322
Overall Steps per Second: 10,749.02179

Timestep Collection Time: 2.24519
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.65345

Cumulative Model Updates: 152,240
Cumulative Timesteps: 1,269,479,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,889.97902
Policy Entropy: 3.74534
Value Function Loss: 0.02382

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.43883
Value Function Update Magnitude: 0.32753

Collected Steps per Second: 22,764.05775
Overall Steps per Second: 10,830.39127

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.61867

Cumulative Model Updates: 152,246
Cumulative Timesteps: 1,269,529,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1269529174...
Checkpoint 1269529174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,889.97902
Policy Entropy: 3.73523
Value Function Loss: 0.02079

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.45414
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 22,574.93445
Overall Steps per Second: 10,694.36462

Timestep Collection Time: 2.21564
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.67704

Cumulative Model Updates: 152,252
Cumulative Timesteps: 1,269,579,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,889.97902
Policy Entropy: 3.72606
Value Function Loss: 0.02038

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.44701
Value Function Update Magnitude: 0.36967

Collected Steps per Second: 21,403.21673
Overall Steps per Second: 10,473.24335

Timestep Collection Time: 2.33684
Timestep Consumption Time: 2.43875
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.77560

Cumulative Model Updates: 152,258
Cumulative Timesteps: 1,269,629,208

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1269629208...
Checkpoint 1269629208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,735.57903
Policy Entropy: 3.75049
Value Function Loss: 0.01658

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.46092
Value Function Update Magnitude: 0.50584

Collected Steps per Second: 21,830.72210
Overall Steps per Second: 10,588.29603

Timestep Collection Time: 2.29063
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.72276

Cumulative Model Updates: 152,264
Cumulative Timesteps: 1,269,679,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,104.44670
Policy Entropy: 3.77149
Value Function Loss: 0.01720

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.47654
Value Function Update Magnitude: 0.58133

Collected Steps per Second: 21,931.20573
Overall Steps per Second: 10,475.79057

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.77329

Cumulative Model Updates: 152,270
Cumulative Timesteps: 1,269,729,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1269729218...
Checkpoint 1269729218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,833.11117
Policy Entropy: 3.79332
Value Function Loss: 0.01673

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.46675
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 22,014.50746
Overall Steps per Second: 10,629.97038

Timestep Collection Time: 2.27187
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.70500

Cumulative Model Updates: 152,276
Cumulative Timesteps: 1,269,779,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,727.71454
Policy Entropy: 3.76809
Value Function Loss: 0.02171

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.50576
Value Function Update Magnitude: 0.82384

Collected Steps per Second: 22,930.02299
Overall Steps per Second: 10,692.21783

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.67705

Cumulative Model Updates: 152,282
Cumulative Timesteps: 1,269,829,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1269829240...
Checkpoint 1269829240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,966.01575
Policy Entropy: 3.76712
Value Function Loss: 0.02238

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.61385
Value Function Update Magnitude: 0.95225

Collected Steps per Second: 21,610.41736
Overall Steps per Second: 10,629.97968

Timestep Collection Time: 2.31379
Timestep Consumption Time: 2.39007
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.70387

Cumulative Model Updates: 152,288
Cumulative Timesteps: 1,269,879,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,900.04774
Policy Entropy: 3.77359
Value Function Loss: 0.02549

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.66979
Value Function Update Magnitude: 0.82556

Collected Steps per Second: 21,748.01366
Overall Steps per Second: 10,694.47415

Timestep Collection Time: 2.29989
Timestep Consumption Time: 2.37711
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.67699

Cumulative Model Updates: 152,294
Cumulative Timesteps: 1,269,929,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1269929260...
Checkpoint 1269929260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,659.99327
Policy Entropy: 3.80721
Value Function Loss: 0.02607

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12165
Policy Update Magnitude: 0.70663
Value Function Update Magnitude: 0.85388

Collected Steps per Second: 21,945.17566
Overall Steps per Second: 10,626.04206

Timestep Collection Time: 2.27968
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70806

Cumulative Model Updates: 152,300
Cumulative Timesteps: 1,269,979,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,446.03332
Policy Entropy: 3.82189
Value Function Loss: 0.02601

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.75889
Value Function Update Magnitude: 0.92549

Collected Steps per Second: 22,159.98025
Overall Steps per Second: 10,849.56522

Timestep Collection Time: 2.25632
Timestep Consumption Time: 2.35216
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.60848

Cumulative Model Updates: 152,306
Cumulative Timesteps: 1,270,029,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1270029288...
Checkpoint 1270029288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,001.92631
Policy Entropy: 3.78180
Value Function Loss: 0.02662

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.76949
Value Function Update Magnitude: 0.93025

Collected Steps per Second: 21,837.63812
Overall Steps per Second: 10,739.89938

Timestep Collection Time: 2.28962
Timestep Consumption Time: 2.36591
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.65554

Cumulative Model Updates: 152,312
Cumulative Timesteps: 1,270,079,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,611.58947
Policy Entropy: 3.79115
Value Function Loss: 0.02630

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13650
Policy Update Magnitude: 0.71158
Value Function Update Magnitude: 0.85740

Collected Steps per Second: 21,750.12505
Overall Steps per Second: 10,416.91937

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.50225
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.80219

Cumulative Model Updates: 152,318
Cumulative Timesteps: 1,270,129,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1270129312...
Checkpoint 1270129312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,064.81486
Policy Entropy: 3.78806
Value Function Loss: 0.02633

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.67215
Value Function Update Magnitude: 0.69455

Collected Steps per Second: 22,245.38901
Overall Steps per Second: 10,670.72332

Timestep Collection Time: 2.24901
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.68853

Cumulative Model Updates: 152,324
Cumulative Timesteps: 1,270,179,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,406.27129
Policy Entropy: 3.81018
Value Function Loss: 0.02569

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15085
Policy Update Magnitude: 0.62827
Value Function Update Magnitude: 0.66121

Collected Steps per Second: 22,267.01586
Overall Steps per Second: 10,640.82221

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.45410
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.70020

Cumulative Model Updates: 152,330
Cumulative Timesteps: 1,270,229,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1270229356...
Checkpoint 1270229356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,948.73784
Policy Entropy: 3.78218
Value Function Loss: 0.02254

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.62991
Value Function Update Magnitude: 0.67301

Collected Steps per Second: 21,973.28094
Overall Steps per Second: 10,558.51469

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.46071
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.73684

Cumulative Model Updates: 152,336
Cumulative Timesteps: 1,270,279,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,608.41052
Policy Entropy: 3.78539
Value Function Loss: 0.02402

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.66666
Value Function Update Magnitude: 0.59280

Collected Steps per Second: 22,520.62916
Overall Steps per Second: 10,704.09882

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.67260

Cumulative Model Updates: 152,342
Cumulative Timesteps: 1,270,329,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1270329386...
Checkpoint 1270329386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 976.89861
Policy Entropy: 3.79263
Value Function Loss: 0.02284

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.60796
Value Function Update Magnitude: 0.54488

Collected Steps per Second: 22,523.07140
Overall Steps per Second: 10,676.18584

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.68332

Cumulative Model Updates: 152,348
Cumulative Timesteps: 1,270,379,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,014.42441
Policy Entropy: 3.80687
Value Function Loss: 0.02515

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13073
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.52616

Collected Steps per Second: 22,896.34979
Overall Steps per Second: 10,851.96450

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.42409
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.60820

Cumulative Model Updates: 152,354
Cumulative Timesteps: 1,270,429,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1270429394...
Checkpoint 1270429394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,375.96513
Policy Entropy: 3.81929
Value Function Loss: 0.02650

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.53382

Collected Steps per Second: 22,349.41776
Overall Steps per Second: 10,729.19881

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.66242

Cumulative Model Updates: 152,360
Cumulative Timesteps: 1,270,479,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,268.59567
Policy Entropy: 3.81676
Value Function Loss: 0.02571

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11784
Policy Update Magnitude: 0.60589
Value Function Update Magnitude: 0.75255

Collected Steps per Second: 22,965.69149
Overall Steps per Second: 10,845.56971

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.61368

Cumulative Model Updates: 152,366
Cumulative Timesteps: 1,270,529,456

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1270529456...
Checkpoint 1270529456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270,113.88913
Policy Entropy: 3.82430
Value Function Loss: 0.02582

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.79358

Collected Steps per Second: 22,670.92170
Overall Steps per Second: 10,794.27414

Timestep Collection Time: 2.20670
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.63468

Cumulative Model Updates: 152,372
Cumulative Timesteps: 1,270,579,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,167.42203
Policy Entropy: 3.80871
Value Function Loss: 0.02574

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.52881
Value Function Update Magnitude: 0.57909

Collected Steps per Second: 22,763.94811
Overall Steps per Second: 10,814.34836

Timestep Collection Time: 2.19760
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.62589

Cumulative Model Updates: 152,378
Cumulative Timesteps: 1,270,629,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1270629510...
Checkpoint 1270629510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,490.00753
Policy Entropy: 3.80477
Value Function Loss: 0.02550

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.50428
Value Function Update Magnitude: 0.51082

Collected Steps per Second: 22,040.43464
Overall Steps per Second: 10,656.35216

Timestep Collection Time: 2.26919
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.69335

Cumulative Model Updates: 152,384
Cumulative Timesteps: 1,270,679,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,531.40354
Policy Entropy: 3.78951
Value Function Loss: 0.02725

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.50326
Value Function Update Magnitude: 0.55046

Collected Steps per Second: 22,303.06204
Overall Steps per Second: 10,495.01479

Timestep Collection Time: 2.24265
Timestep Consumption Time: 2.52323
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.76588

Cumulative Model Updates: 152,390
Cumulative Timesteps: 1,270,729,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1270729542...
Checkpoint 1270729542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,178.27726
Policy Entropy: 3.78284
Value Function Loss: 0.02492

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.50809
Value Function Update Magnitude: 0.57855

Collected Steps per Second: 22,261.54822
Overall Steps per Second: 10,707.62347

Timestep Collection Time: 2.24629
Timestep Consumption Time: 2.42384
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.67013

Cumulative Model Updates: 152,396
Cumulative Timesteps: 1,270,779,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,127.97249
Policy Entropy: 3.77290
Value Function Loss: 0.02459

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.48882
Value Function Update Magnitude: 0.57574

Collected Steps per Second: 22,364.77499
Overall Steps per Second: 10,572.87201

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.73173

Cumulative Model Updates: 152,402
Cumulative Timesteps: 1,270,829,576

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1270829576...
Checkpoint 1270829576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,619.23594
Policy Entropy: 3.78338
Value Function Loss: 0.02162

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.49414
Value Function Update Magnitude: 0.59743

Collected Steps per Second: 22,604.43931
Overall Steps per Second: 10,529.43045

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.53705
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.74935

Cumulative Model Updates: 152,408
Cumulative Timesteps: 1,270,879,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,332.48869
Policy Entropy: 3.77748
Value Function Loss: 0.02081

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.50377
Value Function Update Magnitude: 0.58445

Collected Steps per Second: 23,051.46259
Overall Steps per Second: 10,830.78508

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.61924

Cumulative Model Updates: 152,414
Cumulative Timesteps: 1,270,929,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1270929614...
Checkpoint 1270929614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230,551.42637
Policy Entropy: 3.78057
Value Function Loss: 0.01914

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12358
Policy Update Magnitude: 0.49516
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 22,784.36698
Overall Steps per Second: 10,669.44621

Timestep Collection Time: 2.19545
Timestep Consumption Time: 2.49289
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68834

Cumulative Model Updates: 152,420
Cumulative Timesteps: 1,270,979,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,397.90292
Policy Entropy: 3.77877
Value Function Loss: 0.01807

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.46971
Value Function Update Magnitude: 0.62445

Collected Steps per Second: 22,973.91874
Overall Steps per Second: 10,859.08444

Timestep Collection Time: 2.17656
Timestep Consumption Time: 2.42825
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.60481

Cumulative Model Updates: 152,426
Cumulative Timesteps: 1,271,029,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1271029640...
Checkpoint 1271029640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,117.36881
Policy Entropy: 3.76506
Value Function Loss: 0.01769

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.45604
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 22,423.96687
Overall Steps per Second: 10,665.16838

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.68872

Cumulative Model Updates: 152,432
Cumulative Timesteps: 1,271,079,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,117.36881
Policy Entropy: 3.75811
Value Function Loss: 0.02048

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.45355
Value Function Update Magnitude: 0.47992

Collected Steps per Second: 22,629.45302
Overall Steps per Second: 10,671.61887

Timestep Collection Time: 2.20986
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.68607

Cumulative Model Updates: 152,438
Cumulative Timesteps: 1,271,129,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1271129654...
Checkpoint 1271129654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,417.05837
Policy Entropy: 3.76422
Value Function Loss: 0.01835

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.44950
Value Function Update Magnitude: 0.48418

Collected Steps per Second: 21,993.32972
Overall Steps per Second: 10,485.65384

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.77071

Cumulative Model Updates: 152,444
Cumulative Timesteps: 1,271,179,678

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,347.87522
Policy Entropy: 3.77136
Value Function Loss: 0.01897

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13065
Policy Update Magnitude: 0.43072
Value Function Update Magnitude: 0.53870

Collected Steps per Second: 22,728.62188
Overall Steps per Second: 10,813.80834

Timestep Collection Time: 2.20172
Timestep Consumption Time: 2.42588
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.62760

Cumulative Model Updates: 152,450
Cumulative Timesteps: 1,271,229,720

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1271229720...
Checkpoint 1271229720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.32513
Policy Entropy: 3.78528
Value Function Loss: 0.01735

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.41930
Value Function Update Magnitude: 0.44804

Collected Steps per Second: 22,002.72375
Overall Steps per Second: 10,645.49887

Timestep Collection Time: 2.27363
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.69926

Cumulative Model Updates: 152,456
Cumulative Timesteps: 1,271,279,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 613.45400
Policy Entropy: 3.76349
Value Function Loss: 0.02058

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.44250
Value Function Update Magnitude: 0.50627

Collected Steps per Second: 22,164.98785
Overall Steps per Second: 10,520.86085

Timestep Collection Time: 2.25680
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.75455

Cumulative Model Updates: 152,462
Cumulative Timesteps: 1,271,329,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1271329768...
Checkpoint 1271329768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,633.56720
Policy Entropy: 3.76747
Value Function Loss: 0.01948

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.50318
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 22,230.18305
Overall Steps per Second: 10,610.60306

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.46416
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.71434

Cumulative Model Updates: 152,468
Cumulative Timesteps: 1,271,379,790

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,733.41594
Policy Entropy: 3.74486
Value Function Loss: 0.02215

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13536
Policy Update Magnitude: 0.52012
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 22,665.63468
Overall Steps per Second: 10,549.71555

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.53480
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.74193

Cumulative Model Updates: 152,474
Cumulative Timesteps: 1,271,429,816

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1271429816...
Checkpoint 1271429816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,484.78941
Policy Entropy: 3.75103
Value Function Loss: 0.01848

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.51457
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 22,391.81421
Overall Steps per Second: 10,550.14277

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.50651
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.73965

Cumulative Model Updates: 152,480
Cumulative Timesteps: 1,271,479,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,284.33919
Policy Entropy: 3.74262
Value Function Loss: 0.01790

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.50136
Value Function Update Magnitude: 0.66724

Collected Steps per Second: 21,884.68863
Overall Steps per Second: 10,468.46638

Timestep Collection Time: 2.28525
Timestep Consumption Time: 2.49214
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.77740

Cumulative Model Updates: 152,486
Cumulative Timesteps: 1,271,529,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1271529832...
Checkpoint 1271529832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,284.33919
Policy Entropy: 3.74263
Value Function Loss: 0.01725

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.48823
Value Function Update Magnitude: 0.56249

Collected Steps per Second: 21,416.72386
Overall Steps per Second: 10,689.13336

Timestep Collection Time: 2.33472
Timestep Consumption Time: 2.34312
PPO Batch Consumption Time: 0.27541
Total Iteration Time: 4.67783

Cumulative Model Updates: 152,492
Cumulative Timesteps: 1,271,579,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,876.04584
Policy Entropy: 3.74271
Value Function Loss: 0.01801

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13276
Policy Update Magnitude: 0.49147
Value Function Update Magnitude: 0.49422

Collected Steps per Second: 21,857.06375
Overall Steps per Second: 10,786.38743

Timestep Collection Time: 2.28814
Timestep Consumption Time: 2.34845
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.63658

Cumulative Model Updates: 152,498
Cumulative Timesteps: 1,271,629,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1271629846...
Checkpoint 1271629846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,904.09784
Policy Entropy: 3.74322
Value Function Loss: 0.01776

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.50896
Value Function Update Magnitude: 0.52942

Collected Steps per Second: 21,953.37632
Overall Steps per Second: 10,757.48119

Timestep Collection Time: 2.27765
Timestep Consumption Time: 2.37047
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.64811

Cumulative Model Updates: 152,504
Cumulative Timesteps: 1,271,679,848

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,055.07404
Policy Entropy: 3.75554
Value Function Loss: 0.01862

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13917
Policy Update Magnitude: 0.53162
Value Function Update Magnitude: 0.63632

Collected Steps per Second: 22,304.53957
Overall Steps per Second: 10,754.24116

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.40802
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.65007

Cumulative Model Updates: 152,510
Cumulative Timesteps: 1,271,729,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1271729856...
Checkpoint 1271729856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,754.23117
Policy Entropy: 3.76695
Value Function Loss: 0.01949

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.64400

Collected Steps per Second: 22,508.01586
Overall Steps per Second: 10,704.17023

Timestep Collection Time: 2.22188
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.67201

Cumulative Model Updates: 152,516
Cumulative Timesteps: 1,271,779,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,620.81929
Policy Entropy: 3.77769
Value Function Loss: 0.02150

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.51940
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,927.22307
Overall Steps per Second: 10,876.43156

Timestep Collection Time: 2.18134
Timestep Consumption Time: 2.41686
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.59820

Cumulative Model Updates: 152,522
Cumulative Timesteps: 1,271,829,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1271829878...
Checkpoint 1271829878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,716.37523
Policy Entropy: 3.79037
Value Function Loss: 0.02200

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.56646
Value Function Update Magnitude: 0.65360

Collected Steps per Second: 22,295.02128
Overall Steps per Second: 10,743.90454

Timestep Collection Time: 2.24319
Timestep Consumption Time: 2.41173
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65492

Cumulative Model Updates: 152,528
Cumulative Timesteps: 1,271,879,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,941.38080
Policy Entropy: 3.78638
Value Function Loss: 0.02129

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.57760
Value Function Update Magnitude: 0.71286

Collected Steps per Second: 23,158.39300
Overall Steps per Second: 10,932.50392

Timestep Collection Time: 2.16120
Timestep Consumption Time: 2.41689
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.57809

Cumulative Model Updates: 152,534
Cumulative Timesteps: 1,271,929,940

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1271929940...
Checkpoint 1271929940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,667.48465
Policy Entropy: 3.77523
Value Function Loss: 0.02260

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.82270

Collected Steps per Second: 22,108.30834
Overall Steps per Second: 10,574.48357

Timestep Collection Time: 2.26186
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.72893

Cumulative Model Updates: 152,540
Cumulative Timesteps: 1,271,979,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,326.83295
Policy Entropy: 3.75891
Value Function Loss: 0.02615

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.61760
Value Function Update Magnitude: 0.80398

Collected Steps per Second: 22,161.51895
Overall Steps per Second: 10,523.62525

Timestep Collection Time: 2.25725
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.75349

Cumulative Model Updates: 152,546
Cumulative Timesteps: 1,272,029,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1272029970...
Checkpoint 1272029970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,357.34292
Policy Entropy: 3.75861
Value Function Loss: 0.02630

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13286
Policy Update Magnitude: 0.63945
Value Function Update Magnitude: 0.76162

Collected Steps per Second: 22,130.01652
Overall Steps per Second: 10,600.92761

Timestep Collection Time: 2.26055
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.71902

Cumulative Model Updates: 152,552
Cumulative Timesteps: 1,272,079,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,291.92638
Policy Entropy: 3.76897
Value Function Loss: 0.02875

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.63537
Value Function Update Magnitude: 0.67327

Collected Steps per Second: 22,355.77424
Overall Steps per Second: 10,613.19338

Timestep Collection Time: 2.23736
Timestep Consumption Time: 2.47545
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.71281

Cumulative Model Updates: 152,558
Cumulative Timesteps: 1,272,130,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1272130014...
Checkpoint 1272130014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,673.65169
Policy Entropy: 3.76925
Value Function Loss: 0.02423

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.62884
Value Function Update Magnitude: 0.59232

Collected Steps per Second: 22,101.02218
Overall Steps per Second: 10,441.14572

Timestep Collection Time: 2.26234
Timestep Consumption Time: 2.52641
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78875

Cumulative Model Updates: 152,564
Cumulative Timesteps: 1,272,180,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,347.75304
Policy Entropy: 3.77288
Value Function Loss: 0.02565

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.63896
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 22,700.88913
Overall Steps per Second: 10,557.71287

Timestep Collection Time: 2.20256
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.73587

Cumulative Model Updates: 152,570
Cumulative Timesteps: 1,272,230,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1272230014...
Checkpoint 1272230014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,970.41113
Policy Entropy: 3.78707
Value Function Loss: 0.02342

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.64114
Value Function Update Magnitude: 0.59527

Collected Steps per Second: 22,342.18886
Overall Steps per Second: 10,543.23567

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.50566
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.74465

Cumulative Model Updates: 152,576
Cumulative Timesteps: 1,272,280,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,157.22712
Policy Entropy: 3.77142
Value Function Loss: 0.02402

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.66098
Value Function Update Magnitude: 0.63170

Collected Steps per Second: 22,774.27837
Overall Steps per Second: 10,822.47569

Timestep Collection Time: 2.19572
Timestep Consumption Time: 2.42485
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.62057

Cumulative Model Updates: 152,582
Cumulative Timesteps: 1,272,330,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1272330044...
Checkpoint 1272330044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,807.31416
Policy Entropy: 3.76315
Value Function Loss: 0.02276

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.66454
Value Function Update Magnitude: 0.55174

Collected Steps per Second: 22,117.99770
Overall Steps per Second: 10,664.35863

Timestep Collection Time: 2.26151
Timestep Consumption Time: 2.42888
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.69039

Cumulative Model Updates: 152,588
Cumulative Timesteps: 1,272,380,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,919.24249
Policy Entropy: 3.75044
Value Function Loss: 0.02476

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.65222
Value Function Update Magnitude: 0.54246

Collected Steps per Second: 22,875.73154
Overall Steps per Second: 10,720.71908

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.48003
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.66741

Cumulative Model Updates: 152,594
Cumulative Timesteps: 1,272,430,102

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1272430102...
Checkpoint 1272430102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,173.97094
Policy Entropy: 3.75918
Value Function Loss: 0.02278

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.71176
Value Function Update Magnitude: 0.72118

Collected Steps per Second: 22,488.64372
Overall Steps per Second: 10,673.07390

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.68637

Cumulative Model Updates: 152,600
Cumulative Timesteps: 1,272,480,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,960.46293
Policy Entropy: 3.76683
Value Function Loss: 0.02408

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.67386
Value Function Update Magnitude: 0.76083

Collected Steps per Second: 21,719.55618
Overall Steps per Second: 10,613.79771

Timestep Collection Time: 2.30327
Timestep Consumption Time: 2.41003
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.71330

Cumulative Model Updates: 152,606
Cumulative Timesteps: 1,272,530,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1272530146...
Checkpoint 1272530146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,433.11623
Policy Entropy: 3.77497
Value Function Loss: 0.02277

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.66555
Value Function Update Magnitude: 0.65322

Collected Steps per Second: 21,696.42066
Overall Steps per Second: 10,444.09778

Timestep Collection Time: 2.30545
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.78931

Cumulative Model Updates: 152,612
Cumulative Timesteps: 1,272,580,166

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299,340.63107
Policy Entropy: 3.78136
Value Function Loss: 0.02278

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15284
Policy Update Magnitude: 0.71258
Value Function Update Magnitude: 0.53409

Collected Steps per Second: 22,584.59120
Overall Steps per Second: 10,824.76701

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.40629
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.62125

Cumulative Model Updates: 152,618
Cumulative Timesteps: 1,272,630,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1272630190...
Checkpoint 1272630190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,454.54719
Policy Entropy: 3.79500
Value Function Loss: 0.02008

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.65092
Value Function Update Magnitude: 0.57604

Collected Steps per Second: 22,382.20181
Overall Steps per Second: 10,575.69452

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.49400
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.72801

Cumulative Model Updates: 152,624
Cumulative Timesteps: 1,272,680,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,543.91520
Policy Entropy: 3.79286
Value Function Loss: 0.01978

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.14548
Policy Update Magnitude: 0.67333
Value Function Update Magnitude: 0.74160

Collected Steps per Second: 22,400.05117
Overall Steps per Second: 10,940.90132

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.33824
PPO Batch Consumption Time: 0.27596
Total Iteration Time: 4.57074

Cumulative Model Updates: 152,630
Cumulative Timesteps: 1,272,730,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1272730200...
Checkpoint 1272730200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,719.37623
Policy Entropy: 3.79837
Value Function Loss: 0.01923

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.77966
Value Function Update Magnitude: 0.95917

Collected Steps per Second: 22,152.47556
Overall Steps per Second: 10,725.62925

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.40513
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.66266

Cumulative Model Updates: 152,636
Cumulative Timesteps: 1,272,780,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,318.74749
Policy Entropy: 3.79444
Value Function Loss: 0.01955

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.78688
Value Function Update Magnitude: 1.02593

Collected Steps per Second: 22,446.21567
Overall Steps per Second: 10,792.19054

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.63465

Cumulative Model Updates: 152,642
Cumulative Timesteps: 1,272,830,228

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1272830228...
Checkpoint 1272830228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,119.39745
Policy Entropy: 3.80931
Value Function Loss: 0.01798

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.76125
Value Function Update Magnitude: 0.96808

Collected Steps per Second: 21,648.73522
Overall Steps per Second: 10,597.60592

Timestep Collection Time: 2.30988
Timestep Consumption Time: 2.40873
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71861

Cumulative Model Updates: 152,648
Cumulative Timesteps: 1,272,880,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,695.10620
Policy Entropy: 3.77869
Value Function Loss: 0.01871

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.71687
Value Function Update Magnitude: 0.86614

Collected Steps per Second: 22,010.38316
Overall Steps per Second: 10,531.49189

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.74956

Cumulative Model Updates: 152,654
Cumulative Timesteps: 1,272,930,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1272930254...
Checkpoint 1272930254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,044.49109
Policy Entropy: 3.77420
Value Function Loss: 0.02022

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.19410
Policy Update Magnitude: 0.59412
Value Function Update Magnitude: 0.88674

Collected Steps per Second: 22,379.29074
Overall Steps per Second: 10,623.81669

Timestep Collection Time: 2.23626
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.71074

Cumulative Model Updates: 152,660
Cumulative Timesteps: 1,272,980,300

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,356.13031
Policy Entropy: 3.81238
Value Function Loss: 0.02306

Mean KL Divergence: 0.02431
SB3 Clip Fraction: 0.25825
Policy Update Magnitude: 0.53453
Value Function Update Magnitude: 0.73502

Collected Steps per Second: 22,056.40345
Overall Steps per Second: 10,586.45031

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.45640
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.72359

Cumulative Model Updates: 152,666
Cumulative Timesteps: 1,273,030,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1273030306...
Checkpoint 1273030306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.33749
Policy Entropy: 3.82705
Value Function Loss: 0.02293

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.17524
Policy Update Magnitude: 0.48541
Value Function Update Magnitude: 0.60878

Collected Steps per Second: 22,028.40119
Overall Steps per Second: 10,598.26678

Timestep Collection Time: 2.27034
Timestep Consumption Time: 2.44854
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.71888

Cumulative Model Updates: 152,672
Cumulative Timesteps: 1,273,080,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,995.36126
Policy Entropy: 3.83342
Value Function Loss: 0.02666

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08495
Policy Update Magnitude: 0.59387
Value Function Update Magnitude: 0.48388

Collected Steps per Second: 22,880.71913
Overall Steps per Second: 10,775.39432

Timestep Collection Time: 2.18612
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.64206

Cumulative Model Updates: 152,678
Cumulative Timesteps: 1,273,130,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1273130338...
Checkpoint 1273130338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,170.49499
Policy Entropy: 3.79642
Value Function Loss: 0.02349

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.61885
Value Function Update Magnitude: 0.37148

Collected Steps per Second: 22,184.94625
Overall Steps per Second: 10,715.06927

Timestep Collection Time: 2.25495
Timestep Consumption Time: 2.41380
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.66875

Cumulative Model Updates: 152,684
Cumulative Timesteps: 1,273,180,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,936.34108
Policy Entropy: 3.77183
Value Function Loss: 0.02399

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.19850
Policy Update Magnitude: 0.52634
Value Function Update Magnitude: 0.35135

Collected Steps per Second: 22,589.93476
Overall Steps per Second: 10,536.17622

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.53380
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.74859

Cumulative Model Updates: 152,690
Cumulative Timesteps: 1,273,230,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1273230396...
Checkpoint 1273230396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,658.38915
Policy Entropy: 3.75457
Value Function Loss: 0.02271

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.23091
Policy Update Magnitude: 0.48399
Value Function Update Magnitude: 0.40309

Collected Steps per Second: 22,323.01610
Overall Steps per Second: 10,552.52248

Timestep Collection Time: 2.23984
Timestep Consumption Time: 2.49836
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.73820

Cumulative Model Updates: 152,696
Cumulative Timesteps: 1,273,280,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,352.84978
Policy Entropy: 3.78226
Value Function Loss: 0.02569

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.20873
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.38608

Collected Steps per Second: 22,213.25273
Overall Steps per Second: 10,562.28271

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.73420

Cumulative Model Updates: 152,702
Cumulative Timesteps: 1,273,330,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1273330400...
Checkpoint 1273330400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,393.49333
Policy Entropy: 3.82581
Value Function Loss: 0.02592

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.20014
Policy Update Magnitude: 0.52640
Value Function Update Magnitude: 0.48779

Collected Steps per Second: 22,114.46144
Overall Steps per Second: 10,529.98208

Timestep Collection Time: 2.26133
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.74911

Cumulative Model Updates: 152,708
Cumulative Timesteps: 1,273,380,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,224.53602
Policy Entropy: 3.84265
Value Function Loss: 0.02618

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.18422
Policy Update Magnitude: 0.61960
Value Function Update Magnitude: 0.71846

Collected Steps per Second: 21,486.61443
Overall Steps per Second: 10,369.76404

Timestep Collection Time: 2.32787
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.82345

Cumulative Model Updates: 152,714
Cumulative Timesteps: 1,273,430,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1273430426...
Checkpoint 1273430426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,946.61194
Policy Entropy: 3.85160
Value Function Loss: 0.02893

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.20774
Policy Update Magnitude: 0.67583
Value Function Update Magnitude: 0.73099

Collected Steps per Second: 22,242.17764
Overall Steps per Second: 10,741.56230

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.40770
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.65649

Cumulative Model Updates: 152,720
Cumulative Timesteps: 1,273,480,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,947.58859
Policy Entropy: 3.85208
Value Function Loss: 0.03267

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15488
Policy Update Magnitude: 0.72401
Value Function Update Magnitude: 0.72389

Collected Steps per Second: 23,049.26437
Overall Steps per Second: 10,851.18946

Timestep Collection Time: 2.17083
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.61111

Cumulative Model Updates: 152,726
Cumulative Timesteps: 1,273,530,480

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1273530480...
Checkpoint 1273530480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,807.43979
Policy Entropy: 3.86682
Value Function Loss: 0.03099

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.73733
Value Function Update Magnitude: 0.58413

Collected Steps per Second: 22,238.18726
Overall Steps per Second: 10,603.56151

Timestep Collection Time: 2.24838
Timestep Consumption Time: 2.46701
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.71540

Cumulative Model Updates: 152,732
Cumulative Timesteps: 1,273,580,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,622.27363
Policy Entropy: 3.89209
Value Function Loss: 0.03269

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14873
Policy Update Magnitude: 0.81436
Value Function Update Magnitude: 0.71332

Collected Steps per Second: 22,488.98724
Overall Steps per Second: 10,637.78504

Timestep Collection Time: 2.22349
Timestep Consumption Time: 2.47711
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.70060

Cumulative Model Updates: 152,738
Cumulative Timesteps: 1,273,630,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1273630484...
Checkpoint 1273630484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,682.37337
Policy Entropy: 3.92347
Value Function Loss: 0.03397

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.80470
Value Function Update Magnitude: 0.93334

Collected Steps per Second: 22,028.13360
Overall Steps per Second: 10,624.49176

Timestep Collection Time: 2.27010
Timestep Consumption Time: 2.43658
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.70667

Cumulative Model Updates: 152,744
Cumulative Timesteps: 1,273,680,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.79624
Policy Entropy: 3.93400
Value Function Loss: 0.03587

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.86876
Value Function Update Magnitude: 0.80897

Collected Steps per Second: 22,446.65688
Overall Steps per Second: 10,752.58855

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.42351
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.65190

Cumulative Model Updates: 152,750
Cumulative Timesteps: 1,273,730,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1273730510...
Checkpoint 1273730510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,061.71473
Policy Entropy: 3.94236
Value Function Loss: 0.03498

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.82025
Value Function Update Magnitude: 0.79863

Collected Steps per Second: 21,842.76867
Overall Steps per Second: 10,650.02309

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.40574
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.69483

Cumulative Model Updates: 152,756
Cumulative Timesteps: 1,273,780,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.07782
Policy Entropy: 3.91467
Value Function Loss: 0.03357

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.82409
Value Function Update Magnitude: 0.84998

Collected Steps per Second: 23,263.58043
Overall Steps per Second: 10,911.49356

Timestep Collection Time: 2.14937
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.58251

Cumulative Model Updates: 152,762
Cumulative Timesteps: 1,273,830,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1273830512...
Checkpoint 1273830512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,139.37386
Policy Entropy: 3.88674
Value Function Loss: 0.03107

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.76015
Value Function Update Magnitude: 0.92840

Collected Steps per Second: 22,352.46211
Overall Steps per Second: 10,614.82374

Timestep Collection Time: 2.23743
Timestep Consumption Time: 2.47410
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.71152

Cumulative Model Updates: 152,768
Cumulative Timesteps: 1,273,880,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,505.95720
Policy Entropy: 3.84356
Value Function Loss: 0.02992

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.67683
Value Function Update Magnitude: 0.92304

Collected Steps per Second: 23,029.88051
Overall Steps per Second: 10,960.32520

Timestep Collection Time: 2.17196
Timestep Consumption Time: 2.39177
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.56373

Cumulative Model Updates: 152,774
Cumulative Timesteps: 1,273,930,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1273930544...
Checkpoint 1273930544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,132.31247
Policy Entropy: 3.82760
Value Function Loss: 0.03114

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.64176
Value Function Update Magnitude: 0.83335

Collected Steps per Second: 22,407.10134
Overall Steps per Second: 10,647.47751

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69877

Cumulative Model Updates: 152,780
Cumulative Timesteps: 1,273,980,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.04451
Policy Entropy: 3.83492
Value Function Loss: 0.02892

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.60985
Value Function Update Magnitude: 0.74546

Collected Steps per Second: 23,094.77459
Overall Steps per Second: 10,894.88706

Timestep Collection Time: 2.16594
Timestep Consumption Time: 2.42538
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.59133

Cumulative Model Updates: 152,786
Cumulative Timesteps: 1,274,030,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1274030596...
Checkpoint 1274030596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,054.89488
Policy Entropy: 3.84832
Value Function Loss: 0.02881

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.69699

Collected Steps per Second: 22,182.06250
Overall Steps per Second: 10,664.22325

Timestep Collection Time: 2.25488
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.69026

Cumulative Model Updates: 152,792
Cumulative Timesteps: 1,274,080,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,038.48405
Policy Entropy: 3.83965
Value Function Loss: 0.02492

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.61970

Collected Steps per Second: 22,504.35688
Overall Steps per Second: 10,796.11718

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.63389

Cumulative Model Updates: 152,798
Cumulative Timesteps: 1,274,130,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1274130642...
Checkpoint 1274130642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,130.14324
Policy Entropy: 3.80257
Value Function Loss: 0.02288

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12526
Policy Update Magnitude: 0.52214
Value Function Update Magnitude: 0.66239

Collected Steps per Second: 21,929.00607
Overall Steps per Second: 10,643.50798

Timestep Collection Time: 2.28009
Timestep Consumption Time: 2.41761
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.69770

Cumulative Model Updates: 152,804
Cumulative Timesteps: 1,274,180,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,393.68648
Policy Entropy: 3.75630
Value Function Loss: 0.02189

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.50135
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 22,385.89499
Overall Steps per Second: 10,543.31033

Timestep Collection Time: 2.23462
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.74462

Cumulative Model Updates: 152,810
Cumulative Timesteps: 1,274,230,666

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1274230666...
Checkpoint 1274230666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,147.79434
Policy Entropy: 3.75865
Value Function Loss: 0.02232

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11876
Policy Update Magnitude: 0.50702
Value Function Update Magnitude: 0.53986

Collected Steps per Second: 22,219.78830
Overall Steps per Second: 10,707.98010

Timestep Collection Time: 2.25151
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.27524
Total Iteration Time: 4.67203

Cumulative Model Updates: 152,816
Cumulative Timesteps: 1,274,280,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,462.42678
Policy Entropy: 3.76163
Value Function Loss: 0.02191

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.51440
Value Function Update Magnitude: 0.54515

Collected Steps per Second: 23,068.19866
Overall Steps per Second: 10,810.92580

Timestep Collection Time: 2.16783
Timestep Consumption Time: 2.45786
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.62569

Cumulative Model Updates: 152,822
Cumulative Timesteps: 1,274,330,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1274330702...
Checkpoint 1274330702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,162.09114
Policy Entropy: 3.76687
Value Function Loss: 0.01939

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.48706
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 22,546.08820
Overall Steps per Second: 10,634.53407

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.70411

Cumulative Model Updates: 152,828
Cumulative Timesteps: 1,274,380,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,162.09114
Policy Entropy: 3.76461
Value Function Loss: 0.01751

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.44720
Value Function Update Magnitude: 0.60269

Collected Steps per Second: 22,703.73912
Overall Steps per Second: 10,694.83048

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.67759

Cumulative Model Updates: 152,834
Cumulative Timesteps: 1,274,430,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1274430754...
Checkpoint 1274430754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,195.92170
Policy Entropy: 3.75807
Value Function Loss: 0.01755

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.41756
Value Function Update Magnitude: 0.56505

Collected Steps per Second: 22,579.73392
Overall Steps per Second: 10,811.25545

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.41150
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.62684

Cumulative Model Updates: 152,840
Cumulative Timesteps: 1,274,480,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,528.09385
Policy Entropy: 3.77629
Value Function Loss: 0.01962

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.40485
Value Function Update Magnitude: 0.52702

Collected Steps per Second: 22,751.42411
Overall Steps per Second: 10,671.48362

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68745

Cumulative Model Updates: 152,846
Cumulative Timesteps: 1,274,530,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1274530798...
Checkpoint 1274530798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,011.59843
Policy Entropy: 3.79209
Value Function Loss: 0.02146

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.40020
Value Function Update Magnitude: 0.57705

Collected Steps per Second: 22,786.57459
Overall Steps per Second: 10,845.81226

Timestep Collection Time: 2.19524
Timestep Consumption Time: 2.41686
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.61210

Cumulative Model Updates: 152,852
Cumulative Timesteps: 1,274,580,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,419.94058
Policy Entropy: 3.79558
Value Function Loss: 0.02101

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12689
Policy Update Magnitude: 0.40030
Value Function Update Magnitude: 0.59369

Collected Steps per Second: 22,327.91784
Overall Steps per Second: 10,558.20775

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.73622

Cumulative Model Updates: 152,858
Cumulative Timesteps: 1,274,630,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1274630826...
Checkpoint 1274630826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,321.59025
Policy Entropy: 3.77652
Value Function Loss: 0.02010

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.43532
Value Function Update Magnitude: 0.60884

Collected Steps per Second: 22,094.37419
Overall Steps per Second: 10,706.12811

Timestep Collection Time: 2.26338
Timestep Consumption Time: 2.40759
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.67097

Cumulative Model Updates: 152,864
Cumulative Timesteps: 1,274,680,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,654.13777
Policy Entropy: 3.76331
Value Function Loss: 0.01727

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 0.43835
Value Function Update Magnitude: 0.66260

Collected Steps per Second: 22,493.37906
Overall Steps per Second: 10,742.12580

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.65662

Cumulative Model Updates: 152,870
Cumulative Timesteps: 1,274,730,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1274730856...
Checkpoint 1274730856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,241.17517
Policy Entropy: 3.75830
Value Function Loss: 0.01785

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13093
Policy Update Magnitude: 0.45451
Value Function Update Magnitude: 0.70470

Collected Steps per Second: 22,157.57332
Overall Steps per Second: 10,683.33623

Timestep Collection Time: 2.25729
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.68168

Cumulative Model Updates: 152,876
Cumulative Timesteps: 1,274,780,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,803.74476
Policy Entropy: 3.76402
Value Function Loss: 0.01729

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.48919
Value Function Update Magnitude: 0.70863

Collected Steps per Second: 22,853.33084
Overall Steps per Second: 10,591.33582

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.53379
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72235

Cumulative Model Updates: 152,882
Cumulative Timesteps: 1,274,830,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1274830888...
Checkpoint 1274830888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,586.38504
Policy Entropy: 3.76926
Value Function Loss: 0.02113

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.47947
Value Function Update Magnitude: 0.62166

Collected Steps per Second: 22,581.87793
Overall Steps per Second: 10,627.32528

Timestep Collection Time: 2.21558
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.70786

Cumulative Model Updates: 152,888
Cumulative Timesteps: 1,274,880,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,267.55631
Policy Entropy: 3.80132
Value Function Loss: 0.02506

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.50265
Value Function Update Magnitude: 0.57525

Collected Steps per Second: 22,820.30630
Overall Steps per Second: 10,817.12216

Timestep Collection Time: 2.19217
Timestep Consumption Time: 2.43253
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.62471

Cumulative Model Updates: 152,894
Cumulative Timesteps: 1,274,930,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1274930946...
Checkpoint 1274930946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,568.57465
Policy Entropy: 3.80219
Value Function Loss: 0.03022

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.52224
Value Function Update Magnitude: 0.73592

Collected Steps per Second: 22,623.51158
Overall Steps per Second: 10,642.72101

Timestep Collection Time: 2.21142
Timestep Consumption Time: 2.48945
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.70087

Cumulative Model Updates: 152,900
Cumulative Timesteps: 1,274,980,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,601.56927
Policy Entropy: 3.79777
Value Function Loss: 0.02674

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.54590
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 22,744.21998
Overall Steps per Second: 10,827.65551

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.61873

Cumulative Model Updates: 152,906
Cumulative Timesteps: 1,275,030,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1275030986...
Checkpoint 1275030986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,195.80493
Policy Entropy: 3.74913
Value Function Loss: 0.02661

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.53259
Value Function Update Magnitude: 0.50588

Collected Steps per Second: 22,540.78182
Overall Steps per Second: 10,799.12837

Timestep Collection Time: 2.21891
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.63148

Cumulative Model Updates: 152,912
Cumulative Timesteps: 1,275,081,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,568.81091
Policy Entropy: 3.73157
Value Function Loss: 0.02291

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12708
Policy Update Magnitude: 0.52060
Value Function Update Magnitude: 0.44396

Collected Steps per Second: 22,246.94105
Overall Steps per Second: 10,542.04478

Timestep Collection Time: 2.24759
Timestep Consumption Time: 2.49551
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.74310

Cumulative Model Updates: 152,918
Cumulative Timesteps: 1,275,131,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1275131004...
Checkpoint 1275131004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,176.71536
Policy Entropy: 3.74010
Value Function Loss: 0.02740

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.52467
Value Function Update Magnitude: 0.43689

Collected Steps per Second: 22,132.14828
Overall Steps per Second: 10,531.65197

Timestep Collection Time: 2.25997
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.74930

Cumulative Model Updates: 152,924
Cumulative Timesteps: 1,275,181,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,392.62278
Policy Entropy: 3.75562
Value Function Loss: 0.02261

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.45493

Collected Steps per Second: 22,420.24299
Overall Steps per Second: 10,619.82234

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.70893

Cumulative Model Updates: 152,930
Cumulative Timesteps: 1,275,231,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1275231030...
Checkpoint 1275231030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,496.13301
Policy Entropy: 3.75986
Value Function Loss: 0.02247

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.52122
Value Function Update Magnitude: 0.57578

Collected Steps per Second: 22,082.97781
Overall Steps per Second: 10,485.36866

Timestep Collection Time: 2.26473
Timestep Consumption Time: 2.50496
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.76969

Cumulative Model Updates: 152,936
Cumulative Timesteps: 1,275,281,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,033.33870
Policy Entropy: 3.76388
Value Function Loss: 0.02169

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.54046
Value Function Update Magnitude: 0.67716

Collected Steps per Second: 22,558.01404
Overall Steps per Second: 10,537.93877

Timestep Collection Time: 2.21757
Timestep Consumption Time: 2.52947
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.74704

Cumulative Model Updates: 152,942
Cumulative Timesteps: 1,275,331,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1275331066...
Checkpoint 1275331066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,099.45928
Policy Entropy: 3.74987
Value Function Loss: 0.02138

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.58295
Value Function Update Magnitude: 0.67947

Collected Steps per Second: 22,578.23704
Overall Steps per Second: 10,637.28610

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70421

Cumulative Model Updates: 152,948
Cumulative Timesteps: 1,275,381,106

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,849.76943
Policy Entropy: 3.76605
Value Function Loss: 0.02041

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.57807

Collected Steps per Second: 22,954.19203
Overall Steps per Second: 10,785.69087

Timestep Collection Time: 2.17895
Timestep Consumption Time: 2.45831
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.63726

Cumulative Model Updates: 152,954
Cumulative Timesteps: 1,275,431,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1275431122...
Checkpoint 1275431122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,099.14043
Policy Entropy: 3.76936
Value Function Loss: 0.01990

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.49965
Value Function Update Magnitude: 0.43933

Collected Steps per Second: 22,559.82344
Overall Steps per Second: 10,642.79074

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.48318
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.70083

Cumulative Model Updates: 152,960
Cumulative Timesteps: 1,275,481,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,998.92496
Policy Entropy: 3.79122
Value Function Loss: 0.01954

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.46172

Collected Steps per Second: 22,670.80051
Overall Steps per Second: 10,799.17734

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.63165

Cumulative Model Updates: 152,966
Cumulative Timesteps: 1,275,531,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1275531170...
Checkpoint 1275531170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,986.37861
Policy Entropy: 3.78606
Value Function Loss: 0.02052

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.57809
Value Function Update Magnitude: 0.54211

Collected Steps per Second: 22,092.43960
Overall Steps per Second: 10,676.58612

Timestep Collection Time: 2.26421
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.68521

Cumulative Model Updates: 152,972
Cumulative Timesteps: 1,275,581,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,841.93978
Policy Entropy: 3.77794
Value Function Loss: 0.01969

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 22,258.26829
Overall Steps per Second: 10,521.97958

Timestep Collection Time: 2.24645
Timestep Consumption Time: 2.50570
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.75215

Cumulative Model Updates: 152,978
Cumulative Timesteps: 1,275,631,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1275631194...
Checkpoint 1275631194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,412.19645
Policy Entropy: 3.75256
Value Function Loss: 0.01795

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.54683
Value Function Update Magnitude: 0.55085

Collected Steps per Second: 21,872.96204
Overall Steps per Second: 10,609.55689

Timestep Collection Time: 2.28629
Timestep Consumption Time: 2.42719
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.71349

Cumulative Model Updates: 152,984
Cumulative Timesteps: 1,275,681,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,704.66778
Policy Entropy: 3.74560
Value Function Loss: 0.01805

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.51203
Value Function Update Magnitude: 0.45893

Collected Steps per Second: 22,077.92133
Overall Steps per Second: 10,463.00787

Timestep Collection Time: 2.26516
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.77970

Cumulative Model Updates: 152,990
Cumulative Timesteps: 1,275,731,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1275731212...
Checkpoint 1275731212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,556.48578
Policy Entropy: 3.75997
Value Function Loss: 0.01828

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.49635
Value Function Update Magnitude: 0.41873

Collected Steps per Second: 22,067.68323
Overall Steps per Second: 10,629.00659

Timestep Collection Time: 2.26621
Timestep Consumption Time: 2.43884
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.70505

Cumulative Model Updates: 152,996
Cumulative Timesteps: 1,275,781,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,287.21507
Policy Entropy: 3.75429
Value Function Loss: 0.01847

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.47824
Value Function Update Magnitude: 0.42148

Collected Steps per Second: 22,709.50293
Overall Steps per Second: 10,617.85021

Timestep Collection Time: 2.20190
Timestep Consumption Time: 2.50753
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.70943

Cumulative Model Updates: 153,002
Cumulative Timesteps: 1,275,831,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1275831226...
Checkpoint 1275831226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,287.21507
Policy Entropy: 3.74595
Value Function Loss: 0.02077

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12114
Policy Update Magnitude: 0.47455
Value Function Update Magnitude: 0.34636

Collected Steps per Second: 22,338.72395
Overall Steps per Second: 10,568.28917

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.73473

Cumulative Model Updates: 153,008
Cumulative Timesteps: 1,275,881,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,158.46598
Policy Entropy: 3.73149
Value Function Loss: 0.02016

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.32322

Collected Steps per Second: 22,570.06038
Overall Steps per Second: 10,770.02631

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.42826
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.64456

Cumulative Model Updates: 153,014
Cumulative Timesteps: 1,275,931,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1275931286...
Checkpoint 1275931286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,583.27335
Policy Entropy: 3.73265
Value Function Loss: 0.02247

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.50808
Value Function Update Magnitude: 0.33538

Collected Steps per Second: 22,209.37108
Overall Steps per Second: 10,750.22252

Timestep Collection Time: 2.25211
Timestep Consumption Time: 2.40063
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.65274

Cumulative Model Updates: 153,020
Cumulative Timesteps: 1,275,981,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,583.27335
Policy Entropy: 3.74132
Value Function Loss: 0.01936

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.52939
Value Function Update Magnitude: 0.41884

Collected Steps per Second: 22,405.31612
Overall Steps per Second: 10,552.07359

Timestep Collection Time: 2.23170
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.73859

Cumulative Model Updates: 153,026
Cumulative Timesteps: 1,276,031,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1276031306...
Checkpoint 1276031306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,772.23442
Policy Entropy: 3.75075
Value Function Loss: 0.02226

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.51730
Value Function Update Magnitude: 0.39522

Collected Steps per Second: 21,541.99762
Overall Steps per Second: 10,548.07772

Timestep Collection Time: 2.32235
Timestep Consumption Time: 2.42051
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.74285

Cumulative Model Updates: 153,032
Cumulative Timesteps: 1,276,081,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,794.61290
Policy Entropy: 3.76825
Value Function Loss: 0.01658

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.47716
Value Function Update Magnitude: 0.34993

Collected Steps per Second: 21,345.66468
Overall Steps per Second: 10,529.82096

Timestep Collection Time: 2.34286
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.74937

Cumulative Model Updates: 153,038
Cumulative Timesteps: 1,276,131,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1276131344...
Checkpoint 1276131344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,794.61290
Policy Entropy: 3.76302
Value Function Loss: 0.01514

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.43654
Value Function Update Magnitude: 0.41582

Collected Steps per Second: 20,994.41286
Overall Steps per Second: 10,508.40600

Timestep Collection Time: 2.38292
Timestep Consumption Time: 2.37784
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.76076

Cumulative Model Updates: 153,044
Cumulative Timesteps: 1,276,181,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,794.61290
Policy Entropy: 3.75123
Value Function Loss: 0.01517

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.42292
Value Function Update Magnitude: 0.34234

Collected Steps per Second: 21,570.18122
Overall Steps per Second: 10,483.02443

Timestep Collection Time: 2.31922
Timestep Consumption Time: 2.45288
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.77210

Cumulative Model Updates: 153,050
Cumulative Timesteps: 1,276,231,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1276231398...
Checkpoint 1276231398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,585.55767
Policy Entropy: 3.74791
Value Function Loss: 0.01668

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.44029
Value Function Update Magnitude: 0.34484

Collected Steps per Second: 21,761.89089
Overall Steps per Second: 10,673.98945

Timestep Collection Time: 2.29851
Timestep Consumption Time: 2.38764
PPO Batch Consumption Time: 0.27461
Total Iteration Time: 4.68616

Cumulative Model Updates: 153,056
Cumulative Timesteps: 1,276,281,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,369.57638
Policy Entropy: 3.76868
Value Function Loss: 0.01738

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.49287
Value Function Update Magnitude: 0.45526

Collected Steps per Second: 22,950.05275
Overall Steps per Second: 10,823.31704

Timestep Collection Time: 2.18030
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.62317

Cumulative Model Updates: 153,062
Cumulative Timesteps: 1,276,331,456

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1276331456...
Checkpoint 1276331456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,298.06591
Policy Entropy: 3.77843
Value Function Loss: 0.01684

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.49771
Value Function Update Magnitude: 0.53460

Collected Steps per Second: 22,546.98702
Overall Steps per Second: 10,661.87491

Timestep Collection Time: 2.21759
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.68961

Cumulative Model Updates: 153,068
Cumulative Timesteps: 1,276,381,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,711.93373
Policy Entropy: 3.77959
Value Function Loss: 0.01680

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.48003
Value Function Update Magnitude: 0.51379

Collected Steps per Second: 22,765.54398
Overall Steps per Second: 10,829.21696

Timestep Collection Time: 2.19753
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.61972

Cumulative Model Updates: 153,074
Cumulative Timesteps: 1,276,431,484

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1276431484...
Checkpoint 1276431484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,300.82139
Policy Entropy: 3.76701
Value Function Loss: 0.01752

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.48703
Value Function Update Magnitude: 0.50700

Collected Steps per Second: 22,443.29087
Overall Steps per Second: 10,782.03653

Timestep Collection Time: 2.22998
Timestep Consumption Time: 2.41182
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.64179

Cumulative Model Updates: 153,080
Cumulative Timesteps: 1,276,481,532

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,941.66073
Policy Entropy: 3.76539
Value Function Loss: 0.01734

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.50300
Value Function Update Magnitude: 0.49956

Collected Steps per Second: 22,446.45938
Overall Steps per Second: 10,760.54807

Timestep Collection Time: 2.22770
Timestep Consumption Time: 2.41927
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.64698

Cumulative Model Updates: 153,086
Cumulative Timesteps: 1,276,531,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1276531536...
Checkpoint 1276531536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,941.66073
Policy Entropy: 3.75663
Value Function Loss: 0.01581

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.50498
Value Function Update Magnitude: 0.48543

Collected Steps per Second: 22,495.41590
Overall Steps per Second: 10,737.03693

Timestep Collection Time: 2.22312
Timestep Consumption Time: 2.43459
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.65771

Cumulative Model Updates: 153,092
Cumulative Timesteps: 1,276,581,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,941.66073
Policy Entropy: 3.74484
Value Function Loss: 0.01656

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.49139
Value Function Update Magnitude: 0.46810

Collected Steps per Second: 22,283.72341
Overall Steps per Second: 10,564.23675

Timestep Collection Time: 2.24433
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.73409

Cumulative Model Updates: 153,098
Cumulative Timesteps: 1,276,631,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1276631558...
Checkpoint 1276631558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,291.14580
Policy Entropy: 3.74905
Value Function Loss: 0.01737

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.50554
Value Function Update Magnitude: 0.51958

Collected Steps per Second: 21,858.45073
Overall Steps per Second: 10,540.76981

Timestep Collection Time: 2.28845
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.74557

Cumulative Model Updates: 153,104
Cumulative Timesteps: 1,276,681,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,042.03300
Policy Entropy: 3.74181
Value Function Loss: 0.01776

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.50667
Value Function Update Magnitude: 0.59255

Collected Steps per Second: 22,082.88483
Overall Steps per Second: 10,503.09021

Timestep Collection Time: 2.26456
Timestep Consumption Time: 2.49671
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.76127

Cumulative Model Updates: 153,110
Cumulative Timesteps: 1,276,731,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1276731588...
Checkpoint 1276731588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,042.03300
Policy Entropy: 3.76179
Value Function Loss: 0.01536

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.47899
Value Function Update Magnitude: 0.54085

Collected Steps per Second: 22,180.66293
Overall Steps per Second: 10,548.35120

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.48606
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.74046

Cumulative Model Updates: 153,116
Cumulative Timesteps: 1,276,781,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,050.88212
Policy Entropy: 3.76305
Value Function Loss: 0.01428

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.43528
Value Function Update Magnitude: 0.44379

Collected Steps per Second: 22,656.37347
Overall Steps per Second: 10,549.36579

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.53284
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.73981

Cumulative Model Updates: 153,122
Cumulative Timesteps: 1,276,831,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1276831594...
Checkpoint 1276831594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,050.88212
Policy Entropy: 3.77284
Value Function Loss: 0.01301

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.40417
Value Function Update Magnitude: 0.39695

Collected Steps per Second: 22,583.87190
Overall Steps per Second: 10,574.24481

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.51460
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.72866

Cumulative Model Updates: 153,128
Cumulative Timesteps: 1,276,881,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,050.88212
Policy Entropy: 3.76072
Value Function Loss: 0.01190

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.38489
Value Function Update Magnitude: 0.40516

Collected Steps per Second: 22,921.95768
Overall Steps per Second: 10,851.02584

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61081

Cumulative Model Updates: 153,134
Cumulative Timesteps: 1,276,931,628

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1276931628...
Checkpoint 1276931628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,786.16121
Policy Entropy: 3.75459
Value Function Loss: 0.01170

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.37221
Value Function Update Magnitude: 0.39886

Collected Steps per Second: 22,748.83224
Overall Steps per Second: 10,690.67711

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.67903

Cumulative Model Updates: 153,140
Cumulative Timesteps: 1,276,981,650

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,786.16121
Policy Entropy: 3.75198
Value Function Loss: 0.01253

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.39168
Value Function Update Magnitude: 0.41412

Collected Steps per Second: 23,044.32970
Overall Steps per Second: 10,879.89510

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.42726
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.59821

Cumulative Model Updates: 153,146
Cumulative Timesteps: 1,277,031,678

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1277031678...
Checkpoint 1277031678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,786.16121
Policy Entropy: 3.75400
Value Function Loss: 0.01321

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.43439
Value Function Update Magnitude: 0.39738

Collected Steps per Second: 22,466.97989
Overall Steps per Second: 10,693.51408

Timestep Collection Time: 2.22567
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.67611

Cumulative Model Updates: 153,152
Cumulative Timesteps: 1,277,081,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,786.16121
Policy Entropy: 3.75491
Value Function Loss: 0.01512

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.41615
Value Function Update Magnitude: 0.33833

Collected Steps per Second: 22,970.96856
Overall Steps per Second: 10,882.57131

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.41929
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59726

Cumulative Model Updates: 153,158
Cumulative Timesteps: 1,277,131,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1277131712...
Checkpoint 1277131712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,537.60877
Policy Entropy: 3.75347
Value Function Loss: 0.01501

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.41443
Value Function Update Magnitude: 0.41342

Collected Steps per Second: 22,170.37135
Overall Steps per Second: 10,660.76807

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.69047

Cumulative Model Updates: 153,164
Cumulative Timesteps: 1,277,181,716

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,537.60877
Policy Entropy: 3.74569
Value Function Loss: 0.01466

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13746
Policy Update Magnitude: 0.43291
Value Function Update Magnitude: 0.55940

Collected Steps per Second: 21,553.63178
Overall Steps per Second: 10,526.00646

Timestep Collection Time: 2.32165
Timestep Consumption Time: 2.43229
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.75394

Cumulative Model Updates: 153,170
Cumulative Timesteps: 1,277,231,756

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1277231756...
Checkpoint 1277231756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,462.26595
Policy Entropy: 3.76085
Value Function Loss: 0.01363

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.43140
Value Function Update Magnitude: 0.56209

Collected Steps per Second: 21,390.67993
Overall Steps per Second: 10,586.90666

Timestep Collection Time: 2.33784
Timestep Consumption Time: 2.38573
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.72357

Cumulative Model Updates: 153,176
Cumulative Timesteps: 1,277,281,764

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,221.22100
Policy Entropy: 3.76375
Value Function Loss: 0.01277

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.39986
Value Function Update Magnitude: 0.51783

Collected Steps per Second: 21,597.65379
Overall Steps per Second: 10,432.07687

Timestep Collection Time: 2.31581
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.79444

Cumulative Model Updates: 153,182
Cumulative Timesteps: 1,277,331,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1277331780...
Checkpoint 1277331780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,265.83744
Policy Entropy: 3.77838
Value Function Loss: 0.01308

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.38397
Value Function Update Magnitude: 0.49576

Collected Steps per Second: 22,468.81038
Overall Steps per Second: 10,662.86997

Timestep Collection Time: 2.22709
Timestep Consumption Time: 2.46583
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.69292

Cumulative Model Updates: 153,188
Cumulative Timesteps: 1,277,381,820

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,107.95354
Policy Entropy: 3.77084
Value Function Loss: 0.01441

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.40010
Value Function Update Magnitude: 0.54923

Collected Steps per Second: 22,838.53882
Overall Steps per Second: 10,866.77574

Timestep Collection Time: 2.18963
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60192

Cumulative Model Updates: 153,194
Cumulative Timesteps: 1,277,431,828

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1277431828...
Checkpoint 1277431828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,141.06804
Policy Entropy: 3.76408
Value Function Loss: 0.01595

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13643
Policy Update Magnitude: 0.50602
Value Function Update Magnitude: 0.61844

Collected Steps per Second: 22,540.87303
Overall Steps per Second: 10,648.89329

Timestep Collection Time: 2.21819
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69532

Cumulative Model Updates: 153,200
Cumulative Timesteps: 1,277,481,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,067.56769
Policy Entropy: 3.76153
Value Function Loss: 0.02014

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.56792
Value Function Update Magnitude: 0.64775

Collected Steps per Second: 22,988.20150
Overall Steps per Second: 10,845.68740

Timestep Collection Time: 2.17607
Timestep Consumption Time: 2.43627
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.61234

Cumulative Model Updates: 153,206
Cumulative Timesteps: 1,277,531,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1277531852...
Checkpoint 1277531852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,020.29944
Policy Entropy: 3.78599
Value Function Loss: 0.02222

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.64546
Value Function Update Magnitude: 0.74792

Collected Steps per Second: 22,584.18601
Overall Steps per Second: 10,729.50767

Timestep Collection Time: 2.21571
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.66377

Cumulative Model Updates: 153,212
Cumulative Timesteps: 1,277,581,892

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.09010
Policy Entropy: 3.81563
Value Function Loss: 0.02259

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.66061
Value Function Update Magnitude: 0.88904

Collected Steps per Second: 22,500.03263
Overall Steps per Second: 10,660.82510

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.46785
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.69007

Cumulative Model Updates: 153,218
Cumulative Timesteps: 1,277,631,892

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1277631892...
Checkpoint 1277631892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,274.48081
Policy Entropy: 3.83195
Value Function Loss: 0.02410

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.64084
Value Function Update Magnitude: 0.96504

Collected Steps per Second: 22,121.26481
Overall Steps per Second: 10,555.82581

Timestep Collection Time: 2.26036
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.73691

Cumulative Model Updates: 153,224
Cumulative Timesteps: 1,277,681,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,572.44129
Policy Entropy: 3.79711
Value Function Loss: 0.02399

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.64479
Value Function Update Magnitude: 0.87934

Collected Steps per Second: 22,416.55439
Overall Steps per Second: 10,719.21185

Timestep Collection Time: 2.23165
Timestep Consumption Time: 2.43529
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66695

Cumulative Model Updates: 153,230
Cumulative Timesteps: 1,277,731,920

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1277731920...
Checkpoint 1277731920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,684.87549
Policy Entropy: 3.76172
Value Function Loss: 0.02381

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.59832
Value Function Update Magnitude: 0.76451

Collected Steps per Second: 21,888.75339
Overall Steps per Second: 10,622.87369

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.42255
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.70682

Cumulative Model Updates: 153,236
Cumulative Timesteps: 1,277,781,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,273.55802
Policy Entropy: 3.74907
Value Function Loss: 0.02180

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.63223

Collected Steps per Second: 22,489.44028
Overall Steps per Second: 10,544.58424

Timestep Collection Time: 2.22371
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.74272

Cumulative Model Updates: 153,242
Cumulative Timesteps: 1,277,831,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1277831930...
Checkpoint 1277831930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,273.55802
Policy Entropy: 3.74685
Value Function Loss: 0.02051

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.46292

Collected Steps per Second: 22,491.10197
Overall Steps per Second: 10,653.08460

Timestep Collection Time: 2.22426
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.69592

Cumulative Model Updates: 153,248
Cumulative Timesteps: 1,277,881,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,991.31611
Policy Entropy: 3.75191
Value Function Loss: 0.02026

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.41902

Collected Steps per Second: 23,263.28850
Overall Steps per Second: 10,897.42092

Timestep Collection Time: 2.14931
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.58824

Cumulative Model Updates: 153,254
Cumulative Timesteps: 1,277,931,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1277931956...
Checkpoint 1277931956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,654.46492
Policy Entropy: 3.76113
Value Function Loss: 0.02216

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.48093

Collected Steps per Second: 21,974.75956
Overall Steps per Second: 10,658.51794

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.69315

Cumulative Model Updates: 153,260
Cumulative Timesteps: 1,277,981,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,180.75616
Policy Entropy: 3.77539
Value Function Loss: 0.02311

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.57194
Value Function Update Magnitude: 0.55407

Collected Steps per Second: 22,173.57524
Overall Steps per Second: 10,861.61823

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.34890
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.60429

Cumulative Model Updates: 153,266
Cumulative Timesteps: 1,278,031,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1278031988...
Checkpoint 1278031988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,826.24689
Policy Entropy: 3.78185
Value Function Loss: 0.02328

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.57645
Value Function Update Magnitude: 0.58631

Collected Steps per Second: 21,767.46223
Overall Steps per Second: 10,653.73848

Timestep Collection Time: 2.29793
Timestep Consumption Time: 2.39714
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.69507

Cumulative Model Updates: 153,272
Cumulative Timesteps: 1,278,082,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,443.85333
Policy Entropy: 3.77585
Value Function Loss: 0.02370

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.58369
Value Function Update Magnitude: 0.53793

Collected Steps per Second: 21,819.16562
Overall Steps per Second: 10,805.86157

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.33565
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.62730

Cumulative Model Updates: 153,278
Cumulative Timesteps: 1,278,132,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1278132010...
Checkpoint 1278132010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230,064.32121
Policy Entropy: 3.77672
Value Function Loss: 0.02264

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13329
Policy Update Magnitude: 0.57315
Value Function Update Magnitude: 0.61536

Collected Steps per Second: 21,041.20265
Overall Steps per Second: 10,347.21750

Timestep Collection Time: 2.37772
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.83512

Cumulative Model Updates: 153,284
Cumulative Timesteps: 1,278,182,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275,631.53828
Policy Entropy: 3.78585
Value Function Loss: 0.02603

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.59768
Value Function Update Magnitude: 0.78380

Collected Steps per Second: 22,259.41963
Overall Steps per Second: 10,787.99314

Timestep Collection Time: 2.24759
Timestep Consumption Time: 2.38998
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.63756

Cumulative Model Updates: 153,290
Cumulative Timesteps: 1,278,232,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1278232070...
Checkpoint 1278232070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,239.89988
Policy Entropy: 3.80971
Value Function Loss: 0.02678

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.64840
Value Function Update Magnitude: 0.66995

Collected Steps per Second: 22,045.64959
Overall Steps per Second: 10,764.66224

Timestep Collection Time: 2.26902
Timestep Consumption Time: 2.37785
PPO Batch Consumption Time: 0.27550
Total Iteration Time: 4.64687

Cumulative Model Updates: 153,296
Cumulative Timesteps: 1,278,282,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.31143
Policy Entropy: 3.80731
Value Function Loss: 0.02680

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.62205
Value Function Update Magnitude: 0.73919

Collected Steps per Second: 22,298.49884
Overall Steps per Second: 10,770.08126

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.40153
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.64509

Cumulative Model Updates: 153,302
Cumulative Timesteps: 1,278,332,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1278332120...
Checkpoint 1278332120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,905.09438
Policy Entropy: 3.81041
Value Function Loss: 0.02296

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.58215
Value Function Update Magnitude: 0.74306

Collected Steps per Second: 22,660.44971
Overall Steps per Second: 10,625.62183

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.70674

Cumulative Model Updates: 153,308
Cumulative Timesteps: 1,278,382,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,733.02863
Policy Entropy: 3.77729
Value Function Loss: 0.02442

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.53224
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 22,676.93269
Overall Steps per Second: 10,626.44976

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.70656

Cumulative Model Updates: 153,314
Cumulative Timesteps: 1,278,432,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1278432146...
Checkpoint 1278432146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,615.80188
Policy Entropy: 3.79596
Value Function Loss: 0.02111

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.67948

Collected Steps per Second: 22,600.83866
Overall Steps per Second: 10,641.88985

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.70048

Cumulative Model Updates: 153,320
Cumulative Timesteps: 1,278,482,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,628.42184
Policy Entropy: 3.79844
Value Function Loss: 0.02306

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.56243
Value Function Update Magnitude: 0.81114

Collected Steps per Second: 22,716.42036
Overall Steps per Second: 10,809.21685

Timestep Collection Time: 2.20228
Timestep Consumption Time: 2.42599
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62827

Cumulative Model Updates: 153,326
Cumulative Timesteps: 1,278,532,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1278532196...
Checkpoint 1278532196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,900.80541
Policy Entropy: 3.81724
Value Function Loss: 0.02185

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.53110
Value Function Update Magnitude: 0.82010

Collected Steps per Second: 22,363.35603
Overall Steps per Second: 10,634.46806

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.70414

Cumulative Model Updates: 153,332
Cumulative Timesteps: 1,278,582,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,590.87763
Policy Entropy: 3.79942
Value Function Loss: 0.02146

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.49997
Value Function Update Magnitude: 0.68008

Collected Steps per Second: 22,651.15335
Overall Steps per Second: 10,674.64194

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.68475

Cumulative Model Updates: 153,338
Cumulative Timesteps: 1,278,632,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1278632230...
Checkpoint 1278632230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,878.29323
Policy Entropy: 3.79758
Value Function Loss: 0.02109

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.49699
Value Function Update Magnitude: 0.56741

Collected Steps per Second: 21,817.82400
Overall Steps per Second: 10,441.32868

Timestep Collection Time: 2.29271
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.79077

Cumulative Model Updates: 153,344
Cumulative Timesteps: 1,278,682,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,859.46630
Policy Entropy: 3.80639
Value Function Loss: 0.02203

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.54832
Value Function Update Magnitude: 0.54841

Collected Steps per Second: 22,166.10575
Overall Steps per Second: 10,510.58747

Timestep Collection Time: 2.25642
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.75863

Cumulative Model Updates: 153,350
Cumulative Timesteps: 1,278,732,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1278732268...
Checkpoint 1278732268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,550.73103
Policy Entropy: 3.80860
Value Function Loss: 0.02429

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.59896
Value Function Update Magnitude: 0.59814

Collected Steps per Second: 22,051.24230
Overall Steps per Second: 10,565.04408

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.73675

Cumulative Model Updates: 153,356
Cumulative Timesteps: 1,278,782,312

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.08041
Policy Entropy: 3.80264
Value Function Loss: 0.02476

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13111
Policy Update Magnitude: 0.61675
Value Function Update Magnitude: 0.57923

Collected Steps per Second: 22,377.40208
Overall Steps per Second: 10,569.96610

Timestep Collection Time: 2.23475
Timestep Consumption Time: 2.49639
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.73114

Cumulative Model Updates: 153,362
Cumulative Timesteps: 1,278,832,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1278832320...
Checkpoint 1278832320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,098.87247
Policy Entropy: 3.78316
Value Function Loss: 0.02636

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.52373

Collected Steps per Second: 22,546.67015
Overall Steps per Second: 10,555.90760

Timestep Collection Time: 2.21824
Timestep Consumption Time: 2.51977
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.73801

Cumulative Model Updates: 153,368
Cumulative Timesteps: 1,278,882,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,435.22531
Policy Entropy: 3.76475
Value Function Loss: 0.02288

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14410
Policy Update Magnitude: 0.62578
Value Function Update Magnitude: 0.57247

Collected Steps per Second: 22,076.31406
Overall Steps per Second: 10,787.84227

Timestep Collection Time: 2.26560
Timestep Consumption Time: 2.37073
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.63633

Cumulative Model Updates: 153,374
Cumulative Timesteps: 1,278,932,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1278932350...
Checkpoint 1278932350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,016.72998
Policy Entropy: 3.75445
Value Function Loss: 0.02163

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13842
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.58243

Collected Steps per Second: 21,771.84887
Overall Steps per Second: 10,784.78353

Timestep Collection Time: 2.29700
Timestep Consumption Time: 2.34009
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.63709

Cumulative Model Updates: 153,380
Cumulative Timesteps: 1,278,982,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,076.37974
Policy Entropy: 3.75868
Value Function Loss: 0.01903

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.51645
Value Function Update Magnitude: 0.55101

Collected Steps per Second: 22,322.05135
Overall Steps per Second: 10,795.93951

Timestep Collection Time: 2.24012
Timestep Consumption Time: 2.39162
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.63174

Cumulative Model Updates: 153,386
Cumulative Timesteps: 1,279,032,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1279032364...
Checkpoint 1279032364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,089.80357
Policy Entropy: 3.77507
Value Function Loss: 0.01855

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.49986
Value Function Update Magnitude: 0.54088

Collected Steps per Second: 22,331.20653
Overall Steps per Second: 10,706.47449

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.43202
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.67194

Cumulative Model Updates: 153,392
Cumulative Timesteps: 1,279,082,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,364.06043
Policy Entropy: 3.80367
Value Function Loss: 0.02081

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.49599
Value Function Update Magnitude: 0.63611

Collected Steps per Second: 22,658.78886
Overall Steps per Second: 10,847.48803

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.40377
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.61139

Cumulative Model Updates: 153,398
Cumulative Timesteps: 1,279,132,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1279132406...
Checkpoint 1279132406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,311.45922
Policy Entropy: 3.81171
Value Function Loss: 0.02483

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.82808

Collected Steps per Second: 21,677.94433
Overall Steps per Second: 10,626.11032

Timestep Collection Time: 2.30686
Timestep Consumption Time: 2.39928
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.70614

Cumulative Model Updates: 153,404
Cumulative Timesteps: 1,279,182,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,608.75655
Policy Entropy: 3.81626
Value Function Loss: 0.02558

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.63974
Value Function Update Magnitude: 0.94404

Collected Steps per Second: 22,168.08518
Overall Steps per Second: 10,556.23534

Timestep Collection Time: 2.25613
Timestep Consumption Time: 2.48174
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.73786

Cumulative Model Updates: 153,410
Cumulative Timesteps: 1,279,232,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1279232428...
Checkpoint 1279232428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,978.23085
Policy Entropy: 3.79941
Value Function Loss: 0.02670

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.65746
Value Function Update Magnitude: 0.94758

Collected Steps per Second: 22,061.00298
Overall Steps per Second: 10,710.66537

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.40257
PPO Batch Consumption Time: 0.27559
Total Iteration Time: 4.66974

Cumulative Model Updates: 153,416
Cumulative Timesteps: 1,279,282,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,640.77652
Policy Entropy: 3.80135
Value Function Loss: 0.02439

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.63596
Value Function Update Magnitude: 0.93287

Collected Steps per Second: 22,238.40998
Overall Steps per Second: 10,532.85554

Timestep Collection Time: 2.24971
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.74990

Cumulative Model Updates: 153,422
Cumulative Timesteps: 1,279,332,474

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1279332474...
Checkpoint 1279332474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334,860.98817
Policy Entropy: 3.77542
Value Function Loss: 0.02523

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12465
Policy Update Magnitude: 0.61352
Value Function Update Magnitude: 0.88715

Collected Steps per Second: 22,692.74681
Overall Steps per Second: 10,622.29076

Timestep Collection Time: 2.20440
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.70934

Cumulative Model Updates: 153,428
Cumulative Timesteps: 1,279,382,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,703.53026
Policy Entropy: 3.77357
Value Function Loss: 0.01999

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.58901
Value Function Update Magnitude: 0.84654

Collected Steps per Second: 22,738.41617
Overall Steps per Second: 10,805.37610

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.62751

Cumulative Model Updates: 153,434
Cumulative Timesteps: 1,279,432,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1279432500...
Checkpoint 1279432500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569,990.84427
Policy Entropy: 3.73958
Value Function Loss: 0.01981

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.73399

Collected Steps per Second: 22,661.74638
Overall Steps per Second: 10,650.27213

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.48855
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69509

Cumulative Model Updates: 153,440
Cumulative Timesteps: 1,279,482,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,990.98826
Policy Entropy: 3.74311
Value Function Loss: 0.01831

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.49449
Value Function Update Magnitude: 0.64723

Collected Steps per Second: 22,693.94616
Overall Steps per Second: 10,790.78782

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.43152
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.63581

Cumulative Model Updates: 153,446
Cumulative Timesteps: 1,279,532,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1279532528...
Checkpoint 1279532528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,501.75564
Policy Entropy: 3.74614
Value Function Loss: 0.02120

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.49928
Value Function Update Magnitude: 0.65151

Collected Steps per Second: 22,582.20562
Overall Steps per Second: 10,673.77028

Timestep Collection Time: 2.21440
Timestep Consumption Time: 2.47054
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.68494

Cumulative Model Updates: 153,452
Cumulative Timesteps: 1,279,582,534

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,362.92541
Policy Entropy: 3.76031
Value Function Loss: 0.02389

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.56886

Collected Steps per Second: 22,875.22151
Overall Steps per Second: 10,851.36620

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.60900

Cumulative Model Updates: 153,458
Cumulative Timesteps: 1,279,632,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1279632548...
Checkpoint 1279632548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,715.29357
Policy Entropy: 3.75197
Value Function Loss: 0.02206

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.54018
Value Function Update Magnitude: 0.53252

Collected Steps per Second: 22,219.48050
Overall Steps per Second: 10,706.22562

Timestep Collection Time: 2.25244
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.67466

Cumulative Model Updates: 153,464
Cumulative Timesteps: 1,279,682,596

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,525.48805
Policy Entropy: 3.75115
Value Function Loss: 0.01807

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.50392
Value Function Update Magnitude: 0.60314

Collected Steps per Second: 22,354.08034
Overall Steps per Second: 10,583.61056

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.48825
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.72561

Cumulative Model Updates: 153,470
Cumulative Timesteps: 1,279,732,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1279732610...
Checkpoint 1279732610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,087.74493
Policy Entropy: 3.76574
Value Function Loss: 0.01520

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.46744
Value Function Update Magnitude: 0.56361

Collected Steps per Second: 22,269.86082
Overall Steps per Second: 10,561.37161

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.73651

Cumulative Model Updates: 153,476
Cumulative Timesteps: 1,279,782,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.66756
Policy Entropy: 3.76961
Value Function Loss: 0.01362

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.42934
Value Function Update Magnitude: 0.51579

Collected Steps per Second: 22,565.43808
Overall Steps per Second: 10,777.46908

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.42401
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64024

Cumulative Model Updates: 153,482
Cumulative Timesteps: 1,279,832,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1279832644...
Checkpoint 1279832644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.66756
Policy Entropy: 3.75572
Value Function Loss: 0.01287

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.42791
Value Function Update Magnitude: 0.51230

Collected Steps per Second: 22,514.71976
Overall Steps per Second: 10,685.82013

Timestep Collection Time: 2.22086
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.67929

Cumulative Model Updates: 153,488
Cumulative Timesteps: 1,279,882,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.66756
Policy Entropy: 3.73035
Value Function Loss: 0.01373

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.42123
Value Function Update Magnitude: 0.46383

Collected Steps per Second: 22,735.15090
Overall Steps per Second: 10,680.73196

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.48358
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.68414

Cumulative Model Updates: 153,494
Cumulative Timesteps: 1,279,932,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1279932676...
Checkpoint 1279932676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.66756
Policy Entropy: 3.72054
Value Function Loss: 0.01478

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.43585
Value Function Update Magnitude: 0.43902

Collected Steps per Second: 22,861.73119
Overall Steps per Second: 10,877.73853

Timestep Collection Time: 2.18741
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.59728

Cumulative Model Updates: 153,500
Cumulative Timesteps: 1,279,982,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,626.66756
Policy Entropy: 3.72809
Value Function Loss: 0.01545

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14032
Policy Update Magnitude: 0.42829
Value Function Update Magnitude: 0.37443

Collected Steps per Second: 22,668.06690
Overall Steps per Second: 10,612.92652

Timestep Collection Time: 2.20725
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.71444

Cumulative Model Updates: 153,506
Cumulative Timesteps: 1,280,032,718

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1280032718...
Checkpoint 1280032718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378,394.14049
Policy Entropy: 3.73265
Value Function Loss: 0.01840

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.44363
Value Function Update Magnitude: 0.38890

Collected Steps per Second: 22,877.98524
Overall Steps per Second: 10,707.18328

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.48555
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.67219

Cumulative Model Updates: 153,512
Cumulative Timesteps: 1,280,082,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,126.30294
Policy Entropy: 3.73993
Value Function Loss: 0.01950

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13787
Policy Update Magnitude: 0.52769
Value Function Update Magnitude: 0.55162

Collected Steps per Second: 22,582.52035
Overall Steps per Second: 10,708.07293

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.45704
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.67274

Cumulative Model Updates: 153,518
Cumulative Timesteps: 1,280,132,780

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1280132780...
Checkpoint 1280132780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,704.26503
Policy Entropy: 3.73786
Value Function Loss: 0.02509

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.59650
Value Function Update Magnitude: 0.73447

Collected Steps per Second: 22,470.93266
Overall Steps per Second: 10,674.21449

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.45948
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.68493

Cumulative Model Updates: 153,524
Cumulative Timesteps: 1,280,182,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,351.46021
Policy Entropy: 3.76060
Value Function Loss: 0.02242

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.59398
Value Function Update Magnitude: 0.71381

Collected Steps per Second: 22,391.21752
Overall Steps per Second: 10,623.61819

Timestep Collection Time: 2.23445
Timestep Consumption Time: 2.47506
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.70951

Cumulative Model Updates: 153,530
Cumulative Timesteps: 1,280,232,820

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1280232820...
Checkpoint 1280232820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,589.23563
Policy Entropy: 3.75432
Value Function Loss: 0.02224

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.56832
Value Function Update Magnitude: 0.62802

Collected Steps per Second: 22,282.90927
Overall Steps per Second: 10,581.28339

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.48205
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.72646

Cumulative Model Updates: 153,536
Cumulative Timesteps: 1,280,282,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,731.05181
Policy Entropy: 3.76365
Value Function Loss: 0.01680

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.50822
Value Function Update Magnitude: 0.56795

Collected Steps per Second: 22,210.98329
Overall Steps per Second: 10,724.08918

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.41165
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.66315

Cumulative Model Updates: 153,542
Cumulative Timesteps: 1,280,332,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1280332840...
Checkpoint 1280332840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,656.29060
Policy Entropy: 3.75943
Value Function Loss: 0.02003

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13751
Policy Update Magnitude: 0.49409
Value Function Update Magnitude: 0.49579

Collected Steps per Second: 21,534.24431
Overall Steps per Second: 10,701.42877

Timestep Collection Time: 2.32300
Timestep Consumption Time: 2.35152
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.67452

Cumulative Model Updates: 153,548
Cumulative Timesteps: 1,280,382,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,116.67381
Policy Entropy: 3.77537
Value Function Loss: 0.01759

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.49689
Value Function Update Magnitude: 0.53488

Collected Steps per Second: 22,071.94173
Overall Steps per Second: 10,655.32622

Timestep Collection Time: 2.26532
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.69249

Cumulative Model Updates: 153,554
Cumulative Timesteps: 1,280,432,864

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1280432864...
Checkpoint 1280432864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,753.03747
Policy Entropy: 3.77177
Value Function Loss: 0.01937

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13436
Policy Update Magnitude: 0.50634
Value Function Update Magnitude: 0.59089

Collected Steps per Second: 22,051.33882
Overall Steps per Second: 10,831.00518

Timestep Collection Time: 2.26825
Timestep Consumption Time: 2.34979
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.61804

Cumulative Model Updates: 153,560
Cumulative Timesteps: 1,280,482,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,326.44891
Policy Entropy: 3.75998
Value Function Loss: 0.01683

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.49493
Value Function Update Magnitude: 0.52994

Collected Steps per Second: 21,790.90386
Overall Steps per Second: 10,531.69611

Timestep Collection Time: 2.29545
Timestep Consumption Time: 2.45402
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.74947

Cumulative Model Updates: 153,566
Cumulative Timesteps: 1,280,532,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1280532902...
Checkpoint 1280532902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,889.81609
Policy Entropy: 3.75534
Value Function Loss: 0.01871

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13253
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.49987

Collected Steps per Second: 22,385.05646
Overall Steps per Second: 10,635.33776

Timestep Collection Time: 2.23390
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.70187

Cumulative Model Updates: 153,572
Cumulative Timesteps: 1,280,582,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,938.24858
Policy Entropy: 3.74487
Value Function Loss: 0.01771

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.53095
Value Function Update Magnitude: 0.46744

Collected Steps per Second: 22,879.92071
Overall Steps per Second: 10,907.35324

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.39980
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58608

Cumulative Model Updates: 153,578
Cumulative Timesteps: 1,280,632,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1280632930...
Checkpoint 1280632930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,938.24858
Policy Entropy: 3.75257
Value Function Loss: 0.01743

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14054
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.39075

Collected Steps per Second: 22,681.77860
Overall Steps per Second: 10,652.21756

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69517

Cumulative Model Updates: 153,584
Cumulative Timesteps: 1,280,682,944

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,580.98541
Policy Entropy: 3.74206
Value Function Loss: 0.01630

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.49788
Value Function Update Magnitude: 0.34850

Collected Steps per Second: 22,323.90155
Overall Steps per Second: 10,579.25952

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.72736

Cumulative Model Updates: 153,590
Cumulative Timesteps: 1,280,732,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1280732956...
Checkpoint 1280732956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,580.98541
Policy Entropy: 3.74886
Value Function Loss: 0.01677

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.50574
Value Function Update Magnitude: 0.36877

Collected Steps per Second: 22,264.15304
Overall Steps per Second: 10,551.99000

Timestep Collection Time: 2.24576
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.73844

Cumulative Model Updates: 153,596
Cumulative Timesteps: 1,280,782,956

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,193.84273
Policy Entropy: 3.74200
Value Function Loss: 0.01630

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.52081
Value Function Update Magnitude: 0.38334

Collected Steps per Second: 22,231.88633
Overall Steps per Second: 10,543.49023

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.74340

Cumulative Model Updates: 153,602
Cumulative Timesteps: 1,280,832,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1280832968...
Checkpoint 1280832968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247,826.01293
Policy Entropy: 3.74414
Value Function Loss: 0.01847

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12583
Policy Update Magnitude: 0.52584
Value Function Update Magnitude: 0.50763

Collected Steps per Second: 22,319.76130
Overall Steps per Second: 10,538.27957

Timestep Collection Time: 2.24115
Timestep Consumption Time: 2.50554
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.74670

Cumulative Model Updates: 153,608
Cumulative Timesteps: 1,280,882,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,435.95618
Policy Entropy: 3.74578
Value Function Loss: 0.01754

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 22,905.71558
Overall Steps per Second: 10,812.92650

Timestep Collection Time: 2.18469
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.62798

Cumulative Model Updates: 153,614
Cumulative Timesteps: 1,280,933,032

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1280933032...
Checkpoint 1280933032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,316.05576
Policy Entropy: 3.74350
Value Function Loss: 0.01848

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.58269
Value Function Update Magnitude: 0.70249

Collected Steps per Second: 22,453.85910
Overall Steps per Second: 10,699.38062

Timestep Collection Time: 2.22777
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.67522

Cumulative Model Updates: 153,620
Cumulative Timesteps: 1,280,983,054

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,316.05576
Policy Entropy: 3.74505
Value Function Loss: 0.01674

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.72503

Collected Steps per Second: 22,747.26414
Overall Steps per Second: 10,823.73526

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.42170
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.62003

Cumulative Model Updates: 153,626
Cumulative Timesteps: 1,281,033,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1281033060...
Checkpoint 1281033060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,663.20092
Policy Entropy: 3.73775
Value Function Loss: 0.01798

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.57788
Value Function Update Magnitude: 0.68667

Collected Steps per Second: 20,766.14443
Overall Steps per Second: 10,254.36958

Timestep Collection Time: 2.40863
Timestep Consumption Time: 2.46909
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.87773

Cumulative Model Updates: 153,632
Cumulative Timesteps: 1,281,083,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,486.51631
Policy Entropy: 3.74796
Value Function Loss: 0.01782

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.69478

Collected Steps per Second: 22,118.28832
Overall Steps per Second: 10,465.84079

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.51838
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.78031

Cumulative Model Updates: 153,638
Cumulative Timesteps: 1,281,133,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1281133108...
Checkpoint 1281133108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,913.92461
Policy Entropy: 3.75919
Value Function Loss: 0.01951

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.55616
Value Function Update Magnitude: 0.64886

Collected Steps per Second: 22,179.15300
Overall Steps per Second: 10,725.88449

Timestep Collection Time: 2.25518
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.27549
Total Iteration Time: 4.66330

Cumulative Model Updates: 153,644
Cumulative Timesteps: 1,281,183,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,039.28785
Policy Entropy: 3.77179
Value Function Loss: 0.01853

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14312
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.64014

Collected Steps per Second: 22,689.18686
Overall Steps per Second: 10,742.84911

Timestep Collection Time: 2.20369
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.65426

Cumulative Model Updates: 153,650
Cumulative Timesteps: 1,281,233,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1281233126...
Checkpoint 1281233126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,729.94778
Policy Entropy: 3.78278
Value Function Loss: 0.01936

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.61057
Value Function Update Magnitude: 0.62446

Collected Steps per Second: 22,350.93843
Overall Steps per Second: 10,697.76403

Timestep Collection Time: 2.23722
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.67425

Cumulative Model Updates: 153,656
Cumulative Timesteps: 1,281,283,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.26245
Policy Entropy: 3.78281
Value Function Loss: 0.02036

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08025
Policy Update Magnitude: 0.75512
Value Function Update Magnitude: 0.63855

Collected Steps per Second: 22,437.28735
Overall Steps per Second: 10,596.34506

Timestep Collection Time: 2.22897
Timestep Consumption Time: 2.49077
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.71974

Cumulative Model Updates: 153,662
Cumulative Timesteps: 1,281,333,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1281333142...
Checkpoint 1281333142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,865.26245
Policy Entropy: 3.76335
Value Function Loss: 0.02040

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.83398
Value Function Update Magnitude: 0.61214

Collected Steps per Second: 22,370.53996
Overall Steps per Second: 10,579.55543

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.49121
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.72647

Cumulative Model Updates: 153,668
Cumulative Timesteps: 1,281,383,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,514.46754
Policy Entropy: 3.75879
Value Function Loss: 0.01688

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.76717
Value Function Update Magnitude: 0.54746

Collected Steps per Second: 22,737.37662
Overall Steps per Second: 10,780.24328

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.63849

Cumulative Model Updates: 153,674
Cumulative Timesteps: 1,281,433,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1281433150...
Checkpoint 1281433150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,521.07159
Policy Entropy: 3.76624
Value Function Loss: 0.01715

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.14543
Policy Update Magnitude: 0.64346
Value Function Update Magnitude: 0.50803

Collected Steps per Second: 22,461.23336
Overall Steps per Second: 10,690.20601

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.67924

Cumulative Model Updates: 153,680
Cumulative Timesteps: 1,281,483,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,970.04052
Policy Entropy: 3.78671
Value Function Loss: 0.01555

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.66896
Value Function Update Magnitude: 0.53474

Collected Steps per Second: 22,290.31195
Overall Steps per Second: 10,560.37563

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.49285
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.73714

Cumulative Model Updates: 153,686
Cumulative Timesteps: 1,281,533,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1281533198...
Checkpoint 1281533198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,994.61147
Policy Entropy: 3.76941
Value Function Loss: 0.01651

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.72870
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 22,268.31111
Overall Steps per Second: 10,536.54699

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.74596

Cumulative Model Updates: 153,692
Cumulative Timesteps: 1,281,583,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,994.61147
Policy Entropy: 3.74794
Value Function Loss: 0.01638

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.16481
Policy Update Magnitude: 0.66458
Value Function Update Magnitude: 0.50461

Collected Steps per Second: 22,008.43220
Overall Steps per Second: 10,466.64168

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.78014

Cumulative Model Updates: 153,698
Cumulative Timesteps: 1,281,633,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1281633236...
Checkpoint 1281633236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,994.61147
Policy Entropy: 3.75730
Value Function Loss: 0.01597

Mean KL Divergence: 0.01557
SB3 Clip Fraction: 0.18305
Policy Update Magnitude: 0.55727
Value Function Update Magnitude: 0.43532

Collected Steps per Second: 21,803.00872
Overall Steps per Second: 10,604.78085

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.71561

Cumulative Model Updates: 153,704
Cumulative Timesteps: 1,281,683,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,994.61147
Policy Entropy: 3.73708
Value Function Loss: 0.01712

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.36126

Collected Steps per Second: 21,618.94813
Overall Steps per Second: 10,554.41906

Timestep Collection Time: 2.31380
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.27578
Total Iteration Time: 4.73944

Cumulative Model Updates: 153,710
Cumulative Timesteps: 1,281,733,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1281733266...
Checkpoint 1281733266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 355,359.36362
Policy Entropy: 3.74550
Value Function Loss: 0.02219

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.18897
Policy Update Magnitude: 0.60210
Value Function Update Magnitude: 0.36351

Collected Steps per Second: 21,967.87528
Overall Steps per Second: 10,625.49397

Timestep Collection Time: 2.27714
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27577
Total Iteration Time: 4.70792

Cumulative Model Updates: 153,716
Cumulative Timesteps: 1,281,783,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,291.43436
Policy Entropy: 3.79715
Value Function Loss: 0.03168

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.17070
Policy Update Magnitude: 0.66200
Value Function Update Magnitude: 0.55762

Collected Steps per Second: 21,888.34109
Overall Steps per Second: 10,418.09932

Timestep Collection Time: 2.28441
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.79953

Cumulative Model Updates: 153,722
Cumulative Timesteps: 1,281,833,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1281833292...
Checkpoint 1281833292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,402.90953
Policy Entropy: 3.86797
Value Function Loss: 0.03467

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.92104
Value Function Update Magnitude: 0.72521

Collected Steps per Second: 22,601.97943
Overall Steps per Second: 10,617.77851

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.49709
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.70946

Cumulative Model Updates: 153,728
Cumulative Timesteps: 1,281,883,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228.77253
Policy Entropy: 3.91477
Value Function Loss: 0.03488

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.98788
Value Function Update Magnitude: 0.90933

Collected Steps per Second: 22,109.79320
Overall Steps per Second: 10,500.70872

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.50114
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.76349

Cumulative Model Updates: 153,734
Cumulative Timesteps: 1,281,933,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1281933316...
Checkpoint 1281933316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,801.33745
Policy Entropy: 3.93293
Value Function Loss: 0.03032

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.91210
Value Function Update Magnitude: 0.89271

Collected Steps per Second: 22,551.60349
Overall Steps per Second: 10,614.59584

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.71106

Cumulative Model Updates: 153,740
Cumulative Timesteps: 1,281,983,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,683.60317
Policy Entropy: 3.88738
Value Function Loss: 0.03071

Mean KL Divergence: 0.00664
SB3 Clip Fraction: 0.08446
Policy Update Magnitude: 0.88384
Value Function Update Magnitude: 0.91085

Collected Steps per Second: 22,505.23312
Overall Steps per Second: 10,658.13538

Timestep Collection Time: 2.22224
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69238

Cumulative Model Updates: 153,746
Cumulative Timesteps: 1,282,033,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1282033334...
Checkpoint 1282033334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,681.16430
Policy Entropy: 3.85198
Value Function Loss: 0.03433

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.88573
Value Function Update Magnitude: 0.85240

Collected Steps per Second: 22,540.02795
Overall Steps per Second: 10,777.01647

Timestep Collection Time: 2.21952
Timestep Consumption Time: 2.42258
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.64210

Cumulative Model Updates: 153,752
Cumulative Timesteps: 1,282,083,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,421.56441
Policy Entropy: 3.83787
Value Function Loss: 0.03695

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14980
Policy Update Magnitude: 0.81546
Value Function Update Magnitude: 0.85838

Collected Steps per Second: 22,289.32344
Overall Steps per Second: 10,532.46818

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74817

Cumulative Model Updates: 153,758
Cumulative Timesteps: 1,282,133,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1282133372...
Checkpoint 1282133372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.34773
Policy Entropy: 3.82869
Value Function Loss: 0.03473

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.20078
Policy Update Magnitude: 0.79031
Value Function Update Magnitude: 0.98697

Collected Steps per Second: 22,260.82070
Overall Steps per Second: 10,663.96976

Timestep Collection Time: 2.24655
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.68962

Cumulative Model Updates: 153,764
Cumulative Timesteps: 1,282,183,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,039.17414
Policy Entropy: 3.83128
Value Function Loss: 0.03433

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16029
Policy Update Magnitude: 0.75119
Value Function Update Magnitude: 0.98517

Collected Steps per Second: 22,134.91885
Overall Steps per Second: 10,500.78753

Timestep Collection Time: 2.26014
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.76421

Cumulative Model Updates: 153,770
Cumulative Timesteps: 1,282,233,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1282233410...
Checkpoint 1282233410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.13598
Policy Entropy: 3.82766
Value Function Loss: 0.03056

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.71172
Value Function Update Magnitude: 0.93721

Collected Steps per Second: 22,257.75178
Overall Steps per Second: 10,582.42508

Timestep Collection Time: 2.24677
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.72557

Cumulative Model Updates: 153,776
Cumulative Timesteps: 1,282,283,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,792.27386
Policy Entropy: 3.82799
Value Function Loss: 0.03068

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11446
Policy Update Magnitude: 0.67687
Value Function Update Magnitude: 0.83349

Collected Steps per Second: 22,334.51328
Overall Steps per Second: 10,567.12475

Timestep Collection Time: 2.24021
Timestep Consumption Time: 2.49466
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.73487

Cumulative Model Updates: 153,782
Cumulative Timesteps: 1,282,333,452

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1282333452...
Checkpoint 1282333452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,704.56512
Policy Entropy: 3.80022
Value Function Loss: 0.02826

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.67421
Value Function Update Magnitude: 0.68095

Collected Steps per Second: 22,285.66531
Overall Steps per Second: 10,507.22017

Timestep Collection Time: 2.24467
Timestep Consumption Time: 2.51625
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.76092

Cumulative Model Updates: 153,788
Cumulative Timesteps: 1,282,383,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.24125
Policy Entropy: 3.78326
Value Function Loss: 0.02833

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.64040
Value Function Update Magnitude: 0.55678

Collected Steps per Second: 22,663.93835
Overall Steps per Second: 10,615.81403

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.70995

Cumulative Model Updates: 153,794
Cumulative Timesteps: 1,282,433,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1282433476...
Checkpoint 1282433476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,239.35278
Policy Entropy: 3.78735
Value Function Loss: 0.02901

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11281
Policy Update Magnitude: 0.58602
Value Function Update Magnitude: 0.51586

Collected Steps per Second: 22,692.48261
Overall Steps per Second: 10,698.35498

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.47153
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.67605

Cumulative Model Updates: 153,800
Cumulative Timesteps: 1,282,483,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,717.38330
Policy Entropy: 3.80200
Value Function Loss: 0.02612

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 22,877.64677
Overall Steps per Second: 10,693.64148

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.49073
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.67680

Cumulative Model Updates: 153,806
Cumulative Timesteps: 1,282,533,514

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1282533514...
Checkpoint 1282533514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,776.00013
Policy Entropy: 3.79073
Value Function Loss: 0.02693

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.52150
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 22,789.39019
Overall Steps per Second: 10,627.22450

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70546

Cumulative Model Updates: 153,812
Cumulative Timesteps: 1,282,583,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,268.89085
Policy Entropy: 3.80272
Value Function Loss: 0.02514

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.60092

Collected Steps per Second: 22,606.74690
Overall Steps per Second: 10,663.80150

Timestep Collection Time: 2.21288
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.69120

Cumulative Model Updates: 153,818
Cumulative Timesteps: 1,282,633,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1282633546...
Checkpoint 1282633546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,969.85721
Policy Entropy: 3.78882
Value Function Loss: 0.02526

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.68758

Collected Steps per Second: 22,587.01393
Overall Steps per Second: 10,825.48630

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.40536
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.61928

Cumulative Model Updates: 153,824
Cumulative Timesteps: 1,282,683,552

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,484.69993
Policy Entropy: 3.82123
Value Function Loss: 0.02287

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.52483
Value Function Update Magnitude: 0.72092

Collected Steps per Second: 22,149.95963
Overall Steps per Second: 10,505.35001

Timestep Collection Time: 2.25815
Timestep Consumption Time: 2.50304
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.76119

Cumulative Model Updates: 153,830
Cumulative Timesteps: 1,282,733,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1282733570...
Checkpoint 1282733570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,593.88065
Policy Entropy: 3.81346
Value Function Loss: 0.02354

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.51570
Value Function Update Magnitude: 0.70812

Collected Steps per Second: 22,191.92426
Overall Steps per Second: 10,732.71745

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.27559
Total Iteration Time: 4.66145

Cumulative Model Updates: 153,836
Cumulative Timesteps: 1,282,783,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,921.58405
Policy Entropy: 3.82663
Value Function Loss: 0.02096

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.53922
Value Function Update Magnitude: 0.69834

Collected Steps per Second: 22,266.09564
Overall Steps per Second: 10,744.26645

Timestep Collection Time: 2.24727
Timestep Consumption Time: 2.40991
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.65718

Cumulative Model Updates: 153,842
Cumulative Timesteps: 1,282,833,638

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1282833638...
Checkpoint 1282833638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.39296
Policy Entropy: 3.80986
Value Function Loss: 0.01902

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.49888
Value Function Update Magnitude: 0.65692

Collected Steps per Second: 22,069.69035
Overall Steps per Second: 10,658.91717

Timestep Collection Time: 2.26600
Timestep Consumption Time: 2.42584
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69185

Cumulative Model Updates: 153,848
Cumulative Timesteps: 1,282,883,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,500.94837
Policy Entropy: 3.77500
Value Function Loss: 0.02003

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.49299
Value Function Update Magnitude: 0.59329

Collected Steps per Second: 22,537.78708
Overall Steps per Second: 10,486.20958

Timestep Collection Time: 2.22001
Timestep Consumption Time: 2.55140
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.77141

Cumulative Model Updates: 153,854
Cumulative Timesteps: 1,282,933,682

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1282933682...
Checkpoint 1282933682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.99016
Policy Entropy: 3.76319
Value Function Loss: 0.02061

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.51516
Value Function Update Magnitude: 0.61505

Collected Steps per Second: 21,245.88157
Overall Steps per Second: 10,144.22417

Timestep Collection Time: 2.35396
Timestep Consumption Time: 2.57613
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.93010

Cumulative Model Updates: 153,860
Cumulative Timesteps: 1,282,983,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.99016
Policy Entropy: 3.73348
Value Function Loss: 0.02221

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.51474
Value Function Update Magnitude: 0.58848

Collected Steps per Second: 22,585.35044
Overall Steps per Second: 10,599.21540

Timestep Collection Time: 2.21515
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.72016

Cumulative Model Updates: 153,866
Cumulative Timesteps: 1,283,033,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1283033724...
Checkpoint 1283033724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.99016
Policy Entropy: 3.74822
Value Function Loss: 0.01953

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.50213
Value Function Update Magnitude: 0.49386

Collected Steps per Second: 22,722.56812
Overall Steps per Second: 10,646.62761

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.69632

Cumulative Model Updates: 153,872
Cumulative Timesteps: 1,283,083,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,025.99016
Policy Entropy: 3.73871
Value Function Loss: 0.01943

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.46947
Value Function Update Magnitude: 0.42503

Collected Steps per Second: 21,771.37119
Overall Steps per Second: 10,779.34454

Timestep Collection Time: 2.29806
Timestep Consumption Time: 2.34341
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.64147

Cumulative Model Updates: 153,878
Cumulative Timesteps: 1,283,133,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1283133756...
Checkpoint 1283133756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,227.79593
Policy Entropy: 3.74400
Value Function Loss: 0.01961

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.46425
Value Function Update Magnitude: 0.39178

Collected Steps per Second: 21,663.27381
Overall Steps per Second: 10,722.36458

Timestep Collection Time: 2.30833
Timestep Consumption Time: 2.35538
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.66371

Cumulative Model Updates: 153,884
Cumulative Timesteps: 1,283,183,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,475.64776
Policy Entropy: 3.74746
Value Function Loss: 0.02051

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.47767
Value Function Update Magnitude: 0.41008

Collected Steps per Second: 21,866.04339
Overall Steps per Second: 10,653.75043

Timestep Collection Time: 2.28811
Timestep Consumption Time: 2.40807
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.69619

Cumulative Model Updates: 153,890
Cumulative Timesteps: 1,283,233,794

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1283233794...
Checkpoint 1283233794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,685.17592
Policy Entropy: 3.75738
Value Function Loss: 0.01971

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.47106
Value Function Update Magnitude: 0.42276

Collected Steps per Second: 22,075.52080
Overall Steps per Second: 10,593.18557

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.45644
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.72266

Cumulative Model Updates: 153,896
Cumulative Timesteps: 1,283,283,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,192.18213
Policy Entropy: 3.75772
Value Function Loss: 0.01988

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.46767
Value Function Update Magnitude: 0.36407

Collected Steps per Second: 22,354.40873
Overall Steps per Second: 10,821.45478

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.38452
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.62193

Cumulative Model Updates: 153,902
Cumulative Timesteps: 1,283,333,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1283333838...
Checkpoint 1283333838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,048.78729
Policy Entropy: 3.76887
Value Function Loss: 0.01749

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.45085
Value Function Update Magnitude: 0.39726

Collected Steps per Second: 22,228.63610
Overall Steps per Second: 10,597.87716

Timestep Collection Time: 2.24998
Timestep Consumption Time: 2.46927
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.71925

Cumulative Model Updates: 153,908
Cumulative Timesteps: 1,283,383,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,734.80824
Policy Entropy: 3.78017
Value Function Loss: 0.02070

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.48481
Value Function Update Magnitude: 0.49616

Collected Steps per Second: 22,209.08720
Overall Steps per Second: 10,518.16281

Timestep Collection Time: 2.25250
Timestep Consumption Time: 2.50365
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.75615

Cumulative Model Updates: 153,914
Cumulative Timesteps: 1,283,433,878

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1283433878...
Checkpoint 1283433878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,070.53612
Policy Entropy: 3.79383
Value Function Loss: 0.02370

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.60076

Collected Steps per Second: 22,257.94397
Overall Steps per Second: 10,552.53787

Timestep Collection Time: 2.24675
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.73895

Cumulative Model Updates: 153,920
Cumulative Timesteps: 1,283,483,886

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,388.59335
Policy Entropy: 3.77764
Value Function Loss: 0.02281

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.61671
Value Function Update Magnitude: 0.69227

Collected Steps per Second: 22,579.55710
Overall Steps per Second: 10,497.98067

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.54975
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.76530

Cumulative Model Updates: 153,926
Cumulative Timesteps: 1,283,533,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1283533912...
Checkpoint 1283533912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,528.74348
Policy Entropy: 3.76262
Value Function Loss: 0.02529

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.63502

Collected Steps per Second: 22,622.63414
Overall Steps per Second: 10,607.80532

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.50524
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.71709

Cumulative Model Updates: 153,932
Cumulative Timesteps: 1,283,583,950

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,922.46343
Policy Entropy: 3.78860
Value Function Loss: 0.02507

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.62529

Collected Steps per Second: 22,862.32654
Overall Steps per Second: 10,907.48310

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.58603

Cumulative Model Updates: 153,938
Cumulative Timesteps: 1,283,633,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1283633972...
Checkpoint 1283633972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.76312
Policy Entropy: 3.78934
Value Function Loss: 0.02814

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.58939
Value Function Update Magnitude: 0.72968

Collected Steps per Second: 22,802.72646
Overall Steps per Second: 10,670.63735

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.68688

Cumulative Model Updates: 153,944
Cumulative Timesteps: 1,283,683,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,881.90801
Policy Entropy: 3.79223
Value Function Loss: 0.02453

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.61586
Value Function Update Magnitude: 0.84470

Collected Steps per Second: 22,822.61591
Overall Steps per Second: 10,814.92343

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.62361

Cumulative Model Updates: 153,950
Cumulative Timesteps: 1,283,733,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1283733988...
Checkpoint 1283733988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,317.08227
Policy Entropy: 3.76828
Value Function Loss: 0.02258

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14386
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.83752

Collected Steps per Second: 22,736.65517
Overall Steps per Second: 10,718.00727

Timestep Collection Time: 2.19971
Timestep Consumption Time: 2.46664
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66635

Cumulative Model Updates: 153,956
Cumulative Timesteps: 1,283,784,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,586.92655
Policy Entropy: 3.77269
Value Function Loss: 0.02026

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.53007
Value Function Update Magnitude: 0.79464

Collected Steps per Second: 22,468.76120
Overall Steps per Second: 10,638.51188

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.70254

Cumulative Model Updates: 153,962
Cumulative Timesteps: 1,283,834,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1283834030...
Checkpoint 1283834030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,189.57266
Policy Entropy: 3.76700
Value Function Loss: 0.02348

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.57716
Value Function Update Magnitude: 0.67180

Collected Steps per Second: 22,094.39496
Overall Steps per Second: 10,517.89722

Timestep Collection Time: 2.26438
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.75665

Cumulative Model Updates: 153,968
Cumulative Timesteps: 1,283,884,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,162.18394
Policy Entropy: 3.75917
Value Function Loss: 0.02569

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 22,197.06482
Overall Steps per Second: 10,574.59477

Timestep Collection Time: 2.25372
Timestep Consumption Time: 2.47705
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.73077

Cumulative Model Updates: 153,974
Cumulative Timesteps: 1,283,934,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1283934086...
Checkpoint 1283934086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,762.40341
Policy Entropy: 3.76981
Value Function Loss: 0.02698

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.58908
Value Function Update Magnitude: 0.55345

Collected Steps per Second: 22,206.00842
Overall Steps per Second: 10,565.41931

Timestep Collection Time: 2.25281
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.73488

Cumulative Model Updates: 153,980
Cumulative Timesteps: 1,283,984,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,244.43408
Policy Entropy: 3.77165
Value Function Loss: 0.02670

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.59320
Value Function Update Magnitude: 0.55637

Collected Steps per Second: 21,963.41457
Overall Steps per Second: 10,496.49108

Timestep Collection Time: 2.27733
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.76521

Cumulative Model Updates: 153,986
Cumulative Timesteps: 1,284,034,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1284034130...
Checkpoint 1284034130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,155.00982
Policy Entropy: 3.77022
Value Function Loss: 0.02356

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13452
Policy Update Magnitude: 0.60748
Value Function Update Magnitude: 0.55582

Collected Steps per Second: 22,223.26614
Overall Steps per Second: 10,528.40579

Timestep Collection Time: 2.25007
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.74944

Cumulative Model Updates: 153,992
Cumulative Timesteps: 1,284,084,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,155.00982
Policy Entropy: 3.75628
Value Function Loss: 0.02210

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.56971
Value Function Update Magnitude: 0.52924

Collected Steps per Second: 22,702.98037
Overall Steps per Second: 10,627.04808

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.50462
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.70874

Cumulative Model Updates: 153,998
Cumulative Timesteps: 1,284,134,174

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1284134174...
Checkpoint 1284134174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,609.43117
Policy Entropy: 3.75798
Value Function Loss: 0.02018

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.53879

Collected Steps per Second: 22,854.22832
Overall Steps per Second: 10,826.60633

Timestep Collection Time: 2.18883
Timestep Consumption Time: 2.43164
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62047

Cumulative Model Updates: 154,004
Cumulative Timesteps: 1,284,184,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,591.65025
Policy Entropy: 3.75920
Value Function Loss: 0.01829

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14140
Policy Update Magnitude: 0.51574
Value Function Update Magnitude: 0.56386

Collected Steps per Second: 23,146.43563
Overall Steps per Second: 10,905.52929

Timestep Collection Time: 2.16137
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.58740

Cumulative Model Updates: 154,010
Cumulative Timesteps: 1,284,234,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1284234226...
Checkpoint 1284234226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,591.65025
Policy Entropy: 3.76812
Value Function Loss: 0.01707

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.47363
Value Function Update Magnitude: 0.51553

Collected Steps per Second: 22,119.69358
Overall Steps per Second: 10,726.57115

Timestep Collection Time: 2.26179
Timestep Consumption Time: 2.40233
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.66412

Cumulative Model Updates: 154,016
Cumulative Timesteps: 1,284,284,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,988.19818
Policy Entropy: 3.75689
Value Function Loss: 0.01675

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.48686
Value Function Update Magnitude: 0.55518

Collected Steps per Second: 21,909.29473
Overall Steps per Second: 10,665.89607

Timestep Collection Time: 2.28305
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.68971

Cumulative Model Updates: 154,022
Cumulative Timesteps: 1,284,334,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1284334276...
Checkpoint 1284334276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,092.12205
Policy Entropy: 3.73624
Value Function Loss: 0.01831

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 22,138.28987
Overall Steps per Second: 10,885.80930

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.33694
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.59773

Cumulative Model Updates: 154,028
Cumulative Timesteps: 1,284,384,326

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,092.12205
Policy Entropy: 3.74694
Value Function Loss: 0.01641

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.49419
Value Function Update Magnitude: 0.53663

Collected Steps per Second: 21,665.43114
Overall Steps per Second: 10,501.39577

Timestep Collection Time: 2.30847
Timestep Consumption Time: 2.45413
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.76260

Cumulative Model Updates: 154,034
Cumulative Timesteps: 1,284,434,340

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1284434340...
Checkpoint 1284434340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,328.57145
Policy Entropy: 3.74279
Value Function Loss: 0.01750

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.46709
Value Function Update Magnitude: 0.46605

Collected Steps per Second: 21,853.41925
Overall Steps per Second: 10,644.27655

Timestep Collection Time: 2.28806
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.69755

Cumulative Model Updates: 154,040
Cumulative Timesteps: 1,284,484,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,574.95751
Policy Entropy: 3.75047
Value Function Loss: 0.01684

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.12124
Policy Update Magnitude: 0.45529
Value Function Update Magnitude: 0.46450

Collected Steps per Second: 22,240.06507
Overall Steps per Second: 10,775.25237

Timestep Collection Time: 2.24864
Timestep Consumption Time: 2.39255
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.64119

Cumulative Model Updates: 154,046
Cumulative Timesteps: 1,284,534,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1284534352...
Checkpoint 1284534352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,843.29939
Policy Entropy: 3.75947
Value Function Loss: 0.01966

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.48986
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 22,284.56637
Overall Steps per Second: 10,701.85315

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.42916
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.67358

Cumulative Model Updates: 154,052
Cumulative Timesteps: 1,284,584,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,761.36366
Policy Entropy: 3.77342
Value Function Loss: 0.02060

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.51445
Value Function Update Magnitude: 0.55790

Collected Steps per Second: 22,473.52434
Overall Steps per Second: 10,471.78811

Timestep Collection Time: 2.22600
Timestep Consumption Time: 2.55122
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.77722

Cumulative Model Updates: 154,058
Cumulative Timesteps: 1,284,634,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1284634394...
Checkpoint 1284634394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,018.49077
Policy Entropy: 3.77468
Value Function Loss: 0.02051

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13618
Policy Update Magnitude: 0.48246
Value Function Update Magnitude: 0.48565

Collected Steps per Second: 22,572.82249
Overall Steps per Second: 10,627.12420

Timestep Collection Time: 2.21585
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.70664

Cumulative Model Updates: 154,064
Cumulative Timesteps: 1,284,684,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,018.49077
Policy Entropy: 3.74937
Value Function Loss: 0.01875

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.43697
Value Function Update Magnitude: 0.50185

Collected Steps per Second: 22,550.99052
Overall Steps per Second: 10,625.75721

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.48925
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.70724

Cumulative Model Updates: 154,070
Cumulative Timesteps: 1,284,734,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1284734430...
Checkpoint 1284734430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,847.96337
Policy Entropy: 3.74607
Value Function Loss: 0.01687

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.43157
Value Function Update Magnitude: 0.49618

Collected Steps per Second: 22,649.41567
Overall Steps per Second: 10,684.79921

Timestep Collection Time: 2.20862
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.68179

Cumulative Model Updates: 154,076
Cumulative Timesteps: 1,284,784,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,958.18958
Policy Entropy: 3.75829
Value Function Loss: 0.01973

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.45040
Value Function Update Magnitude: 0.48858

Collected Steps per Second: 22,973.04957
Overall Steps per Second: 10,710.51881

Timestep Collection Time: 2.17716
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.66980

Cumulative Model Updates: 154,082
Cumulative Timesteps: 1,284,834,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1284834470...
Checkpoint 1284834470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,470.28850
Policy Entropy: 3.77280
Value Function Loss: 0.01747

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.48755
Value Function Update Magnitude: 0.53822

Collected Steps per Second: 21,411.08400
Overall Steps per Second: 10,564.95587

Timestep Collection Time: 2.33645
Timestep Consumption Time: 2.39864
PPO Batch Consumption Time: 0.27526
Total Iteration Time: 4.73509

Cumulative Model Updates: 154,088
Cumulative Timesteps: 1,284,884,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,470.28850
Policy Entropy: 3.75478
Value Function Loss: 0.01964

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13896
Policy Update Magnitude: 0.46101
Value Function Update Magnitude: 0.48437

Collected Steps per Second: 22,438.02561
Overall Steps per Second: 10,580.83831

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.49816
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.72741

Cumulative Model Updates: 154,094
Cumulative Timesteps: 1,284,934,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1284934516...
Checkpoint 1284934516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,470.28850
Policy Entropy: 3.75287
Value Function Loss: 0.01522

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.41332
Value Function Update Magnitude: 0.38181

Collected Steps per Second: 22,086.41108
Overall Steps per Second: 10,582.96521

Timestep Collection Time: 2.26429
Timestep Consumption Time: 2.46123
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.72552

Cumulative Model Updates: 154,100
Cumulative Timesteps: 1,284,984,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,199.50242
Policy Entropy: 3.74337
Value Function Loss: 0.01764

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.42136
Value Function Update Magnitude: 0.36695

Collected Steps per Second: 22,040.80485
Overall Steps per Second: 10,538.81438

Timestep Collection Time: 2.26852
Timestep Consumption Time: 2.47585
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.74437

Cumulative Model Updates: 154,106
Cumulative Timesteps: 1,285,034,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1285034526...
Checkpoint 1285034526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,844.78741
Policy Entropy: 3.77280
Value Function Loss: 0.01603

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.43988
Value Function Update Magnitude: 0.53311

Collected Steps per Second: 22,440.59008
Overall Steps per Second: 10,618.59720

Timestep Collection Time: 2.22846
Timestep Consumption Time: 2.48101
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.70947

Cumulative Model Updates: 154,112
Cumulative Timesteps: 1,285,084,534

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,776.52655
Policy Entropy: 3.77117
Value Function Loss: 0.01932

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.46480
Value Function Update Magnitude: 0.65740

Collected Steps per Second: 21,791.89119
Overall Steps per Second: 10,766.83245

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.35040
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.64575

Cumulative Model Updates: 154,118
Cumulative Timesteps: 1,285,134,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1285134554...
Checkpoint 1285134554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,903.11693
Policy Entropy: 3.78761
Value Function Loss: 0.01764

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.49825
Value Function Update Magnitude: 0.67624

Collected Steps per Second: 21,540.05725
Overall Steps per Second: 10,685.26322

Timestep Collection Time: 2.32200
Timestep Consumption Time: 2.35884
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.68084

Cumulative Model Updates: 154,124
Cumulative Timesteps: 1,285,184,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,065.11151
Policy Entropy: 3.76241
Value Function Loss: 0.02202

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.52207
Value Function Update Magnitude: 0.71370

Collected Steps per Second: 21,975.95272
Overall Steps per Second: 10,696.87259

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.40001
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.67613

Cumulative Model Updates: 154,130
Cumulative Timesteps: 1,285,234,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1285234590...
Checkpoint 1285234590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,482.95709
Policy Entropy: 3.77817
Value Function Loss: 0.02217

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.58358
Value Function Update Magnitude: 0.75982

Collected Steps per Second: 21,930.05249
Overall Steps per Second: 10,818.77294

Timestep Collection Time: 2.28025
Timestep Consumption Time: 2.34190
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.62215

Cumulative Model Updates: 154,136
Cumulative Timesteps: 1,285,284,596

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,034.21614
Policy Entropy: 3.75919
Value Function Loss: 0.02743

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.58111
Value Function Update Magnitude: 0.70262

Collected Steps per Second: 21,919.48176
Overall Steps per Second: 10,484.84592

Timestep Collection Time: 2.28144
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.76955

Cumulative Model Updates: 154,142
Cumulative Timesteps: 1,285,334,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1285334604...
Checkpoint 1285334604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,239.69770
Policy Entropy: 3.78855
Value Function Loss: 0.02268

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 22,617.40495
Overall Steps per Second: 10,689.81132

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.67829

Cumulative Model Updates: 154,148
Cumulative Timesteps: 1,285,384,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,420.37597
Policy Entropy: 3.77638
Value Function Loss: 0.02070

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.60312

Collected Steps per Second: 22,681.53528
Overall Steps per Second: 10,891.72663

Timestep Collection Time: 2.20488
Timestep Consumption Time: 2.38668
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.59156

Cumulative Model Updates: 154,154
Cumulative Timesteps: 1,285,434,624

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1285434624...
Checkpoint 1285434624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,907.35095
Policy Entropy: 3.77505
Value Function Loss: 0.01727

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.50384
Value Function Update Magnitude: 0.58767

Collected Steps per Second: 22,591.49787
Overall Steps per Second: 10,615.97324

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.71252

Cumulative Model Updates: 154,160
Cumulative Timesteps: 1,285,484,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,533.94157
Policy Entropy: 3.76300
Value Function Loss: 0.01832

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.46513
Value Function Update Magnitude: 0.59885

Collected Steps per Second: 22,051.68088
Overall Steps per Second: 10,442.77809

Timestep Collection Time: 2.26858
Timestep Consumption Time: 2.52191
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.79049

Cumulative Model Updates: 154,166
Cumulative Timesteps: 1,285,534,678

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1285534678...
Checkpoint 1285534678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,856.45655
Policy Entropy: 3.75583
Value Function Loss: 0.01879

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.48978
Value Function Update Magnitude: 0.62305

Collected Steps per Second: 22,421.95903
Overall Steps per Second: 10,637.89409

Timestep Collection Time: 2.22996
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.70018

Cumulative Model Updates: 154,172
Cumulative Timesteps: 1,285,584,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,925.82822
Policy Entropy: 3.74912
Value Function Loss: 0.02063

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.50022
Value Function Update Magnitude: 0.67214

Collected Steps per Second: 21,852.51406
Overall Steps per Second: 10,473.13548

Timestep Collection Time: 2.28825
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.77450

Cumulative Model Updates: 154,178
Cumulative Timesteps: 1,285,634,682

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1285634682...
Checkpoint 1285634682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,104.75501
Policy Entropy: 3.75879
Value Function Loss: 0.02091

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.52543
Value Function Update Magnitude: 0.57513

Collected Steps per Second: 22,236.64071
Overall Steps per Second: 10,707.73948

Timestep Collection Time: 2.24881
Timestep Consumption Time: 2.42127
PPO Batch Consumption Time: 0.27601
Total Iteration Time: 4.67008

Cumulative Model Updates: 154,184
Cumulative Timesteps: 1,285,684,688

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,675.96059
Policy Entropy: 3.77474
Value Function Loss: 0.02010

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.59009

Collected Steps per Second: 22,655.12013
Overall Steps per Second: 10,585.39305

Timestep Collection Time: 2.20842
Timestep Consumption Time: 2.51809
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.72651

Cumulative Model Updates: 154,190
Cumulative Timesteps: 1,285,734,720

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1285734720...
Checkpoint 1285734720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,186.80008
Policy Entropy: 3.79880
Value Function Loss: 0.01971

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.59853

Collected Steps per Second: 22,648.94698
Overall Steps per Second: 10,657.39432

Timestep Collection Time: 2.20858
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69364

Cumulative Model Updates: 154,196
Cumulative Timesteps: 1,285,784,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,101.67473
Policy Entropy: 3.79782
Value Function Loss: 0.02007

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.53354
Value Function Update Magnitude: 0.56451

Collected Steps per Second: 22,917.58145
Overall Steps per Second: 10,692.85400

Timestep Collection Time: 2.18199
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.67658

Cumulative Model Updates: 154,202
Cumulative Timesteps: 1,285,834,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1285834748...
Checkpoint 1285834748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,567.96672
Policy Entropy: 3.79150
Value Function Loss: 0.02078

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.56072

Collected Steps per Second: 22,669.30423
Overall Steps per Second: 10,665.58520

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.68798

Cumulative Model Updates: 154,208
Cumulative Timesteps: 1,285,884,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,951.31170
Policy Entropy: 3.79590
Value Function Loss: 0.02015

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12127
Policy Update Magnitude: 0.50671
Value Function Update Magnitude: 0.51086

Collected Steps per Second: 22,838.65056
Overall Steps per Second: 10,813.52898

Timestep Collection Time: 2.18988
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62513

Cumulative Model Updates: 154,214
Cumulative Timesteps: 1,285,934,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1285934762...
Checkpoint 1285934762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,036.50079
Policy Entropy: 3.78478
Value Function Loss: 0.02025

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.48272
Value Function Update Magnitude: 0.48031

Collected Steps per Second: 22,657.62597
Overall Steps per Second: 10,719.88824

Timestep Collection Time: 2.20685
Timestep Consumption Time: 2.45756
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.66441

Cumulative Model Updates: 154,220
Cumulative Timesteps: 1,285,984,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338,458.61100
Policy Entropy: 3.78134
Value Function Loss: 0.02171

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.49790
Value Function Update Magnitude: 0.58348

Collected Steps per Second: 22,573.02008
Overall Steps per Second: 10,693.25484

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.67697

Cumulative Model Updates: 154,226
Cumulative Timesteps: 1,286,034,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1286034776...
Checkpoint 1286034776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,158.99028
Policy Entropy: 3.76956
Value Function Loss: 0.02112

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11801
Policy Update Magnitude: 0.53336
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,036.43165
Overall Steps per Second: 10,511.03455

Timestep Collection Time: 2.27006
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.75919

Cumulative Model Updates: 154,232
Cumulative Timesteps: 1,286,084,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,609.66144
Policy Entropy: 3.79298
Value Function Loss: 0.02094

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.80150

Collected Steps per Second: 22,332.02931
Overall Steps per Second: 10,746.15151

Timestep Collection Time: 2.23894
Timestep Consumption Time: 2.41389
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.65283

Cumulative Model Updates: 154,238
Cumulative Timesteps: 1,286,134,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1286134800...
Checkpoint 1286134800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,388.98641
Policy Entropy: 3.79498
Value Function Loss: 0.01885

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.54198
Value Function Update Magnitude: 0.88969

Collected Steps per Second: 22,324.01566
Overall Steps per Second: 10,707.09963

Timestep Collection Time: 2.23983
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.66999

Cumulative Model Updates: 154,244
Cumulative Timesteps: 1,286,184,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,218.09494
Policy Entropy: 3.77934
Value Function Loss: 0.01999

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.50532
Value Function Update Magnitude: 0.77916

Collected Steps per Second: 22,430.33244
Overall Steps per Second: 10,564.29603

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.73368

Cumulative Model Updates: 154,250
Cumulative Timesteps: 1,286,234,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1286234810...
Checkpoint 1286234810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,145.48057
Policy Entropy: 3.75449
Value Function Loss: 0.02200

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.67959

Collected Steps per Second: 22,620.08489
Overall Steps per Second: 10,525.24810

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.54036
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.75105

Cumulative Model Updates: 154,256
Cumulative Timesteps: 1,286,284,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,436.09515
Policy Entropy: 3.75356
Value Function Loss: 0.02129

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.60597
Value Function Update Magnitude: 0.74381

Collected Steps per Second: 22,606.74729
Overall Steps per Second: 10,664.08222

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69145

Cumulative Model Updates: 154,262
Cumulative Timesteps: 1,286,334,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1286334846...
Checkpoint 1286334846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,658.08298
Policy Entropy: 3.76613
Value Function Loss: 0.02177

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.75822

Collected Steps per Second: 22,750.04730
Overall Steps per Second: 10,820.34399

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.62203

Cumulative Model Updates: 154,268
Cumulative Timesteps: 1,286,384,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,298.31098
Policy Entropy: 3.79106
Value Function Loss: 0.02073

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 22,872.13978
Overall Steps per Second: 10,717.95768

Timestep Collection Time: 2.18711
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.66731

Cumulative Model Updates: 154,274
Cumulative Timesteps: 1,286,434,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1286434882...
Checkpoint 1286434882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,917.87439
Policy Entropy: 3.79298
Value Function Loss: 0.02259

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.57303
Value Function Update Magnitude: 0.65810

Collected Steps per Second: 22,624.19289
Overall Steps per Second: 10,838.60957

Timestep Collection Time: 2.21091
Timestep Consumption Time: 2.40408
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.61498

Cumulative Model Updates: 154,280
Cumulative Timesteps: 1,286,484,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,702.22602
Policy Entropy: 3.81792
Value Function Loss: 0.02224

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.62177
Value Function Update Magnitude: 0.80324

Collected Steps per Second: 22,472.51585
Overall Steps per Second: 10,587.87895

Timestep Collection Time: 2.22592
Timestep Consumption Time: 2.49854
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.72446

Cumulative Model Updates: 154,286
Cumulative Timesteps: 1,286,534,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1286534924...
Checkpoint 1286534924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,471.95722
Policy Entropy: 3.82276
Value Function Loss: 0.02322

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.67138
Value Function Update Magnitude: 0.77628

Collected Steps per Second: 22,527.04892
Overall Steps per Second: 10,620.12431

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71049

Cumulative Model Updates: 154,292
Cumulative Timesteps: 1,286,584,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,080.14337
Policy Entropy: 3.82251
Value Function Loss: 0.02215

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.65597
Value Function Update Magnitude: 0.73260

Collected Steps per Second: 22,174.01100
Overall Steps per Second: 10,523.10289

Timestep Collection Time: 2.25697
Timestep Consumption Time: 2.49886
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.75582

Cumulative Model Updates: 154,298
Cumulative Timesteps: 1,286,634,996

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1286634996...
Checkpoint 1286634996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,502.79589
Policy Entropy: 3.79972
Value Function Loss: 0.01854

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.62668

Collected Steps per Second: 22,091.77373
Overall Steps per Second: 10,563.18754

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.47013
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.73342

Cumulative Model Updates: 154,304
Cumulative Timesteps: 1,286,684,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,345.49338
Policy Entropy: 3.78503
Value Function Loss: 0.01629

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.47520
Value Function Update Magnitude: 0.48583

Collected Steps per Second: 22,298.22361
Overall Steps per Second: 10,554.57959

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.73974

Cumulative Model Updates: 154,310
Cumulative Timesteps: 1,286,735,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1286735022...
Checkpoint 1286735022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,345.49338
Policy Entropy: 3.76762
Value Function Loss: 0.01512

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.46010
Value Function Update Magnitude: 0.41557

Collected Steps per Second: 22,284.44868
Overall Steps per Second: 10,415.53448

Timestep Collection Time: 2.24470
Timestep Consumption Time: 2.55793
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.80263

Cumulative Model Updates: 154,316
Cumulative Timesteps: 1,286,785,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,868.91371
Policy Entropy: 3.77467
Value Function Loss: 0.01719

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.46842
Value Function Update Magnitude: 0.51785

Collected Steps per Second: 22,679.20633
Overall Steps per Second: 10,666.77970

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.48418
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.69008

Cumulative Model Updates: 154,322
Cumulative Timesteps: 1,286,835,072

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1286835072...
Checkpoint 1286835072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,028.47085
Policy Entropy: 3.77287
Value Function Loss: 0.02023

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.53620
Value Function Update Magnitude: 0.61751

Collected Steps per Second: 21,890.12946
Overall Steps per Second: 10,682.28200

Timestep Collection Time: 2.28441
Timestep Consumption Time: 2.39680
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.68121

Cumulative Model Updates: 154,328
Cumulative Timesteps: 1,286,885,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,966.95098
Policy Entropy: 3.78820
Value Function Loss: 0.02101

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.58818
Value Function Update Magnitude: 0.67598

Collected Steps per Second: 22,135.59468
Overall Steps per Second: 10,771.86441

Timestep Collection Time: 2.26025
Timestep Consumption Time: 2.38444
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.64469

Cumulative Model Updates: 154,334
Cumulative Timesteps: 1,286,935,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1286935110...
Checkpoint 1286935110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,365.13652
Policy Entropy: 3.77096
Value Function Loss: 0.02269

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11664
Policy Update Magnitude: 0.58584
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 21,792.20855
Overall Steps per Second: 10,617.34358

Timestep Collection Time: 2.29559
Timestep Consumption Time: 2.41613
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.71172

Cumulative Model Updates: 154,340
Cumulative Timesteps: 1,286,985,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,518.10836
Policy Entropy: 3.76903
Value Function Loss: 0.02254

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.60695
Value Function Update Magnitude: 0.58763

Collected Steps per Second: 21,699.72471
Overall Steps per Second: 10,489.51768

Timestep Collection Time: 2.30501
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.76838

Cumulative Model Updates: 154,346
Cumulative Timesteps: 1,287,035,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1287035154...
Checkpoint 1287035154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.79474
Policy Entropy: 3.73426
Value Function Loss: 0.02394

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12314
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.55687

Collected Steps per Second: 22,102.20753
Overall Steps per Second: 10,633.12920

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.44153
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.70511

Cumulative Model Updates: 154,352
Cumulative Timesteps: 1,287,085,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.59915
Policy Entropy: 3.75043
Value Function Loss: 0.02117

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.49469

Collected Steps per Second: 22,046.66496
Overall Steps per Second: 10,553.56132

Timestep Collection Time: 2.26891
Timestep Consumption Time: 2.47091
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.73982

Cumulative Model Updates: 154,358
Cumulative Timesteps: 1,287,135,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1287135206...
Checkpoint 1287135206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,268.65286
Policy Entropy: 3.74472
Value Function Loss: 0.02152

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.46463

Collected Steps per Second: 22,008.59495
Overall Steps per Second: 10,536.01092

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28473
Total Iteration Time: 4.74715

Cumulative Model Updates: 154,364
Cumulative Timesteps: 1,287,185,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,197.89118
Policy Entropy: 3.77256
Value Function Loss: 0.01911

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.53289
Value Function Update Magnitude: 0.51751

Collected Steps per Second: 21,841.51592
Overall Steps per Second: 10,482.89995

Timestep Collection Time: 2.28949
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.77024

Cumulative Model Updates: 154,370
Cumulative Timesteps: 1,287,235,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1287235228...
Checkpoint 1287235228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,918.76802
Policy Entropy: 3.76472
Value Function Loss: 0.02273

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.52496
Value Function Update Magnitude: 0.55137

Collected Steps per Second: 22,418.23558
Overall Steps per Second: 10,617.80692

Timestep Collection Time: 2.23051
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.70945

Cumulative Model Updates: 154,376
Cumulative Timesteps: 1,287,285,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,028.56981
Policy Entropy: 3.78366
Value Function Loss: 0.02254

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.53490
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 22,553.28674
Overall Steps per Second: 10,584.02057

Timestep Collection Time: 2.21768
Timestep Consumption Time: 2.50793
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.72561

Cumulative Model Updates: 154,382
Cumulative Timesteps: 1,287,335,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1287335248...
Checkpoint 1287335248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,888.85111
Policy Entropy: 3.78414
Value Function Loss: 0.02283

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.52156
Value Function Update Magnitude: 0.59674

Collected Steps per Second: 22,974.99831
Overall Steps per Second: 10,878.34921

Timestep Collection Time: 2.17828
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.60051

Cumulative Model Updates: 154,388
Cumulative Timesteps: 1,287,385,294

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 600.28949
Policy Entropy: 3.80187
Value Function Loss: 0.01844

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.48664
Value Function Update Magnitude: 0.66444

Collected Steps per Second: 22,815.76339
Overall Steps per Second: 10,731.34940

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.46975
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.66297

Cumulative Model Updates: 154,394
Cumulative Timesteps: 1,287,435,334

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1287435334...
Checkpoint 1287435334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 600.28949
Policy Entropy: 3.78435
Value Function Loss: 0.01602

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.61693

Collected Steps per Second: 22,640.17597
Overall Steps per Second: 10,822.37660

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.62006

Cumulative Model Updates: 154,400
Cumulative Timesteps: 1,287,485,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,357.91120
Policy Entropy: 3.77185
Value Function Loss: 0.01586

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.43441
Value Function Update Magnitude: 0.50275

Collected Steps per Second: 22,225.61084
Overall Steps per Second: 10,497.28891

Timestep Collection Time: 2.25002
Timestep Consumption Time: 2.51388
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.76390

Cumulative Model Updates: 154,406
Cumulative Timesteps: 1,287,535,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1287535342...
Checkpoint 1287535342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,934.80709
Policy Entropy: 3.74762
Value Function Loss: 0.01659

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.43398
Value Function Update Magnitude: 0.50540

Collected Steps per Second: 22,486.88392
Overall Steps per Second: 10,687.28060

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.68033

Cumulative Model Updates: 154,412
Cumulative Timesteps: 1,287,585,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,934.80709
Policy Entropy: 3.74572
Value Function Loss: 0.01789

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.45477
Value Function Update Magnitude: 0.50644

Collected Steps per Second: 21,595.17020
Overall Steps per Second: 10,443.02813

Timestep Collection Time: 2.31654
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.79037

Cumulative Model Updates: 154,418
Cumulative Timesteps: 1,287,635,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1287635388...
Checkpoint 1287635388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,651.22363
Policy Entropy: 3.73936
Value Function Loss: 0.01734

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.47431
Value Function Update Magnitude: 0.54239

Collected Steps per Second: 22,264.17895
Overall Steps per Second: 10,663.35450

Timestep Collection Time: 2.24639
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.69027

Cumulative Model Updates: 154,424
Cumulative Timesteps: 1,287,685,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128,732.34491
Policy Entropy: 3.74690
Value Function Loss: 0.01727

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.47714
Value Function Update Magnitude: 0.56236

Collected Steps per Second: 21,615.55701
Overall Steps per Second: 10,571.13923

Timestep Collection Time: 2.31454
Timestep Consumption Time: 2.41816
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.73270

Cumulative Model Updates: 154,430
Cumulative Timesteps: 1,287,735,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1287735432...
Checkpoint 1287735432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,274.63903
Policy Entropy: 3.75659
Value Function Loss: 0.01627

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.47348
Value Function Update Magnitude: 0.55369

Collected Steps per Second: 21,708.08469
Overall Steps per Second: 10,582.57673

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.72513

Cumulative Model Updates: 154,436
Cumulative Timesteps: 1,287,785,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,274.63903
Policy Entropy: 3.75017
Value Function Loss: 0.01632

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.43662
Value Function Update Magnitude: 0.49344

Collected Steps per Second: 21,725.84024
Overall Steps per Second: 10,724.67696

Timestep Collection Time: 2.30196
Timestep Consumption Time: 2.36130
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.66326

Cumulative Model Updates: 154,442
Cumulative Timesteps: 1,287,835,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1287835448...
Checkpoint 1287835448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,274.63903
Policy Entropy: 3.74634
Value Function Loss: 0.01418

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.39375
Value Function Update Magnitude: 0.42965

Collected Steps per Second: 22,102.27686
Overall Steps per Second: 10,672.47789

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.42419
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.68776

Cumulative Model Updates: 154,448
Cumulative Timesteps: 1,287,885,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,274.63903
Policy Entropy: 3.74602
Value Function Loss: 0.01274

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.37979
Value Function Update Magnitude: 0.37774

Collected Steps per Second: 22,164.63955
Overall Steps per Second: 10,544.32312

Timestep Collection Time: 2.25720
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.74473

Cumulative Model Updates: 154,454
Cumulative Timesteps: 1,287,935,508

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1287935508...
Checkpoint 1287935508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,274.63903
Policy Entropy: 3.74735
Value Function Loss: 0.01242

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.37980
Value Function Update Magnitude: 0.37881

Collected Steps per Second: 22,868.27764
Overall Steps per Second: 10,688.83953

Timestep Collection Time: 2.18661
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.67815

Cumulative Model Updates: 154,460
Cumulative Timesteps: 1,287,985,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,705.70599
Policy Entropy: 3.75617
Value Function Loss: 0.01849

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.44423
Value Function Update Magnitude: 0.40974

Collected Steps per Second: 22,800.52151
Overall Steps per Second: 10,823.71614

Timestep Collection Time: 2.19346
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62059

Cumulative Model Updates: 154,466
Cumulative Timesteps: 1,288,035,524

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1288035524...
Checkpoint 1288035524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,062.86247
Policy Entropy: 3.78229
Value Function Loss: 0.01901

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13973
Policy Update Magnitude: 0.53029
Value Function Update Magnitude: 0.68064

Collected Steps per Second: 22,827.59127
Overall Steps per Second: 10,705.75594

Timestep Collection Time: 2.19138
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.67263

Cumulative Model Updates: 154,472
Cumulative Timesteps: 1,288,085,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,532.43455
Policy Entropy: 3.78445
Value Function Loss: 0.02145

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54711
Value Function Update Magnitude: 0.76577

Collected Steps per Second: 22,393.07722
Overall Steps per Second: 10,611.30062

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.47972
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.71309

Cumulative Model Updates: 154,478
Cumulative Timesteps: 1,288,135,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1288135560...
Checkpoint 1288135560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,496.75777
Policy Entropy: 3.78519
Value Function Loss: 0.01833

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.53034
Value Function Update Magnitude: 0.61078

Collected Steps per Second: 21,763.83691
Overall Steps per Second: 10,433.75091

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.79310

Cumulative Model Updates: 154,484
Cumulative Timesteps: 1,288,185,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,444.71417
Policy Entropy: 3.75005
Value Function Loss: 0.02046

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.48170
Value Function Update Magnitude: 0.52143

Collected Steps per Second: 22,276.54735
Overall Steps per Second: 10,567.00451

Timestep Collection Time: 2.24541
Timestep Consumption Time: 2.48819
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.73360

Cumulative Model Updates: 154,490
Cumulative Timesteps: 1,288,235,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1288235590...
Checkpoint 1288235590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,386.16919
Policy Entropy: 3.75082
Value Function Loss: 0.02204

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.47003
Value Function Update Magnitude: 0.48301

Collected Steps per Second: 22,249.52779
Overall Steps per Second: 10,556.55500

Timestep Collection Time: 2.24814
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.73829

Cumulative Model Updates: 154,496
Cumulative Timesteps: 1,288,285,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,386.16919
Policy Entropy: 3.72543
Value Function Loss: 0.02434

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.48424
Value Function Update Magnitude: 0.38625

Collected Steps per Second: 22,387.61322
Overall Steps per Second: 10,611.90744

Timestep Collection Time: 2.23472
Timestep Consumption Time: 2.47980
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.71452

Cumulative Model Updates: 154,502
Cumulative Timesteps: 1,288,335,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1288335640...
Checkpoint 1288335640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,973.59238
Policy Entropy: 3.74484
Value Function Loss: 0.02084

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.47243
Value Function Update Magnitude: 0.38830

Collected Steps per Second: 21,744.57269
Overall Steps per Second: 10,660.94718

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.39164
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.69208

Cumulative Model Updates: 154,508
Cumulative Timesteps: 1,288,385,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,168.75717
Policy Entropy: 3.76855
Value Function Loss: 0.02153

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.48774
Value Function Update Magnitude: 0.51078

Collected Steps per Second: 22,295.73137
Overall Steps per Second: 10,734.96126

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.66122

Cumulative Model Updates: 154,514
Cumulative Timesteps: 1,288,435,700

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1288435700...
Checkpoint 1288435700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,974.19154
Policy Entropy: 3.79270
Value Function Loss: 0.02178

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 22,106.45358
Overall Steps per Second: 10,688.41265

Timestep Collection Time: 2.26323
Timestep Consumption Time: 2.41773
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68096

Cumulative Model Updates: 154,520
Cumulative Timesteps: 1,288,485,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,787.04751
Policy Entropy: 3.81261
Value Function Loss: 0.01923

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.67305

Collected Steps per Second: 22,197.13366
Overall Steps per Second: 10,739.45855

Timestep Collection Time: 2.25317
Timestep Consumption Time: 2.40386
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.65703

Cumulative Model Updates: 154,526
Cumulative Timesteps: 1,288,535,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1288535746...
Checkpoint 1288535746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,787.04751
Policy Entropy: 3.78833
Value Function Loss: 0.01542

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.50918
Value Function Update Magnitude: 0.67760

Collected Steps per Second: 22,777.19664
Overall Steps per Second: 10,721.75653

Timestep Collection Time: 2.19570
Timestep Consumption Time: 2.46883
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66453

Cumulative Model Updates: 154,532
Cumulative Timesteps: 1,288,585,758

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,787.04751
Policy Entropy: 3.74752
Value Function Loss: 0.01551

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.46195
Value Function Update Magnitude: 0.60902

Collected Steps per Second: 22,732.72884
Overall Steps per Second: 10,859.54966

Timestep Collection Time: 2.20062
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60664

Cumulative Model Updates: 154,538
Cumulative Timesteps: 1,288,635,784

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1288635784...
Checkpoint 1288635784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,787.04751
Policy Entropy: 3.72580
Value Function Loss: 0.01641

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13565
Policy Update Magnitude: 0.48032
Value Function Update Magnitude: 0.63816

Collected Steps per Second: 22,679.79718
Overall Steps per Second: 10,743.58113

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.45090
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.65692

Cumulative Model Updates: 154,544
Cumulative Timesteps: 1,288,685,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,102.48017
Policy Entropy: 3.73851
Value Function Loss: 0.01893

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14317
Policy Update Magnitude: 0.51322
Value Function Update Magnitude: 0.65029

Collected Steps per Second: 22,368.47442
Overall Steps per Second: 10,583.02368

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.72644

Cumulative Model Updates: 154,550
Cumulative Timesteps: 1,288,735,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1288735836...
Checkpoint 1288735836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,473.86886
Policy Entropy: 3.76377
Value Function Loss: 0.01873

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.70544

Collected Steps per Second: 22,500.18027
Overall Steps per Second: 10,674.72613

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.46274
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68583

Cumulative Model Updates: 154,556
Cumulative Timesteps: 1,288,785,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,338.48447
Policy Entropy: 3.76664
Value Function Loss: 0.01798

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.56102
Value Function Update Magnitude: 0.74681

Collected Steps per Second: 22,704.27800
Overall Steps per Second: 10,745.25665

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.45138
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.65396

Cumulative Model Updates: 154,562
Cumulative Timesteps: 1,288,835,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1288835864...
Checkpoint 1288835864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,389.62414
Policy Entropy: 3.76152
Value Function Loss: 0.02144

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 22,408.01252
Overall Steps per Second: 10,624.48531

Timestep Collection Time: 2.23250
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.70856

Cumulative Model Updates: 154,568
Cumulative Timesteps: 1,288,885,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,894.11022
Policy Entropy: 3.76383
Value Function Loss: 0.01909

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.53813
Value Function Update Magnitude: 0.50974

Collected Steps per Second: 22,669.97460
Overall Steps per Second: 10,591.04320

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.51551
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.72116

Cumulative Model Updates: 154,574
Cumulative Timesteps: 1,288,935,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1288935892...
Checkpoint 1288935892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 583,281.62646
Policy Entropy: 3.75893
Value Function Loss: 0.01785

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.48310
Value Function Update Magnitude: 0.59191

Collected Steps per Second: 22,552.80775
Overall Steps per Second: 10,591.20372

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.50468
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.72241

Cumulative Model Updates: 154,580
Cumulative Timesteps: 1,288,985,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,386.55257
Policy Entropy: 3.76993
Value Function Loss: 0.01551

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.43170
Value Function Update Magnitude: 0.52279

Collected Steps per Second: 23,008.13249
Overall Steps per Second: 10,793.37664

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.63284

Cumulative Model Updates: 154,586
Cumulative Timesteps: 1,289,035,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1289035912...
Checkpoint 1289035912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,745.10987
Policy Entropy: 3.77181
Value Function Loss: 0.01477

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.45268
Value Function Update Magnitude: 0.46451

Collected Steps per Second: 23,051.12417
Overall Steps per Second: 10,753.09910

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.65243

Cumulative Model Updates: 154,592
Cumulative Timesteps: 1,289,085,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,966.69696
Policy Entropy: 3.76734
Value Function Loss: 0.01646

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.49373
Value Function Update Magnitude: 0.58146

Collected Steps per Second: 22,364.73373
Overall Steps per Second: 10,722.06551

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.42888
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.66571

Cumulative Model Updates: 154,598
Cumulative Timesteps: 1,289,135,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1289135966...
Checkpoint 1289135966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,399.66395
Policy Entropy: 3.76088
Value Function Loss: 0.01635

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.66962

Collected Steps per Second: 22,679.67729
Overall Steps per Second: 10,689.52456

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.67879

Cumulative Model Updates: 154,604
Cumulative Timesteps: 1,289,185,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,651.72572
Policy Entropy: 3.76093
Value Function Loss: 0.01549

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.51357
Value Function Update Magnitude: 0.63125

Collected Steps per Second: 22,450.53621
Overall Steps per Second: 10,532.67111

Timestep Collection Time: 2.22828
Timestep Consumption Time: 2.52133
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.74960

Cumulative Model Updates: 154,610
Cumulative Timesteps: 1,289,236,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1289236006...
Checkpoint 1289236006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,651.72572
Policy Entropy: 3.77487
Value Function Loss: 0.01505

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.47332
Value Function Update Magnitude: 0.55301

Collected Steps per Second: 22,553.05773
Overall Steps per Second: 10,595.69893

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.71965

Cumulative Model Updates: 154,616
Cumulative Timesteps: 1,289,286,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,651.72572
Policy Entropy: 3.76078
Value Function Loss: 0.01469

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13731
Policy Update Magnitude: 0.48324
Value Function Update Magnitude: 0.53509

Collected Steps per Second: 22,273.10185
Overall Steps per Second: 10,531.87706

Timestep Collection Time: 2.24495
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.74768

Cumulative Model Updates: 154,622
Cumulative Timesteps: 1,289,336,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1289336016...
Checkpoint 1289336016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,651.72572
Policy Entropy: 3.75373
Value Function Loss: 0.01381

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13265
Policy Update Magnitude: 0.47107
Value Function Update Magnitude: 0.48399

Collected Steps per Second: 22,215.25845
Overall Steps per Second: 10,578.76286

Timestep Collection Time: 2.25134
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.72777

Cumulative Model Updates: 154,628
Cumulative Timesteps: 1,289,386,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,651.72572
Policy Entropy: 3.74047
Value Function Loss: 0.01354

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.43606
Value Function Update Magnitude: 0.40507

Collected Steps per Second: 22,085.09182
Overall Steps per Second: 10,468.98797

Timestep Collection Time: 2.26433
Timestep Consumption Time: 2.51244
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.77677

Cumulative Model Updates: 154,634
Cumulative Timesteps: 1,289,436,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1289436038...
Checkpoint 1289436038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,843.37335
Policy Entropy: 3.75734
Value Function Loss: 0.01426

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.41226
Value Function Update Magnitude: 0.41969

Collected Steps per Second: 22,463.95683
Overall Steps per Second: 10,630.50417

Timestep Collection Time: 2.22677
Timestep Consumption Time: 2.47875
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.70552

Cumulative Model Updates: 154,640
Cumulative Timesteps: 1,289,486,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,843.37335
Policy Entropy: 3.74686
Value Function Loss: 0.01453

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.41572
Value Function Update Magnitude: 0.49489

Collected Steps per Second: 22,780.15330
Overall Steps per Second: 10,614.84551

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.71227

Cumulative Model Updates: 154,646
Cumulative Timesteps: 1,289,536,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1289536080...
Checkpoint 1289536080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,843.37335
Policy Entropy: 3.75165
Value Function Loss: 0.01328

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13923
Policy Update Magnitude: 0.41631
Value Function Update Magnitude: 0.46362

Collected Steps per Second: 22,458.68206
Overall Steps per Second: 10,607.32321

Timestep Collection Time: 2.22765
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.71655

Cumulative Model Updates: 154,652
Cumulative Timesteps: 1,289,586,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,767.40454
Policy Entropy: 3.74793
Value Function Loss: 0.01288

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.39410
Value Function Update Magnitude: 0.39252

Collected Steps per Second: 22,899.61681
Overall Steps per Second: 10,819.28546

Timestep Collection Time: 2.18379
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.62212

Cumulative Model Updates: 154,658
Cumulative Timesteps: 1,289,636,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1289636118...
Checkpoint 1289636118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,033.79336
Policy Entropy: 3.76133
Value Function Loss: 0.01397

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.38664
Value Function Update Magnitude: 0.35441

Collected Steps per Second: 22,065.28353
Overall Steps per Second: 10,689.91033

Timestep Collection Time: 2.26609
Timestep Consumption Time: 2.41140
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.67749

Cumulative Model Updates: 154,664
Cumulative Timesteps: 1,289,686,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,033.79336
Policy Entropy: 3.74753
Value Function Loss: 0.01625

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.40753
Value Function Update Magnitude: 0.42589

Collected Steps per Second: 22,232.88467
Overall Steps per Second: 10,702.18656

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.67344

Cumulative Model Updates: 154,670
Cumulative Timesteps: 1,289,736,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1289736136...
Checkpoint 1289736136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 352,033.79336
Policy Entropy: 3.75947
Value Function Loss: 0.01579

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.45181
Value Function Update Magnitude: 0.44852

Collected Steps per Second: 21,650.77950
Overall Steps per Second: 10,745.46808

Timestep Collection Time: 2.30966
Timestep Consumption Time: 2.34402
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.65368

Cumulative Model Updates: 154,676
Cumulative Timesteps: 1,289,786,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,033.79336
Policy Entropy: 3.73096
Value Function Loss: 0.01712

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.14006
Policy Update Magnitude: 0.45210
Value Function Update Magnitude: 0.40851

Collected Steps per Second: 21,610.22822
Overall Steps per Second: 10,497.91468

Timestep Collection Time: 2.31390
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.76323

Cumulative Model Updates: 154,682
Cumulative Timesteps: 1,289,836,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1289836146...
Checkpoint 1289836146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,330.68210
Policy Entropy: 3.75381
Value Function Loss: 0.01581

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.45127
Value Function Update Magnitude: 0.38486

Collected Steps per Second: 22,127.98634
Overall Steps per Second: 10,626.61991

Timestep Collection Time: 2.25967
Timestep Consumption Time: 2.44568
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.70535

Cumulative Model Updates: 154,688
Cumulative Timesteps: 1,289,886,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,247.34595
Policy Entropy: 3.73629
Value Function Loss: 0.01765

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.47318
Value Function Update Magnitude: 0.37625

Collected Steps per Second: 22,441.98713
Overall Steps per Second: 10,817.59444

Timestep Collection Time: 2.22797
Timestep Consumption Time: 2.39413
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.62210

Cumulative Model Updates: 154,694
Cumulative Timesteps: 1,289,936,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1289936148...
Checkpoint 1289936148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,151.79464
Policy Entropy: 3.75833
Value Function Loss: 0.01513

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.44393
Value Function Update Magnitude: 0.41946

Collected Steps per Second: 22,064.94217
Overall Steps per Second: 10,654.63783

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.42695
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.69317

Cumulative Model Updates: 154,700
Cumulative Timesteps: 1,289,986,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,625.95626
Policy Entropy: 3.74842
Value Function Loss: 0.01534

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.43789
Value Function Update Magnitude: 0.46272

Collected Steps per Second: 22,023.17352
Overall Steps per Second: 10,515.28381

Timestep Collection Time: 2.27079
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.75593

Cumulative Model Updates: 154,706
Cumulative Timesteps: 1,290,036,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1290036162...
Checkpoint 1290036162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,860.46346
Policy Entropy: 3.75665
Value Function Loss: 0.01409

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.43544
Value Function Update Magnitude: 0.40032

Collected Steps per Second: 22,535.82257
Overall Steps per Second: 10,636.29669

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.48279
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.70201

Cumulative Model Updates: 154,712
Cumulative Timesteps: 1,290,086,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,860.46346
Policy Entropy: 3.75480
Value Function Loss: 0.01470

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.48115
Value Function Update Magnitude: 0.46003

Collected Steps per Second: 22,779.47794
Overall Steps per Second: 10,782.22568

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.44328
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.63912

Cumulative Model Updates: 154,718
Cumulative Timesteps: 1,290,136,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1290136194...
Checkpoint 1290136194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,029.76361
Policy Entropy: 3.76177
Value Function Loss: 0.01509

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 22,542.00483
Overall Steps per Second: 10,780.04874

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.42167
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.64117

Cumulative Model Updates: 154,724
Cumulative Timesteps: 1,290,186,226

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,095.68332
Policy Entropy: 3.75844
Value Function Loss: 0.01543

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07812
Policy Update Magnitude: 0.64235
Value Function Update Magnitude: 0.58912

Collected Steps per Second: 22,747.00175
Overall Steps per Second: 10,817.14820

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.62395

Cumulative Model Updates: 154,730
Cumulative Timesteps: 1,290,236,244

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1290236244...
Checkpoint 1290236244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,095.68332
Policy Entropy: 3.74963
Value Function Loss: 0.01884

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.58807
Value Function Update Magnitude: 0.47480

Collected Steps per Second: 22,303.27180
Overall Steps per Second: 10,752.11502

Timestep Collection Time: 2.24299
Timestep Consumption Time: 2.40968
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.65267

Cumulative Model Updates: 154,736
Cumulative Timesteps: 1,290,286,270

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,072.72170
Policy Entropy: 3.76257
Value Function Loss: 0.01876

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.58613
Value Function Update Magnitude: 0.38610

Collected Steps per Second: 22,523.46201
Overall Steps per Second: 10,764.58825

Timestep Collection Time: 2.21991
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.64486

Cumulative Model Updates: 154,742
Cumulative Timesteps: 1,290,336,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1290336270...
Checkpoint 1290336270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,755.26762
Policy Entropy: 3.76023
Value Function Loss: 0.02395

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14972
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.40754

Collected Steps per Second: 22,081.19063
Overall Steps per Second: 10,673.72432

Timestep Collection Time: 2.26491
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.68552

Cumulative Model Updates: 154,748
Cumulative Timesteps: 1,290,386,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226,875.81842
Policy Entropy: 3.78216
Value Function Loss: 0.02164

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15790
Policy Update Magnitude: 0.66916
Value Function Update Magnitude: 0.67089

Collected Steps per Second: 22,404.28278
Overall Steps per Second: 10,605.56202

Timestep Collection Time: 2.23189
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.71488

Cumulative Model Updates: 154,754
Cumulative Timesteps: 1,290,436,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1290436286...
Checkpoint 1290436286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,681.19213
Policy Entropy: 3.77141
Value Function Loss: 0.02603

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.80432
Value Function Update Magnitude: 0.78817

Collected Steps per Second: 21,645.10688
Overall Steps per Second: 10,562.50369

Timestep Collection Time: 2.31082
Timestep Consumption Time: 2.42461
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73543

Cumulative Model Updates: 154,760
Cumulative Timesteps: 1,290,486,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,834.12310
Policy Entropy: 3.79177
Value Function Loss: 0.03270

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16826
Policy Update Magnitude: 0.85970
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 21,537.15294
Overall Steps per Second: 10,555.58860

Timestep Collection Time: 2.32287
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.73948

Cumulative Model Updates: 154,766
Cumulative Timesteps: 1,290,536,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1290536332...
Checkpoint 1290536332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 473,833.73331
Policy Entropy: 3.79209
Value Function Loss: 0.03503

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16145
Policy Update Magnitude: 0.79554
Value Function Update Magnitude: 0.57850

Collected Steps per Second: 21,515.40283
Overall Steps per Second: 10,501.71023

Timestep Collection Time: 2.32438
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.76208

Cumulative Model Updates: 154,772
Cumulative Timesteps: 1,290,586,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,888.84226
Policy Entropy: 3.78817
Value Function Loss: 0.03147

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15573
Policy Update Magnitude: 0.71484
Value Function Update Magnitude: 0.59548

Collected Steps per Second: 21,800.88700
Overall Steps per Second: 10,570.10982

Timestep Collection Time: 2.29404
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.73146

Cumulative Model Updates: 154,778
Cumulative Timesteps: 1,290,636,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1290636354...
Checkpoint 1290636354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,045.02996
Policy Entropy: 3.76614
Value Function Loss: 0.02602

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.63344
Value Function Update Magnitude: 0.53325

Collected Steps per Second: 22,029.93197
Overall Steps per Second: 10,524.58214

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.75116

Cumulative Model Updates: 154,784
Cumulative Timesteps: 1,290,686,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,042.12085
Policy Entropy: 3.77760
Value Function Loss: 0.02208

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12447
Policy Update Magnitude: 0.68648
Value Function Update Magnitude: 0.56769

Collected Steps per Second: 22,582.82049
Overall Steps per Second: 10,850.10066

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.39552
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.61083

Cumulative Model Updates: 154,790
Cumulative Timesteps: 1,290,736,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1290736386...
Checkpoint 1290736386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,130.93184
Policy Entropy: 3.77992
Value Function Loss: 0.02267

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.67899
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 22,419.11611
Overall Steps per Second: 10,708.48557

Timestep Collection Time: 2.23140
Timestep Consumption Time: 2.44022
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.67162

Cumulative Model Updates: 154,796
Cumulative Timesteps: 1,290,786,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,650.39970
Policy Entropy: 3.79182
Value Function Loss: 0.02120

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.66558
Value Function Update Magnitude: 0.58901

Collected Steps per Second: 22,529.50220
Overall Steps per Second: 10,863.72687

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.38469
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.60542

Cumulative Model Updates: 154,802
Cumulative Timesteps: 1,290,836,444

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1290836444...
Checkpoint 1290836444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,065.09931
Policy Entropy: 3.77747
Value Function Loss: 0.02146

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.63338
Value Function Update Magnitude: 0.52821

Collected Steps per Second: 22,520.49985
Overall Steps per Second: 10,734.84070

Timestep Collection Time: 2.22144
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.66034

Cumulative Model Updates: 154,808
Cumulative Timesteps: 1,290,886,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,728.99773
Policy Entropy: 3.78234
Value Function Loss: 0.02071

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.63995
Value Function Update Magnitude: 0.55261

Collected Steps per Second: 22,177.85980
Overall Steps per Second: 10,508.47661

Timestep Collection Time: 2.25531
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75978

Cumulative Model Updates: 154,814
Cumulative Timesteps: 1,290,936,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1290936490...
Checkpoint 1290936490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,316.69093
Policy Entropy: 3.77000
Value Function Loss: 0.02087

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.60477
Value Function Update Magnitude: 0.52448

Collected Steps per Second: 22,396.25209
Overall Steps per Second: 10,583.00167

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.72569

Cumulative Model Updates: 154,820
Cumulative Timesteps: 1,290,986,502

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,117.28832
Policy Entropy: 3.76809
Value Function Loss: 0.01996

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.48115

Collected Steps per Second: 22,076.73085
Overall Steps per Second: 10,485.94551

Timestep Collection Time: 2.26592
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.77058

Cumulative Model Updates: 154,826
Cumulative Timesteps: 1,291,036,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1291036526...
Checkpoint 1291036526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,376.63851
Policy Entropy: 3.76886
Value Function Loss: 0.01770

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.50317
Value Function Update Magnitude: 0.45823

Collected Steps per Second: 22,322.16960
Overall Steps per Second: 10,558.94174

Timestep Collection Time: 2.24109
Timestep Consumption Time: 2.49669
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.73779

Cumulative Model Updates: 154,832
Cumulative Timesteps: 1,291,086,552

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,368.38372
Policy Entropy: 3.76612
Value Function Loss: 0.01921

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.51232
Value Function Update Magnitude: 0.44867

Collected Steps per Second: 22,286.62383
Overall Steps per Second: 10,477.29894

Timestep Collection Time: 2.24377
Timestep Consumption Time: 2.52903
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.77279

Cumulative Model Updates: 154,838
Cumulative Timesteps: 1,291,136,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1291136558...
Checkpoint 1291136558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,741.49050
Policy Entropy: 3.76956
Value Function Loss: 0.01939

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.52116
Value Function Update Magnitude: 0.44765

Collected Steps per Second: 22,714.90614
Overall Steps per Second: 10,617.08710

Timestep Collection Time: 2.20278
Timestep Consumption Time: 2.51000
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.71278

Cumulative Model Updates: 154,844
Cumulative Timesteps: 1,291,186,594

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,902.38226
Policy Entropy: 3.76940
Value Function Loss: 0.02031

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.55814
Value Function Update Magnitude: 0.48878

Collected Steps per Second: 22,597.47919
Overall Steps per Second: 10,632.00880

Timestep Collection Time: 2.21299
Timestep Consumption Time: 2.49054
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.70353

Cumulative Model Updates: 154,850
Cumulative Timesteps: 1,291,236,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1291236602...
Checkpoint 1291236602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,298.45005
Policy Entropy: 3.78364
Value Function Loss: 0.01805

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.54216
Value Function Update Magnitude: 0.48084

Collected Steps per Second: 22,649.31291
Overall Steps per Second: 10,691.74591

Timestep Collection Time: 2.20801
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.67744

Cumulative Model Updates: 154,856
Cumulative Timesteps: 1,291,286,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,298.45005
Policy Entropy: 3.78197
Value Function Loss: 0.01668

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.49571
Value Function Update Magnitude: 0.45089

Collected Steps per Second: 22,463.13744
Overall Steps per Second: 10,708.49200

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.67218

Cumulative Model Updates: 154,862
Cumulative Timesteps: 1,291,336,644

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1291336644...
Checkpoint 1291336644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,771.63149
Policy Entropy: 3.77725
Value Function Loss: 0.01525

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.42510
Value Function Update Magnitude: 0.42598

Collected Steps per Second: 22,389.72269
Overall Steps per Second: 10,630.44786

Timestep Collection Time: 2.23433
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.70592

Cumulative Model Updates: 154,868
Cumulative Timesteps: 1,291,386,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,856.82869
Policy Entropy: 3.76952
Value Function Loss: 0.01493

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.40451
Value Function Update Magnitude: 0.43270

Collected Steps per Second: 23,125.22924
Overall Steps per Second: 10,931.55047

Timestep Collection Time: 2.16231
Timestep Consumption Time: 2.41197
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.57428

Cumulative Model Updates: 154,874
Cumulative Timesteps: 1,291,436,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1291436674...
Checkpoint 1291436674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,788.60026
Policy Entropy: 3.76279
Value Function Loss: 0.01427

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.39223
Value Function Update Magnitude: 0.41976

Collected Steps per Second: 22,151.16661
Overall Steps per Second: 10,641.15105

Timestep Collection Time: 2.25848
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.70137

Cumulative Model Updates: 154,880
Cumulative Timesteps: 1,291,486,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247,969.98135
Policy Entropy: 3.75092
Value Function Loss: 0.01459

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.39246
Value Function Update Magnitude: 0.39169

Collected Steps per Second: 22,271.46200
Overall Steps per Second: 10,601.63348

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.71720

Cumulative Model Updates: 154,886
Cumulative Timesteps: 1,291,536,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1291536712...
Checkpoint 1291536712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247,969.98135
Policy Entropy: 3.75031
Value Function Loss: 0.01380

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.38092
Value Function Update Magnitude: 0.36014

Collected Steps per Second: 21,686.23176
Overall Steps per Second: 10,642.62412

Timestep Collection Time: 2.30662
Timestep Consumption Time: 2.39353
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70016

Cumulative Model Updates: 154,892
Cumulative Timesteps: 1,291,586,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,793.97324
Policy Entropy: 3.75354
Value Function Loss: 0.01479

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.37613
Value Function Update Magnitude: 0.39099

Collected Steps per Second: 22,218.94086
Overall Steps per Second: 10,758.93273

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.39706
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.64749

Cumulative Model Updates: 154,898
Cumulative Timesteps: 1,291,636,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1291636736...
Checkpoint 1291636736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,773.04302
Policy Entropy: 3.75636
Value Function Loss: 0.01490

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.40227
Value Function Update Magnitude: 0.46714

Collected Steps per Second: 21,938.90827
Overall Steps per Second: 10,607.09790

Timestep Collection Time: 2.27924
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.71420

Cumulative Model Updates: 154,904
Cumulative Timesteps: 1,291,686,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,529.57144
Policy Entropy: 3.76644
Value Function Loss: 0.01660

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.41112
Value Function Update Magnitude: 0.49353

Collected Steps per Second: 22,912.18014
Overall Steps per Second: 10,866.71231

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.60323

Cumulative Model Updates: 154,910
Cumulative Timesteps: 1,291,736,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1291736762...
Checkpoint 1291736762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,359.86867
Policy Entropy: 3.77780
Value Function Loss: 0.01651

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.43363
Value Function Update Magnitude: 0.59447

Collected Steps per Second: 22,435.05550
Overall Steps per Second: 10,643.58008

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.46931
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.69823

Cumulative Model Updates: 154,916
Cumulative Timesteps: 1,291,786,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,707.39042
Policy Entropy: 3.78629
Value Function Loss: 0.01725

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.47146
Value Function Update Magnitude: 0.73143

Collected Steps per Second: 22,743.09652
Overall Steps per Second: 10,833.63927

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.61562

Cumulative Model Updates: 154,922
Cumulative Timesteps: 1,291,836,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1291836772...
Checkpoint 1291836772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,399.74669
Policy Entropy: 3.79764
Value Function Loss: 0.01766

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.51995
Value Function Update Magnitude: 0.79137

Collected Steps per Second: 22,549.02615
Overall Steps per Second: 10,812.76256

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.40812
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.62675

Cumulative Model Updates: 154,928
Cumulative Timesteps: 1,291,886,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,872.05082
Policy Entropy: 3.81752
Value Function Loss: 0.01962

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13014
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.86462

Collected Steps per Second: 22,565.36070
Overall Steps per Second: 10,847.35569

Timestep Collection Time: 2.21623
Timestep Consumption Time: 2.39411
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.61034

Cumulative Model Updates: 154,934
Cumulative Timesteps: 1,291,936,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1291936810...
Checkpoint 1291936810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277,245.76539
Policy Entropy: 3.83048
Value Function Loss: 0.02098

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12320
Policy Update Magnitude: 0.56287
Value Function Update Magnitude: 0.93494

Collected Steps per Second: 22,141.98562
Overall Steps per Second: 10,708.76944

Timestep Collection Time: 2.25851
Timestep Consumption Time: 2.41130
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.66982

Cumulative Model Updates: 154,940
Cumulative Timesteps: 1,291,986,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,318.20495
Policy Entropy: 3.83055
Value Function Loss: 0.02312

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.63506
Value Function Update Magnitude: 0.98530

Collected Steps per Second: 22,494.83300
Overall Steps per Second: 10,761.43556

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.42494
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.64901

Cumulative Model Updates: 154,946
Cumulative Timesteps: 1,292,036,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1292036848...
Checkpoint 1292036848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,158.42393
Policy Entropy: 3.81026
Value Function Loss: 0.02497

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.67706
Value Function Update Magnitude: 1.00781

Collected Steps per Second: 22,528.19797
Overall Steps per Second: 10,657.83449

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.69326

Cumulative Model Updates: 154,952
Cumulative Timesteps: 1,292,086,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,369.68900
Policy Entropy: 3.79625
Value Function Loss: 0.02331

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.68417
Value Function Update Magnitude: 1.01533

Collected Steps per Second: 22,947.07591
Overall Steps per Second: 10,844.41786

Timestep Collection Time: 2.17945
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.61177

Cumulative Model Updates: 154,958
Cumulative Timesteps: 1,292,136,880

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1292136880...
Checkpoint 1292136880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,888.79160
Policy Entropy: 3.80423
Value Function Loss: 0.02031

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.64004
Value Function Update Magnitude: 0.95756

Collected Steps per Second: 22,187.00222
Overall Steps per Second: 10,677.29104

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.68377

Cumulative Model Updates: 154,964
Cumulative Timesteps: 1,292,186,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,027.67678
Policy Entropy: 3.79767
Value Function Loss: 0.01825

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12654
Policy Update Magnitude: 0.59153
Value Function Update Magnitude: 0.85618

Collected Steps per Second: 22,718.57223
Overall Steps per Second: 10,667.08457

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.68882

Cumulative Model Updates: 154,970
Cumulative Timesteps: 1,292,236,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1292236906...
Checkpoint 1292236906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,000.82583
Policy Entropy: 3.79346
Value Function Loss: 0.01746

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.83207

Collected Steps per Second: 22,801.76753
Overall Steps per Second: 10,882.47633

Timestep Collection Time: 2.19378
Timestep Consumption Time: 2.40279
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.59656

Cumulative Model Updates: 154,976
Cumulative Timesteps: 1,292,286,928

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,193.64225
Policy Entropy: 3.78087
Value Function Loss: 0.02202

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.80900

Collected Steps per Second: 22,595.35851
Overall Steps per Second: 10,624.89840

Timestep Collection Time: 2.21320
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.70668

Cumulative Model Updates: 154,982
Cumulative Timesteps: 1,292,336,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1292336936...
Checkpoint 1292336936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,074.88072
Policy Entropy: 3.78702
Value Function Loss: 0.02296

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.55249
Value Function Update Magnitude: 0.67616

Collected Steps per Second: 22,268.13743
Overall Steps per Second: 10,585.12135

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.72399

Cumulative Model Updates: 154,988
Cumulative Timesteps: 1,292,386,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263,968.80932
Policy Entropy: 3.77183
Value Function Loss: 0.02517

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13699
Policy Update Magnitude: 0.53383
Value Function Update Magnitude: 0.54991

Collected Steps per Second: 22,314.16713
Overall Steps per Second: 10,607.56663

Timestep Collection Time: 2.24154
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.71531

Cumulative Model Updates: 154,994
Cumulative Timesteps: 1,292,436,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1292436958...
Checkpoint 1292436958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,870.72373
Policy Entropy: 3.78364
Value Function Loss: 0.02052

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.51226
Value Function Update Magnitude: 0.52068

Collected Steps per Second: 22,406.33280
Overall Steps per Second: 10,668.40999

Timestep Collection Time: 2.23214
Timestep Consumption Time: 2.45591
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.68805

Cumulative Model Updates: 155,000
Cumulative Timesteps: 1,292,486,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,058.77378
Policy Entropy: 3.78436
Value Function Loss: 0.01946

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.48859
Value Function Update Magnitude: 0.65921

Collected Steps per Second: 20,670.80080
Overall Steps per Second: 10,361.91879

Timestep Collection Time: 2.41945
Timestep Consumption Time: 2.40707
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.82652

Cumulative Model Updates: 155,006
Cumulative Timesteps: 1,292,536,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1292536984...
Checkpoint 1292536984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,337.75257
Policy Entropy: 3.79915
Value Function Loss: 0.01572

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.54161
Value Function Update Magnitude: 0.70360

Collected Steps per Second: 21,594.09068
Overall Steps per Second: 10,543.54556

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.74357

Cumulative Model Updates: 155,012
Cumulative Timesteps: 1,292,586,998

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,440.29954
Policy Entropy: 3.76975
Value Function Loss: 0.01893

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.61076
Value Function Update Magnitude: 0.72421

Collected Steps per Second: 22,209.83113
Overall Steps per Second: 10,823.38906

Timestep Collection Time: 2.25198
Timestep Consumption Time: 2.36913
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.62110

Cumulative Model Updates: 155,018
Cumulative Timesteps: 1,292,637,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1292637014...
Checkpoint 1292637014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,823.03866
Policy Entropy: 3.77464
Value Function Loss: 0.02102

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.59513
Value Function Update Magnitude: 0.65890

Collected Steps per Second: 22,036.74006
Overall Steps per Second: 10,713.00699

Timestep Collection Time: 2.26966
Timestep Consumption Time: 2.39905
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.66872

Cumulative Model Updates: 155,024
Cumulative Timesteps: 1,292,687,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 170,770.46132
Policy Entropy: 3.76945
Value Function Loss: 0.02319

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.59835
Value Function Update Magnitude: 0.70662

Collected Steps per Second: 22,240.79821
Overall Steps per Second: 10,621.80023

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.46016
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.70918

Cumulative Model Updates: 155,030
Cumulative Timesteps: 1,292,737,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1292737050...
Checkpoint 1292737050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,380.33163
Policy Entropy: 3.80503
Value Function Loss: 0.02332

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.62061
Value Function Update Magnitude: 0.85750

Collected Steps per Second: 22,832.56823
Overall Steps per Second: 10,908.02264

Timestep Collection Time: 2.18985
Timestep Consumption Time: 2.39393
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.58378

Cumulative Model Updates: 155,036
Cumulative Timesteps: 1,292,787,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.80512
Policy Entropy: 3.80655
Value Function Loss: 0.02331

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.60037
Value Function Update Magnitude: 0.77795

Collected Steps per Second: 22,636.23493
Overall Steps per Second: 10,864.52479

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.39329
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60213

Cumulative Model Updates: 155,042
Cumulative Timesteps: 1,292,837,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1292837050...
Checkpoint 1292837050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,074.15637
Policy Entropy: 3.81466
Value Function Loss: 0.02319

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12015
Policy Update Magnitude: 0.58073
Value Function Update Magnitude: 0.70058

Collected Steps per Second: 22,766.82754
Overall Steps per Second: 10,725.03505

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.46739
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.66497

Cumulative Model Updates: 155,048
Cumulative Timesteps: 1,292,887,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,676.01567
Policy Entropy: 3.77753
Value Function Loss: 0.02454

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.79642

Collected Steps per Second: 22,529.88180
Overall Steps per Second: 10,640.16082

Timestep Collection Time: 2.22034
Timestep Consumption Time: 2.48109
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.70143

Cumulative Model Updates: 155,054
Cumulative Timesteps: 1,292,937,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1292937106...
Checkpoint 1292937106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,290.42581
Policy Entropy: 3.78248
Value Function Loss: 0.02648

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12709
Policy Update Magnitude: 0.63900
Value Function Update Magnitude: 0.85319

Collected Steps per Second: 22,180.03648
Overall Steps per Second: 10,564.99398

Timestep Collection Time: 2.25500
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.73412

Cumulative Model Updates: 155,060
Cumulative Timesteps: 1,292,987,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,772.32445
Policy Entropy: 3.81248
Value Function Loss: 0.02900

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.72299
Value Function Update Magnitude: 0.89930

Collected Steps per Second: 22,671.30708
Overall Steps per Second: 10,816.91620

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.62294

Cumulative Model Updates: 155,066
Cumulative Timesteps: 1,293,037,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1293037128...
Checkpoint 1293037128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.80383
Policy Entropy: 3.82367
Value Function Loss: 0.02888

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.74014
Value Function Update Magnitude: 0.89372

Collected Steps per Second: 22,917.02599
Overall Steps per Second: 10,620.82688

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.52726
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.71018

Cumulative Model Updates: 155,072
Cumulative Timesteps: 1,293,087,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141.31130
Policy Entropy: 3.80194
Value Function Loss: 0.02744

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.67658
Value Function Update Magnitude: 0.76873

Collected Steps per Second: 23,001.03584
Overall Steps per Second: 10,820.13958

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.44749
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.62157

Cumulative Model Updates: 155,078
Cumulative Timesteps: 1,293,137,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1293137160...
Checkpoint 1293137160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,765.80561
Policy Entropy: 3.76927
Value Function Loss: 0.02470

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.63821
Value Function Update Magnitude: 0.62694

Collected Steps per Second: 22,609.74859
Overall Steps per Second: 10,698.92993

Timestep Collection Time: 2.21179
Timestep Consumption Time: 2.46232
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.67411

Cumulative Model Updates: 155,084
Cumulative Timesteps: 1,293,187,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,605.85518
Policy Entropy: 3.78985
Value Function Loss: 0.02147

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.70085
Value Function Update Magnitude: 0.49078

Collected Steps per Second: 22,853.96650
Overall Steps per Second: 10,683.46865

Timestep Collection Time: 2.18903
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.68275

Cumulative Model Updates: 155,090
Cumulative Timesteps: 1,293,237,196

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1293237196...
Checkpoint 1293237196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,971.05098
Policy Entropy: 3.80010
Value Function Loss: 0.01867

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07533
Policy Update Magnitude: 0.70409
Value Function Update Magnitude: 0.52199

Collected Steps per Second: 22,672.44689
Overall Steps per Second: 10,803.08506

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.42318
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.62868

Cumulative Model Updates: 155,096
Cumulative Timesteps: 1,293,287,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,983.29304
Policy Entropy: 3.81812
Value Function Loss: 0.01675

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.66113
Value Function Update Magnitude: 0.55753

Collected Steps per Second: 22,934.76406
Overall Steps per Second: 10,895.70131

Timestep Collection Time: 2.18123
Timestep Consumption Time: 2.41012
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.59135

Cumulative Model Updates: 155,102
Cumulative Timesteps: 1,293,337,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1293337226...
Checkpoint 1293337226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,712.76229
Policy Entropy: 3.79648
Value Function Loss: 0.02019

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.65749
Value Function Update Magnitude: 0.69240

Collected Steps per Second: 22,060.77089
Overall Steps per Second: 10,656.89244

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.42553
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.69217

Cumulative Model Updates: 155,108
Cumulative Timesteps: 1,293,387,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,574.19198
Policy Entropy: 3.79657
Value Function Loss: 0.02239

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13812
Policy Update Magnitude: 0.63711
Value Function Update Magnitude: 0.81091

Collected Steps per Second: 22,194.53858
Overall Steps per Second: 10,540.96772

Timestep Collection Time: 2.25380
Timestep Consumption Time: 2.49169
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.74548

Cumulative Model Updates: 155,114
Cumulative Timesteps: 1,293,437,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1293437252...
Checkpoint 1293437252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,127.48428
Policy Entropy: 3.79075
Value Function Loss: 0.02128

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17833
Policy Update Magnitude: 0.64862
Value Function Update Magnitude: 0.82352

Collected Steps per Second: 22,276.87441
Overall Steps per Second: 10,640.80551

Timestep Collection Time: 2.24466
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.69927

Cumulative Model Updates: 155,120
Cumulative Timesteps: 1,293,487,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,267.92349
Policy Entropy: 3.78755
Value Function Loss: 0.02110

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.16247
Policy Update Magnitude: 0.58553
Value Function Update Magnitude: 0.72944

Collected Steps per Second: 22,448.45859
Overall Steps per Second: 10,537.11087

Timestep Collection Time: 2.22884
Timestep Consumption Time: 2.51952
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74836

Cumulative Model Updates: 155,126
Cumulative Timesteps: 1,293,537,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1293537290...
Checkpoint 1293537290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,597.69808
Policy Entropy: 3.80073
Value Function Loss: 0.02022

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.67476
Value Function Update Magnitude: 0.69682

Collected Steps per Second: 22,133.07169
Overall Steps per Second: 10,516.09290

Timestep Collection Time: 2.25942
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.75538

Cumulative Model Updates: 155,132
Cumulative Timesteps: 1,293,587,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,640.60600
Policy Entropy: 3.79771
Value Function Loss: 0.03183

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.17326
Policy Update Magnitude: 0.72371
Value Function Update Magnitude: 0.71134

Collected Steps per Second: 21,788.30402
Overall Steps per Second: 10,437.81697

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.79219

Cumulative Model Updates: 155,138
Cumulative Timesteps: 1,293,637,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1293637318...
Checkpoint 1293637318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.40421
Policy Entropy: 3.85114
Value Function Loss: 0.03574

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.77851
Value Function Update Magnitude: 0.74448

Collected Steps per Second: 22,332.45102
Overall Steps per Second: 10,668.74583

Timestep Collection Time: 2.23934
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.68752

Cumulative Model Updates: 155,144
Cumulative Timesteps: 1,293,687,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,409.49998
Policy Entropy: 3.84570
Value Function Loss: 0.03734

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.86641
Value Function Update Magnitude: 0.73919

Collected Steps per Second: 22,695.56962
Overall Steps per Second: 10,703.94429

Timestep Collection Time: 2.20404
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.67323

Cumulative Model Updates: 155,150
Cumulative Timesteps: 1,293,737,350

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1293737350...
Checkpoint 1293737350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 250.53194
Policy Entropy: 3.85549
Value Function Loss: 0.03110

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.85987
Value Function Update Magnitude: 0.75396

Collected Steps per Second: 22,347.16338
Overall Steps per Second: 10,609.18733

Timestep Collection Time: 2.23840
Timestep Consumption Time: 2.47657
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.71497

Cumulative Model Updates: 155,156
Cumulative Timesteps: 1,293,787,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,965.75201
Policy Entropy: 3.82927
Value Function Loss: 0.02813

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.86877
Value Function Update Magnitude: 0.81382

Collected Steps per Second: 23,073.25174
Overall Steps per Second: 10,689.96838

Timestep Collection Time: 2.16710
Timestep Consumption Time: 2.51037
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67747

Cumulative Model Updates: 155,162
Cumulative Timesteps: 1,293,837,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1293837374...
Checkpoint 1293837374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,689.88406
Policy Entropy: 3.82713
Value Function Loss: 0.02288

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07468
Policy Update Magnitude: 0.80822
Value Function Update Magnitude: 0.87731

Collected Steps per Second: 22,547.32458
Overall Steps per Second: 10,652.18560

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.69387

Cumulative Model Updates: 155,168
Cumulative Timesteps: 1,293,887,374

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,954.21343
Policy Entropy: 3.82242
Value Function Loss: 0.02251

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12351
Policy Update Magnitude: 0.69250
Value Function Update Magnitude: 0.81606

Collected Steps per Second: 22,559.22914
Overall Steps per Second: 10,638.08566

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.70216

Cumulative Model Updates: 155,174
Cumulative Timesteps: 1,293,937,396

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1293937396...
Checkpoint 1293937396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,103.94180
Policy Entropy: 3.80502
Value Function Loss: 0.02302

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.56594
Value Function Update Magnitude: 0.71861

Collected Steps per Second: 21,977.90902
Overall Steps per Second: 10,464.19158

Timestep Collection Time: 2.27638
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.78107

Cumulative Model Updates: 155,180
Cumulative Timesteps: 1,293,987,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,566.17588
Policy Entropy: 3.79699
Value Function Loss: 0.02821

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.71300

Collected Steps per Second: 22,206.07890
Overall Steps per Second: 10,545.46991

Timestep Collection Time: 2.25164
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.74137

Cumulative Model Updates: 155,186
Cumulative Timesteps: 1,294,037,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1294037426...
Checkpoint 1294037426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,532.57999
Policy Entropy: 3.81555
Value Function Loss: 0.02931

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.67359
Value Function Update Magnitude: 0.69676

Collected Steps per Second: 22,392.25524
Overall Steps per Second: 10,648.35223

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.46275
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.69575

Cumulative Model Updates: 155,192
Cumulative Timesteps: 1,294,087,428

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,299.05505
Policy Entropy: 3.83621
Value Function Loss: 0.03117

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.75798
Value Function Update Magnitude: 0.71334

Collected Steps per Second: 22,853.50923
Overall Steps per Second: 10,838.79697

Timestep Collection Time: 2.18907
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.61564

Cumulative Model Updates: 155,198
Cumulative Timesteps: 1,294,137,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1294137456...
Checkpoint 1294137456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,637.21552
Policy Entropy: 3.81276
Value Function Loss: 0.02904

Mean KL Divergence: 0.02253
SB3 Clip Fraction: 0.22746
Policy Update Magnitude: 0.62766
Value Function Update Magnitude: 0.65768

Collected Steps per Second: 22,470.76321
Overall Steps per Second: 10,612.04395

Timestep Collection Time: 2.22583
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.71314

Cumulative Model Updates: 155,204
Cumulative Timesteps: 1,294,187,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.44676
Policy Entropy: 3.81555
Value Function Loss: 0.02850

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.59856
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 22,686.99300
Overall Steps per Second: 10,820.64557

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.41844
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.62375

Cumulative Model Updates: 155,210
Cumulative Timesteps: 1,294,237,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1294237504...
Checkpoint 1294237504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.85620
Policy Entropy: 3.80508
Value Function Loss: 0.02499

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.68498
Value Function Update Magnitude: 0.66953

Collected Steps per Second: 22,479.55020
Overall Steps per Second: 10,769.10472

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.64533

Cumulative Model Updates: 155,216
Cumulative Timesteps: 1,294,287,530

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,790.56843
Policy Entropy: 3.78418
Value Function Loss: 0.02805

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.63448
Value Function Update Magnitude: 0.60334

Collected Steps per Second: 22,593.24945
Overall Steps per Second: 10,776.84692

Timestep Collection Time: 2.21340
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.64032

Cumulative Model Updates: 155,222
Cumulative Timesteps: 1,294,337,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1294337538...
Checkpoint 1294337538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 333,890.68120
Policy Entropy: 3.78830
Value Function Loss: 0.02719

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13557
Policy Update Magnitude: 0.64858
Value Function Update Magnitude: 0.57802

Collected Steps per Second: 22,384.91150
Overall Steps per Second: 10,779.10193

Timestep Collection Time: 2.23535
Timestep Consumption Time: 2.40679
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.64213

Cumulative Model Updates: 155,228
Cumulative Timesteps: 1,294,387,576

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,664.35741
Policy Entropy: 3.77037
Value Function Loss: 0.02854

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.62406
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 20,985.19588
Overall Steps per Second: 10,356.82539

Timestep Collection Time: 2.38378
Timestep Consumption Time: 2.44628
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.83005

Cumulative Model Updates: 155,234
Cumulative Timesteps: 1,294,437,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1294437600...
Checkpoint 1294437600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,052.57258
Policy Entropy: 3.78792
Value Function Loss: 0.02411

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11739
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.57665

Collected Steps per Second: 21,740.05369
Overall Steps per Second: 10,627.76444

Timestep Collection Time: 2.30045
Timestep Consumption Time: 2.40533
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.70579

Cumulative Model Updates: 155,240
Cumulative Timesteps: 1,294,487,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,690.56830
Policy Entropy: 3.79136
Value Function Loss: 0.02484

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12101
Policy Update Magnitude: 0.53058
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,181.04239
Overall Steps per Second: 10,515.93946

Timestep Collection Time: 2.25445
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.75526

Cumulative Model Updates: 155,246
Cumulative Timesteps: 1,294,537,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1294537618...
Checkpoint 1294537618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,396.13659
Policy Entropy: 3.81574
Value Function Loss: 0.02558

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.51022
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 21,763.52827
Overall Steps per Second: 10,558.65020

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73564

Cumulative Model Updates: 155,252
Cumulative Timesteps: 1,294,587,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,298.47537
Policy Entropy: 3.79835
Value Function Loss: 0.02699

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.66356

Collected Steps per Second: 22,765.25296
Overall Steps per Second: 10,626.65966

Timestep Collection Time: 2.19642
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.70534

Cumulative Model Updates: 155,258
Cumulative Timesteps: 1,294,637,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1294637622...
Checkpoint 1294637622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,580.28719
Policy Entropy: 3.77915
Value Function Loss: 0.02718

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.61807
Value Function Update Magnitude: 0.70762

Collected Steps per Second: 22,520.40236
Overall Steps per Second: 10,589.92201

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.72600

Cumulative Model Updates: 155,264
Cumulative Timesteps: 1,294,687,670

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,003.90382
Policy Entropy: 3.75307
Value Function Loss: 0.02578

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.58905
Value Function Update Magnitude: 0.75330

Collected Steps per Second: 23,018.62926
Overall Steps per Second: 10,894.28319

Timestep Collection Time: 2.17259
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.59048

Cumulative Model Updates: 155,270
Cumulative Timesteps: 1,294,737,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1294737680...
Checkpoint 1294737680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,714.88031
Policy Entropy: 3.76466
Value Function Loss: 0.02273

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.51980
Value Function Update Magnitude: 0.69347

Collected Steps per Second: 22,506.48414
Overall Steps per Second: 10,616.11733

Timestep Collection Time: 2.22327
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71340

Cumulative Model Updates: 155,276
Cumulative Timesteps: 1,294,787,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,332.22828
Policy Entropy: 3.77639
Value Function Loss: 0.01915

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.43590
Value Function Update Magnitude: 0.49687

Collected Steps per Second: 23,070.08640
Overall Steps per Second: 10,951.00667

Timestep Collection Time: 2.16896
Timestep Consumption Time: 2.40030
PPO Batch Consumption Time: 0.27626
Total Iteration Time: 4.56926

Cumulative Model Updates: 155,282
Cumulative Timesteps: 1,294,837,756

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1294837756...
Checkpoint 1294837756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,000.60703
Policy Entropy: 3.78533
Value Function Loss: 0.01648

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.37477
Value Function Update Magnitude: 0.39129

Collected Steps per Second: 22,856.14566
Overall Steps per Second: 10,643.51031

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.51171
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70070

Cumulative Model Updates: 155,288
Cumulative Timesteps: 1,294,887,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,281.05220
Policy Entropy: 3.77263
Value Function Loss: 0.01516

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.36054
Value Function Update Magnitude: 0.36179

Collected Steps per Second: 21,710.22228
Overall Steps per Second: 10,642.52035

Timestep Collection Time: 2.30325
Timestep Consumption Time: 2.39526
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69851

Cumulative Model Updates: 155,294
Cumulative Timesteps: 1,294,937,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1294937792...
Checkpoint 1294937792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,376.44028
Policy Entropy: 3.76644
Value Function Loss: 0.01645

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.36563
Value Function Update Magnitude: 0.38983

Collected Steps per Second: 21,637.11587
Overall Steps per Second: 10,633.46471

Timestep Collection Time: 2.31186
Timestep Consumption Time: 2.39234
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.70421

Cumulative Model Updates: 155,300
Cumulative Timesteps: 1,294,987,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,542.33778
Policy Entropy: 3.76172
Value Function Loss: 0.01878

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.40364
Value Function Update Magnitude: 0.40667

Collected Steps per Second: 22,118.64503
Overall Steps per Second: 10,792.66187

Timestep Collection Time: 2.26054
Timestep Consumption Time: 2.37224
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.63278

Cumulative Model Updates: 155,306
Cumulative Timesteps: 1,295,037,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1295037814...
Checkpoint 1295037814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,465.01516
Policy Entropy: 3.77528
Value Function Loss: 0.01886

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.42916
Value Function Update Magnitude: 0.42805

Collected Steps per Second: 21,718.06552
Overall Steps per Second: 10,646.77317

Timestep Collection Time: 2.30334
Timestep Consumption Time: 2.39518
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.69851

Cumulative Model Updates: 155,312
Cumulative Timesteps: 1,295,087,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,933.56008
Policy Entropy: 3.77098
Value Function Loss: 0.01994

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.42776
Value Function Update Magnitude: 0.54198

Collected Steps per Second: 22,698.71443
Overall Steps per Second: 10,790.15788

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.63867

Cumulative Model Updates: 155,318
Cumulative Timesteps: 1,295,137,890

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1295137890...
Checkpoint 1295137890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,767.94443
Policy Entropy: 3.76784
Value Function Loss: 0.01935

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.45737
Value Function Update Magnitude: 0.58369

Collected Steps per Second: 22,435.39541
Overall Steps per Second: 10,630.76880

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.47560
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.70502

Cumulative Model Updates: 155,324
Cumulative Timesteps: 1,295,187,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,767.94443
Policy Entropy: 3.76398
Value Function Loss: 0.01910

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.47014
Value Function Update Magnitude: 0.53974

Collected Steps per Second: 22,344.34846
Overall Steps per Second: 10,516.82863

Timestep Collection Time: 2.23878
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.75657

Cumulative Model Updates: 155,330
Cumulative Timesteps: 1,295,237,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1295237932...
Checkpoint 1295237932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,958.12720
Policy Entropy: 3.76946
Value Function Loss: 0.01831

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.44274
Value Function Update Magnitude: 0.38913

Collected Steps per Second: 22,469.13628
Overall Steps per Second: 10,640.40835

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.69944

Cumulative Model Updates: 155,336
Cumulative Timesteps: 1,295,287,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,743.84843
Policy Entropy: 3.76885
Value Function Loss: 0.01949

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.46071
Value Function Update Magnitude: 0.35418

Collected Steps per Second: 23,123.68806
Overall Steps per Second: 10,868.66185

Timestep Collection Time: 2.16263
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.60112

Cumulative Model Updates: 155,342
Cumulative Timesteps: 1,295,337,944

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1295337944...
Checkpoint 1295337944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,603.57169
Policy Entropy: 3.76999
Value Function Loss: 0.02102

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.50206
Value Function Update Magnitude: 0.40027

Collected Steps per Second: 22,402.18344
Overall Steps per Second: 10,644.15465

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.46549
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.69741

Cumulative Model Updates: 155,348
Cumulative Timesteps: 1,295,387,944

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,648.62668
Policy Entropy: 3.76228
Value Function Loss: 0.02464

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.51566
Value Function Update Magnitude: 0.45988

Collected Steps per Second: 22,812.07010
Overall Steps per Second: 10,859.38141

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.41259
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.60450

Cumulative Model Updates: 155,354
Cumulative Timesteps: 1,295,437,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1295437946...
Checkpoint 1295437946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,848.98050
Policy Entropy: 3.76881
Value Function Loss: 0.02407

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.50964

Collected Steps per Second: 21,058.01800
Overall Steps per Second: 10,248.94209

Timestep Collection Time: 2.37439
Timestep Consumption Time: 2.50416
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.87855

Cumulative Model Updates: 155,360
Cumulative Timesteps: 1,295,487,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,171.09523
Policy Entropy: 3.77578
Value Function Loss: 0.02179

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.62649
Value Function Update Magnitude: 0.60893

Collected Steps per Second: 21,301.06761
Overall Steps per Second: 10,399.41945

Timestep Collection Time: 2.34833
Timestep Consumption Time: 2.46174
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.81008

Cumulative Model Updates: 155,366
Cumulative Timesteps: 1,295,537,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295537968...
Checkpoint 1295537968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,837.17956
Policy Entropy: 3.77380
Value Function Loss: 0.02410

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.62909

Collected Steps per Second: 22,100.98670
Overall Steps per Second: 10,653.20167

Timestep Collection Time: 2.26279
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69436

Cumulative Model Updates: 155,372
Cumulative Timesteps: 1,295,587,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,370.86538
Policy Entropy: 3.77408
Value Function Loss: 0.02004

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.69417
Value Function Update Magnitude: 0.67942

Collected Steps per Second: 22,931.33450
Overall Steps per Second: 10,637.83501

Timestep Collection Time: 2.18042
Timestep Consumption Time: 2.51978
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.70020

Cumulative Model Updates: 155,378
Cumulative Timesteps: 1,295,637,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1295637978...
Checkpoint 1295637978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,370.86538
Policy Entropy: 3.77362
Value Function Loss: 0.01952

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.65643
Value Function Update Magnitude: 0.58595

Collected Steps per Second: 22,988.86173
Overall Steps per Second: 10,849.52990

Timestep Collection Time: 2.17627
Timestep Consumption Time: 2.43499
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.61126

Cumulative Model Updates: 155,384
Cumulative Timesteps: 1,295,688,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,535.19022
Policy Entropy: 3.77148
Value Function Loss: 0.01649

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12074
Policy Update Magnitude: 0.50590
Value Function Update Magnitude: 0.55605

Collected Steps per Second: 22,777.65718
Overall Steps per Second: 10,691.68671

Timestep Collection Time: 2.19557
Timestep Consumption Time: 2.48189
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.67747

Cumulative Model Updates: 155,390
Cumulative Timesteps: 1,295,738,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1295738018...
Checkpoint 1295738018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,945.82176
Policy Entropy: 3.76637
Value Function Loss: 0.01633

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.19109
Policy Update Magnitude: 0.42681
Value Function Update Magnitude: 0.50497

Collected Steps per Second: 22,091.11986
Overall Steps per Second: 10,896.17820

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.32653
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.59097

Cumulative Model Updates: 155,396
Cumulative Timesteps: 1,295,788,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,071.32415
Policy Entropy: 3.78133
Value Function Loss: 0.01649

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.40678
Value Function Update Magnitude: 0.42588

Collected Steps per Second: 22,339.41785
Overall Steps per Second: 10,908.24996

Timestep Collection Time: 2.23918
Timestep Consumption Time: 2.34652
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.58570

Cumulative Model Updates: 155,402
Cumulative Timesteps: 1,295,838,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1295838064...
Checkpoint 1295838064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.31297
Policy Entropy: 3.79686
Value Function Loss: 0.01351

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14638
Policy Update Magnitude: 0.40899
Value Function Update Magnitude: 0.51594

Collected Steps per Second: 21,846.67093
Overall Steps per Second: 10,741.64052

Timestep Collection Time: 2.28941
Timestep Consumption Time: 2.36686
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.65627

Cumulative Model Updates: 155,408
Cumulative Timesteps: 1,295,888,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.31297
Policy Entropy: 3.77544
Value Function Loss: 0.01268

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.40399
Value Function Update Magnitude: 0.60795

Collected Steps per Second: 21,935.13798
Overall Steps per Second: 10,510.84633

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.76137

Cumulative Model Updates: 155,414
Cumulative Timesteps: 1,295,938,126

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1295938126...
Checkpoint 1295938126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.31297
Policy Entropy: 3.75114
Value Function Loss: 0.01145

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14177
Policy Update Magnitude: 0.38079
Value Function Update Magnitude: 0.57150

Collected Steps per Second: 21,994.20583
Overall Steps per Second: 10,571.89107

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.73066

Cumulative Model Updates: 155,420
Cumulative Timesteps: 1,295,988,138

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,521.31297
Policy Entropy: 3.73283
Value Function Loss: 0.01122

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15355
Policy Update Magnitude: 0.33198
Value Function Update Magnitude: 0.48104

Collected Steps per Second: 22,460.64975
Overall Steps per Second: 10,847.83761

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.38443
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.61179

Cumulative Model Updates: 155,426
Cumulative Timesteps: 1,296,038,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1296038166...
Checkpoint 1296038166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,935.45216
Policy Entropy: 3.73562
Value Function Loss: 0.01436

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.31895
Value Function Update Magnitude: 0.49069

Collected Steps per Second: 22,040.42425
Overall Steps per Second: 10,641.65752

Timestep Collection Time: 2.26883
Timestep Consumption Time: 2.43025
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.69908

Cumulative Model Updates: 155,432
Cumulative Timesteps: 1,296,088,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,935.45216
Policy Entropy: 3.75174
Value Function Loss: 0.01668

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.39312
Value Function Update Magnitude: 0.56651

Collected Steps per Second: 22,626.65931
Overall Steps per Second: 10,497.40050

Timestep Collection Time: 2.21067
Timestep Consumption Time: 2.55432
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.76499

Cumulative Model Updates: 155,438
Cumulative Timesteps: 1,296,138,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1296138192...
Checkpoint 1296138192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,291.17064
Policy Entropy: 3.74829
Value Function Loss: 0.02003

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.43383
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 22,546.10170
Overall Steps per Second: 10,646.25171

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.47911
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.69705

Cumulative Model Updates: 155,444
Cumulative Timesteps: 1,296,188,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,244.43115
Policy Entropy: 3.75774
Value Function Loss: 0.01787

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.43485
Value Function Update Magnitude: 0.47694

Collected Steps per Second: 23,076.35745
Overall Steps per Second: 10,897.69810

Timestep Collection Time: 2.16776
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.59033

Cumulative Model Updates: 155,450
Cumulative Timesteps: 1,296,238,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1296238222...
Checkpoint 1296238222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,360.66912
Policy Entropy: 3.72946
Value Function Loss: 0.01995

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13139
Policy Update Magnitude: 0.43006
Value Function Update Magnitude: 0.49805

Collected Steps per Second: 22,888.64912
Overall Steps per Second: 10,686.66309

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67966

Cumulative Model Updates: 155,456
Cumulative Timesteps: 1,296,288,232

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,668.17115
Policy Entropy: 3.73931
Value Function Loss: 0.02128

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.46554
Value Function Update Magnitude: 0.51035

Collected Steps per Second: 22,333.75806
Overall Steps per Second: 10,475.38324

Timestep Collection Time: 2.23966
Timestep Consumption Time: 2.53535
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.77500

Cumulative Model Updates: 155,462
Cumulative Timesteps: 1,296,338,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1296338252...
Checkpoint 1296338252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,507.25640
Policy Entropy: 3.75861
Value Function Loss: 0.02310

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.50668
Value Function Update Magnitude: 0.49764

Collected Steps per Second: 22,596.95616
Overall Steps per Second: 10,596.49726

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.71873

Cumulative Model Updates: 155,468
Cumulative Timesteps: 1,296,388,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,556.31923
Policy Entropy: 3.76924
Value Function Loss: 0.02398

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.49353
Value Function Update Magnitude: 0.53989

Collected Steps per Second: 22,702.56799
Overall Steps per Second: 10,836.31193

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.61504

Cumulative Model Updates: 155,474
Cumulative Timesteps: 1,296,438,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1296438264...
Checkpoint 1296438264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,549.40582
Policy Entropy: 3.79229
Value Function Loss: 0.02327

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.47689
Value Function Update Magnitude: 0.57861

Collected Steps per Second: 21,926.58802
Overall Steps per Second: 10,643.23849

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.41787
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.69857

Cumulative Model Updates: 155,480
Cumulative Timesteps: 1,296,488,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,242.12853
Policy Entropy: 3.78362
Value Function Loss: 0.02195

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12935
Policy Update Magnitude: 0.44739
Value Function Update Magnitude: 0.56543

Collected Steps per Second: 22,280.44449
Overall Steps per Second: 10,505.20321

Timestep Collection Time: 2.24412
Timestep Consumption Time: 2.51543
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.75955

Cumulative Model Updates: 155,486
Cumulative Timesteps: 1,296,538,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1296538272...
Checkpoint 1296538272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,242.12853
Policy Entropy: 3.78296
Value Function Loss: 0.01804

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.42164
Value Function Update Magnitude: 0.50523

Collected Steps per Second: 22,280.88775
Overall Steps per Second: 10,617.55052

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.46659
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.71201

Cumulative Model Updates: 155,492
Cumulative Timesteps: 1,296,588,302

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,068.02343
Policy Entropy: 3.75278
Value Function Loss: 0.01715

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.41561
Value Function Update Magnitude: 0.43958

Collected Steps per Second: 22,464.27085
Overall Steps per Second: 10,597.17129

Timestep Collection Time: 2.22593
Timestep Consumption Time: 2.49268
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.71862

Cumulative Model Updates: 155,498
Cumulative Timesteps: 1,296,638,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1296638306...
Checkpoint 1296638306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,655.35394
Policy Entropy: 3.76163
Value Function Loss: 0.01785

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.39814
Value Function Update Magnitude: 0.53669

Collected Steps per Second: 22,888.34473
Overall Steps per Second: 10,680.35342

Timestep Collection Time: 2.18522
Timestep Consumption Time: 2.49777
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68299

Cumulative Model Updates: 155,504
Cumulative Timesteps: 1,296,688,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,805.56334
Policy Entropy: 3.77266
Value Function Loss: 0.02005

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.41501
Value Function Update Magnitude: 0.66801

Collected Steps per Second: 23,066.10423
Overall Steps per Second: 10,754.37684

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.48278
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.65150

Cumulative Model Updates: 155,510
Cumulative Timesteps: 1,296,738,346

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1296738346...
Checkpoint 1296738346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,232.48804
Policy Entropy: 3.79562
Value Function Loss: 0.01919

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.43721
Value Function Update Magnitude: 0.73033

Collected Steps per Second: 22,425.24280
Overall Steps per Second: 10,655.61674

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.69443

Cumulative Model Updates: 155,516
Cumulative Timesteps: 1,296,788,368

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,401.05268
Policy Entropy: 3.77624
Value Function Loss: 0.02255

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12902
Policy Update Magnitude: 0.47013
Value Function Update Magnitude: 0.67914

Collected Steps per Second: 22,814.44968
Overall Steps per Second: 10,842.52819

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.42152
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.61461

Cumulative Model Updates: 155,522
Cumulative Timesteps: 1,296,838,402

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1296838402...
Checkpoint 1296838402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,614.15736
Policy Entropy: 3.77103
Value Function Loss: 0.02105

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.48713
Value Function Update Magnitude: 0.65728

Collected Steps per Second: 22,569.81638
Overall Steps per Second: 10,699.53839

Timestep Collection Time: 2.21721
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.67702

Cumulative Model Updates: 155,528
Cumulative Timesteps: 1,296,888,444

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,417.69212
Policy Entropy: 3.75441
Value Function Loss: 0.02513

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13040
Policy Update Magnitude: 0.48908
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,708.13945
Overall Steps per Second: 10,826.22903

Timestep Collection Time: 2.20309
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.62100

Cumulative Model Updates: 155,534
Cumulative Timesteps: 1,296,938,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1296938472...
Checkpoint 1296938472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.53441
Policy Entropy: 3.77833
Value Function Loss: 0.02301

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.50467
Value Function Update Magnitude: 0.51379

Collected Steps per Second: 21,904.67028
Overall Steps per Second: 10,652.07119

Timestep Collection Time: 2.28371
Timestep Consumption Time: 2.41246
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.69618

Cumulative Model Updates: 155,540
Cumulative Timesteps: 1,296,988,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,074.55396
Policy Entropy: 3.80441
Value Function Loss: 0.02223

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.49947
Value Function Update Magnitude: 0.52422

Collected Steps per Second: 22,427.90323
Overall Steps per Second: 10,568.59238

Timestep Collection Time: 2.23070
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.73384

Cumulative Model Updates: 155,546
Cumulative Timesteps: 1,297,038,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1297038526...
Checkpoint 1297038526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,687.19190
Policy Entropy: 3.82735
Value Function Loss: 0.02558

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.48815
Value Function Update Magnitude: 0.57788

Collected Steps per Second: 22,198.10412
Overall Steps per Second: 10,624.64658

Timestep Collection Time: 2.25290
Timestep Consumption Time: 2.45408
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.70698

Cumulative Model Updates: 155,552
Cumulative Timesteps: 1,297,088,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,782.97472
Policy Entropy: 3.83164
Value Function Loss: 0.02945

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12444
Policy Update Magnitude: 0.56786
Value Function Update Magnitude: 0.70573

Collected Steps per Second: 22,105.07891
Overall Steps per Second: 10,504.34553

Timestep Collection Time: 2.26238
Timestep Consumption Time: 2.49851
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.76089

Cumulative Model Updates: 155,558
Cumulative Timesteps: 1,297,138,546

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1297138546...
Checkpoint 1297138546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,401.10902
Policy Entropy: 3.82438
Value Function Loss: 0.03262

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.62901
Value Function Update Magnitude: 0.71123

Collected Steps per Second: 22,139.80562
Overall Steps per Second: 10,579.99057

Timestep Collection Time: 2.25955
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.72836

Cumulative Model Updates: 155,564
Cumulative Timesteps: 1,297,188,572

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,617.19589
Policy Entropy: 3.83269
Value Function Loss: 0.02824

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12594
Policy Update Magnitude: 0.61024
Value Function Update Magnitude: 0.70383

Collected Steps per Second: 23,052.32273
Overall Steps per Second: 10,704.04780

Timestep Collection Time: 2.17011
Timestep Consumption Time: 2.50345
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.67356

Cumulative Model Updates: 155,570
Cumulative Timesteps: 1,297,238,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1297238598...
Checkpoint 1297238598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,375.55582
Policy Entropy: 3.82662
Value Function Loss: 0.02521

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.67931

Collected Steps per Second: 22,573.50095
Overall Steps per Second: 10,741.63629

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.65702

Cumulative Model Updates: 155,576
Cumulative Timesteps: 1,297,288,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,158.23707
Policy Entropy: 3.82259
Value Function Loss: 0.02321

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.50081
Value Function Update Magnitude: 0.74301

Collected Steps per Second: 22,829.37940
Overall Steps per Second: 10,606.12861

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.71482

Cumulative Model Updates: 155,582
Cumulative Timesteps: 1,297,338,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1297338628...
Checkpoint 1297338628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,355.90408
Policy Entropy: 3.81573
Value Function Loss: 0.02320

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.49482
Value Function Update Magnitude: 0.82387

Collected Steps per Second: 22,470.09801
Overall Steps per Second: 10,590.85732

Timestep Collection Time: 2.22598
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.72275

Cumulative Model Updates: 155,588
Cumulative Timesteps: 1,297,388,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,600.56329
Policy Entropy: 3.81741
Value Function Loss: 0.02509

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.48550
Value Function Update Magnitude: 0.83230

Collected Steps per Second: 22,996.57194
Overall Steps per Second: 10,889.50302

Timestep Collection Time: 2.17511
Timestep Consumption Time: 2.41831
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.59341

Cumulative Model Updates: 155,594
Cumulative Timesteps: 1,297,438,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1297438666...
Checkpoint 1297438666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,640.95508
Policy Entropy: 3.80451
Value Function Loss: 0.02304

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.47699
Value Function Update Magnitude: 0.72742

Collected Steps per Second: 22,575.17796
Overall Steps per Second: 10,699.67919

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.67472

Cumulative Model Updates: 155,600
Cumulative Timesteps: 1,297,488,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.24637
Policy Entropy: 3.77624
Value Function Loss: 0.02154

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.47410
Value Function Update Magnitude: 0.57461

Collected Steps per Second: 22,734.20306
Overall Steps per Second: 10,837.54585

Timestep Collection Time: 2.20047
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61599

Cumulative Model Updates: 155,606
Cumulative Timesteps: 1,297,538,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1297538710...
Checkpoint 1297538710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,170.24637
Policy Entropy: 3.75758
Value Function Loss: 0.01723

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.44537
Value Function Update Magnitude: 0.45970

Collected Steps per Second: 22,292.60355
Overall Steps per Second: 10,755.63439

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.27578
Total Iteration Time: 4.65003

Cumulative Model Updates: 155,612
Cumulative Timesteps: 1,297,588,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,340.14747
Policy Entropy: 3.75819
Value Function Loss: 0.01688

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.42762
Value Function Update Magnitude: 0.44736

Collected Steps per Second: 21,682.10686
Overall Steps per Second: 10,773.41911

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.33687
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.64477

Cumulative Model Updates: 155,618
Cumulative Timesteps: 1,297,638,764

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1297638764...
Checkpoint 1297638764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,009.26153
Policy Entropy: 3.76231
Value Function Loss: 0.01866

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.44436
Value Function Update Magnitude: 0.48779

Collected Steps per Second: 21,977.18204
Overall Steps per Second: 10,778.83887

Timestep Collection Time: 2.27645
Timestep Consumption Time: 2.36505
PPO Batch Consumption Time: 0.27552
Total Iteration Time: 4.64150

Cumulative Model Updates: 155,624
Cumulative Timesteps: 1,297,688,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,667.89419
Policy Entropy: 3.76865
Value Function Loss: 0.01843

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.48623
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 22,202.75199
Overall Steps per Second: 10,712.40835

Timestep Collection Time: 2.25278
Timestep Consumption Time: 2.41638
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.66916

Cumulative Model Updates: 155,630
Cumulative Timesteps: 1,297,738,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1297738812...
Checkpoint 1297738812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,882.48724
Policy Entropy: 3.76119
Value Function Loss: 0.02045

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.47290
Value Function Update Magnitude: 0.53855

Collected Steps per Second: 22,178.90859
Overall Steps per Second: 10,731.39520

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.40551
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.66053

Cumulative Model Updates: 155,636
Cumulative Timesteps: 1,297,788,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,692.79532
Policy Entropy: 3.77783
Value Function Loss: 0.02026

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.45571
Value Function Update Magnitude: 0.40540

Collected Steps per Second: 22,543.45293
Overall Steps per Second: 10,864.60423

Timestep Collection Time: 2.21821
Timestep Consumption Time: 2.38445
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.60265

Cumulative Model Updates: 155,642
Cumulative Timesteps: 1,297,838,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1297838832...
Checkpoint 1297838832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,140.48989
Policy Entropy: 3.77253
Value Function Loss: 0.01981

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.48520
Value Function Update Magnitude: 0.46000

Collected Steps per Second: 22,894.88228
Overall Steps per Second: 10,748.47570

Timestep Collection Time: 2.18582
Timestep Consumption Time: 2.47010
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.65592

Cumulative Model Updates: 155,648
Cumulative Timesteps: 1,297,888,876

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,434.55814
Policy Entropy: 3.77161
Value Function Loss: 0.01977

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.51297
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 22,765.03404
Overall Steps per Second: 10,828.16450

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.42201
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61907

Cumulative Model Updates: 155,654
Cumulative Timesteps: 1,297,938,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1297938892...
Checkpoint 1297938892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,095.73251
Policy Entropy: 3.76679
Value Function Loss: 0.01855

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12415
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.67224

Collected Steps per Second: 21,850.61775
Overall Steps per Second: 10,641.91369

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.41101
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.70009

Cumulative Model Updates: 155,660
Cumulative Timesteps: 1,297,988,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,615.86466
Policy Entropy: 3.75051
Value Function Loss: 0.01998

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.60849

Collected Steps per Second: 22,286.00140
Overall Steps per Second: 10,560.34320

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.73943

Cumulative Model Updates: 155,666
Cumulative Timesteps: 1,298,038,960

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1298038960...
Checkpoint 1298038960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,615.86466
Policy Entropy: 3.76203
Value Function Loss: 0.01804

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.47026

Collected Steps per Second: 22,150.38224
Overall Steps per Second: 10,629.84815

Timestep Collection Time: 2.25829
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.70581

Cumulative Model Updates: 155,672
Cumulative Timesteps: 1,298,088,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,061.32386
Policy Entropy: 3.75673
Value Function Loss: 0.01632

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.47875
Value Function Update Magnitude: 0.42715

Collected Steps per Second: 22,134.34816
Overall Steps per Second: 10,500.84702

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.50299
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.76228

Cumulative Model Updates: 155,678
Cumulative Timesteps: 1,298,138,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1298138990...
Checkpoint 1298138990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,061.32386
Policy Entropy: 3.77433
Value Function Loss: 0.01525

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.44714
Value Function Update Magnitude: 0.44894

Collected Steps per Second: 21,973.47921
Overall Steps per Second: 10,560.47318

Timestep Collection Time: 2.27629
Timestep Consumption Time: 2.46005
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.73634

Cumulative Model Updates: 155,684
Cumulative Timesteps: 1,298,189,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,061.32386
Policy Entropy: 3.75458
Value Function Loss: 0.01592

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.53278
Value Function Update Magnitude: 0.42048

Collected Steps per Second: 22,634.27955
Overall Steps per Second: 10,603.64259

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.71744

Cumulative Model Updates: 155,690
Cumulative Timesteps: 1,298,239,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1298239030...
Checkpoint 1298239030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,061.32386
Policy Entropy: 3.75559
Value Function Loss: 0.01552

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.50813
Value Function Update Magnitude: 0.44831

Collected Steps per Second: 22,554.43744
Overall Steps per Second: 10,668.95472

Timestep Collection Time: 2.21845
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68987

Cumulative Model Updates: 155,696
Cumulative Timesteps: 1,298,289,066

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,211.09569
Policy Entropy: 3.76167
Value Function Loss: 0.01514

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.47151
Value Function Update Magnitude: 0.38637

Collected Steps per Second: 21,983.03641
Overall Steps per Second: 10,742.52558

Timestep Collection Time: 2.27475
Timestep Consumption Time: 2.38020
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.65496

Cumulative Model Updates: 155,702
Cumulative Timesteps: 1,298,339,072

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1298339072...
Checkpoint 1298339072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,211.09569
Policy Entropy: 3.76048
Value Function Loss: 0.01530

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.44804
Value Function Update Magnitude: 0.34567

Collected Steps per Second: 21,831.70969
Overall Steps per Second: 10,618.85029

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.41884
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.70955

Cumulative Model Updates: 155,708
Cumulative Timesteps: 1,298,389,082

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,211.09569
Policy Entropy: 3.76001
Value Function Loss: 0.01497

Mean KL Divergence: 0.01470
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.42018
Value Function Update Magnitude: 0.28242

Collected Steps per Second: 22,050.26367
Overall Steps per Second: 10,839.54462

Timestep Collection Time: 2.26845
Timestep Consumption Time: 2.34613
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.61458

Cumulative Model Updates: 155,714
Cumulative Timesteps: 1,298,439,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1298439102...
Checkpoint 1298439102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,906.69504
Policy Entropy: 3.74072
Value Function Loss: 0.02306

Mean KL Divergence: 0.02451
SB3 Clip Fraction: 0.24901
Policy Update Magnitude: 0.44521
Value Function Update Magnitude: 0.38090

Collected Steps per Second: 22,029.88677
Overall Steps per Second: 10,722.04390

Timestep Collection Time: 2.27082
Timestep Consumption Time: 2.39489
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.66571

Cumulative Model Updates: 155,720
Cumulative Timesteps: 1,298,489,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,548.40152
Policy Entropy: 3.75145
Value Function Loss: 0.03011

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.19614
Policy Update Magnitude: 0.70893
Value Function Update Magnitude: 0.55649

Collected Steps per Second: 22,089.62598
Overall Steps per Second: 10,570.01548

Timestep Collection Time: 2.26450
Timestep Consumption Time: 2.46794
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.73244

Cumulative Model Updates: 155,726
Cumulative Timesteps: 1,298,539,150

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1298539150...
Checkpoint 1298539150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,619.28480
Policy Entropy: 3.75450
Value Function Loss: 0.04405

Mean KL Divergence: 0.02215
SB3 Clip Fraction: 0.23695
Policy Update Magnitude: 0.78569
Value Function Update Magnitude: 0.59044

Collected Steps per Second: 21,786.78569
Overall Steps per Second: 10,552.08525

Timestep Collection Time: 2.29515
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.73878

Cumulative Model Updates: 155,732
Cumulative Timesteps: 1,298,589,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,455.52755
Policy Entropy: 3.84280
Value Function Loss: 0.04287

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.14633
Policy Update Magnitude: 1.07059
Value Function Update Magnitude: 0.62642

Collected Steps per Second: 22,315.47798
Overall Steps per Second: 10,812.79684

Timestep Collection Time: 2.24167
Timestep Consumption Time: 2.38470
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62637

Cumulative Model Updates: 155,738
Cumulative Timesteps: 1,298,639,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1298639178...
Checkpoint 1298639178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.68911
Policy Entropy: 3.89794
Value Function Loss: 0.04036

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.15164
Policy Update Magnitude: 1.31213
Value Function Update Magnitude: 0.80468

Collected Steps per Second: 22,087.83046
Overall Steps per Second: 10,760.03790

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.38342
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.64738

Cumulative Model Updates: 155,744
Cumulative Timesteps: 1,298,689,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,354.83653
Policy Entropy: 3.93637
Value Function Loss: 0.03733

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 1.23658
Value Function Update Magnitude: 0.82007

Collected Steps per Second: 22,388.32288
Overall Steps per Second: 10,612.95287

Timestep Collection Time: 2.23447
Timestep Consumption Time: 2.47921
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.71367

Cumulative Model Updates: 155,750
Cumulative Timesteps: 1,298,739,210

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1298739210...
Checkpoint 1298739210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,900.60177
Policy Entropy: 3.92097
Value Function Loss: 0.03573

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 1.07054
Value Function Update Magnitude: 0.90085

Collected Steps per Second: 22,634.77463
Overall Steps per Second: 10,818.18989

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.62462

Cumulative Model Updates: 155,756
Cumulative Timesteps: 1,298,789,240

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,086.82312
Policy Entropy: 3.89954
Value Function Loss: 0.03856

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 1.01760
Value Function Update Magnitude: 0.90309

Collected Steps per Second: 22,438.58191
Overall Steps per Second: 10,661.04444

Timestep Collection Time: 2.22911
Timestep Consumption Time: 2.46255
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.69166

Cumulative Model Updates: 155,762
Cumulative Timesteps: 1,298,839,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1298839258...
Checkpoint 1298839258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157.89272
Policy Entropy: 3.89818
Value Function Loss: 0.03610

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 1.08608
Value Function Update Magnitude: 0.90078

Collected Steps per Second: 22,328.17770
Overall Steps per Second: 10,918.71957

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.34072
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.58076

Cumulative Model Updates: 155,768
Cumulative Timesteps: 1,298,889,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,165.70574
Policy Entropy: 3.88159
Value Function Loss: 0.03443

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 1.06693
Value Function Update Magnitude: 0.78406

Collected Steps per Second: 22,191.09535
Overall Steps per Second: 10,603.55209

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.46293
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.71672

Cumulative Model Updates: 155,774
Cumulative Timesteps: 1,298,939,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1298939288...
Checkpoint 1298939288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.04628
Policy Entropy: 3.87409
Value Function Loss: 0.03084

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07625
Policy Update Magnitude: 0.99747
Value Function Update Magnitude: 0.69940

Collected Steps per Second: 22,438.02561
Overall Steps per Second: 10,616.33716

Timestep Collection Time: 2.22925
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.71161

Cumulative Model Updates: 155,780
Cumulative Timesteps: 1,298,989,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,238.11803
Policy Entropy: 3.86571
Value Function Loss: 0.02888

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06621
Policy Update Magnitude: 0.91699
Value Function Update Magnitude: 0.66603

Collected Steps per Second: 22,596.03643
Overall Steps per Second: 10,872.68311

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.38714
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.60107

Cumulative Model Updates: 155,786
Cumulative Timesteps: 1,299,039,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1299039334...
Checkpoint 1299039334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,318.31618
Policy Entropy: 3.84609
Value Function Loss: 0.02596

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.82115
Value Function Update Magnitude: 0.69787

Collected Steps per Second: 22,088.35368
Overall Steps per Second: 10,618.20768

Timestep Collection Time: 2.26536
Timestep Consumption Time: 2.44711
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.71247

Cumulative Model Updates: 155,792
Cumulative Timesteps: 1,299,089,372

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,044.15951
Policy Entropy: 3.83742
Value Function Loss: 0.02235

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07081
Policy Update Magnitude: 0.73759
Value Function Update Magnitude: 0.65974

Collected Steps per Second: 22,661.17068
Overall Steps per Second: 10,834.39488

Timestep Collection Time: 2.20651
Timestep Consumption Time: 2.40861
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61512

Cumulative Model Updates: 155,798
Cumulative Timesteps: 1,299,139,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1299139374...
Checkpoint 1299139374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232.14918
Policy Entropy: 3.83807
Value Function Loss: 0.01845

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.60535
Value Function Update Magnitude: 0.68388

Collected Steps per Second: 22,304.81182
Overall Steps per Second: 10,679.60031

Timestep Collection Time: 2.24185
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.68220

Cumulative Model Updates: 155,804
Cumulative Timesteps: 1,299,189,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.77399
Policy Entropy: 3.84861
Value Function Loss: 0.01813

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.48503
Value Function Update Magnitude: 0.65113

Collected Steps per Second: 22,572.00761
Overall Steps per Second: 10,599.36978

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.50313
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71915

Cumulative Model Updates: 155,810
Cumulative Timesteps: 1,299,239,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1299239398...
Checkpoint 1299239398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,435.41262
Policy Entropy: 3.82307
Value Function Loss: 0.02009

Mean KL Divergence: 0.01851
SB3 Clip Fraction: 0.21869
Policy Update Magnitude: 0.42860
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 22,969.24811
Overall Steps per Second: 10,712.48379

Timestep Collection Time: 2.17856
Timestep Consumption Time: 2.49262
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.67119

Cumulative Model Updates: 155,816
Cumulative Timesteps: 1,299,289,438

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,520.21325
Policy Entropy: 3.83941
Value Function Loss: 0.03667

Mean KL Divergence: 0.02463
SB3 Clip Fraction: 0.23589
Policy Update Magnitude: 0.47964
Value Function Update Magnitude: 0.63595

Collected Steps per Second: 22,700.95020
Overall Steps per Second: 10,703.12725

Timestep Collection Time: 2.20361
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.67377

Cumulative Model Updates: 155,822
Cumulative Timesteps: 1,299,339,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1299339462...
Checkpoint 1299339462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,904.89489
Policy Entropy: 3.91266
Value Function Loss: 0.03971

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.85997
Value Function Update Magnitude: 0.60559

Collected Steps per Second: 22,659.73343
Overall Steps per Second: 10,709.63594

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.46342
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67112

Cumulative Model Updates: 155,828
Cumulative Timesteps: 1,299,389,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,496.20432
Policy Entropy: 3.99570
Value Function Loss: 0.03937

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 1.02322
Value Function Update Magnitude: 0.71361

Collected Steps per Second: 23,093.17143
Overall Steps per Second: 10,807.72015

Timestep Collection Time: 2.16514
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.62632

Cumulative Model Updates: 155,834
Cumulative Timesteps: 1,299,439,488

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1299439488...
Checkpoint 1299439488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.23593
Policy Entropy: 3.99265
Value Function Loss: 0.03828

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.15288
Policy Update Magnitude: 0.92981
Value Function Update Magnitude: 0.73613

Collected Steps per Second: 22,761.28730
Overall Steps per Second: 11,052.61303

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.32831
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.52617

Cumulative Model Updates: 155,840
Cumulative Timesteps: 1,299,489,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,250.12074
Policy Entropy: 3.97684
Value Function Loss: 0.04136

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.16870
Policy Update Magnitude: 0.66946
Value Function Update Magnitude: 0.69130

Collected Steps per Second: 21,838.19572
Overall Steps per Second: 10,627.88407

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.41581
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70611

Cumulative Model Updates: 155,846
Cumulative Timesteps: 1,299,539,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1299539530...
Checkpoint 1299539530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.53584
Policy Entropy: 3.93712
Value Function Loss: 0.04279

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.17604
Policy Update Magnitude: 0.61341
Value Function Update Magnitude: 0.62460

Collected Steps per Second: 21,691.53637
Overall Steps per Second: 10,601.00669

Timestep Collection Time: 2.30505
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71653

Cumulative Model Updates: 155,852
Cumulative Timesteps: 1,299,589,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,861.59061
Policy Entropy: 3.92504
Value Function Loss: 0.04936

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.15450
Policy Update Magnitude: 0.51798
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 22,543.01390
Overall Steps per Second: 10,798.61719

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.41253
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.63078

Cumulative Model Updates: 155,858
Cumulative Timesteps: 1,299,639,536

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1299639536...
Checkpoint 1299639536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,723.87963
Policy Entropy: 3.93186
Value Function Loss: 0.05089

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13571
Policy Update Magnitude: 0.51435
Value Function Update Magnitude: 0.51045

Collected Steps per Second: 22,556.35028
Overall Steps per Second: 10,711.20136

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.66838

Cumulative Model Updates: 155,864
Cumulative Timesteps: 1,299,689,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.70180
Policy Entropy: 3.97107
Value Function Loss: 0.04770

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.58455
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 22,653.44412
Overall Steps per Second: 10,631.75482

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.70289

Cumulative Model Updates: 155,870
Cumulative Timesteps: 1,299,739,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1299739540...
Checkpoint 1299739540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.60285
Policy Entropy: 3.99373
Value Function Loss: 0.04045

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.66700
Value Function Update Magnitude: 0.80069

Collected Steps per Second: 22,839.32473
Overall Steps per Second: 10,590.15291

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.53338
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.72363

Cumulative Model Updates: 155,876
Cumulative Timesteps: 1,299,789,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.07562
Policy Entropy: 3.98598
Value Function Loss: 0.03746

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.68297
Value Function Update Magnitude: 0.90518

Collected Steps per Second: 22,833.41300
Overall Steps per Second: 10,696.46616

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67612

Cumulative Model Updates: 155,882
Cumulative Timesteps: 1,299,839,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1299839582...
Checkpoint 1299839582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.44749
Policy Entropy: 3.95209
Value Function Loss: 0.03818

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11829
Policy Update Magnitude: 0.65138
Value Function Update Magnitude: 0.85831

Collected Steps per Second: 22,837.03326
Overall Steps per Second: 10,740.45635

Timestep Collection Time: 2.18960
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.65567

Cumulative Model Updates: 155,888
Cumulative Timesteps: 1,299,889,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,776.28423
Policy Entropy: 3.93158
Value Function Loss: 0.03945

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.61531
Value Function Update Magnitude: 0.84873

Collected Steps per Second: 22,729.75814
Overall Steps per Second: 10,886.39360

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.39351
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.59362

Cumulative Model Updates: 155,894
Cumulative Timesteps: 1,299,939,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1299939594...
Checkpoint 1299939594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,251.15089
Policy Entropy: 3.94719
Value Function Loss: 0.03806

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.61044
Value Function Update Magnitude: 0.75512

Collected Steps per Second: 22,841.81488
Overall Steps per Second: 11,040.10816

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.34138
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.53166

Cumulative Model Updates: 155,900
Cumulative Timesteps: 1,299,989,624

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106.78358
Policy Entropy: 3.94575
Value Function Loss: 0.03849

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12045
Policy Update Magnitude: 0.60848
Value Function Update Magnitude: 0.69808

Collected Steps per Second: 21,730.32397
Overall Steps per Second: 10,608.61296

Timestep Collection Time: 2.30167
Timestep Consumption Time: 2.41299
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71466

Cumulative Model Updates: 155,906
Cumulative Timesteps: 1,300,039,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1300039640...
Checkpoint 1300039640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.39064
Policy Entropy: 3.98471
Value Function Loss: 0.03554

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11590
Policy Update Magnitude: 0.65989
Value Function Update Magnitude: 0.82934

Collected Steps per Second: 22,305.63420
Overall Steps per Second: 10,588.36858

Timestep Collection Time: 2.24212
Timestep Consumption Time: 2.48117
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.72330

Cumulative Model Updates: 155,912
Cumulative Timesteps: 1,300,089,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103.06802
Policy Entropy: 3.99243
Value Function Loss: 0.03491

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.68878
Value Function Update Magnitude: 0.87480

Collected Steps per Second: 22,507.08010
Overall Steps per Second: 10,779.87110

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.63957

Cumulative Model Updates: 155,918
Cumulative Timesteps: 1,300,139,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1300139666...
Checkpoint 1300139666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.34938
Policy Entropy: 3.99903
Value Function Loss: 0.03629

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.70363
Value Function Update Magnitude: 0.80913

Collected Steps per Second: 20,953.23346
Overall Steps per Second: 10,263.27713

Timestep Collection Time: 2.38713
Timestep Consumption Time: 2.48637
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.87349

Cumulative Model Updates: 155,924
Cumulative Timesteps: 1,300,189,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,536.80315
Policy Entropy: 4.00177
Value Function Loss: 0.03571

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.08488
Policy Update Magnitude: 0.86184
Value Function Update Magnitude: 0.79765

Collected Steps per Second: 22,268.44670
Overall Steps per Second: 10,576.35665

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.72771

Cumulative Model Updates: 155,930
Cumulative Timesteps: 1,300,239,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1300239686...
Checkpoint 1300239686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,382.94325
Policy Entropy: 3.99061
Value Function Loss: 0.03458

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.97863
Value Function Update Magnitude: 0.88903

Collected Steps per Second: 22,315.29729
Overall Steps per Second: 10,558.92750

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.73798

Cumulative Model Updates: 155,936
Cumulative Timesteps: 1,300,289,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,596.39983
Policy Entropy: 3.95886
Value Function Loss: 0.03354

Mean KL Divergence: 0.00580
SB3 Clip Fraction: 0.07180
Policy Update Magnitude: 0.97194
Value Function Update Magnitude: 0.86005

Collected Steps per Second: 22,681.52931
Overall Steps per Second: 10,570.13414

Timestep Collection Time: 2.20558
Timestep Consumption Time: 2.52719
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.73277

Cumulative Model Updates: 155,942
Cumulative Timesteps: 1,300,339,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1300339740...
Checkpoint 1300339740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,179.37631
Policy Entropy: 3.91214
Value Function Loss: 0.03368

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.94628
Value Function Update Magnitude: 0.74807

Collected Steps per Second: 22,499.79183
Overall Steps per Second: 10,617.08495

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.48794
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.71090

Cumulative Model Updates: 155,948
Cumulative Timesteps: 1,300,389,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.59500
Policy Entropy: 3.89827
Value Function Loss: 0.03247

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.07060
Policy Update Magnitude: 0.88030
Value Function Update Magnitude: 0.76481

Collected Steps per Second: 22,633.89534
Overall Steps per Second: 10,834.71594

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.40630
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.61590

Cumulative Model Updates: 155,954
Cumulative Timesteps: 1,300,439,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1300439768...
Checkpoint 1300439768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,565.05699
Policy Entropy: 3.88936
Value Function Loss: 0.02968

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07198
Policy Update Magnitude: 0.81782
Value Function Update Magnitude: 0.75335

Collected Steps per Second: 22,500.25756
Overall Steps per Second: 10,593.42295

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.72123

Cumulative Model Updates: 155,960
Cumulative Timesteps: 1,300,489,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79667
Policy Entropy: 3.88122
Value Function Loss: 0.02413

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07210
Policy Update Magnitude: 0.67904
Value Function Update Magnitude: 0.66391

Collected Steps per Second: 22,680.30043
Overall Steps per Second: 10,808.33549

Timestep Collection Time: 2.20473
Timestep Consumption Time: 2.42170
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62643

Cumulative Model Updates: 155,966
Cumulative Timesteps: 1,300,539,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1300539786...
Checkpoint 1300539786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.17875
Policy Entropy: 3.84337
Value Function Loss: 0.02094

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.61538
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,447.82472
Overall Steps per Second: 10,783.43559

Timestep Collection Time: 2.22765
Timestep Consumption Time: 2.40964
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.63730

Cumulative Model Updates: 155,972
Cumulative Timesteps: 1,300,589,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,282.22060
Policy Entropy: 3.81694
Value Function Loss: 0.01996

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11743
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.47346

Collected Steps per Second: 22,137.09475
Overall Steps per Second: 10,553.22296

Timestep Collection Time: 2.25983
Timestep Consumption Time: 2.48053
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.74035

Cumulative Model Updates: 155,978
Cumulative Timesteps: 1,300,639,818

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1300639818...
Checkpoint 1300639818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,458.76792
Policy Entropy: 3.79244
Value Function Loss: 0.02405

Mean KL Divergence: 0.02132
SB3 Clip Fraction: 0.23519
Policy Update Magnitude: 0.46925
Value Function Update Magnitude: 0.41150

Collected Steps per Second: 22,068.45085
Overall Steps per Second: 10,494.41160

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.49936
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76558

Cumulative Model Updates: 155,984
Cumulative Timesteps: 1,300,689,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,655.54390
Policy Entropy: 3.80715
Value Function Loss: 0.02667

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.20004
Policy Update Magnitude: 0.38002
Value Function Update Magnitude: 0.36057

Collected Steps per Second: 22,517.14681
Overall Steps per Second: 10,627.69234

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.70469

Cumulative Model Updates: 155,990
Cumulative Timesteps: 1,300,739,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1300739830...
Checkpoint 1300739830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,861.17626
Policy Entropy: 3.80493
Value Function Loss: 0.02525

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16059
Policy Update Magnitude: 0.34262
Value Function Update Magnitude: 0.28498

Collected Steps per Second: 22,332.55540
Overall Steps per Second: 10,568.19181

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.49309
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73269

Cumulative Model Updates: 155,996
Cumulative Timesteps: 1,300,789,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,756.41259
Policy Entropy: 3.79580
Value Function Loss: 0.02193

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14601
Policy Update Magnitude: 0.31438
Value Function Update Magnitude: 0.28719

Collected Steps per Second: 22,686.13202
Overall Steps per Second: 10,762.47296

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.64689

Cumulative Model Updates: 156,002
Cumulative Timesteps: 1,300,839,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1300839858...
Checkpoint 1300839858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,997.10313
Policy Entropy: 3.78878
Value Function Loss: 0.02424

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.32191
Value Function Update Magnitude: 0.33970

Collected Steps per Second: 22,630.45354
Overall Steps per Second: 10,661.45402

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69054

Cumulative Model Updates: 156,008
Cumulative Timesteps: 1,300,889,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,917.49497
Policy Entropy: 3.78549
Value Function Loss: 0.02465

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.36551
Value Function Update Magnitude: 0.32530

Collected Steps per Second: 22,705.48743
Overall Steps per Second: 10,818.34515

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62344

Cumulative Model Updates: 156,014
Cumulative Timesteps: 1,300,939,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1300939884...
Checkpoint 1300939884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,529.12874
Policy Entropy: 3.77044
Value Function Loss: 0.02322

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.37485
Value Function Update Magnitude: 0.39131

Collected Steps per Second: 22,515.42290
Overall Steps per Second: 10,738.21964

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.43586
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.65682

Cumulative Model Updates: 156,020
Cumulative Timesteps: 1,300,989,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,224.93944
Policy Entropy: 3.75834
Value Function Loss: 0.02047

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.38129
Value Function Update Magnitude: 0.49727

Collected Steps per Second: 22,345.16756
Overall Steps per Second: 10,933.12554

Timestep Collection Time: 2.23807
Timestep Consumption Time: 2.33610
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.57417

Cumulative Model Updates: 156,026
Cumulative Timesteps: 1,301,039,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1301039900...
Checkpoint 1301039900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,224.93944
Policy Entropy: 3.74468
Value Function Loss: 0.01948

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.37216
Value Function Update Magnitude: 0.48986

Collected Steps per Second: 21,871.78264
Overall Steps per Second: 10,648.33709

Timestep Collection Time: 2.28623
Timestep Consumption Time: 2.40971
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.69594

Cumulative Model Updates: 156,032
Cumulative Timesteps: 1,301,089,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,454.25308
Policy Entropy: 3.74013
Value Function Loss: 0.02208

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.35899
Value Function Update Magnitude: 0.38826

Collected Steps per Second: 21,448.85299
Overall Steps per Second: 10,541.08959

Timestep Collection Time: 2.33178
Timestep Consumption Time: 2.41289
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.74467

Cumulative Model Updates: 156,038
Cumulative Timesteps: 1,301,139,918

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1301139918...
Checkpoint 1301139918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,440.27228
Policy Entropy: 3.73843
Value Function Loss: 0.02240

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.37386
Value Function Update Magnitude: 0.42033

Collected Steps per Second: 21,288.21667
Overall Steps per Second: 10,526.05844

Timestep Collection Time: 2.35013
Timestep Consumption Time: 2.40284
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.75297

Cumulative Model Updates: 156,044
Cumulative Timesteps: 1,301,189,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,379.92063
Policy Entropy: 3.72709
Value Function Loss: 0.02651

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.40713
Value Function Update Magnitude: 0.39066

Collected Steps per Second: 22,034.13917
Overall Steps per Second: 10,564.27029

Timestep Collection Time: 2.26939
Timestep Consumption Time: 2.46393
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73331

Cumulative Model Updates: 156,050
Cumulative Timesteps: 1,301,239,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1301239952...
Checkpoint 1301239952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,195.52121
Policy Entropy: 3.73261
Value Function Loss: 0.02531

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12626
Policy Update Magnitude: 0.44167
Value Function Update Magnitude: 0.38769

Collected Steps per Second: 22,290.69294
Overall Steps per Second: 10,552.85779

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.49566
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.73938

Cumulative Model Updates: 156,056
Cumulative Timesteps: 1,301,289,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,107.66496
Policy Entropy: 3.75059
Value Function Loss: 0.02803

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.45370
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 22,693.97538
Overall Steps per Second: 10,520.80089

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.54957
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.75306

Cumulative Model Updates: 156,062
Cumulative Timesteps: 1,301,339,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1301339972...
Checkpoint 1301339972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,323.69672
Policy Entropy: 3.76153
Value Function Loss: 0.02517

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13468
Policy Update Magnitude: 0.45593
Value Function Update Magnitude: 0.35860

Collected Steps per Second: 22,748.46901
Overall Steps per Second: 10,638.04159

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.70312

Cumulative Model Updates: 156,068
Cumulative Timesteps: 1,301,390,004

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,625.83912
Policy Entropy: 3.76038
Value Function Loss: 0.02471

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13537
Policy Update Magnitude: 0.45711
Value Function Update Magnitude: 0.38714

Collected Steps per Second: 22,689.50204
Overall Steps per Second: 10,802.98588

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.63039

Cumulative Model Updates: 156,074
Cumulative Timesteps: 1,301,440,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1301440026...
Checkpoint 1301440026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,921.79510
Policy Entropy: 3.76342
Value Function Loss: 0.02162

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13195
Policy Update Magnitude: 0.42994
Value Function Update Magnitude: 0.42092

Collected Steps per Second: 22,756.29467
Overall Steps per Second: 10,689.12644

Timestep Collection Time: 2.19834
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68008

Cumulative Model Updates: 156,080
Cumulative Timesteps: 1,301,490,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,166.94273
Policy Entropy: 3.76719
Value Function Loss: 0.02284

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.41748
Value Function Update Magnitude: 0.46862

Collected Steps per Second: 23,109.63491
Overall Steps per Second: 10,861.57538

Timestep Collection Time: 2.16412
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.60449

Cumulative Model Updates: 156,086
Cumulative Timesteps: 1,301,540,064

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1301540064...
Checkpoint 1301540064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.27701
Policy Entropy: 3.76984
Value Function Loss: 0.02406

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.42728
Value Function Update Magnitude: 0.48298

Collected Steps per Second: 22,710.89993
Overall Steps per Second: 10,670.40537

Timestep Collection Time: 2.20238
Timestep Consumption Time: 2.48517
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.68754

Cumulative Model Updates: 156,092
Cumulative Timesteps: 1,301,590,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.47238
Policy Entropy: 3.77303
Value Function Loss: 0.02453

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.42147
Value Function Update Magnitude: 0.52044

Collected Steps per Second: 22,231.57006
Overall Steps per Second: 10,532.67995

Timestep Collection Time: 2.25031
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.74979

Cumulative Model Updates: 156,098
Cumulative Timesteps: 1,301,640,110

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1301640110...
Checkpoint 1301640110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,816.83446
Policy Entropy: 3.75567
Value Function Loss: 0.02383

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.42606
Value Function Update Magnitude: 0.54429

Collected Steps per Second: 22,463.76040
Overall Steps per Second: 10,592.22320

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.72328

Cumulative Model Updates: 156,104
Cumulative Timesteps: 1,301,690,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,113.87668
Policy Entropy: 3.74021
Value Function Loss: 0.02104

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.42967
Value Function Update Magnitude: 0.52791

Collected Steps per Second: 22,641.11305
Overall Steps per Second: 10,796.61677

Timestep Collection Time: 2.20864
Timestep Consumption Time: 2.42300
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.63164

Cumulative Model Updates: 156,110
Cumulative Timesteps: 1,301,740,146

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1301740146...
Checkpoint 1301740146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,915.42579
Policy Entropy: 3.72575
Value Function Loss: 0.02123

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.41934
Value Function Update Magnitude: 0.48095

Collected Steps per Second: 22,453.12264
Overall Steps per Second: 10,754.82833

Timestep Collection Time: 2.22704
Timestep Consumption Time: 2.42241
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.64945

Cumulative Model Updates: 156,116
Cumulative Timesteps: 1,301,790,150

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,387.29140
Policy Entropy: 3.74029
Value Function Loss: 0.01772

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14121
Policy Update Magnitude: 0.41618
Value Function Update Magnitude: 0.44745

Collected Steps per Second: 22,557.03565
Overall Steps per Second: 10,604.16606

Timestep Collection Time: 2.21714
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71626

Cumulative Model Updates: 156,122
Cumulative Timesteps: 1,301,840,162

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1301840162...
Checkpoint 1301840162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,387.29140
Policy Entropy: 3.73356
Value Function Loss: 0.01820

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.38918
Value Function Update Magnitude: 0.42119

Collected Steps per Second: 22,998.68861
Overall Steps per Second: 10,838.03290

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.43935
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.61338

Cumulative Model Updates: 156,128
Cumulative Timesteps: 1,301,890,162

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,387.29140
Policy Entropy: 3.73705
Value Function Loss: 0.01638

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.14059
Policy Update Magnitude: 0.37298
Value Function Update Magnitude: 0.41297

Collected Steps per Second: 22,862.27640
Overall Steps per Second: 10,675.05263

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68682

Cumulative Model Updates: 156,134
Cumulative Timesteps: 1,301,940,194

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1301940194...
Checkpoint 1301940194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,791.26636
Policy Entropy: 3.73917
Value Function Loss: 0.01726

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.38448
Value Function Update Magnitude: 0.49061

Collected Steps per Second: 22,723.43431
Overall Steps per Second: 10,695.71015

Timestep Collection Time: 2.20143
Timestep Consumption Time: 2.47559
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67702

Cumulative Model Updates: 156,140
Cumulative Timesteps: 1,301,990,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,542.37618
Policy Entropy: 3.73408
Value Function Loss: 0.01775

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.41108
Value Function Update Magnitude: 0.56760

Collected Steps per Second: 22,916.77356
Overall Steps per Second: 10,738.60970

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.47538
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.65814

Cumulative Model Updates: 156,146
Cumulative Timesteps: 1,302,040,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1302040240...
Checkpoint 1302040240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,519.87236
Policy Entropy: 3.75937
Value Function Loss: 0.01733

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12978
Policy Update Magnitude: 0.44847
Value Function Update Magnitude: 0.66847

Collected Steps per Second: 21,559.30212
Overall Steps per Second: 10,531.78656

Timestep Collection Time: 2.31928
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.74772

Cumulative Model Updates: 156,152
Cumulative Timesteps: 1,302,090,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,937.04206
Policy Entropy: 3.76188
Value Function Loss: 0.01863

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13016
Policy Update Magnitude: 0.46626
Value Function Update Magnitude: 0.66218

Collected Steps per Second: 22,409.83115
Overall Steps per Second: 10,538.40587

Timestep Collection Time: 2.23170
Timestep Consumption Time: 2.51399
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74569

Cumulative Model Updates: 156,158
Cumulative Timesteps: 1,302,140,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1302140254...
Checkpoint 1302140254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,690.75938
Policy Entropy: 3.77221
Value Function Loss: 0.01890

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.45200
Value Function Update Magnitude: 0.64212

Collected Steps per Second: 22,267.13718
Overall Steps per Second: 10,560.52692

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.73632

Cumulative Model Updates: 156,164
Cumulative Timesteps: 1,302,190,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,513.13914
Policy Entropy: 3.76054
Value Function Loss: 0.02002

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.43750
Value Function Update Magnitude: 0.70340

Collected Steps per Second: 21,920.97374
Overall Steps per Second: 10,516.69480

Timestep Collection Time: 2.28247
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.75758

Cumulative Model Updates: 156,170
Cumulative Timesteps: 1,302,240,306

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1302240306...
Checkpoint 1302240306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,156.54457
Policy Entropy: 3.75795
Value Function Loss: 0.01869

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.43618
Value Function Update Magnitude: 0.72077

Collected Steps per Second: 22,106.23935
Overall Steps per Second: 10,713.80662

Timestep Collection Time: 2.26271
Timestep Consumption Time: 2.40603
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.66874

Cumulative Model Updates: 156,176
Cumulative Timesteps: 1,302,290,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,795.85859
Policy Entropy: 3.75843
Value Function Loss: 0.01680

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.41275
Value Function Update Magnitude: 0.70399

Collected Steps per Second: 22,164.19228
Overall Steps per Second: 10,525.94274

Timestep Collection Time: 2.25661
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.75169

Cumulative Model Updates: 156,182
Cumulative Timesteps: 1,302,340,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1302340342...
Checkpoint 1302340342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,090.12272
Policy Entropy: 3.75325
Value Function Loss: 0.01676

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.38683
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 22,903.52501
Overall Steps per Second: 10,635.04055

Timestep Collection Time: 2.18394
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70332

Cumulative Model Updates: 156,188
Cumulative Timesteps: 1,302,390,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,764.16818
Policy Entropy: 3.75278
Value Function Loss: 0.01556

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.39754
Value Function Update Magnitude: 0.53056

Collected Steps per Second: 22,738.35649
Overall Steps per Second: 10,849.27029

Timestep Collection Time: 2.19937
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.60953

Cumulative Model Updates: 156,194
Cumulative Timesteps: 1,302,440,372

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1302440372...
Checkpoint 1302440372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,719.77160
Policy Entropy: 3.73239
Value Function Loss: 0.01707

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.39724
Value Function Update Magnitude: 0.46760

Collected Steps per Second: 22,056.01934
Overall Steps per Second: 10,737.52932

Timestep Collection Time: 2.26841
Timestep Consumption Time: 2.39114
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.65954

Cumulative Model Updates: 156,200
Cumulative Timesteps: 1,302,490,404

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,028.08281
Policy Entropy: 3.74662
Value Function Loss: 0.01704

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.39998
Value Function Update Magnitude: 0.42879

Collected Steps per Second: 22,271.69707
Overall Steps per Second: 10,782.49822

Timestep Collection Time: 2.24617
Timestep Consumption Time: 2.39339
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.63956

Cumulative Model Updates: 156,206
Cumulative Timesteps: 1,302,540,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1302540430...
Checkpoint 1302540430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,439.67207
Policy Entropy: 3.73489
Value Function Loss: 0.01870

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.43713
Value Function Update Magnitude: 0.52726

Collected Steps per Second: 21,917.48122
Overall Steps per Second: 10,617.21977

Timestep Collection Time: 2.28229
Timestep Consumption Time: 2.42912
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.71140

Cumulative Model Updates: 156,212
Cumulative Timesteps: 1,302,590,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,762.27934
Policy Entropy: 3.75992
Value Function Loss: 0.01815

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.45704
Value Function Update Magnitude: 0.55726

Collected Steps per Second: 22,527.11283
Overall Steps per Second: 10,862.31957

Timestep Collection Time: 2.22070
Timestep Consumption Time: 2.38476
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.60546

Cumulative Model Updates: 156,218
Cumulative Timesteps: 1,302,640,478

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1302640478...
Checkpoint 1302640478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,531.53179
Policy Entropy: 3.76342
Value Function Loss: 0.01831

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12694
Policy Update Magnitude: 0.46176
Value Function Update Magnitude: 0.60011

Collected Steps per Second: 22,258.50907
Overall Steps per Second: 10,707.96796

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.66961

Cumulative Model Updates: 156,224
Cumulative Timesteps: 1,302,690,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,713.55855
Policy Entropy: 3.75923
Value Function Loss: 0.01956

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.44629
Value Function Update Magnitude: 0.49164

Collected Steps per Second: 22,268.81277
Overall Steps per Second: 10,655.02560

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69300

Cumulative Model Updates: 156,230
Cumulative Timesteps: 1,302,740,484

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1302740484...
Checkpoint 1302740484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,280.95852
Policy Entropy: 3.74953
Value Function Loss: 0.02009

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.42991
Value Function Update Magnitude: 0.41448

Collected Steps per Second: 22,170.17707
Overall Steps per Second: 10,589.15006

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.46791
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.72446

Cumulative Model Updates: 156,236
Cumulative Timesteps: 1,302,790,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,358.00924
Policy Entropy: 3.73667
Value Function Loss: 0.02133

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.40878
Value Function Update Magnitude: 0.36242

Collected Steps per Second: 22,257.57134
Overall Steps per Second: 10,717.31050

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.66703

Cumulative Model Updates: 156,242
Cumulative Timesteps: 1,302,840,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1302840530...
Checkpoint 1302840530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,778.09576
Policy Entropy: 3.74183
Value Function Loss: 0.01972

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.39470
Value Function Update Magnitude: 0.31314

Collected Steps per Second: 22,943.08372
Overall Steps per Second: 10,670.18379

Timestep Collection Time: 2.17931
Timestep Consumption Time: 2.50665
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.68595

Cumulative Model Updates: 156,248
Cumulative Timesteps: 1,302,890,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,284.02784
Policy Entropy: 3.74445
Value Function Loss: 0.01957

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.41123
Value Function Update Magnitude: 0.28598

Collected Steps per Second: 22,898.13116
Overall Steps per Second: 10,820.27786

Timestep Collection Time: 2.18376
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.62132

Cumulative Model Updates: 156,254
Cumulative Timesteps: 1,302,940,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1302940534...
Checkpoint 1302940534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,619.55337
Policy Entropy: 3.73501
Value Function Loss: 0.02070

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.42166
Value Function Update Magnitude: 0.35694

Collected Steps per Second: 22,691.71718
Overall Steps per Second: 10,723.58222

Timestep Collection Time: 2.20468
Timestep Consumption Time: 2.46055
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.66523

Cumulative Model Updates: 156,260
Cumulative Timesteps: 1,302,990,562

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,675.23971
Policy Entropy: 3.74783
Value Function Loss: 0.02004

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.47114
Value Function Update Magnitude: 0.48448

Collected Steps per Second: 22,686.44478
Overall Steps per Second: 10,816.56784

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.41964
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.62457

Cumulative Model Updates: 156,266
Cumulative Timesteps: 1,303,040,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1303040584...
Checkpoint 1303040584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,343.91685
Policy Entropy: 3.72290
Value Function Loss: 0.02041

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.48345
Value Function Update Magnitude: 0.59898

Collected Steps per Second: 22,794.23076
Overall Steps per Second: 10,732.81730

Timestep Collection Time: 2.19459
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.66085

Cumulative Model Updates: 156,272
Cumulative Timesteps: 1,303,090,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,696.88564
Policy Entropy: 3.75651
Value Function Loss: 0.01976

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12887
Policy Update Magnitude: 0.47115
Value Function Update Magnitude: 0.73018

Collected Steps per Second: 22,602.12946
Overall Steps per Second: 10,658.20476

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.69329

Cumulative Model Updates: 156,278
Cumulative Timesteps: 1,303,140,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1303140630...
Checkpoint 1303140630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,139.90717
Policy Entropy: 3.73391
Value Function Loss: 0.02114

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.47228
Value Function Update Magnitude: 0.74554

Collected Steps per Second: 22,677.67456
Overall Steps per Second: 10,843.24080

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.61615

Cumulative Model Updates: 156,284
Cumulative Timesteps: 1,303,190,684

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,139.90717
Policy Entropy: 3.74615
Value Function Loss: 0.02074

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.49384
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 21,845.09044
Overall Steps per Second: 10,550.61928

Timestep Collection Time: 2.28985
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.74114

Cumulative Model Updates: 156,290
Cumulative Timesteps: 1,303,240,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1303240706...
Checkpoint 1303240706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,253.74885
Policy Entropy: 3.73677
Value Function Loss: 0.01929

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13231
Policy Update Magnitude: 0.49663
Value Function Update Magnitude: 0.55294

Collected Steps per Second: 22,345.07978
Overall Steps per Second: 10,623.76025

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.47137
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71133

Cumulative Model Updates: 156,296
Cumulative Timesteps: 1,303,290,758

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,106.42124
Policy Entropy: 3.74561
Value Function Loss: 0.01824

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.51097
Value Function Update Magnitude: 0.53492

Collected Steps per Second: 22,409.45311
Overall Steps per Second: 10,521.83903

Timestep Collection Time: 2.23165
Timestep Consumption Time: 2.52132
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.75297

Cumulative Model Updates: 156,302
Cumulative Timesteps: 1,303,340,768

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1303340768...
Checkpoint 1303340768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,684.52966
Policy Entropy: 3.75688
Value Function Loss: 0.01961

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.50448
Value Function Update Magnitude: 0.48571

Collected Steps per Second: 22,980.17027
Overall Steps per Second: 10,702.79887

Timestep Collection Time: 2.17709
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.67448

Cumulative Model Updates: 156,308
Cumulative Timesteps: 1,303,390,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,577.21092
Policy Entropy: 3.77008
Value Function Loss: 0.02063

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.48179
Value Function Update Magnitude: 0.47661

Collected Steps per Second: 22,180.03199
Overall Steps per Second: 10,802.31852

Timestep Collection Time: 2.25455
Timestep Consumption Time: 2.37464
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.62919

Cumulative Model Updates: 156,314
Cumulative Timesteps: 1,303,440,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1303440804...
Checkpoint 1303440804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,484.32173
Policy Entropy: 3.78377
Value Function Loss: 0.02376

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.48941
Value Function Update Magnitude: 0.50038

Collected Steps per Second: 21,882.34549
Overall Steps per Second: 10,604.17439

Timestep Collection Time: 2.28559
Timestep Consumption Time: 2.43086
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.71644

Cumulative Model Updates: 156,320
Cumulative Timesteps: 1,303,490,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,238.77736
Policy Entropy: 3.78810
Value Function Loss: 0.02438

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.52349
Value Function Update Magnitude: 0.52255

Collected Steps per Second: 22,078.27040
Overall Steps per Second: 10,802.86771

Timestep Collection Time: 2.26503
Timestep Consumption Time: 2.36411
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.62914

Cumulative Model Updates: 156,326
Cumulative Timesteps: 1,303,540,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1303540826...
Checkpoint 1303540826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,238.77736
Policy Entropy: 3.75012
Value Function Loss: 0.02260

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.53363
Value Function Update Magnitude: 0.55025

Collected Steps per Second: 22,157.83904
Overall Steps per Second: 10,734.80816

Timestep Collection Time: 2.25663
Timestep Consumption Time: 2.40130
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.65793

Cumulative Model Updates: 156,332
Cumulative Timesteps: 1,303,590,828

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,238.77736
Policy Entropy: 3.73749
Value Function Loss: 0.02006

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.50426
Value Function Update Magnitude: 0.57664

Collected Steps per Second: 22,843.97485
Overall Steps per Second: 10,884.37873

Timestep Collection Time: 2.18955
Timestep Consumption Time: 2.40584
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.59539

Cumulative Model Updates: 156,338
Cumulative Timesteps: 1,303,640,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1303640846...
Checkpoint 1303640846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258,983.94318
Policy Entropy: 3.73610
Value Function Loss: 0.01795

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.47530
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 21,903.98001
Overall Steps per Second: 10,724.87993

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.37965
PPO Batch Consumption Time: 0.27513
Total Iteration Time: 4.66262

Cumulative Model Updates: 156,344
Cumulative Timesteps: 1,303,690,852

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,983.94318
Policy Entropy: 3.74143
Value Function Loss: 0.01781

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.46890
Value Function Update Magnitude: 0.49179

Collected Steps per Second: 22,471.17202
Overall Steps per Second: 10,764.71931

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.64592

Cumulative Model Updates: 156,350
Cumulative Timesteps: 1,303,740,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1303740864...
Checkpoint 1303740864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258,983.94318
Policy Entropy: 3.74955
Value Function Loss: 0.01529

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.46185
Value Function Update Magnitude: 0.43672

Collected Steps per Second: 22,045.40184
Overall Steps per Second: 10,644.69071

Timestep Collection Time: 2.26904
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.69924

Cumulative Model Updates: 156,356
Cumulative Timesteps: 1,303,790,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,983.94318
Policy Entropy: 3.73338
Value Function Loss: 0.01577

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.45874
Value Function Update Magnitude: 0.40744

Collected Steps per Second: 22,246.74412
Overall Steps per Second: 10,533.19348

Timestep Collection Time: 2.24815
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.74823

Cumulative Model Updates: 156,362
Cumulative Timesteps: 1,303,840,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1303840900...
Checkpoint 1303840900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258,983.94318
Policy Entropy: 3.73597
Value Function Loss: 0.01627

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12471
Policy Update Magnitude: 0.45117
Value Function Update Magnitude: 0.33695

Collected Steps per Second: 22,621.66734
Overall Steps per Second: 10,678.84591

Timestep Collection Time: 2.21089
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.68346

Cumulative Model Updates: 156,368
Cumulative Timesteps: 1,303,890,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,564.39742
Policy Entropy: 3.73355
Value Function Loss: 0.01985

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.43023
Value Function Update Magnitude: 0.32850

Collected Steps per Second: 22,800.81049
Overall Steps per Second: 10,796.57652

Timestep Collection Time: 2.19343
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63221

Cumulative Model Updates: 156,374
Cumulative Timesteps: 1,303,940,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1303940926...
Checkpoint 1303940926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,438.93844
Policy Entropy: 3.74562
Value Function Loss: 0.02178

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.44253
Value Function Update Magnitude: 0.37009

Collected Steps per Second: 22,535.12043
Overall Steps per Second: 10,740.21606

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.65857

Cumulative Model Updates: 156,380
Cumulative Timesteps: 1,303,990,960

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,178.35208
Policy Entropy: 3.75059
Value Function Loss: 0.02414

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.49305
Value Function Update Magnitude: 0.42888

Collected Steps per Second: 22,676.66210
Overall Steps per Second: 10,820.22211

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.41723
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.62320

Cumulative Model Updates: 156,386
Cumulative Timesteps: 1,304,040,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1304040984...
Checkpoint 1304040984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,805.92710
Policy Entropy: 3.75388
Value Function Loss: 0.02695

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11803
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.48483

Collected Steps per Second: 22,630.48281
Overall Steps per Second: 10,673.12033

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.68654

Cumulative Model Updates: 156,392
Cumulative Timesteps: 1,304,091,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,255.15800
Policy Entropy: 3.76362
Value Function Loss: 0.02676

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.53934

Collected Steps per Second: 22,679.42899
Overall Steps per Second: 10,692.94792

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.67785

Cumulative Model Updates: 156,398
Cumulative Timesteps: 1,304,141,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1304141024...
Checkpoint 1304141024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,620.03947
Policy Entropy: 3.75808
Value Function Loss: 0.02405

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.54040
Value Function Update Magnitude: 0.52961

Collected Steps per Second: 22,345.57991
Overall Steps per Second: 10,621.16868

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.70852

Cumulative Model Updates: 156,404
Cumulative Timesteps: 1,304,191,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,620.03947
Policy Entropy: 3.77556
Value Function Loss: 0.01845

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.46409
Value Function Update Magnitude: 0.41302

Collected Steps per Second: 22,457.36539
Overall Steps per Second: 10,786.67993

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.40900
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.63553

Cumulative Model Updates: 156,410
Cumulative Timesteps: 1,304,241,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1304241036...
Checkpoint 1304241036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,620.03947
Policy Entropy: 3.75429
Value Function Loss: 0.01483

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.38178
Value Function Update Magnitude: 0.32287

Collected Steps per Second: 22,196.14588
Overall Steps per Second: 10,554.52483

Timestep Collection Time: 2.25372
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.73958

Cumulative Model Updates: 156,416
Cumulative Timesteps: 1,304,291,060

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,620.03947
Policy Entropy: 3.75100
Value Function Loss: 0.01308

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.33070
Value Function Update Magnitude: 0.27505

Collected Steps per Second: 22,386.10035
Overall Steps per Second: 10,557.19933

Timestep Collection Time: 2.23460
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.73838

Cumulative Model Updates: 156,422
Cumulative Timesteps: 1,304,341,084

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1304341084...
Checkpoint 1304341084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,620.03947
Policy Entropy: 3.73419
Value Function Loss: 0.01414

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.33240
Value Function Update Magnitude: 0.30949

Collected Steps per Second: 22,294.22268
Overall Steps per Second: 10,548.22848

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.74222

Cumulative Model Updates: 156,428
Cumulative Timesteps: 1,304,391,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,398.71925
Policy Entropy: 3.74637
Value Function Loss: 0.01451

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12379
Policy Update Magnitude: 0.37486
Value Function Update Magnitude: 0.41303

Collected Steps per Second: 22,742.80441
Overall Steps per Second: 10,714.77322

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.66664

Cumulative Model Updates: 156,434
Cumulative Timesteps: 1,304,441,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1304441108...
Checkpoint 1304441108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.95949
Policy Entropy: 3.74785
Value Function Loss: 0.01439

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.37649
Value Function Update Magnitude: 0.43074

Collected Steps per Second: 22,339.80873
Overall Steps per Second: 10,734.70641

Timestep Collection Time: 2.23941
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.66040

Cumulative Model Updates: 156,440
Cumulative Timesteps: 1,304,491,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,997.95949
Policy Entropy: 3.73732
Value Function Loss: 0.01486

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.37106
Value Function Update Magnitude: 0.38794

Collected Steps per Second: 22,695.92238
Overall Steps per Second: 10,639.78215

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.49720
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70104

Cumulative Model Updates: 156,446
Cumulative Timesteps: 1,304,541,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1304541154...
Checkpoint 1304541154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,060.89953
Policy Entropy: 3.74625
Value Function Loss: 0.01424

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.40400
Value Function Update Magnitude: 0.43112

Collected Steps per Second: 23,190.12475
Overall Steps per Second: 10,938.42911

Timestep Collection Time: 2.15635
Timestep Consumption Time: 2.41524
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.57159

Cumulative Model Updates: 156,452
Cumulative Timesteps: 1,304,591,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353,648.59809
Policy Entropy: 3.73599
Value Function Loss: 0.01633

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.42945
Value Function Update Magnitude: 0.44776

Collected Steps per Second: 22,016.04483
Overall Steps per Second: 10,684.69487

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.40862
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.67978

Cumulative Model Updates: 156,458
Cumulative Timesteps: 1,304,641,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1304641162...
Checkpoint 1304641162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,156.84505
Policy Entropy: 3.75743
Value Function Loss: 0.01644

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.43756
Value Function Update Magnitude: 0.52351

Collected Steps per Second: 22,189.14968
Overall Steps per Second: 10,886.16342

Timestep Collection Time: 2.25498
Timestep Consumption Time: 2.34132
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.59629

Cumulative Model Updates: 156,464
Cumulative Timesteps: 1,304,691,198

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,922.30954
Policy Entropy: 3.74971
Value Function Loss: 0.01988

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.46982
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 21,607.32840
Overall Steps per Second: 10,567.78347

Timestep Collection Time: 2.31431
Timestep Consumption Time: 2.41762
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.73193

Cumulative Model Updates: 156,470
Cumulative Timesteps: 1,304,741,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1304741204...
Checkpoint 1304741204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,546.83984
Policy Entropy: 3.78465
Value Function Loss: 0.02068

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.51602
Value Function Update Magnitude: 0.70720

Collected Steps per Second: 21,753.01136
Overall Steps per Second: 10,597.98148

Timestep Collection Time: 2.29890
Timestep Consumption Time: 2.41973
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.71863

Cumulative Model Updates: 156,476
Cumulative Timesteps: 1,304,791,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,799.08972
Policy Entropy: 3.77423
Value Function Loss: 0.02226

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.55159
Value Function Update Magnitude: 0.70641

Collected Steps per Second: 21,585.41191
Overall Steps per Second: 10,449.90099

Timestep Collection Time: 2.31749
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.78703

Cumulative Model Updates: 156,482
Cumulative Timesteps: 1,304,841,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1304841236...
Checkpoint 1304841236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,138.71921
Policy Entropy: 3.77038
Value Function Loss: 0.02125

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.64302

Collected Steps per Second: 22,077.08128
Overall Steps per Second: 10,609.63883

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.44830
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.71345

Cumulative Model Updates: 156,488
Cumulative Timesteps: 1,304,891,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,199.82206
Policy Entropy: 3.74514
Value Function Loss: 0.02117

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.52931
Value Function Update Magnitude: 0.49315

Collected Steps per Second: 22,810.48089
Overall Steps per Second: 10,807.24564

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.43562
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.62856

Cumulative Model Updates: 156,494
Cumulative Timesteps: 1,304,941,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1304941266...
Checkpoint 1304941266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,404.72356
Policy Entropy: 3.74975
Value Function Loss: 0.01943

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.51129
Value Function Update Magnitude: 0.41837

Collected Steps per Second: 22,740.10439
Overall Steps per Second: 10,629.47670

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.70616

Cumulative Model Updates: 156,500
Cumulative Timesteps: 1,304,991,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.64346
Policy Entropy: 3.76638
Value Function Loss: 0.01974

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.49354
Value Function Update Magnitude: 0.45886

Collected Steps per Second: 22,770.56267
Overall Steps per Second: 10,652.77000

Timestep Collection Time: 2.19582
Timestep Consumption Time: 2.49780
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.69361

Cumulative Model Updates: 156,506
Cumulative Timesteps: 1,305,041,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1305041290...
Checkpoint 1305041290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,890.32749
Policy Entropy: 3.76631
Value Function Loss: 0.01723

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.45576
Value Function Update Magnitude: 0.61104

Collected Steps per Second: 22,924.94355
Overall Steps per Second: 10,746.55302

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.65377

Cumulative Model Updates: 156,512
Cumulative Timesteps: 1,305,091,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,890.32749
Policy Entropy: 3.76918
Value Function Loss: 0.01674

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.43244
Value Function Update Magnitude: 0.53114

Collected Steps per Second: 22,984.87630
Overall Steps per Second: 10,685.29565

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.50438
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.68008

Cumulative Model Updates: 156,518
Cumulative Timesteps: 1,305,141,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1305141310...
Checkpoint 1305141310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,241.09443
Policy Entropy: 3.76140
Value Function Loss: 0.01608

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.41638
Value Function Update Magnitude: 0.48499

Collected Steps per Second: 22,235.38102
Overall Steps per Second: 10,721.06138

Timestep Collection Time: 2.24894
Timestep Consumption Time: 2.41534
PPO Batch Consumption Time: 0.27565
Total Iteration Time: 4.66428

Cumulative Model Updates: 156,524
Cumulative Timesteps: 1,305,191,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,969.54741
Policy Entropy: 3.76558
Value Function Loss: 0.01617

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.42559
Value Function Update Magnitude: 0.50059

Collected Steps per Second: 22,648.84009
Overall Steps per Second: 10,804.15215

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.62896

Cumulative Model Updates: 156,530
Cumulative Timesteps: 1,305,241,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1305241328...
Checkpoint 1305241328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,969.54741
Policy Entropy: 3.75336
Value Function Loss: 0.01592

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12084
Policy Update Magnitude: 0.40757
Value Function Update Magnitude: 0.48564

Collected Steps per Second: 22,305.88117
Overall Steps per Second: 10,763.26134

Timestep Collection Time: 2.24300
Timestep Consumption Time: 2.40541
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.64841

Cumulative Model Updates: 156,536
Cumulative Timesteps: 1,305,291,360

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,969.54741
Policy Entropy: 3.75160
Value Function Loss: 0.01614

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.40359
Value Function Update Magnitude: 0.40081

Collected Steps per Second: 22,123.23804
Overall Steps per Second: 10,549.66657

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.74024

Cumulative Model Updates: 156,542
Cumulative Timesteps: 1,305,341,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1305341368...
Checkpoint 1305341368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,341.75717
Policy Entropy: 3.76093
Value Function Loss: 0.02152

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.43361
Value Function Update Magnitude: 0.36049

Collected Steps per Second: 22,334.73834
Overall Steps per Second: 10,569.79343

Timestep Collection Time: 2.23956
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.73235

Cumulative Model Updates: 156,548
Cumulative Timesteps: 1,305,391,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,182.51280
Policy Entropy: 3.76979
Value Function Loss: 0.02135

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.51705
Value Function Update Magnitude: 0.46136

Collected Steps per Second: 22,448.71539
Overall Steps per Second: 10,770.91772

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.41531
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.64306

Cumulative Model Updates: 156,554
Cumulative Timesteps: 1,305,441,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1305441398...
Checkpoint 1305441398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,024.93052
Policy Entropy: 3.77421
Value Function Loss: 0.02056

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 22,490.72202
Overall Steps per Second: 10,740.39637

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.27520
Total Iteration Time: 4.65718

Cumulative Model Updates: 156,560
Cumulative Timesteps: 1,305,491,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,342.04562
Policy Entropy: 3.76962
Value Function Loss: 0.02193

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.52760
Value Function Update Magnitude: 0.55589

Collected Steps per Second: 22,713.06406
Overall Steps per Second: 10,775.82701

Timestep Collection Time: 2.20208
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.64150

Cumulative Model Updates: 156,566
Cumulative Timesteps: 1,305,541,434

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1305541434...
Checkpoint 1305541434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,512.60848
Policy Entropy: 3.78456
Value Function Loss: 0.02169

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.56050

Collected Steps per Second: 22,460.83560
Overall Steps per Second: 10,704.03579

Timestep Collection Time: 2.22619
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.67132

Cumulative Model Updates: 156,572
Cumulative Timesteps: 1,305,591,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,990.76167
Policy Entropy: 3.78901
Value Function Loss: 0.02186

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.51243
Value Function Update Magnitude: 0.54655

Collected Steps per Second: 22,553.27111
Overall Steps per Second: 10,797.23026

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63174

Cumulative Model Updates: 156,578
Cumulative Timesteps: 1,305,641,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1305641446...
Checkpoint 1305641446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.62727
Policy Entropy: 3.78756
Value Function Loss: 0.01743

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.46921
Value Function Update Magnitude: 0.48416

Collected Steps per Second: 22,222.96559
Overall Steps per Second: 10,704.54680

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.67315

Cumulative Model Updates: 156,584
Cumulative Timesteps: 1,305,691,470

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.62727
Policy Entropy: 3.76504
Value Function Loss: 0.01685

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.43324
Value Function Update Magnitude: 0.42565

Collected Steps per Second: 21,986.54259
Overall Steps per Second: 10,836.09451

Timestep Collection Time: 2.27657
Timestep Consumption Time: 2.34262
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.61919

Cumulative Model Updates: 156,590
Cumulative Timesteps: 1,305,741,524

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1305741524...
Checkpoint 1305741524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.62727
Policy Entropy: 3.75640
Value Function Loss: 0.01581

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.44582
Value Function Update Magnitude: 0.41414

Collected Steps per Second: 21,488.40591
Overall Steps per Second: 10,693.11067

Timestep Collection Time: 2.32777
Timestep Consumption Time: 2.35001
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.67778

Cumulative Model Updates: 156,596
Cumulative Timesteps: 1,305,791,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,730.31462
Policy Entropy: 3.75588
Value Function Loss: 0.01650

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.45979
Value Function Update Magnitude: 0.39521

Collected Steps per Second: 21,926.36759
Overall Steps per Second: 10,684.18767

Timestep Collection Time: 2.28118
Timestep Consumption Time: 2.40032
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.68150

Cumulative Model Updates: 156,602
Cumulative Timesteps: 1,305,841,562

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1305841562...
Checkpoint 1305841562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,730.31462
Policy Entropy: 3.75188
Value Function Loss: 0.01717

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.40993

Collected Steps per Second: 21,417.34501
Overall Steps per Second: 10,461.56565

Timestep Collection Time: 2.33512
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.78055

Cumulative Model Updates: 156,608
Cumulative Timesteps: 1,305,891,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,828.84833
Policy Entropy: 3.74334
Value Function Loss: 0.01858

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.53529
Value Function Update Magnitude: 0.47033

Collected Steps per Second: 22,540.83086
Overall Steps per Second: 10,838.68937

Timestep Collection Time: 2.21900
Timestep Consumption Time: 2.39577
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.61476

Cumulative Model Updates: 156,614
Cumulative Timesteps: 1,305,941,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1305941592...
Checkpoint 1305941592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,073.51756
Policy Entropy: 3.73878
Value Function Loss: 0.01880

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.59538
Value Function Update Magnitude: 0.54369

Collected Steps per Second: 22,063.83451
Overall Steps per Second: 10,759.83811

Timestep Collection Time: 2.26679
Timestep Consumption Time: 2.38142
PPO Batch Consumption Time: 0.27544
Total Iteration Time: 4.64821

Cumulative Model Updates: 156,620
Cumulative Timesteps: 1,305,991,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,073.51756
Policy Entropy: 3.75093
Value Function Loss: 0.01619

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.57688
Value Function Update Magnitude: 0.52664

Collected Steps per Second: 23,022.78800
Overall Steps per Second: 10,908.30297

Timestep Collection Time: 2.17176
Timestep Consumption Time: 2.41190
PPO Batch Consumption Time: 0.27542
Total Iteration Time: 4.58366

Cumulative Model Updates: 156,626
Cumulative Timesteps: 1,306,041,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1306041606...
Checkpoint 1306041606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,216.42096
Policy Entropy: 3.74933
Value Function Loss: 0.01573

Mean KL Divergence: 0.02313
SB3 Clip Fraction: 0.27322
Policy Update Magnitude: 0.47044
Value Function Update Magnitude: 0.46088

Collected Steps per Second: 22,148.70228
Overall Steps per Second: 10,584.69776

Timestep Collection Time: 2.25774
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.72437

Cumulative Model Updates: 156,632
Cumulative Timesteps: 1,306,091,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,354.59381
Policy Entropy: 3.77961
Value Function Loss: 0.02676

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.47554
Value Function Update Magnitude: 0.42669

Collected Steps per Second: 22,513.70280
Overall Steps per Second: 10,602.94297

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.49600
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.71794

Cumulative Model Updates: 156,638
Cumulative Timesteps: 1,306,141,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1306141636...
Checkpoint 1306141636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,509.52069
Policy Entropy: 3.79566
Value Function Loss: 0.03375

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14503
Policy Update Magnitude: 0.64442
Value Function Update Magnitude: 0.59882

Collected Steps per Second: 22,395.91607
Overall Steps per Second: 10,627.96123

Timestep Collection Time: 2.23291
Timestep Consumption Time: 2.47242
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70532

Cumulative Model Updates: 156,644
Cumulative Timesteps: 1,306,191,644

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,441.15485
Policy Entropy: 3.80524
Value Function Loss: 0.03958

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.17315
Policy Update Magnitude: 0.87645
Value Function Update Magnitude: 0.56735

Collected Steps per Second: 22,682.39500
Overall Steps per Second: 10,800.13637

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.63142

Cumulative Model Updates: 156,650
Cumulative Timesteps: 1,306,241,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1306241664...
Checkpoint 1306241664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,686.66282
Policy Entropy: 3.79141
Value Function Loss: 0.02661

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.86587
Value Function Update Magnitude: 0.52811

Collected Steps per Second: 22,794.15847
Overall Steps per Second: 10,667.87416

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68716

Cumulative Model Updates: 156,656
Cumulative Timesteps: 1,306,291,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,686.66282
Policy Entropy: 3.76008
Value Function Loss: 0.02154

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.79692
Value Function Update Magnitude: 0.52871

Collected Steps per Second: 22,739.30086
Overall Steps per Second: 10,806.48926

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.62722

Cumulative Model Updates: 156,662
Cumulative Timesteps: 1,306,341,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1306341670...
Checkpoint 1306341670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,175.98459
Policy Entropy: 3.75033
Value Function Loss: 0.02334

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.72892
Value Function Update Magnitude: 0.48256

Collected Steps per Second: 22,463.79419
Overall Steps per Second: 10,638.69149

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.47412
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.70001

Cumulative Model Updates: 156,668
Cumulative Timesteps: 1,306,391,672

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,704.55065
Policy Entropy: 3.75090
Value Function Loss: 0.02475

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.67706
Value Function Update Magnitude: 0.49174

Collected Steps per Second: 22,291.24822
Overall Steps per Second: 10,567.34779

Timestep Collection Time: 2.24447
Timestep Consumption Time: 2.49012
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73458

Cumulative Model Updates: 156,674
Cumulative Timesteps: 1,306,441,704

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1306441704...
Checkpoint 1306441704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,470.40126
Policy Entropy: 3.77057
Value Function Loss: 0.02918

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.13974
Policy Update Magnitude: 0.65254
Value Function Update Magnitude: 0.47192

Collected Steps per Second: 22,154.38307
Overall Steps per Second: 10,573.11407

Timestep Collection Time: 2.25743
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.73011

Cumulative Model Updates: 156,680
Cumulative Timesteps: 1,306,491,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,823.49839
Policy Entropy: 3.77936
Value Function Loss: 0.02580

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14511
Policy Update Magnitude: 0.61805
Value Function Update Magnitude: 0.49312

Collected Steps per Second: 22,397.25210
Overall Steps per Second: 10,573.74793

Timestep Collection Time: 2.23286
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.72964

Cumulative Model Updates: 156,686
Cumulative Timesteps: 1,306,541,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1306541726...
Checkpoint 1306541726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,621.76418
Policy Entropy: 3.77575
Value Function Loss: 0.02603

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.44752

Collected Steps per Second: 22,004.94891
Overall Steps per Second: 10,476.48926

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.77488

Cumulative Model Updates: 156,692
Cumulative Timesteps: 1,306,591,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167,106.49097
Policy Entropy: 3.79526
Value Function Loss: 0.02276

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12445
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.42300

Collected Steps per Second: 22,359.11860
Overall Steps per Second: 10,582.01551

Timestep Collection Time: 2.23676
Timestep Consumption Time: 2.48937
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.72613

Cumulative Model Updates: 156,698
Cumulative Timesteps: 1,306,641,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1306641762...
Checkpoint 1306641762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,358.92391
Policy Entropy: 3.79704
Value Function Loss: 0.02276

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.13676
Policy Update Magnitude: 0.53594
Value Function Update Magnitude: 0.41396

Collected Steps per Second: 22,075.03180
Overall Steps per Second: 10,517.25040

Timestep Collection Time: 2.26546
Timestep Consumption Time: 2.48959
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.75505

Cumulative Model Updates: 156,704
Cumulative Timesteps: 1,306,691,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.80359
Value Function Loss: 0.02088

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.36651

Collected Steps per Second: 22,453.83781
Overall Steps per Second: 10,512.06799

Timestep Collection Time: 2.22875
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.76062

Cumulative Model Updates: 156,710
Cumulative Timesteps: 1,306,741,816

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1306741816...
Checkpoint 1306741816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.78620
Value Function Loss: 0.01839

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.61780
Value Function Update Magnitude: 0.37128

Collected Steps per Second: 22,550.92228
Overall Steps per Second: 10,564.26435

Timestep Collection Time: 2.21809
Timestep Consumption Time: 2.51674
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.73483

Cumulative Model Updates: 156,716
Cumulative Timesteps: 1,306,791,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.77900
Value Function Loss: 0.01538

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07010
Policy Update Magnitude: 0.59958
Value Function Update Magnitude: 0.36232

Collected Steps per Second: 22,488.57060
Overall Steps per Second: 10,600.19341

Timestep Collection Time: 2.22433
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.71897

Cumulative Model Updates: 156,722
Cumulative Timesteps: 1,306,841,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1306841858...
Checkpoint 1306841858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.77573
Value Function Loss: 0.01284

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04767
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.34240

Collected Steps per Second: 22,534.54763
Overall Steps per Second: 10,660.13197

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69094

Cumulative Model Updates: 156,728
Cumulative Timesteps: 1,306,891,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.76031
Value Function Loss: 0.01155

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04600
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.38706

Collected Steps per Second: 22,952.25924
Overall Steps per Second: 10,772.39994

Timestep Collection Time: 2.17939
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.64353

Cumulative Model Updates: 156,734
Cumulative Timesteps: 1,306,941,886

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1306941886...
Checkpoint 1306941886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.77145
Value Function Loss: 0.00984

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05301
Policy Update Magnitude: 0.51801
Value Function Update Magnitude: 0.39388

Collected Steps per Second: 22,875.64486
Overall Steps per Second: 10,697.95954

Timestep Collection Time: 2.18713
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67678

Cumulative Model Updates: 156,740
Cumulative Timesteps: 1,306,991,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.57648
Policy Entropy: 3.76358
Value Function Loss: 0.00966

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07097
Policy Update Magnitude: 0.44632
Value Function Update Magnitude: 0.34092

Collected Steps per Second: 22,446.25308
Overall Steps per Second: 10,897.87713

Timestep Collection Time: 2.22906
Timestep Consumption Time: 2.36211
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59117

Cumulative Model Updates: 156,746
Cumulative Timesteps: 1,307,041,952

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1307041952...
Checkpoint 1307041952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,624.90152
Policy Entropy: 3.76672
Value Function Loss: 0.01022

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06734
Policy Update Magnitude: 0.43094
Value Function Update Magnitude: 0.31411

Collected Steps per Second: 21,422.89092
Overall Steps per Second: 10,638.14645

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.36621
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.70025

Cumulative Model Updates: 156,752
Cumulative Timesteps: 1,307,091,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,624.90152
Policy Entropy: 3.76870
Value Function Loss: 0.00969

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07266
Policy Update Magnitude: 0.44877
Value Function Update Magnitude: 0.33301

Collected Steps per Second: 21,855.86034
Overall Steps per Second: 10,484.70020

Timestep Collection Time: 2.28945
Timestep Consumption Time: 2.48302
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.77248

Cumulative Model Updates: 156,758
Cumulative Timesteps: 1,307,141,992

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1307141992...
Checkpoint 1307141992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,246.22047
Policy Entropy: 3.77414
Value Function Loss: 0.00979

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.43709
Value Function Update Magnitude: 0.34059

Collected Steps per Second: 22,059.43438
Overall Steps per Second: 10,588.89998

Timestep Collection Time: 2.26660
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.72193

Cumulative Model Updates: 156,764
Cumulative Timesteps: 1,307,191,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,962.27282
Policy Entropy: 3.79367
Value Function Loss: 0.00892

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16900
Policy Update Magnitude: 0.36989
Value Function Update Magnitude: 0.36792

Collected Steps per Second: 22,209.34106
Overall Steps per Second: 10,606.43249

Timestep Collection Time: 2.25239
Timestep Consumption Time: 2.46400
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.71638

Cumulative Model Updates: 156,770
Cumulative Timesteps: 1,307,242,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1307242016...
Checkpoint 1307242016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,164.46849
Policy Entropy: 3.77357
Value Function Loss: 0.01250

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.17494
Policy Update Magnitude: 0.33333
Value Function Update Magnitude: 0.46563

Collected Steps per Second: 22,295.97059
Overall Steps per Second: 10,515.45601

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.51335
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.75681

Cumulative Model Updates: 156,776
Cumulative Timesteps: 1,307,292,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,164.46849
Policy Entropy: 3.78135
Value Function Loss: 0.01207

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18111
Policy Update Magnitude: 0.44005
Value Function Update Magnitude: 0.56853

Collected Steps per Second: 22,929.39472
Overall Steps per Second: 10,781.45600

Timestep Collection Time: 2.18183
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64019

Cumulative Model Updates: 156,782
Cumulative Timesteps: 1,307,342,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1307342064...
Checkpoint 1307342064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,164.46849
Policy Entropy: 3.77194
Value Function Loss: 0.01407

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16757
Policy Update Magnitude: 0.41036
Value Function Update Magnitude: 0.51487

Collected Steps per Second: 22,441.69017
Overall Steps per Second: 10,736.75215

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.42997
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.65895

Cumulative Model Updates: 156,788
Cumulative Timesteps: 1,307,392,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,877.52316
Policy Entropy: 3.77835
Value Function Loss: 0.01420

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16633
Policy Update Magnitude: 0.36730
Value Function Update Magnitude: 0.37136

Collected Steps per Second: 22,944.21129
Overall Steps per Second: 10,868.85567

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.42110
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.60030

Cumulative Model Updates: 156,794
Cumulative Timesteps: 1,307,442,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1307442086...
Checkpoint 1307442086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,908.43035
Policy Entropy: 3.77251
Value Function Loss: 0.01589

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.15825
Policy Update Magnitude: 0.32414
Value Function Update Magnitude: 0.29634

Collected Steps per Second: 22,200.82609
Overall Steps per Second: 10,680.66511

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.43026
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.68342

Cumulative Model Updates: 156,800
Cumulative Timesteps: 1,307,492,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,805.85632
Policy Entropy: 3.76427
Value Function Loss: 0.01752

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.31240
Value Function Update Magnitude: 0.29862

Collected Steps per Second: 22,500.55226
Overall Steps per Second: 10,645.75468

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.69784

Cumulative Model Updates: 156,806
Cumulative Timesteps: 1,307,542,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1307542120...
Checkpoint 1307542120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,805.85632
Policy Entropy: 3.77012
Value Function Loss: 0.01724

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.34714
Value Function Update Magnitude: 0.32835

Collected Steps per Second: 22,588.08738
Overall Steps per Second: 10,667.57895

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.68860

Cumulative Model Updates: 156,812
Cumulative Timesteps: 1,307,592,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,603.14709
Policy Entropy: 3.76069
Value Function Loss: 0.01882

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.42171
Value Function Update Magnitude: 0.35166

Collected Steps per Second: 22,094.70338
Overall Steps per Second: 10,646.73711

Timestep Collection Time: 2.26299
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.69627

Cumulative Model Updates: 156,818
Cumulative Timesteps: 1,307,642,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1307642136...
Checkpoint 1307642136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,244.42476
Policy Entropy: 3.77084
Value Function Loss: 0.01902

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07785
Policy Update Magnitude: 0.56977
Value Function Update Magnitude: 0.49275

Collected Steps per Second: 21,948.96368
Overall Steps per Second: 10,657.45467

Timestep Collection Time: 2.27810
Timestep Consumption Time: 2.41364
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.69174

Cumulative Model Updates: 156,824
Cumulative Timesteps: 1,307,692,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234,308.80176
Policy Entropy: 3.77675
Value Function Loss: 0.02128

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.18930
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.63176

Collected Steps per Second: 22,226.51424
Overall Steps per Second: 10,490.23942

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.51687
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.76653

Cumulative Model Updates: 156,830
Cumulative Timesteps: 1,307,742,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1307742140...
Checkpoint 1307742140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,425.77858
Policy Entropy: 3.76630
Value Function Loss: 0.02005

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.52404
Value Function Update Magnitude: 0.65178

Collected Steps per Second: 22,149.55234
Overall Steps per Second: 10,710.10721

Timestep Collection Time: 2.25865
Timestep Consumption Time: 2.41246
PPO Batch Consumption Time: 0.27586
Total Iteration Time: 4.67110

Cumulative Model Updates: 156,836
Cumulative Timesteps: 1,307,792,168

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,881.13855
Policy Entropy: 3.76021
Value Function Loss: 0.02620

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.58931
Value Function Update Magnitude: 0.67055

Collected Steps per Second: 21,307.68789
Overall Steps per Second: 10,410.39160

Timestep Collection Time: 2.34779
Timestep Consumption Time: 2.45760
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.80539

Cumulative Model Updates: 156,842
Cumulative Timesteps: 1,307,842,194

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1307842194...
Checkpoint 1307842194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,944.71086
Policy Entropy: 3.79116
Value Function Loss: 0.02802

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.65631
Value Function Update Magnitude: 0.61421

Collected Steps per Second: 21,813.24091
Overall Steps per Second: 10,618.81582

Timestep Collection Time: 2.29329
Timestep Consumption Time: 2.41760
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.71088

Cumulative Model Updates: 156,848
Cumulative Timesteps: 1,307,892,218

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534,761.01074
Policy Entropy: 3.82438
Value Function Loss: 0.03128

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.67634
Value Function Update Magnitude: 0.57181

Collected Steps per Second: 22,165.67890
Overall Steps per Second: 10,518.22141

Timestep Collection Time: 2.25691
Timestep Consumption Time: 2.49921
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.75613

Cumulative Model Updates: 156,854
Cumulative Timesteps: 1,307,942,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1307942244...
Checkpoint 1307942244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,465.65202
Policy Entropy: 3.83727
Value Function Loss: 0.02759

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.65209
Value Function Update Magnitude: 0.61421

Collected Steps per Second: 22,444.62332
Overall Steps per Second: 10,594.49386

Timestep Collection Time: 2.22860
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.72132

Cumulative Model Updates: 156,860
Cumulative Timesteps: 1,307,992,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,865.66268
Policy Entropy: 3.80002
Value Function Loss: 0.02666

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13272
Policy Update Magnitude: 0.61734
Value Function Update Magnitude: 0.67509

Collected Steps per Second: 22,684.77075
Overall Steps per Second: 10,648.28166

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.49147
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.69559

Cumulative Model Updates: 156,866
Cumulative Timesteps: 1,308,042,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1308042264...
Checkpoint 1308042264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,319.31497
Policy Entropy: 3.77726
Value Function Loss: 0.02370

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13173
Policy Update Magnitude: 0.61614
Value Function Update Magnitude: 0.67467

Collected Steps per Second: 22,456.47727
Overall Steps per Second: 10,637.21784

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.70142

Cumulative Model Updates: 156,872
Cumulative Timesteps: 1,308,092,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,482.38364
Policy Entropy: 3.77486
Value Function Loss: 0.02608

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.61285
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,980.10991
Overall Steps per Second: 10,705.95738

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.49500
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.67123

Cumulative Model Updates: 156,878
Cumulative Timesteps: 1,308,142,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1308142284...
Checkpoint 1308142284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,554.15474
Policy Entropy: 3.77835
Value Function Loss: 0.02386

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.60556

Collected Steps per Second: 22,307.49574
Overall Steps per Second: 10,636.90075

Timestep Collection Time: 2.24274
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.70344

Cumulative Model Updates: 156,884
Cumulative Timesteps: 1,308,192,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,204.15099
Policy Entropy: 3.77551
Value Function Loss: 0.02036

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.57920
Value Function Update Magnitude: 0.68706

Collected Steps per Second: 22,799.45684
Overall Steps per Second: 10,834.53300

Timestep Collection Time: 2.19426
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.61746

Cumulative Model Updates: 156,890
Cumulative Timesteps: 1,308,242,342

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1308242342...
Checkpoint 1308242342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,204.15099
Policy Entropy: 3.76910
Value Function Loss: 0.01554

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.17444
Policy Update Magnitude: 0.45592
Value Function Update Magnitude: 0.56730

Collected Steps per Second: 22,362.77078
Overall Steps per Second: 10,777.29500

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.40381
PPO Batch Consumption Time: 0.27546
Total Iteration Time: 4.63994

Cumulative Model Updates: 156,896
Cumulative Timesteps: 1,308,292,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,893.40018
Policy Entropy: 3.75413
Value Function Loss: 0.01520

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.39772
Value Function Update Magnitude: 0.43814

Collected Steps per Second: 22,456.09701
Overall Steps per Second: 10,765.52612

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.41944
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64743

Cumulative Model Updates: 156,902
Cumulative Timesteps: 1,308,342,380

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1308342380...
Checkpoint 1308342380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,373.48903
Policy Entropy: 3.74932
Value Function Loss: 0.01635

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.06000
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.42634

Collected Steps per Second: 22,415.50500
Overall Steps per Second: 10,698.43172

Timestep Collection Time: 2.23185
Timestep Consumption Time: 2.44435
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.67620

Cumulative Model Updates: 156,908
Cumulative Timesteps: 1,308,392,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,373.48903
Policy Entropy: 3.75135
Value Function Loss: 0.01672

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07803
Policy Update Magnitude: 0.67400
Value Function Update Magnitude: 0.50246

Collected Steps per Second: 22,660.89676
Overall Steps per Second: 10,681.67611

Timestep Collection Time: 2.20856
Timestep Consumption Time: 2.47684
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.68541

Cumulative Model Updates: 156,914
Cumulative Timesteps: 1,308,442,456

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1308442456...
Checkpoint 1308442456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,145.03581
Policy Entropy: 3.76558
Value Function Loss: 0.01502

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06087
Policy Update Magnitude: 0.68663
Value Function Update Magnitude: 0.53522

Collected Steps per Second: 21,624.84053
Overall Steps per Second: 10,599.47706

Timestep Collection Time: 2.31336
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.71967

Cumulative Model Updates: 156,920
Cumulative Timesteps: 1,308,492,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,661.50259
Policy Entropy: 3.77422
Value Function Loss: 0.01265

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05313
Policy Update Magnitude: 0.67403
Value Function Update Magnitude: 0.59340

Collected Steps per Second: 22,331.32216
Overall Steps per Second: 10,748.92126

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.65256

Cumulative Model Updates: 156,926
Cumulative Timesteps: 1,308,542,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1308542492...
Checkpoint 1308542492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,689.31843
Policy Entropy: 3.78257
Value Function Loss: 0.01237

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06333
Policy Update Magnitude: 0.62674
Value Function Update Magnitude: 0.60564

Collected Steps per Second: 22,015.98140
Overall Steps per Second: 10,592.42725

Timestep Collection Time: 2.27108
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.72035

Cumulative Model Updates: 156,932
Cumulative Timesteps: 1,308,592,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,896.93719
Policy Entropy: 3.78241
Value Function Loss: 0.01423

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06796
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.61676

Collected Steps per Second: 22,751.20642
Overall Steps per Second: 10,881.21502

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.39796
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.59618

Cumulative Model Updates: 156,938
Cumulative Timesteps: 1,308,642,504

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1308642504...
Checkpoint 1308642504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,180.34006
Policy Entropy: 3.77346
Value Function Loss: 0.01679

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.20936
Policy Update Magnitude: 0.47771
Value Function Update Magnitude: 0.67377

Collected Steps per Second: 22,431.87522
Overall Steps per Second: 10,748.33175

Timestep Collection Time: 2.22968
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.65337

Cumulative Model Updates: 156,944
Cumulative Timesteps: 1,308,692,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,199.09818
Policy Entropy: 3.77760
Value Function Loss: 0.01537

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.16670
Policy Update Magnitude: 0.43668
Value Function Update Magnitude: 0.69858

Collected Steps per Second: 23,285.43086
Overall Steps per Second: 10,865.08007

Timestep Collection Time: 2.14727
Timestep Consumption Time: 2.45463
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.60190

Cumulative Model Updates: 156,950
Cumulative Timesteps: 1,308,742,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1308742520...
Checkpoint 1308742520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,199.09818
Policy Entropy: 3.75202
Value Function Loss: 0.01476

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.38946
Value Function Update Magnitude: 0.61715

Collected Steps per Second: 22,575.39618
Overall Steps per Second: 10,675.06864

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.46970
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.68512

Cumulative Model Updates: 156,956
Cumulative Timesteps: 1,308,792,534

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267,054.74810
Policy Entropy: 3.74690
Value Function Loss: 0.01511

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15006
Policy Update Magnitude: 0.36225
Value Function Update Magnitude: 0.50425

Collected Steps per Second: 22,118.78651
Overall Steps per Second: 10,530.40885

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.75233

Cumulative Model Updates: 156,962
Cumulative Timesteps: 1,308,842,578

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1308842578...
Checkpoint 1308842578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,316.04335
Policy Entropy: 3.73840
Value Function Loss: 0.01654

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.35885
Value Function Update Magnitude: 0.50321

Collected Steps per Second: 21,783.70753
Overall Steps per Second: 10,633.76726

Timestep Collection Time: 2.29612
Timestep Consumption Time: 2.40758
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.70370

Cumulative Model Updates: 156,968
Cumulative Timesteps: 1,308,892,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,978.55685
Policy Entropy: 3.73989
Value Function Loss: 0.02070

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14105
Policy Update Magnitude: 0.40936
Value Function Update Magnitude: 0.47557

Collected Steps per Second: 22,417.12726
Overall Steps per Second: 10,748.92186

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.65330

Cumulative Model Updates: 156,974
Cumulative Timesteps: 1,308,942,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1308942614...
Checkpoint 1308942614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,376.52114
Policy Entropy: 3.75620
Value Function Loss: 0.02254

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.46874
Value Function Update Magnitude: 0.47720

Collected Steps per Second: 22,291.55848
Overall Steps per Second: 10,629.52956

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.46117
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.70444

Cumulative Model Updates: 156,980
Cumulative Timesteps: 1,308,992,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,625.44630
Policy Entropy: 3.77491
Value Function Loss: 0.02896

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.52193
Value Function Update Magnitude: 0.57281

Collected Steps per Second: 22,724.24924
Overall Steps per Second: 10,695.89825

Timestep Collection Time: 2.20170
Timestep Consumption Time: 2.47598
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.67768

Cumulative Model Updates: 156,986
Cumulative Timesteps: 1,309,042,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1309042652...
Checkpoint 1309042652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,981.56856
Policy Entropy: 3.81406
Value Function Loss: 0.02773

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.54170
Value Function Update Magnitude: 0.71814

Collected Steps per Second: 22,552.48380
Overall Steps per Second: 10,694.09488

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.67548

Cumulative Model Updates: 156,992
Cumulative Timesteps: 1,309,092,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,618.79255
Policy Entropy: 3.79283
Value Function Loss: 0.02654

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.51719
Value Function Update Magnitude: 0.82715

Collected Steps per Second: 22,208.82045
Overall Steps per Second: 10,676.30955

Timestep Collection Time: 2.25244
Timestep Consumption Time: 2.43308
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.68551

Cumulative Model Updates: 156,998
Cumulative Timesteps: 1,309,142,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1309142676...
Checkpoint 1309142676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258,220.42876
Policy Entropy: 3.77129
Value Function Loss: 0.02271

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.49848
Value Function Update Magnitude: 0.80328

Collected Steps per Second: 22,058.08447
Overall Steps per Second: 10,638.54453

Timestep Collection Time: 2.26738
Timestep Consumption Time: 2.43383
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.70121

Cumulative Model Updates: 157,004
Cumulative Timesteps: 1,309,192,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,222.97164
Policy Entropy: 3.74381
Value Function Loss: 0.02325

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.49202
Value Function Update Magnitude: 0.78867

Collected Steps per Second: 22,398.91743
Overall Steps per Second: 10,948.98347

Timestep Collection Time: 2.23350
Timestep Consumption Time: 2.33569
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.56919

Cumulative Model Updates: 157,010
Cumulative Timesteps: 1,309,242,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1309242718...
Checkpoint 1309242718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,497.93804
Policy Entropy: 3.75701
Value Function Loss: 0.02103

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.69190

Collected Steps per Second: 21,657.58207
Overall Steps per Second: 10,623.37217

Timestep Collection Time: 2.31005
Timestep Consumption Time: 2.39938
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.70943

Cumulative Model Updates: 157,016
Cumulative Timesteps: 1,309,292,748

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,370.43204
Policy Entropy: 3.76934
Value Function Loss: 0.02058

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.47219
Value Function Update Magnitude: 0.54312

Collected Steps per Second: 22,546.27789
Overall Steps per Second: 10,832.04349

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.39904
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61741

Cumulative Model Updates: 157,022
Cumulative Timesteps: 1,309,342,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1309342764...
Checkpoint 1309342764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,373.45671
Policy Entropy: 3.75864
Value Function Loss: 0.01812

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.45172
Value Function Update Magnitude: 0.42253

Collected Steps per Second: 21,863.87979
Overall Steps per Second: 10,666.01342

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.40101
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.68797

Cumulative Model Updates: 157,028
Cumulative Timesteps: 1,309,392,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,089.23101
Policy Entropy: 3.76238
Value Function Loss: 0.02096

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.43400
Value Function Update Magnitude: 0.40843

Collected Steps per Second: 22,711.16043
Overall Steps per Second: 10,676.93751

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.68786

Cumulative Model Updates: 157,034
Cumulative Timesteps: 1,309,442,818

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1309442818...
Checkpoint 1309442818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,599.05345
Policy Entropy: 3.75588
Value Function Loss: 0.01966

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12759
Policy Update Magnitude: 0.43360
Value Function Update Magnitude: 0.46437

Collected Steps per Second: 21,999.89814
Overall Steps per Second: 10,504.51624

Timestep Collection Time: 2.27374
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.76195

Cumulative Model Updates: 157,040
Cumulative Timesteps: 1,309,492,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,128.15785
Policy Entropy: 3.76828
Value Function Loss: 0.02076

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.46378
Value Function Update Magnitude: 0.53825

Collected Steps per Second: 23,263.92939
Overall Steps per Second: 10,867.03563

Timestep Collection Time: 2.14951
Timestep Consumption Time: 2.45212
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.60162

Cumulative Model Updates: 157,046
Cumulative Timesteps: 1,309,542,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1309542846...
Checkpoint 1309542846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,361.64364
Policy Entropy: 3.76055
Value Function Loss: 0.01896

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.45180
Value Function Update Magnitude: 0.54143

Collected Steps per Second: 22,816.45562
Overall Steps per Second: 10,639.00950

Timestep Collection Time: 2.19228
Timestep Consumption Time: 2.50929
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70157

Cumulative Model Updates: 157,052
Cumulative Timesteps: 1,309,592,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,974.33950
Policy Entropy: 3.76539
Value Function Loss: 0.02007

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.45458
Value Function Update Magnitude: 0.56292

Collected Steps per Second: 22,804.22398
Overall Steps per Second: 10,851.25198

Timestep Collection Time: 2.19389
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61053

Cumulative Model Updates: 157,058
Cumulative Timesteps: 1,309,642,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1309642896...
Checkpoint 1309642896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,256.21007
Policy Entropy: 3.77390
Value Function Loss: 0.02012

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.46802
Value Function Update Magnitude: 0.73484

Collected Steps per Second: 22,536.23821
Overall Steps per Second: 10,798.09473

Timestep Collection Time: 2.21963
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.63248

Cumulative Model Updates: 157,064
Cumulative Timesteps: 1,309,692,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,427.79717
Policy Entropy: 3.78585
Value Function Loss: 0.02052

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.50128
Value Function Update Magnitude: 0.78550

Collected Steps per Second: 21,740.92185
Overall Steps per Second: 10,385.65210

Timestep Collection Time: 2.30082
Timestep Consumption Time: 2.51563
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.81645

Cumulative Model Updates: 157,070
Cumulative Timesteps: 1,309,742,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1309742940...
Checkpoint 1309742940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.48700
Policy Entropy: 3.78251
Value Function Loss: 0.01913

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.49061
Value Function Update Magnitude: 0.72721

Collected Steps per Second: 22,415.71723
Overall Steps per Second: 10,645.30687

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.46741
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.69897

Cumulative Model Updates: 157,076
Cumulative Timesteps: 1,309,792,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,692.34625
Policy Entropy: 3.76490
Value Function Loss: 0.01848

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.44420
Value Function Update Magnitude: 0.65650

Collected Steps per Second: 22,362.04738
Overall Steps per Second: 10,593.71834

Timestep Collection Time: 2.23611
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.72016

Cumulative Model Updates: 157,082
Cumulative Timesteps: 1,309,842,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1309842966...
Checkpoint 1309842966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,751.03853
Policy Entropy: 3.74586
Value Function Loss: 0.01804

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.45621
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 21,380.01878
Overall Steps per Second: 10,508.32504

Timestep Collection Time: 2.33929
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.75946

Cumulative Model Updates: 157,088
Cumulative Timesteps: 1,309,892,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 161,751.03853
Policy Entropy: 3.75117
Value Function Loss: 0.01770

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.44017
Value Function Update Magnitude: 0.47019

Collected Steps per Second: 21,450.67053
Overall Steps per Second: 10,534.58302

Timestep Collection Time: 2.33177
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.74798

Cumulative Model Updates: 157,094
Cumulative Timesteps: 1,309,942,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1309942998...
Checkpoint 1309942998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,751.03853
Policy Entropy: 3.74221
Value Function Loss: 0.01677

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.40975
Value Function Update Magnitude: 0.34517

Collected Steps per Second: 21,647.05206
Overall Steps per Second: 10,621.72662

Timestep Collection Time: 2.31117
Timestep Consumption Time: 2.39899
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.71016

Cumulative Model Updates: 157,100
Cumulative Timesteps: 1,309,993,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,020.02621
Policy Entropy: 3.74727
Value Function Loss: 0.01740

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.40611
Value Function Update Magnitude: 0.32476

Collected Steps per Second: 22,742.19864
Overall Steps per Second: 10,832.36168

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.61746

Cumulative Model Updates: 157,106
Cumulative Timesteps: 1,310,043,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1310043046...
Checkpoint 1310043046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,955.05776
Policy Entropy: 3.74200
Value Function Loss: 0.01769

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.42696
Value Function Update Magnitude: 0.33500

Collected Steps per Second: 22,332.11295
Overall Steps per Second: 10,659.96814

Timestep Collection Time: 2.24126
Timestep Consumption Time: 2.45407
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.69532

Cumulative Model Updates: 157,112
Cumulative Timesteps: 1,310,093,098

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,401.66049
Policy Entropy: 3.74970
Value Function Loss: 0.01796

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.42992
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 22,717.57272
Overall Steps per Second: 10,825.47270

Timestep Collection Time: 2.20173
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.62040

Cumulative Model Updates: 157,118
Cumulative Timesteps: 1,310,143,116

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1310143116...
Checkpoint 1310143116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,401.66049
Policy Entropy: 3.75328
Value Function Loss: 0.01632

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.43392
Value Function Update Magnitude: 0.37636

Collected Steps per Second: 22,855.03893
Overall Steps per Second: 10,719.42185

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.47831
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.66742

Cumulative Model Updates: 157,124
Cumulative Timesteps: 1,310,193,148

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,993.87434
Policy Entropy: 3.77227
Value Function Loss: 0.01813

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.44484
Value Function Update Magnitude: 0.42718

Collected Steps per Second: 23,108.75418
Overall Steps per Second: 10,892.26655

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.59353

Cumulative Model Updates: 157,130
Cumulative Timesteps: 1,310,243,182

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1310243182...
Checkpoint 1310243182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,047.58389
Policy Entropy: 3.78107
Value Function Loss: 0.01790

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12596
Policy Update Magnitude: 0.46515
Value Function Update Magnitude: 0.52462

Collected Steps per Second: 22,426.60008
Overall Steps per Second: 10,779.05286

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.41067
PPO Batch Consumption Time: 0.27620
Total Iteration Time: 4.64160

Cumulative Model Updates: 157,136
Cumulative Timesteps: 1,310,293,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,444.04024
Policy Entropy: 3.77760
Value Function Loss: 0.01960

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.51910
Value Function Update Magnitude: 0.66124

Collected Steps per Second: 22,381.53173
Overall Steps per Second: 10,758.28138

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.64907

Cumulative Model Updates: 157,142
Cumulative Timesteps: 1,310,343,230

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1310343230...
Checkpoint 1310343230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,613.16221
Policy Entropy: 3.77229
Value Function Loss: 0.02145

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.67996

Collected Steps per Second: 22,393.15316
Overall Steps per Second: 10,741.64383

Timestep Collection Time: 2.23318
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.65553

Cumulative Model Updates: 157,148
Cumulative Timesteps: 1,310,393,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,959.45125
Policy Entropy: 3.76607
Value Function Loss: 0.02580

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.55408

Collected Steps per Second: 22,483.94101
Overall Steps per Second: 10,641.22610

Timestep Collection Time: 2.22461
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.70040

Cumulative Model Updates: 157,154
Cumulative Timesteps: 1,310,443,256

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1310443256...
Checkpoint 1310443256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,683.20137
Policy Entropy: 3.75554
Value Function Loss: 0.02528

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12069
Policy Update Magnitude: 0.55377
Value Function Update Magnitude: 0.45197

Collected Steps per Second: 21,829.09156
Overall Steps per Second: 10,426.76704

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.50513
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.79593

Cumulative Model Updates: 157,160
Cumulative Timesteps: 1,310,493,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299,409.80946
Policy Entropy: 3.74474
Value Function Loss: 0.02353

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.52908
Value Function Update Magnitude: 0.46828

Collected Steps per Second: 22,887.71818
Overall Steps per Second: 10,649.38499

Timestep Collection Time: 2.18641
Timestep Consumption Time: 2.51264
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.69905

Cumulative Model Updates: 157,166
Cumulative Timesteps: 1,310,543,304

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1310543304...
Checkpoint 1310543304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,827.80262
Policy Entropy: 3.74004
Value Function Loss: 0.02015

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.50692
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 22,223.68858
Overall Steps per Second: 10,554.03559

Timestep Collection Time: 2.25048
Timestep Consumption Time: 2.48837
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.73885

Cumulative Model Updates: 157,172
Cumulative Timesteps: 1,310,593,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247,330.28322
Policy Entropy: 3.75163
Value Function Loss: 0.01863

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.48811
Value Function Update Magnitude: 0.62914

Collected Steps per Second: 23,268.77067
Overall Steps per Second: 10,851.36989

Timestep Collection Time: 2.15009
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.61048

Cumulative Model Updates: 157,178
Cumulative Timesteps: 1,310,643,348

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1310643348...
Checkpoint 1310643348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,109.97257
Policy Entropy: 3.75439
Value Function Loss: 0.01846

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.45237
Value Function Update Magnitude: 0.50055

Collected Steps per Second: 21,840.72849
Overall Steps per Second: 10,595.46685

Timestep Collection Time: 2.28939
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.71919

Cumulative Model Updates: 157,184
Cumulative Timesteps: 1,310,693,350

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,109.97257
Policy Entropy: 3.76269
Value Function Loss: 0.01626

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.43403
Value Function Update Magnitude: 0.48298

Collected Steps per Second: 22,143.52510
Overall Steps per Second: 10,862.38830

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.34645
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.60580

Cumulative Model Updates: 157,190
Cumulative Timesteps: 1,310,743,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1310743380...
Checkpoint 1310743380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,109.97257
Policy Entropy: 3.75229
Value Function Loss: 0.01565

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.41682
Value Function Update Magnitude: 0.43924

Collected Steps per Second: 21,576.86538
Overall Steps per Second: 10,756.86500

Timestep Collection Time: 2.31785
Timestep Consumption Time: 2.33146
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.64931

Cumulative Model Updates: 157,196
Cumulative Timesteps: 1,310,793,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,456.33316
Policy Entropy: 3.74167
Value Function Loss: 0.01758

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.44358
Value Function Update Magnitude: 0.43085

Collected Steps per Second: 21,650.80882
Overall Steps per Second: 10,437.65047

Timestep Collection Time: 2.31068
Timestep Consumption Time: 2.48236
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.79303

Cumulative Model Updates: 157,202
Cumulative Timesteps: 1,310,843,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1310843420...
Checkpoint 1310843420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,246.72928
Policy Entropy: 3.73761
Value Function Loss: 0.01886

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.47972
Value Function Update Magnitude: 0.42514

Collected Steps per Second: 21,808.02319
Overall Steps per Second: 10,695.53304

Timestep Collection Time: 2.29301
Timestep Consumption Time: 2.38240
PPO Batch Consumption Time: 0.27540
Total Iteration Time: 4.67541

Cumulative Model Updates: 157,208
Cumulative Timesteps: 1,310,893,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,785.50919
Policy Entropy: 3.75072
Value Function Loss: 0.02353

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12938
Policy Update Magnitude: 0.50763
Value Function Update Magnitude: 0.39830

Collected Steps per Second: 22,326.07020
Overall Steps per Second: 10,733.80499

Timestep Collection Time: 2.23953
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.65818

Cumulative Model Updates: 157,214
Cumulative Timesteps: 1,310,943,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1310943426...
Checkpoint 1310943426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,485.87671
Policy Entropy: 3.77502
Value Function Loss: 0.02200

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.44039

Collected Steps per Second: 22,708.73359
Overall Steps per Second: 10,769.67962

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.64434

Cumulative Model Updates: 157,220
Cumulative Timesteps: 1,310,993,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275,427.21650
Policy Entropy: 3.77242
Value Function Loss: 0.02636

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.59313
Value Function Update Magnitude: 0.47628

Collected Steps per Second: 22,960.54432
Overall Steps per Second: 10,813.06483

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.44766
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.62644

Cumulative Model Updates: 157,226
Cumulative Timesteps: 1,311,043,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1311043470...
Checkpoint 1311043470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,864.09260
Policy Entropy: 3.78590
Value Function Loss: 0.02440

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.64181
Value Function Update Magnitude: 0.55995

Collected Steps per Second: 22,457.97817
Overall Steps per Second: 10,702.80742

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.44637
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.67373

Cumulative Model Updates: 157,232
Cumulative Timesteps: 1,311,093,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,884.96264
Policy Entropy: 3.77181
Value Function Loss: 0.02527

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.61186
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 22,879.80322
Overall Steps per Second: 10,824.03267

Timestep Collection Time: 2.18612
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.62101

Cumulative Model Updates: 157,238
Cumulative Timesteps: 1,311,143,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1311143510...
Checkpoint 1311143510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,884.96264
Policy Entropy: 3.76378
Value Function Loss: 0.01940

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11807
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.48140

Collected Steps per Second: 22,796.53956
Overall Steps per Second: 10,675.66973

Timestep Collection Time: 2.19454
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68617

Cumulative Model Updates: 157,244
Cumulative Timesteps: 1,311,193,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309,342.43475
Policy Entropy: 3.75171
Value Function Loss: 0.02067

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.40494

Collected Steps per Second: 22,807.78819
Overall Steps per Second: 10,833.49683

Timestep Collection Time: 2.19320
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.61735

Cumulative Model Updates: 157,250
Cumulative Timesteps: 1,311,243,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1311243560...
Checkpoint 1311243560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,959.82162
Policy Entropy: 3.76567
Value Function Loss: 0.02126

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.47387
Value Function Update Magnitude: 0.41399

Collected Steps per Second: 21,970.85124
Overall Steps per Second: 10,663.00711

Timestep Collection Time: 2.27665
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.69098

Cumulative Model Updates: 157,256
Cumulative Timesteps: 1,311,293,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,606.19479
Policy Entropy: 3.77509
Value Function Loss: 0.02494

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12537
Policy Update Magnitude: 0.49281
Value Function Update Magnitude: 0.50828

Collected Steps per Second: 22,252.92737
Overall Steps per Second: 10,546.61341

Timestep Collection Time: 2.24761
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.74238

Cumulative Model Updates: 157,262
Cumulative Timesteps: 1,311,343,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1311343596...
Checkpoint 1311343596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,512.60023
Policy Entropy: 3.79222
Value Function Loss: 0.02347

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.52371
Value Function Update Magnitude: 0.69649

Collected Steps per Second: 22,197.90020
Overall Steps per Second: 10,618.06395

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.45669
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.70933

Cumulative Model Updates: 157,268
Cumulative Timesteps: 1,311,393,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,247.17488
Policy Entropy: 3.77999
Value Function Loss: 0.02315

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.58971
Value Function Update Magnitude: 0.69673

Collected Steps per Second: 22,306.78377
Overall Steps per Second: 10,506.68444

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.51740
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.75888

Cumulative Model Updates: 157,274
Cumulative Timesteps: 1,311,443,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1311443600...
Checkpoint 1311443600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.99795
Policy Entropy: 3.80791
Value Function Loss: 0.02065

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.59135
Value Function Update Magnitude: 0.58966

Collected Steps per Second: 22,417.85971
Overall Steps per Second: 10,681.13243

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.68284

Cumulative Model Updates: 157,280
Cumulative Timesteps: 1,311,493,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.59868
Policy Entropy: 3.80372
Value Function Loss: 0.01708

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08805
Policy Update Magnitude: 0.63629
Value Function Update Magnitude: 0.66097

Collected Steps per Second: 22,886.63899
Overall Steps per Second: 10,809.15489

Timestep Collection Time: 2.18582
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62811

Cumulative Model Updates: 157,286
Cumulative Timesteps: 1,311,543,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1311543644...
Checkpoint 1311543644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.59868
Policy Entropy: 3.79409
Value Function Loss: 0.01344

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08442
Policy Update Magnitude: 0.58666
Value Function Update Magnitude: 0.65121

Collected Steps per Second: 22,725.86507
Overall Steps per Second: 10,671.65974

Timestep Collection Time: 2.20225
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.68980

Cumulative Model Updates: 157,292
Cumulative Timesteps: 1,311,593,692

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.59868
Policy Entropy: 3.76868
Value Function Loss: 0.01128

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08228
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.51172

Collected Steps per Second: 22,818.61075
Overall Steps per Second: 10,619.25131

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.51814
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.71012

Cumulative Model Updates: 157,298
Cumulative Timesteps: 1,311,643,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1311643710...
Checkpoint 1311643710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,289.59868
Policy Entropy: 3.76735
Value Function Loss: 0.00943

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.47563
Value Function Update Magnitude: 0.38375

Collected Steps per Second: 22,534.39420
Overall Steps per Second: 10,724.79181

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.66508

Cumulative Model Updates: 157,304
Cumulative Timesteps: 1,311,693,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,394.61383
Policy Entropy: 3.76469
Value Function Loss: 0.01032

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14556
Policy Update Magnitude: 0.42469
Value Function Update Magnitude: 0.34950

Collected Steps per Second: 21,875.06218
Overall Steps per Second: 10,678.62329

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.39760
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.68431

Cumulative Model Updates: 157,310
Cumulative Timesteps: 1,311,743,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1311743764...
Checkpoint 1311743764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,545.05780
Policy Entropy: 3.75482
Value Function Loss: 0.01199

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.42962
Value Function Update Magnitude: 0.45469

Collected Steps per Second: 21,509.17278
Overall Steps per Second: 10,645.38690

Timestep Collection Time: 2.32589
Timestep Consumption Time: 2.37361
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.69950

Cumulative Model Updates: 157,316
Cumulative Timesteps: 1,311,793,792

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,891.36934
Policy Entropy: 3.74469
Value Function Loss: 0.01367

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16998
Policy Update Magnitude: 0.42362
Value Function Update Magnitude: 0.52706

Collected Steps per Second: 21,340.83531
Overall Steps per Second: 10,430.78961

Timestep Collection Time: 2.34349
Timestep Consumption Time: 2.45116
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.79465

Cumulative Model Updates: 157,322
Cumulative Timesteps: 1,311,843,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1311843804...
Checkpoint 1311843804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,265.16235
Policy Entropy: 3.75764
Value Function Loss: 0.01614

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14641
Policy Update Magnitude: 0.44512
Value Function Update Magnitude: 0.59392

Collected Steps per Second: 21,676.42773
Overall Steps per Second: 10,620.16582

Timestep Collection Time: 2.30702
Timestep Consumption Time: 2.40176
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.70878

Cumulative Model Updates: 157,328
Cumulative Timesteps: 1,311,893,812

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,670.53081
Policy Entropy: 3.75052
Value Function Loss: 0.01912

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.49792
Value Function Update Magnitude: 0.56617

Collected Steps per Second: 22,264.52271
Overall Steps per Second: 10,613.67394

Timestep Collection Time: 2.24599
Timestep Consumption Time: 2.46547
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.71147

Cumulative Model Updates: 157,334
Cumulative Timesteps: 1,311,943,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1311943818...
Checkpoint 1311943818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,651.27254
Policy Entropy: 3.74890
Value Function Loss: 0.02071

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.50417
Value Function Update Magnitude: 0.50138

Collected Steps per Second: 22,655.42588
Overall Steps per Second: 10,489.02593

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.56104
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.76898

Cumulative Model Updates: 157,340
Cumulative Timesteps: 1,311,993,840

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,528.63314
Policy Entropy: 3.74160
Value Function Loss: 0.02283

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.51040
Value Function Update Magnitude: 0.47746

Collected Steps per Second: 22,551.88105
Overall Steps per Second: 10,623.11402

Timestep Collection Time: 2.21800
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.70860

Cumulative Model Updates: 157,346
Cumulative Timesteps: 1,312,043,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1312043860...
Checkpoint 1312043860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,446.03128
Policy Entropy: 3.75340
Value Function Loss: 0.01993

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.60969

Collected Steps per Second: 22,248.69902
Overall Steps per Second: 10,546.97377

Timestep Collection Time: 2.24750
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74108

Cumulative Model Updates: 157,352
Cumulative Timesteps: 1,312,093,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,648.41637
Policy Entropy: 3.74255
Value Function Loss: 0.02107

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.66950

Collected Steps per Second: 22,790.09481
Overall Steps per Second: 10,815.11968

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.62353

Cumulative Model Updates: 157,358
Cumulative Timesteps: 1,312,143,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1312143868...
Checkpoint 1312143868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,113.32050
Policy Entropy: 3.75489
Value Function Loss: 0.02429

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11610
Policy Update Magnitude: 0.62155
Value Function Update Magnitude: 0.71030

Collected Steps per Second: 22,406.86600
Overall Steps per Second: 10,679.51186

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.68355

Cumulative Model Updates: 157,364
Cumulative Timesteps: 1,312,193,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,514.81991
Policy Entropy: 3.75437
Value Function Loss: 0.02807

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.66190
Value Function Update Magnitude: 0.67823

Collected Steps per Second: 22,710.03582
Overall Steps per Second: 10,836.44051

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.41297
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.61517

Cumulative Model Updates: 157,370
Cumulative Timesteps: 1,312,243,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1312243898...
Checkpoint 1312243898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,568.46870
Policy Entropy: 3.78848
Value Function Loss: 0.02549

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.67588
Value Function Update Magnitude: 0.72458

Collected Steps per Second: 21,825.72690
Overall Steps per Second: 10,641.18013

Timestep Collection Time: 2.29207
Timestep Consumption Time: 2.40910
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.70117

Cumulative Model Updates: 157,376
Cumulative Timesteps: 1,312,293,924

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,755.92234
Policy Entropy: 3.79783
Value Function Loss: 0.02489

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.62866
Value Function Update Magnitude: 0.78425

Collected Steps per Second: 21,829.61114
Overall Steps per Second: 10,631.44832

Timestep Collection Time: 2.29184
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70585

Cumulative Model Updates: 157,382
Cumulative Timesteps: 1,312,343,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1312343954...
Checkpoint 1312343954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,649.50856
Policy Entropy: 3.80702
Value Function Loss: 0.02300

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12489
Policy Update Magnitude: 0.59080
Value Function Update Magnitude: 0.66579

Collected Steps per Second: 21,482.64692
Overall Steps per Second: 10,546.55558

Timestep Collection Time: 2.32951
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.74506

Cumulative Model Updates: 157,388
Cumulative Timesteps: 1,312,393,998

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,111.77705
Policy Entropy: 3.78176
Value Function Loss: 0.02305

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.54828
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 21,854.51276
Overall Steps per Second: 10,667.11722

Timestep Collection Time: 2.28914
Timestep Consumption Time: 2.40079
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68993

Cumulative Model Updates: 157,394
Cumulative Timesteps: 1,312,444,026

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1312444026...
Checkpoint 1312444026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,857.60193
Policy Entropy: 3.78169
Value Function Loss: 0.02264

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12281
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.55376

Collected Steps per Second: 21,496.19278
Overall Steps per Second: 10,585.63632

Timestep Collection Time: 2.32674
Timestep Consumption Time: 2.39816
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.72489

Cumulative Model Updates: 157,400
Cumulative Timesteps: 1,312,494,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,432.55902
Policy Entropy: 3.77783
Value Function Loss: 0.02519

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.56923
Value Function Update Magnitude: 0.59015

Collected Steps per Second: 22,362.66112
Overall Steps per Second: 10,710.65087

Timestep Collection Time: 2.23623
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.66900

Cumulative Model Updates: 157,406
Cumulative Timesteps: 1,312,544,050

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1312544050...
Checkpoint 1312544050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,702.84067
Policy Entropy: 3.77104
Value Function Loss: 0.02517

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.58317
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,538.91425
Overall Steps per Second: 10,580.48258

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.72795

Cumulative Model Updates: 157,412
Cumulative Timesteps: 1,312,594,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,067.00387
Policy Entropy: 3.75803
Value Function Loss: 0.02476

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.59785
Value Function Update Magnitude: 0.57920

Collected Steps per Second: 22,751.20922
Overall Steps per Second: 10,744.99976

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.45584
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.65370

Cumulative Model Updates: 157,418
Cumulative Timesteps: 1,312,644,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1312644078...
Checkpoint 1312644078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189,806.29585
Policy Entropy: 3.77268
Value Function Loss: 0.02465

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.60127
Value Function Update Magnitude: 0.59666

Collected Steps per Second: 22,769.97720
Overall Steps per Second: 10,831.78716

Timestep Collection Time: 2.19623
Timestep Consumption Time: 2.42056
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.61678

Cumulative Model Updates: 157,424
Cumulative Timesteps: 1,312,694,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,067.36801
Policy Entropy: 3.79991
Value Function Loss: 0.02369

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12369
Policy Update Magnitude: 0.60395
Value Function Update Magnitude: 0.63295

Collected Steps per Second: 22,893.55007
Overall Steps per Second: 10,866.78802

Timestep Collection Time: 2.18437
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.60191

Cumulative Model Updates: 157,430
Cumulative Timesteps: 1,312,744,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1312744094...
Checkpoint 1312744094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,400.65382
Policy Entropy: 3.79900
Value Function Loss: 0.02282

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.55610
Value Function Update Magnitude: 0.74914

Collected Steps per Second: 22,944.55277
Overall Steps per Second: 10,752.25583

Timestep Collection Time: 2.18065
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.65335

Cumulative Model Updates: 157,436
Cumulative Timesteps: 1,312,794,128

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,210.84459
Policy Entropy: 3.78909
Value Function Loss: 0.01935

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12610
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.74596

Collected Steps per Second: 22,518.72289
Overall Steps per Second: 10,606.80595

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.71414

Cumulative Model Updates: 157,442
Cumulative Timesteps: 1,312,844,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1312844130...
Checkpoint 1312844130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.12013
Policy Entropy: 3.77759
Value Function Loss: 0.01813

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.68478

Collected Steps per Second: 22,237.89973
Overall Steps per Second: 10,558.06034

Timestep Collection Time: 2.24922
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.73742

Cumulative Model Updates: 157,448
Cumulative Timesteps: 1,312,894,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,403.65144
Policy Entropy: 3.77261
Value Function Loss: 0.01920

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12449
Policy Update Magnitude: 0.45644
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 22,511.92612
Overall Steps per Second: 10,741.20824

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.43402
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.65516

Cumulative Model Updates: 157,454
Cumulative Timesteps: 1,312,944,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1312944150...
Checkpoint 1312944150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,775.81931
Policy Entropy: 3.77643
Value Function Loss: 0.02102

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.50391
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 21,982.38077
Overall Steps per Second: 10,636.03828

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.42645
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.70100

Cumulative Model Updates: 157,460
Cumulative Timesteps: 1,312,994,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,475.09313
Policy Entropy: 3.78702
Value Function Loss: 0.02460

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.55986

Collected Steps per Second: 22,512.67142
Overall Steps per Second: 10,541.23534

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.52301
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.74461

Cumulative Model Updates: 157,466
Cumulative Timesteps: 1,313,044,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1313044164...
Checkpoint 1313044164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.46374
Policy Entropy: 3.81561
Value Function Loss: 0.02248

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.50059
Value Function Update Magnitude: 0.54031

Collected Steps per Second: 22,633.92751
Overall Steps per Second: 10,666.16837

Timestep Collection Time: 2.21022
Timestep Consumption Time: 2.47993
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.69016

Cumulative Model Updates: 157,472
Cumulative Timesteps: 1,313,094,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,542.06859
Policy Entropy: 3.80761
Value Function Loss: 0.02327

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11785
Policy Update Magnitude: 0.49858
Value Function Update Magnitude: 0.54791

Collected Steps per Second: 22,784.33567
Overall Steps per Second: 10,806.35428

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.62728

Cumulative Model Updates: 157,478
Cumulative Timesteps: 1,313,144,194

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1313144194...
Checkpoint 1313144194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.87747
Policy Entropy: 3.80188
Value Function Loss: 0.01907

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11753
Policy Update Magnitude: 0.53179
Value Function Update Magnitude: 0.68056

Collected Steps per Second: 22,600.01755
Overall Steps per Second: 10,700.37080

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.67535

Cumulative Model Updates: 157,484
Cumulative Timesteps: 1,313,194,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392.43316
Policy Entropy: 3.78874
Value Function Loss: 0.01837

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.51496
Value Function Update Magnitude: 0.69554

Collected Steps per Second: 22,696.91918
Overall Steps per Second: 10,695.81003

Timestep Collection Time: 2.20418
Timestep Consumption Time: 2.47317
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.67735

Cumulative Model Updates: 157,490
Cumulative Timesteps: 1,313,244,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1313244250...
Checkpoint 1313244250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,852.23763
Policy Entropy: 3.78545
Value Function Loss: 0.01731

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12430
Policy Update Magnitude: 0.46070
Value Function Update Magnitude: 0.57469

Collected Steps per Second: 22,471.42938
Overall Steps per Second: 10,801.52687

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.40393
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.62898

Cumulative Model Updates: 157,496
Cumulative Timesteps: 1,313,294,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,624.76559
Policy Entropy: 3.79609
Value Function Loss: 0.01768

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.44299
Value Function Update Magnitude: 0.63963

Collected Steps per Second: 22,791.23550
Overall Steps per Second: 10,727.88620

Timestep Collection Time: 2.19584
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.66504

Cumulative Model Updates: 157,502
Cumulative Timesteps: 1,313,344,296

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1313344296...
Checkpoint 1313344296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,142.65471
Policy Entropy: 3.78820
Value Function Loss: 0.01765

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.45388
Value Function Update Magnitude: 0.71566

Collected Steps per Second: 22,783.91775
Overall Steps per Second: 10,846.47651

Timestep Collection Time: 2.19497
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61071

Cumulative Model Updates: 157,508
Cumulative Timesteps: 1,313,394,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,386.50326
Policy Entropy: 3.78291
Value Function Loss: 0.01913

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.73424

Collected Steps per Second: 21,829.87202
Overall Steps per Second: 10,659.24054

Timestep Collection Time: 2.29071
Timestep Consumption Time: 2.40061
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.69133

Cumulative Model Updates: 157,514
Cumulative Timesteps: 1,313,444,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1313444312...
Checkpoint 1313444312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,615.64474
Policy Entropy: 3.77575
Value Function Loss: 0.01893

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.51148
Value Function Update Magnitude: 0.63531

Collected Steps per Second: 21,600.06000
Overall Steps per Second: 10,610.24589

Timestep Collection Time: 2.31583
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.71450

Cumulative Model Updates: 157,520
Cumulative Timesteps: 1,313,494,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,270.98786
Policy Entropy: 3.79662
Value Function Loss: 0.02040

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.51639
Value Function Update Magnitude: 0.51607

Collected Steps per Second: 21,829.20385
Overall Steps per Second: 10,725.08123

Timestep Collection Time: 2.29161
Timestep Consumption Time: 2.37260
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.66421

Cumulative Model Updates: 157,526
Cumulative Timesteps: 1,313,544,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1313544358...
Checkpoint 1313544358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,006.19499
Policy Entropy: 3.79175
Value Function Loss: 0.02048

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.52845
Value Function Update Magnitude: 0.64641

Collected Steps per Second: 21,673.10438
Overall Steps per Second: 10,646.54641

Timestep Collection Time: 2.30765
Timestep Consumption Time: 2.39002
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.69767

Cumulative Model Updates: 157,532
Cumulative Timesteps: 1,313,594,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,865.67550
Policy Entropy: 3.80007
Value Function Loss: 0.02276

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,265.00026
Overall Steps per Second: 10,590.95581

Timestep Collection Time: 2.24586
Timestep Consumption Time: 2.47553
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.72139

Cumulative Model Updates: 157,538
Cumulative Timesteps: 1,313,644,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1313644376...
Checkpoint 1313644376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,851.40813
Policy Entropy: 3.79718
Value Function Loss: 0.02030

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.59076

Collected Steps per Second: 22,807.15801
Overall Steps per Second: 10,906.18916

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.39331
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.58657

Cumulative Model Updates: 157,544
Cumulative Timesteps: 1,313,694,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,981.69399
Policy Entropy: 3.78620
Value Function Loss: 0.01955

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.50669
Value Function Update Magnitude: 0.60989

Collected Steps per Second: 22,503.63841
Overall Steps per Second: 10,728.23866

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.44000
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.66302

Cumulative Model Updates: 157,550
Cumulative Timesteps: 1,313,744,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1313744424...
Checkpoint 1313744424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,468.84659
Policy Entropy: 3.77088
Value Function Loss: 0.01813

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.64900

Collected Steps per Second: 22,608.88451
Overall Steps per Second: 10,815.81699

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.41279
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.62563

Cumulative Model Updates: 157,556
Cumulative Timesteps: 1,313,794,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,624.14037
Policy Entropy: 3.74793
Value Function Loss: 0.01905

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.49962
Value Function Update Magnitude: 0.48238

Collected Steps per Second: 22,724.55100
Overall Steps per Second: 10,669.60473

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.68808

Cumulative Model Updates: 157,562
Cumulative Timesteps: 1,313,844,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1313844474...
Checkpoint 1313844474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,624.14037
Policy Entropy: 3.75203
Value Function Loss: 0.01836

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.49616
Value Function Update Magnitude: 0.49593

Collected Steps per Second: 22,207.67449
Overall Steps per Second: 10,529.70440

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.74904

Cumulative Model Updates: 157,568
Cumulative Timesteps: 1,313,894,480

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,748.08522
Policy Entropy: 3.76580
Value Function Loss: 0.02074

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.51594
Value Function Update Magnitude: 0.58096

Collected Steps per Second: 22,290.71433
Overall Steps per Second: 10,588.20383

Timestep Collection Time: 2.24354
Timestep Consumption Time: 2.47965
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.72318

Cumulative Model Updates: 157,574
Cumulative Timesteps: 1,313,944,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1313944490...
Checkpoint 1313944490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,972.70528
Policy Entropy: 3.76251
Value Function Loss: 0.02141

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.51117
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 21,922.34283
Overall Steps per Second: 10,480.10548

Timestep Collection Time: 2.28187
Timestep Consumption Time: 2.49136
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.77323

Cumulative Model Updates: 157,580
Cumulative Timesteps: 1,313,994,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,539.65739
Policy Entropy: 3.76554
Value Function Loss: 0.02090

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.49464
Value Function Update Magnitude: 0.60395

Collected Steps per Second: 22,197.98288
Overall Steps per Second: 10,558.58606

Timestep Collection Time: 2.25318
Timestep Consumption Time: 2.48382
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.73700

Cumulative Model Updates: 157,586
Cumulative Timesteps: 1,314,044,530

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1314044530...
Checkpoint 1314044530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,053.31742
Policy Entropy: 3.75520
Value Function Loss: 0.01780

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.50666
Value Function Update Magnitude: 0.58190

Collected Steps per Second: 22,247.19438
Overall Steps per Second: 10,541.62838

Timestep Collection Time: 2.24810
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.74443

Cumulative Model Updates: 157,592
Cumulative Timesteps: 1,314,094,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,130.54451
Policy Entropy: 3.76248
Value Function Loss: 0.01663

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.47783
Value Function Update Magnitude: 0.60522

Collected Steps per Second: 22,605.92448
Overall Steps per Second: 10,551.53679

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.52744
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.73978

Cumulative Model Updates: 157,598
Cumulative Timesteps: 1,314,144,556

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1314144556...
Checkpoint 1314144556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,385.04860
Policy Entropy: 3.76503
Value Function Loss: 0.01832

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.49849
Value Function Update Magnitude: 0.54332

Collected Steps per Second: 22,609.08885
Overall Steps per Second: 10,658.49104

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.69297

Cumulative Model Updates: 157,604
Cumulative Timesteps: 1,314,194,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,923.77505
Policy Entropy: 3.77348
Value Function Loss: 0.02013

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12531
Policy Update Magnitude: 0.52162
Value Function Update Magnitude: 0.46393

Collected Steps per Second: 22,125.38502
Overall Steps per Second: 10,823.68208

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.36088
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.62190

Cumulative Model Updates: 157,610
Cumulative Timesteps: 1,314,244,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1314244602...
Checkpoint 1314244602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,325.03433
Policy Entropy: 3.78598
Value Function Loss: 0.02204

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.54139
Value Function Update Magnitude: 0.55316

Collected Steps per Second: 22,131.82341
Overall Steps per Second: 10,715.52027

Timestep Collection Time: 2.25937
Timestep Consumption Time: 2.40713
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.66650

Cumulative Model Updates: 157,616
Cumulative Timesteps: 1,314,294,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,586.67457
Policy Entropy: 3.79868
Value Function Loss: 0.02213

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13545
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.54296

Collected Steps per Second: 22,151.98953
Overall Steps per Second: 10,832.27926

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.36002
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.61842

Cumulative Model Updates: 157,622
Cumulative Timesteps: 1,314,344,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1314344634...
Checkpoint 1314344634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,227.53008
Policy Entropy: 3.79909
Value Function Loss: 0.02042

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.60442

Collected Steps per Second: 22,072.68220
Overall Steps per Second: 10,695.67935

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.41147
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.67852

Cumulative Model Updates: 157,628
Cumulative Timesteps: 1,314,394,674

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,721.66286
Policy Entropy: 3.78455
Value Function Loss: 0.01762

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.59300
Value Function Update Magnitude: 0.73578

Collected Steps per Second: 21,661.78749
Overall Steps per Second: 10,472.65369

Timestep Collection Time: 2.30821
Timestep Consumption Time: 2.46613
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.77434

Cumulative Model Updates: 157,634
Cumulative Timesteps: 1,314,444,674

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1314444674...
Checkpoint 1314444674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,761.03656
Policy Entropy: 3.77079
Value Function Loss: 0.01863

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.59812
Value Function Update Magnitude: 0.74195

Collected Steps per Second: 21,991.21205
Overall Steps per Second: 10,554.71758

Timestep Collection Time: 2.27427
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.73854

Cumulative Model Updates: 157,640
Cumulative Timesteps: 1,314,494,688

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,455.78512
Policy Entropy: 3.76056
Value Function Loss: 0.02056

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.59007
Value Function Update Magnitude: 0.68286

Collected Steps per Second: 22,492.71991
Overall Steps per Second: 10,810.48437

Timestep Collection Time: 2.22356
Timestep Consumption Time: 2.40287
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.62643

Cumulative Model Updates: 157,646
Cumulative Timesteps: 1,314,544,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1314544702...
Checkpoint 1314544702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,893.42648
Policy Entropy: 3.76461
Value Function Loss: 0.01978

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13982
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.66186

Collected Steps per Second: 22,448.16379
Overall Steps per Second: 10,660.31378

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.46412
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.69254

Cumulative Model Updates: 157,652
Cumulative Timesteps: 1,314,594,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,700.12944
Policy Entropy: 3.78400
Value Function Loss: 0.02063

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 22,889.40445
Overall Steps per Second: 10,728.19656

Timestep Collection Time: 2.18485
Timestep Consumption Time: 2.47669
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.66155

Cumulative Model Updates: 157,658
Cumulative Timesteps: 1,314,644,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1314644736...
Checkpoint 1314644736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,725.97360
Policy Entropy: 3.80200
Value Function Loss: 0.01873

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.52136
Value Function Update Magnitude: 0.64256

Collected Steps per Second: 22,543.08905
Overall Steps per Second: 10,799.37950

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.41269
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.63138

Cumulative Model Updates: 157,664
Cumulative Timesteps: 1,314,694,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.72133
Policy Entropy: 3.82029
Value Function Loss: 0.01882

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.47940
Value Function Update Magnitude: 0.73802

Collected Steps per Second: 22,862.87360
Overall Steps per Second: 10,732.17039

Timestep Collection Time: 2.18730
Timestep Consumption Time: 2.47233
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.65964

Cumulative Model Updates: 157,670
Cumulative Timesteps: 1,314,744,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1314744760...
Checkpoint 1314744760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,219.45773
Policy Entropy: 3.81993
Value Function Loss: 0.01999

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.49256
Value Function Update Magnitude: 0.81369

Collected Steps per Second: 22,941.90969
Overall Steps per Second: 10,853.93782

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.42730
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.60681

Cumulative Model Updates: 157,676
Cumulative Timesteps: 1,314,794,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,176.94745
Policy Entropy: 3.82216
Value Function Loss: 0.01928

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.81866

Collected Steps per Second: 22,765.36289
Overall Steps per Second: 10,692.84669

Timestep Collection Time: 2.19658
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.67658

Cumulative Model Updates: 157,682
Cumulative Timesteps: 1,314,844,768

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1314844768...
Checkpoint 1314844768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,146.76286
Policy Entropy: 3.80209
Value Function Loss: 0.01935

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12985
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.79440

Collected Steps per Second: 21,882.50628
Overall Steps per Second: 10,462.81833

Timestep Collection Time: 2.28575
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.78055

Cumulative Model Updates: 157,688
Cumulative Timesteps: 1,314,894,786

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,104.72694
Policy Entropy: 3.80043
Value Function Loss: 0.01708

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12539
Policy Update Magnitude: 0.50677
Value Function Update Magnitude: 0.78270

Collected Steps per Second: 21,952.79329
Overall Steps per Second: 10,455.95565

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.50465
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.78254

Cumulative Model Updates: 157,694
Cumulative Timesteps: 1,314,944,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1314944792...
Checkpoint 1314944792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.96584
Policy Entropy: 3.78539
Value Function Loss: 0.01586

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.46121
Value Function Update Magnitude: 0.67473

Collected Steps per Second: 21,858.83964
Overall Steps per Second: 10,637.83808

Timestep Collection Time: 2.28804
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.70152

Cumulative Model Updates: 157,700
Cumulative Timesteps: 1,314,994,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,481.77089
Policy Entropy: 3.78550
Value Function Loss: 0.01553

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.41159
Value Function Update Magnitude: 0.64619

Collected Steps per Second: 22,275.40452
Overall Steps per Second: 10,553.48270

Timestep Collection Time: 2.24553
Timestep Consumption Time: 2.49414
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.73967

Cumulative Model Updates: 157,706
Cumulative Timesteps: 1,315,044,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1315044826...
Checkpoint 1315044826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,994.17682
Policy Entropy: 3.77677
Value Function Loss: 0.01495

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.40859
Value Function Update Magnitude: 0.70961

Collected Steps per Second: 22,599.48970
Overall Steps per Second: 10,575.20625

Timestep Collection Time: 2.21377
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.73088

Cumulative Model Updates: 157,712
Cumulative Timesteps: 1,315,094,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,843.55526
Policy Entropy: 3.77124
Value Function Loss: 0.01807

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12544
Policy Update Magnitude: 0.43261
Value Function Update Magnitude: 0.71893

Collected Steps per Second: 22,667.63862
Overall Steps per Second: 10,760.96568

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.64661

Cumulative Model Updates: 157,718
Cumulative Timesteps: 1,315,144,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1315144858...
Checkpoint 1315144858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,508.58646
Policy Entropy: 3.77875
Value Function Loss: 0.01866

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.46987
Value Function Update Magnitude: 0.65110

Collected Steps per Second: 22,431.66476
Overall Steps per Second: 10,759.51154

Timestep Collection Time: 2.22953
Timestep Consumption Time: 2.41864
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.64817

Cumulative Model Updates: 157,724
Cumulative Timesteps: 1,315,194,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,801.62631
Policy Entropy: 3.78193
Value Function Loss: 0.02349

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.47757
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 22,738.02455
Overall Steps per Second: 10,812.15285

Timestep Collection Time: 2.19984
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.62628

Cumulative Model Updates: 157,730
Cumulative Timesteps: 1,315,244,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1315244890...
Checkpoint 1315244890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,944.18069
Policy Entropy: 3.80103
Value Function Loss: 0.02313

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11539
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 22,662.57019
Overall Steps per Second: 10,735.09358

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.45232
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.65948

Cumulative Model Updates: 157,736
Cumulative Timesteps: 1,315,294,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,979.21431
Policy Entropy: 3.79645
Value Function Loss: 0.02496

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12055
Policy Update Magnitude: 0.49159
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,500.28261
Overall Steps per Second: 10,636.34262

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.70256

Cumulative Model Updates: 157,742
Cumulative Timesteps: 1,315,344,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1315344928...
Checkpoint 1315344928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,770.86680
Policy Entropy: 3.79624
Value Function Loss: 0.02068

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.51307
Value Function Update Magnitude: 0.61727

Collected Steps per Second: 21,684.35194
Overall Steps per Second: 10,433.65423

Timestep Collection Time: 2.30636
Timestep Consumption Time: 2.48697
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.79334

Cumulative Model Updates: 157,748
Cumulative Timesteps: 1,315,394,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,934.99292
Policy Entropy: 3.78377
Value Function Loss: 0.01890

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.51186
Value Function Update Magnitude: 0.61471

Collected Steps per Second: 22,149.33267
Overall Steps per Second: 10,527.32142

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.49354
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.75221

Cumulative Model Updates: 157,754
Cumulative Timesteps: 1,315,444,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1315444968...
Checkpoint 1315444968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85,606.86078
Policy Entropy: 3.79587
Value Function Loss: 0.01736

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.49489
Value Function Update Magnitude: 0.69552

Collected Steps per Second: 21,545.22947
Overall Steps per Second: 10,577.59309

Timestep Collection Time: 2.32153
Timestep Consumption Time: 2.40714
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.72868

Cumulative Model Updates: 157,760
Cumulative Timesteps: 1,315,494,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,494.53617
Policy Entropy: 3.79365
Value Function Loss: 0.01948

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.82874

Collected Steps per Second: 22,220.22304
Overall Steps per Second: 10,526.21699

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.75156

Cumulative Model Updates: 157,766
Cumulative Timesteps: 1,315,545,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1315545002...
Checkpoint 1315545002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,850.37920
Policy Entropy: 3.77632
Value Function Loss: 0.01907

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.80133

Collected Steps per Second: 21,589.80924
Overall Steps per Second: 10,578.11482

Timestep Collection Time: 2.31757
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.73014

Cumulative Model Updates: 157,772
Cumulative Timesteps: 1,315,595,038

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,576.10999
Policy Entropy: 3.75514
Value Function Loss: 0.01919

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.81070

Collected Steps per Second: 21,969.35262
Overall Steps per Second: 10,641.17052

Timestep Collection Time: 2.27681
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.70061

Cumulative Model Updates: 157,778
Cumulative Timesteps: 1,315,645,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1315645058...
Checkpoint 1315645058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,324.02856
Policy Entropy: 3.76364
Value Function Loss: 0.01844

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.53523
Value Function Update Magnitude: 0.76986

Collected Steps per Second: 22,136.84911
Overall Steps per Second: 10,827.00735

Timestep Collection Time: 2.25913
Timestep Consumption Time: 2.35988
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.61900

Cumulative Model Updates: 157,784
Cumulative Timesteps: 1,315,695,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,512.69976
Policy Entropy: 3.78940
Value Function Loss: 0.01969

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.51900
Value Function Update Magnitude: 0.73149

Collected Steps per Second: 21,966.54938
Overall Steps per Second: 10,667.07496

Timestep Collection Time: 2.27719
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.68938

Cumulative Model Updates: 157,790
Cumulative Timesteps: 1,315,745,090

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1315745090...
Checkpoint 1315745090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.23037
Policy Entropy: 3.81465
Value Function Loss: 0.01998

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.50542
Value Function Update Magnitude: 0.71803

Collected Steps per Second: 21,901.80002
Overall Steps per Second: 10,677.97541

Timestep Collection Time: 2.28301
Timestep Consumption Time: 2.39971
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68272

Cumulative Model Updates: 157,796
Cumulative Timesteps: 1,315,795,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,368.86628
Policy Entropy: 3.81294
Value Function Loss: 0.01986

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.50366
Value Function Update Magnitude: 0.70907

Collected Steps per Second: 22,446.51483
Overall Steps per Second: 10,750.90056

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.65208

Cumulative Model Updates: 157,802
Cumulative Timesteps: 1,315,845,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1315845106...
Checkpoint 1315845106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,284.93414
Policy Entropy: 3.77984
Value Function Loss: 0.01981

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.49527
Value Function Update Magnitude: 0.68707

Collected Steps per Second: 22,556.11773
Overall Steps per Second: 10,686.19624

Timestep Collection Time: 2.21785
Timestep Consumption Time: 2.46352
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.68137

Cumulative Model Updates: 157,808
Cumulative Timesteps: 1,315,895,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,565.71359
Policy Entropy: 3.76985
Value Function Loss: 0.01803

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.45323
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 22,264.29382
Overall Steps per Second: 10,764.91944

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.39897
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.64472

Cumulative Model Updates: 157,814
Cumulative Timesteps: 1,315,945,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1315945132...
Checkpoint 1315945132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,436.63368
Policy Entropy: 3.77593
Value Function Loss: 0.01657

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12951
Policy Update Magnitude: 0.39091
Value Function Update Magnitude: 0.54888

Collected Steps per Second: 22,199.97214
Overall Steps per Second: 10,680.13243

Timestep Collection Time: 2.25298
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.68309

Cumulative Model Updates: 157,820
Cumulative Timesteps: 1,315,995,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,262.84293
Policy Entropy: 3.80391
Value Function Loss: 0.01559

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.37278
Value Function Update Magnitude: 0.52550

Collected Steps per Second: 22,586.40844
Overall Steps per Second: 10,633.05639

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.70307

Cumulative Model Updates: 157,826
Cumulative Timesteps: 1,316,045,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1316045156...
Checkpoint 1316045156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.96177
Policy Entropy: 3.81660
Value Function Loss: 0.01699

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.40508
Value Function Update Magnitude: 0.57763

Collected Steps per Second: 22,567.83729
Overall Steps per Second: 10,568.95995

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.51630
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.73273

Cumulative Model Updates: 157,832
Cumulative Timesteps: 1,316,095,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,800.51320
Policy Entropy: 3.82192
Value Function Loss: 0.01864

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.43328
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 22,756.88327
Overall Steps per Second: 10,763.25360

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.44849
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.64581

Cumulative Model Updates: 157,838
Cumulative Timesteps: 1,316,145,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1316145180...
Checkpoint 1316145180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,667.47231
Policy Entropy: 3.80566
Value Function Loss: 0.01747

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.46450
Value Function Update Magnitude: 0.71191

Collected Steps per Second: 22,981.35427
Overall Steps per Second: 10,691.18123

Timestep Collection Time: 2.17655
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.67862

Cumulative Model Updates: 157,844
Cumulative Timesteps: 1,316,195,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,459.32196
Policy Entropy: 3.78775
Value Function Loss: 0.01783

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.43265
Value Function Update Magnitude: 0.60501

Collected Steps per Second: 22,910.82572
Overall Steps per Second: 10,857.22866

Timestep Collection Time: 2.18272
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.60596

Cumulative Model Updates: 157,850
Cumulative Timesteps: 1,316,245,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1316245208...
Checkpoint 1316245208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,874.44343
Policy Entropy: 3.77195
Value Function Loss: 0.01571

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13580
Policy Update Magnitude: 0.41067
Value Function Update Magnitude: 0.46020

Collected Steps per Second: 22,715.00294
Overall Steps per Second: 10,695.25373

Timestep Collection Time: 2.20145
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.67553

Cumulative Model Updates: 157,856
Cumulative Timesteps: 1,316,295,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,964.69544
Policy Entropy: 3.75936
Value Function Loss: 0.01791

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.42629
Value Function Update Magnitude: 0.43074

Collected Steps per Second: 22,660.61133
Overall Steps per Second: 10,806.15423

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.42101
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62792

Cumulative Model Updates: 157,862
Cumulative Timesteps: 1,316,345,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1316345224...
Checkpoint 1316345224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,938.29627
Policy Entropy: 3.76813
Value Function Loss: 0.01758

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.49917
Value Function Update Magnitude: 0.56111

Collected Steps per Second: 22,423.84045
Overall Steps per Second: 10,744.28222

Timestep Collection Time: 2.22977
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.65364

Cumulative Model Updates: 157,868
Cumulative Timesteps: 1,316,395,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,204.58670
Policy Entropy: 3.77869
Value Function Loss: 0.01923

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13238
Policy Update Magnitude: 0.53487
Value Function Update Magnitude: 0.71856

Collected Steps per Second: 22,174.34364
Overall Steps per Second: 10,516.38817

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.50093
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75696

Cumulative Model Updates: 157,874
Cumulative Timesteps: 1,316,445,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1316445250...
Checkpoint 1316445250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.37106
Policy Entropy: 3.79935
Value Function Loss: 0.01731

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.78760

Collected Steps per Second: 22,335.48613
Overall Steps per Second: 10,622.02459

Timestep Collection Time: 2.24047
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.71115

Cumulative Model Updates: 157,880
Cumulative Timesteps: 1,316,495,292

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,711.66794
Policy Entropy: 3.82392
Value Function Loss: 0.01857

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12279
Policy Update Magnitude: 0.51328
Value Function Update Magnitude: 0.81402

Collected Steps per Second: 22,143.16822
Overall Steps per Second: 10,532.84529

Timestep Collection Time: 2.25848
Timestep Consumption Time: 2.48952
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.74800

Cumulative Model Updates: 157,886
Cumulative Timesteps: 1,316,545,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1316545302...
Checkpoint 1316545302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,920.89983
Policy Entropy: 3.84519
Value Function Loss: 0.01921

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.50076
Value Function Update Magnitude: 0.78159

Collected Steps per Second: 22,431.47318
Overall Steps per Second: 10,577.82971

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.72725

Cumulative Model Updates: 157,892
Cumulative Timesteps: 1,316,595,306

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,454.00835
Policy Entropy: 3.84874
Value Function Loss: 0.02237

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.50282
Value Function Update Magnitude: 0.79643

Collected Steps per Second: 22,453.30805
Overall Steps per Second: 10,482.88393

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.54385
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.77159

Cumulative Model Updates: 157,898
Cumulative Timesteps: 1,316,645,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1316645326...
Checkpoint 1316645326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,591.48704
Policy Entropy: 3.82277
Value Function Loss: 0.02449

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12071
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.79388

Collected Steps per Second: 22,762.45591
Overall Steps per Second: 10,686.35613

Timestep Collection Time: 2.19765
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.68111

Cumulative Model Updates: 157,904
Cumulative Timesteps: 1,316,695,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,564.07535
Policy Entropy: 3.79001
Value Function Loss: 0.02989

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11719
Policy Update Magnitude: 0.60960
Value Function Update Magnitude: 0.81814

Collected Steps per Second: 22,705.09987
Overall Steps per Second: 10,840.96527

Timestep Collection Time: 2.20232
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.61250

Cumulative Model Updates: 157,910
Cumulative Timesteps: 1,316,745,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1316745354...
Checkpoint 1316745354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,112.33365
Policy Entropy: 3.78238
Value Function Loss: 0.02825

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.64768
Value Function Update Magnitude: 0.78554

Collected Steps per Second: 22,613.71840
Overall Steps per Second: 10,640.36465

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.70153

Cumulative Model Updates: 157,916
Cumulative Timesteps: 1,316,795,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,851.01973
Policy Entropy: 3.78625
Value Function Loss: 0.03311

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.65518
Value Function Update Magnitude: 0.66475

Collected Steps per Second: 22,673.51083
Overall Steps per Second: 10,803.37348

Timestep Collection Time: 2.20530
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62837

Cumulative Model Updates: 157,922
Cumulative Timesteps: 1,316,845,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1316845382...
Checkpoint 1316845382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.47219
Policy Entropy: 3.80416
Value Function Loss: 0.03172

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.71955
Value Function Update Magnitude: 0.71446

Collected Steps per Second: 22,623.91359
Overall Steps per Second: 10,711.11542

Timestep Collection Time: 2.21120
Timestep Consumption Time: 2.45928
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.67048

Cumulative Model Updates: 157,928
Cumulative Timesteps: 1,316,895,408

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,653.51449
Policy Entropy: 3.80656
Value Function Loss: 0.03180

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.77141
Value Function Update Magnitude: 0.76535

Collected Steps per Second: 22,114.36908
Overall Steps per Second: 10,523.39388

Timestep Collection Time: 2.26170
Timestep Consumption Time: 2.49114
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75284

Cumulative Model Updates: 157,934
Cumulative Timesteps: 1,316,945,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1316945424...
Checkpoint 1316945424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,634.19117
Policy Entropy: 3.81545
Value Function Loss: 0.02723

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.73252
Value Function Update Magnitude: 0.87306

Collected Steps per Second: 21,968.58264
Overall Steps per Second: 10,573.34547

Timestep Collection Time: 2.27689
Timestep Consumption Time: 2.45388
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.73076

Cumulative Model Updates: 157,940
Cumulative Timesteps: 1,316,995,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,740.29898
Policy Entropy: 3.81780
Value Function Loss: 0.02450

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.67894
Value Function Update Magnitude: 0.79113

Collected Steps per Second: 22,375.26488
Overall Steps per Second: 10,625.34514

Timestep Collection Time: 2.23586
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.70836

Cumulative Model Updates: 157,946
Cumulative Timesteps: 1,317,045,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1317045472...
Checkpoint 1317045472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,897.47262
Policy Entropy: 3.82319
Value Function Loss: 0.02188

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.63679
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 22,300.80042
Overall Steps per Second: 10,858.66934

Timestep Collection Time: 2.24360
Timestep Consumption Time: 2.36415
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.60775

Cumulative Model Updates: 157,952
Cumulative Timesteps: 1,317,095,506

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,503.12045
Policy Entropy: 3.79750
Value Function Loss: 0.02062

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13763
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.56745

Collected Steps per Second: 21,602.86860
Overall Steps per Second: 10,513.27602

Timestep Collection Time: 2.31608
Timestep Consumption Time: 2.44304
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.75913

Cumulative Model Updates: 157,958
Cumulative Timesteps: 1,317,145,540

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1317145540...
Checkpoint 1317145540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,759.31346
Policy Entropy: 3.78412
Value Function Loss: 0.01730

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14135
Policy Update Magnitude: 0.46401
Value Function Update Magnitude: 0.50586

Collected Steps per Second: 22,052.39415
Overall Steps per Second: 10,663.48596

Timestep Collection Time: 2.26751
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68927

Cumulative Model Updates: 157,964
Cumulative Timesteps: 1,317,195,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,759.31346
Policy Entropy: 3.75740
Value Function Loss: 0.01533

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.49641
Value Function Update Magnitude: 0.43261

Collected Steps per Second: 22,286.32795
Overall Steps per Second: 10,657.48565

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.69398

Cumulative Model Updates: 157,970
Cumulative Timesteps: 1,317,245,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1317245570...
Checkpoint 1317245570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,903.99465
Policy Entropy: 3.75699
Value Function Loss: 0.01745

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.46551
Value Function Update Magnitude: 0.46648

Collected Steps per Second: 22,542.61998
Overall Steps per Second: 10,838.80563

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.39503
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.61305

Cumulative Model Updates: 157,976
Cumulative Timesteps: 1,317,295,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,336.22076
Policy Entropy: 3.79044
Value Function Loss: 0.01833

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.18838
Policy Update Magnitude: 0.50668
Value Function Update Magnitude: 0.56833

Collected Steps per Second: 22,712.90134
Overall Steps per Second: 10,893.74228

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.39041
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.59365

Cumulative Model Updates: 157,982
Cumulative Timesteps: 1,317,345,612

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1317345612...
Checkpoint 1317345612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,581.81684
Policy Entropy: 3.82078
Value Function Loss: 0.01890

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.24807
Policy Update Magnitude: 0.46481
Value Function Update Magnitude: 0.64037

Collected Steps per Second: 21,282.21334
Overall Steps per Second: 10,241.29453

Timestep Collection Time: 2.34938
Timestep Consumption Time: 2.53282
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.88220

Cumulative Model Updates: 157,988
Cumulative Timesteps: 1,317,395,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,632.31414
Policy Entropy: 3.83634
Value Function Loss: 0.02203

Mean KL Divergence: 0.01941
SB3 Clip Fraction: 0.22236
Policy Update Magnitude: 0.40478
Value Function Update Magnitude: 0.62864

Collected Steps per Second: 22,209.37786
Overall Steps per Second: 10,524.88148

Timestep Collection Time: 2.25157
Timestep Consumption Time: 2.49965
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.75122

Cumulative Model Updates: 157,994
Cumulative Timesteps: 1,317,445,618

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1317445618...
Checkpoint 1317445618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.80492
Policy Entropy: 3.83244
Value Function Loss: 0.02630

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.52088
Value Function Update Magnitude: 0.64948

Collected Steps per Second: 22,460.15142
Overall Steps per Second: 10,684.97460

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.68040

Cumulative Model Updates: 158,000
Cumulative Timesteps: 1,317,495,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.00481
Policy Entropy: 3.80916
Value Function Loss: 0.02898

Mean KL Divergence: 0.01562
SB3 Clip Fraction: 0.18923
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.52346

Collected Steps per Second: 22,473.07733
Overall Steps per Second: 10,735.25416

Timestep Collection Time: 2.22560
Timestep Consumption Time: 2.43345
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.65904

Cumulative Model Updates: 158,006
Cumulative Timesteps: 1,317,545,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1317545644...
Checkpoint 1317545644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,817.01961
Policy Entropy: 3.80295
Value Function Loss: 0.03852

Mean KL Divergence: 0.02335
SB3 Clip Fraction: 0.23772
Policy Update Magnitude: 0.52739
Value Function Update Magnitude: 0.53006

Collected Steps per Second: 22,328.97197
Overall Steps per Second: 10,670.26661

Timestep Collection Time: 2.23942
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.68629

Cumulative Model Updates: 158,012
Cumulative Timesteps: 1,317,595,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,190.48232
Policy Entropy: 3.83986
Value Function Loss: 0.04523

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.73060
Value Function Update Magnitude: 0.66176

Collected Steps per Second: 22,286.66651
Overall Steps per Second: 10,649.65968

Timestep Collection Time: 2.24466
Timestep Consumption Time: 2.45277
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.69743

Cumulative Model Updates: 158,018
Cumulative Timesteps: 1,317,645,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1317645674...
Checkpoint 1317645674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.14181
Policy Entropy: 3.89693
Value Function Loss: 0.04402

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.97020
Value Function Update Magnitude: 0.72218

Collected Steps per Second: 22,502.69349
Overall Steps per Second: 10,701.97666

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.67316

Cumulative Model Updates: 158,024
Cumulative Timesteps: 1,317,695,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,796.48010
Policy Entropy: 3.94498
Value Function Loss: 0.04080

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.89464
Value Function Update Magnitude: 0.72563

Collected Steps per Second: 23,071.07921
Overall Steps per Second: 10,768.89464

Timestep Collection Time: 2.16782
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64430

Cumulative Model Updates: 158,030
Cumulative Timesteps: 1,317,745,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1317745700...
Checkpoint 1317745700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131.35879
Policy Entropy: 3.96761
Value Function Loss: 0.03251

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06811
Policy Update Magnitude: 0.91105
Value Function Update Magnitude: 0.87462

Collected Steps per Second: 22,787.94272
Overall Steps per Second: 10,776.54939

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.64230

Cumulative Model Updates: 158,036
Cumulative Timesteps: 1,317,795,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,415.96130
Policy Entropy: 3.93185
Value Function Loss: 0.03214

Mean KL Divergence: 0.00625
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.90415
Value Function Update Magnitude: 1.03885

Collected Steps per Second: 22,467.92392
Overall Steps per Second: 10,737.68077

Timestep Collection Time: 2.22566
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.65706

Cumulative Model Updates: 158,042
Cumulative Timesteps: 1,317,845,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1317845734...
Checkpoint 1317845734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.71047
Policy Entropy: 3.91658
Value Function Loss: 0.02707

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07231
Policy Update Magnitude: 0.83268
Value Function Update Magnitude: 1.04549

Collected Steps per Second: 22,286.81238
Overall Steps per Second: 10,625.42641

Timestep Collection Time: 2.24348
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.70569

Cumulative Model Updates: 158,048
Cumulative Timesteps: 1,317,895,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.48668
Policy Entropy: 3.86975
Value Function Loss: 0.02506

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.74294
Value Function Update Magnitude: 0.99676

Collected Steps per Second: 22,023.99259
Overall Steps per Second: 10,559.23236

Timestep Collection Time: 2.27025
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.73519

Cumulative Model Updates: 158,054
Cumulative Timesteps: 1,317,945,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1317945734...
Checkpoint 1317945734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,427.83639
Policy Entropy: 3.83167
Value Function Loss: 0.02271

Mean KL Divergence: 0.00730
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.70857
Value Function Update Magnitude: 0.90770

Collected Steps per Second: 22,543.23397
Overall Steps per Second: 10,716.26691

Timestep Collection Time: 2.21849
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.66692

Cumulative Model Updates: 158,060
Cumulative Timesteps: 1,317,995,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,513.61858
Policy Entropy: 3.81901
Value Function Loss: 0.02257

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13877
Policy Update Magnitude: 0.70004
Value Function Update Magnitude: 0.80707

Collected Steps per Second: 22,394.02253
Overall Steps per Second: 10,735.14016

Timestep Collection Time: 2.23399
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.66021

Cumulative Model Updates: 158,066
Cumulative Timesteps: 1,318,045,774

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1318045774...
Checkpoint 1318045774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,592.62503
Policy Entropy: 3.80261
Value Function Loss: 0.02637

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.18617
Policy Update Magnitude: 0.60027
Value Function Update Magnitude: 0.62054

Collected Steps per Second: 22,618.37367
Overall Steps per Second: 10,637.89190

Timestep Collection Time: 2.21103
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.70112

Cumulative Model Updates: 158,072
Cumulative Timesteps: 1,318,095,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,977.03795
Policy Entropy: 3.83139
Value Function Loss: 0.03253

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16413
Policy Update Magnitude: 0.61408
Value Function Update Magnitude: 0.44657

Collected Steps per Second: 22,145.52263
Overall Steps per Second: 10,508.11170

Timestep Collection Time: 2.25833
Timestep Consumption Time: 2.50104
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.75937

Cumulative Model Updates: 158,078
Cumulative Timesteps: 1,318,145,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1318145796...
Checkpoint 1318145796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,057.73864
Policy Entropy: 3.81272
Value Function Loss: 0.03111

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.17723
Policy Update Magnitude: 0.55674
Value Function Update Magnitude: 0.35739

Collected Steps per Second: 22,684.13854
Overall Steps per Second: 10,746.61053

Timestep Collection Time: 2.20480
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.65393

Cumulative Model Updates: 158,084
Cumulative Timesteps: 1,318,195,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,486.53680
Policy Entropy: 3.83119
Value Function Loss: 0.03059

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.15696
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.32092

Collected Steps per Second: 22,725.46502
Overall Steps per Second: 10,727.34373

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.66099

Cumulative Model Updates: 158,090
Cumulative Timesteps: 1,318,245,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1318245810...
Checkpoint 1318245810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,703.91636
Policy Entropy: 3.81380
Value Function Loss: 0.03598

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.48040
Value Function Update Magnitude: 0.28111

Collected Steps per Second: 22,407.48467
Overall Steps per Second: 10,611.72819

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.71290

Cumulative Model Updates: 158,096
Cumulative Timesteps: 1,318,295,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,458.58258
Policy Entropy: 3.82268
Value Function Loss: 0.05422

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.45619
Value Function Update Magnitude: 0.25467

Collected Steps per Second: 22,281.81499
Overall Steps per Second: 10,557.51300

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.49338
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.73862

Cumulative Model Updates: 158,102
Cumulative Timesteps: 1,318,345,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1318345850...
Checkpoint 1318345850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,806.10351
Policy Entropy: 3.82022
Value Function Loss: 0.04500

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.48181
Value Function Update Magnitude: 0.33272

Collected Steps per Second: 22,343.01446
Overall Steps per Second: 10,555.62021

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.49968
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.73814

Cumulative Model Updates: 158,108
Cumulative Timesteps: 1,318,395,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,385.61886
Policy Entropy: 3.81572
Value Function Loss: 0.03613

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.53264
Value Function Update Magnitude: 0.30250

Collected Steps per Second: 21,610.29815
Overall Steps per Second: 10,474.85478

Timestep Collection Time: 2.31464
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.77525

Cumulative Model Updates: 158,114
Cumulative Timesteps: 1,318,445,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1318445884...
Checkpoint 1318445884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,508.03653
Policy Entropy: 3.83434
Value Function Loss: 0.02400

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.63280
Value Function Update Magnitude: 0.51499

Collected Steps per Second: 22,206.22352
Overall Steps per Second: 10,645.91982

Timestep Collection Time: 2.25171
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.69682

Cumulative Model Updates: 158,120
Cumulative Timesteps: 1,318,495,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,668.00672
Policy Entropy: 3.86570
Value Function Loss: 0.02676

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.66878
Value Function Update Magnitude: 0.71097

Collected Steps per Second: 21,810.82351
Overall Steps per Second: 10,543.84625

Timestep Collection Time: 2.29262
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.74248

Cumulative Model Updates: 158,126
Cumulative Timesteps: 1,318,545,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1318545890...
Checkpoint 1318545890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107.18099
Policy Entropy: 3.89339
Value Function Loss: 0.02762

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.68732
Value Function Update Magnitude: 0.79419

Collected Steps per Second: 22,082.89144
Overall Steps per Second: 10,565.25107

Timestep Collection Time: 2.26546
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.73515

Cumulative Model Updates: 158,132
Cumulative Timesteps: 1,318,595,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98.11624
Policy Entropy: 3.87821
Value Function Loss: 0.02823

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.71287
Value Function Update Magnitude: 0.68801

Collected Steps per Second: 22,153.42190
Overall Steps per Second: 10,623.96771

Timestep Collection Time: 2.25816
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.70879

Cumulative Model Updates: 158,138
Cumulative Timesteps: 1,318,645,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1318645944...
Checkpoint 1318645944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,119.54089
Policy Entropy: 3.83828
Value Function Loss: 0.02633

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.71443
Value Function Update Magnitude: 0.62339

Collected Steps per Second: 22,683.62983
Overall Steps per Second: 10,653.09226

Timestep Collection Time: 2.20556
Timestep Consumption Time: 2.49073
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.69629

Cumulative Model Updates: 158,144
Cumulative Timesteps: 1,318,695,974

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,523.68146
Policy Entropy: 3.82444
Value Function Loss: 0.02758

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12407
Policy Update Magnitude: 0.61508
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 22,353.50343
Overall Steps per Second: 10,660.43775

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.69380

Cumulative Model Updates: 158,150
Cumulative Timesteps: 1,318,746,012

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1318746012...
Checkpoint 1318746012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.38590
Policy Entropy: 3.83933
Value Function Loss: 0.02826

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.64614
Value Function Update Magnitude: 0.61921

Collected Steps per Second: 22,555.05915
Overall Steps per Second: 10,638.83113

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70014

Cumulative Model Updates: 158,156
Cumulative Timesteps: 1,318,796,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,577.17069
Policy Entropy: 3.85548
Value Function Loss: 0.03013

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.20347
Policy Update Magnitude: 0.60007
Value Function Update Magnitude: 0.70637

Collected Steps per Second: 22,480.19934
Overall Steps per Second: 10,842.84775

Timestep Collection Time: 2.22436
Timestep Consumption Time: 2.38735
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.61170

Cumulative Model Updates: 158,162
Cumulative Timesteps: 1,318,846,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1318846020...
Checkpoint 1318846020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,791.84047
Policy Entropy: 3.88370
Value Function Loss: 0.03202

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14512
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.68691

Collected Steps per Second: 22,455.15705
Overall Steps per Second: 10,730.63107

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.65956

Cumulative Model Updates: 158,168
Cumulative Timesteps: 1,318,896,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148.59053
Policy Entropy: 3.90011
Value Function Loss: 0.03107

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16470
Policy Update Magnitude: 0.62959
Value Function Update Magnitude: 0.78618

Collected Steps per Second: 22,371.73082
Overall Steps per Second: 10,796.14385

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.63369

Cumulative Model Updates: 158,174
Cumulative Timesteps: 1,318,946,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1318946046...
Checkpoint 1318946046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.18368
Policy Entropy: 3.88387
Value Function Loss: 0.03378

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.16576
Policy Update Magnitude: 0.64346
Value Function Update Magnitude: 0.82358

Collected Steps per Second: 22,141.61862
Overall Steps per Second: 10,777.47990

Timestep Collection Time: 2.25909
Timestep Consumption Time: 2.38207
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.64116

Cumulative Model Updates: 158,180
Cumulative Timesteps: 1,318,996,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,919.35976
Policy Entropy: 3.89546
Value Function Loss: 0.03363

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.72137
Value Function Update Magnitude: 0.79408

Collected Steps per Second: 22,649.01014
Overall Steps per Second: 10,849.85889

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.40085
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.60854

Cumulative Model Updates: 158,186
Cumulative Timesteps: 1,319,046,068

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1319046068...
Checkpoint 1319046068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,266.70143
Policy Entropy: 3.88267
Value Function Loss: 0.03390

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14937
Policy Update Magnitude: 0.67768
Value Function Update Magnitude: 0.73251

Collected Steps per Second: 22,542.32750
Overall Steps per Second: 10,675.67054

Timestep Collection Time: 2.21814
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.68373

Cumulative Model Updates: 158,192
Cumulative Timesteps: 1,319,096,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,098.92786
Policy Entropy: 3.91651
Value Function Loss: 0.02995

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15237
Policy Update Magnitude: 0.62147
Value Function Update Magnitude: 0.78748

Collected Steps per Second: 22,561.71655
Overall Steps per Second: 10,842.43270

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.39613
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.61299

Cumulative Model Updates: 158,198
Cumulative Timesteps: 1,319,146,086

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1319146086...
Checkpoint 1319146086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208.54136
Policy Entropy: 3.91726
Value Function Loss: 0.02817

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.62005
Value Function Update Magnitude: 0.70913

Collected Steps per Second: 22,758.70581
Overall Steps per Second: 10,658.58467

Timestep Collection Time: 2.19810
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.69349

Cumulative Model Updates: 158,204
Cumulative Timesteps: 1,319,196,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,084.31025
Policy Entropy: 3.91768
Value Function Loss: 0.02768

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.65061
Value Function Update Magnitude: 0.64094

Collected Steps per Second: 22,460.83390
Overall Steps per Second: 10,836.20353

Timestep Collection Time: 2.22645
Timestep Consumption Time: 2.38845
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61490

Cumulative Model Updates: 158,210
Cumulative Timesteps: 1,319,246,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1319246120...
Checkpoint 1319246120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,578.27088
Policy Entropy: 3.87357
Value Function Loss: 0.02778

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08432
Policy Update Magnitude: 0.77334
Value Function Update Magnitude: 0.72374

Collected Steps per Second: 22,359.91232
Overall Steps per Second: 10,664.45809

Timestep Collection Time: 2.23668
Timestep Consumption Time: 2.45291
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.68960

Cumulative Model Updates: 158,216
Cumulative Timesteps: 1,319,296,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,568.91009
Policy Entropy: 3.81749
Value Function Loss: 0.02816

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.81250
Value Function Update Magnitude: 0.73729

Collected Steps per Second: 22,796.38999
Overall Steps per Second: 10,659.45334

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.49784
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.69161

Cumulative Model Updates: 158,222
Cumulative Timesteps: 1,319,346,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1319346142...
Checkpoint 1319346142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,900.22341
Policy Entropy: 3.79422
Value Function Loss: 0.02882

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17736
Policy Update Magnitude: 0.64378
Value Function Update Magnitude: 0.67413

Collected Steps per Second: 22,765.99149
Overall Steps per Second: 10,720.67884

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.46822
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.66500

Cumulative Model Updates: 158,228
Cumulative Timesteps: 1,319,396,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,973.52031
Policy Entropy: 3.78394
Value Function Loss: 0.03354

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.18937
Policy Update Magnitude: 0.61941
Value Function Update Magnitude: 0.82732

Collected Steps per Second: 23,018.91898
Overall Steps per Second: 10,796.77333

Timestep Collection Time: 2.17230
Timestep Consumption Time: 2.45908
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.63138

Cumulative Model Updates: 158,234
Cumulative Timesteps: 1,319,446,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1319446158...
Checkpoint 1319446158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,701.62952
Policy Entropy: 3.80337
Value Function Loss: 0.03833

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18355
Policy Update Magnitude: 0.66077
Value Function Update Magnitude: 0.78609

Collected Steps per Second: 22,532.05537
Overall Steps per Second: 10,740.01309

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.65828

Cumulative Model Updates: 158,240
Cumulative Timesteps: 1,319,496,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,465.17056
Policy Entropy: 3.81825
Value Function Loss: 0.04140

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15213
Policy Update Magnitude: 0.70361
Value Function Update Magnitude: 0.66104

Collected Steps per Second: 22,433.18108
Overall Steps per Second: 10,723.41543

Timestep Collection Time: 2.22938
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.66381

Cumulative Model Updates: 158,246
Cumulative Timesteps: 1,319,546,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1319546200...
Checkpoint 1319546200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.75438
Policy Entropy: 3.87624
Value Function Loss: 0.03895

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12342
Policy Update Magnitude: 0.73267
Value Function Update Magnitude: 0.62629

Collected Steps per Second: 22,197.40757
Overall Steps per Second: 10,609.61646

Timestep Collection Time: 2.25360
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.71497

Cumulative Model Updates: 158,252
Cumulative Timesteps: 1,319,596,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.71535
Policy Entropy: 3.89783
Value Function Loss: 0.03769

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.73325
Value Function Update Magnitude: 0.52786

Collected Steps per Second: 22,592.37494
Overall Steps per Second: 10,851.60205

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.39457
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.60780

Cumulative Model Updates: 158,258
Cumulative Timesteps: 1,319,646,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1319646226...
Checkpoint 1319646226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,981.64685
Policy Entropy: 3.89903
Value Function Loss: 0.03439

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13470
Policy Update Magnitude: 0.68058
Value Function Update Magnitude: 0.57524

Collected Steps per Second: 23,078.79551
Overall Steps per Second: 10,691.19252

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.51046
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.67712

Cumulative Model Updates: 158,264
Cumulative Timesteps: 1,319,696,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,481.98313
Policy Entropy: 3.85639
Value Function Loss: 0.03166

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.57722
Value Function Update Magnitude: 0.71275

Collected Steps per Second: 22,859.30957
Overall Steps per Second: 10,838.57040

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.61445

Cumulative Model Updates: 158,270
Cumulative Timesteps: 1,319,746,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1319746244...
Checkpoint 1319746244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,566.81178
Policy Entropy: 3.81226
Value Function Loss: 0.03029

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 22,753.03953
Overall Steps per Second: 10,713.62507

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.47004
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.66807

Cumulative Model Updates: 158,276
Cumulative Timesteps: 1,319,796,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,948.48759
Policy Entropy: 3.78289
Value Function Loss: 0.02999

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.56831

Collected Steps per Second: 23,001.30522
Overall Steps per Second: 10,885.82095

Timestep Collection Time: 2.17466
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.59497

Cumulative Model Updates: 158,282
Cumulative Timesteps: 1,319,846,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1319846276...
Checkpoint 1319846276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.95940
Policy Entropy: 3.79368
Value Function Loss: 0.03268

Mean KL Divergence: 0.01919
SB3 Clip Fraction: 0.21730
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.57973

Collected Steps per Second: 22,964.03293
Overall Steps per Second: 10,814.87095

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.62585

Cumulative Model Updates: 158,288
Cumulative Timesteps: 1,319,896,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,126.79637
Policy Entropy: 3.83849
Value Function Loss: 0.03781

Mean KL Divergence: 0.02007
SB3 Clip Fraction: 0.22353
Policy Update Magnitude: 0.59265
Value Function Update Magnitude: 0.66460

Collected Steps per Second: 22,442.64032
Overall Steps per Second: 10,758.08193

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.42064
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.64934

Cumulative Model Updates: 158,294
Cumulative Timesteps: 1,319,946,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1319946322...
Checkpoint 1319946322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,576.68645
Policy Entropy: 3.88755
Value Function Loss: 0.04353

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.19934
Policy Update Magnitude: 0.59499
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,225.90659
Overall Steps per Second: 10,616.83344

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.46066
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.71101

Cumulative Model Updates: 158,300
Cumulative Timesteps: 1,319,996,338

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.46248
Policy Entropy: 4.01198
Value Function Loss: 0.04282

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.14695
Policy Update Magnitude: 0.63558
Value Function Update Magnitude: 0.68023

Collected Steps per Second: 22,705.25522
Overall Steps per Second: 10,977.42658

Timestep Collection Time: 2.20310
Timestep Consumption Time: 2.35370
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.55681

Cumulative Model Updates: 158,306
Cumulative Timesteps: 1,320,046,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1320046360...
Checkpoint 1320046360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.86145
Policy Entropy: 4.11450
Value Function Loss: 0.03635

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.07565
Policy Update Magnitude: 0.83598
Value Function Update Magnitude: 0.64002

Collected Steps per Second: 22,714.88626
Overall Steps per Second: 10,682.78513

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.68174

Cumulative Model Updates: 158,312
Cumulative Timesteps: 1,320,096,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.18352
Policy Entropy: 4.16784
Value Function Loss: 0.02673

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05796
Policy Update Magnitude: 1.02844
Value Function Update Magnitude: 0.73763

Collected Steps per Second: 22,339.40920
Overall Steps per Second: 10,742.69184

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.65526

Cumulative Model Updates: 158,318
Cumulative Timesteps: 1,320,146,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1320146384...
Checkpoint 1320146384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.65991
Policy Entropy: 4.12390
Value Function Loss: 0.02743

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06124
Policy Update Magnitude: 1.08089
Value Function Update Magnitude: 0.87974

Collected Steps per Second: 22,833.36306
Overall Steps per Second: 10,682.18214

Timestep Collection Time: 2.19048
Timestep Consumption Time: 2.49171
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.68219

Cumulative Model Updates: 158,324
Cumulative Timesteps: 1,320,196,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,964.90573
Policy Entropy: 4.04915
Value Function Loss: 0.03392

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 1.08528
Value Function Update Magnitude: 0.82106

Collected Steps per Second: 22,835.31077
Overall Steps per Second: 10,877.19948

Timestep Collection Time: 2.19064
Timestep Consumption Time: 2.40834
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.59898

Cumulative Model Updates: 158,330
Cumulative Timesteps: 1,320,246,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1320246424...
Checkpoint 1320246424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,878.84643
Policy Entropy: 3.97117
Value Function Loss: 0.03636

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 1.01567
Value Function Update Magnitude: 0.70995

Collected Steps per Second: 22,538.03586
Overall Steps per Second: 10,712.66024

Timestep Collection Time: 2.21954
Timestep Consumption Time: 2.45008
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.66962

Cumulative Model Updates: 158,336
Cumulative Timesteps: 1,320,296,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,590.25136
Policy Entropy: 3.90835
Value Function Loss: 0.03743

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.93661
Value Function Update Magnitude: 0.73541

Collected Steps per Second: 22,847.13237
Overall Steps per Second: 10,879.37062

Timestep Collection Time: 2.18925
Timestep Consumption Time: 2.40826
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59751

Cumulative Model Updates: 158,342
Cumulative Timesteps: 1,320,346,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1320346466...
Checkpoint 1320346466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,758.26778
Policy Entropy: 3.84867
Value Function Loss: 0.03921

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.19314
Policy Update Magnitude: 0.78304
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 22,734.49920
Overall Steps per Second: 10,716.93165

Timestep Collection Time: 2.19930
Timestep Consumption Time: 2.46621
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.66551

Cumulative Model Updates: 158,348
Cumulative Timesteps: 1,320,396,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,011.74005
Policy Entropy: 3.86281
Value Function Loss: 0.04462

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.14821
Policy Update Magnitude: 0.60985
Value Function Update Magnitude: 0.50864

Collected Steps per Second: 22,453.61426
Overall Steps per Second: 10,905.82635

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.35959
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.58801

Cumulative Model Updates: 158,354
Cumulative Timesteps: 1,320,446,502

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1320446502...
Checkpoint 1320446502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244.48624
Policy Entropy: 3.90230
Value Function Loss: 0.04419

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.88781
Value Function Update Magnitude: 0.55526

Collected Steps per Second: 21,770.21468
Overall Steps per Second: 10,614.47650

Timestep Collection Time: 2.29754
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71224

Cumulative Model Updates: 158,360
Cumulative Timesteps: 1,320,496,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.08256
Policy Entropy: 3.93454
Value Function Loss: 0.04238

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.92828
Value Function Update Magnitude: 0.63881

Collected Steps per Second: 21,950.65145
Overall Steps per Second: 10,485.57370

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.77094

Cumulative Model Updates: 158,366
Cumulative Timesteps: 1,320,546,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1320546546...
Checkpoint 1320546546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.45452
Policy Entropy: 3.96641
Value Function Loss: 0.03846

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.83097
Value Function Update Magnitude: 0.57688

Collected Steps per Second: 22,264.86680
Overall Steps per Second: 10,594.57301

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.47440
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.72072

Cumulative Model Updates: 158,372
Cumulative Timesteps: 1,320,596,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.67734
Policy Entropy: 3.92655
Value Function Loss: 0.03646

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.67784
Value Function Update Magnitude: 0.58281

Collected Steps per Second: 22,701.90125
Overall Steps per Second: 10,833.93314

Timestep Collection Time: 2.20263
Timestep Consumption Time: 2.41286
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.61550

Cumulative Model Updates: 158,378
Cumulative Timesteps: 1,320,646,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1320646564...
Checkpoint 1320646564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,055.62672
Policy Entropy: 3.90632
Value Function Loss: 0.03359

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.59482
Value Function Update Magnitude: 0.62614

Collected Steps per Second: 22,276.99741
Overall Steps per Second: 10,726.27433

Timestep Collection Time: 2.24510
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.66276

Cumulative Model Updates: 158,384
Cumulative Timesteps: 1,320,696,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,844.44010
Policy Entropy: 3.85960
Value Function Loss: 0.03373

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.48039
Value Function Update Magnitude: 0.64924

Collected Steps per Second: 22,140.49446
Overall Steps per Second: 10,820.54611

Timestep Collection Time: 2.25948
Timestep Consumption Time: 2.36376
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.62324

Cumulative Model Updates: 158,390
Cumulative Timesteps: 1,320,746,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1320746604...
Checkpoint 1320746604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.33045
Policy Entropy: 3.88628
Value Function Loss: 0.03292

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.45198
Value Function Update Magnitude: 0.69264

Collected Steps per Second: 22,703.16631
Overall Steps per Second: 10,715.84910

Timestep Collection Time: 2.20339
Timestep Consumption Time: 2.46483
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.66823

Cumulative Model Updates: 158,396
Cumulative Timesteps: 1,320,796,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,435.80977
Policy Entropy: 3.91680
Value Function Loss: 0.03216

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.43932
Value Function Update Magnitude: 0.75422

Collected Steps per Second: 23,060.33514
Overall Steps per Second: 10,898.02397

Timestep Collection Time: 2.16909
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.58982

Cumulative Model Updates: 158,402
Cumulative Timesteps: 1,320,846,648

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1320846648...
Checkpoint 1320846648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204.70024
Policy Entropy: 3.89579
Value Function Loss: 0.02823

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.41181
Value Function Update Magnitude: 0.67845

Collected Steps per Second: 22,215.36530
Overall Steps per Second: 10,730.42678

Timestep Collection Time: 2.25141
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.66114

Cumulative Model Updates: 158,408
Cumulative Timesteps: 1,320,896,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,977.64959
Policy Entropy: 3.82720
Value Function Loss: 0.02265

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.38858
Value Function Update Magnitude: 0.51866

Collected Steps per Second: 22,141.92220
Overall Steps per Second: 10,856.49257

Timestep Collection Time: 2.25897
Timestep Consumption Time: 2.34822
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.60720

Cumulative Model Updates: 158,414
Cumulative Timesteps: 1,320,946,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1320946682...
Checkpoint 1320946682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,065.22007
Policy Entropy: 3.77294
Value Function Loss: 0.01972

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.36949
Value Function Update Magnitude: 0.46373

Collected Steps per Second: 21,623.51499
Overall Steps per Second: 10,667.82359

Timestep Collection Time: 2.31248
Timestep Consumption Time: 2.37488
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.68737

Cumulative Model Updates: 158,420
Cumulative Timesteps: 1,320,996,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,746.64094
Policy Entropy: 3.76934
Value Function Loss: 0.01701

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.34763
Value Function Update Magnitude: 0.49687

Collected Steps per Second: 21,750.41290
Overall Steps per Second: 10,450.66885

Timestep Collection Time: 2.29945
Timestep Consumption Time: 2.48627
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.78572

Cumulative Model Updates: 158,426
Cumulative Timesteps: 1,321,046,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1321046700...
Checkpoint 1321046700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,021.56370
Policy Entropy: 3.77062
Value Function Loss: 0.01776

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.36258
Value Function Update Magnitude: 0.51224

Collected Steps per Second: 22,287.18889
Overall Steps per Second: 10,621.83545

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70879

Cumulative Model Updates: 158,432
Cumulative Timesteps: 1,321,096,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,277.70680
Policy Entropy: 3.75618
Value Function Loss: 0.01792

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.37870
Value Function Update Magnitude: 0.54369

Collected Steps per Second: 22,337.77775
Overall Steps per Second: 10,653.94198

Timestep Collection Time: 2.23881
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.69404

Cumulative Model Updates: 158,438
Cumulative Timesteps: 1,321,146,726

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1321146726...
Checkpoint 1321146726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,170.36558
Policy Entropy: 3.72773
Value Function Loss: 0.01987

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.39149
Value Function Update Magnitude: 0.51775

Collected Steps per Second: 22,451.15390
Overall Steps per Second: 10,547.97371

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.51389
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.74157

Cumulative Model Updates: 158,444
Cumulative Timesteps: 1,321,196,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,704.48303
Policy Entropy: 3.73107
Value Function Loss: 0.02194

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.41932
Value Function Update Magnitude: 0.53620

Collected Steps per Second: 22,765.33983
Overall Steps per Second: 10,787.10548

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.63739

Cumulative Model Updates: 158,450
Cumulative Timesteps: 1,321,246,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1321246764...
Checkpoint 1321246764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,909.43094
Policy Entropy: 3.74828
Value Function Loss: 0.02281

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12725
Policy Update Magnitude: 0.43662
Value Function Update Magnitude: 0.54369

Collected Steps per Second: 22,788.27496
Overall Steps per Second: 10,661.99678

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.69162

Cumulative Model Updates: 158,456
Cumulative Timesteps: 1,321,296,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,242.54935
Policy Entropy: 3.75378
Value Function Loss: 0.02259

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.42195
Value Function Update Magnitude: 0.53412

Collected Steps per Second: 22,582.55211
Overall Steps per Second: 10,649.70117

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.69722

Cumulative Model Updates: 158,462
Cumulative Timesteps: 1,321,346,810

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1321346810...
Checkpoint 1321346810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,099.07797
Policy Entropy: 3.76250
Value Function Loss: 0.02066

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13394
Policy Update Magnitude: 0.40800
Value Function Update Magnitude: 0.52756

Collected Steps per Second: 22,844.29884
Overall Steps per Second: 10,824.95495

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.43062
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.61970

Cumulative Model Updates: 158,468
Cumulative Timesteps: 1,321,396,818

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,093.19093
Policy Entropy: 3.75642
Value Function Loss: 0.02436

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.42237
Value Function Update Magnitude: 0.51220

Collected Steps per Second: 22,601.71268
Overall Steps per Second: 10,608.10882

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.50235
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71564

Cumulative Model Updates: 158,474
Cumulative Timesteps: 1,321,446,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1321446842...
Checkpoint 1321446842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,071.68047
Policy Entropy: 3.77269
Value Function Loss: 0.02638

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.44911
Value Function Update Magnitude: 0.51348

Collected Steps per Second: 22,485.07655
Overall Steps per Second: 10,630.67217

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70525

Cumulative Model Updates: 158,480
Cumulative Timesteps: 1,321,496,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,338.68524
Policy Entropy: 3.76921
Value Function Loss: 0.02704

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12461
Policy Update Magnitude: 0.45512
Value Function Update Magnitude: 0.52895

Collected Steps per Second: 22,248.02270
Overall Steps per Second: 10,600.27631

Timestep Collection Time: 2.24802
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.71818

Cumulative Model Updates: 158,486
Cumulative Timesteps: 1,321,546,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1321546876...
Checkpoint 1321546876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,813.46669
Policy Entropy: 3.76896
Value Function Loss: 0.02246

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.46410
Value Function Update Magnitude: 0.67752

Collected Steps per Second: 22,316.00728
Overall Steps per Second: 10,633.58945

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70321

Cumulative Model Updates: 158,492
Cumulative Timesteps: 1,321,596,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,523.32916
Policy Entropy: 3.74917
Value Function Loss: 0.02027

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.42820
Value Function Update Magnitude: 0.61559

Collected Steps per Second: 21,272.15825
Overall Steps per Second: 10,620.60579

Timestep Collection Time: 2.35134
Timestep Consumption Time: 2.35819
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.70952

Cumulative Model Updates: 158,498
Cumulative Timesteps: 1,321,646,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1321646906...
Checkpoint 1321646906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,975.33259
Policy Entropy: 3.75787
Value Function Loss: 0.01999

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.40090
Value Function Update Magnitude: 0.49530

Collected Steps per Second: 21,662.53742
Overall Steps per Second: 10,775.10969

Timestep Collection Time: 2.31035
Timestep Consumption Time: 2.33443
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.64478

Cumulative Model Updates: 158,504
Cumulative Timesteps: 1,321,696,954

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225.61832
Policy Entropy: 3.77622
Value Function Loss: 0.02256

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.42045
Value Function Update Magnitude: 0.46467

Collected Steps per Second: 21,846.39302
Overall Steps per Second: 10,624.79299

Timestep Collection Time: 2.29072
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.71012

Cumulative Model Updates: 158,510
Cumulative Timesteps: 1,321,746,998

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1321746998...
Checkpoint 1321746998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,569.09975
Policy Entropy: 3.79908
Value Function Loss: 0.02390

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.48272
Value Function Update Magnitude: 0.47090

Collected Steps per Second: 21,989.35583
Overall Steps per Second: 10,795.39786

Timestep Collection Time: 2.27501
Timestep Consumption Time: 2.35900
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.63401

Cumulative Model Updates: 158,516
Cumulative Timesteps: 1,321,797,024

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,180.93950
Policy Entropy: 3.78150
Value Function Loss: 0.02649

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.50470
Value Function Update Magnitude: 0.47106

Collected Steps per Second: 22,000.27438
Overall Steps per Second: 10,548.53878

Timestep Collection Time: 2.27352
Timestep Consumption Time: 2.46818
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.74170

Cumulative Model Updates: 158,522
Cumulative Timesteps: 1,321,847,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1321847042...
Checkpoint 1321847042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,533.47660
Policy Entropy: 3.77677
Value Function Loss: 0.02567

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.52830
Value Function Update Magnitude: 0.50110

Collected Steps per Second: 22,784.18452
Overall Steps per Second: 10,729.55572

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.46601
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.66096

Cumulative Model Updates: 158,528
Cumulative Timesteps: 1,321,897,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,453.92506
Policy Entropy: 3.75076
Value Function Loss: 0.02321

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.52290
Value Function Update Magnitude: 0.60175

Collected Steps per Second: 22,883.65735
Overall Steps per Second: 10,805.44402

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.44380
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.63007

Cumulative Model Updates: 158,534
Cumulative Timesteps: 1,321,947,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1321947082...
Checkpoint 1321947082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,260.46823
Policy Entropy: 3.74298
Value Function Loss: 0.02609

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.50584
Value Function Update Magnitude: 0.58389

Collected Steps per Second: 22,780.43149
Overall Steps per Second: 10,664.70731

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.69324

Cumulative Model Updates: 158,540
Cumulative Timesteps: 1,321,997,134

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221,852.73698
Policy Entropy: 3.74594
Value Function Loss: 0.02613

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.53052
Value Function Update Magnitude: 0.53666

Collected Steps per Second: 22,211.30444
Overall Steps per Second: 10,547.16519

Timestep Collection Time: 2.25219
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.74289

Cumulative Model Updates: 158,546
Cumulative Timesteps: 1,322,047,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1322047158...
Checkpoint 1322047158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,738.89149
Policy Entropy: 3.74739
Value Function Loss: 0.02891

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.51827
Value Function Update Magnitude: 0.47507

Collected Steps per Second: 21,870.74855
Overall Steps per Second: 10,563.90831

Timestep Collection Time: 2.28753
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.73594

Cumulative Model Updates: 158,552
Cumulative Timesteps: 1,322,097,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,523.08929
Policy Entropy: 3.75866
Value Function Loss: 0.02785

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.49717
Value Function Update Magnitude: 0.48508

Collected Steps per Second: 22,097.90812
Overall Steps per Second: 10,534.79743

Timestep Collection Time: 2.26392
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.74883

Cumulative Model Updates: 158,558
Cumulative Timesteps: 1,322,147,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1322147216...
Checkpoint 1322147216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,070.91096
Policy Entropy: 3.77461
Value Function Loss: 0.02598

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.49437

Collected Steps per Second: 22,330.55633
Overall Steps per Second: 10,543.38159

Timestep Collection Time: 2.24052
Timestep Consumption Time: 2.50483
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.74535

Cumulative Model Updates: 158,564
Cumulative Timesteps: 1,322,197,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,981.83144
Policy Entropy: 3.79793
Value Function Loss: 0.02526

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11329
Policy Update Magnitude: 0.48596
Value Function Update Magnitude: 0.50872

Collected Steps per Second: 22,279.64266
Overall Steps per Second: 10,569.90817

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.73079

Cumulative Model Updates: 158,570
Cumulative Timesteps: 1,322,247,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1322247252...
Checkpoint 1322247252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,813.77692
Policy Entropy: 3.82320
Value Function Loss: 0.02342

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11477
Policy Update Magnitude: 0.48113
Value Function Update Magnitude: 0.56720

Collected Steps per Second: 22,281.21344
Overall Steps per Second: 10,518.40102

Timestep Collection Time: 2.24440
Timestep Consumption Time: 2.50993
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.75433

Cumulative Model Updates: 158,576
Cumulative Timesteps: 1,322,297,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.93453
Policy Entropy: 3.80038
Value Function Loss: 0.02300

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.45663
Value Function Update Magnitude: 0.60137

Collected Steps per Second: 22,677.50450
Overall Steps per Second: 10,574.99954

Timestep Collection Time: 2.20659
Timestep Consumption Time: 2.52532
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.73192

Cumulative Model Updates: 158,582
Cumulative Timesteps: 1,322,347,300

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1322347300...
Checkpoint 1322347300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,568.69485
Policy Entropy: 3.79528
Value Function Loss: 0.02046

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.41635
Value Function Update Magnitude: 0.56301

Collected Steps per Second: 22,876.49573
Overall Steps per Second: 10,699.08380

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.67591

Cumulative Model Updates: 158,588
Cumulative Timesteps: 1,322,397,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,049.32298
Policy Entropy: 3.75922
Value Function Loss: 0.02012

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12386
Policy Update Magnitude: 0.40948
Value Function Update Magnitude: 0.54433

Collected Steps per Second: 23,122.97836
Overall Steps per Second: 10,724.32590

Timestep Collection Time: 2.16235
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.66230

Cumulative Model Updates: 158,594
Cumulative Timesteps: 1,322,447,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1322447328...
Checkpoint 1322447328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,221.16063
Policy Entropy: 3.76537
Value Function Loss: 0.02108

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.44791
Value Function Update Magnitude: 0.51037

Collected Steps per Second: 22,746.75321
Overall Steps per Second: 10,682.56677

Timestep Collection Time: 2.19917
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68277

Cumulative Model Updates: 158,600
Cumulative Timesteps: 1,322,497,352

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,801.14141
Policy Entropy: 3.74588
Value Function Loss: 0.02110

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.45140
Value Function Update Magnitude: 0.48356

Collected Steps per Second: 22,628.25084
Overall Steps per Second: 10,799.78890

Timestep Collection Time: 2.21060
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.63176

Cumulative Model Updates: 158,606
Cumulative Timesteps: 1,322,547,374

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1322547374...
Checkpoint 1322547374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,246.89839
Policy Entropy: 3.75036
Value Function Loss: 0.02027

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.43368
Value Function Update Magnitude: 0.40948

Collected Steps per Second: 22,759.65349
Overall Steps per Second: 10,691.52669

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67810

Cumulative Model Updates: 158,612
Cumulative Timesteps: 1,322,597,390

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,246.89839
Policy Entropy: 3.73020
Value Function Loss: 0.01873

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.42842
Value Function Update Magnitude: 0.40681

Collected Steps per Second: 21,798.48342
Overall Steps per Second: 10,682.18013

Timestep Collection Time: 2.29420
Timestep Consumption Time: 2.38743
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.68163

Cumulative Model Updates: 158,618
Cumulative Timesteps: 1,322,647,400

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1322647400...
Checkpoint 1322647400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,570.24002
Policy Entropy: 3.73781
Value Function Loss: 0.01822

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.43266
Value Function Update Magnitude: 0.45685

Collected Steps per Second: 21,596.78697
Overall Steps per Second: 10,662.57281

Timestep Collection Time: 2.31664
Timestep Consumption Time: 2.37566
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.69230

Cumulative Model Updates: 158,624
Cumulative Timesteps: 1,322,697,432

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,108.37895
Policy Entropy: 3.73553
Value Function Loss: 0.01890

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.44612
Value Function Update Magnitude: 0.59533

Collected Steps per Second: 21,521.91681
Overall Steps per Second: 10,584.79232

Timestep Collection Time: 2.32405
Timestep Consumption Time: 2.40141
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.72546

Cumulative Model Updates: 158,630
Cumulative Timesteps: 1,322,747,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1322747450...
Checkpoint 1322747450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,030.14558
Policy Entropy: 3.75158
Value Function Loss: 0.01905

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.46516
Value Function Update Magnitude: 0.73327

Collected Steps per Second: 22,005.93510
Overall Steps per Second: 10,699.42341

Timestep Collection Time: 2.27275
Timestep Consumption Time: 2.40171
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.67446

Cumulative Model Updates: 158,636
Cumulative Timesteps: 1,322,797,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,030.14558
Policy Entropy: 3.74764
Value Function Loss: 0.01725

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.45640
Value Function Update Magnitude: 0.73168

Collected Steps per Second: 22,766.10705
Overall Steps per Second: 10,871.84709

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.40308
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.59959

Cumulative Model Updates: 158,642
Cumulative Timesteps: 1,322,847,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1322847470...
Checkpoint 1322847470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,868.95085
Policy Entropy: 3.74710
Value Function Loss: 0.01703

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.44851
Value Function Update Magnitude: 0.69902

Collected Steps per Second: 22,742.48605
Overall Steps per Second: 10,698.35017

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.47549
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.67437

Cumulative Model Updates: 158,648
Cumulative Timesteps: 1,322,897,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,923.95657
Policy Entropy: 3.75443
Value Function Loss: 0.01802

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12122
Policy Update Magnitude: 0.43987
Value Function Update Magnitude: 0.65690

Collected Steps per Second: 22,372.91180
Overall Steps per Second: 10,601.61483

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.71758

Cumulative Model Updates: 158,654
Cumulative Timesteps: 1,322,947,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1322947492...
Checkpoint 1322947492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,480.87990
Policy Entropy: 3.76421
Value Function Loss: 0.02312

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.48178
Value Function Update Magnitude: 0.70481

Collected Steps per Second: 22,721.15139
Overall Steps per Second: 10,848.96727

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.40853
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.60947

Cumulative Model Updates: 158,660
Cumulative Timesteps: 1,322,997,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,557.53119
Policy Entropy: 3.77463
Value Function Loss: 0.02447

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.53887
Value Function Update Magnitude: 0.81910

Collected Steps per Second: 22,546.84841
Overall Steps per Second: 10,646.15582

Timestep Collection Time: 2.21902
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.69954

Cumulative Model Updates: 158,666
Cumulative Timesteps: 1,323,047,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1323047532...
Checkpoint 1323047532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.41549
Policy Entropy: 3.78101
Value Function Loss: 0.02352

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.53597
Value Function Update Magnitude: 0.76672

Collected Steps per Second: 22,563.07711
Overall Steps per Second: 10,639.62149

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69942

Cumulative Model Updates: 158,672
Cumulative Timesteps: 1,323,097,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.41549
Policy Entropy: 3.77221
Value Function Loss: 0.02033

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.49202
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 20,964.25954
Overall Steps per Second: 10,399.94721

Timestep Collection Time: 2.38597
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.80964

Cumulative Model Updates: 158,678
Cumulative Timesteps: 1,323,147,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1323147552...
Checkpoint 1323147552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,115.41549
Policy Entropy: 3.76517
Value Function Loss: 0.01556

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.40458
Value Function Update Magnitude: 0.40013

Collected Steps per Second: 22,127.39391
Overall Steps per Second: 10,609.88934

Timestep Collection Time: 2.25973
Timestep Consumption Time: 2.45304
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.71277

Cumulative Model Updates: 158,684
Cumulative Timesteps: 1,323,197,554

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,130.08990
Policy Entropy: 3.75206
Value Function Loss: 0.01476

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.33878
Value Function Update Magnitude: 0.33645

Collected Steps per Second: 21,801.19872
Overall Steps per Second: 10,615.11618

Timestep Collection Time: 2.29400
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.71139

Cumulative Model Updates: 158,690
Cumulative Timesteps: 1,323,247,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1323247566...
Checkpoint 1323247566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,146.64061
Policy Entropy: 3.76289
Value Function Loss: 0.01634

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.34054
Value Function Update Magnitude: 0.41715

Collected Steps per Second: 22,083.93077
Overall Steps per Second: 10,824.23090

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.35593
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.62074

Cumulative Model Updates: 158,696
Cumulative Timesteps: 1,323,297,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,922.57107
Policy Entropy: 3.77392
Value Function Loss: 0.01940

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13459
Policy Update Magnitude: 0.40126
Value Function Update Magnitude: 0.56518

Collected Steps per Second: 21,762.27606
Overall Steps per Second: 10,592.26618

Timestep Collection Time: 2.29765
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.72061

Cumulative Model Updates: 158,702
Cumulative Timesteps: 1,323,347,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1323347584...
Checkpoint 1323347584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,836.21362
Policy Entropy: 3.78045
Value Function Loss: 0.01720

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.44777
Value Function Update Magnitude: 0.63948

Collected Steps per Second: 22,269.74490
Overall Steps per Second: 10,573.23254

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.73138

Cumulative Model Updates: 158,708
Cumulative Timesteps: 1,323,397,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,597.17870
Policy Entropy: 3.76250
Value Function Loss: 0.01711

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.44523
Value Function Update Magnitude: 0.60714

Collected Steps per Second: 22,897.01329
Overall Steps per Second: 10,896.41795

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.40574
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.59013

Cumulative Model Updates: 158,714
Cumulative Timesteps: 1,323,447,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1323447626...
Checkpoint 1323447626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,120.74955
Policy Entropy: 3.75296
Value Function Loss: 0.01570

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.42317
Value Function Update Magnitude: 0.47688

Collected Steps per Second: 22,331.52357
Overall Steps per Second: 10,690.92325

Timestep Collection Time: 2.23988
Timestep Consumption Time: 2.43885
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.67874

Cumulative Model Updates: 158,720
Cumulative Timesteps: 1,323,497,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452,573.01856
Policy Entropy: 3.74320
Value Function Loss: 0.01915

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.45440
Value Function Update Magnitude: 0.45232

Collected Steps per Second: 22,522.09039
Overall Steps per Second: 10,602.97458

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.71622

Cumulative Model Updates: 158,726
Cumulative Timesteps: 1,323,547,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1323547652...
Checkpoint 1323547652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,211.68852
Policy Entropy: 3.76307
Value Function Loss: 0.01929

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.46471
Value Function Update Magnitude: 0.51525

Collected Steps per Second: 22,100.99861
Overall Steps per Second: 10,509.49663

Timestep Collection Time: 2.26252
Timestep Consumption Time: 2.49546
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.75798

Cumulative Model Updates: 158,732
Cumulative Timesteps: 1,323,597,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,126.14356
Policy Entropy: 3.76162
Value Function Loss: 0.02073

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.46228
Value Function Update Magnitude: 0.54364

Collected Steps per Second: 22,041.85689
Overall Steps per Second: 10,514.95748

Timestep Collection Time: 2.27059
Timestep Consumption Time: 2.48911
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.75970

Cumulative Model Updates: 158,738
Cumulative Timesteps: 1,323,647,704

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1323647704...
Checkpoint 1323647704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,558.44762
Policy Entropy: 3.78589
Value Function Loss: 0.01965

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.47442
Value Function Update Magnitude: 0.57003

Collected Steps per Second: 21,954.59460
Overall Steps per Second: 10,566.63601

Timestep Collection Time: 2.27788
Timestep Consumption Time: 2.45494
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.73282

Cumulative Model Updates: 158,744
Cumulative Timesteps: 1,323,697,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,786.50295
Policy Entropy: 3.77804
Value Function Loss: 0.01952

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.47443
Value Function Update Magnitude: 0.61244

Collected Steps per Second: 21,792.63364
Overall Steps per Second: 10,408.31690

Timestep Collection Time: 2.29527
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.80577

Cumulative Model Updates: 158,750
Cumulative Timesteps: 1,323,747,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1323747734...
Checkpoint 1323747734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,039.06542
Policy Entropy: 3.77610
Value Function Loss: 0.01896

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.46433
Value Function Update Magnitude: 0.51002

Collected Steps per Second: 22,131.54663
Overall Steps per Second: 10,679.42213

Timestep Collection Time: 2.25985
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.68321

Cumulative Model Updates: 158,756
Cumulative Timesteps: 1,323,797,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,085.34476
Policy Entropy: 3.77186
Value Function Loss: 0.02400

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.46159
Value Function Update Magnitude: 0.45944

Collected Steps per Second: 22,859.27250
Overall Steps per Second: 10,625.53939

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.70809

Cumulative Model Updates: 158,762
Cumulative Timesteps: 1,323,847,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1323847774...
Checkpoint 1323847774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,224.31239
Policy Entropy: 3.77461
Value Function Loss: 0.02410

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12501
Policy Update Magnitude: 0.51826
Value Function Update Magnitude: 0.48230

Collected Steps per Second: 22,809.67894
Overall Steps per Second: 10,839.13666

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.42193
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.61494

Cumulative Model Updates: 158,768
Cumulative Timesteps: 1,323,897,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,312.89880
Policy Entropy: 3.78264
Value Function Loss: 0.02638

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11896
Policy Update Magnitude: 0.52514
Value Function Update Magnitude: 0.45425

Collected Steps per Second: 22,686.77036
Overall Steps per Second: 10,638.94021

Timestep Collection Time: 2.20419
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.70028

Cumulative Model Updates: 158,774
Cumulative Timesteps: 1,323,947,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1323947802...
Checkpoint 1323947802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,850.30941
Policy Entropy: 3.78028
Value Function Loss: 0.02202

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12199
Policy Update Magnitude: 0.48684
Value Function Update Magnitude: 0.42836

Collected Steps per Second: 22,518.71625
Overall Steps per Second: 10,614.91808

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.71111

Cumulative Model Updates: 158,780
Cumulative Timesteps: 1,323,997,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,850.30941
Policy Entropy: 3.75782
Value Function Loss: 0.02154

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.46941
Value Function Update Magnitude: 0.41455

Collected Steps per Second: 22,714.50508
Overall Steps per Second: 10,827.70172

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.61889

Cumulative Model Updates: 158,786
Cumulative Timesteps: 1,324,047,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1324047822...
Checkpoint 1324047822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,850.30941
Policy Entropy: 3.74557
Value Function Loss: 0.01995

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.48981
Value Function Update Magnitude: 0.38657

Collected Steps per Second: 22,093.93124
Overall Steps per Second: 10,705.44677

Timestep Collection Time: 2.26352
Timestep Consumption Time: 2.40794
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67145

Cumulative Model Updates: 158,792
Cumulative Timesteps: 1,324,097,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,123.12597
Policy Entropy: 3.74090
Value Function Loss: 0.02154

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.48873
Value Function Update Magnitude: 0.40019

Collected Steps per Second: 21,369.54384
Overall Steps per Second: 10,549.96414

Timestep Collection Time: 2.34015
Timestep Consumption Time: 2.39996
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.74011

Cumulative Model Updates: 158,798
Cumulative Timesteps: 1,324,147,840

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1324147840...
Checkpoint 1324147840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,795.91217
Policy Entropy: 3.76030
Value Function Loss: 0.02009

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.48002
Value Function Update Magnitude: 0.48425

Collected Steps per Second: 21,744.52926
Overall Steps per Second: 10,472.45135

Timestep Collection Time: 2.29961
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.77481

Cumulative Model Updates: 158,804
Cumulative Timesteps: 1,324,197,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,795.91217
Policy Entropy: 3.75510
Value Function Loss: 0.02018

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.45870
Value Function Update Magnitude: 0.44353

Collected Steps per Second: 22,624.33306
Overall Steps per Second: 10,851.67533

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.39815
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.60869

Cumulative Model Updates: 158,810
Cumulative Timesteps: 1,324,247,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1324247856...
Checkpoint 1324247856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,946.65603
Policy Entropy: 3.75407
Value Function Loss: 0.01853

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.42790
Value Function Update Magnitude: 0.38216

Collected Steps per Second: 22,582.76690
Overall Steps per Second: 10,721.91942

Timestep Collection Time: 2.21425
Timestep Consumption Time: 2.44946
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.66372

Cumulative Model Updates: 158,816
Cumulative Timesteps: 1,324,297,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,215.89699
Policy Entropy: 3.76050
Value Function Loss: 0.01871

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.40238
Value Function Update Magnitude: 0.39423

Collected Steps per Second: 22,776.67110
Overall Steps per Second: 10,802.48887

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63041

Cumulative Model Updates: 158,822
Cumulative Timesteps: 1,324,347,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1324347880...
Checkpoint 1324347880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 157,215.89699
Policy Entropy: 3.75775
Value Function Loss: 0.01697

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.37978
Value Function Update Magnitude: 0.41513

Collected Steps per Second: 22,592.31171
Overall Steps per Second: 10,683.86566

Timestep Collection Time: 2.21394
Timestep Consumption Time: 2.46770
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.68164

Cumulative Model Updates: 158,828
Cumulative Timesteps: 1,324,397,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,016.20050
Policy Entropy: 3.76742
Value Function Loss: 0.01602

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.35164
Value Function Update Magnitude: 0.46539

Collected Steps per Second: 22,755.30950
Overall Steps per Second: 10,711.22697

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.66987

Cumulative Model Updates: 158,834
Cumulative Timesteps: 1,324,447,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1324447918...
Checkpoint 1324447918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 147,521.44454
Policy Entropy: 3.75677
Value Function Loss: 0.01683

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.35821
Value Function Update Magnitude: 0.44924

Collected Steps per Second: 22,275.56857
Overall Steps per Second: 10,610.76143

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.46897
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.71484

Cumulative Model Updates: 158,840
Cumulative Timesteps: 1,324,497,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,437.47913
Policy Entropy: 3.77826
Value Function Loss: 0.01736

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.38473
Value Function Update Magnitude: 0.56434

Collected Steps per Second: 22,585.12786
Overall Steps per Second: 10,737.72882

Timestep Collection Time: 2.21447
Timestep Consumption Time: 2.44332
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.65778

Cumulative Model Updates: 158,846
Cumulative Timesteps: 1,324,547,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1324547960...
Checkpoint 1324547960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,352.75503
Policy Entropy: 3.76718
Value Function Loss: 0.01740

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.39030
Value Function Update Magnitude: 0.59649

Collected Steps per Second: 22,352.33080
Overall Steps per Second: 10,615.16160

Timestep Collection Time: 2.23798
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.71250

Cumulative Model Updates: 158,852
Cumulative Timesteps: 1,324,597,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,352.75503
Policy Entropy: 3.75822
Value Function Loss: 0.01566

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.37542
Value Function Update Magnitude: 0.54696

Collected Steps per Second: 21,579.78193
Overall Steps per Second: 10,578.77375

Timestep Collection Time: 2.31726
Timestep Consumption Time: 2.40975
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.72701

Cumulative Model Updates: 158,858
Cumulative Timesteps: 1,324,647,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1324647990...
Checkpoint 1324647990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,352.75503
Policy Entropy: 3.73844
Value Function Loss: 0.01538

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.35951
Value Function Update Magnitude: 0.46585

Collected Steps per Second: 21,453.72974
Overall Steps per Second: 10,545.04926

Timestep Collection Time: 2.33144
Timestep Consumption Time: 2.41183
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.74327

Cumulative Model Updates: 158,864
Cumulative Timesteps: 1,324,698,008

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,352.75503
Policy Entropy: 3.73009
Value Function Loss: 0.01664

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11740
Policy Update Magnitude: 0.37497
Value Function Update Magnitude: 0.36888

Collected Steps per Second: 21,580.90973
Overall Steps per Second: 10,436.19754

Timestep Collection Time: 2.31751
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.79236

Cumulative Model Updates: 158,870
Cumulative Timesteps: 1,324,748,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1324748022...
Checkpoint 1324748022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,436.96659
Policy Entropy: 3.74148
Value Function Loss: 0.01596

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.39741
Value Function Update Magnitude: 0.35388

Collected Steps per Second: 22,341.05519
Overall Steps per Second: 10,663.36979

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.45249
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.69195

Cumulative Model Updates: 158,876
Cumulative Timesteps: 1,324,798,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,593.21819
Policy Entropy: 3.75577
Value Function Loss: 0.01639

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.42218
Value Function Update Magnitude: 0.46484

Collected Steps per Second: 22,847.55587
Overall Steps per Second: 10,825.18189

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.43073
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.61941

Cumulative Model Updates: 158,882
Cumulative Timesteps: 1,324,848,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1324848060...
Checkpoint 1324848060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,793.66268
Policy Entropy: 3.77811
Value Function Loss: 0.01722

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12363
Policy Update Magnitude: 0.41885
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 22,672.78341
Overall Steps per Second: 10,687.81530

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.67916

Cumulative Model Updates: 158,888
Cumulative Timesteps: 1,324,898,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,320.94508
Policy Entropy: 3.79073
Value Function Loss: 0.02092

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.42944
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 22,821.90735
Overall Steps per Second: 10,851.93081

Timestep Collection Time: 2.19149
Timestep Consumption Time: 2.41727
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.60877

Cumulative Model Updates: 158,894
Cumulative Timesteps: 1,324,948,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1324948084...
Checkpoint 1324948084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,653.59586
Policy Entropy: 3.81135
Value Function Loss: 0.02419

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.46438
Value Function Update Magnitude: 0.56172

Collected Steps per Second: 23,115.97759
Overall Steps per Second: 10,754.44142

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.65129

Cumulative Model Updates: 158,900
Cumulative Timesteps: 1,324,998,106

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,305.41516
Policy Entropy: 3.80972
Value Function Loss: 0.02619

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.44145
Value Function Update Magnitude: 0.50927

Collected Steps per Second: 21,510.19551
Overall Steps per Second: 10,405.45053

Timestep Collection Time: 2.32494
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.80614

Cumulative Model Updates: 158,906
Cumulative Timesteps: 1,325,048,116

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1325048116...
Checkpoint 1325048116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,347.98934
Policy Entropy: 3.80025
Value Function Loss: 0.02374

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.42633
Value Function Update Magnitude: 0.52124

Collected Steps per Second: 22,595.67347
Overall Steps per Second: 10,652.48472

Timestep Collection Time: 2.21281
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.69374

Cumulative Model Updates: 158,912
Cumulative Timesteps: 1,325,098,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,087.15435
Policy Entropy: 3.77687
Value Function Loss: 0.02130

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 0.42732
Value Function Update Magnitude: 0.51095

Collected Steps per Second: 22,124.67856
Overall Steps per Second: 10,507.65342

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.76072

Cumulative Model Updates: 158,918
Cumulative Timesteps: 1,325,148,140

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1325148140...
Checkpoint 1325148140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,656.42950
Policy Entropy: 3.76475
Value Function Loss: 0.01776

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.41483
Value Function Update Magnitude: 0.50607

Collected Steps per Second: 22,064.88733
Overall Steps per Second: 10,577.98780

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.73020

Cumulative Model Updates: 158,924
Cumulative Timesteps: 1,325,198,176

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,636.14211
Policy Entropy: 3.75917
Value Function Loss: 0.02055

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.41404
Value Function Update Magnitude: 0.41530

Collected Steps per Second: 21,806.93927
Overall Steps per Second: 10,475.35044

Timestep Collection Time: 2.29395
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.77540

Cumulative Model Updates: 158,930
Cumulative Timesteps: 1,325,248,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1325248200...
Checkpoint 1325248200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,881.50622
Policy Entropy: 3.77452
Value Function Loss: 0.02204

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.49421
Value Function Update Magnitude: 0.47143

Collected Steps per Second: 22,440.71566
Overall Steps per Second: 10,655.60839

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.69368

Cumulative Model Updates: 158,936
Cumulative Timesteps: 1,325,298,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,727.87533
Policy Entropy: 3.80780
Value Function Loss: 0.02539

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11968
Policy Update Magnitude: 0.53457
Value Function Update Magnitude: 0.54473

Collected Steps per Second: 22,063.44559
Overall Steps per Second: 10,580.28059

Timestep Collection Time: 2.26710
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.72766

Cumulative Model Updates: 158,942
Cumulative Timesteps: 1,325,348,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1325348234...
Checkpoint 1325348234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,250.19478
Policy Entropy: 3.83273
Value Function Loss: 0.02354

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.51852
Value Function Update Magnitude: 0.55934

Collected Steps per Second: 22,635.07119
Overall Steps per Second: 10,670.05570

Timestep Collection Time: 2.21038
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.68901

Cumulative Model Updates: 158,948
Cumulative Timesteps: 1,325,398,266

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,229.52123
Policy Entropy: 3.81903
Value Function Loss: 0.02498

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.47802
Value Function Update Magnitude: 0.55446

Collected Steps per Second: 22,805.55476
Overall Steps per Second: 10,748.90347

Timestep Collection Time: 2.19289
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.65257

Cumulative Model Updates: 158,954
Cumulative Timesteps: 1,325,448,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1325448276...
Checkpoint 1325448276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,062.59569
Policy Entropy: 3.79809
Value Function Loss: 0.02712

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.53096

Collected Steps per Second: 22,736.13314
Overall Steps per Second: 10,634.72036

Timestep Collection Time: 2.20029
Timestep Consumption Time: 2.50374
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.70403

Cumulative Model Updates: 158,960
Cumulative Timesteps: 1,325,498,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,786.02845
Policy Entropy: 3.76664
Value Function Loss: 0.02944

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.59566

Collected Steps per Second: 22,621.36043
Overall Steps per Second: 10,833.50519

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.40732
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.61974

Cumulative Model Updates: 158,966
Cumulative Timesteps: 1,325,548,350

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1325548350...
Checkpoint 1325548350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,297.29844
Policy Entropy: 3.75820
Value Function Loss: 0.02806

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.56870
Value Function Update Magnitude: 0.59164

Collected Steps per Second: 22,615.87584
Overall Steps per Second: 10,692.25031

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.67778

Cumulative Model Updates: 158,972
Cumulative Timesteps: 1,325,598,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,189.78036
Policy Entropy: 3.75506
Value Function Loss: 0.02582

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.14250
Policy Update Magnitude: 0.52342
Value Function Update Magnitude: 0.54368

Collected Steps per Second: 22,528.03289
Overall Steps per Second: 10,549.82437

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.52036
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.74017

Cumulative Model Updates: 158,978
Cumulative Timesteps: 1,325,648,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1325648374...
Checkpoint 1325648374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,758.43828
Policy Entropy: 3.74833
Value Function Loss: 0.02201

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.47269
Value Function Update Magnitude: 0.50092

Collected Steps per Second: 22,712.32259
Overall Steps per Second: 10,684.35670

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.47859
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.68030

Cumulative Model Updates: 158,984
Cumulative Timesteps: 1,325,698,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,445.86825
Policy Entropy: 3.75283
Value Function Loss: 0.01958

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.43166
Value Function Update Magnitude: 0.54975

Collected Steps per Second: 22,300.59363
Overall Steps per Second: 10,725.07122

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.66291

Cumulative Model Updates: 158,990
Cumulative Timesteps: 1,325,748,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1325748390...
Checkpoint 1325748390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,445.86825
Policy Entropy: 3.74965
Value Function Loss: 0.01663

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.39709
Value Function Update Magnitude: 0.55210

Collected Steps per Second: 22,158.16545
Overall Steps per Second: 10,707.13774

Timestep Collection Time: 2.25741
Timestep Consumption Time: 2.41424
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.67165

Cumulative Model Updates: 158,996
Cumulative Timesteps: 1,325,798,410

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,024.36207
Policy Entropy: 3.75150
Value Function Loss: 0.01621

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.37686
Value Function Update Magnitude: 0.47416

Collected Steps per Second: 22,355.92635
Overall Steps per Second: 10,591.35668

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.48538
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.72291

Cumulative Model Updates: 159,002
Cumulative Timesteps: 1,325,848,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1325848432...
Checkpoint 1325848432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,623.01936
Policy Entropy: 3.74907
Value Function Loss: 0.01692

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.40628
Value Function Update Magnitude: 0.52490

Collected Steps per Second: 22,370.08496
Overall Steps per Second: 10,583.00290

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.49033
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.72626

Cumulative Model Updates: 159,008
Cumulative Timesteps: 1,325,898,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,714.61534
Policy Entropy: 3.76004
Value Function Loss: 0.01780

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12496
Policy Update Magnitude: 0.43978
Value Function Update Magnitude: 0.64644

Collected Steps per Second: 22,796.41528
Overall Steps per Second: 10,747.80452

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.45938
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.65323

Cumulative Model Updates: 159,014
Cumulative Timesteps: 1,325,948,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1325948462...
Checkpoint 1325948462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.95278
Policy Entropy: 3.77537
Value Function Loss: 0.01718

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.42829
Value Function Update Magnitude: 0.64114

Collected Steps per Second: 22,567.87823
Overall Steps per Second: 10,654.51371

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.69491

Cumulative Model Updates: 159,020
Cumulative Timesteps: 1,325,998,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.95278
Policy Entropy: 3.76694
Value Function Loss: 0.01678

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.41411
Value Function Update Magnitude: 0.60740

Collected Steps per Second: 22,907.94882
Overall Steps per Second: 10,740.02054

Timestep Collection Time: 2.18274
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.65567

Cumulative Model Updates: 159,026
Cumulative Timesteps: 1,326,048,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1326048486...
Checkpoint 1326048486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,032.95278
Policy Entropy: 3.74551
Value Function Loss: 0.01648

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.41183
Value Function Update Magnitude: 0.57825

Collected Steps per Second: 22,434.07467
Overall Steps per Second: 10,789.96653

Timestep Collection Time: 2.22911
Timestep Consumption Time: 2.40557
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.63468

Cumulative Model Updates: 159,032
Cumulative Timesteps: 1,326,098,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,253.36656
Policy Entropy: 3.75465
Value Function Loss: 0.01631

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12786
Policy Update Magnitude: 0.39437
Value Function Update Magnitude: 0.54759

Collected Steps per Second: 22,909.67746
Overall Steps per Second: 10,719.77237

Timestep Collection Time: 2.18292
Timestep Consumption Time: 2.48229
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.66521

Cumulative Model Updates: 159,038
Cumulative Timesteps: 1,326,148,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1326148504...
Checkpoint 1326148504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,732.21916
Policy Entropy: 3.77271
Value Function Loss: 0.01460

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.36241
Value Function Update Magnitude: 0.46745

Collected Steps per Second: 23,100.05959
Overall Steps per Second: 10,935.83696

Timestep Collection Time: 2.16484
Timestep Consumption Time: 2.40801
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.57286

Cumulative Model Updates: 159,044
Cumulative Timesteps: 1,326,198,512

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,584.45864
Policy Entropy: 3.76634
Value Function Loss: 0.01501

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.35917
Value Function Update Magnitude: 0.42141

Collected Steps per Second: 22,469.43724
Overall Steps per Second: 10,629.23156

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.48005
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.70646

Cumulative Model Updates: 159,050
Cumulative Timesteps: 1,326,248,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1326248538...
Checkpoint 1326248538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,923.94761
Policy Entropy: 3.73680
Value Function Loss: 0.01696

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.43085
Value Function Update Magnitude: 0.47932

Collected Steps per Second: 22,317.12419
Overall Steps per Second: 10,580.40572

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.48737
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.72969

Cumulative Model Updates: 159,056
Cumulative Timesteps: 1,326,298,580

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,526.52021
Policy Entropy: 3.72794
Value Function Loss: 0.02026

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.48839
Value Function Update Magnitude: 0.48874

Collected Steps per Second: 22,251.99571
Overall Steps per Second: 10,717.69325

Timestep Collection Time: 2.24861
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.66854

Cumulative Model Updates: 159,062
Cumulative Timesteps: 1,326,348,616

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1326348616...
Checkpoint 1326348616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,693.36204
Policy Entropy: 3.73614
Value Function Loss: 0.01912

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.50293
Value Function Update Magnitude: 0.46681

Collected Steps per Second: 22,006.85695
Overall Steps per Second: 10,627.46690

Timestep Collection Time: 2.27311
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.70705

Cumulative Model Updates: 159,068
Cumulative Timesteps: 1,326,398,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247,605.91158
Policy Entropy: 3.74953
Value Function Loss: 0.01997

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12086
Policy Update Magnitude: 0.46965
Value Function Update Magnitude: 0.42834

Collected Steps per Second: 22,755.18871
Overall Steps per Second: 10,526.06345

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.55343
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.75125

Cumulative Model Updates: 159,074
Cumulative Timesteps: 1,326,448,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1326448652...
Checkpoint 1326448652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,547.43787
Policy Entropy: 3.75205
Value Function Loss: 0.01882

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.47230
Value Function Update Magnitude: 0.50973

Collected Steps per Second: 22,716.10514
Overall Steps per Second: 10,656.21340

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.69360

Cumulative Model Updates: 159,080
Cumulative Timesteps: 1,326,498,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,124.66069
Policy Entropy: 3.75316
Value Function Loss: 0.02415

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.49071
Value Function Update Magnitude: 0.58994

Collected Steps per Second: 22,975.15803
Overall Steps per Second: 10,864.11833

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.42701
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60415

Cumulative Model Updates: 159,086
Cumulative Timesteps: 1,326,548,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1326548688...
Checkpoint 1326548688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,213.94575
Policy Entropy: 3.77854
Value Function Loss: 0.02387

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.48134
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 22,433.97608
Overall Steps per Second: 10,630.28422

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.70580

Cumulative Model Updates: 159,092
Cumulative Timesteps: 1,326,598,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,145.22886
Policy Entropy: 3.78303
Value Function Loss: 0.02641

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.52639
Value Function Update Magnitude: 0.56369

Collected Steps per Second: 22,572.59224
Overall Steps per Second: 10,635.87932

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.70257

Cumulative Model Updates: 159,098
Cumulative Timesteps: 1,326,648,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1326648728...
Checkpoint 1326648728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,727.81946
Policy Entropy: 3.78682
Value Function Loss: 0.02354

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.55666
Value Function Update Magnitude: 0.54415

Collected Steps per Second: 22,781.08203
Overall Steps per Second: 10,851.61249

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.41358
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.60908

Cumulative Model Updates: 159,104
Cumulative Timesteps: 1,326,698,744

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,550.63386
Policy Entropy: 3.77910
Value Function Loss: 0.02694

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.52134
Value Function Update Magnitude: 0.51711

Collected Steps per Second: 22,281.49210
Overall Steps per Second: 10,551.79454

Timestep Collection Time: 2.24581
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.74232

Cumulative Model Updates: 159,110
Cumulative Timesteps: 1,326,748,784

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1326748784...
Checkpoint 1326748784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,571.44605
Policy Entropy: 3.79895
Value Function Loss: 0.02527

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.50324
Value Function Update Magnitude: 0.53380

Collected Steps per Second: 22,426.37321
Overall Steps per Second: 10,626.02881

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.47631
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.70618

Cumulative Model Updates: 159,116
Cumulative Timesteps: 1,326,798,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,499.50629
Policy Entropy: 3.81505
Value Function Loss: 0.02589

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11857
Policy Update Magnitude: 0.52130
Value Function Update Magnitude: 0.59758

Collected Steps per Second: 21,655.83290
Overall Steps per Second: 10,632.26720

Timestep Collection Time: 2.30940
Timestep Consumption Time: 2.39439
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70379

Cumulative Model Updates: 159,122
Cumulative Timesteps: 1,326,848,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1326848804...
Checkpoint 1326848804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,840.31845
Policy Entropy: 3.82431
Value Function Loss: 0.02546

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.50661
Value Function Update Magnitude: 0.60486

Collected Steps per Second: 21,848.21656
Overall Steps per Second: 10,834.83246

Timestep Collection Time: 2.28961
Timestep Consumption Time: 2.32735
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.61696

Cumulative Model Updates: 159,128
Cumulative Timesteps: 1,326,898,828

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,060.18279
Policy Entropy: 3.81584
Value Function Loss: 0.02489

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.48378
Value Function Update Magnitude: 0.52755

Collected Steps per Second: 21,622.65162
Overall Steps per Second: 10,447.93768

Timestep Collection Time: 2.31331
Timestep Consumption Time: 2.47423
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.78755

Cumulative Model Updates: 159,134
Cumulative Timesteps: 1,326,948,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1326948848...
Checkpoint 1326948848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,950.85135
Policy Entropy: 3.80936
Value Function Loss: 0.02080

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11847
Policy Update Magnitude: 0.45869
Value Function Update Magnitude: 0.51130

Collected Steps per Second: 21,946.54072
Overall Steps per Second: 10,712.54421

Timestep Collection Time: 2.27863
Timestep Consumption Time: 2.38954
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.66817

Cumulative Model Updates: 159,140
Cumulative Timesteps: 1,326,998,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,735.65409
Policy Entropy: 3.79265
Value Function Loss: 0.02135

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.43423
Value Function Update Magnitude: 0.50977

Collected Steps per Second: 22,163.30831
Overall Steps per Second: 10,578.52383

Timestep Collection Time: 2.25715
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.72902

Cumulative Model Updates: 159,146
Cumulative Timesteps: 1,327,048,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1327048882...
Checkpoint 1327048882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,127.08295
Policy Entropy: 3.79760
Value Function Loss: 0.01895

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11844
Policy Update Magnitude: 0.49767
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,971.88138
Overall Steps per Second: 10,948.39323

Timestep Collection Time: 2.17684
Timestep Consumption Time: 2.39059
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.56743

Cumulative Model Updates: 159,152
Cumulative Timesteps: 1,327,098,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,743.58430
Policy Entropy: 3.79093
Value Function Loss: 0.02205

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.11439
Policy Update Magnitude: 0.53370
Value Function Update Magnitude: 0.72111

Collected Steps per Second: 22,729.18382
Overall Steps per Second: 10,867.58259

Timestep Collection Time: 2.20008
Timestep Consumption Time: 2.40131
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.60139

Cumulative Model Updates: 159,158
Cumulative Timesteps: 1,327,148,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1327148894...
Checkpoint 1327148894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,309.61776
Policy Entropy: 3.80771
Value Function Loss: 0.02395

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.55997
Value Function Update Magnitude: 0.65734

Collected Steps per Second: 21,798.54886
Overall Steps per Second: 10,665.36925

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.39635
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.69201

Cumulative Model Updates: 159,164
Cumulative Timesteps: 1,327,198,936

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,848.81343
Policy Entropy: 3.81414
Value Function Loss: 0.03157

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.62881
Value Function Update Magnitude: 0.56806

Collected Steps per Second: 22,217.42575
Overall Steps per Second: 10,622.75018

Timestep Collection Time: 2.25166
Timestep Consumption Time: 2.45767
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70933

Cumulative Model Updates: 159,170
Cumulative Timesteps: 1,327,248,962

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1327248962...
Checkpoint 1327248962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,135.62356
Policy Entropy: 3.83432
Value Function Loss: 0.03187

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.63623
Value Function Update Magnitude: 0.56831

Collected Steps per Second: 22,552.20149
Overall Steps per Second: 10,647.25341

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.69886

Cumulative Model Updates: 159,176
Cumulative Timesteps: 1,327,298,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,273.88019
Policy Entropy: 3.82361
Value Function Loss: 0.03283

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.60519
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 22,631.65517
Overall Steps per Second: 10,750.09875

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.44212
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.65168

Cumulative Model Updates: 159,182
Cumulative Timesteps: 1,327,348,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1327348998...
Checkpoint 1327348998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,310.93628
Policy Entropy: 3.80451
Value Function Loss: 0.02425

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.50668

Collected Steps per Second: 22,029.20235
Overall Steps per Second: 10,589.82935

Timestep Collection Time: 2.26971
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.72151

Cumulative Model Updates: 159,188
Cumulative Timesteps: 1,327,398,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,178.38177
Policy Entropy: 3.78323
Value Function Loss: 0.02654

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.54882
Value Function Update Magnitude: 0.72949

Collected Steps per Second: 22,938.17943
Overall Steps per Second: 10,697.24909

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.67503

Cumulative Model Updates: 159,194
Cumulative Timesteps: 1,327,449,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1327449008...
Checkpoint 1327449008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,007.32506
Policy Entropy: 3.80116
Value Function Loss: 0.02636

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13577
Policy Update Magnitude: 0.61799
Value Function Update Magnitude: 0.88311

Collected Steps per Second: 22,903.55262
Overall Steps per Second: 10,916.05507

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.39801
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.58169

Cumulative Model Updates: 159,200
Cumulative Timesteps: 1,327,499,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,802.98566
Policy Entropy: 3.82876
Value Function Loss: 0.03653

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.68358
Value Function Update Magnitude: 0.77025

Collected Steps per Second: 22,729.86475
Overall Steps per Second: 10,849.00749

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.41012
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61093

Cumulative Model Updates: 159,206
Cumulative Timesteps: 1,327,549,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1327549046...
Checkpoint 1327549046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.74947
Policy Entropy: 3.86204
Value Function Loss: 0.03231

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.72372
Value Function Update Magnitude: 0.75221

Collected Steps per Second: 22,422.86654
Overall Steps per Second: 10,737.76758

Timestep Collection Time: 2.23067
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.65814

Cumulative Model Updates: 159,212
Cumulative Timesteps: 1,327,599,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,310.59884
Policy Entropy: 3.84010
Value Function Loss: 0.03830

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.69204
Value Function Update Magnitude: 0.79229

Collected Steps per Second: 22,634.36912
Overall Steps per Second: 10,666.75104

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.69028

Cumulative Model Updates: 159,218
Cumulative Timesteps: 1,327,649,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1327649094...
Checkpoint 1327649094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,990.81591
Policy Entropy: 3.81605
Value Function Loss: 0.03076

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.66210
Value Function Update Magnitude: 0.60244

Collected Steps per Second: 22,389.18829
Overall Steps per Second: 10,642.56650

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.46539
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69905

Cumulative Model Updates: 159,224
Cumulative Timesteps: 1,327,699,104

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.63057
Policy Entropy: 3.79857
Value Function Loss: 0.02962

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.65131
Value Function Update Magnitude: 0.48835

Collected Steps per Second: 22,214.53315
Overall Steps per Second: 10,688.06548

Timestep Collection Time: 2.25168
Timestep Consumption Time: 2.42831
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.67999

Cumulative Model Updates: 159,230
Cumulative Timesteps: 1,327,749,124

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1327749124...
Checkpoint 1327749124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,613.76259
Policy Entropy: 3.79474
Value Function Loss: 0.02394

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.60394
Value Function Update Magnitude: 0.47617

Collected Steps per Second: 22,284.90052
Overall Steps per Second: 10,635.65690

Timestep Collection Time: 2.24430
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.70248

Cumulative Model Updates: 159,236
Cumulative Timesteps: 1,327,799,138

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,802.68962
Policy Entropy: 3.79794
Value Function Loss: 0.02492

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.58670
Value Function Update Magnitude: 0.52018

Collected Steps per Second: 22,077.89857
Overall Steps per Second: 10,464.76631

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.77947

Cumulative Model Updates: 159,242
Cumulative Timesteps: 1,327,849,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1327849154...
Checkpoint 1327849154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,432.46825
Policy Entropy: 3.77948
Value Function Loss: 0.02438

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.17489
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.63331

Collected Steps per Second: 22,046.77250
Overall Steps per Second: 10,686.89415

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.27558
Total Iteration Time: 4.68031

Cumulative Model Updates: 159,248
Cumulative Timesteps: 1,327,899,172

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,063.14793
Policy Entropy: 3.76880
Value Function Loss: 0.02607

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.18613
Policy Update Magnitude: 0.50913
Value Function Update Magnitude: 0.68551

Collected Steps per Second: 22,602.16049
Overall Steps per Second: 10,527.75597

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.53798
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.75087

Cumulative Model Updates: 159,254
Cumulative Timesteps: 1,327,949,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1327949188...
Checkpoint 1327949188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,122.76275
Policy Entropy: 3.78917
Value Function Loss: 0.02262

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.14674
Policy Update Magnitude: 0.44764
Value Function Update Magnitude: 0.58340

Collected Steps per Second: 22,612.30211
Overall Steps per Second: 10,655.93485

Timestep Collection Time: 2.21260
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.69522

Cumulative Model Updates: 159,260
Cumulative Timesteps: 1,327,999,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,355.19355
Policy Entropy: 3.78680
Value Function Loss: 0.02305

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.41363
Value Function Update Magnitude: 0.48770

Collected Steps per Second: 22,981.57751
Overall Steps per Second: 10,789.15316

Timestep Collection Time: 2.17600
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.63503

Cumulative Model Updates: 159,266
Cumulative Timesteps: 1,328,049,228

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1328049228...
Checkpoint 1328049228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.71565
Policy Entropy: 3.80865
Value Function Loss: 0.01980

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.43402
Value Function Update Magnitude: 0.57532

Collected Steps per Second: 22,890.23819
Overall Steps per Second: 10,674.31923

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.68451

Cumulative Model Updates: 159,272
Cumulative Timesteps: 1,328,099,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,071.66455
Policy Entropy: 3.77713
Value Function Loss: 0.02086

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.44795
Value Function Update Magnitude: 0.65874

Collected Steps per Second: 23,136.06304
Overall Steps per Second: 10,923.70223

Timestep Collection Time: 2.16156
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.57812

Cumulative Model Updates: 159,278
Cumulative Timesteps: 1,328,149,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1328149242...
Checkpoint 1328149242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,531.50555
Policy Entropy: 3.78595
Value Function Loss: 0.01700

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.41844
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 22,566.45611
Overall Steps per Second: 10,594.50776

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.72301

Cumulative Model Updates: 159,284
Cumulative Timesteps: 1,328,199,280

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,776.28565
Policy Entropy: 3.75846
Value Function Loss: 0.01696

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.37199
Value Function Update Magnitude: 0.54480

Collected Steps per Second: 22,769.14149
Overall Steps per Second: 10,826.26633

Timestep Collection Time: 2.19675
Timestep Consumption Time: 2.42331
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.62006

Cumulative Model Updates: 159,290
Cumulative Timesteps: 1,328,249,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1328249298...
Checkpoint 1328249298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,021.91196
Policy Entropy: 3.77900
Value Function Loss: 0.01537

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.35473
Value Function Update Magnitude: 0.44792

Collected Steps per Second: 22,325.10650
Overall Steps per Second: 10,771.02188

Timestep Collection Time: 2.24008
Timestep Consumption Time: 2.40293
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.64301

Cumulative Model Updates: 159,296
Cumulative Timesteps: 1,328,299,308

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,432.51124
Policy Entropy: 3.77124
Value Function Loss: 0.01678

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.36071
Value Function Update Magnitude: 0.53686

Collected Steps per Second: 22,510.57403
Overall Steps per Second: 10,774.74906

Timestep Collection Time: 2.22162
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.64141

Cumulative Model Updates: 159,302
Cumulative Timesteps: 1,328,349,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1328349318...
Checkpoint 1328349318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,338.28725
Policy Entropy: 3.78331
Value Function Loss: 0.01775

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13808
Policy Update Magnitude: 0.40163
Value Function Update Magnitude: 0.64066

Collected Steps per Second: 22,134.59732
Overall Steps per Second: 10,679.49431

Timestep Collection Time: 2.25900
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.68206

Cumulative Model Updates: 159,308
Cumulative Timesteps: 1,328,399,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,860.80887
Policy Entropy: 3.77554
Value Function Loss: 0.02282

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.44261
Value Function Update Magnitude: 0.67547

Collected Steps per Second: 22,250.64807
Overall Steps per Second: 10,478.95518

Timestep Collection Time: 2.24749
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.77223

Cumulative Model Updates: 159,314
Cumulative Timesteps: 1,328,449,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1328449328...
Checkpoint 1328449328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,919.90662
Policy Entropy: 3.77862
Value Function Loss: 0.02537

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.49858
Value Function Update Magnitude: 0.69454

Collected Steps per Second: 22,829.51170
Overall Steps per Second: 10,672.43194

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.49502
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.68534

Cumulative Model Updates: 159,320
Cumulative Timesteps: 1,328,499,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,342.28035
Policy Entropy: 3.80485
Value Function Loss: 0.02564

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.53659
Value Function Update Magnitude: 0.80172

Collected Steps per Second: 22,823.65865
Overall Steps per Second: 10,814.06625

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62527

Cumulative Model Updates: 159,326
Cumulative Timesteps: 1,328,549,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1328549350...
Checkpoint 1328549350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,937.01027
Policy Entropy: 3.83352
Value Function Loss: 0.02555

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.50706
Value Function Update Magnitude: 0.71618

Collected Steps per Second: 22,555.91207
Overall Steps per Second: 10,702.65904

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.45512
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.67192

Cumulative Model Updates: 159,332
Cumulative Timesteps: 1,328,599,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,540.10795
Policy Entropy: 3.84524
Value Function Loss: 0.02350

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.47393
Value Function Update Magnitude: 0.82221

Collected Steps per Second: 22,875.38589
Overall Steps per Second: 10,832.04683

Timestep Collection Time: 2.18698
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.61852

Cumulative Model Updates: 159,338
Cumulative Timesteps: 1,328,649,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1328649380...
Checkpoint 1328649380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,284.49177
Policy Entropy: 3.84434
Value Function Loss: 0.02432

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.48249
Value Function Update Magnitude: 0.89230

Collected Steps per Second: 22,673.12776
Overall Steps per Second: 10,741.40387

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.65582

Cumulative Model Updates: 159,344
Cumulative Timesteps: 1,328,699,390

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,264.83864
Policy Entropy: 3.81558
Value Function Loss: 0.02163

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.47193
Value Function Update Magnitude: 0.76316

Collected Steps per Second: 22,884.69643
Overall Steps per Second: 10,915.59654

Timestep Collection Time: 2.18670
Timestep Consumption Time: 2.39775
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.58445

Cumulative Model Updates: 159,350
Cumulative Timesteps: 1,328,749,432

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1328749432...
Checkpoint 1328749432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,528.35034
Policy Entropy: 3.81222
Value Function Loss: 0.01858

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.45954
Value Function Update Magnitude: 0.72823

Collected Steps per Second: 22,219.43993
Overall Steps per Second: 10,620.54664

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.71049

Cumulative Model Updates: 159,356
Cumulative Timesteps: 1,328,799,460

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,810.44496
Policy Entropy: 3.78214
Value Function Loss: 0.01901

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.47228
Value Function Update Magnitude: 0.79725

Collected Steps per Second: 22,245.12470
Overall Steps per Second: 10,549.08756

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.74202

Cumulative Model Updates: 159,362
Cumulative Timesteps: 1,328,849,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1328849484...
Checkpoint 1328849484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,082.08914
Policy Entropy: 3.79714
Value Function Loss: 0.01834

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.51634
Value Function Update Magnitude: 0.83792

Collected Steps per Second: 22,192.82901
Overall Steps per Second: 10,582.48328

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.72573

Cumulative Model Updates: 159,368
Cumulative Timesteps: 1,328,899,494

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,288.16037
Policy Entropy: 3.80176
Value Function Loss: 0.02049

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.50020
Value Function Update Magnitude: 0.83828

Collected Steps per Second: 22,375.76950
Overall Steps per Second: 10,583.84246

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.72872

Cumulative Model Updates: 159,374
Cumulative Timesteps: 1,328,949,542

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1328949542...
Checkpoint 1328949542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,974.48609
Policy Entropy: 3.79949
Value Function Loss: 0.01974

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.48342
Value Function Update Magnitude: 0.82625

Collected Steps per Second: 22,652.45101
Overall Steps per Second: 10,584.32728

Timestep Collection Time: 2.20788
Timestep Consumption Time: 2.51740
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.72529

Cumulative Model Updates: 159,380
Cumulative Timesteps: 1,328,999,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,937.38068
Policy Entropy: 3.77378
Value Function Loss: 0.02126

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.47746
Value Function Update Magnitude: 0.82759

Collected Steps per Second: 22,776.60961
Overall Steps per Second: 10,799.94969

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.43510
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63095

Cumulative Model Updates: 159,386
Cumulative Timesteps: 1,329,049,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1329049570...
Checkpoint 1329049570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,228.83860
Policy Entropy: 3.79546
Value Function Loss: 0.02065

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.48755
Value Function Update Magnitude: 0.80586

Collected Steps per Second: 22,833.12603
Overall Steps per Second: 10,647.73411

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69828

Cumulative Model Updates: 159,392
Cumulative Timesteps: 1,329,099,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,937.24000
Policy Entropy: 3.81785
Value Function Loss: 0.02162

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11708
Policy Update Magnitude: 0.52980
Value Function Update Magnitude: 0.85200

Collected Steps per Second: 23,165.56957
Overall Steps per Second: 10,894.15535

Timestep Collection Time: 2.15863
Timestep Consumption Time: 2.43153
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.59017

Cumulative Model Updates: 159,398
Cumulative Timesteps: 1,329,149,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1329149602...
Checkpoint 1329149602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.10238
Policy Entropy: 3.83382
Value Function Loss: 0.02021

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.11568
Policy Update Magnitude: 0.55161
Value Function Update Magnitude: 0.79310

Collected Steps per Second: 22,530.30906
Overall Steps per Second: 10,614.14157

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.49166
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.71107

Cumulative Model Updates: 159,404
Cumulative Timesteps: 1,329,199,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,001.33530
Policy Entropy: 3.78529
Value Function Loss: 0.01940

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12161
Policy Update Magnitude: 0.52559
Value Function Update Magnitude: 0.73276

Collected Steps per Second: 22,807.51039
Overall Steps per Second: 10,693.09172

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.48385
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.67629

Cumulative Model Updates: 159,410
Cumulative Timesteps: 1,329,249,610

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1329249610...
Checkpoint 1329249610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,889.82041
Policy Entropy: 3.76044
Value Function Loss: 0.01664

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.47927
Value Function Update Magnitude: 0.64519

Collected Steps per Second: 22,403.54387
Overall Steps per Second: 10,655.58085

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.46187
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.69482

Cumulative Model Updates: 159,416
Cumulative Timesteps: 1,329,299,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,416.55705
Policy Entropy: 3.76486
Value Function Loss: 0.01498

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.42130
Value Function Update Magnitude: 0.54768

Collected Steps per Second: 22,557.24201
Overall Steps per Second: 10,706.65944

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.67018

Cumulative Model Updates: 159,422
Cumulative Timesteps: 1,329,349,638

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1329349638...
Checkpoint 1329349638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,054.51310
Policy Entropy: 3.77608
Value Function Loss: 0.01606

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.40516
Value Function Update Magnitude: 0.55076

Collected Steps per Second: 21,933.51715
Overall Steps per Second: 10,616.58052

Timestep Collection Time: 2.28053
Timestep Consumption Time: 2.43097
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.71150

Cumulative Model Updates: 159,428
Cumulative Timesteps: 1,329,399,658

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,195.20843
Policy Entropy: 3.78697
Value Function Loss: 0.01484

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.42583
Value Function Update Magnitude: 0.61753

Collected Steps per Second: 22,407.46246
Overall Steps per Second: 10,634.21974

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.70255

Cumulative Model Updates: 159,434
Cumulative Timesteps: 1,329,449,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1329449666...
Checkpoint 1329449666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,250.56009
Policy Entropy: 3.78886
Value Function Loss: 0.01581

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.41060
Value Function Update Magnitude: 0.60044

Collected Steps per Second: 21,525.58703
Overall Steps per Second: 10,560.41798

Timestep Collection Time: 2.32337
Timestep Consumption Time: 2.41242
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.73580

Cumulative Model Updates: 159,440
Cumulative Timesteps: 1,329,499,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,241.11852
Policy Entropy: 3.79709
Value Function Loss: 0.01441

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.41775
Value Function Update Magnitude: 0.54501

Collected Steps per Second: 22,545.26180
Overall Steps per Second: 10,885.27988

Timestep Collection Time: 2.21865
Timestep Consumption Time: 2.37655
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.59520

Cumulative Model Updates: 159,446
Cumulative Timesteps: 1,329,549,698

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1329549698...
Checkpoint 1329549698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,916.31457
Policy Entropy: 3.78147
Value Function Loss: 0.01904

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.43942
Value Function Update Magnitude: 0.50965

Collected Steps per Second: 21,840.94107
Overall Steps per Second: 10,601.62483

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71852

Cumulative Model Updates: 159,452
Cumulative Timesteps: 1,329,599,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,439.36743
Policy Entropy: 3.78519
Value Function Loss: 0.01926

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.49617
Value Function Update Magnitude: 0.51287

Collected Steps per Second: 22,111.09285
Overall Steps per Second: 10,855.14699

Timestep Collection Time: 2.26131
Timestep Consumption Time: 2.34480
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.60611

Cumulative Model Updates: 159,458
Cumulative Timesteps: 1,329,649,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1329649722...
Checkpoint 1329649722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,826.68345
Policy Entropy: 3.76911
Value Function Loss: 0.02339

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.51608
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 21,960.49079
Overall Steps per Second: 10,736.27889

Timestep Collection Time: 2.27764
Timestep Consumption Time: 2.38115
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.65878

Cumulative Model Updates: 159,464
Cumulative Timesteps: 1,329,699,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,295.61956
Policy Entropy: 3.78030
Value Function Loss: 0.02155

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11634
Policy Update Magnitude: 0.53724
Value Function Update Magnitude: 0.57021

Collected Steps per Second: 22,716.53030
Overall Steps per Second: 10,889.67083

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.39171
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.59389

Cumulative Model Updates: 159,470
Cumulative Timesteps: 1,329,749,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1329749766...
Checkpoint 1329749766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,261.69073
Policy Entropy: 3.77318
Value Function Loss: 0.02200

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.46738

Collected Steps per Second: 22,335.96881
Overall Steps per Second: 10,584.36984

Timestep Collection Time: 2.23917
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.72527

Cumulative Model Updates: 159,476
Cumulative Timesteps: 1,329,799,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,687.43603
Policy Entropy: 3.77066
Value Function Loss: 0.01969

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.48263
Value Function Update Magnitude: 0.41322

Collected Steps per Second: 22,162.69242
Overall Steps per Second: 10,483.79288

Timestep Collection Time: 2.25695
Timestep Consumption Time: 2.51423
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.77117

Cumulative Model Updates: 159,482
Cumulative Timesteps: 1,329,849,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1329849800...
Checkpoint 1329849800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,485.24502
Policy Entropy: 3.76805
Value Function Loss: 0.01824

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.45352
Value Function Update Magnitude: 0.41561

Collected Steps per Second: 22,243.51269
Overall Steps per Second: 10,631.27053

Timestep Collection Time: 2.24848
Timestep Consumption Time: 2.45595
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.70442

Cumulative Model Updates: 159,488
Cumulative Timesteps: 1,329,899,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,673.91422
Policy Entropy: 3.76993
Value Function Loss: 0.01542

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12292
Policy Update Magnitude: 0.42678
Value Function Update Magnitude: 0.34600

Collected Steps per Second: 22,602.82730
Overall Steps per Second: 10,637.35175

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.70455

Cumulative Model Updates: 159,494
Cumulative Timesteps: 1,329,949,858

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1329949858...
Checkpoint 1329949858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,673.91422
Policy Entropy: 3.75505
Value Function Loss: 0.01464

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.42889
Value Function Update Magnitude: 0.37202

Collected Steps per Second: 22,503.82617
Overall Steps per Second: 10,534.09393

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.52616
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.74934

Cumulative Model Updates: 159,500
Cumulative Timesteps: 1,329,999,888

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,624.62564
Policy Entropy: 3.75752
Value Function Loss: 0.02049

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.47322
Value Function Update Magnitude: 0.40360

Collected Steps per Second: 22,902.12879
Overall Steps per Second: 10,765.85185

Timestep Collection Time: 2.18425
Timestep Consumption Time: 2.46229
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.64654

Cumulative Model Updates: 159,506
Cumulative Timesteps: 1,330,049,912

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1330049912...
Checkpoint 1330049912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,284.97766
Policy Entropy: 3.74503
Value Function Loss: 0.02470

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.52631
Value Function Update Magnitude: 0.38801

Collected Steps per Second: 22,679.56595
Overall Steps per Second: 10,714.63077

Timestep Collection Time: 2.20480
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.66689

Cumulative Model Updates: 159,512
Cumulative Timesteps: 1,330,099,916

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,987.05422
Policy Entropy: 3.74872
Value Function Loss: 0.02318

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12318
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 22,338.22111
Overall Steps per Second: 10,890.27367

Timestep Collection Time: 2.23858
Timestep Consumption Time: 2.35322
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.59180

Cumulative Model Updates: 159,518
Cumulative Timesteps: 1,330,149,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1330149922...
Checkpoint 1330149922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,167.95322
Policy Entropy: 3.76843
Value Function Loss: 0.02257

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.57952
Value Function Update Magnitude: 0.63303

Collected Steps per Second: 21,693.99378
Overall Steps per Second: 10,670.42214

Timestep Collection Time: 2.30580
Timestep Consumption Time: 2.38211
PPO Batch Consumption Time: 0.28427
Total Iteration Time: 4.68791

Cumulative Model Updates: 159,524
Cumulative Timesteps: 1,330,199,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,514.90818
Policy Entropy: 3.79347
Value Function Loss: 0.02096

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11965
Policy Update Magnitude: 0.56626
Value Function Update Magnitude: 0.72634

Collected Steps per Second: 22,327.96785
Overall Steps per Second: 10,916.15000

Timestep Collection Time: 2.24024
Timestep Consumption Time: 2.34196
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.58220

Cumulative Model Updates: 159,530
Cumulative Timesteps: 1,330,249,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1330249964...
Checkpoint 1330249964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,296.83729
Policy Entropy: 3.80381
Value Function Loss: 0.01965

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11997
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.71673

Collected Steps per Second: 21,926.48598
Overall Steps per Second: 10,655.66361

Timestep Collection Time: 2.28062
Timestep Consumption Time: 2.41228
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.69290

Cumulative Model Updates: 159,536
Cumulative Timesteps: 1,330,299,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,910.22768
Policy Entropy: 3.79126
Value Function Loss: 0.01913

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.52151
Value Function Update Magnitude: 0.70233

Collected Steps per Second: 22,074.34145
Overall Steps per Second: 10,588.17498

Timestep Collection Time: 2.26707
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.72640

Cumulative Model Updates: 159,542
Cumulative Timesteps: 1,330,350,014

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1330350014...
Checkpoint 1330350014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,918.64487
Policy Entropy: 3.76309
Value Function Loss: 0.01800

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.54690
Value Function Update Magnitude: 0.67302

Collected Steps per Second: 22,103.23773
Overall Steps per Second: 10,562.63389

Timestep Collection Time: 2.26229
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.73405

Cumulative Model Updates: 159,548
Cumulative Timesteps: 1,330,400,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317,233.77147
Policy Entropy: 3.73720
Value Function Loss: 0.02626

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.17829
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.60547

Collected Steps per Second: 22,084.25658
Overall Steps per Second: 10,610.20451

Timestep Collection Time: 2.26451
Timestep Consumption Time: 2.44888
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.71339

Cumulative Model Updates: 159,554
Cumulative Timesteps: 1,330,450,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1330450028...
Checkpoint 1330450028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,211.33473
Policy Entropy: 3.74265
Value Function Loss: 0.02532

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 0.76054
Value Function Update Magnitude: 0.63956

Collected Steps per Second: 22,686.96399
Overall Steps per Second: 10,650.90648

Timestep Collection Time: 2.20435
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.69537

Cumulative Model Updates: 159,560
Cumulative Timesteps: 1,330,500,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,649.65583
Policy Entropy: 3.75896
Value Function Loss: 0.02500

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.73377
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 22,810.24395
Overall Steps per Second: 10,674.43356

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68409

Cumulative Model Updates: 159,566
Cumulative Timesteps: 1,330,550,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1330550038...
Checkpoint 1330550038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,755.61933
Policy Entropy: 3.75245
Value Function Loss: 0.02200

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.18521
Policy Update Magnitude: 0.66263
Value Function Update Magnitude: 0.65849

Collected Steps per Second: 22,479.42988
Overall Steps per Second: 10,623.10161

Timestep Collection Time: 2.22515
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.70861

Cumulative Model Updates: 159,572
Cumulative Timesteps: 1,330,600,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,284.57012
Policy Entropy: 3.75699
Value Function Loss: 0.02677

Mean KL Divergence: 0.01757
SB3 Clip Fraction: 0.20008
Policy Update Magnitude: 0.70762
Value Function Update Magnitude: 0.67199

Collected Steps per Second: 21,974.39751
Overall Steps per Second: 10,472.97850

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.77495

Cumulative Model Updates: 159,578
Cumulative Timesteps: 1,330,650,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1330650066...
Checkpoint 1330650066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,124.10201
Policy Entropy: 3.76276
Value Function Loss: 0.03530

Mean KL Divergence: 0.02494
SB3 Clip Fraction: 0.25867
Policy Update Magnitude: 0.70803
Value Function Update Magnitude: 0.61513

Collected Steps per Second: 22,562.37766
Overall Steps per Second: 10,694.28475

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67670

Cumulative Model Updates: 159,584
Cumulative Timesteps: 1,330,700,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,447.51974
Policy Entropy: 3.85997
Value Function Loss: 0.04422

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.19478
Policy Update Magnitude: 0.64058
Value Function Update Magnitude: 0.60827

Collected Steps per Second: 22,813.41555
Overall Steps per Second: 10,899.16950

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.39629
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.58842

Cumulative Model Updates: 159,590
Cumulative Timesteps: 1,330,750,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1330750090...
Checkpoint 1330750090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,935.19068
Policy Entropy: 3.96948
Value Function Loss: 0.04974

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.72083
Value Function Update Magnitude: 0.57636

Collected Steps per Second: 21,117.62585
Overall Steps per Second: 10,626.99030

Timestep Collection Time: 2.36769
Timestep Consumption Time: 2.33731
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.70500

Cumulative Model Updates: 159,596
Cumulative Timesteps: 1,330,800,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.31311
Policy Entropy: 4.04639
Value Function Loss: 0.04385

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.11239
Policy Update Magnitude: 0.89828
Value Function Update Magnitude: 0.69948

Collected Steps per Second: 22,701.13962
Overall Steps per Second: 10,827.10963

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.41570
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61841

Cumulative Model Updates: 159,602
Cumulative Timesteps: 1,330,850,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1330850094...
Checkpoint 1330850094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,988.23768
Policy Entropy: 4.09202
Value Function Loss: 0.03763

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.97457
Value Function Update Magnitude: 0.76501

Collected Steps per Second: 22,443.65774
Overall Steps per Second: 10,717.94465

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.43922
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.66881

Cumulative Model Updates: 159,608
Cumulative Timesteps: 1,330,900,134

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.20104
Policy Entropy: 4.10468
Value Function Loss: 0.03476

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 1.03600
Value Function Update Magnitude: 0.74178

Collected Steps per Second: 23,112.92122
Overall Steps per Second: 10,844.71823

Timestep Collection Time: 2.16355
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61109

Cumulative Model Updates: 159,614
Cumulative Timesteps: 1,330,950,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1330950140...
Checkpoint 1330950140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 404.75455
Policy Entropy: 4.12148
Value Function Loss: 0.02982

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.08681
Policy Update Magnitude: 1.03696
Value Function Update Magnitude: 0.86463

Collected Steps per Second: 22,229.92348
Overall Steps per Second: 10,646.13282

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.69786

Cumulative Model Updates: 159,620
Cumulative Timesteps: 1,331,000,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,875.75241
Policy Entropy: 4.09059
Value Function Loss: 0.02865

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07705
Policy Update Magnitude: 1.02916
Value Function Update Magnitude: 0.92486

Collected Steps per Second: 23,061.41029
Overall Steps per Second: 10,957.43593

Timestep Collection Time: 2.16838
Timestep Consumption Time: 2.39527
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.56366

Cumulative Model Updates: 159,626
Cumulative Timesteps: 1,331,050,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1331050160...
Checkpoint 1331050160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.64136
Policy Entropy: 4.00391
Value Function Loss: 0.03052

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06481
Policy Update Magnitude: 0.97755
Value Function Update Magnitude: 0.90538

Collected Steps per Second: 22,473.17891
Overall Steps per Second: 10,662.00680

Timestep Collection Time: 2.22630
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.69255

Cumulative Model Updates: 159,632
Cumulative Timesteps: 1,331,100,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127.62716
Policy Entropy: 3.89551
Value Function Loss: 0.03115

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.92254
Value Function Update Magnitude: 0.81586

Collected Steps per Second: 22,708.42608
Overall Steps per Second: 10,837.06608

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.41293
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.61564

Cumulative Model Updates: 159,638
Cumulative Timesteps: 1,331,150,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1331150212...
Checkpoint 1331150212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,286.50665
Policy Entropy: 3.82448
Value Function Loss: 0.02902

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06590
Policy Update Magnitude: 0.84861
Value Function Update Magnitude: 0.74984

Collected Steps per Second: 22,286.37339
Overall Steps per Second: 10,711.32973

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.66982

Cumulative Model Updates: 159,644
Cumulative Timesteps: 1,331,200,232

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,175.53625
Policy Entropy: 3.80662
Value Function Loss: 0.02513

Mean KL Divergence: 0.00616
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.75274
Value Function Update Magnitude: 0.61115

Collected Steps per Second: 22,541.75024
Overall Steps per Second: 10,841.38185

Timestep Collection Time: 2.21855
Timestep Consumption Time: 2.39433
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.61288

Cumulative Model Updates: 159,650
Cumulative Timesteps: 1,331,250,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1331250242...
Checkpoint 1331250242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,459.01505
Policy Entropy: 3.80841
Value Function Loss: 0.02139

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07745
Policy Update Magnitude: 0.63989
Value Function Update Magnitude: 0.43971

Collected Steps per Second: 22,013.95608
Overall Steps per Second: 10,671.83319

Timestep Collection Time: 2.27174
Timestep Consumption Time: 2.41443
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.68617

Cumulative Model Updates: 159,656
Cumulative Timesteps: 1,331,300,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,812.86054
Policy Entropy: 3.81598
Value Function Loss: 0.01713

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.58930
Value Function Update Magnitude: 0.37979

Collected Steps per Second: 22,853.29601
Overall Steps per Second: 10,823.95064

Timestep Collection Time: 2.19014
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.62419

Cumulative Model Updates: 159,662
Cumulative Timesteps: 1,331,350,304

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1331350304...
Checkpoint 1331350304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,164.22371
Policy Entropy: 3.78709
Value Function Loss: 0.02288

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.50891
Value Function Update Magnitude: 0.41824

Collected Steps per Second: 22,015.17340
Overall Steps per Second: 10,633.13241

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.70247

Cumulative Model Updates: 159,668
Cumulative Timesteps: 1,331,400,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,365.45694
Policy Entropy: 3.81144
Value Function Loss: 0.02531

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.50464
Value Function Update Magnitude: 0.54673

Collected Steps per Second: 22,704.28132
Overall Steps per Second: 10,674.64303

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.48197
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.68437

Cumulative Model Updates: 159,674
Cumulative Timesteps: 1,331,450,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1331450310...
Checkpoint 1331450310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,594.45195
Policy Entropy: 3.80558
Value Function Loss: 0.03337

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.52688
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 22,696.45376
Overall Steps per Second: 10,661.30138

Timestep Collection Time: 2.20422
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.69249

Cumulative Model Updates: 159,680
Cumulative Timesteps: 1,331,500,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,975.25589
Policy Entropy: 3.86650
Value Function Loss: 0.02938

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11868
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.74298

Collected Steps per Second: 23,071.56858
Overall Steps per Second: 10,746.47214

Timestep Collection Time: 2.16856
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.65567

Cumulative Model Updates: 159,686
Cumulative Timesteps: 1,331,550,370

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1331550370...
Checkpoint 1331550370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,585.08593
Policy Entropy: 3.85589
Value Function Loss: 0.02917

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.57431
Value Function Update Magnitude: 0.77784

Collected Steps per Second: 22,600.53291
Overall Steps per Second: 10,611.40485

Timestep Collection Time: 2.21251
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.71229

Cumulative Model Updates: 159,692
Cumulative Timesteps: 1,331,600,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,182.38350
Policy Entropy: 3.84837
Value Function Loss: 0.02633

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.79968

Collected Steps per Second: 22,769.40219
Overall Steps per Second: 10,711.69156

Timestep Collection Time: 2.19637
Timestep Consumption Time: 2.47236
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.66873

Cumulative Model Updates: 159,698
Cumulative Timesteps: 1,331,650,384

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1331650384...
Checkpoint 1331650384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,497.24359
Policy Entropy: 3.79998
Value Function Loss: 0.02465

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.50834
Value Function Update Magnitude: 0.75097

Collected Steps per Second: 22,336.50307
Overall Steps per Second: 10,656.65552

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69397

Cumulative Model Updates: 159,704
Cumulative Timesteps: 1,331,700,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,668.84041
Policy Entropy: 3.78055
Value Function Loss: 0.02310

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.49953
Value Function Update Magnitude: 0.78971

Collected Steps per Second: 21,976.31361
Overall Steps per Second: 10,635.97598

Timestep Collection Time: 2.27709
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.70497

Cumulative Model Updates: 159,710
Cumulative Timesteps: 1,331,750,448

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1331750448...
Checkpoint 1331750448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,804.36553
Policy Entropy: 3.77859
Value Function Loss: 0.02112

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13051
Policy Update Magnitude: 0.47643
Value Function Update Magnitude: 0.76197

Collected Steps per Second: 21,943.48524
Overall Steps per Second: 10,637.67726

Timestep Collection Time: 2.27940
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.70197

Cumulative Model Updates: 159,716
Cumulative Timesteps: 1,331,800,466

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,058.45038
Policy Entropy: 3.77808
Value Function Loss: 0.02005

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.44801
Value Function Update Magnitude: 0.71323

Collected Steps per Second: 22,578.26729
Overall Steps per Second: 10,642.68115

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.69919

Cumulative Model Updates: 159,722
Cumulative Timesteps: 1,331,850,478

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1331850478...
Checkpoint 1331850478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,135.38412
Policy Entropy: 3.79155
Value Function Loss: 0.02118

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.42897
Value Function Update Magnitude: 0.73652

Collected Steps per Second: 22,669.41213
Overall Steps per Second: 10,617.60341

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.70991

Cumulative Model Updates: 159,728
Cumulative Timesteps: 1,331,900,486

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,376.93399
Policy Entropy: 3.78394
Value Function Loss: 0.02127

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.47580
Value Function Update Magnitude: 0.81776

Collected Steps per Second: 22,804.71243
Overall Steps per Second: 10,745.37020

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.65447

Cumulative Model Updates: 159,734
Cumulative Timesteps: 1,331,950,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1331950500...
Checkpoint 1331950500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,166.70555
Policy Entropy: 3.78281
Value Function Loss: 0.02362

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.49462
Value Function Update Magnitude: 0.85328

Collected Steps per Second: 21,810.48856
Overall Steps per Second: 10,655.37750

Timestep Collection Time: 2.29348
Timestep Consumption Time: 2.40105
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.69453

Cumulative Model Updates: 159,740
Cumulative Timesteps: 1,332,000,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,565.60892
Policy Entropy: 3.79036
Value Function Loss: 0.03034

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13482
Policy Update Magnitude: 0.50617
Value Function Update Magnitude: 0.90206

Collected Steps per Second: 22,199.13036
Overall Steps per Second: 10,860.99138

Timestep Collection Time: 2.25351
Timestep Consumption Time: 2.35251
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.60603

Cumulative Model Updates: 159,746
Cumulative Timesteps: 1,332,050,548

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1332050548...
Checkpoint 1332050548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,880.58019
Policy Entropy: 3.82370
Value Function Loss: 0.03246

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12664
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.93203

Collected Steps per Second: 22,038.47230
Overall Steps per Second: 10,692.39456

Timestep Collection Time: 2.26876
Timestep Consumption Time: 2.40746
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.67622

Cumulative Model Updates: 159,752
Cumulative Timesteps: 1,332,100,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,719.95362
Policy Entropy: 3.84675
Value Function Loss: 0.03282

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.89056

Collected Steps per Second: 22,293.15277
Overall Steps per Second: 10,876.84510

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.35455
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.59784

Cumulative Model Updates: 159,758
Cumulative Timesteps: 1,332,150,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1332150558...
Checkpoint 1332150558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,332.06414
Policy Entropy: 3.85402
Value Function Loss: 0.02704

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.53161
Value Function Update Magnitude: 0.83176

Collected Steps per Second: 21,548.72039
Overall Steps per Second: 10,754.60543

Timestep Collection Time: 2.32181
Timestep Consumption Time: 2.33034
PPO Batch Consumption Time: 0.27551
Total Iteration Time: 4.65215

Cumulative Model Updates: 159,764
Cumulative Timesteps: 1,332,200,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,178.37613
Policy Entropy: 3.82813
Value Function Loss: 0.02711

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12262
Policy Update Magnitude: 0.50362
Value Function Update Magnitude: 0.71066

Collected Steps per Second: 21,719.01268
Overall Steps per Second: 10,770.22742

Timestep Collection Time: 2.30231
Timestep Consumption Time: 2.34048
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.64280

Cumulative Model Updates: 159,770
Cumulative Timesteps: 1,332,250,594

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1332250594...
Checkpoint 1332250594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,115.56080
Policy Entropy: 3.79345
Value Function Loss: 0.02718

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.47493
Value Function Update Magnitude: 0.54599

Collected Steps per Second: 21,430.35221
Overall Steps per Second: 10,705.32098

Timestep Collection Time: 2.33445
Timestep Consumption Time: 2.33874
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.67319

Cumulative Model Updates: 159,776
Cumulative Timesteps: 1,332,300,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,168.14353
Policy Entropy: 3.78073
Value Function Loss: 0.02416

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.42775
Value Function Update Magnitude: 0.54791

Collected Steps per Second: 21,969.05300
Overall Steps per Second: 10,531.96663

Timestep Collection Time: 2.27720
Timestep Consumption Time: 2.47291
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.75011

Cumulative Model Updates: 159,782
Cumulative Timesteps: 1,332,350,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1332350650...
Checkpoint 1332350650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,960.18783
Policy Entropy: 3.75322
Value Function Loss: 0.02410

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.41219
Value Function Update Magnitude: 0.57269

Collected Steps per Second: 21,897.00023
Overall Steps per Second: 10,574.31989

Timestep Collection Time: 2.28442
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.73052

Cumulative Model Updates: 159,788
Cumulative Timesteps: 1,332,400,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,337.75489
Policy Entropy: 3.75947
Value Function Loss: 0.02359

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.40099
Value Function Update Magnitude: 0.42657

Collected Steps per Second: 22,959.81234
Overall Steps per Second: 10,844.02142

Timestep Collection Time: 2.17824
Timestep Consumption Time: 2.43370
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.61194

Cumulative Model Updates: 159,794
Cumulative Timesteps: 1,332,450,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1332450684...
Checkpoint 1332450684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,073.02843
Policy Entropy: 3.74028
Value Function Loss: 0.02229

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.14091
Policy Update Magnitude: 0.38741
Value Function Update Magnitude: 0.46901

Collected Steps per Second: 22,801.17864
Overall Steps per Second: 10,705.79702

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.47819
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67167

Cumulative Model Updates: 159,800
Cumulative Timesteps: 1,332,500,698

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,493.60659
Policy Entropy: 3.74961
Value Function Loss: 0.02189

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.39297
Value Function Update Magnitude: 0.56779

Collected Steps per Second: 22,890.21715
Overall Steps per Second: 10,853.85817

Timestep Collection Time: 2.18652
Timestep Consumption Time: 2.42474
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.61126

Cumulative Model Updates: 159,806
Cumulative Timesteps: 1,332,550,748

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1332550748...
Checkpoint 1332550748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,493.60659
Policy Entropy: 3.74379
Value Function Loss: 0.02380

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.44890
Value Function Update Magnitude: 0.53393

Collected Steps per Second: 22,365.24322
Overall Steps per Second: 10,738.89162

Timestep Collection Time: 2.23588
Timestep Consumption Time: 2.42065
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.65653

Cumulative Model Updates: 159,812
Cumulative Timesteps: 1,332,600,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,493.60659
Policy Entropy: 3.74378
Value Function Loss: 0.01987

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.45224
Value Function Update Magnitude: 0.47782

Collected Steps per Second: 22,780.20965
Overall Steps per Second: 10,824.86249

Timestep Collection Time: 2.19515
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.61955

Cumulative Model Updates: 159,818
Cumulative Timesteps: 1,332,650,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1332650760...
Checkpoint 1332650760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,493.60659
Policy Entropy: 3.72965
Value Function Loss: 0.02152

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.40264
Value Function Update Magnitude: 0.38422

Collected Steps per Second: 22,122.82205
Overall Steps per Second: 10,624.64120

Timestep Collection Time: 2.26038
Timestep Consumption Time: 2.44623
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.70661

Cumulative Model Updates: 159,824
Cumulative Timesteps: 1,332,700,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,405.17901
Policy Entropy: 3.73565
Value Function Loss: 0.01825

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.38569
Value Function Update Magnitude: 0.37598

Collected Steps per Second: 22,526.14135
Overall Steps per Second: 10,628.74890

Timestep Collection Time: 2.22000
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.70498

Cumulative Model Updates: 159,830
Cumulative Timesteps: 1,332,750,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1332750774...
Checkpoint 1332750774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,813.67750
Policy Entropy: 3.74480
Value Function Loss: 0.02274

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.40110
Value Function Update Magnitude: 0.35447

Collected Steps per Second: 21,525.97430
Overall Steps per Second: 10,533.90481

Timestep Collection Time: 2.32333
Timestep Consumption Time: 2.42438
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.74772

Cumulative Model Updates: 159,836
Cumulative Timesteps: 1,332,800,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,311.90719
Policy Entropy: 3.75365
Value Function Loss: 0.01967

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.44439
Value Function Update Magnitude: 0.31324

Collected Steps per Second: 21,725.71658
Overall Steps per Second: 10,655.80918

Timestep Collection Time: 2.30262
Timestep Consumption Time: 2.39210
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.69472

Cumulative Model Updates: 159,842
Cumulative Timesteps: 1,332,850,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1332850812...
Checkpoint 1332850812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,460.80264
Policy Entropy: 3.75996
Value Function Loss: 0.01798

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.42050
Value Function Update Magnitude: 0.34006

Collected Steps per Second: 21,765.98833
Overall Steps per Second: 10,499.12720

Timestep Collection Time: 2.29744
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.76287

Cumulative Model Updates: 159,848
Cumulative Timesteps: 1,332,900,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,460.80264
Policy Entropy: 3.74913
Value Function Loss: 0.01523

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.37320
Value Function Update Magnitude: 0.30993

Collected Steps per Second: 22,673.26193
Overall Steps per Second: 10,808.12899

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.62615

Cumulative Model Updates: 159,854
Cumulative Timesteps: 1,332,950,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1332950818...
Checkpoint 1332950818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,360.34013
Policy Entropy: 3.74617
Value Function Loss: 0.01549

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.35101
Value Function Update Magnitude: 0.31449

Collected Steps per Second: 22,446.68508
Overall Steps per Second: 10,649.68826

Timestep Collection Time: 2.22812
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.69629

Cumulative Model Updates: 159,860
Cumulative Timesteps: 1,333,000,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,873.81671
Policy Entropy: 3.74326
Value Function Loss: 0.01827

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.38944
Value Function Update Magnitude: 0.42376

Collected Steps per Second: 22,990.40017
Overall Steps per Second: 10,891.25200

Timestep Collection Time: 2.17578
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.59286

Cumulative Model Updates: 159,866
Cumulative Timesteps: 1,333,050,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1333050854...
Checkpoint 1333050854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,278.33861
Policy Entropy: 3.78134
Value Function Loss: 0.02133

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.41484
Value Function Update Magnitude: 0.51561

Collected Steps per Second: 22,578.71279
Overall Steps per Second: 10,669.54249

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68642

Cumulative Model Updates: 159,872
Cumulative Timesteps: 1,333,100,856

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.31417
Policy Entropy: 3.80728
Value Function Loss: 0.02389

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12325
Policy Update Magnitude: 0.44308
Value Function Update Magnitude: 0.48358

Collected Steps per Second: 22,865.41869
Overall Steps per Second: 10,837.92783

Timestep Collection Time: 2.18688
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.61380

Cumulative Model Updates: 159,878
Cumulative Timesteps: 1,333,150,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1333150860...
Checkpoint 1333150860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 198.23127
Policy Entropy: 3.80033
Value Function Loss: 0.02357

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.47182
Value Function Update Magnitude: 0.53052

Collected Steps per Second: 22,508.62951
Overall Steps per Second: 10,583.77138

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.50384
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.72610

Cumulative Model Updates: 159,884
Cumulative Timesteps: 1,333,200,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,428.97482
Policy Entropy: 3.77594
Value Function Loss: 0.02328

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12252
Policy Update Magnitude: 0.46934
Value Function Update Magnitude: 0.50074

Collected Steps per Second: 22,690.71045
Overall Steps per Second: 10,633.26522

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70523

Cumulative Model Updates: 159,890
Cumulative Timesteps: 1,333,250,912

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1333250912...
Checkpoint 1333250912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,963.11872
Policy Entropy: 3.76676
Value Function Loss: 0.02279

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.48216
Value Function Update Magnitude: 0.44471

Collected Steps per Second: 21,957.93408
Overall Steps per Second: 10,611.66316

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.43559
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.71349

Cumulative Model Updates: 159,896
Cumulative Timesteps: 1,333,300,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,009.79168
Policy Entropy: 3.76392
Value Function Loss: 0.02364

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13017
Policy Update Magnitude: 0.48699
Value Function Update Magnitude: 0.42020

Collected Steps per Second: 22,287.49920
Overall Steps per Second: 9,699.11371

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.91182
PPO Batch Consumption Time: 0.36063
Total Iteration Time: 5.15532

Cumulative Model Updates: 159,902
Cumulative Timesteps: 1,333,350,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1333350932...
Checkpoint 1333350932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389,558.56018
Policy Entropy: 3.78493
Value Function Loss: 0.02350

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.52063
Value Function Update Magnitude: 0.40157

Collected Steps per Second: 10,835.57121
Overall Steps per Second: 6,771.02119

Timestep Collection Time: 4.61683
Timestep Consumption Time: 2.77142
PPO Batch Consumption Time: 0.32685
Total Iteration Time: 7.38825

Cumulative Model Updates: 159,908
Cumulative Timesteps: 1,333,400,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,397.27946
Policy Entropy: 3.77234
Value Function Loss: 0.02623

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.11948
Policy Update Magnitude: 0.54759
Value Function Update Magnitude: 0.50255

Collected Steps per Second: 16,140.33892
Overall Steps per Second: 8,376.94476

Timestep Collection Time: 3.09894
Timestep Consumption Time: 2.87197
PPO Batch Consumption Time: 0.34087
Total Iteration Time: 5.97091

Cumulative Model Updates: 159,914
Cumulative Timesteps: 1,333,450,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1333450976...
Checkpoint 1333450976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,096.01719
Policy Entropy: 3.77569
Value Function Loss: 0.02806

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13697
Policy Update Magnitude: 0.57182
Value Function Update Magnitude: 0.61495

Collected Steps per Second: 17,085.42099
Overall Steps per Second: 9,207.33385

Timestep Collection Time: 2.92659
Timestep Consumption Time: 2.50408
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 5.43067

Cumulative Model Updates: 159,920
Cumulative Timesteps: 1,333,500,978

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,592.01395
Policy Entropy: 3.77078
Value Function Loss: 0.02658

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.57686
Value Function Update Magnitude: 0.69976

Collected Steps per Second: 17,084.46040
Overall Steps per Second: 8,834.88981

Timestep Collection Time: 2.92828
Timestep Consumption Time: 2.73427
PPO Batch Consumption Time: 0.33215
Total Iteration Time: 5.66255

Cumulative Model Updates: 159,926
Cumulative Timesteps: 1,333,551,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1333551006...
Checkpoint 1333551006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,603.04491
Policy Entropy: 3.74797
Value Function Loss: 0.02598

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13303
Policy Update Magnitude: 0.53181
Value Function Update Magnitude: 0.74232

Collected Steps per Second: 18,688.20402
Overall Steps per Second: 9,098.92607

Timestep Collection Time: 2.67720
Timestep Consumption Time: 2.82147
PPO Batch Consumption Time: 0.34168
Total Iteration Time: 5.49867

Cumulative Model Updates: 159,932
Cumulative Timesteps: 1,333,601,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,220.18036
Policy Entropy: 3.76917
Value Function Loss: 0.02354

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14417
Policy Update Magnitude: 0.47808
Value Function Update Magnitude: 0.72125

Collected Steps per Second: 19,860.52045
Overall Steps per Second: 9,680.47015

Timestep Collection Time: 2.51806
Timestep Consumption Time: 2.64801
PPO Batch Consumption Time: 0.31339
Total Iteration Time: 5.16607

Cumulative Model Updates: 159,938
Cumulative Timesteps: 1,333,651,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1333651048...
Checkpoint 1333651048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,772.42273
Policy Entropy: 3.75989
Value Function Loss: 0.02357

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.46528
Value Function Update Magnitude: 0.62291

Collected Steps per Second: 17,204.88714
Overall Steps per Second: 9,128.85810

Timestep Collection Time: 2.90766
Timestep Consumption Time: 2.57232
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 5.47998

Cumulative Model Updates: 159,944
Cumulative Timesteps: 1,333,701,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,772.42273
Policy Entropy: 3.77324
Value Function Loss: 0.01949

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.46468
Value Function Update Magnitude: 0.54647

Collected Steps per Second: 15,631.61203
Overall Steps per Second: 8,599.72301

Timestep Collection Time: 3.20108
Timestep Consumption Time: 2.61748
PPO Batch Consumption Time: 0.31598
Total Iteration Time: 5.81856

Cumulative Model Updates: 159,950
Cumulative Timesteps: 1,333,751,112

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1333751112...
Checkpoint 1333751112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,515.96328
Policy Entropy: 3.75526
Value Function Loss: 0.02286

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.47385
Value Function Update Magnitude: 0.62023

Collected Steps per Second: 15,953.01592
Overall Steps per Second: 8,682.55163

Timestep Collection Time: 3.13659
Timestep Consumption Time: 2.62647
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 5.76305

Cumulative Model Updates: 159,956
Cumulative Timesteps: 1,333,801,150

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,328.72860
Policy Entropy: 3.75092
Value Function Loss: 0.02607

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 16,638.88251
Overall Steps per Second: 8,947.22298

Timestep Collection Time: 3.00525
Timestep Consumption Time: 2.58352
PPO Batch Consumption Time: 0.30624
Total Iteration Time: 5.58877

Cumulative Model Updates: 159,962
Cumulative Timesteps: 1,333,851,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1333851154...
Checkpoint 1333851154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,988.20440
Policy Entropy: 3.76277
Value Function Loss: 0.03060

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.48612

Collected Steps per Second: 17,576.06849
Overall Steps per Second: 9,260.38854

Timestep Collection Time: 2.84557
Timestep Consumption Time: 2.55528
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 5.40085

Cumulative Model Updates: 159,968
Cumulative Timesteps: 1,333,901,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,732.03398
Policy Entropy: 3.78243
Value Function Loss: 0.02441

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13954
Policy Update Magnitude: 0.56026
Value Function Update Magnitude: 0.51662

Collected Steps per Second: 15,548.03190
Overall Steps per Second: 8,682.70452

Timestep Collection Time: 3.21584
Timestep Consumption Time: 2.54273
PPO Batch Consumption Time: 0.30454
Total Iteration Time: 5.75857

Cumulative Model Updates: 159,974
Cumulative Timesteps: 1,333,951,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1333951168...
Checkpoint 1333951168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,471.89283
Policy Entropy: 3.79648
Value Function Loss: 0.02200

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12762
Policy Update Magnitude: 0.54794
Value Function Update Magnitude: 0.65109

Collected Steps per Second: 17,124.78051
Overall Steps per Second: 9,022.23263

Timestep Collection Time: 2.92033
Timestep Consumption Time: 2.62264
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 5.54297

Cumulative Model Updates: 159,980
Cumulative Timesteps: 1,334,001,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,840.52527
Policy Entropy: 3.80482
Value Function Loss: 0.02293

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.61049

Collected Steps per Second: 17,919.96066
Overall Steps per Second: 9,412.13496

Timestep Collection Time: 2.79175
Timestep Consumption Time: 2.52352
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 5.31527

Cumulative Model Updates: 159,986
Cumulative Timesteps: 1,334,051,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1334051206...
Checkpoint 1334051206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,438.02750
Policy Entropy: 3.79979
Value Function Loss: 0.02216

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.58103

Collected Steps per Second: 18,026.95523
Overall Steps per Second: 9,447.88988

Timestep Collection Time: 2.77451
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 5.29388

Cumulative Model Updates: 159,992
Cumulative Timesteps: 1,334,101,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,005.52813
Policy Entropy: 3.76979
Value Function Loss: 0.02437

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13180
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.53845

Collected Steps per Second: 18,187.74142
Overall Steps per Second: 9,377.30781

Timestep Collection Time: 2.75064
Timestep Consumption Time: 2.58436
PPO Batch Consumption Time: 0.30464
Total Iteration Time: 5.33501

Cumulative Model Updates: 159,998
Cumulative Timesteps: 1,334,151,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1334151250...
Checkpoint 1334151250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,960.56201
Policy Entropy: 3.75415
Value Function Loss: 0.02725

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.55175
Value Function Update Magnitude: 0.55231

Collected Steps per Second: 18,429.45136
Overall Steps per Second: 9,348.56072

Timestep Collection Time: 2.71576
Timestep Consumption Time: 2.63800
PPO Batch Consumption Time: 0.31239
Total Iteration Time: 5.35377

Cumulative Model Updates: 160,004
Cumulative Timesteps: 1,334,201,300

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,995.02700
Policy Entropy: 3.77406
Value Function Loss: 0.02731

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.59119
Value Function Update Magnitude: 0.72621

Collected Steps per Second: 18,986.89282
Overall Steps per Second: 9,572.09390

Timestep Collection Time: 2.63340
Timestep Consumption Time: 2.59012
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 5.22352

Cumulative Model Updates: 160,010
Cumulative Timesteps: 1,334,251,300

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1334251300...
Checkpoint 1334251300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,406.47430
Policy Entropy: 3.79659
Value Function Loss: 0.02828

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.57736
Value Function Update Magnitude: 0.89156

Collected Steps per Second: 18,815.05204
Overall Steps per Second: 9,448.17057

Timestep Collection Time: 2.65787
Timestep Consumption Time: 2.63500
PPO Batch Consumption Time: 0.30622
Total Iteration Time: 5.29288

Cumulative Model Updates: 160,016
Cumulative Timesteps: 1,334,301,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,520.42730
Policy Entropy: 3.78387
Value Function Loss: 0.02761

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13242
Policy Update Magnitude: 0.54109
Value Function Update Magnitude: 0.75573

Collected Steps per Second: 18,934.08174
Overall Steps per Second: 9,392.37009

Timestep Collection Time: 2.64222
Timestep Consumption Time: 2.68423
PPO Batch Consumption Time: 0.31571
Total Iteration Time: 5.32645

Cumulative Model Updates: 160,022
Cumulative Timesteps: 1,334,351,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1334351336...
Checkpoint 1334351336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,313.91296
Policy Entropy: 3.76666
Value Function Loss: 0.02320

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.50427
Value Function Update Magnitude: 0.55949

Collected Steps per Second: 18,848.33615
Overall Steps per Second: 9,329.60025

Timestep Collection Time: 2.65435
Timestep Consumption Time: 2.70816
PPO Batch Consumption Time: 0.31134
Total Iteration Time: 5.36250

Cumulative Model Updates: 160,028
Cumulative Timesteps: 1,334,401,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,905.36617
Policy Entropy: 3.75131
Value Function Loss: 0.02086

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.47278
Value Function Update Magnitude: 0.63078

Collected Steps per Second: 19,041.79738
Overall Steps per Second: 9,522.20124

Timestep Collection Time: 2.62664
Timestep Consumption Time: 2.62592
PPO Batch Consumption Time: 0.30333
Total Iteration Time: 5.25257

Cumulative Model Updates: 160,034
Cumulative Timesteps: 1,334,451,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1334451382...
Checkpoint 1334451382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,411.62433
Policy Entropy: 3.76919
Value Function Loss: 0.01988

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12406
Policy Update Magnitude: 0.47340
Value Function Update Magnitude: 0.69233

Collected Steps per Second: 18,521.15544
Overall Steps per Second: 9,333.12288

Timestep Collection Time: 2.70026
Timestep Consumption Time: 2.65829
PPO Batch Consumption Time: 0.30387
Total Iteration Time: 5.35855

Cumulative Model Updates: 160,040
Cumulative Timesteps: 1,334,501,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,577.39327
Policy Entropy: 3.76228
Value Function Loss: 0.02116

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.49993
Value Function Update Magnitude: 0.73027

Collected Steps per Second: 17,165.54187
Overall Steps per Second: 9,031.80394

Timestep Collection Time: 2.91363
Timestep Consumption Time: 2.62391
PPO Batch Consumption Time: 0.30665
Total Iteration Time: 5.53754

Cumulative Model Updates: 160,046
Cumulative Timesteps: 1,334,551,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1334551408...
Checkpoint 1334551408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,738.92054
Policy Entropy: 3.77038
Value Function Loss: 0.01996

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.49851
Value Function Update Magnitude: 0.71493

Collected Steps per Second: 17,967.49137
Overall Steps per Second: 9,424.11695

Timestep Collection Time: 2.78447
Timestep Consumption Time: 2.52425
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 5.30872

Cumulative Model Updates: 160,052
Cumulative Timesteps: 1,334,601,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,238.48966
Policy Entropy: 3.76994
Value Function Loss: 0.01922

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.47898
Value Function Update Magnitude: 0.55052

Collected Steps per Second: 17,071.34608
Overall Steps per Second: 9,040.85886

Timestep Collection Time: 2.93006
Timestep Consumption Time: 2.60260
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 5.53266

Cumulative Model Updates: 160,058
Cumulative Timesteps: 1,334,651,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1334651458...
Checkpoint 1334651458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,760.37428
Policy Entropy: 3.77895
Value Function Loss: 0.01755

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.44268
Value Function Update Magnitude: 0.40455

Collected Steps per Second: 17,090.12432
Overall Steps per Second: 9,134.81842

Timestep Collection Time: 2.92719
Timestep Consumption Time: 2.54922
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 5.47641

Cumulative Model Updates: 160,064
Cumulative Timesteps: 1,334,701,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,092.29517
Policy Entropy: 3.77506
Value Function Loss: 0.01756

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.39749
Value Function Update Magnitude: 0.33577

Collected Steps per Second: 17,224.44590
Overall Steps per Second: 9,132.17790

Timestep Collection Time: 2.90285
Timestep Consumption Time: 2.57229
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 5.47515

Cumulative Model Updates: 160,070
Cumulative Timesteps: 1,334,751,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1334751484...
Checkpoint 1334751484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,423.77433
Policy Entropy: 3.76105
Value Function Loss: 0.02149

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.44875
Value Function Update Magnitude: 0.37133

Collected Steps per Second: 16,929.12541
Overall Steps per Second: 8,834.94208

Timestep Collection Time: 2.95514
Timestep Consumption Time: 2.70737
PPO Batch Consumption Time: 0.31859
Total Iteration Time: 5.66252

Cumulative Model Updates: 160,076
Cumulative Timesteps: 1,334,801,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,867.20369
Policy Entropy: 3.75290
Value Function Loss: 0.02141

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.49840
Value Function Update Magnitude: 0.42451

Collected Steps per Second: 17,216.61628
Overall Steps per Second: 8,959.28872

Timestep Collection Time: 2.90429
Timestep Consumption Time: 2.67674
PPO Batch Consumption Time: 0.31331
Total Iteration Time: 5.58102

Cumulative Model Updates: 160,082
Cumulative Timesteps: 1,334,851,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1334851514...
Checkpoint 1334851514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,867.20369
Policy Entropy: 3.73905
Value Function Loss: 0.02650

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.51909
Value Function Update Magnitude: 0.54524

Collected Steps per Second: 16,932.71174
Overall Steps per Second: 9,061.28840

Timestep Collection Time: 2.95286
Timestep Consumption Time: 2.56511
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 5.51798

Cumulative Model Updates: 160,088
Cumulative Timesteps: 1,334,901,514

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,497.88653
Policy Entropy: 3.75353
Value Function Loss: 0.02490

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.67717

Collected Steps per Second: 17,178.36124
Overall Steps per Second: 9,117.84229

Timestep Collection Time: 2.91099
Timestep Consumption Time: 2.57342
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 5.48441

Cumulative Model Updates: 160,094
Cumulative Timesteps: 1,334,951,520

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1334951520...
Checkpoint 1334951520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,713.34890
Policy Entropy: 3.75591
Value Function Loss: 0.03618

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.58875
Value Function Update Magnitude: 0.54786

Collected Steps per Second: 17,140.16997
Overall Steps per Second: 9,050.15459

Timestep Collection Time: 2.91969
Timestep Consumption Time: 2.60994
PPO Batch Consumption Time: 0.30009
Total Iteration Time: 5.52963

Cumulative Model Updates: 160,100
Cumulative Timesteps: 1,335,001,564

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,325.76564
Policy Entropy: 3.79003
Value Function Loss: 0.03506

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.63112
Value Function Update Magnitude: 0.57704

Collected Steps per Second: 16,825.73057
Overall Steps per Second: 8,973.66014

Timestep Collection Time: 2.97188
Timestep Consumption Time: 2.60043
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 5.57231

Cumulative Model Updates: 160,106
Cumulative Timesteps: 1,335,051,568

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1335051568...
Checkpoint 1335051568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,082.72573
Policy Entropy: 3.77848
Value Function Loss: 0.03984

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.63229
Value Function Update Magnitude: 0.50305

Collected Steps per Second: 17,170.49945
Overall Steps per Second: 9,024.23774

Timestep Collection Time: 2.91255
Timestep Consumption Time: 2.62919
PPO Batch Consumption Time: 0.30322
Total Iteration Time: 5.54174

Cumulative Model Updates: 160,112
Cumulative Timesteps: 1,335,101,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,662.23899
Policy Entropy: 3.79530
Value Function Loss: 0.02665

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.59626
Value Function Update Magnitude: 0.55454

Collected Steps per Second: 17,073.44644
Overall Steps per Second: 8,986.75166

Timestep Collection Time: 2.92899
Timestep Consumption Time: 2.63564
PPO Batch Consumption Time: 0.30451
Total Iteration Time: 5.56464

Cumulative Model Updates: 160,118
Cumulative Timesteps: 1,335,151,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1335151586...
Checkpoint 1335151586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,450.30956
Policy Entropy: 3.78289
Value Function Loss: 0.02696

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.55006

Collected Steps per Second: 17,447.79933
Overall Steps per Second: 9,122.85969

Timestep Collection Time: 2.86730
Timestep Consumption Time: 2.61651
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 5.48381

Cumulative Model Updates: 160,124
Cumulative Timesteps: 1,335,201,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,251.44527
Policy Entropy: 3.77247
Value Function Loss: 0.02356

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.53004
Value Function Update Magnitude: 0.46664

Collected Steps per Second: 17,380.67333
Overall Steps per Second: 8,988.79005

Timestep Collection Time: 2.87837
Timestep Consumption Time: 2.68723
PPO Batch Consumption Time: 0.31793
Total Iteration Time: 5.56560

Cumulative Model Updates: 160,130
Cumulative Timesteps: 1,335,251,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1335251642...
Checkpoint 1335251642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,251.44527
Policy Entropy: 3.74318
Value Function Loss: 0.02268

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.48262
Value Function Update Magnitude: 0.37676

Collected Steps per Second: 17,234.57259
Overall Steps per Second: 9,210.81423

Timestep Collection Time: 2.90231
Timestep Consumption Time: 2.52827
PPO Batch Consumption Time: 0.30468
Total Iteration Time: 5.43057

Cumulative Model Updates: 160,136
Cumulative Timesteps: 1,335,301,662

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,251.44527
Policy Entropy: 3.73970
Value Function Loss: 0.01802

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13532
Policy Update Magnitude: 0.43796
Value Function Update Magnitude: 0.29458

Collected Steps per Second: 17,082.13998
Overall Steps per Second: 9,157.07811

Timestep Collection Time: 2.92914
Timestep Consumption Time: 2.53505
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 5.46419

Cumulative Model Updates: 160,142
Cumulative Timesteps: 1,335,351,698

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1335351698...
Checkpoint 1335351698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,251.44527
Policy Entropy: 3.75615
Value Function Loss: 0.01578

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.40078
Value Function Update Magnitude: 0.29751

Collected Steps per Second: 16,558.47663
Overall Steps per Second: 9,111.93144

Timestep Collection Time: 3.01996
Timestep Consumption Time: 2.46801
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 5.48797

Cumulative Model Updates: 160,148
Cumulative Timesteps: 1,335,401,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,251.44527
Policy Entropy: 3.76995
Value Function Loss: 0.01459

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.37368
Value Function Update Magnitude: 0.31207

Collected Steps per Second: 16,611.83188
Overall Steps per Second: 9,030.53354

Timestep Collection Time: 3.01123
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 5.53921

Cumulative Model Updates: 160,154
Cumulative Timesteps: 1,335,451,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1335451726...
Checkpoint 1335451726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,340.78996
Policy Entropy: 3.77417
Value Function Loss: 0.01669

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.12034
Policy Update Magnitude: 0.38287
Value Function Update Magnitude: 0.31313

Collected Steps per Second: 16,441.14216
Overall Steps per Second: 8,900.67188

Timestep Collection Time: 3.04419
Timestep Consumption Time: 2.57898
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.62317

Cumulative Model Updates: 160,160
Cumulative Timesteps: 1,335,501,776

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,142.93758
Policy Entropy: 3.77589
Value Function Loss: 0.01655

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11883
Policy Update Magnitude: 0.41022
Value Function Update Magnitude: 0.38468

Collected Steps per Second: 17,171.74374
Overall Steps per Second: 9,182.27388

Timestep Collection Time: 2.91176
Timestep Consumption Time: 2.53351
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 5.44527

Cumulative Model Updates: 160,166
Cumulative Timesteps: 1,335,551,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1335551776...
Checkpoint 1335551776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,310.83633
Policy Entropy: 3.79081
Value Function Loss: 0.01629

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12159
Policy Update Magnitude: 0.41902
Value Function Update Magnitude: 0.43853

Collected Steps per Second: 17,145.60244
Overall Steps per Second: 9,021.23969

Timestep Collection Time: 2.91678
Timestep Consumption Time: 2.62680
PPO Batch Consumption Time: 0.31038
Total Iteration Time: 5.54358

Cumulative Model Updates: 160,172
Cumulative Timesteps: 1,335,601,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,087.76920
Policy Entropy: 3.79284
Value Function Loss: 0.01607

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.40069
Value Function Update Magnitude: 0.42106

Collected Steps per Second: 17,572.55682
Overall Steps per Second: 9,197.52775

Timestep Collection Time: 2.84569
Timestep Consumption Time: 2.59121
PPO Batch Consumption Time: 0.30389
Total Iteration Time: 5.43690

Cumulative Model Updates: 160,178
Cumulative Timesteps: 1,335,651,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1335651792...
Checkpoint 1335651792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,888.13056
Policy Entropy: 3.79665
Value Function Loss: 0.01596

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.41013
Value Function Update Magnitude: 0.45629

Collected Steps per Second: 17,477.41074
Overall Steps per Second: 9,070.89852

Timestep Collection Time: 2.86164
Timestep Consumption Time: 2.65204
PPO Batch Consumption Time: 0.31324
Total Iteration Time: 5.51368

Cumulative Model Updates: 160,184
Cumulative Timesteps: 1,335,701,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,816.79690
Policy Entropy: 3.76774
Value Function Loss: 0.01679

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15465
Policy Update Magnitude: 0.38314
Value Function Update Magnitude: 0.46202

Collected Steps per Second: 17,367.27189
Overall Steps per Second: 9,061.09232

Timestep Collection Time: 2.87944
Timestep Consumption Time: 2.63954
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 5.51898

Cumulative Model Updates: 160,190
Cumulative Timesteps: 1,335,751,814

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1335751814...
Checkpoint 1335751814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,035.57317
Policy Entropy: 3.76190
Value Function Loss: 0.01729

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.38003
Value Function Update Magnitude: 0.39320

Collected Steps per Second: 17,136.19304
Overall Steps per Second: 9,128.51994

Timestep Collection Time: 2.91943
Timestep Consumption Time: 2.56097
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 5.48041

Cumulative Model Updates: 160,196
Cumulative Timesteps: 1,335,801,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,640.34806
Policy Entropy: 3.75551
Value Function Loss: 0.01949

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.41439
Value Function Update Magnitude: 0.37657

Collected Steps per Second: 16,929.97805
Overall Steps per Second: 9,048.45800

Timestep Collection Time: 2.95334
Timestep Consumption Time: 2.57246
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 5.52580

Cumulative Model Updates: 160,202
Cumulative Timesteps: 1,335,851,842

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1335851842...
Checkpoint 1335851842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,968.56340
Policy Entropy: 3.77657
Value Function Loss: 0.02195

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12619
Policy Update Magnitude: 0.51604
Value Function Update Magnitude: 0.44175

Collected Steps per Second: 16,847.41090
Overall Steps per Second: 9,063.68143

Timestep Collection Time: 2.97090
Timestep Consumption Time: 2.55136
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 5.52226

Cumulative Model Updates: 160,208
Cumulative Timesteps: 1,335,901,894

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,801.39783
Policy Entropy: 3.78982
Value Function Loss: 0.02260

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12231
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.50068

Collected Steps per Second: 17,268.17070
Overall Steps per Second: 9,145.02479

Timestep Collection Time: 2.89793
Timestep Consumption Time: 2.57411
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 5.47205

Cumulative Model Updates: 160,214
Cumulative Timesteps: 1,335,951,936

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1335951936...
Checkpoint 1335951936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.62968
Policy Entropy: 3.79885
Value Function Loss: 0.02166

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.53711
Value Function Update Magnitude: 0.56077

Collected Steps per Second: 17,230.72861
Overall Steps per Second: 9,082.85781

Timestep Collection Time: 2.90284
Timestep Consumption Time: 2.60402
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 5.50686

Cumulative Model Updates: 160,220
Cumulative Timesteps: 1,336,001,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338,899.51379
Policy Entropy: 3.77582
Value Function Loss: 0.01997

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.51027
Value Function Update Magnitude: 0.62592

Collected Steps per Second: 17,178.11350
Overall Steps per Second: 9,072.29335

Timestep Collection Time: 2.91196
Timestep Consumption Time: 2.60175
PPO Batch Consumption Time: 0.29944
Total Iteration Time: 5.51371

Cumulative Model Updates: 160,226
Cumulative Timesteps: 1,336,051,976

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1336051976...
Checkpoint 1336051976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,240.91903
Policy Entropy: 3.77428
Value Function Loss: 0.02635

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.62853

Collected Steps per Second: 17,571.53367
Overall Steps per Second: 9,156.92152

Timestep Collection Time: 2.84642
Timestep Consumption Time: 2.61568
PPO Batch Consumption Time: 0.30202
Total Iteration Time: 5.46210

Cumulative Model Updates: 160,232
Cumulative Timesteps: 1,336,101,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,093.42098
Policy Entropy: 3.79534
Value Function Loss: 0.02688

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.62724
Value Function Update Magnitude: 0.65901

Collected Steps per Second: 17,580.10192
Overall Steps per Second: 9,055.67961

Timestep Collection Time: 2.84503
Timestep Consumption Time: 2.67813
PPO Batch Consumption Time: 0.31400
Total Iteration Time: 5.52316

Cumulative Model Updates: 160,238
Cumulative Timesteps: 1,336,152,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1336152008...
Checkpoint 1336152008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,014.51210
Policy Entropy: 3.81450
Value Function Loss: 0.02759

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13034
Policy Update Magnitude: 0.67701
Value Function Update Magnitude: 0.71760

Collected Steps per Second: 17,431.79602
Overall Steps per Second: 9,051.54622

Timestep Collection Time: 2.86912
Timestep Consumption Time: 2.65634
PPO Batch Consumption Time: 0.30331
Total Iteration Time: 5.52546

Cumulative Model Updates: 160,244
Cumulative Timesteps: 1,336,202,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.37487
Policy Entropy: 3.80269
Value Function Loss: 0.02170

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12216
Policy Update Magnitude: 0.65556
Value Function Update Magnitude: 0.68133

Collected Steps per Second: 17,271.88364
Overall Steps per Second: 9,028.89336

Timestep Collection Time: 2.89569
Timestep Consumption Time: 2.64364
PPO Batch Consumption Time: 0.30432
Total Iteration Time: 5.53933

Cumulative Model Updates: 160,250
Cumulative Timesteps: 1,336,252,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1336252036...
Checkpoint 1336252036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,222.23430
Policy Entropy: 3.77513
Value Function Loss: 0.02118

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14127
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.55094

Collected Steps per Second: 16,996.20249
Overall Steps per Second: 9,071.80735

Timestep Collection Time: 2.94372
Timestep Consumption Time: 2.57139
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 5.51511

Cumulative Model Updates: 160,256
Cumulative Timesteps: 1,336,302,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,999.47142
Policy Entropy: 3.76541
Value Function Loss: 0.02176

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.50064

Collected Steps per Second: 16,819.03377
Overall Steps per Second: 8,965.89557

Timestep Collection Time: 2.97484
Timestep Consumption Time: 2.60564
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 5.58048

Cumulative Model Updates: 160,262
Cumulative Timesteps: 1,336,352,102

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1336352102...
Checkpoint 1336352102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,363.79506
Policy Entropy: 3.77925
Value Function Loss: 0.02406

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13610
Policy Update Magnitude: 0.61613
Value Function Update Magnitude: 0.47686

Collected Steps per Second: 16,813.28952
Overall Steps per Second: 8,819.09215

Timestep Collection Time: 2.97574
Timestep Consumption Time: 2.69741
PPO Batch Consumption Time: 0.30376
Total Iteration Time: 5.67315

Cumulative Model Updates: 160,268
Cumulative Timesteps: 1,336,402,134

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,354.30359
Policy Entropy: 3.79077
Value Function Loss: 0.02354

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12561
Policy Update Magnitude: 0.67424
Value Function Update Magnitude: 0.50946

Collected Steps per Second: 16,929.07661
Overall Steps per Second: 8,870.09733

Timestep Collection Time: 2.95362
Timestep Consumption Time: 2.68353
PPO Batch Consumption Time: 0.29952
Total Iteration Time: 5.63714

Cumulative Model Updates: 160,274
Cumulative Timesteps: 1,336,452,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1336452136...
Checkpoint 1336452136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,290.34340
Policy Entropy: 3.80223
Value Function Loss: 0.02244

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.63132
Value Function Update Magnitude: 0.53632

Collected Steps per Second: 17,165.79948
Overall Steps per Second: 9,055.84306

Timestep Collection Time: 2.91277
Timestep Consumption Time: 2.60853
PPO Batch Consumption Time: 0.30296
Total Iteration Time: 5.52130

Cumulative Model Updates: 160,280
Cumulative Timesteps: 1,336,502,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,208.52378
Policy Entropy: 3.81010
Value Function Loss: 0.02203

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.16096
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 17,611.43852
Overall Steps per Second: 9,019.87159

Timestep Collection Time: 2.83918
Timestep Consumption Time: 2.70436
PPO Batch Consumption Time: 0.31815
Total Iteration Time: 5.54354

Cumulative Model Updates: 160,286
Cumulative Timesteps: 1,336,552,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1336552138...
Checkpoint 1336552138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.56882
Policy Entropy: 3.81363
Value Function Loss: 0.02085

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.52689
Value Function Update Magnitude: 0.52998

Collected Steps per Second: 17,511.35080
Overall Steps per Second: 9,113.33365

Timestep Collection Time: 2.85758
Timestep Consumption Time: 2.63328
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 5.49086

Cumulative Model Updates: 160,292
Cumulative Timesteps: 1,336,602,178

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,612.05158
Policy Entropy: 3.82873
Value Function Loss: 0.02835

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.52599
Value Function Update Magnitude: 0.52338

Collected Steps per Second: 17,468.90702
Overall Steps per Second: 9,144.30424

Timestep Collection Time: 2.86326
Timestep Consumption Time: 2.60659
PPO Batch Consumption Time: 0.30417
Total Iteration Time: 5.46985

Cumulative Model Updates: 160,298
Cumulative Timesteps: 1,336,652,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1336652196...
Checkpoint 1336652196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,758.84048
Policy Entropy: 3.84006
Value Function Loss: 0.03117

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.60801
Value Function Update Magnitude: 0.69234

Collected Steps per Second: 16,935.58669
Overall Steps per Second: 9,044.49953

Timestep Collection Time: 2.95295
Timestep Consumption Time: 2.57637
PPO Batch Consumption Time: 0.30393
Total Iteration Time: 5.52933

Cumulative Model Updates: 160,304
Cumulative Timesteps: 1,336,702,206

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,589.47177
Policy Entropy: 3.83498
Value Function Loss: 0.03672

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13004
Policy Update Magnitude: 0.65898
Value Function Update Magnitude: 0.65573

Collected Steps per Second: 16,629.32727
Overall Steps per Second: 8,970.32870

Timestep Collection Time: 3.00746
Timestep Consumption Time: 2.56781
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 5.57527

Cumulative Model Updates: 160,310
Cumulative Timesteps: 1,336,752,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1336752218...
Checkpoint 1336752218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.82370
Policy Entropy: 3.83895
Value Function Loss: 0.03129

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.65866
Value Function Update Magnitude: 0.60124

Collected Steps per Second: 16,894.55849
Overall Steps per Second: 9,108.36320

Timestep Collection Time: 2.95953
Timestep Consumption Time: 2.52993
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 5.48946

Cumulative Model Updates: 160,316
Cumulative Timesteps: 1,336,802,218

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.28204
Policy Entropy: 3.82688
Value Function Loss: 0.03088

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.61592
Value Function Update Magnitude: 0.57586

Collected Steps per Second: 16,884.67569
Overall Steps per Second: 9,024.62473

Timestep Collection Time: 2.96138
Timestep Consumption Time: 2.57923
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 5.54062

Cumulative Model Updates: 160,322
Cumulative Timesteps: 1,336,852,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1336852220...
Checkpoint 1336852220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,114.16391
Policy Entropy: 3.81293
Value Function Loss: 0.02669

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12538
Policy Update Magnitude: 0.58505
Value Function Update Magnitude: 0.55530

Collected Steps per Second: 17,023.13660
Overall Steps per Second: 8,941.05612

Timestep Collection Time: 2.93753
Timestep Consumption Time: 2.65532
PPO Batch Consumption Time: 0.31704
Total Iteration Time: 5.59285

Cumulative Model Updates: 160,328
Cumulative Timesteps: 1,336,902,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,037.43110
Policy Entropy: 3.79921
Value Function Loss: 0.02510

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.54316
Value Function Update Magnitude: 0.49637

Collected Steps per Second: 17,547.61670
Overall Steps per Second: 9,155.34207

Timestep Collection Time: 2.84985
Timestep Consumption Time: 2.61232
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 5.46217

Cumulative Model Updates: 160,334
Cumulative Timesteps: 1,336,952,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1336952234...
Checkpoint 1336952234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,258.65497
Policy Entropy: 3.78647
Value Function Loss: 0.02141

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.51258
Value Function Update Magnitude: 0.51960

Collected Steps per Second: 17,547.97950
Overall Steps per Second: 9,128.53701

Timestep Collection Time: 2.85013
Timestep Consumption Time: 2.62873
PPO Batch Consumption Time: 0.30300
Total Iteration Time: 5.47886

Cumulative Model Updates: 160,340
Cumulative Timesteps: 1,337,002,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,061.64475
Policy Entropy: 3.77601
Value Function Loss: 0.02139

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.52563
Value Function Update Magnitude: 0.57301

Collected Steps per Second: 17,522.14417
Overall Steps per Second: 9,076.33780

Timestep Collection Time: 2.85422
Timestep Consumption Time: 2.65594
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 5.51015

Cumulative Model Updates: 160,346
Cumulative Timesteps: 1,337,052,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1337052260...
Checkpoint 1337052260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,644.08402
Policy Entropy: 3.76777
Value Function Loss: 0.02148

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13569
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.61697

Collected Steps per Second: 17,447.39210
Overall Steps per Second: 9,230.70680

Timestep Collection Time: 2.86576
Timestep Consumption Time: 2.55095
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 5.41670

Cumulative Model Updates: 160,352
Cumulative Timesteps: 1,337,102,260

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,729.82135
Policy Entropy: 3.77103
Value Function Loss: 0.02199

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.58319

Collected Steps per Second: 17,047.96581
Overall Steps per Second: 8,975.38419

Timestep Collection Time: 2.93337
Timestep Consumption Time: 2.63831
PPO Batch Consumption Time: 0.30667
Total Iteration Time: 5.57168

Cumulative Model Updates: 160,358
Cumulative Timesteps: 1,337,152,268

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1337152268...
Checkpoint 1337152268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,767.23187
Policy Entropy: 3.78484
Value Function Loss: 0.01976

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12791
Policy Update Magnitude: 0.51815
Value Function Update Magnitude: 0.55717

Collected Steps per Second: 17,011.65816
Overall Steps per Second: 9,008.77234

Timestep Collection Time: 2.94116
Timestep Consumption Time: 2.61276
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 5.55392

Cumulative Model Updates: 160,364
Cumulative Timesteps: 1,337,202,302

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,781.50356
Policy Entropy: 3.78699
Value Function Loss: 0.02135

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.52609
Value Function Update Magnitude: 0.52555

Collected Steps per Second: 17,059.02271
Overall Steps per Second: 9,021.49809

Timestep Collection Time: 2.93346
Timestep Consumption Time: 2.61351
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 5.54697

Cumulative Model Updates: 160,370
Cumulative Timesteps: 1,337,252,344

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1337252344...
Checkpoint 1337252344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,740.84328
Policy Entropy: 3.79054
Value Function Loss: 0.02096

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.50754
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 17,211.04710
Overall Steps per Second: 9,046.49959

Timestep Collection Time: 2.90592
Timestep Consumption Time: 2.62262
PPO Batch Consumption Time: 0.31150
Total Iteration Time: 5.52855

Cumulative Model Updates: 160,376
Cumulative Timesteps: 1,337,302,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,169.14852
Policy Entropy: 3.77581
Value Function Loss: 0.02281

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 17,358.13370
Overall Steps per Second: 8,988.22833

Timestep Collection Time: 2.88107
Timestep Consumption Time: 2.68287
PPO Batch Consumption Time: 0.31341
Total Iteration Time: 5.56394

Cumulative Model Updates: 160,382
Cumulative Timesteps: 1,337,352,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1337352368...
Checkpoint 1337352368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,169.14852
Policy Entropy: 3.75753
Value Function Loss: 0.02161

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.54879
Value Function Update Magnitude: 0.75202

Collected Steps per Second: 17,240.70590
Overall Steps per Second: 9,030.16511

Timestep Collection Time: 2.90081
Timestep Consumption Time: 2.63752
PPO Batch Consumption Time: 0.30366
Total Iteration Time: 5.53833

Cumulative Model Updates: 160,388
Cumulative Timesteps: 1,337,402,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,169.10916
Policy Entropy: 3.76494
Value Function Loss: 0.02492

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.80905

Collected Steps per Second: 17,563.61648
Overall Steps per Second: 9,176.38563

Timestep Collection Time: 2.84725
Timestep Consumption Time: 2.60239
PPO Batch Consumption Time: 0.30163
Total Iteration Time: 5.44964

Cumulative Model Updates: 160,394
Cumulative Timesteps: 1,337,452,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1337452388...
Checkpoint 1337452388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,527.15435
Policy Entropy: 3.77801
Value Function Loss: 0.02400

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.77844

Collected Steps per Second: 17,493.62961
Overall Steps per Second: 9,212.19110

Timestep Collection Time: 2.85818
Timestep Consumption Time: 2.56941
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 5.42759

Cumulative Model Updates: 160,400
Cumulative Timesteps: 1,337,502,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,262.68971
Policy Entropy: 3.78476
Value Function Loss: 0.02586

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.52959
Value Function Update Magnitude: 0.70879

Collected Steps per Second: 17,441.21477
Overall Steps per Second: 9,162.83693

Timestep Collection Time: 2.86872
Timestep Consumption Time: 2.59181
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 5.46054

Cumulative Model Updates: 160,406
Cumulative Timesteps: 1,337,552,422

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1337552422...
Checkpoint 1337552422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,912.53031
Policy Entropy: 3.78935
Value Function Loss: 0.02410

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.50551
Value Function Update Magnitude: 0.81143

Collected Steps per Second: 17,004.54084
Overall Steps per Second: 8,994.53642

Timestep Collection Time: 2.94063
Timestep Consumption Time: 2.61875
PPO Batch Consumption Time: 0.30230
Total Iteration Time: 5.55937

Cumulative Model Updates: 160,412
Cumulative Timesteps: 1,337,602,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,432.80617
Policy Entropy: 3.78287
Value Function Loss: 0.02441

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13852
Policy Update Magnitude: 0.49935
Value Function Update Magnitude: 0.79099

Collected Steps per Second: 17,195.53678
Overall Steps per Second: 9,211.44503

Timestep Collection Time: 2.90936
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 5.43107

Cumulative Model Updates: 160,418
Cumulative Timesteps: 1,337,652,454

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1337652454...
Checkpoint 1337652454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,870.78261
Policy Entropy: 3.79600
Value Function Loss: 0.01997

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13396
Policy Update Magnitude: 0.47159
Value Function Update Magnitude: 0.77692

Collected Steps per Second: 17,384.04622
Overall Steps per Second: 9,225.46698

Timestep Collection Time: 2.87678
Timestep Consumption Time: 2.54409
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 5.42086

Cumulative Model Updates: 160,424
Cumulative Timesteps: 1,337,702,464

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260,487.19490
Policy Entropy: 3.78280
Value Function Loss: 0.01958

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.47869
Value Function Update Magnitude: 0.77597

Collected Steps per Second: 16,977.99439
Overall Steps per Second: 8,933.55751

Timestep Collection Time: 2.94628
Timestep Consumption Time: 2.65305
PPO Batch Consumption Time: 0.31018
Total Iteration Time: 5.59934

Cumulative Model Updates: 160,430
Cumulative Timesteps: 1,337,752,486

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1337752486...
Checkpoint 1337752486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,842.63883
Policy Entropy: 3.77282
Value Function Loss: 0.01775

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13688
Policy Update Magnitude: 0.46641
Value Function Update Magnitude: 0.68304

Collected Steps per Second: 17,564.89477
Overall Steps per Second: 9,044.33117

Timestep Collection Time: 2.84670
Timestep Consumption Time: 2.68185
PPO Batch Consumption Time: 0.31562
Total Iteration Time: 5.52855

Cumulative Model Updates: 160,436
Cumulative Timesteps: 1,337,802,488

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,124.37459
Policy Entropy: 3.75756
Value Function Loss: 0.02106

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.49368
Value Function Update Magnitude: 0.75419

Collected Steps per Second: 17,335.93554
Overall Steps per Second: 8,969.49599

Timestep Collection Time: 2.88591
Timestep Consumption Time: 2.69188
PPO Batch Consumption Time: 0.31652
Total Iteration Time: 5.57779

Cumulative Model Updates: 160,442
Cumulative Timesteps: 1,337,852,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1337852518...
Checkpoint 1337852518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,277.99299
Policy Entropy: 3.76025
Value Function Loss: 0.01831

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.50462
Value Function Update Magnitude: 0.75224

Collected Steps per Second: 17,592.99466
Overall Steps per Second: 9,118.31332

Timestep Collection Time: 2.84272
Timestep Consumption Time: 2.64206
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 5.48479

Cumulative Model Updates: 160,448
Cumulative Timesteps: 1,337,902,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220,277.99299
Policy Entropy: 3.75609
Value Function Loss: 0.01697

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.45334
Value Function Update Magnitude: 0.63495

Collected Steps per Second: 17,358.55326
Overall Steps per Second: 8,983.81401

Timestep Collection Time: 2.88192
Timestep Consumption Time: 2.68654
PPO Batch Consumption Time: 0.31076
Total Iteration Time: 5.56846

Cumulative Model Updates: 160,454
Cumulative Timesteps: 1,337,952,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1337952556...
Checkpoint 1337952556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,277.99299
Policy Entropy: 3.75037
Value Function Loss: 0.01342

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.38922
Value Function Update Magnitude: 0.42786

Collected Steps per Second: 17,110.49909
Overall Steps per Second: 9,111.90054

Timestep Collection Time: 2.92440
Timestep Consumption Time: 2.56710
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 5.49150

Cumulative Model Updates: 160,460
Cumulative Timesteps: 1,338,002,594

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 188,813.05995
Policy Entropy: 3.74956
Value Function Loss: 0.01396

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.36527
Value Function Update Magnitude: 0.33512

Collected Steps per Second: 17,180.55323
Overall Steps per Second: 9,036.62177

Timestep Collection Time: 2.91062
Timestep Consumption Time: 2.62309
PPO Batch Consumption Time: 0.30502
Total Iteration Time: 5.53371

Cumulative Model Updates: 160,466
Cumulative Timesteps: 1,338,052,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1338052600...
Checkpoint 1338052600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,813.05995
Policy Entropy: 3.74670
Value Function Loss: 0.01329

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.37058
Value Function Update Magnitude: 0.37491

Collected Steps per Second: 16,635.53796
Overall Steps per Second: 9,009.11709

Timestep Collection Time: 3.00634
Timestep Consumption Time: 2.54493
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 5.55127

Cumulative Model Updates: 160,472
Cumulative Timesteps: 1,338,102,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,277.17134
Policy Entropy: 3.75691
Value Function Loss: 0.01361

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.37055
Value Function Update Magnitude: 0.40027

Collected Steps per Second: 17,217.57066
Overall Steps per Second: 9,062.92986

Timestep Collection Time: 2.90622
Timestep Consumption Time: 2.61496
PPO Batch Consumption Time: 0.30374
Total Iteration Time: 5.52117

Cumulative Model Updates: 160,478
Cumulative Timesteps: 1,338,152,650

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1338152650...
Checkpoint 1338152650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,210.22382
Policy Entropy: 3.76167
Value Function Loss: 0.01314

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.38856
Value Function Update Magnitude: 0.42295

Collected Steps per Second: 16,865.28509
Overall Steps per Second: 8,905.85616

Timestep Collection Time: 2.96574
Timestep Consumption Time: 2.65057
PPO Batch Consumption Time: 0.30609
Total Iteration Time: 5.61630

Cumulative Model Updates: 160,484
Cumulative Timesteps: 1,338,202,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,085.67545
Policy Entropy: 3.77157
Value Function Loss: 0.01546

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.41772
Value Function Update Magnitude: 0.44111

Collected Steps per Second: 17,324.32201
Overall Steps per Second: 9,039.58110

Timestep Collection Time: 2.88785
Timestep Consumption Time: 2.64670
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 5.53455

Cumulative Model Updates: 160,490
Cumulative Timesteps: 1,338,252,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1338252698...
Checkpoint 1338252698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,996.23082
Policy Entropy: 3.77007
Value Function Loss: 0.01722

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.44870
Value Function Update Magnitude: 0.46388

Collected Steps per Second: 17,233.34243
Overall Steps per Second: 9,049.90668

Timestep Collection Time: 2.90321
Timestep Consumption Time: 2.62525
PPO Batch Consumption Time: 0.30404
Total Iteration Time: 5.52845

Cumulative Model Updates: 160,496
Cumulative Timesteps: 1,338,302,730

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,272.85418
Policy Entropy: 3.76783
Value Function Loss: 0.01911

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.46880
Value Function Update Magnitude: 0.45612

Collected Steps per Second: 17,618.60952
Overall Steps per Second: 9,142.46788

Timestep Collection Time: 2.83859
Timestep Consumption Time: 2.63171
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 5.47030

Cumulative Model Updates: 160,502
Cumulative Timesteps: 1,338,352,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1338352742...
Checkpoint 1338352742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,578.60097
Policy Entropy: 3.78273
Value Function Loss: 0.01770

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.46641
Value Function Update Magnitude: 0.47917

Collected Steps per Second: 16,725.33714
Overall Steps per Second: 9,001.67334

Timestep Collection Time: 2.99211
Timestep Consumption Time: 2.56730
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 5.55941

Cumulative Model Updates: 160,508
Cumulative Timesteps: 1,338,402,786

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,440.29986
Policy Entropy: 3.80196
Value Function Loss: 0.01931

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12659
Policy Update Magnitude: 0.48013
Value Function Update Magnitude: 0.50513

Collected Steps per Second: 17,204.76028
Overall Steps per Second: 9,041.82945

Timestep Collection Time: 2.90733
Timestep Consumption Time: 2.62473
PPO Batch Consumption Time: 0.30096
Total Iteration Time: 5.53207

Cumulative Model Updates: 160,514
Cumulative Timesteps: 1,338,452,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1338452806...
Checkpoint 1338452806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,610.06849
Policy Entropy: 3.77954
Value Function Loss: 0.02052

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.52324
Value Function Update Magnitude: 0.61238

Collected Steps per Second: 17,469.39659
Overall Steps per Second: 9,175.62398

Timestep Collection Time: 2.86283
Timestep Consumption Time: 2.58769
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 5.45053

Cumulative Model Updates: 160,520
Cumulative Timesteps: 1,338,502,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,684.42632
Policy Entropy: 3.78229
Value Function Loss: 0.02194

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.73818

Collected Steps per Second: 17,071.86573
Overall Steps per Second: 9,019.81969

Timestep Collection Time: 2.92926
Timestep Consumption Time: 2.61497
PPO Batch Consumption Time: 0.30337
Total Iteration Time: 5.54423

Cumulative Model Updates: 160,526
Cumulative Timesteps: 1,338,552,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1338552826...
Checkpoint 1338552826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,068.16733
Policy Entropy: 3.76871
Value Function Loss: 0.02015

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.57522
Value Function Update Magnitude: 0.69148

Collected Steps per Second: 17,246.73555
Overall Steps per Second: 8,955.17300

Timestep Collection Time: 2.90026
Timestep Consumption Time: 2.68534
PPO Batch Consumption Time: 0.31481
Total Iteration Time: 5.58560

Cumulative Model Updates: 160,532
Cumulative Timesteps: 1,338,602,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,821.31824
Policy Entropy: 3.78877
Value Function Loss: 0.02048

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12573
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.61019

Collected Steps per Second: 17,230.07194
Overall Steps per Second: 8,954.53414

Timestep Collection Time: 2.90214
Timestep Consumption Time: 2.68207
PPO Batch Consumption Time: 0.31636
Total Iteration Time: 5.58421

Cumulative Model Updates: 160,538
Cumulative Timesteps: 1,338,652,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1338652850...
Checkpoint 1338652850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,766.81234
Policy Entropy: 3.78040
Value Function Loss: 0.01908

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 15,207.45794
Overall Steps per Second: 8,595.78055

Timestep Collection Time: 3.29075
Timestep Consumption Time: 2.53117
PPO Batch Consumption Time: 0.29933
Total Iteration Time: 5.82193

Cumulative Model Updates: 160,544
Cumulative Timesteps: 1,338,702,894

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,698.46684
Policy Entropy: 3.78717
Value Function Loss: 0.01973

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 17,920.51455
Overall Steps per Second: 9,167.28968

Timestep Collection Time: 2.79133
Timestep Consumption Time: 2.66525
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 5.45657

Cumulative Model Updates: 160,550
Cumulative Timesteps: 1,338,752,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1338752916...
Checkpoint 1338752916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,698.46684
Policy Entropy: 3.76423
Value Function Loss: 0.01624

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.49531
Value Function Update Magnitude: 0.55011

Collected Steps per Second: 17,973.82621
Overall Steps per Second: 9,260.37854

Timestep Collection Time: 2.78316
Timestep Consumption Time: 2.61878
PPO Batch Consumption Time: 0.30546
Total Iteration Time: 5.40194

Cumulative Model Updates: 160,556
Cumulative Timesteps: 1,338,802,940

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,698.46684
Policy Entropy: 3.75597
Value Function Loss: 0.01471

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.45138
Value Function Update Magnitude: 0.52542

Collected Steps per Second: 18,240.53488
Overall Steps per Second: 9,303.03028

Timestep Collection Time: 2.74213
Timestep Consumption Time: 2.63439
PPO Batch Consumption Time: 0.30638
Total Iteration Time: 5.37653

Cumulative Model Updates: 160,562
Cumulative Timesteps: 1,338,852,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1338852958...
Checkpoint 1338852958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,698.46684
Policy Entropy: 3.74605
Value Function Loss: 0.01359

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.43530
Value Function Update Magnitude: 0.46997

Collected Steps per Second: 18,087.01041
Overall Steps per Second: 9,415.53905

Timestep Collection Time: 2.76508
Timestep Consumption Time: 2.54657
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 5.31164

Cumulative Model Updates: 160,568
Cumulative Timesteps: 1,338,902,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,693.24178
Policy Entropy: 3.76107
Value Function Loss: 0.01651

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.46846
Value Function Update Magnitude: 0.58768

Collected Steps per Second: 18,427.62028
Overall Steps per Second: 9,427.80003

Timestep Collection Time: 2.71386
Timestep Consumption Time: 2.59066
PPO Batch Consumption Time: 0.30204
Total Iteration Time: 5.30452

Cumulative Model Updates: 160,574
Cumulative Timesteps: 1,338,952,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1338952980...
Checkpoint 1338952980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,497.48318
Policy Entropy: 3.77990
Value Function Loss: 0.01983

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12163
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 18,435.46402
Overall Steps per Second: 9,356.93124

Timestep Collection Time: 2.71216
Timestep Consumption Time: 2.63147
PPO Batch Consumption Time: 0.30518
Total Iteration Time: 5.34363

Cumulative Model Updates: 160,580
Cumulative Timesteps: 1,339,002,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.94911
Policy Entropy: 3.79943
Value Function Loss: 0.02191

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.58580
Value Function Update Magnitude: 0.60130

Collected Steps per Second: 18,092.38428
Overall Steps per Second: 9,052.43087

Timestep Collection Time: 2.76525
Timestep Consumption Time: 2.76144
PPO Batch Consumption Time: 0.32947
Total Iteration Time: 5.52669

Cumulative Model Updates: 160,586
Cumulative Timesteps: 1,339,053,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1339053010...
Checkpoint 1339053010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 561.94911
Policy Entropy: 3.78418
Value Function Loss: 0.01882

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.60831

Collected Steps per Second: 17,391.58622
Overall Steps per Second: 8,825.99447

Timestep Collection Time: 2.87518
Timestep Consumption Time: 2.79035
PPO Batch Consumption Time: 0.32893
Total Iteration Time: 5.66554

Cumulative Model Updates: 160,592
Cumulative Timesteps: 1,339,103,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307,802.01638
Policy Entropy: 3.76073
Value Function Loss: 0.01674

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.60983

Collected Steps per Second: 16,066.38665
Overall Steps per Second: 8,575.48024

Timestep Collection Time: 3.11234
Timestep Consumption Time: 2.71871
PPO Batch Consumption Time: 0.31208
Total Iteration Time: 5.83104

Cumulative Model Updates: 160,598
Cumulative Timesteps: 1,339,153,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1339153018...
Checkpoint 1339153018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,321.47087
Policy Entropy: 3.73416
Value Function Loss: 0.01464

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14372
Policy Update Magnitude: 0.52423
Value Function Update Magnitude: 0.55270

Collected Steps per Second: 17,280.92234
Overall Steps per Second: 9,178.36044

Timestep Collection Time: 2.89510
Timestep Consumption Time: 2.55576
PPO Batch Consumption Time: 0.29803
Total Iteration Time: 5.45086

Cumulative Model Updates: 160,604
Cumulative Timesteps: 1,339,203,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,987.12619
Policy Entropy: 3.73513
Value Function Loss: 0.01939

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.52334
Value Function Update Magnitude: 0.53431

Collected Steps per Second: 18,108.44963
Overall Steps per Second: 9,527.06021

Timestep Collection Time: 2.76125
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 5.24842

Cumulative Model Updates: 160,610
Cumulative Timesteps: 1,339,253,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1339253050...
Checkpoint 1339253050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,314.00350
Policy Entropy: 3.75029
Value Function Loss: 0.02029

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.59005

Collected Steps per Second: 17,691.78612
Overall Steps per Second: 9,258.03360

Timestep Collection Time: 2.82696
Timestep Consumption Time: 2.57527
PPO Batch Consumption Time: 0.31471
Total Iteration Time: 5.40223

Cumulative Model Updates: 160,616
Cumulative Timesteps: 1,339,303,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,583.06707
Policy Entropy: 3.76184
Value Function Loss: 0.03104

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.48832

Collected Steps per Second: 17,482.60428
Overall Steps per Second: 9,371.63983

Timestep Collection Time: 2.86021
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 5.33567

Cumulative Model Updates: 160,622
Cumulative Timesteps: 1,339,353,068

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1339353068...
Checkpoint 1339353068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,137.76119
Policy Entropy: 3.80210
Value Function Loss: 0.03352

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.64266
Value Function Update Magnitude: 0.47364

Collected Steps per Second: 18,029.76693
Overall Steps per Second: 9,541.31593

Timestep Collection Time: 2.77319
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 5.24037

Cumulative Model Updates: 160,628
Cumulative Timesteps: 1,339,403,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,137.00769
Policy Entropy: 3.80104
Value Function Loss: 0.03446

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14384
Policy Update Magnitude: 0.66099
Value Function Update Magnitude: 0.56153

Collected Steps per Second: 18,236.21555
Overall Steps per Second: 9,352.22289

Timestep Collection Time: 2.74235
Timestep Consumption Time: 2.60505
PPO Batch Consumption Time: 0.30828
Total Iteration Time: 5.34739

Cumulative Model Updates: 160,634
Cumulative Timesteps: 1,339,453,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1339453078...
Checkpoint 1339453078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.35654
Policy Entropy: 3.82377
Value Function Loss: 0.02713

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12428
Policy Update Magnitude: 0.62730
Value Function Update Magnitude: 0.78790

Collected Steps per Second: 18,299.36256
Overall Steps per Second: 9,449.21434

Timestep Collection Time: 2.73419
Timestep Consumption Time: 2.56085
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 5.29504

Cumulative Model Updates: 160,640
Cumulative Timesteps: 1,339,503,112

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.99622
Policy Entropy: 3.80269
Value Function Loss: 0.02333

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.82539

Collected Steps per Second: 17,172.73135
Overall Steps per Second: 8,847.11374

Timestep Collection Time: 2.91334
Timestep Consumption Time: 2.74161
PPO Batch Consumption Time: 0.31695
Total Iteration Time: 5.65495

Cumulative Model Updates: 160,646
Cumulative Timesteps: 1,339,553,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1339553142...
Checkpoint 1339553142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350.32619
Policy Entropy: 3.79232
Value Function Loss: 0.01864

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.51564
Value Function Update Magnitude: 0.70500

Collected Steps per Second: 17,861.03936
Overall Steps per Second: 9,182.11477

Timestep Collection Time: 2.80196
Timestep Consumption Time: 2.64841
PPO Batch Consumption Time: 0.31553
Total Iteration Time: 5.45038

Cumulative Model Updates: 160,652
Cumulative Timesteps: 1,339,603,188

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,536.00627
Policy Entropy: 3.77644
Value Function Loss: 0.01789

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13424
Policy Update Magnitude: 0.48419
Value Function Update Magnitude: 0.67290

Collected Steps per Second: 16,880.23183
Overall Steps per Second: 8,809.89355

Timestep Collection Time: 2.96287
Timestep Consumption Time: 2.71415
PPO Batch Consumption Time: 0.32603
Total Iteration Time: 5.67703

Cumulative Model Updates: 160,658
Cumulative Timesteps: 1,339,653,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1339653202...
Checkpoint 1339653202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309,957.67439
Policy Entropy: 3.75164
Value Function Loss: 0.01750

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.51962
Value Function Update Magnitude: 0.68992

Collected Steps per Second: 16,945.05389
Overall Steps per Second: 9,119.60412

Timestep Collection Time: 2.95178
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 5.48467

Cumulative Model Updates: 160,664
Cumulative Timesteps: 1,339,703,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,491.57572
Policy Entropy: 3.76152
Value Function Loss: 0.01962

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.71725

Collected Steps per Second: 16,782.19625
Overall Steps per Second: 8,840.81656

Timestep Collection Time: 2.97994
Timestep Consumption Time: 2.67677
PPO Batch Consumption Time: 0.31044
Total Iteration Time: 5.65672

Cumulative Model Updates: 160,670
Cumulative Timesteps: 1,339,753,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1339753230...
Checkpoint 1339753230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,768.73735
Policy Entropy: 3.75180
Value Function Loss: 0.01751

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.50579
Value Function Update Magnitude: 0.70232

Collected Steps per Second: 19,379.48994
Overall Steps per Second: 9,778.97653

Timestep Collection Time: 2.58201
Timestep Consumption Time: 2.53489
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 5.11690

Cumulative Model Updates: 160,676
Cumulative Timesteps: 1,339,803,268

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,686.94353
Policy Entropy: 3.76880
Value Function Loss: 0.01865

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.47456
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 19,176.87252
Overall Steps per Second: 9,684.75882

Timestep Collection Time: 2.60752
Timestep Consumption Time: 2.55565
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 5.16316

Cumulative Model Updates: 160,682
Cumulative Timesteps: 1,339,853,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1339853272...
Checkpoint 1339853272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,052.70880
Policy Entropy: 3.75732
Value Function Loss: 0.01680

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.46174
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 19,177.77366
Overall Steps per Second: 9,634.30348

Timestep Collection Time: 2.60802
Timestep Consumption Time: 2.58343
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 5.19145

Cumulative Model Updates: 160,688
Cumulative Timesteps: 1,339,903,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,065.48576
Policy Entropy: 3.75402
Value Function Loss: 0.01930

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.44296
Value Function Update Magnitude: 0.49590

Collected Steps per Second: 19,248.18139
Overall Steps per Second: 9,802.55796

Timestep Collection Time: 2.59931
Timestep Consumption Time: 2.50466
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 5.10397

Cumulative Model Updates: 160,694
Cumulative Timesteps: 1,339,953,320

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1339953320...
Checkpoint 1339953320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,201.06586
Policy Entropy: 3.76190
Value Function Loss: 0.01669

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.40853
Value Function Update Magnitude: 0.41767

Collected Steps per Second: 19,340.16688
Overall Steps per Second: 9,815.75109

Timestep Collection Time: 2.58529
Timestep Consumption Time: 2.50856
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 5.09385

Cumulative Model Updates: 160,700
Cumulative Timesteps: 1,340,003,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,201.06586
Policy Entropy: 3.75226
Value Function Loss: 0.01571

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.39683
Value Function Update Magnitude: 0.37534

Collected Steps per Second: 19,502.22079
Overall Steps per Second: 9,755.64942

Timestep Collection Time: 2.56463
Timestep Consumption Time: 2.56224
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 5.12688

Cumulative Model Updates: 160,706
Cumulative Timesteps: 1,340,053,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1340053336...
Checkpoint 1340053336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,564.86933
Policy Entropy: 3.75645
Value Function Loss: 0.01284

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.38025
Value Function Update Magnitude: 0.36566

Collected Steps per Second: 19,419.00218
Overall Steps per Second: 9,815.48047

Timestep Collection Time: 2.57593
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 5.09624

Cumulative Model Updates: 160,712
Cumulative Timesteps: 1,340,103,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,774.74488
Policy Entropy: 3.74536
Value Function Loss: 0.01444

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.41485
Value Function Update Magnitude: 0.48398

Collected Steps per Second: 19,179.79610
Overall Steps per Second: 9,638.80810

Timestep Collection Time: 2.60816
Timestep Consumption Time: 2.58169
PPO Batch Consumption Time: 0.29953
Total Iteration Time: 5.18985

Cumulative Model Updates: 160,718
Cumulative Timesteps: 1,340,153,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1340153382...
Checkpoint 1340153382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,416.94416
Policy Entropy: 3.75519
Value Function Loss: 0.01483

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.46170
Value Function Update Magnitude: 0.59863

Collected Steps per Second: 19,111.70279
Overall Steps per Second: 9,756.61629

Timestep Collection Time: 2.61735
Timestep Consumption Time: 2.50963
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 5.12698

Cumulative Model Updates: 160,724
Cumulative Timesteps: 1,340,203,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,416.94416
Policy Entropy: 3.75590
Value Function Loss: 0.01592

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.45403
Value Function Update Magnitude: 0.58122

Collected Steps per Second: 19,250.37325
Overall Steps per Second: 9,687.30594

Timestep Collection Time: 2.59974
Timestep Consumption Time: 2.56640
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 5.16614

Cumulative Model Updates: 160,730
Cumulative Timesteps: 1,340,253,450

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1340253450...
Checkpoint 1340253450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,416.94416
Policy Entropy: 3.75928
Value Function Loss: 0.01410

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.43833
Value Function Update Magnitude: 0.49159

Collected Steps per Second: 19,245.59129
Overall Steps per Second: 9,748.35578

Timestep Collection Time: 2.59852
Timestep Consumption Time: 2.53158
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 5.13010

Cumulative Model Updates: 160,736
Cumulative Timesteps: 1,340,303,460

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 193,970.21051
Policy Entropy: 3.74487
Value Function Loss: 0.01615

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12554
Policy Update Magnitude: 0.42230
Value Function Update Magnitude: 0.43843

Collected Steps per Second: 19,202.74077
Overall Steps per Second: 9,762.59147

Timestep Collection Time: 2.60504
Timestep Consumption Time: 2.51900
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 5.12405

Cumulative Model Updates: 160,742
Cumulative Timesteps: 1,340,353,484

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1340353484...
Checkpoint 1340353484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,787.04178
Policy Entropy: 3.74473
Value Function Loss: 0.01524

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12814
Policy Update Magnitude: 0.46504
Value Function Update Magnitude: 0.56823

Collected Steps per Second: 19,991.55513
Overall Steps per Second: 10,033.58745

Timestep Collection Time: 2.50306
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.98725

Cumulative Model Updates: 160,748
Cumulative Timesteps: 1,340,403,524

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,832.99276
Policy Entropy: 3.74118
Value Function Loss: 0.01870

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.48269
Value Function Update Magnitude: 0.67959

Collected Steps per Second: 19,350.89954
Overall Steps per Second: 9,710.49964

Timestep Collection Time: 2.58479
Timestep Consumption Time: 2.56613
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 5.15092

Cumulative Model Updates: 160,754
Cumulative Timesteps: 1,340,453,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1340453542...
Checkpoint 1340453542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,669.10163
Policy Entropy: 3.77132
Value Function Loss: 0.01732

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.47689
Value Function Update Magnitude: 0.62419

Collected Steps per Second: 19,459.13292
Overall Steps per Second: 9,721.95077

Timestep Collection Time: 2.56980
Timestep Consumption Time: 2.57382
PPO Batch Consumption Time: 0.30296
Total Iteration Time: 5.14362

Cumulative Model Updates: 160,760
Cumulative Timesteps: 1,340,503,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,916.83029
Policy Entropy: 3.77518
Value Function Loss: 0.01970

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.48028
Value Function Update Magnitude: 0.59269

Collected Steps per Second: 19,314.57575
Overall Steps per Second: 9,626.82415

Timestep Collection Time: 2.59058
Timestep Consumption Time: 2.60698
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.19756

Cumulative Model Updates: 160,766
Cumulative Timesteps: 1,340,553,584

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1340553584...
Checkpoint 1340553584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,453.84498
Policy Entropy: 3.78467
Value Function Loss: 0.01942

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.47698
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 19,512.16392
Overall Steps per Second: 9,600.12439

Timestep Collection Time: 2.56435
Timestep Consumption Time: 2.64767
PPO Batch Consumption Time: 0.31607
Total Iteration Time: 5.21202

Cumulative Model Updates: 160,772
Cumulative Timesteps: 1,340,603,620

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,420.34411
Policy Entropy: 3.78119
Value Function Loss: 0.02051

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.48118
Value Function Update Magnitude: 0.68386

Collected Steps per Second: 19,348.24458
Overall Steps per Second: 9,625.19062

Timestep Collection Time: 2.58607
Timestep Consumption Time: 2.61237
PPO Batch Consumption Time: 0.30817
Total Iteration Time: 5.19844

Cumulative Model Updates: 160,778
Cumulative Timesteps: 1,340,653,656

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1340653656...
Checkpoint 1340653656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,970.28130
Policy Entropy: 3.77808
Value Function Loss: 0.01877

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.47126
Value Function Update Magnitude: 0.60269

Collected Steps per Second: 19,466.80996
Overall Steps per Second: 9,695.84389

Timestep Collection Time: 2.56889
Timestep Consumption Time: 2.58879
PPO Batch Consumption Time: 0.30572
Total Iteration Time: 5.15767

Cumulative Model Updates: 160,784
Cumulative Timesteps: 1,340,703,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,514.10266
Policy Entropy: 3.76039
Value Function Loss: 0.01907

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.48604
Value Function Update Magnitude: 0.52033

Collected Steps per Second: 19,517.79492
Overall Steps per Second: 9,697.72878

Timestep Collection Time: 2.56176
Timestep Consumption Time: 2.59408
PPO Batch Consumption Time: 0.30465
Total Iteration Time: 5.15585

Cumulative Model Updates: 160,790
Cumulative Timesteps: 1,340,753,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1340753664...
Checkpoint 1340753664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 146,618.91530
Policy Entropy: 3.75554
Value Function Loss: 0.02191

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.56364

Collected Steps per Second: 19,317.00762
Overall Steps per Second: 9,623.43171

Timestep Collection Time: 2.58891
Timestep Consumption Time: 2.60778
PPO Batch Consumption Time: 0.30798
Total Iteration Time: 5.19669

Cumulative Model Updates: 160,796
Cumulative Timesteps: 1,340,803,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,181.27079
Policy Entropy: 3.76025
Value Function Loss: 0.02134

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.66539
Value Function Update Magnitude: 0.71207

Collected Steps per Second: 19,571.57007
Overall Steps per Second: 9,717.27642

Timestep Collection Time: 2.55524
Timestep Consumption Time: 2.59127
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 5.14650

Cumulative Model Updates: 160,802
Cumulative Timesteps: 1,340,853,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1340853684...
Checkpoint 1340853684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,717.48708
Policy Entropy: 3.76635
Value Function Loss: 0.02278

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.60644
Value Function Update Magnitude: 0.75872

Collected Steps per Second: 18,862.12035
Overall Steps per Second: 9,676.88113

Timestep Collection Time: 2.65294
Timestep Consumption Time: 2.51815
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 5.17109

Cumulative Model Updates: 160,808
Cumulative Timesteps: 1,340,903,724

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,660.78872
Policy Entropy: 3.78042
Value Function Loss: 0.02499

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12261
Policy Update Magnitude: 0.58680
Value Function Update Magnitude: 0.70822

Collected Steps per Second: 19,473.29994
Overall Steps per Second: 9,726.37976

Timestep Collection Time: 2.56906
Timestep Consumption Time: 2.57448
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 5.14354

Cumulative Model Updates: 160,814
Cumulative Timesteps: 1,340,953,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1340953752...
Checkpoint 1340953752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,479.40072
Policy Entropy: 3.80193
Value Function Loss: 0.02750

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.62925
Value Function Update Magnitude: 0.74741

Collected Steps per Second: 18,832.85678
Overall Steps per Second: 9,706.88686

Timestep Collection Time: 2.65642
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 5.15387

Cumulative Model Updates: 160,820
Cumulative Timesteps: 1,341,003,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,536.51840
Policy Entropy: 3.80837
Value Function Loss: 0.03006

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12137
Policy Update Magnitude: 0.66247
Value Function Update Magnitude: 0.69885

Collected Steps per Second: 19,103.47278
Overall Steps per Second: 9,744.44891

Timestep Collection Time: 2.61827
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 5.13297

Cumulative Model Updates: 160,826
Cumulative Timesteps: 1,341,053,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1341053798...
Checkpoint 1341053798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,663.65751
Policy Entropy: 3.84081
Value Function Loss: 0.02752

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.71198
Value Function Update Magnitude: 0.70381

Collected Steps per Second: 18,894.91886
Overall Steps per Second: 9,611.43278

Timestep Collection Time: 2.64717
Timestep Consumption Time: 2.55684
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 5.20401

Cumulative Model Updates: 160,832
Cumulative Timesteps: 1,341,103,816

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,991.89095
Policy Entropy: 3.86119
Value Function Loss: 0.02635

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.67785
Value Function Update Magnitude: 0.71182

Collected Steps per Second: 19,457.57538
Overall Steps per Second: 9,845.23203

Timestep Collection Time: 2.57257
Timestep Consumption Time: 2.51172
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 5.08429

Cumulative Model Updates: 160,838
Cumulative Timesteps: 1,341,153,872

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1341153872...
Checkpoint 1341153872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304,394.60945
Policy Entropy: 3.85013
Value Function Loss: 0.02613

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.61683
Value Function Update Magnitude: 0.74920

Collected Steps per Second: 18,964.46256
Overall Steps per Second: 9,661.53198

Timestep Collection Time: 2.63799
Timestep Consumption Time: 2.54007
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 5.17806

Cumulative Model Updates: 160,844
Cumulative Timesteps: 1,341,203,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,765.77941
Policy Entropy: 3.82856
Value Function Loss: 0.02635

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.72163

Collected Steps per Second: 19,445.21276
Overall Steps per Second: 9,846.89786

Timestep Collection Time: 2.57236
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 5.07977

Cumulative Model Updates: 160,850
Cumulative Timesteps: 1,341,253,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1341253920...
Checkpoint 1341253920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,824.37850
Policy Entropy: 3.79353
Value Function Loss: 0.02396

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.52298
Value Function Update Magnitude: 0.64789

Collected Steps per Second: 18,997.22579
Overall Steps per Second: 9,734.01290

Timestep Collection Time: 2.63217
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 5.13704

Cumulative Model Updates: 160,856
Cumulative Timesteps: 1,341,303,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,663.20695
Policy Entropy: 3.80195
Value Function Loss: 0.01907

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.48412
Value Function Update Magnitude: 0.58392

Collected Steps per Second: 19,452.83173
Overall Steps per Second: 9,748.35618

Timestep Collection Time: 2.57053
Timestep Consumption Time: 2.55895
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 5.12948

Cumulative Model Updates: 160,862
Cumulative Timesteps: 1,341,353,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1341353928...
Checkpoint 1341353928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,765.85181
Policy Entropy: 3.77727
Value Function Loss: 0.01827

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13651
Policy Update Magnitude: 0.46210
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 19,285.80695
Overall Steps per Second: 9,765.94729

Timestep Collection Time: 2.59465
Timestep Consumption Time: 2.52927
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 5.12393

Cumulative Model Updates: 160,868
Cumulative Timesteps: 1,341,403,968

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,765.85181
Policy Entropy: 3.77064
Value Function Loss: 0.01521

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13720
Policy Update Magnitude: 0.45462
Value Function Update Magnitude: 0.62879

Collected Steps per Second: 19,481.14146
Overall Steps per Second: 9,722.74167

Timestep Collection Time: 2.56720
Timestep Consumption Time: 2.57662
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 5.14382

Cumulative Model Updates: 160,874
Cumulative Timesteps: 1,341,453,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1341453980...
Checkpoint 1341453980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,544.04773
Policy Entropy: 3.74675
Value Function Loss: 0.01460

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14156
Policy Update Magnitude: 0.46517
Value Function Update Magnitude: 0.56314

Collected Steps per Second: 19,141.45475
Overall Steps per Second: 9,758.96191

Timestep Collection Time: 2.61328
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 5.12575

Cumulative Model Updates: 160,880
Cumulative Timesteps: 1,341,504,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,972.05476
Policy Entropy: 3.76118
Value Function Loss: 0.01356

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.45823
Value Function Update Magnitude: 0.56046

Collected Steps per Second: 19,347.57299
Overall Steps per Second: 9,678.47760

Timestep Collection Time: 2.58678
Timestep Consumption Time: 2.58428
PPO Batch Consumption Time: 0.30458
Total Iteration Time: 5.17106

Cumulative Model Updates: 160,886
Cumulative Timesteps: 1,341,554,050

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1341554050...
Checkpoint 1341554050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,272.39736
Policy Entropy: 3.76031
Value Function Loss: 0.01303

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.44464
Value Function Update Magnitude: 0.57881

Collected Steps per Second: 19,420.88977
Overall Steps per Second: 9,758.08680

Timestep Collection Time: 2.57589
Timestep Consumption Time: 2.55073
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 5.12662

Cumulative Model Updates: 160,892
Cumulative Timesteps: 1,341,604,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,757.09425
Policy Entropy: 3.76598
Value Function Loss: 0.01429

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.45173
Value Function Update Magnitude: 0.62148

Collected Steps per Second: 19,302.09452
Overall Steps per Second: 9,564.18258

Timestep Collection Time: 2.59267
Timestep Consumption Time: 2.63977
PPO Batch Consumption Time: 0.30683
Total Iteration Time: 5.23244

Cumulative Model Updates: 160,898
Cumulative Timesteps: 1,341,654,120

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1341654120...
Checkpoint 1341654120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,777.54712
Policy Entropy: 3.77077
Value Function Loss: 0.01467

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.47790
Value Function Update Magnitude: 0.67854

Collected Steps per Second: 19,617.22481
Overall Steps per Second: 9,596.32912

Timestep Collection Time: 2.54898
Timestep Consumption Time: 2.66176
PPO Batch Consumption Time: 0.31501
Total Iteration Time: 5.21074

Cumulative Model Updates: 160,904
Cumulative Timesteps: 1,341,704,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,566.02054
Policy Entropy: 3.76398
Value Function Loss: 0.01612

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.47320
Value Function Update Magnitude: 0.66391

Collected Steps per Second: 19,594.02644
Overall Steps per Second: 9,623.59988

Timestep Collection Time: 2.55190
Timestep Consumption Time: 2.64387
PPO Batch Consumption Time: 0.31540
Total Iteration Time: 5.19577

Cumulative Model Updates: 160,910
Cumulative Timesteps: 1,341,754,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1341754126...
Checkpoint 1341754126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,298.92527
Policy Entropy: 3.78009
Value Function Loss: 0.01593

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.48228
Value Function Update Magnitude: 0.65901

Collected Steps per Second: 19,607.91538
Overall Steps per Second: 9,732.93745

Timestep Collection Time: 2.55121
Timestep Consumption Time: 2.58845
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 5.13966

Cumulative Model Updates: 160,916
Cumulative Timesteps: 1,341,804,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,723.27312
Policy Entropy: 3.78509
Value Function Loss: 0.01650

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12029
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.72909

Collected Steps per Second: 19,664.98151
Overall Steps per Second: 9,701.03591

Timestep Collection Time: 2.54412
Timestep Consumption Time: 2.61306
PPO Batch Consumption Time: 0.30851
Total Iteration Time: 5.15718

Cumulative Model Updates: 160,922
Cumulative Timesteps: 1,341,854,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1341854180...
Checkpoint 1341854180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,451.92219
Policy Entropy: 3.78023
Value Function Loss: 0.01714

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.80503

Collected Steps per Second: 19,717.36109
Overall Steps per Second: 9,724.21239

Timestep Collection Time: 2.53584
Timestep Consumption Time: 2.60597
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 5.14180

Cumulative Model Updates: 160,928
Cumulative Timesteps: 1,341,904,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,356.62584
Policy Entropy: 3.75972
Value Function Loss: 0.01840

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.53229
Value Function Update Magnitude: 0.85829

Collected Steps per Second: 19,314.35768
Overall Steps per Second: 9,699.12858

Timestep Collection Time: 2.58885
Timestep Consumption Time: 2.56646
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 5.15531

Cumulative Model Updates: 160,934
Cumulative Timesteps: 1,341,954,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1341954182...
Checkpoint 1341954182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,839.85135
Policy Entropy: 3.74052
Value Function Loss: 0.01788

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.50472
Value Function Update Magnitude: 0.80748

Collected Steps per Second: 19,511.45090
Overall Steps per Second: 9,876.53268

Timestep Collection Time: 2.56414
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 5.06554

Cumulative Model Updates: 160,940
Cumulative Timesteps: 1,342,004,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,478.11695
Policy Entropy: 3.74785
Value Function Loss: 0.02005

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.51224
Value Function Update Magnitude: 0.71024

Collected Steps per Second: 19,750.83921
Overall Steps per Second: 9,787.26099

Timestep Collection Time: 2.53285
Timestep Consumption Time: 2.57848
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 5.11134

Cumulative Model Updates: 160,946
Cumulative Timesteps: 1,342,054,238

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1342054238...
Checkpoint 1342054238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,762.14389
Policy Entropy: 3.75029
Value Function Loss: 0.01834

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12451
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.70849

Collected Steps per Second: 19,300.56610
Overall Steps per Second: 9,754.31683

Timestep Collection Time: 2.59194
Timestep Consumption Time: 2.53666
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 5.12860

Cumulative Model Updates: 160,952
Cumulative Timesteps: 1,342,104,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 100,971.98370
Policy Entropy: 3.74008
Value Function Loss: 0.01973

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.52911
Value Function Update Magnitude: 0.65948

Collected Steps per Second: 19,531.84397
Overall Steps per Second: 9,703.87942

Timestep Collection Time: 2.56156
Timestep Consumption Time: 2.59432
PPO Batch Consumption Time: 0.29881
Total Iteration Time: 5.15588

Cumulative Model Updates: 160,958
Cumulative Timesteps: 1,342,154,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1342154296...
Checkpoint 1342154296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,251.28051
Policy Entropy: 3.75640
Value Function Loss: 0.01634

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12503
Policy Update Magnitude: 0.51395
Value Function Update Magnitude: 0.66054

Collected Steps per Second: 19,256.27685
Overall Steps per Second: 9,726.24648

Timestep Collection Time: 2.59666
Timestep Consumption Time: 2.54428
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 5.14093

Cumulative Model Updates: 160,964
Cumulative Timesteps: 1,342,204,298

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,251.28051
Policy Entropy: 3.74969
Value Function Loss: 0.01723

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.49554
Value Function Update Magnitude: 0.56059

Collected Steps per Second: 19,014.52299
Overall Steps per Second: 9,603.06321

Timestep Collection Time: 2.63073
Timestep Consumption Time: 2.57824
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 5.20896

Cumulative Model Updates: 160,970
Cumulative Timesteps: 1,342,254,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1342254320...
Checkpoint 1342254320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,960.09389
Policy Entropy: 3.76814
Value Function Loss: 0.01787

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12090
Policy Update Magnitude: 0.53530
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 19,031.57854
Overall Steps per Second: 9,590.78744

Timestep Collection Time: 2.62763
Timestep Consumption Time: 2.58654
PPO Batch Consumption Time: 0.30077
Total Iteration Time: 5.21417

Cumulative Model Updates: 160,976
Cumulative Timesteps: 1,342,304,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,262.87870
Policy Entropy: 3.77230
Value Function Loss: 0.01877

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12672
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.76378

Collected Steps per Second: 18,894.40566
Overall Steps per Second: 9,616.06286

Timestep Collection Time: 2.64724
Timestep Consumption Time: 2.55427
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.20151

Cumulative Model Updates: 160,982
Cumulative Timesteps: 1,342,354,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1342354346...
Checkpoint 1342354346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,891.00372
Policy Entropy: 3.78110
Value Function Loss: 0.01816

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.56567
Value Function Update Magnitude: 0.78825

Collected Steps per Second: 19,103.85385
Overall Steps per Second: 9,614.20250

Timestep Collection Time: 2.61905
Timestep Consumption Time: 2.58512
PPO Batch Consumption Time: 0.30189
Total Iteration Time: 5.20418

Cumulative Model Updates: 160,988
Cumulative Timesteps: 1,342,404,380

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,725.65062
Policy Entropy: 3.80185
Value Function Loss: 0.01597

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.69998

Collected Steps per Second: 19,116.11003
Overall Steps per Second: 9,596.17246

Timestep Collection Time: 2.61601
Timestep Consumption Time: 2.59523
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 5.21124

Cumulative Model Updates: 160,994
Cumulative Timesteps: 1,342,454,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1342454388...
Checkpoint 1342454388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,997.58123
Policy Entropy: 3.76576
Value Function Loss: 0.01688

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.53018
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 19,128.84004
Overall Steps per Second: 9,688.48987

Timestep Collection Time: 2.61490
Timestep Consumption Time: 2.54793
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 5.16283

Cumulative Model Updates: 161,000
Cumulative Timesteps: 1,342,504,408

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,047.84912
Policy Entropy: 3.76590
Value Function Loss: 0.01732

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.53965
Value Function Update Magnitude: 0.49109

Collected Steps per Second: 19,034.40124
Overall Steps per Second: 9,652.55920

Timestep Collection Time: 2.62777
Timestep Consumption Time: 2.55407
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 5.18184

Cumulative Model Updates: 161,006
Cumulative Timesteps: 1,342,554,426

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1342554426...
Checkpoint 1342554426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,262.27608
Policy Entropy: 3.75150
Value Function Loss: 0.01789

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.52905
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 19,029.32345
Overall Steps per Second: 9,571.95089

Timestep Collection Time: 2.62910
Timestep Consumption Time: 2.59763
PPO Batch Consumption Time: 0.30386
Total Iteration Time: 5.22673

Cumulative Model Updates: 161,012
Cumulative Timesteps: 1,342,604,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242,228.31683
Policy Entropy: 3.75891
Value Function Loss: 0.01775

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.60140

Collected Steps per Second: 18,677.91325
Overall Steps per Second: 9,492.39126

Timestep Collection Time: 2.67782
Timestep Consumption Time: 2.59125
PPO Batch Consumption Time: 0.30526
Total Iteration Time: 5.26906

Cumulative Model Updates: 161,018
Cumulative Timesteps: 1,342,654,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1342654472...
Checkpoint 1342654472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,971.64071
Policy Entropy: 3.76539
Value Function Loss: 0.01766

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.50995
Value Function Update Magnitude: 0.53162

Collected Steps per Second: 19,445.82925
Overall Steps per Second: 9,698.41227

Timestep Collection Time: 2.57155
Timestep Consumption Time: 2.58455
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 5.15610

Cumulative Model Updates: 161,024
Cumulative Timesteps: 1,342,704,478

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,113.76271
Policy Entropy: 3.76705
Value Function Loss: 0.01919

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.52622
Value Function Update Magnitude: 0.41898

Collected Steps per Second: 19,449.35860
Overall Steps per Second: 9,640.07961

Timestep Collection Time: 2.57222
Timestep Consumption Time: 2.61737
PPO Batch Consumption Time: 0.30370
Total Iteration Time: 5.18958

Cumulative Model Updates: 161,030
Cumulative Timesteps: 1,342,754,506

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1342754506...
Checkpoint 1342754506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,362.64144
Policy Entropy: 3.78851
Value Function Loss: 0.01797

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12215
Policy Update Magnitude: 0.53517
Value Function Update Magnitude: 0.48732

Collected Steps per Second: 19,631.20059
Overall Steps per Second: 9,585.17220

Timestep Collection Time: 2.54829
Timestep Consumption Time: 2.67081
PPO Batch Consumption Time: 0.31528
Total Iteration Time: 5.21910

Cumulative Model Updates: 161,036
Cumulative Timesteps: 1,342,804,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,273.15710
Policy Entropy: 3.77015
Value Function Loss: 0.01890

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.56413
Value Function Update Magnitude: 0.60705

Collected Steps per Second: 19,323.27814
Overall Steps per Second: 9,540.97035

Timestep Collection Time: 2.58890
Timestep Consumption Time: 2.65438
PPO Batch Consumption Time: 0.31725
Total Iteration Time: 5.24328

Cumulative Model Updates: 161,042
Cumulative Timesteps: 1,342,854,558

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1342854558...
Checkpoint 1342854558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,515.10778
Policy Entropy: 3.79645
Value Function Loss: 0.01731

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.58427

Collected Steps per Second: 19,630.73111
Overall Steps per Second: 9,791.80014

Timestep Collection Time: 2.54805
Timestep Consumption Time: 2.56031
PPO Batch Consumption Time: 0.30278
Total Iteration Time: 5.10836

Cumulative Model Updates: 161,048
Cumulative Timesteps: 1,342,904,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,332.06624
Policy Entropy: 3.78401
Value Function Loss: 0.02001

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.59163
Value Function Update Magnitude: 0.56271

Collected Steps per Second: 19,375.61914
Overall Steps per Second: 9,690.67324

Timestep Collection Time: 2.58149
Timestep Consumption Time: 2.57997
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 5.16146

Cumulative Model Updates: 161,054
Cumulative Timesteps: 1,342,954,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1342954596...
Checkpoint 1342954596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,235.33199
Policy Entropy: 3.79474
Value Function Loss: 0.02080

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06642
Policy Update Magnitude: 0.72178
Value Function Update Magnitude: 0.59826

Collected Steps per Second: 19,170.49758
Overall Steps per Second: 9,609.31368

Timestep Collection Time: 2.60838
Timestep Consumption Time: 2.59532
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 5.20370

Cumulative Model Updates: 161,060
Cumulative Timesteps: 1,343,004,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,199.17283
Policy Entropy: 3.77591
Value Function Loss: 0.02148

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07404
Policy Update Magnitude: 0.85041
Value Function Update Magnitude: 0.62653

Collected Steps per Second: 19,341.59055
Overall Steps per Second: 9,617.39151

Timestep Collection Time: 2.58748
Timestep Consumption Time: 2.61622
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 5.20370

Cumulative Model Updates: 161,066
Cumulative Timesteps: 1,343,054,646

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1343054646...
Checkpoint 1343054646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,021.38877
Policy Entropy: 3.78146
Value Function Loss: 0.02034

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08483
Policy Update Magnitude: 0.82339
Value Function Update Magnitude: 0.59590

Collected Steps per Second: 19,528.18014
Overall Steps per Second: 9,949.03250

Timestep Collection Time: 2.56081
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 5.02642

Cumulative Model Updates: 161,072
Cumulative Timesteps: 1,343,104,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,705.89811
Policy Entropy: 3.78463
Value Function Loss: 0.01961

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15238
Policy Update Magnitude: 0.67992
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 19,391.77632
Overall Steps per Second: 9,696.55429

Timestep Collection Time: 2.58017
Timestep Consumption Time: 2.57981
PPO Batch Consumption Time: 0.30287
Total Iteration Time: 5.15998

Cumulative Model Updates: 161,078
Cumulative Timesteps: 1,343,154,688

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1343154688...
Checkpoint 1343154688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,663.83044
Policy Entropy: 3.78987
Value Function Loss: 0.01851

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16298
Policy Update Magnitude: 0.60399
Value Function Update Magnitude: 0.63762

Collected Steps per Second: 19,018.62539
Overall Steps per Second: 9,718.61931

Timestep Collection Time: 2.62921
Timestep Consumption Time: 2.51596
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 5.14518

Cumulative Model Updates: 161,084
Cumulative Timesteps: 1,343,204,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,601.91633
Policy Entropy: 3.79546
Value Function Loss: 0.02545

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.17065
Policy Update Magnitude: 0.59585
Value Function Update Magnitude: 0.63632

Collected Steps per Second: 18,649.78467
Overall Steps per Second: 9,613.98902

Timestep Collection Time: 2.68260
Timestep Consumption Time: 2.52127
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 5.20388

Cumulative Model Updates: 161,090
Cumulative Timesteps: 1,343,254,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1343254722...
Checkpoint 1343254722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,509.96064
Policy Entropy: 3.78193
Value Function Loss: 0.02704

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14263
Policy Update Magnitude: 0.78974
Value Function Update Magnitude: 0.63671

Collected Steps per Second: 18,872.69184
Overall Steps per Second: 9,581.64157

Timestep Collection Time: 2.64933
Timestep Consumption Time: 2.56898
PPO Batch Consumption Time: 0.30260
Total Iteration Time: 5.21831

Cumulative Model Updates: 161,096
Cumulative Timesteps: 1,343,304,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,317.18577
Policy Entropy: 3.77786
Value Function Loss: 0.03101

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.23393
Policy Update Magnitude: 0.75733
Value Function Update Magnitude: 0.63854

Collected Steps per Second: 18,793.74578
Overall Steps per Second: 9,540.55479

Timestep Collection Time: 2.66089
Timestep Consumption Time: 2.58074
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 5.24162

Cumulative Model Updates: 161,102
Cumulative Timesteps: 1,343,354,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1343354730...
Checkpoint 1343354730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,966.63993
Policy Entropy: 3.80328
Value Function Loss: 0.03223

Mean KL Divergence: 0.02085
SB3 Clip Fraction: 0.22118
Policy Update Magnitude: 0.57631
Value Function Update Magnitude: 0.51096

Collected Steps per Second: 18,342.73604
Overall Steps per Second: 9,427.71511

Timestep Collection Time: 2.72620
Timestep Consumption Time: 2.57795
PPO Batch Consumption Time: 0.29832
Total Iteration Time: 5.30415

Cumulative Model Updates: 161,108
Cumulative Timesteps: 1,343,404,736

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,859.80961
Policy Entropy: 3.83070
Value Function Loss: 0.03302

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.68827
Value Function Update Magnitude: 0.51831

Collected Steps per Second: 18,310.48127
Overall Steps per Second: 9,393.20387

Timestep Collection Time: 2.73330
Timestep Consumption Time: 2.59481
PPO Batch Consumption Time: 0.30747
Total Iteration Time: 5.32811

Cumulative Model Updates: 161,114
Cumulative Timesteps: 1,343,454,784

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1343454784...
Checkpoint 1343454784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.01636
Policy Entropy: 3.84388
Value Function Loss: 0.03116

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.83929
Value Function Update Magnitude: 0.68103

Collected Steps per Second: 18,718.47961
Overall Steps per Second: 9,640.73867

Timestep Collection Time: 2.67158
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 5.18715

Cumulative Model Updates: 161,120
Cumulative Timesteps: 1,343,504,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.92342
Policy Entropy: 3.83162
Value Function Loss: 0.02659

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.81230
Value Function Update Magnitude: 0.66551

Collected Steps per Second: 19,121.49892
Overall Steps per Second: 9,779.62052

Timestep Collection Time: 2.61611
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 5.11513

Cumulative Model Updates: 161,126
Cumulative Timesteps: 1,343,554,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1343554816...
Checkpoint 1343554816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.49331
Policy Entropy: 3.82119
Value Function Loss: 0.02106

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.16845
Policy Update Magnitude: 0.73243
Value Function Update Magnitude: 0.61047

Collected Steps per Second: 19,207.34456
Overall Steps per Second: 9,772.52582

Timestep Collection Time: 2.60442
Timestep Consumption Time: 2.51442
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 5.11884

Cumulative Model Updates: 161,132
Cumulative Timesteps: 1,343,604,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,937.91483
Policy Entropy: 3.77676
Value Function Loss: 0.02432

Mean KL Divergence: 0.01475
SB3 Clip Fraction: 0.18564
Policy Update Magnitude: 0.62521
Value Function Update Magnitude: 0.70758

Collected Steps per Second: 18,289.27619
Overall Steps per Second: 9,357.56857

Timestep Collection Time: 2.73472
Timestep Consumption Time: 2.61026
PPO Batch Consumption Time: 0.30938
Total Iteration Time: 5.34498

Cumulative Model Updates: 161,138
Cumulative Timesteps: 1,343,654,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1343654856...
Checkpoint 1343654856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,866.12908
Policy Entropy: 3.77441
Value Function Loss: 0.02340

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.66131
Value Function Update Magnitude: 0.73262

Collected Steps per Second: 19,066.75400
Overall Steps per Second: 9,558.90063

Timestep Collection Time: 2.62258
Timestep Consumption Time: 2.60857
PPO Batch Consumption Time: 0.30531
Total Iteration Time: 5.23115

Cumulative Model Updates: 161,144
Cumulative Timesteps: 1,343,704,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,953.95624
Policy Entropy: 3.76260
Value Function Loss: 0.02465

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.65409
Value Function Update Magnitude: 0.60261

Collected Steps per Second: 18,888.58188
Overall Steps per Second: 9,351.36924

Timestep Collection Time: 2.64742
Timestep Consumption Time: 2.70003
PPO Batch Consumption Time: 0.31803
Total Iteration Time: 5.34745

Cumulative Model Updates: 161,150
Cumulative Timesteps: 1,343,754,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1343754866...
Checkpoint 1343754866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,394.15863
Policy Entropy: 3.76825
Value Function Loss: 0.02045

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.60210
Value Function Update Magnitude: 0.45223

Collected Steps per Second: 19,330.25352
Overall Steps per Second: 9,202.75838

Timestep Collection Time: 2.58734
Timestep Consumption Time: 2.84733
PPO Batch Consumption Time: 0.33541
Total Iteration Time: 5.43467

Cumulative Model Updates: 161,156
Cumulative Timesteps: 1,343,804,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,238.29019
Policy Entropy: 3.76458
Value Function Loss: 0.02030

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07202
Policy Update Magnitude: 0.70053
Value Function Update Magnitude: 0.44143

Collected Steps per Second: 18,428.47097
Overall Steps per Second: 9,338.79240

Timestep Collection Time: 2.71482
Timestep Consumption Time: 2.64240
PPO Batch Consumption Time: 0.31271
Total Iteration Time: 5.35722

Cumulative Model Updates: 161,162
Cumulative Timesteps: 1,343,854,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1343854910...
Checkpoint 1343854910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,199.64909
Policy Entropy: 3.76781
Value Function Loss: 0.01959

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.76127
Value Function Update Magnitude: 0.50394

Collected Steps per Second: 17,158.38646
Overall Steps per Second: 8,949.13311

Timestep Collection Time: 2.91438
Timestep Consumption Time: 2.67343
PPO Batch Consumption Time: 0.31404
Total Iteration Time: 5.58780

Cumulative Model Updates: 161,168
Cumulative Timesteps: 1,343,904,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,187.13793
Policy Entropy: 3.78347
Value Function Loss: 0.01736

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07901
Policy Update Magnitude: 0.72736
Value Function Update Magnitude: 0.51725

Collected Steps per Second: 17,154.67226
Overall Steps per Second: 9,221.21555

Timestep Collection Time: 2.91501
Timestep Consumption Time: 2.50792
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 5.42293

Cumulative Model Updates: 161,174
Cumulative Timesteps: 1,343,954,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1343954922...
Checkpoint 1343954922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,187.13793
Policy Entropy: 3.78068
Value Function Loss: 0.01492

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.08010
Policy Update Magnitude: 0.62951
Value Function Update Magnitude: 0.48049

Collected Steps per Second: 18,390.52152
Overall Steps per Second: 9,237.20853

Timestep Collection Time: 2.71890
Timestep Consumption Time: 2.69421
PPO Batch Consumption Time: 0.31866
Total Iteration Time: 5.41311

Cumulative Model Updates: 161,180
Cumulative Timesteps: 1,344,004,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,803.59314
Policy Entropy: 3.77508
Value Function Loss: 0.01278

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05323
Policy Update Magnitude: 0.54043
Value Function Update Magnitude: 0.36098

Collected Steps per Second: 18,043.99761
Overall Steps per Second: 9,343.41302

Timestep Collection Time: 2.77189
Timestep Consumption Time: 2.58118
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 5.35308

Cumulative Model Updates: 161,186
Cumulative Timesteps: 1,344,054,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1344054940...
Checkpoint 1344054940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,803.59314
Policy Entropy: 3.77156
Value Function Loss: 0.01118

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06420
Policy Update Magnitude: 0.48447
Value Function Update Magnitude: 0.27933

Collected Steps per Second: 19,089.06331
Overall Steps per Second: 9,280.14402

Timestep Collection Time: 2.62066
Timestep Consumption Time: 2.76999
PPO Batch Consumption Time: 0.33283
Total Iteration Time: 5.39065

Cumulative Model Updates: 161,192
Cumulative Timesteps: 1,344,104,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,803.59314
Policy Entropy: 3.78519
Value Function Loss: 0.01136

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06065
Policy Update Magnitude: 0.45852
Value Function Update Magnitude: 0.25823

Collected Steps per Second: 18,672.47376
Overall Steps per Second: 9,448.03717

Timestep Collection Time: 2.67774
Timestep Consumption Time: 2.61437
PPO Batch Consumption Time: 0.30138
Total Iteration Time: 5.29210

Cumulative Model Updates: 161,198
Cumulative Timesteps: 1,344,154,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1344154966...
Checkpoint 1344154966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,803.59314
Policy Entropy: 3.78898
Value Function Loss: 0.01014

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05372
Policy Update Magnitude: 0.47608
Value Function Update Magnitude: 0.35936

Collected Steps per Second: 19,392.78085
Overall Steps per Second: 9,761.50511

Timestep Collection Time: 2.57921
Timestep Consumption Time: 2.54480
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 5.12400

Cumulative Model Updates: 161,204
Cumulative Timesteps: 1,344,204,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,907.54114
Policy Entropy: 3.78705
Value Function Loss: 0.01088

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05918
Policy Update Magnitude: 0.51983
Value Function Update Magnitude: 0.49046

Collected Steps per Second: 18,183.13578
Overall Steps per Second: 9,055.64642

Timestep Collection Time: 2.75156
Timestep Consumption Time: 2.77339
PPO Batch Consumption Time: 0.31913
Total Iteration Time: 5.52495

Cumulative Model Updates: 161,210
Cumulative Timesteps: 1,344,255,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1344255016...
Checkpoint 1344255016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,105.57823
Policy Entropy: 3.79027
Value Function Loss: 0.01089

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.49264
Value Function Update Magnitude: 0.52465

Collected Steps per Second: 18,455.97499
Overall Steps per Second: 9,288.42108

Timestep Collection Time: 2.71153
Timestep Consumption Time: 2.67625
PPO Batch Consumption Time: 0.31991
Total Iteration Time: 5.38778

Cumulative Model Updates: 161,216
Cumulative Timesteps: 1,344,305,060

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,925.49646
Policy Entropy: 3.79704
Value Function Loss: 0.01078

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05737
Policy Update Magnitude: 0.45560
Value Function Update Magnitude: 0.52472

Collected Steps per Second: 18,539.84246
Overall Steps per Second: 9,334.95832

Timestep Collection Time: 2.69754
Timestep Consumption Time: 2.65995
PPO Batch Consumption Time: 0.31516
Total Iteration Time: 5.35750

Cumulative Model Updates: 161,222
Cumulative Timesteps: 1,344,355,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1344355072...
Checkpoint 1344355072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,617.06968
Policy Entropy: 3.81334
Value Function Loss: 0.01092

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.45255
Value Function Update Magnitude: 0.52231

Collected Steps per Second: 20,622.81053
Overall Steps per Second: 9,935.82474

Timestep Collection Time: 2.42547
Timestep Consumption Time: 2.60884
PPO Batch Consumption Time: 0.31108
Total Iteration Time: 5.03431

Cumulative Model Updates: 161,228
Cumulative Timesteps: 1,344,405,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,209.89408
Policy Entropy: 3.80465
Value Function Loss: 0.01085

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.46322
Value Function Update Magnitude: 0.55539

Collected Steps per Second: 20,124.00580
Overall Steps per Second: 9,869.08862

Timestep Collection Time: 2.48638
Timestep Consumption Time: 2.58359
PPO Batch Consumption Time: 0.30176
Total Iteration Time: 5.06997

Cumulative Model Updates: 161,234
Cumulative Timesteps: 1,344,455,128

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1344455128...
Checkpoint 1344455128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,703.69464
Policy Entropy: 3.79248
Value Function Loss: 0.01267

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05340
Policy Update Magnitude: 0.47923
Value Function Update Magnitude: 0.58492

Collected Steps per Second: 20,288.12776
Overall Steps per Second: 9,975.64094

Timestep Collection Time: 2.46509
Timestep Consumption Time: 2.54833
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 5.01341

Cumulative Model Updates: 161,240
Cumulative Timesteps: 1,344,505,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,891.13694
Policy Entropy: 3.79605
Value Function Loss: 0.01385

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07246
Policy Update Magnitude: 0.54423
Value Function Update Magnitude: 0.66450

Collected Steps per Second: 20,859.09606
Overall Steps per Second: 9,716.05018

Timestep Collection Time: 2.39704
Timestep Consumption Time: 2.74909
PPO Batch Consumption Time: 0.32650
Total Iteration Time: 5.14612

Cumulative Model Updates: 161,246
Cumulative Timesteps: 1,344,555,140

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1344555140...
Checkpoint 1344555140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,810.14355
Policy Entropy: 3.79854
Value Function Loss: 0.01750

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06982
Policy Update Magnitude: 0.61187
Value Function Update Magnitude: 0.68449

Collected Steps per Second: 19,618.74795
Overall Steps per Second: 9,331.94881

Timestep Collection Time: 2.55113
Timestep Consumption Time: 2.81216
PPO Batch Consumption Time: 0.31818
Total Iteration Time: 5.36330

Cumulative Model Updates: 161,252
Cumulative Timesteps: 1,344,605,190

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,168.87374
Policy Entropy: 3.79707
Value Function Loss: 0.02258

Mean KL Divergence: 0.02071
SB3 Clip Fraction: 0.20966
Policy Update Magnitude: 0.60976
Value Function Update Magnitude: 0.69027

Collected Steps per Second: 19,019.56902
Overall Steps per Second: 9,285.72630

Timestep Collection Time: 2.62898
Timestep Consumption Time: 2.75585
PPO Batch Consumption Time: 0.32884
Total Iteration Time: 5.38482

Cumulative Model Updates: 161,258
Cumulative Timesteps: 1,344,655,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1344655192...
Checkpoint 1344655192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325,861.43133
Policy Entropy: 3.85620
Value Function Loss: 0.03749

Mean KL Divergence: 0.02609
SB3 Clip Fraction: 0.23284
Policy Update Magnitude: 0.67877
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 19,704.92381
Overall Steps per Second: 9,612.86680

Timestep Collection Time: 2.53987
Timestep Consumption Time: 2.66648
PPO Batch Consumption Time: 0.32146
Total Iteration Time: 5.20636

Cumulative Model Updates: 161,264
Cumulative Timesteps: 1,344,705,240

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,419.22374
Policy Entropy: 3.95029
Value Function Loss: 0.04058

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 1.08613
Value Function Update Magnitude: 0.66852

Collected Steps per Second: 19,979.09961
Overall Steps per Second: 9,819.74751

Timestep Collection Time: 2.50302
Timestep Consumption Time: 2.58958
PPO Batch Consumption Time: 0.31755
Total Iteration Time: 5.09260

Cumulative Model Updates: 161,270
Cumulative Timesteps: 1,344,755,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1344755248...
Checkpoint 1344755248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.69447
Policy Entropy: 3.99141
Value Function Loss: 0.05355

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11746
Policy Update Magnitude: 1.23551
Value Function Update Magnitude: 0.75495

Collected Steps per Second: 18,360.55406
Overall Steps per Second: 9,524.77929

Timestep Collection Time: 2.72410
Timestep Consumption Time: 2.52704
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 5.25115

Cumulative Model Updates: 161,276
Cumulative Timesteps: 1,344,805,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,508.49491
Policy Entropy: 3.99023
Value Function Loss: 0.04087

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 1.14960
Value Function Update Magnitude: 0.65950

Collected Steps per Second: 19,822.68158
Overall Steps per Second: 9,691.47062

Timestep Collection Time: 2.52367
Timestep Consumption Time: 2.63818
PPO Batch Consumption Time: 0.30551
Total Iteration Time: 5.16186

Cumulative Model Updates: 161,282
Cumulative Timesteps: 1,344,855,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1344855290...
Checkpoint 1344855290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.12816
Policy Entropy: 3.97273
Value Function Loss: 0.03640

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 1.03559
Value Function Update Magnitude: 0.73897

Collected Steps per Second: 17,029.36403
Overall Steps per Second: 8,995.64118

Timestep Collection Time: 2.93810
Timestep Consumption Time: 2.62393
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 5.56203

Cumulative Model Updates: 161,288
Cumulative Timesteps: 1,344,905,324

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.05303
Policy Entropy: 3.95405
Value Function Loss: 0.03168

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07665
Policy Update Magnitude: 1.03783
Value Function Update Magnitude: 0.86970

Collected Steps per Second: 18,254.66484
Overall Steps per Second: 9,386.79173

Timestep Collection Time: 2.73990
Timestep Consumption Time: 2.58844
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 5.32834

Cumulative Model Updates: 161,294
Cumulative Timesteps: 1,344,955,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1344955340...
Checkpoint 1344955340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,297.59822
Policy Entropy: 3.97272
Value Function Loss: 0.02913

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07338
Policy Update Magnitude: 1.03861
Value Function Update Magnitude: 0.98805

Collected Steps per Second: 19,608.31902
Overall Steps per Second: 9,747.54027

Timestep Collection Time: 2.55045
Timestep Consumption Time: 2.58008
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 5.13053

Cumulative Model Updates: 161,300
Cumulative Timesteps: 1,345,005,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.41082
Policy Entropy: 3.96162
Value Function Loss: 0.02869

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 1.02753
Value Function Update Magnitude: 0.99207

Collected Steps per Second: 19,605.80438
Overall Steps per Second: 9,647.47867

Timestep Collection Time: 2.55057
Timestep Consumption Time: 2.63275
PPO Batch Consumption Time: 0.30747
Total Iteration Time: 5.18332

Cumulative Model Updates: 161,306
Cumulative Timesteps: 1,345,055,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1345055356...
Checkpoint 1345055356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,267.73448
Policy Entropy: 3.95280
Value Function Loss: 0.02896

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06820
Policy Update Magnitude: 1.00150
Value Function Update Magnitude: 0.95719

Collected Steps per Second: 19,894.03689
Overall Steps per Second: 9,680.30322

Timestep Collection Time: 2.51412
Timestep Consumption Time: 2.65266
PPO Batch Consumption Time: 0.31130
Total Iteration Time: 5.16678

Cumulative Model Updates: 161,312
Cumulative Timesteps: 1,345,105,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,042.61880
Policy Entropy: 3.91018
Value Function Loss: 0.02865

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.07205
Policy Update Magnitude: 0.95929
Value Function Update Magnitude: 0.87681

Collected Steps per Second: 18,890.58448
Overall Steps per Second: 9,475.07009

Timestep Collection Time: 2.64693
Timestep Consumption Time: 2.63029
PPO Batch Consumption Time: 0.31516
Total Iteration Time: 5.27722

Cumulative Model Updates: 161,318
Cumulative Timesteps: 1,345,155,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1345155374...
Checkpoint 1345155374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,518.99574
Policy Entropy: 3.89301
Value Function Loss: 0.02908

Mean KL Divergence: 0.00631
SB3 Clip Fraction: 0.07964
Policy Update Magnitude: 0.91182
Value Function Update Magnitude: 0.80687

Collected Steps per Second: 20,239.20004
Overall Steps per Second: 9,663.98475

Timestep Collection Time: 2.47115
Timestep Consumption Time: 2.70415
PPO Batch Consumption Time: 0.32599
Total Iteration Time: 5.17530

Cumulative Model Updates: 161,324
Cumulative Timesteps: 1,345,205,388

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,465.21494
Policy Entropy: 3.86884
Value Function Loss: 0.03019

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.86363
Value Function Update Magnitude: 0.67317

Collected Steps per Second: 20,481.74807
Overall Steps per Second: 9,717.47778

Timestep Collection Time: 2.44266
Timestep Consumption Time: 2.70579
PPO Batch Consumption Time: 0.32673
Total Iteration Time: 5.14846

Cumulative Model Updates: 161,330
Cumulative Timesteps: 1,345,255,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1345255418...
Checkpoint 1345255418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,390.26954
Policy Entropy: 3.87732
Value Function Loss: 0.03067

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.85949
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 20,329.60977
Overall Steps per Second: 9,713.20881

Timestep Collection Time: 2.45986
Timestep Consumption Time: 2.68859
PPO Batch Consumption Time: 0.32106
Total Iteration Time: 5.14845

Cumulative Model Updates: 161,336
Cumulative Timesteps: 1,345,305,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 325.33174
Policy Entropy: 3.88769
Value Function Loss: 0.02992

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08140
Policy Update Magnitude: 0.88581
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 19,980.69730
Overall Steps per Second: 9,781.35371

Timestep Collection Time: 2.50442
Timestep Consumption Time: 2.61144
PPO Batch Consumption Time: 0.31868
Total Iteration Time: 5.11586

Cumulative Model Updates: 161,342
Cumulative Timesteps: 1,345,355,466

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1345355466...
Checkpoint 1345355466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,235.34775
Policy Entropy: 3.92183
Value Function Loss: 0.03009

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.85725
Value Function Update Magnitude: 0.69234

Collected Steps per Second: 20,136.37713
Overall Steps per Second: 9,847.83371

Timestep Collection Time: 2.48476
Timestep Consumption Time: 2.59595
PPO Batch Consumption Time: 0.31777
Total Iteration Time: 5.08071

Cumulative Model Updates: 161,348
Cumulative Timesteps: 1,345,405,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,821.47580
Policy Entropy: 3.90001
Value Function Loss: 0.03213

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15305
Policy Update Magnitude: 0.75860
Value Function Update Magnitude: 0.75464

Collected Steps per Second: 20,790.59716
Overall Steps per Second: 9,949.49369

Timestep Collection Time: 2.40590
Timestep Consumption Time: 2.62150
PPO Batch Consumption Time: 0.30901
Total Iteration Time: 5.02739

Cumulative Model Updates: 161,354
Cumulative Timesteps: 1,345,455,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1345455520...
Checkpoint 1345455520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.98566
Policy Entropy: 3.92358
Value Function Loss: 0.03077

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15173
Policy Update Magnitude: 0.64749
Value Function Update Magnitude: 0.77415

Collected Steps per Second: 20,667.94573
Overall Steps per Second: 9,607.97518

Timestep Collection Time: 2.42046
Timestep Consumption Time: 2.78625
PPO Batch Consumption Time: 0.33801
Total Iteration Time: 5.20672

Cumulative Model Updates: 161,360
Cumulative Timesteps: 1,345,505,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.84111
Policy Entropy: 3.90882
Value Function Loss: 0.02924

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.15806
Policy Update Magnitude: 0.63828
Value Function Update Magnitude: 0.80660

Collected Steps per Second: 17,779.33903
Overall Steps per Second: 9,283.67487

Timestep Collection Time: 2.81484
Timestep Consumption Time: 2.57591
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 5.39075

Cumulative Model Updates: 161,366
Cumulative Timesteps: 1,345,555,592

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1345555592...
Checkpoint 1345555592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,155.15848
Policy Entropy: 3.90162
Value Function Loss: 0.03091

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.78306

Collected Steps per Second: 18,241.17710
Overall Steps per Second: 9,449.84252

Timestep Collection Time: 2.74215
Timestep Consumption Time: 2.55106
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 5.29321

Cumulative Model Updates: 161,372
Cumulative Timesteps: 1,345,605,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,648.22212
Policy Entropy: 3.88122
Value Function Loss: 0.03360

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.19773
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.77760

Collected Steps per Second: 20,647.99294
Overall Steps per Second: 10,059.29233

Timestep Collection Time: 2.42348
Timestep Consumption Time: 2.55102
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.97451

Cumulative Model Updates: 161,378
Cumulative Timesteps: 1,345,655,652

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1345655652...
Checkpoint 1345655652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.07831
Policy Entropy: 3.90062
Value Function Loss: 0.03483

Mean KL Divergence: 0.01717
SB3 Clip Fraction: 0.19693
Policy Update Magnitude: 0.56565
Value Function Update Magnitude: 0.82447

Collected Steps per Second: 19,299.02189
Overall Steps per Second: 9,791.75268

Timestep Collection Time: 2.59153
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 5.10777

Cumulative Model Updates: 161,384
Cumulative Timesteps: 1,345,705,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.72000
Policy Entropy: 3.94144
Value Function Loss: 0.03035

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10900
Policy Update Magnitude: 0.60008
Value Function Update Magnitude: 0.77874

Collected Steps per Second: 20,018.89419
Overall Steps per Second: 9,792.23396

Timestep Collection Time: 2.49844
Timestep Consumption Time: 2.60928
PPO Batch Consumption Time: 0.31536
Total Iteration Time: 5.10772

Cumulative Model Updates: 161,390
Cumulative Timesteps: 1,345,755,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1345755682...
Checkpoint 1345755682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,509.39647
Policy Entropy: 3.94204
Value Function Loss: 0.02679

Mean KL Divergence: 0.00704
SB3 Clip Fraction: 0.08990
Policy Update Magnitude: 0.70638
Value Function Update Magnitude: 0.82938

Collected Steps per Second: 18,129.98771
Overall Steps per Second: 9,481.98968

Timestep Collection Time: 2.75885
Timestep Consumption Time: 2.51620
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.27505

Cumulative Model Updates: 161,396
Cumulative Timesteps: 1,345,805,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 167.49699
Policy Entropy: 3.93628
Value Function Loss: 0.02694

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.73077
Value Function Update Magnitude: 0.81008

Collected Steps per Second: 18,893.27333
Overall Steps per Second: 9,559.14137

Timestep Collection Time: 2.64729
Timestep Consumption Time: 2.58498
PPO Batch Consumption Time: 0.31444
Total Iteration Time: 5.23227

Cumulative Model Updates: 161,402
Cumulative Timesteps: 1,345,855,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1345855716...
Checkpoint 1345855716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454.00193
Policy Entropy: 3.92583
Value Function Loss: 0.02703

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17348
Policy Update Magnitude: 0.60156
Value Function Update Magnitude: 0.88467

Collected Steps per Second: 20,248.19768
Overall Steps per Second: 9,930.76300

Timestep Collection Time: 2.47044
Timestep Consumption Time: 2.56663
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 5.03708

Cumulative Model Updates: 161,408
Cumulative Timesteps: 1,345,905,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,267.95048
Policy Entropy: 3.91002
Value Function Loss: 0.02686

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.51508
Value Function Update Magnitude: 0.85368

Collected Steps per Second: 19,895.13388
Overall Steps per Second: 9,790.89896

Timestep Collection Time: 2.51519
Timestep Consumption Time: 2.59568
PPO Batch Consumption Time: 0.30116
Total Iteration Time: 5.11087

Cumulative Model Updates: 161,414
Cumulative Timesteps: 1,345,955,778

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1345955778...
Checkpoint 1345955778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.47567
Policy Entropy: 3.86913
Value Function Loss: 0.02346

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.51387
Value Function Update Magnitude: 0.80248

Collected Steps per Second: 20,296.10599
Overall Steps per Second: 9,826.36957

Timestep Collection Time: 2.46461
Timestep Consumption Time: 2.62598
PPO Batch Consumption Time: 0.30867
Total Iteration Time: 5.09059

Cumulative Model Updates: 161,420
Cumulative Timesteps: 1,346,005,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,385.53117
Policy Entropy: 3.81666
Value Function Loss: 0.02399

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.49488
Value Function Update Magnitude: 0.75996

Collected Steps per Second: 17,601.60165
Overall Steps per Second: 9,359.44030

Timestep Collection Time: 2.84247
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 5.34562

Cumulative Model Updates: 161,426
Cumulative Timesteps: 1,346,055,832

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1346055832...
Checkpoint 1346055832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,783.55071
Policy Entropy: 3.79728
Value Function Loss: 0.02963

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14485
Policy Update Magnitude: 0.51802
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 19,699.37328
Overall Steps per Second: 9,585.74232

Timestep Collection Time: 2.53927
Timestep Consumption Time: 2.67911
PPO Batch Consumption Time: 0.30007
Total Iteration Time: 5.21838

Cumulative Model Updates: 161,432
Cumulative Timesteps: 1,346,105,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,156.19143
Policy Entropy: 3.82734
Value Function Loss: 0.03411

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.67062

Collected Steps per Second: 19,586.63579
Overall Steps per Second: 9,191.99721

Timestep Collection Time: 2.55470
Timestep Consumption Time: 2.88895
PPO Batch Consumption Time: 0.35307
Total Iteration Time: 5.44365

Cumulative Model Updates: 161,438
Cumulative Timesteps: 1,346,155,892

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1346155892...
Checkpoint 1346155892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.58940
Policy Entropy: 3.88920
Value Function Loss: 0.03739

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.59916
Value Function Update Magnitude: 0.66248

Collected Steps per Second: 21,739.76242
Overall Steps per Second: 9,996.40191

Timestep Collection Time: 2.30122
Timestep Consumption Time: 2.70338
PPO Batch Consumption Time: 0.32434
Total Iteration Time: 5.00460

Cumulative Model Updates: 161,444
Cumulative Timesteps: 1,346,205,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07621
Policy Entropy: 3.90639
Value Function Loss: 0.03385

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11040
Policy Update Magnitude: 0.59651
Value Function Update Magnitude: 0.72909

Collected Steps per Second: 19,824.61227
Overall Steps per Second: 9,390.23389

Timestep Collection Time: 2.52292
Timestep Consumption Time: 2.80346
PPO Batch Consumption Time: 0.31917
Total Iteration Time: 5.32638

Cumulative Model Updates: 161,450
Cumulative Timesteps: 1,346,255,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1346255936...
Checkpoint 1346255936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,177.00343
Policy Entropy: 3.90036
Value Function Loss: 0.03598

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.77341

Collected Steps per Second: 20,829.50101
Overall Steps per Second: 9,894.19637

Timestep Collection Time: 2.40063
Timestep Consumption Time: 2.65324
PPO Batch Consumption Time: 0.31888
Total Iteration Time: 5.05387

Cumulative Model Updates: 161,456
Cumulative Timesteps: 1,346,305,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.29986
Policy Entropy: 3.88073
Value Function Loss: 0.03101

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.85160

Collected Steps per Second: 21,292.88392
Overall Steps per Second: 9,907.01041

Timestep Collection Time: 2.34905
Timestep Consumption Time: 2.69970
PPO Batch Consumption Time: 0.31719
Total Iteration Time: 5.04875

Cumulative Model Updates: 161,462
Cumulative Timesteps: 1,346,355,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1346355958...
Checkpoint 1346355958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.64057
Policy Entropy: 3.87018
Value Function Loss: 0.03191

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11288
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.72527

Collected Steps per Second: 16,467.80770
Overall Steps per Second: 8,529.91050

Timestep Collection Time: 3.03708
Timestep Consumption Time: 2.82629
PPO Batch Consumption Time: 0.34611
Total Iteration Time: 5.86337

Cumulative Model Updates: 161,468
Cumulative Timesteps: 1,346,405,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,005.39140
Policy Entropy: 3.87753
Value Function Loss: 0.02836

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.57733
Value Function Update Magnitude: 0.63362

Collected Steps per Second: 19,529.63385
Overall Steps per Second: 9,551.52668

Timestep Collection Time: 2.56083
Timestep Consumption Time: 2.67520
PPO Batch Consumption Time: 0.31012
Total Iteration Time: 5.23602

Cumulative Model Updates: 161,474
Cumulative Timesteps: 1,346,455,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1346455984...
Checkpoint 1346455984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 493.22954
Policy Entropy: 3.87014
Value Function Loss: 0.02962

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.62220

Collected Steps per Second: 20,801.45180
Overall Steps per Second: 9,914.60304

Timestep Collection Time: 2.40474
Timestep Consumption Time: 2.64055
PPO Batch Consumption Time: 0.31229
Total Iteration Time: 5.04529

Cumulative Model Updates: 161,480
Cumulative Timesteps: 1,346,506,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,502.28885
Policy Entropy: 3.86275
Value Function Loss: 0.02890

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11843
Policy Update Magnitude: 0.53602
Value Function Update Magnitude: 0.73571

Collected Steps per Second: 19,409.68911
Overall Steps per Second: 9,639.35132

Timestep Collection Time: 2.57624
Timestep Consumption Time: 2.61125
PPO Batch Consumption Time: 0.31052
Total Iteration Time: 5.18749

Cumulative Model Updates: 161,486
Cumulative Timesteps: 1,346,556,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1346556010...
Checkpoint 1346556010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,041.89557
Policy Entropy: 3.85313
Value Function Loss: 0.02885

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.54413
Value Function Update Magnitude: 0.76823

Collected Steps per Second: 19,046.63900
Overall Steps per Second: 9,304.13101

Timestep Collection Time: 2.62766
Timestep Consumption Time: 2.75146
PPO Batch Consumption Time: 0.33284
Total Iteration Time: 5.37912

Cumulative Model Updates: 161,492
Cumulative Timesteps: 1,346,606,058

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.92840
Policy Entropy: 3.85456
Value Function Loss: 0.02783

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11373
Policy Update Magnitude: 0.53101
Value Function Update Magnitude: 0.73512

Collected Steps per Second: 19,385.35140
Overall Steps per Second: 9,797.68572

Timestep Collection Time: 2.57978
Timestep Consumption Time: 2.52448
PPO Batch Consumption Time: 0.30653
Total Iteration Time: 5.10427

Cumulative Model Updates: 161,498
Cumulative Timesteps: 1,346,656,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1346656068...
Checkpoint 1346656068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201.65901
Policy Entropy: 3.86808
Value Function Loss: 0.02792

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.50444
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 19,298.26104
Overall Steps per Second: 9,736.72201

Timestep Collection Time: 2.59257
Timestep Consumption Time: 2.54592
PPO Batch Consumption Time: 0.30934
Total Iteration Time: 5.13848

Cumulative Model Updates: 161,504
Cumulative Timesteps: 1,346,706,100

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,016.59521
Policy Entropy: 3.84068
Value Function Loss: 0.02759

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.49337
Value Function Update Magnitude: 0.51089

Collected Steps per Second: 20,069.22297
Overall Steps per Second: 10,080.08256

Timestep Collection Time: 2.49287
Timestep Consumption Time: 2.47038
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.96325

Cumulative Model Updates: 161,510
Cumulative Timesteps: 1,346,756,130

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1346756130...
Checkpoint 1346756130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,465.15405
Policy Entropy: 3.83914
Value Function Loss: 0.02775

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.52232
Value Function Update Magnitude: 0.48401

Collected Steps per Second: 19,429.25892
Overall Steps per Second: 9,788.12287

Timestep Collection Time: 2.57467
Timestep Consumption Time: 2.53601
PPO Batch Consumption Time: 0.30766
Total Iteration Time: 5.11068

Cumulative Model Updates: 161,516
Cumulative Timesteps: 1,346,806,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,664.12224
Policy Entropy: 3.81271
Value Function Loss: 0.02809

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.51039
Value Function Update Magnitude: 0.49718

Collected Steps per Second: 20,454.12058
Overall Steps per Second: 10,029.10390

Timestep Collection Time: 2.44459
Timestep Consumption Time: 2.54110
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.98569

Cumulative Model Updates: 161,522
Cumulative Timesteps: 1,346,856,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1346856156...
Checkpoint 1346856156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.99043
Policy Entropy: 3.82210
Value Function Loss: 0.02678

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.48192
Value Function Update Magnitude: 0.47736

Collected Steps per Second: 19,307.63132
Overall Steps per Second: 9,830.28515

Timestep Collection Time: 2.58975
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.30055
Total Iteration Time: 5.08653

Cumulative Model Updates: 161,528
Cumulative Timesteps: 1,346,906,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,953.03381
Policy Entropy: 3.79887
Value Function Loss: 0.02385

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12274
Policy Update Magnitude: 0.46586
Value Function Update Magnitude: 0.57984

Collected Steps per Second: 20,382.21501
Overall Steps per Second: 9,999.35780

Timestep Collection Time: 2.45449
Timestep Consumption Time: 2.54863
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 5.00312

Cumulative Model Updates: 161,534
Cumulative Timesteps: 1,346,956,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1346956186...
Checkpoint 1346956186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,131.89770
Policy Entropy: 3.79143
Value Function Loss: 0.02207

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.44507
Value Function Update Magnitude: 0.60905

Collected Steps per Second: 19,561.63552
Overall Steps per Second: 9,682.06207

Timestep Collection Time: 2.55653
Timestep Consumption Time: 2.60869
PPO Batch Consumption Time: 0.31862
Total Iteration Time: 5.16522

Cumulative Model Updates: 161,540
Cumulative Timesteps: 1,347,006,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,831.16493
Policy Entropy: 3.79355
Value Function Loss: 0.02277

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.46122
Value Function Update Magnitude: 0.58914

Collected Steps per Second: 20,437.55781
Overall Steps per Second: 9,831.77839

Timestep Collection Time: 2.44853
Timestep Consumption Time: 2.64129
PPO Batch Consumption Time: 0.30856
Total Iteration Time: 5.08982

Cumulative Model Updates: 161,546
Cumulative Timesteps: 1,347,056,238

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1347056238...
Checkpoint 1347056238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,805.16733
Policy Entropy: 3.78441
Value Function Loss: 0.02279

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.45618
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 20,315.12245
Overall Steps per Second: 9,814.41496

Timestep Collection Time: 2.46161
Timestep Consumption Time: 2.63375
PPO Batch Consumption Time: 0.30942
Total Iteration Time: 5.09536

Cumulative Model Updates: 161,552
Cumulative Timesteps: 1,347,106,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,736.89177
Policy Entropy: 3.77922
Value Function Loss: 0.02163

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.42725
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 19,331.80782
Overall Steps per Second: 9,653.43173

Timestep Collection Time: 2.58755
Timestep Consumption Time: 2.59424
PPO Batch Consumption Time: 0.30183
Total Iteration Time: 5.18178

Cumulative Model Updates: 161,558
Cumulative Timesteps: 1,347,156,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1347156268...
Checkpoint 1347156268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,383.09895
Policy Entropy: 3.77613
Value Function Loss: 0.01984

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.40194
Value Function Update Magnitude: 0.43012

Collected Steps per Second: 20,170.64973
Overall Steps per Second: 9,804.72479

Timestep Collection Time: 2.48004
Timestep Consumption Time: 2.62199
PPO Batch Consumption Time: 0.30687
Total Iteration Time: 5.10203

Cumulative Model Updates: 161,564
Cumulative Timesteps: 1,347,206,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,377.83366
Policy Entropy: 3.77198
Value Function Loss: 0.02208

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.42469
Value Function Update Magnitude: 0.48443

Collected Steps per Second: 20,578.95211
Overall Steps per Second: 9,947.94352

Timestep Collection Time: 2.43083
Timestep Consumption Time: 2.59774
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 5.02858

Cumulative Model Updates: 161,570
Cumulative Timesteps: 1,347,256,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1347256316...
Checkpoint 1347256316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,549.02842
Policy Entropy: 3.77816
Value Function Loss: 0.02005

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.45574
Value Function Update Magnitude: 0.53187

Collected Steps per Second: 20,175.74274
Overall Steps per Second: 9,905.82731

Timestep Collection Time: 2.47921
Timestep Consumption Time: 2.57034
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 5.04955

Cumulative Model Updates: 161,576
Cumulative Timesteps: 1,347,306,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,609.02071
Policy Entropy: 3.76770
Value Function Loss: 0.02365

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.46598
Value Function Update Magnitude: 0.59438

Collected Steps per Second: 20,500.95378
Overall Steps per Second: 9,951.13933

Timestep Collection Time: 2.43940
Timestep Consumption Time: 2.58616
PPO Batch Consumption Time: 0.30326
Total Iteration Time: 5.02556

Cumulative Model Updates: 161,582
Cumulative Timesteps: 1,347,356,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1347356346...
Checkpoint 1347356346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,128.91392
Policy Entropy: 3.80194
Value Function Loss: 0.02171

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.49415
Value Function Update Magnitude: 0.59065

Collected Steps per Second: 19,828.07530
Overall Steps per Second: 9,697.55797

Timestep Collection Time: 2.52299
Timestep Consumption Time: 2.63563
PPO Batch Consumption Time: 0.30912
Total Iteration Time: 5.15862

Cumulative Model Updates: 161,588
Cumulative Timesteps: 1,347,406,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.32028
Policy Entropy: 3.82644
Value Function Loss: 0.02447

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.47095
Value Function Update Magnitude: 0.64461

Collected Steps per Second: 20,980.40163
Overall Steps per Second: 9,859.43380

Timestep Collection Time: 2.38461
Timestep Consumption Time: 2.68972
PPO Batch Consumption Time: 0.32018
Total Iteration Time: 5.07433

Cumulative Model Updates: 161,594
Cumulative Timesteps: 1,347,456,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1347456402...
Checkpoint 1347456402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.80261
Policy Entropy: 3.84262
Value Function Loss: 0.02234

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.68708

Collected Steps per Second: 20,196.87982
Overall Steps per Second: 9,703.55445

Timestep Collection Time: 2.47751
Timestep Consumption Time: 2.67916
PPO Batch Consumption Time: 0.31627
Total Iteration Time: 5.15667

Cumulative Model Updates: 161,600
Cumulative Timesteps: 1,347,506,440

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.30085
Policy Entropy: 3.82205
Value Function Loss: 0.02163

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.49669
Value Function Update Magnitude: 0.70401

Collected Steps per Second: 21,027.38161
Overall Steps per Second: 9,906.09502

Timestep Collection Time: 2.37966
Timestep Consumption Time: 2.67157
PPO Batch Consumption Time: 0.31547
Total Iteration Time: 5.05123

Cumulative Model Updates: 161,606
Cumulative Timesteps: 1,347,556,478

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1347556478...
Checkpoint 1347556478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,255.27388
Policy Entropy: 3.79571
Value Function Loss: 0.01987

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.46878
Value Function Update Magnitude: 0.64618

Collected Steps per Second: 20,275.03855
Overall Steps per Second: 9,799.45915

Timestep Collection Time: 2.46619
Timestep Consumption Time: 2.63634
PPO Batch Consumption Time: 0.31087
Total Iteration Time: 5.10253

Cumulative Model Updates: 161,612
Cumulative Timesteps: 1,347,606,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,855.90594
Policy Entropy: 3.78343
Value Function Loss: 0.02036

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.45666
Value Function Update Magnitude: 0.57925

Collected Steps per Second: 20,952.24379
Overall Steps per Second: 9,762.43912

Timestep Collection Time: 2.38714
Timestep Consumption Time: 2.73617
PPO Batch Consumption Time: 0.32736
Total Iteration Time: 5.12331

Cumulative Model Updates: 161,618
Cumulative Timesteps: 1,347,656,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1347656496...
Checkpoint 1347656496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,083.60177
Policy Entropy: 3.76394
Value Function Loss: 0.02149

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.46206
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 19,959.22548
Overall Steps per Second: 9,556.96676

Timestep Collection Time: 2.50681
Timestep Consumption Time: 2.72853
PPO Batch Consumption Time: 0.32326
Total Iteration Time: 5.23534

Cumulative Model Updates: 161,624
Cumulative Timesteps: 1,347,706,530

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,192.32624
Policy Entropy: 3.74875
Value Function Loss: 0.02614

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.48361
Value Function Update Magnitude: 0.49174

Collected Steps per Second: 19,264.24530
Overall Steps per Second: 9,168.66437

Timestep Collection Time: 2.59548
Timestep Consumption Time: 2.85788
PPO Batch Consumption Time: 0.32596
Total Iteration Time: 5.45336

Cumulative Model Updates: 161,630
Cumulative Timesteps: 1,347,756,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1347756530...
Checkpoint 1347756530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,127.37855
Policy Entropy: 3.76332
Value Function Loss: 0.02406

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13306
Policy Update Magnitude: 0.48292
Value Function Update Magnitude: 0.42517

Collected Steps per Second: 19,370.77992
Overall Steps per Second: 9,587.52964

Timestep Collection Time: 2.58276
Timestep Consumption Time: 2.63548
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 5.21824

Cumulative Model Updates: 161,636
Cumulative Timesteps: 1,347,806,560

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,528.00422
Policy Entropy: 3.78157
Value Function Loss: 0.02379

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.47894
Value Function Update Magnitude: 0.41723

Collected Steps per Second: 20,874.33065
Overall Steps per Second: 9,927.37220

Timestep Collection Time: 2.39624
Timestep Consumption Time: 2.64235
PPO Batch Consumption Time: 0.30106
Total Iteration Time: 5.03859

Cumulative Model Updates: 161,642
Cumulative Timesteps: 1,347,856,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1347856580...
Checkpoint 1347856580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,261.79525
Policy Entropy: 3.79006
Value Function Loss: 0.02180

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.47201
Value Function Update Magnitude: 0.48244

Collected Steps per Second: 20,517.53360
Overall Steps per Second: 10,048.32248

Timestep Collection Time: 2.43860
Timestep Consumption Time: 2.54074
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.97934

Cumulative Model Updates: 161,648
Cumulative Timesteps: 1,347,906,614

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,680.37673
Policy Entropy: 3.77949
Value Function Loss: 0.02101

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.48874
Value Function Update Magnitude: 0.51084

Collected Steps per Second: 21,082.07079
Overall Steps per Second: 10,026.52599

Timestep Collection Time: 2.37263
Timestep Consumption Time: 2.61613
PPO Batch Consumption Time: 0.30360
Total Iteration Time: 4.98877

Cumulative Model Updates: 161,654
Cumulative Timesteps: 1,347,956,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1347956634...
Checkpoint 1347956634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,884.75185
Policy Entropy: 3.76412
Value Function Loss: 0.01993

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.47460
Value Function Update Magnitude: 0.50070

Collected Steps per Second: 19,854.32197
Overall Steps per Second: 9,763.76160

Timestep Collection Time: 2.51875
Timestep Consumption Time: 2.60305
PPO Batch Consumption Time: 0.30597
Total Iteration Time: 5.12180

Cumulative Model Updates: 161,660
Cumulative Timesteps: 1,348,006,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,884.75185
Policy Entropy: 3.75848
Value Function Loss: 0.01766

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16631
Policy Update Magnitude: 0.47200
Value Function Update Magnitude: 0.49131

Collected Steps per Second: 20,973.37077
Overall Steps per Second: 10,003.29639

Timestep Collection Time: 2.38607
Timestep Consumption Time: 2.61668
PPO Batch Consumption Time: 0.30502
Total Iteration Time: 5.00275

Cumulative Model Updates: 161,666
Cumulative Timesteps: 1,348,056,686

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1348056686...
Checkpoint 1348056686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,430.53324
Policy Entropy: 3.73044
Value Function Loss: 0.02447

Mean KL Divergence: 0.02498
SB3 Clip Fraction: 0.27203
Policy Update Magnitude: 0.46727
Value Function Update Magnitude: 0.47260

Collected Steps per Second: 19,912.08910
Overall Steps per Second: 9,875.68734

Timestep Collection Time: 2.51254
Timestep Consumption Time: 2.55343
PPO Batch Consumption Time: 0.30167
Total Iteration Time: 5.06598

Cumulative Model Updates: 161,672
Cumulative Timesteps: 1,348,106,716

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,700.77475
Policy Entropy: 3.73247
Value Function Loss: 0.03067

Mean KL Divergence: 0.01618
SB3 Clip Fraction: 0.19630
Policy Update Magnitude: 0.45292
Value Function Update Magnitude: 0.54166

Collected Steps per Second: 20,061.88040
Overall Steps per Second: 9,869.27426

Timestep Collection Time: 2.49239
Timestep Consumption Time: 2.57404
PPO Batch Consumption Time: 0.30066
Total Iteration Time: 5.06643

Cumulative Model Updates: 161,678
Cumulative Timesteps: 1,348,156,718

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1348156718...
Checkpoint 1348156718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,121.03036
Policy Entropy: 3.71950
Value Function Loss: 0.03761

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.53579
Value Function Update Magnitude: 0.46446

Collected Steps per Second: 19,172.59154
Overall Steps per Second: 9,639.17950

Timestep Collection Time: 2.60862
Timestep Consumption Time: 2.58000
PPO Batch Consumption Time: 0.30759
Total Iteration Time: 5.18862

Cumulative Model Updates: 161,684
Cumulative Timesteps: 1,348,206,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,012.02693
Policy Entropy: 3.74897
Value Function Loss: 0.03308

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.71665
Value Function Update Magnitude: 0.41793

Collected Steps per Second: 20,256.00920
Overall Steps per Second: 9,818.14064

Timestep Collection Time: 2.46949
Timestep Consumption Time: 2.62537
PPO Batch Consumption Time: 0.31009
Total Iteration Time: 5.09485

Cumulative Model Updates: 161,690
Cumulative Timesteps: 1,348,256,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1348256754...
Checkpoint 1348256754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,192.86525
Policy Entropy: 3.75903
Value Function Loss: 0.03459

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.69730
Value Function Update Magnitude: 0.37786

Collected Steps per Second: 20,220.90038
Overall Steps per Second: 9,976.67012

Timestep Collection Time: 2.47397
Timestep Consumption Time: 2.54032
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 5.01430

Cumulative Model Updates: 161,696
Cumulative Timesteps: 1,348,306,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,812.95108
Policy Entropy: 3.78821
Value Function Loss: 0.02509

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.18576
Policy Update Magnitude: 0.56760
Value Function Update Magnitude: 0.46450

Collected Steps per Second: 20,345.97596
Overall Steps per Second: 9,962.65240

Timestep Collection Time: 2.45847
Timestep Consumption Time: 2.56228
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 5.02075

Cumulative Model Updates: 161,702
Cumulative Timesteps: 1,348,356,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1348356800...
Checkpoint 1348356800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,130.16954
Policy Entropy: 3.77838
Value Function Loss: 0.02222

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.48344
Value Function Update Magnitude: 0.50843

Collected Steps per Second: 19,313.45719
Overall Steps per Second: 9,752.50101

Timestep Collection Time: 2.59104
Timestep Consumption Time: 2.54015
PPO Batch Consumption Time: 0.29960
Total Iteration Time: 5.13120

Cumulative Model Updates: 161,708
Cumulative Timesteps: 1,348,406,842

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,106.33760
Policy Entropy: 3.75762
Value Function Loss: 0.02230

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.45238
Value Function Update Magnitude: 0.41035

Collected Steps per Second: 20,384.73841
Overall Steps per Second: 9,947.66254

Timestep Collection Time: 2.45448
Timestep Consumption Time: 2.57524
PPO Batch Consumption Time: 0.30361
Total Iteration Time: 5.02972

Cumulative Model Updates: 161,714
Cumulative Timesteps: 1,348,456,876

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1348456876...
Checkpoint 1348456876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,822.01174
Policy Entropy: 3.75091
Value Function Loss: 0.02159

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.52155
Value Function Update Magnitude: 0.35065

Collected Steps per Second: 19,855.56092
Overall Steps per Second: 9,965.37997

Timestep Collection Time: 2.51919
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 5.01938

Cumulative Model Updates: 161,720
Cumulative Timesteps: 1,348,506,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,019.77081
Policy Entropy: 3.75477
Value Function Loss: 0.02145

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.62821
Value Function Update Magnitude: 0.37806

Collected Steps per Second: 20,316.52143
Overall Steps per Second: 9,875.24100

Timestep Collection Time: 2.46263
Timestep Consumption Time: 2.60378
PPO Batch Consumption Time: 0.30434
Total Iteration Time: 5.06641

Cumulative Model Updates: 161,726
Cumulative Timesteps: 1,348,556,928

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1348556928...
Checkpoint 1348556928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,396.68681
Policy Entropy: 3.77273
Value Function Loss: 0.01810

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07636
Policy Update Magnitude: 0.61316
Value Function Update Magnitude: 0.32813

Collected Steps per Second: 19,602.33023
Overall Steps per Second: 9,807.04448

Timestep Collection Time: 2.55194
Timestep Consumption Time: 2.54888
PPO Batch Consumption Time: 0.30247
Total Iteration Time: 5.10082

Cumulative Model Updates: 161,732
Cumulative Timesteps: 1,348,606,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,396.68681
Policy Entropy: 3.76192
Value Function Loss: 0.01744

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.16164
Policy Update Magnitude: 0.48744
Value Function Update Magnitude: 0.33135

Collected Steps per Second: 20,438.05232
Overall Steps per Second: 9,911.35105

Timestep Collection Time: 2.44837
Timestep Consumption Time: 2.60038
PPO Batch Consumption Time: 0.30977
Total Iteration Time: 5.04876

Cumulative Model Updates: 161,738
Cumulative Timesteps: 1,348,656,992

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1348656992...
Checkpoint 1348656992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,137.53007
Policy Entropy: 3.76959
Value Function Loss: 0.01762

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13523
Policy Update Magnitude: 0.39157
Value Function Update Magnitude: 0.41729

Collected Steps per Second: 19,560.45423
Overall Steps per Second: 9,782.81314

Timestep Collection Time: 2.55822
Timestep Consumption Time: 2.55687
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 5.11509

Cumulative Model Updates: 161,744
Cumulative Timesteps: 1,348,707,032

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,526.44712
Policy Entropy: 3.77073
Value Function Loss: 0.01826

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.38657
Value Function Update Magnitude: 0.49999

Collected Steps per Second: 20,470.46469
Overall Steps per Second: 9,970.47761

Timestep Collection Time: 2.44381
Timestep Consumption Time: 2.57360
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 5.01741

Cumulative Model Updates: 161,750
Cumulative Timesteps: 1,348,757,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1348757058...
Checkpoint 1348757058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,586.95467
Policy Entropy: 3.77418
Value Function Loss: 0.01764

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.37034
Value Function Update Magnitude: 0.49557

Collected Steps per Second: 20,393.34793
Overall Steps per Second: 9,943.80494

Timestep Collection Time: 2.45237
Timestep Consumption Time: 2.57709
PPO Batch Consumption Time: 0.30764
Total Iteration Time: 5.02946

Cumulative Model Updates: 161,756
Cumulative Timesteps: 1,348,807,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,678.25920
Policy Entropy: 3.77262
Value Function Loss: 0.01705

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.36098
Value Function Update Magnitude: 0.51238

Collected Steps per Second: 20,482.13470
Overall Steps per Second: 9,852.90597

Timestep Collection Time: 2.44115
Timestep Consumption Time: 2.63349
PPO Batch Consumption Time: 0.30940
Total Iteration Time: 5.07465

Cumulative Model Updates: 161,762
Cumulative Timesteps: 1,348,857,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1348857070...
Checkpoint 1348857070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,096.94500
Policy Entropy: 3.78239
Value Function Loss: 0.01625

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.38785
Value Function Update Magnitude: 0.60668

Collected Steps per Second: 20,025.74842
Overall Steps per Second: 9,899.17314

Timestep Collection Time: 2.49918
Timestep Consumption Time: 2.55659
PPO Batch Consumption Time: 0.30327
Total Iteration Time: 5.05578

Cumulative Model Updates: 161,768
Cumulative Timesteps: 1,348,907,118

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,404.32449
Policy Entropy: 3.76798
Value Function Loss: 0.01669

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.39598
Value Function Update Magnitude: 0.65123

Collected Steps per Second: 20,195.38602
Overall Steps per Second: 9,939.97318

Timestep Collection Time: 2.47631
Timestep Consumption Time: 2.55489
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 5.03120

Cumulative Model Updates: 161,774
Cumulative Timesteps: 1,348,957,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1348957128...
Checkpoint 1348957128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,293.69170
Policy Entropy: 3.76484
Value Function Loss: 0.02018

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 0.41683
Value Function Update Magnitude: 0.68741

Collected Steps per Second: 20,333.18149
Overall Steps per Second: 9,912.24452

Timestep Collection Time: 2.46071
Timestep Consumption Time: 2.58699
PPO Batch Consumption Time: 0.30862
Total Iteration Time: 5.04770

Cumulative Model Updates: 161,780
Cumulative Timesteps: 1,349,007,162

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,716.40221
Policy Entropy: 3.77854
Value Function Loss: 0.02397

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.47978
Value Function Update Magnitude: 0.79946

Collected Steps per Second: 20,341.36404
Overall Steps per Second: 9,972.50662

Timestep Collection Time: 2.45903
Timestep Consumption Time: 2.55676
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 5.01579

Cumulative Model Updates: 161,786
Cumulative Timesteps: 1,349,057,182

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1349057182...
Checkpoint 1349057182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,043.89963
Policy Entropy: 3.78571
Value Function Loss: 0.02879

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.53391
Value Function Update Magnitude: 0.86482

Collected Steps per Second: 20,508.07966
Overall Steps per Second: 9,886.48535

Timestep Collection Time: 2.43816
Timestep Consumption Time: 2.61945
PPO Batch Consumption Time: 0.31486
Total Iteration Time: 5.05761

Cumulative Model Updates: 161,792
Cumulative Timesteps: 1,349,107,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,064.17781
Policy Entropy: 3.80232
Value Function Loss: 0.02701

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.53493
Value Function Update Magnitude: 0.73830

Collected Steps per Second: 20,827.28581
Overall Steps per Second: 9,853.29124

Timestep Collection Time: 2.40147
Timestep Consumption Time: 2.67461
PPO Batch Consumption Time: 0.31927
Total Iteration Time: 5.07607

Cumulative Model Updates: 161,798
Cumulative Timesteps: 1,349,157,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1349157200...
Checkpoint 1349157200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,253.32890
Policy Entropy: 3.77503
Value Function Loss: 0.02714

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13237
Policy Update Magnitude: 0.48942
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 20,519.13754
Overall Steps per Second: 9,824.67301

Timestep Collection Time: 2.43802
Timestep Consumption Time: 2.65386
PPO Batch Consumption Time: 0.31672
Total Iteration Time: 5.09187

Cumulative Model Updates: 161,804
Cumulative Timesteps: 1,349,207,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,290.87969
Policy Entropy: 3.78264
Value Function Loss: 0.02373

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.45508
Value Function Update Magnitude: 0.47523

Collected Steps per Second: 20,783.01244
Overall Steps per Second: 9,903.02909

Timestep Collection Time: 2.40610
Timestep Consumption Time: 2.64347
PPO Batch Consumption Time: 0.31449
Total Iteration Time: 5.04957

Cumulative Model Updates: 161,810
Cumulative Timesteps: 1,349,257,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1349257232...
Checkpoint 1349257232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.83970
Policy Entropy: 3.78124
Value Function Loss: 0.02330

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.44362
Value Function Update Magnitude: 0.45382

Collected Steps per Second: 21,080.76600
Overall Steps per Second: 10,001.13998

Timestep Collection Time: 2.37297
Timestep Consumption Time: 2.62886
PPO Batch Consumption Time: 0.31402
Total Iteration Time: 5.00183

Cumulative Model Updates: 161,816
Cumulative Timesteps: 1,349,307,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.00949
Policy Entropy: 3.77859
Value Function Loss: 0.02218

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.41310
Value Function Update Magnitude: 0.46792

Collected Steps per Second: 20,979.31390
Overall Steps per Second: 9,963.12981

Timestep Collection Time: 2.38492
Timestep Consumption Time: 2.63700
PPO Batch Consumption Time: 0.31151
Total Iteration Time: 5.02192

Cumulative Model Updates: 161,822
Cumulative Timesteps: 1,349,357,290

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1349357290...
Checkpoint 1349357290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,177.53130
Policy Entropy: 3.75988
Value Function Loss: 0.02349

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.44108
Value Function Update Magnitude: 0.57186

Collected Steps per Second: 20,695.71123
Overall Steps per Second: 9,859.58100

Timestep Collection Time: 2.41673
Timestep Consumption Time: 2.65610
PPO Batch Consumption Time: 0.31247
Total Iteration Time: 5.07283

Cumulative Model Updates: 161,828
Cumulative Timesteps: 1,349,407,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,614.61522
Policy Entropy: 3.74322
Value Function Loss: 0.02215

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.48222
Value Function Update Magnitude: 0.67525

Collected Steps per Second: 20,754.68012
Overall Steps per Second: 9,818.41832

Timestep Collection Time: 2.41093
Timestep Consumption Time: 2.68541
PPO Batch Consumption Time: 0.32143
Total Iteration Time: 5.09634

Cumulative Model Updates: 161,834
Cumulative Timesteps: 1,349,457,344

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1349457344...
Checkpoint 1349457344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,614.61522
Policy Entropy: 3.74013
Value Function Loss: 0.01922

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.47389
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 20,644.77768
Overall Steps per Second: 9,908.30000

Timestep Collection Time: 2.42318
Timestep Consumption Time: 2.62572
PPO Batch Consumption Time: 0.31073
Total Iteration Time: 5.04890

Cumulative Model Updates: 161,840
Cumulative Timesteps: 1,349,507,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,614.61522
Policy Entropy: 3.74201
Value Function Loss: 0.01369

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.41165
Value Function Update Magnitude: 0.45689

Collected Steps per Second: 20,573.98972
Overall Steps per Second: 9,728.76369

Timestep Collection Time: 2.43132
Timestep Consumption Time: 2.71034
PPO Batch Consumption Time: 0.32743
Total Iteration Time: 5.14166

Cumulative Model Updates: 161,846
Cumulative Timesteps: 1,349,557,392

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1349557392...
Checkpoint 1349557392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,218.31035
Policy Entropy: 3.75388
Value Function Loss: 0.01389

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.36243
Value Function Update Magnitude: 0.33174

Collected Steps per Second: 20,745.20173
Overall Steps per Second: 9,870.42038

Timestep Collection Time: 2.41029
Timestep Consumption Time: 2.65555
PPO Batch Consumption Time: 0.31819
Total Iteration Time: 5.06584

Cumulative Model Updates: 161,852
Cumulative Timesteps: 1,349,607,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,218.31035
Policy Entropy: 3.74836
Value Function Loss: 0.01191

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.35817
Value Function Update Magnitude: 0.37277

Collected Steps per Second: 20,788.26825
Overall Steps per Second: 9,899.54276

Timestep Collection Time: 2.40578
Timestep Consumption Time: 2.64617
PPO Batch Consumption Time: 0.31480
Total Iteration Time: 5.05195

Cumulative Model Updates: 161,858
Cumulative Timesteps: 1,349,657,406

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1349657406...
Checkpoint 1349657406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,218.31035
Policy Entropy: 3.73477
Value Function Loss: 0.01331

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.40417
Value Function Update Magnitude: 0.45932

Collected Steps per Second: 20,836.23107
Overall Steps per Second: 9,906.02608

Timestep Collection Time: 2.39986
Timestep Consumption Time: 2.64798
PPO Batch Consumption Time: 0.31696
Total Iteration Time: 5.04784

Cumulative Model Updates: 161,864
Cumulative Timesteps: 1,349,707,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,970.92893
Policy Entropy: 3.72597
Value Function Loss: 0.01622

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.43925
Value Function Update Magnitude: 0.59640

Collected Steps per Second: 20,588.75628
Overall Steps per Second: 9,849.83908

Timestep Collection Time: 2.42977
Timestep Consumption Time: 2.64909
PPO Batch Consumption Time: 0.31582
Total Iteration Time: 5.07886

Cumulative Model Updates: 161,870
Cumulative Timesteps: 1,349,757,436

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1349757436...
Checkpoint 1349757436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,530.01401
Policy Entropy: 3.74525
Value Function Loss: 0.01806

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12493
Policy Update Magnitude: 0.46385
Value Function Update Magnitude: 0.71318

Collected Steps per Second: 20,474.53581
Overall Steps per Second: 9,928.03978

Timestep Collection Time: 2.44264
Timestep Consumption Time: 2.59481
PPO Batch Consumption Time: 0.30575
Total Iteration Time: 5.03745

Cumulative Model Updates: 161,876
Cumulative Timesteps: 1,349,807,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 200,982.03551
Policy Entropy: 3.74369
Value Function Loss: 0.02120

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.77361

Collected Steps per Second: 20,242.26763
Overall Steps per Second: 9,776.90700

Timestep Collection Time: 2.47038
Timestep Consumption Time: 2.64433
PPO Batch Consumption Time: 0.30491
Total Iteration Time: 5.11471

Cumulative Model Updates: 161,882
Cumulative Timesteps: 1,349,857,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1349857454...
Checkpoint 1349857454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,550.58347
Policy Entropy: 3.76598
Value Function Loss: 0.01967

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12349
Policy Update Magnitude: 0.51598
Value Function Update Magnitude: 0.77488

Collected Steps per Second: 20,969.86308
Overall Steps per Second: 10,084.63311

Timestep Collection Time: 2.38580
Timestep Consumption Time: 2.57521
PPO Batch Consumption Time: 0.30048
Total Iteration Time: 4.96101

Cumulative Model Updates: 161,888
Cumulative Timesteps: 1,349,907,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,662.90020
Policy Entropy: 3.74770
Value Function Loss: 0.01927

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.51360
Value Function Update Magnitude: 0.76152

Collected Steps per Second: 20,366.98111
Overall Steps per Second: 9,790.93105

Timestep Collection Time: 2.45574
Timestep Consumption Time: 2.65266
PPO Batch Consumption Time: 0.30177
Total Iteration Time: 5.10840

Cumulative Model Updates: 161,894
Cumulative Timesteps: 1,349,957,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1349957500...
Checkpoint 1349957500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,301.45829
Policy Entropy: 3.74981
Value Function Loss: 0.01955

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.73750

Collected Steps per Second: 20,985.48608
Overall Steps per Second: 10,096.74632

Timestep Collection Time: 2.38288
Timestep Consumption Time: 2.56980
PPO Batch Consumption Time: 0.29830
Total Iteration Time: 4.95268

Cumulative Model Updates: 161,900
Cumulative Timesteps: 1,350,007,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,690.66416
Policy Entropy: 3.74940
Value Function Loss: 0.02138

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13214
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.65557

Collected Steps per Second: 20,312.27513
Overall Steps per Second: 9,873.16694

Timestep Collection Time: 2.46186
Timestep Consumption Time: 2.60298
PPO Batch Consumption Time: 0.30222
Total Iteration Time: 5.06484

Cumulative Model Updates: 161,906
Cumulative Timesteps: 1,350,057,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1350057512...
Checkpoint 1350057512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,437.67334
Policy Entropy: 3.76582
Value Function Loss: 0.02030

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.52670
Value Function Update Magnitude: 0.66175

Collected Steps per Second: 20,363.37199
Overall Steps per Second: 9,956.30575

Timestep Collection Time: 2.45716
Timestep Consumption Time: 2.56840
PPO Batch Consumption Time: 0.30415
Total Iteration Time: 5.02556

Cumulative Model Updates: 161,912
Cumulative Timesteps: 1,350,107,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,393.52970
Policy Entropy: 3.77260
Value Function Loss: 0.02089

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12774
Policy Update Magnitude: 0.48720
Value Function Update Magnitude: 0.59902

Collected Steps per Second: 20,273.38375
Overall Steps per Second: 9,824.48165

Timestep Collection Time: 2.46639
Timestep Consumption Time: 2.62314
PPO Batch Consumption Time: 0.30977
Total Iteration Time: 5.08953

Cumulative Model Updates: 161,918
Cumulative Timesteps: 1,350,157,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1350157550...
Checkpoint 1350157550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,886.60596
Policy Entropy: 3.77897
Value Function Loss: 0.01826

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.47822
Value Function Update Magnitude: 0.56184

Collected Steps per Second: 20,878.82053
Overall Steps per Second: 10,102.66587

Timestep Collection Time: 2.39573
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.95117

Cumulative Model Updates: 161,924
Cumulative Timesteps: 1,350,207,570

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,347.15212
Policy Entropy: 3.75767
Value Function Loss: 0.02163

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.48281
Value Function Update Magnitude: 0.56590

Collected Steps per Second: 20,633.20659
Overall Steps per Second: 9,960.47874

Timestep Collection Time: 2.42386
Timestep Consumption Time: 2.59718
PPO Batch Consumption Time: 0.30262
Total Iteration Time: 5.02104

Cumulative Model Updates: 161,930
Cumulative Timesteps: 1,350,257,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1350257582...
Checkpoint 1350257582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,019.55728
Policy Entropy: 3.76108
Value Function Loss: 0.02011

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.60931

Collected Steps per Second: 20,185.59264
Overall Steps per Second: 9,967.90880

Timestep Collection Time: 2.47711
Timestep Consumption Time: 2.53918
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 5.01630

Cumulative Model Updates: 161,936
Cumulative Timesteps: 1,350,307,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,064.63242
Policy Entropy: 3.75458
Value Function Loss: 0.02468

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.60184

Collected Steps per Second: 20,205.88241
Overall Steps per Second: 9,903.05167

Timestep Collection Time: 2.47621
Timestep Consumption Time: 2.57617
PPO Batch Consumption Time: 0.30351
Total Iteration Time: 5.05238

Cumulative Model Updates: 161,942
Cumulative Timesteps: 1,350,357,618

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1350357618...
Checkpoint 1350357618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,953.42825
Policy Entropy: 3.77579
Value Function Loss: 0.02706

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.58710
Value Function Update Magnitude: 0.56484

Collected Steps per Second: 20,283.73727
Overall Steps per Second: 9,996.33381

Timestep Collection Time: 2.46749
Timestep Consumption Time: 2.53934
PPO Batch Consumption Time: 0.29861
Total Iteration Time: 5.00684

Cumulative Model Updates: 161,948
Cumulative Timesteps: 1,350,407,668

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,977.17990
Policy Entropy: 3.78703
Value Function Loss: 0.02692

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.62207
Value Function Update Magnitude: 0.53411

Collected Steps per Second: 20,056.01038
Overall Steps per Second: 9,909.61749

Timestep Collection Time: 2.49372
Timestep Consumption Time: 2.55330
PPO Batch Consumption Time: 0.29984
Total Iteration Time: 5.04702

Cumulative Model Updates: 161,954
Cumulative Timesteps: 1,350,457,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1350457682...
Checkpoint 1350457682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,426.23745
Policy Entropy: 3.78061
Value Function Loss: 0.02727

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12480
Policy Update Magnitude: 0.63043
Value Function Update Magnitude: 0.51244

Collected Steps per Second: 20,188.18681
Overall Steps per Second: 9,927.63234

Timestep Collection Time: 2.47739
Timestep Consumption Time: 2.56047
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 5.03786

Cumulative Model Updates: 161,960
Cumulative Timesteps: 1,350,507,696

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,012.69896
Policy Entropy: 3.80527
Value Function Loss: 0.02533

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.61582
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 20,172.49617
Overall Steps per Second: 9,957.27378

Timestep Collection Time: 2.48070
Timestep Consumption Time: 2.54497
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 5.02567

Cumulative Model Updates: 161,966
Cumulative Timesteps: 1,350,557,738

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1350557738...
Checkpoint 1350557738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,978.37794
Policy Entropy: 3.81657
Value Function Loss: 0.02804

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.62177
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 20,487.74216
Overall Steps per Second: 9,927.15284

Timestep Collection Time: 2.44068
Timestep Consumption Time: 2.59641
PPO Batch Consumption Time: 0.31119
Total Iteration Time: 5.03709

Cumulative Model Updates: 161,972
Cumulative Timesteps: 1,350,607,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,626.87563
Policy Entropy: 3.82265
Value Function Loss: 0.02656

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.61562
Value Function Update Magnitude: 0.61489

Collected Steps per Second: 20,070.37274
Overall Steps per Second: 9,925.66096

Timestep Collection Time: 2.49133
Timestep Consumption Time: 2.54632
PPO Batch Consumption Time: 0.29871
Total Iteration Time: 5.03765

Cumulative Model Updates: 161,978
Cumulative Timesteps: 1,350,657,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1350657744...
Checkpoint 1350657744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.84716
Policy Entropy: 3.78742
Value Function Loss: 0.02454

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.63021

Collected Steps per Second: 18,755.08624
Overall Steps per Second: 9,467.66937

Timestep Collection Time: 2.66626
Timestep Consumption Time: 2.61550
PPO Batch Consumption Time: 0.31357
Total Iteration Time: 5.28176

Cumulative Model Updates: 161,984
Cumulative Timesteps: 1,350,707,750

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.31368
Policy Entropy: 3.74461
Value Function Loss: 0.02311

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.58865

Collected Steps per Second: 19,260.89028
Overall Steps per Second: 9,706.54728

Timestep Collection Time: 2.59760
Timestep Consumption Time: 2.55686
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 5.15446

Cumulative Model Updates: 161,990
Cumulative Timesteps: 1,350,757,782

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1350757782...
Checkpoint 1350757782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,934.18990
Policy Entropy: 3.74285
Value Function Loss: 0.02650

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.53858

Collected Steps per Second: 20,183.35325
Overall Steps per Second: 9,875.27480

Timestep Collection Time: 2.47788
Timestep Consumption Time: 2.58648
PPO Batch Consumption Time: 0.30941
Total Iteration Time: 5.06437

Cumulative Model Updates: 161,996
Cumulative Timesteps: 1,350,807,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,805.68387
Policy Entropy: 3.74598
Value Function Loss: 0.02427

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 19,858.50359
Overall Steps per Second: 9,912.58277

Timestep Collection Time: 2.51801
Timestep Consumption Time: 2.52648
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 5.04450

Cumulative Model Updates: 162,002
Cumulative Timesteps: 1,350,857,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1350857798...
Checkpoint 1350857798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,942.09784
Policy Entropy: 3.76062
Value Function Loss: 0.02766

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.61671

Collected Steps per Second: 20,498.76335
Overall Steps per Second: 9,972.72605

Timestep Collection Time: 2.43985
Timestep Consumption Time: 2.57522
PPO Batch Consumption Time: 0.30769
Total Iteration Time: 5.01508

Cumulative Model Updates: 162,008
Cumulative Timesteps: 1,350,907,812

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,586.43623
Policy Entropy: 3.76896
Value Function Loss: 0.02688

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12308
Policy Update Magnitude: 0.59665
Value Function Update Magnitude: 0.53830

Collected Steps per Second: 19,955.67603
Overall Steps per Second: 9,892.08717

Timestep Collection Time: 2.50736
Timestep Consumption Time: 2.55083
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 5.05818

Cumulative Model Updates: 162,014
Cumulative Timesteps: 1,350,957,848

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1350957848...
Checkpoint 1350957848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.86620
Policy Entropy: 3.77800
Value Function Loss: 0.02795

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.61068
Value Function Update Magnitude: 0.58278

Collected Steps per Second: 20,153.40565
Overall Steps per Second: 9,805.55587

Timestep Collection Time: 2.48236
Timestep Consumption Time: 2.61965
PPO Batch Consumption Time: 0.31413
Total Iteration Time: 5.10201

Cumulative Model Updates: 162,020
Cumulative Timesteps: 1,351,007,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.52045
Policy Entropy: 3.76301
Value Function Loss: 0.02419

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.58212
Value Function Update Magnitude: 0.56259

Collected Steps per Second: 19,972.92793
Overall Steps per Second: 9,921.17215

Timestep Collection Time: 2.50509
Timestep Consumption Time: 2.53806
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 5.04315

Cumulative Model Updates: 162,026
Cumulative Timesteps: 1,351,057,910

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1351057910...
Checkpoint 1351057910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,750.14500
Policy Entropy: 3.75251
Value Function Loss: 0.02642

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12609
Policy Update Magnitude: 0.59351
Value Function Update Magnitude: 0.55159

Collected Steps per Second: 20,181.18526
Overall Steps per Second: 9,880.22962

Timestep Collection Time: 2.47865
Timestep Consumption Time: 2.58419
PPO Batch Consumption Time: 0.30787
Total Iteration Time: 5.06284

Cumulative Model Updates: 162,032
Cumulative Timesteps: 1,351,107,932

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,780.95772
Policy Entropy: 3.77677
Value Function Loss: 0.02805

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.64190
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 19,979.93539
Overall Steps per Second: 9,861.09661

Timestep Collection Time: 2.50371
Timestep Consumption Time: 2.56915
PPO Batch Consumption Time: 0.30353
Total Iteration Time: 5.07286

Cumulative Model Updates: 162,038
Cumulative Timesteps: 1,351,157,956

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1351157956...
Checkpoint 1351157956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,748.20702
Policy Entropy: 3.79253
Value Function Loss: 0.03068

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12665
Policy Update Magnitude: 0.66384
Value Function Update Magnitude: 0.73223

Collected Steps per Second: 20,100.87248
Overall Steps per Second: 9,824.68733

Timestep Collection Time: 2.48835
Timestep Consumption Time: 2.60270
PPO Batch Consumption Time: 0.30537
Total Iteration Time: 5.09105

Cumulative Model Updates: 162,044
Cumulative Timesteps: 1,351,207,974

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,805.66581
Policy Entropy: 3.81382
Value Function Loss: 0.03030

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12255
Policy Update Magnitude: 0.68382
Value Function Update Magnitude: 0.75615

Collected Steps per Second: 19,909.13225
Overall Steps per Second: 9,853.12797

Timestep Collection Time: 2.51282
Timestep Consumption Time: 2.56456
PPO Batch Consumption Time: 0.29995
Total Iteration Time: 5.07737

Cumulative Model Updates: 162,050
Cumulative Timesteps: 1,351,258,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1351258002...
Checkpoint 1351258002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,274.91186
Policy Entropy: 3.80068
Value Function Loss: 0.02888

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.68903
Value Function Update Magnitude: 0.68753

Collected Steps per Second: 20,544.06411
Overall Steps per Second: 10,044.34180

Timestep Collection Time: 2.43506
Timestep Consumption Time: 2.54546
PPO Batch Consumption Time: 0.30893
Total Iteration Time: 4.98052

Cumulative Model Updates: 162,056
Cumulative Timesteps: 1,351,308,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,268.58616
Policy Entropy: 3.79606
Value Function Loss: 0.02667

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.62772
Value Function Update Magnitude: 0.61156

Collected Steps per Second: 19,617.79876
Overall Steps per Second: 9,682.34339

Timestep Collection Time: 2.55034
Timestep Consumption Time: 2.61701
PPO Batch Consumption Time: 0.31827
Total Iteration Time: 5.16734

Cumulative Model Updates: 162,062
Cumulative Timesteps: 1,351,358,060

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1351358060...
Checkpoint 1351358060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326,764.60274
Policy Entropy: 3.78220
Value Function Loss: 0.03025

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.59668
Value Function Update Magnitude: 0.52009

Collected Steps per Second: 20,075.59624
Overall Steps per Second: 9,770.01810

Timestep Collection Time: 2.49079
Timestep Consumption Time: 2.62732
PPO Batch Consumption Time: 0.32020
Total Iteration Time: 5.11811

Cumulative Model Updates: 162,068
Cumulative Timesteps: 1,351,408,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,513.38688
Policy Entropy: 3.77569
Value Function Loss: 0.02736

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.57097
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 19,517.85276
Overall Steps per Second: 9,720.53227

Timestep Collection Time: 2.56247
Timestep Consumption Time: 2.58272
PPO Batch Consumption Time: 0.31349
Total Iteration Time: 5.14519

Cumulative Model Updates: 162,074
Cumulative Timesteps: 1,351,458,078

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1351458078...
Checkpoint 1351458078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,585.25595
Policy Entropy: 3.77300
Value Function Loss: 0.02771

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12398
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.52038

Collected Steps per Second: 20,353.83610
Overall Steps per Second: 9,849.04856

Timestep Collection Time: 2.45880
Timestep Consumption Time: 2.62250
PPO Batch Consumption Time: 0.32420
Total Iteration Time: 5.08130

Cumulative Model Updates: 162,080
Cumulative Timesteps: 1,351,508,124

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,991.76419
Policy Entropy: 3.77742
Value Function Loss: 0.02271

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12020
Policy Update Magnitude: 0.54599
Value Function Update Magnitude: 0.45228

Collected Steps per Second: 19,898.47784
Overall Steps per Second: 9,886.85581

Timestep Collection Time: 2.51456
Timestep Consumption Time: 2.54630
PPO Batch Consumption Time: 0.30797
Total Iteration Time: 5.06086

Cumulative Model Updates: 162,086
Cumulative Timesteps: 1,351,558,160

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1351558160...
Checkpoint 1351558160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,965.38519
Policy Entropy: 3.77553
Value Function Loss: 0.02618

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.52591
Value Function Update Magnitude: 0.48674

Collected Steps per Second: 19,765.30381
Overall Steps per Second: 9,779.10689

Timestep Collection Time: 2.53110
Timestep Consumption Time: 2.58470
PPO Batch Consumption Time: 0.31329
Total Iteration Time: 5.11580

Cumulative Model Updates: 162,092
Cumulative Timesteps: 1,351,608,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,086.44382
Policy Entropy: 3.78902
Value Function Loss: 0.02476

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11609
Policy Update Magnitude: 0.57656
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 19,989.96308
Overall Steps per Second: 9,754.38978

Timestep Collection Time: 2.50356
Timestep Consumption Time: 2.62706
PPO Batch Consumption Time: 0.30842
Total Iteration Time: 5.13061

Cumulative Model Updates: 162,098
Cumulative Timesteps: 1,351,658,234

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1351658234...
Checkpoint 1351658234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.51227
Policy Entropy: 3.79154
Value Function Loss: 0.02909

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.59408
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 20,798.08060
Overall Steps per Second: 9,827.92911

Timestep Collection Time: 2.40484
Timestep Consumption Time: 2.68433
PPO Batch Consumption Time: 0.31825
Total Iteration Time: 5.08917

Cumulative Model Updates: 162,104
Cumulative Timesteps: 1,351,708,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.05909
Policy Entropy: 3.80807
Value Function Loss: 0.02905

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.63738
Value Function Update Magnitude: 0.62636

Collected Steps per Second: 20,649.03516
Overall Steps per Second: 9,823.13678

Timestep Collection Time: 2.42152
Timestep Consumption Time: 2.66871
PPO Batch Consumption Time: 0.31566
Total Iteration Time: 5.09023

Cumulative Model Updates: 162,110
Cumulative Timesteps: 1,351,758,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1351758252...
Checkpoint 1351758252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.42000
Policy Entropy: 3.81894
Value Function Loss: 0.03010

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.60196
Value Function Update Magnitude: 0.60568

Collected Steps per Second: 20,707.34526
Overall Steps per Second: 9,871.78836

Timestep Collection Time: 2.41480
Timestep Consumption Time: 2.65055
PPO Batch Consumption Time: 0.31296
Total Iteration Time: 5.06534

Cumulative Model Updates: 162,116
Cumulative Timesteps: 1,351,808,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,267.77948
Policy Entropy: 3.83513
Value Function Loss: 0.02886

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11845
Policy Update Magnitude: 0.56993
Value Function Update Magnitude: 0.49290

Collected Steps per Second: 20,273.30622
Overall Steps per Second: 9,861.60241

Timestep Collection Time: 2.46728
Timestep Consumption Time: 2.60491
PPO Batch Consumption Time: 0.30201
Total Iteration Time: 5.07220

Cumulative Model Updates: 162,122
Cumulative Timesteps: 1,351,858,276

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1351858276...
Checkpoint 1351858276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,914.52295
Policy Entropy: 3.82682
Value Function Loss: 0.02780

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.53959
Value Function Update Magnitude: 0.55745

Collected Steps per Second: 20,568.62055
Overall Steps per Second: 9,964.49700

Timestep Collection Time: 2.43205
Timestep Consumption Time: 2.58817
PPO Batch Consumption Time: 0.30702
Total Iteration Time: 5.02022

Cumulative Model Updates: 162,128
Cumulative Timesteps: 1,351,908,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.14827
Policy Entropy: 3.82286
Value Function Loss: 0.02579

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12119
Policy Update Magnitude: 0.49331
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 20,549.89835
Overall Steps per Second: 9,814.92663

Timestep Collection Time: 2.43408
Timestep Consumption Time: 2.66224
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 5.09632

Cumulative Model Updates: 162,134
Cumulative Timesteps: 1,351,958,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1351958320...
Checkpoint 1351958320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,801.33566
Policy Entropy: 3.79937
Value Function Loss: 0.02425

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.49104
Value Function Update Magnitude: 0.65547

Collected Steps per Second: 20,939.40543
Overall Steps per Second: 9,927.82572

Timestep Collection Time: 2.38928
Timestep Consumption Time: 2.65010
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 5.03937

Cumulative Model Updates: 162,140
Cumulative Timesteps: 1,352,008,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,247.91707
Policy Entropy: 3.79589
Value Function Loss: 0.02279

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.47670
Value Function Update Magnitude: 0.64597

Collected Steps per Second: 20,595.89483
Overall Steps per Second: 9,981.26011

Timestep Collection Time: 2.42980
Timestep Consumption Time: 2.58399
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 5.01380

Cumulative Model Updates: 162,146
Cumulative Timesteps: 1,352,058,394

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1352058394...
Checkpoint 1352058394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.02310
Policy Entropy: 3.80127
Value Function Loss: 0.02221

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11880
Policy Update Magnitude: 0.46222
Value Function Update Magnitude: 0.64262

Collected Steps per Second: 20,579.23823
Overall Steps per Second: 9,864.19415

Timestep Collection Time: 2.43148
Timestep Consumption Time: 2.64121
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 5.07269

Cumulative Model Updates: 162,152
Cumulative Timesteps: 1,352,108,432

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,080.71326
Policy Entropy: 3.81669
Value Function Loss: 0.02269

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11949
Policy Update Magnitude: 0.45728
Value Function Update Magnitude: 0.68902

Collected Steps per Second: 20,670.40353
Overall Steps per Second: 10,068.04628

Timestep Collection Time: 2.41950
Timestep Consumption Time: 2.54790
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.96740

Cumulative Model Updates: 162,158
Cumulative Timesteps: 1,352,158,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1352158444...
Checkpoint 1352158444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,580.04516
Policy Entropy: 3.82520
Value Function Loss: 0.02405

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.51816
Value Function Update Magnitude: 0.67720

Collected Steps per Second: 20,749.09026
Overall Steps per Second: 10,017.64920

Timestep Collection Time: 2.41167
Timestep Consumption Time: 2.58351
PPO Batch Consumption Time: 0.30458
Total Iteration Time: 4.99518

Cumulative Model Updates: 162,164
Cumulative Timesteps: 1,352,208,484

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.25142
Policy Entropy: 3.82420
Value Function Loss: 0.02462

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11715
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.77323

Collected Steps per Second: 19,528.55718
Overall Steps per Second: 9,872.93228

Timestep Collection Time: 2.56179
Timestep Consumption Time: 2.50540
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 5.06719

Cumulative Model Updates: 162,170
Cumulative Timesteps: 1,352,258,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1352258512...
Checkpoint 1352258512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.62192
Policy Entropy: 3.82900
Value Function Loss: 0.02537

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.56796
Value Function Update Magnitude: 0.81588

Collected Steps per Second: 20,198.49251
Overall Steps per Second: 9,688.99744

Timestep Collection Time: 2.47622
Timestep Consumption Time: 2.68592
PPO Batch Consumption Time: 0.32435
Total Iteration Time: 5.16214

Cumulative Model Updates: 162,176
Cumulative Timesteps: 1,352,308,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.53593
Policy Entropy: 3.81535
Value Function Loss: 0.02531

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12138
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.69943

Collected Steps per Second: 20,104.86380
Overall Steps per Second: 9,174.22577

Timestep Collection Time: 2.48786
Timestep Consumption Time: 2.96416
PPO Batch Consumption Time: 0.36879
Total Iteration Time: 5.45201

Cumulative Model Updates: 162,182
Cumulative Timesteps: 1,352,358,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1352358546...
Checkpoint 1352358546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,828.96982
Policy Entropy: 3.79072
Value Function Loss: 0.02253

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.51854
Value Function Update Magnitude: 0.64372

Collected Steps per Second: 20,158.06701
Overall Steps per Second: 9,941.70078

Timestep Collection Time: 2.48129
Timestep Consumption Time: 2.54984
PPO Batch Consumption Time: 0.30057
Total Iteration Time: 5.03113

Cumulative Model Updates: 162,188
Cumulative Timesteps: 1,352,408,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,348.35565
Policy Entropy: 3.77226
Value Function Loss: 0.02308

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12712
Policy Update Magnitude: 0.50832
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 20,515.76951
Overall Steps per Second: 10,090.33735

Timestep Collection Time: 2.43803
Timestep Consumption Time: 2.51899
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.95702

Cumulative Model Updates: 162,194
Cumulative Timesteps: 1,352,458,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1352458582...
Checkpoint 1352458582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,931.00252
Policy Entropy: 3.77901
Value Function Loss: 0.02534

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.68233

Collected Steps per Second: 20,446.56792
Overall Steps per Second: 9,880.67193

Timestep Collection Time: 2.44735
Timestep Consumption Time: 2.61708
PPO Batch Consumption Time: 0.31377
Total Iteration Time: 5.06443

Cumulative Model Updates: 162,200
Cumulative Timesteps: 1,352,508,622

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,820.17004
Policy Entropy: 3.80816
Value Function Loss: 0.02671

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.53472
Value Function Update Magnitude: 0.63439

Collected Steps per Second: 20,398.55366
Overall Steps per Second: 10,016.64477

Timestep Collection Time: 2.45312
Timestep Consumption Time: 2.54257
PPO Batch Consumption Time: 0.30913
Total Iteration Time: 4.99568

Cumulative Model Updates: 162,206
Cumulative Timesteps: 1,352,558,662

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1352558662...
Checkpoint 1352558662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.56006
Policy Entropy: 3.82201
Value Function Loss: 0.02325

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.52583
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 16,995.97732
Overall Steps per Second: 9,190.84167

Timestep Collection Time: 2.94234
Timestep Consumption Time: 2.49873
PPO Batch Consumption Time: 0.30249
Total Iteration Time: 5.44107

Cumulative Model Updates: 162,212
Cumulative Timesteps: 1,352,608,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.60757
Policy Entropy: 3.81071
Value Function Loss: 0.01985

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.51377
Value Function Update Magnitude: 0.55554

Collected Steps per Second: 19,731.23527
Overall Steps per Second: 9,947.40295

Timestep Collection Time: 2.53567
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 5.02965

Cumulative Model Updates: 162,218
Cumulative Timesteps: 1,352,658,702

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1352658702...
Checkpoint 1352658702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,599.54179
Policy Entropy: 3.76747
Value Function Loss: 0.02211

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.49253
Value Function Update Magnitude: 0.58586

Collected Steps per Second: 19,517.27797
Overall Steps per Second: 9,746.29006

Timestep Collection Time: 2.56204
Timestep Consumption Time: 2.56853
PPO Batch Consumption Time: 0.31442
Total Iteration Time: 5.13057

Cumulative Model Updates: 162,224
Cumulative Timesteps: 1,352,708,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,743.61577
Policy Entropy: 3.76314
Value Function Loss: 0.02328

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.49439
Value Function Update Magnitude: 0.58609

Collected Steps per Second: 19,829.63817
Overall Steps per Second: 9,991.16093

Timestep Collection Time: 2.52168
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 5.00482

Cumulative Model Updates: 162,230
Cumulative Timesteps: 1,352,758,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1352758710...
Checkpoint 1352758710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,758.72952
Policy Entropy: 3.75713
Value Function Loss: 0.02199

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.50898
Value Function Update Magnitude: 0.55472

Collected Steps per Second: 19,067.80670
Overall Steps per Second: 9,732.51669

Timestep Collection Time: 2.62348
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.30257
Total Iteration Time: 5.13988

Cumulative Model Updates: 162,236
Cumulative Timesteps: 1,352,808,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,235.13899
Policy Entropy: 3.76338
Value Function Loss: 0.01797

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.47647
Value Function Update Magnitude: 0.49022

Collected Steps per Second: 19,961.62179
Overall Steps per Second: 9,865.42728

Timestep Collection Time: 2.50481
Timestep Consumption Time: 2.56340
PPO Batch Consumption Time: 0.31275
Total Iteration Time: 5.06820

Cumulative Model Updates: 162,242
Cumulative Timesteps: 1,352,858,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1352858734...
Checkpoint 1352858734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,085.03375
Policy Entropy: 3.75443
Value Function Loss: 0.01697

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.44435
Value Function Update Magnitude: 0.44096

Collected Steps per Second: 19,190.02447
Overall Steps per Second: 9,749.43333

Timestep Collection Time: 2.60708
Timestep Consumption Time: 2.52450
PPO Batch Consumption Time: 0.30456
Total Iteration Time: 5.13158

Cumulative Model Updates: 162,248
Cumulative Timesteps: 1,352,908,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,273.15249
Policy Entropy: 3.75837
Value Function Loss: 0.01844

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.44927
Value Function Update Magnitude: 0.39299

Collected Steps per Second: 20,036.97297
Overall Steps per Second: 9,984.18505

Timestep Collection Time: 2.49599
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.30035
Total Iteration Time: 5.00912

Cumulative Model Updates: 162,254
Cumulative Timesteps: 1,352,958,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1352958776...
Checkpoint 1352958776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,037.28247
Policy Entropy: 3.77842
Value Function Loss: 0.01759

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.45340
Value Function Update Magnitude: 0.37609

Collected Steps per Second: 19,765.20201
Overall Steps per Second: 9,770.88110

Timestep Collection Time: 2.53142
Timestep Consumption Time: 2.58931
PPO Batch Consumption Time: 0.31358
Total Iteration Time: 5.12073

Cumulative Model Updates: 162,260
Cumulative Timesteps: 1,353,008,810

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307,524.60307
Policy Entropy: 3.77310
Value Function Loss: 0.01845

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.42878
Value Function Update Magnitude: 0.37507

Collected Steps per Second: 20,347.42887
Overall Steps per Second: 9,933.38533

Timestep Collection Time: 2.45898
Timestep Consumption Time: 2.57797
PPO Batch Consumption Time: 0.31226
Total Iteration Time: 5.03695

Cumulative Model Updates: 162,266
Cumulative Timesteps: 1,353,058,844

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1353058844...
Checkpoint 1353058844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,767.33977
Policy Entropy: 3.78118
Value Function Loss: 0.01689

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.46497
Value Function Update Magnitude: 0.38483

Collected Steps per Second: 20,310.28583
Overall Steps per Second: 9,798.06883

Timestep Collection Time: 2.46220
Timestep Consumption Time: 2.64166
PPO Batch Consumption Time: 0.31275
Total Iteration Time: 5.10386

Cumulative Model Updates: 162,272
Cumulative Timesteps: 1,353,108,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,161.11222
Policy Entropy: 3.75821
Value Function Loss: 0.02029

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.48893
Value Function Update Magnitude: 0.42999

Collected Steps per Second: 20,231.70497
Overall Steps per Second: 9,783.99916

Timestep Collection Time: 2.47176
Timestep Consumption Time: 2.63944
PPO Batch Consumption Time: 0.32177
Total Iteration Time: 5.11120

Cumulative Model Updates: 162,278
Cumulative Timesteps: 1,353,158,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1353158860...
Checkpoint 1353158860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,284.86018
Policy Entropy: 3.76892
Value Function Loss: 0.01994

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.49011
Value Function Update Magnitude: 0.44753

Collected Steps per Second: 19,719.11051
Overall Steps per Second: 9,769.43039

Timestep Collection Time: 2.53632
Timestep Consumption Time: 2.58312
PPO Batch Consumption Time: 0.31366
Total Iteration Time: 5.11944

Cumulative Model Updates: 162,284
Cumulative Timesteps: 1,353,208,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,518.79656
Policy Entropy: 3.75314
Value Function Loss: 0.02040

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12377
Policy Update Magnitude: 0.52205
Value Function Update Magnitude: 0.43744

Collected Steps per Second: 20,118.79412
Overall Steps per Second: 9,841.33663

Timestep Collection Time: 2.48613
Timestep Consumption Time: 2.59631
PPO Batch Consumption Time: 0.31873
Total Iteration Time: 5.08244

Cumulative Model Updates: 162,290
Cumulative Timesteps: 1,353,258,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1353258892...
Checkpoint 1353258892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,608.99353
Policy Entropy: 3.75409
Value Function Loss: 0.02123

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.52720
Value Function Update Magnitude: 0.47999

Collected Steps per Second: 20,070.40735
Overall Steps per Second: 9,650.25626

Timestep Collection Time: 2.49193
Timestep Consumption Time: 2.69073
PPO Batch Consumption Time: 0.31365
Total Iteration Time: 5.18266

Cumulative Model Updates: 162,296
Cumulative Timesteps: 1,353,308,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,334.30873
Policy Entropy: 3.74334
Value Function Loss: 0.02286

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.54068
Value Function Update Magnitude: 0.51417

Collected Steps per Second: 20,880.69125
Overall Steps per Second: 9,900.21480

Timestep Collection Time: 2.39532
Timestep Consumption Time: 2.65669
PPO Batch Consumption Time: 0.31326
Total Iteration Time: 5.05201

Cumulative Model Updates: 162,302
Cumulative Timesteps: 1,353,358,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1353358922...
Checkpoint 1353358922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,119.41614
Policy Entropy: 3.74130
Value Function Loss: 0.02250

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13986
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.52164

Collected Steps per Second: 19,856.10535
Overall Steps per Second: 9,584.09040

Timestep Collection Time: 2.51943
Timestep Consumption Time: 2.70027
PPO Batch Consumption Time: 0.32132
Total Iteration Time: 5.21969

Cumulative Model Updates: 162,308
Cumulative Timesteps: 1,353,408,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,647.71107
Policy Entropy: 3.73559
Value Function Loss: 0.02138

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.42021

Collected Steps per Second: 20,235.67563
Overall Steps per Second: 9,884.68278

Timestep Collection Time: 2.47187
Timestep Consumption Time: 2.58848
PPO Batch Consumption Time: 0.31426
Total Iteration Time: 5.06035

Cumulative Model Updates: 162,314
Cumulative Timesteps: 1,353,458,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1353458968...
Checkpoint 1353458968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,716.20451
Policy Entropy: 3.73366
Value Function Loss: 0.02219

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.37087

Collected Steps per Second: 19,461.49023
Overall Steps per Second: 9,722.49989

Timestep Collection Time: 2.57082
Timestep Consumption Time: 2.57518
PPO Batch Consumption Time: 0.31227
Total Iteration Time: 5.14600

Cumulative Model Updates: 162,320
Cumulative Timesteps: 1,353,509,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,088.15085
Policy Entropy: 3.74658
Value Function Loss: 0.02142

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.13884
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.34708

Collected Steps per Second: 20,427.99037
Overall Steps per Second: 10,114.51298

Timestep Collection Time: 2.44831
Timestep Consumption Time: 2.49647
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 4.94478

Cumulative Model Updates: 162,326
Cumulative Timesteps: 1,353,559,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1353559014...
Checkpoint 1353559014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,612.01437
Policy Entropy: 3.75923
Value Function Loss: 0.02214

Mean KL Divergence: 0.02127
SB3 Clip Fraction: 0.22287
Policy Update Magnitude: 0.53385
Value Function Update Magnitude: 0.33298

Collected Steps per Second: 19,138.45053
Overall Steps per Second: 9,607.77968

Timestep Collection Time: 2.61286
Timestep Consumption Time: 2.59189
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 5.20474

Cumulative Model Updates: 162,332
Cumulative Timesteps: 1,353,609,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,165.44542
Policy Entropy: 3.77132
Value Function Loss: 0.02401

Mean KL Divergence: 0.02396
SB3 Clip Fraction: 0.25195
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.35660

Collected Steps per Second: 18,859.36080
Overall Steps per Second: 9,676.79534

Timestep Collection Time: 2.65248
Timestep Consumption Time: 2.51700
PPO Batch Consumption Time: 0.30034
Total Iteration Time: 5.16948

Cumulative Model Updates: 162,338
Cumulative Timesteps: 1,353,659,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1353659044...
Checkpoint 1353659044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,947.76328
Policy Entropy: 3.79772
Value Function Loss: 0.02483

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.15801
Policy Update Magnitude: 0.71071
Value Function Update Magnitude: 0.49681

Collected Steps per Second: 18,460.77195
Overall Steps per Second: 9,564.75762

Timestep Collection Time: 2.70877
Timestep Consumption Time: 2.51938
PPO Batch Consumption Time: 0.30342
Total Iteration Time: 5.22815

Cumulative Model Updates: 162,344
Cumulative Timesteps: 1,353,709,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 226,752.67316
Policy Entropy: 3.80498
Value Function Loss: 0.02791

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.84107
Value Function Update Magnitude: 0.52174

Collected Steps per Second: 18,772.00395
Overall Steps per Second: 9,509.24158

Timestep Collection Time: 2.66461
Timestep Consumption Time: 2.59554
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 5.26015

Cumulative Model Updates: 162,350
Cumulative Timesteps: 1,353,759,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1353759070...
Checkpoint 1353759070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,045.37300
Policy Entropy: 3.80615
Value Function Loss: 0.03152

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.88850
Value Function Update Magnitude: 0.50728

Collected Steps per Second: 19,011.93876
Overall Steps per Second: 9,569.26850

Timestep Collection Time: 2.63056
Timestep Consumption Time: 2.59576
PPO Batch Consumption Time: 0.30926
Total Iteration Time: 5.22631

Cumulative Model Updates: 162,356
Cumulative Timesteps: 1,353,809,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,714.88504
Policy Entropy: 3.78674
Value Function Loss: 0.03099

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.90427
Value Function Update Magnitude: 0.53911

Collected Steps per Second: 20,008.54491
Overall Steps per Second: 9,853.39348

Timestep Collection Time: 2.49903
Timestep Consumption Time: 2.57556
PPO Batch Consumption Time: 0.29997
Total Iteration Time: 5.07460

Cumulative Model Updates: 162,362
Cumulative Timesteps: 1,353,859,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1353859084...
Checkpoint 1353859084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,264.21977
Policy Entropy: 3.78454
Value Function Loss: 0.02673

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.91127
Value Function Update Magnitude: 0.63276

Collected Steps per Second: 19,846.78567
Overall Steps per Second: 9,946.24790

Timestep Collection Time: 2.51980
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 5.02803

Cumulative Model Updates: 162,368
Cumulative Timesteps: 1,353,909,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,413.90076
Policy Entropy: 3.80114
Value Function Loss: 0.02282

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.84892
Value Function Update Magnitude: 0.67422

Collected Steps per Second: 20,723.67834
Overall Steps per Second: 10,014.92329

Timestep Collection Time: 2.41395
Timestep Consumption Time: 2.58119
PPO Batch Consumption Time: 0.31440
Total Iteration Time: 4.99515

Cumulative Model Updates: 162,374
Cumulative Timesteps: 1,353,959,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1353959120...
Checkpoint 1353959120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,141.67609
Policy Entropy: 3.81609
Value Function Loss: 0.02345

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.68248
Value Function Update Magnitude: 0.64111

Collected Steps per Second: 19,706.79523
Overall Steps per Second: 9,879.08413

Timestep Collection Time: 2.53801
Timestep Consumption Time: 2.52481
PPO Batch Consumption Time: 0.30967
Total Iteration Time: 5.06282

Cumulative Model Updates: 162,380
Cumulative Timesteps: 1,354,009,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.92048
Policy Entropy: 3.81120
Value Function Loss: 0.02319

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14666
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.60350

Collected Steps per Second: 20,189.96844
Overall Steps per Second: 9,963.66572

Timestep Collection Time: 2.47786
Timestep Consumption Time: 2.54318
PPO Batch Consumption Time: 0.30724
Total Iteration Time: 5.02104

Cumulative Model Updates: 162,386
Cumulative Timesteps: 1,354,059,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1354059164...
Checkpoint 1354059164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,414.71877
Policy Entropy: 3.81331
Value Function Loss: 0.02558

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.52659
Value Function Update Magnitude: 0.56476

Collected Steps per Second: 19,495.64159
Overall Steps per Second: 9,879.18316

Timestep Collection Time: 2.56539
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.30236
Total Iteration Time: 5.06256

Cumulative Model Updates: 162,392
Cumulative Timesteps: 1,354,109,178

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,430.11704
Policy Entropy: 3.81281
Value Function Loss: 0.02668

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.66385

Collected Steps per Second: 20,290.97582
Overall Steps per Second: 9,973.95017

Timestep Collection Time: 2.46445
Timestep Consumption Time: 2.54922
PPO Batch Consumption Time: 0.30848
Total Iteration Time: 5.01366

Cumulative Model Updates: 162,398
Cumulative Timesteps: 1,354,159,184

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1354159184...
Checkpoint 1354159184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,346.92733
Policy Entropy: 3.83616
Value Function Loss: 0.02868

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.54958
Value Function Update Magnitude: 0.61330

Collected Steps per Second: 20,276.97459
Overall Steps per Second: 9,857.00134

Timestep Collection Time: 2.46644
Timestep Consumption Time: 2.60731
PPO Batch Consumption Time: 0.30867
Total Iteration Time: 5.07375

Cumulative Model Updates: 162,404
Cumulative Timesteps: 1,354,209,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.92925
Policy Entropy: 3.82713
Value Function Loss: 0.03011

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.59571

Collected Steps per Second: 20,632.98417
Overall Steps per Second: 9,970.45770

Timestep Collection Time: 2.42350
Timestep Consumption Time: 2.59172
PPO Batch Consumption Time: 0.30200
Total Iteration Time: 5.01522

Cumulative Model Updates: 162,410
Cumulative Timesteps: 1,354,259,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1354259200...
Checkpoint 1354259200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,018.61780
Policy Entropy: 3.82715
Value Function Loss: 0.03226

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.58654

Collected Steps per Second: 20,216.98012
Overall Steps per Second: 9,846.99714

Timestep Collection Time: 2.47436
Timestep Consumption Time: 2.60577
PPO Batch Consumption Time: 0.30763
Total Iteration Time: 5.08013

Cumulative Model Updates: 162,416
Cumulative Timesteps: 1,354,309,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,854.67841
Policy Entropy: 3.83253
Value Function Loss: 0.02978

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11615
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.59195

Collected Steps per Second: 20,591.30023
Overall Steps per Second: 9,932.67886

Timestep Collection Time: 2.42976
Timestep Consumption Time: 2.60735
PPO Batch Consumption Time: 0.30295
Total Iteration Time: 5.03711

Cumulative Model Updates: 162,422
Cumulative Timesteps: 1,354,359,256

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1354359256...
Checkpoint 1354359256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.01176
Policy Entropy: 3.82799
Value Function Loss: 0.02837

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11021
Policy Update Magnitude: 0.51773
Value Function Update Magnitude: 0.59924

Collected Steps per Second: 19,714.56111
Overall Steps per Second: 9,776.46999

Timestep Collection Time: 2.53883
Timestep Consumption Time: 2.58081
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 5.11964

Cumulative Model Updates: 162,428
Cumulative Timesteps: 1,354,409,308

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,863.94830
Policy Entropy: 3.83118
Value Function Loss: 0.02432

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.45881
Value Function Update Magnitude: 0.55048

Collected Steps per Second: 20,645.55311
Overall Steps per Second: 9,877.80773

Timestep Collection Time: 2.42377
Timestep Consumption Time: 2.64213
PPO Batch Consumption Time: 0.31010
Total Iteration Time: 5.06590

Cumulative Model Updates: 162,434
Cumulative Timesteps: 1,354,459,348

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1354459348...
Checkpoint 1354459348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.59467
Policy Entropy: 3.79686
Value Function Loss: 0.02333

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12686
Policy Update Magnitude: 0.40723
Value Function Update Magnitude: 0.47910

Collected Steps per Second: 19,941.13298
Overall Steps per Second: 9,774.10595

Timestep Collection Time: 2.50738
Timestep Consumption Time: 2.60818
PPO Batch Consumption Time: 0.30863
Total Iteration Time: 5.11556

Cumulative Model Updates: 162,440
Cumulative Timesteps: 1,354,509,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,501.39001
Policy Entropy: 3.79547
Value Function Loss: 0.02281

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11999
Policy Update Magnitude: 0.38871
Value Function Update Magnitude: 0.39126

Collected Steps per Second: 20,522.93997
Overall Steps per Second: 9,899.23452

Timestep Collection Time: 2.43795
Timestep Consumption Time: 2.61638
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 5.05433

Cumulative Model Updates: 162,446
Cumulative Timesteps: 1,354,559,382

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1354559382...
Checkpoint 1354559382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,299.25969
Policy Entropy: 3.79871
Value Function Loss: 0.02240

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.42528
Value Function Update Magnitude: 0.40797

Collected Steps per Second: 20,325.12643
Overall Steps per Second: 9,819.96502

Timestep Collection Time: 2.46070
Timestep Consumption Time: 2.63240
PPO Batch Consumption Time: 0.30970
Total Iteration Time: 5.09309

Cumulative Model Updates: 162,452
Cumulative Timesteps: 1,354,609,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,439.57996
Policy Entropy: 3.79838
Value Function Loss: 0.02351

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.45584
Value Function Update Magnitude: 0.43182

Collected Steps per Second: 20,969.88903
Overall Steps per Second: 9,916.29101

Timestep Collection Time: 2.38447
Timestep Consumption Time: 2.65794
PPO Batch Consumption Time: 0.31136
Total Iteration Time: 5.04241

Cumulative Model Updates: 162,458
Cumulative Timesteps: 1,354,659,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1354659398...
Checkpoint 1354659398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,171.86938
Policy Entropy: 3.79111
Value Function Loss: 0.02247

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.45051
Value Function Update Magnitude: 0.51006

Collected Steps per Second: 20,607.91070
Overall Steps per Second: 9,884.90380

Timestep Collection Time: 2.42635
Timestep Consumption Time: 2.63207
PPO Batch Consumption Time: 0.30916
Total Iteration Time: 5.05842

Cumulative Model Updates: 162,464
Cumulative Timesteps: 1,354,709,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,829.08973
Policy Entropy: 3.78880
Value Function Loss: 0.02320

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.44833
Value Function Update Magnitude: 0.52278

Collected Steps per Second: 20,793.43838
Overall Steps per Second: 9,843.15820

Timestep Collection Time: 2.40653
Timestep Consumption Time: 2.67721
PPO Batch Consumption Time: 0.31575
Total Iteration Time: 5.08373

Cumulative Model Updates: 162,470
Cumulative Timesteps: 1,354,759,440

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1354759440...
Checkpoint 1354759440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,529.21774
Policy Entropy: 3.78497
Value Function Loss: 0.02149

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12135
Policy Update Magnitude: 0.45014
Value Function Update Magnitude: 0.48811

Collected Steps per Second: 19,741.28354
Overall Steps per Second: 9,301.81912

Timestep Collection Time: 2.53489
Timestep Consumption Time: 2.84492
PPO Batch Consumption Time: 0.33302
Total Iteration Time: 5.37981

Cumulative Model Updates: 162,476
Cumulative Timesteps: 1,354,809,482

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,940.56686
Policy Entropy: 3.77932
Value Function Loss: 0.02365

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.47921
Value Function Update Magnitude: 0.47282

Collected Steps per Second: 16,517.55680
Overall Steps per Second: 8,257.00884

Timestep Collection Time: 3.02902
Timestep Consumption Time: 3.03032
PPO Batch Consumption Time: 0.36880
Total Iteration Time: 6.05934

Cumulative Model Updates: 162,482
Cumulative Timesteps: 1,354,859,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1354859514...
Checkpoint 1354859514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,582.99176
Policy Entropy: 3.78528
Value Function Loss: 0.02354

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12205
Policy Update Magnitude: 0.50217
Value Function Update Magnitude: 0.60856

Collected Steps per Second: 18,910.89046
Overall Steps per Second: 9,446.42660

Timestep Collection Time: 2.64461
Timestep Consumption Time: 2.64966
PPO Batch Consumption Time: 0.30589
Total Iteration Time: 5.29428

Cumulative Model Updates: 162,488
Cumulative Timesteps: 1,354,909,526

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.87567
Policy Entropy: 3.78337
Value Function Loss: 0.02379

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11812
Policy Update Magnitude: 0.51269
Value Function Update Magnitude: 0.67422

Collected Steps per Second: 20,298.24219
Overall Steps per Second: 9,839.48656

Timestep Collection Time: 2.46396
Timestep Consumption Time: 2.61903
PPO Batch Consumption Time: 0.30672
Total Iteration Time: 5.08299

Cumulative Model Updates: 162,494
Cumulative Timesteps: 1,354,959,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1354959540...
Checkpoint 1354959540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.22579
Policy Entropy: 3.78566
Value Function Loss: 0.02211

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.50332
Value Function Update Magnitude: 0.60463

Collected Steps per Second: 21,060.70430
Overall Steps per Second: 10,134.91652

Timestep Collection Time: 2.37447
Timestep Consumption Time: 2.55976
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.93423

Cumulative Model Updates: 162,500
Cumulative Timesteps: 1,355,009,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,985.99983
Policy Entropy: 3.76465
Value Function Loss: 0.02494

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.49136
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 20,244.95243
Overall Steps per Second: 9,803.63094

Timestep Collection Time: 2.46995
Timestep Consumption Time: 2.63061
PPO Batch Consumption Time: 0.31338
Total Iteration Time: 5.10056

Cumulative Model Updates: 162,506
Cumulative Timesteps: 1,355,059,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1355059552...
Checkpoint 1355059552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 247,390.56338
Policy Entropy: 3.78790
Value Function Loss: 0.02715

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.49457
Value Function Update Magnitude: 0.62280

Collected Steps per Second: 20,217.49550
Overall Steps per Second: 9,932.69232

Timestep Collection Time: 2.47419
Timestep Consumption Time: 2.56190
PPO Batch Consumption Time: 0.30523
Total Iteration Time: 5.03610

Cumulative Model Updates: 162,512
Cumulative Timesteps: 1,355,109,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,481.71265
Policy Entropy: 3.78284
Value Function Loss: 0.02889

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.49798
Value Function Update Magnitude: 0.62095

Collected Steps per Second: 18,992.11698
Overall Steps per Second: 9,488.74627

Timestep Collection Time: 2.63372
Timestep Consumption Time: 2.63778
PPO Batch Consumption Time: 0.31523
Total Iteration Time: 5.27151

Cumulative Model Updates: 162,518
Cumulative Timesteps: 1,355,159,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1355159594...
Checkpoint 1355159594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,938.72947
Policy Entropy: 3.79162
Value Function Loss: 0.02546

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11925
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.59423

Collected Steps per Second: 20,464.26338
Overall Steps per Second: 9,991.73928

Timestep Collection Time: 2.44377
Timestep Consumption Time: 2.56136
PPO Batch Consumption Time: 0.30383
Total Iteration Time: 5.00513

Cumulative Model Updates: 162,524
Cumulative Timesteps: 1,355,209,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,699.32309
Policy Entropy: 3.77736
Value Function Loss: 0.02464

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11972
Policy Update Magnitude: 0.48084
Value Function Update Magnitude: 0.56497

Collected Steps per Second: 20,186.54523
Overall Steps per Second: 9,783.73400

Timestep Collection Time: 2.47908
Timestep Consumption Time: 2.63594
PPO Batch Consumption Time: 0.30970
Total Iteration Time: 5.11502

Cumulative Model Updates: 162,530
Cumulative Timesteps: 1,355,259,648

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1355259648...
Checkpoint 1355259648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,344.39759
Policy Entropy: 3.79106
Value Function Loss: 0.02267

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.52526

Collected Steps per Second: 20,616.17242
Overall Steps per Second: 10,021.77100

Timestep Collection Time: 2.42654
Timestep Consumption Time: 2.56519
PPO Batch Consumption Time: 0.30734
Total Iteration Time: 4.99173

Cumulative Model Updates: 162,536
Cumulative Timesteps: 1,355,309,674

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,841.12231
Policy Entropy: 3.77861
Value Function Loss: 0.02146

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11472
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.54158

Collected Steps per Second: 20,297.71003
Overall Steps per Second: 9,908.64259

Timestep Collection Time: 2.46432
Timestep Consumption Time: 2.58380
PPO Batch Consumption Time: 0.30608
Total Iteration Time: 5.04812

Cumulative Model Updates: 162,542
Cumulative Timesteps: 1,355,359,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1355359694...
Checkpoint 1355359694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,467.20051
Policy Entropy: 3.79866
Value Function Loss: 0.01837

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.49463
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 20,636.56167
Overall Steps per Second: 10,071.12399

Timestep Collection Time: 2.42327
Timestep Consumption Time: 2.54221
PPO Batch Consumption Time: 0.29912
Total Iteration Time: 4.96548

Cumulative Model Updates: 162,548
Cumulative Timesteps: 1,355,409,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,104.49341
Policy Entropy: 3.78037
Value Function Loss: 0.02336

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.59664

Collected Steps per Second: 20,366.30682
Overall Steps per Second: 9,989.95751

Timestep Collection Time: 2.45553
Timestep Consumption Time: 2.55050
PPO Batch Consumption Time: 0.30162
Total Iteration Time: 5.00603

Cumulative Model Updates: 162,554
Cumulative Timesteps: 1,355,459,712

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1355459712...
Checkpoint 1355459712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,660.07015
Policy Entropy: 3.78689
Value Function Loss: 0.02779

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.59994
Value Function Update Magnitude: 0.58015

Collected Steps per Second: 20,555.82767
Overall Steps per Second: 9,966.30136

Timestep Collection Time: 2.43318
Timestep Consumption Time: 2.58533
PPO Batch Consumption Time: 0.30861
Total Iteration Time: 5.01851

Cumulative Model Updates: 162,560
Cumulative Timesteps: 1,355,509,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,954.65983
Policy Entropy: 3.76376
Value Function Loss: 0.02889

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14571
Policy Update Magnitude: 0.65465
Value Function Update Magnitude: 0.58208

Collected Steps per Second: 20,522.32218
Overall Steps per Second: 10,003.68896

Timestep Collection Time: 2.43822
Timestep Consumption Time: 2.56373
PPO Batch Consumption Time: 0.29988
Total Iteration Time: 5.00195

Cumulative Model Updates: 162,566
Cumulative Timesteps: 1,355,559,766

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1355559766...
Checkpoint 1355559766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,612.84275
Policy Entropy: 3.77031
Value Function Loss: 0.02684

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.62117
Value Function Update Magnitude: 0.54738

Collected Steps per Second: 20,594.71619
Overall Steps per Second: 9,915.86645

Timestep Collection Time: 2.42790
Timestep Consumption Time: 2.61472
PPO Batch Consumption Time: 0.31349
Total Iteration Time: 5.04263

Cumulative Model Updates: 162,572
Cumulative Timesteps: 1,355,609,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,421.55414
Policy Entropy: 3.75947
Value Function Loss: 0.02266

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13429
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.49716

Collected Steps per Second: 19,722.35739
Overall Steps per Second: 9,673.03134

Timestep Collection Time: 2.53530
Timestep Consumption Time: 2.63392
PPO Batch Consumption Time: 0.30931
Total Iteration Time: 5.16922

Cumulative Model Updates: 162,578
Cumulative Timesteps: 1,355,659,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1355659770...
Checkpoint 1355659770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,012.78140
Policy Entropy: 3.76691
Value Function Loss: 0.02061

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.57458
Value Function Update Magnitude: 0.48456

Collected Steps per Second: 20,465.11795
Overall Steps per Second: 10,066.90240

Timestep Collection Time: 2.44455
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29801
Total Iteration Time: 4.96955

Cumulative Model Updates: 162,584
Cumulative Timesteps: 1,355,709,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,711.13942
Policy Entropy: 3.79021
Value Function Loss: 0.02067

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.52660
Value Function Update Magnitude: 0.53362

Collected Steps per Second: 20,395.84306
Overall Steps per Second: 9,997.96448

Timestep Collection Time: 2.45324
Timestep Consumption Time: 2.55137
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 5.00462

Cumulative Model Updates: 162,590
Cumulative Timesteps: 1,355,759,834

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1355759834...
Checkpoint 1355759834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,741.31811
Policy Entropy: 3.82002
Value Function Loss: 0.01967

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.61345
Value Function Update Magnitude: 0.56502

Collected Steps per Second: 20,554.50491
Overall Steps per Second: 9,951.27456

Timestep Collection Time: 2.43402
Timestep Consumption Time: 2.59348
PPO Batch Consumption Time: 0.31041
Total Iteration Time: 5.02750

Cumulative Model Updates: 162,596
Cumulative Timesteps: 1,355,809,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,930.12663
Policy Entropy: 3.80923
Value Function Loss: 0.02021

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05543
Policy Update Magnitude: 0.68042
Value Function Update Magnitude: 0.67400

Collected Steps per Second: 20,172.60442
Overall Steps per Second: 9,968.11300

Timestep Collection Time: 2.47960
Timestep Consumption Time: 2.53840
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 5.01800

Cumulative Model Updates: 162,602
Cumulative Timesteps: 1,355,859,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1355859884...
Checkpoint 1355859884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 100,220.65420
Policy Entropy: 3.80172
Value Function Loss: 0.01815

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05392
Policy Update Magnitude: 0.65837
Value Function Update Magnitude: 0.64023

Collected Steps per Second: 20,702.87417
Overall Steps per Second: 10,064.04395

Timestep Collection Time: 2.41512
Timestep Consumption Time: 2.55306
PPO Batch Consumption Time: 0.30185
Total Iteration Time: 4.96818

Cumulative Model Updates: 162,608
Cumulative Timesteps: 1,355,909,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,160.95576
Policy Entropy: 3.78040
Value Function Loss: 0.01810

Mean KL Divergence: 0.01835
SB3 Clip Fraction: 0.22094
Policy Update Magnitude: 0.52053
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 20,107.39002
Overall Steps per Second: 9,812.33315

Timestep Collection Time: 2.48764
Timestep Consumption Time: 2.61002
PPO Batch Consumption Time: 0.31055
Total Iteration Time: 5.09767

Cumulative Model Updates: 162,614
Cumulative Timesteps: 1,355,959,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1355959904...
Checkpoint 1355959904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,622.49126
Policy Entropy: 3.79562
Value Function Loss: 0.03625

Mean KL Divergence: 0.02288
SB3 Clip Fraction: 0.22727
Policy Update Magnitude: 0.50181
Value Function Update Magnitude: 0.54511

Collected Steps per Second: 20,356.74129
Overall Steps per Second: 9,900.67158

Timestep Collection Time: 2.45825
Timestep Consumption Time: 2.59615
PPO Batch Consumption Time: 0.30956
Total Iteration Time: 5.05440

Cumulative Model Updates: 162,620
Cumulative Timesteps: 1,356,009,946

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,861.04890
Policy Entropy: 3.89512
Value Function Loss: 0.05804

Mean KL Divergence: 0.02223
SB3 Clip Fraction: 0.20786
Policy Update Magnitude: 0.70564
Value Function Update Magnitude: 0.54328

Collected Steps per Second: 20,049.14882
Overall Steps per Second: 9,940.29506

Timestep Collection Time: 2.49577
Timestep Consumption Time: 2.53809
PPO Batch Consumption Time: 0.30689
Total Iteration Time: 5.03385

Cumulative Model Updates: 162,626
Cumulative Timesteps: 1,356,059,984

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1356059984...
Checkpoint 1356059984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209.27129
Policy Entropy: 3.99981
Value Function Loss: 0.05600

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.13091
Policy Update Magnitude: 0.92249
Value Function Update Magnitude: 0.50231

Collected Steps per Second: 20,068.61652
Overall Steps per Second: 9,756.35463

Timestep Collection Time: 2.49255
Timestep Consumption Time: 2.63457
PPO Batch Consumption Time: 0.31110
Total Iteration Time: 5.12712

Cumulative Model Updates: 162,632
Cumulative Timesteps: 1,356,110,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.00262
Policy Entropy: 4.05797
Value Function Loss: 0.04264

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 1.09226
Value Function Update Magnitude: 0.60121

Collected Steps per Second: 20,401.73432
Overall Steps per Second: 9,896.60087

Timestep Collection Time: 2.45097
Timestep Consumption Time: 2.60168
PPO Batch Consumption Time: 0.30371
Total Iteration Time: 5.05264

Cumulative Model Updates: 162,638
Cumulative Timesteps: 1,356,160,010

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1356160010...
Checkpoint 1356160010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.04274
Policy Entropy: 4.02483
Value Function Loss: 0.04312

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 1.11853
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 20,622.64254
Overall Steps per Second: 9,868.06488

Timestep Collection Time: 2.42578
Timestep Consumption Time: 2.64370
PPO Batch Consumption Time: 0.31723
Total Iteration Time: 5.06948

Cumulative Model Updates: 162,644
Cumulative Timesteps: 1,356,210,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,489.38145
Policy Entropy: 3.95003
Value Function Loss: 0.03695

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.98203
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 20,293.45328
Overall Steps per Second: 9,786.04894

Timestep Collection Time: 2.46572
Timestep Consumption Time: 2.64748
PPO Batch Consumption Time: 0.31703
Total Iteration Time: 5.11320

Cumulative Model Updates: 162,650
Cumulative Timesteps: 1,356,260,074

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1356260074...
Checkpoint 1356260074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,517.41838
Policy Entropy: 3.87672
Value Function Loss: 0.03264

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12099
Policy Update Magnitude: 0.77832
Value Function Update Magnitude: 0.50116

Collected Steps per Second: 21,092.29867
Overall Steps per Second: 10,003.89678

Timestep Collection Time: 2.37110
Timestep Consumption Time: 2.62815
PPO Batch Consumption Time: 0.31368
Total Iteration Time: 4.99925

Cumulative Model Updates: 162,656
Cumulative Timesteps: 1,356,310,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,871.10251
Policy Entropy: 3.81082
Value Function Loss: 0.02550

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14279
Policy Update Magnitude: 0.60841
Value Function Update Magnitude: 0.53148

Collected Steps per Second: 20,535.10697
Overall Steps per Second: 9,790.06263

Timestep Collection Time: 2.43680
Timestep Consumption Time: 2.67450
PPO Batch Consumption Time: 0.32032
Total Iteration Time: 5.11131

Cumulative Model Updates: 162,662
Cumulative Timesteps: 1,356,360,126

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1356360126...
Checkpoint 1356360126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,230.63448
Policy Entropy: 3.79122
Value Function Loss: 0.02661

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.65478

Collected Steps per Second: 20,865.47490
Overall Steps per Second: 9,958.88028

Timestep Collection Time: 2.39649
Timestep Consumption Time: 2.62455
PPO Batch Consumption Time: 0.31385
Total Iteration Time: 5.02105

Cumulative Model Updates: 162,668
Cumulative Timesteps: 1,356,410,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.60390
Policy Entropy: 3.81292
Value Function Loss: 0.02601

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.50947
Value Function Update Magnitude: 0.66735

Collected Steps per Second: 20,342.41506
Overall Steps per Second: 9,846.90188

Timestep Collection Time: 2.45861
Timestep Consumption Time: 2.62055
PPO Batch Consumption Time: 0.32306
Total Iteration Time: 5.07916

Cumulative Model Updates: 162,674
Cumulative Timesteps: 1,356,460,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1356460144...
Checkpoint 1356460144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,067.14657
Policy Entropy: 3.83816
Value Function Loss: 0.02569

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.60602
Value Function Update Magnitude: 0.73226

Collected Steps per Second: 20,475.41652
Overall Steps per Second: 9,975.65514

Timestep Collection Time: 2.44225
Timestep Consumption Time: 2.57056
PPO Batch Consumption Time: 0.31577
Total Iteration Time: 5.01280

Cumulative Model Updates: 162,680
Cumulative Timesteps: 1,356,510,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,684.07095
Policy Entropy: 3.84875
Value Function Loss: 0.02651

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12633
Policy Update Magnitude: 0.56365
Value Function Update Magnitude: 0.74913

Collected Steps per Second: 18,983.73275
Overall Steps per Second: 9,544.87559

Timestep Collection Time: 2.63510
Timestep Consumption Time: 2.60583
PPO Batch Consumption Time: 0.31821
Total Iteration Time: 5.24093

Cumulative Model Updates: 162,686
Cumulative Timesteps: 1,356,560,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1356560174...
Checkpoint 1356560174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,993.76887
Policy Entropy: 3.84984
Value Function Loss: 0.02683

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.15684
Policy Update Magnitude: 0.60701
Value Function Update Magnitude: 0.85056

Collected Steps per Second: 20,058.24606
Overall Steps per Second: 9,732.41671

Timestep Collection Time: 2.49394
Timestep Consumption Time: 2.64600
PPO Batch Consumption Time: 0.32612
Total Iteration Time: 5.13994

Cumulative Model Updates: 162,692
Cumulative Timesteps: 1,356,610,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,200.58064
Policy Entropy: 3.84220
Value Function Loss: 0.02758

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.63908
Value Function Update Magnitude: 0.93011

Collected Steps per Second: 20,651.97826
Overall Steps per Second: 9,889.93538

Timestep Collection Time: 2.42272
Timestep Consumption Time: 2.63636
PPO Batch Consumption Time: 0.31159
Total Iteration Time: 5.05908

Cumulative Model Updates: 162,698
Cumulative Timesteps: 1,356,660,232

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1356660232...
Checkpoint 1356660232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,403.31368
Policy Entropy: 3.85091
Value Function Loss: 0.02735

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.63812
Value Function Update Magnitude: 0.88531

Collected Steps per Second: 20,962.31466
Overall Steps per Second: 9,968.62993

Timestep Collection Time: 2.38752
Timestep Consumption Time: 2.63303
PPO Batch Consumption Time: 0.31100
Total Iteration Time: 5.02055

Cumulative Model Updates: 162,704
Cumulative Timesteps: 1,356,710,280

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,695.25134
Policy Entropy: 3.85420
Value Function Loss: 0.02976

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.62678
Value Function Update Magnitude: 0.76747

Collected Steps per Second: 20,572.26491
Overall Steps per Second: 9,792.96400

Timestep Collection Time: 2.43182
Timestep Consumption Time: 2.67675
PPO Batch Consumption Time: 0.31653
Total Iteration Time: 5.10857

Cumulative Model Updates: 162,710
Cumulative Timesteps: 1,356,760,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1356760308...
Checkpoint 1356760308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,782.07959
Policy Entropy: 3.84458
Value Function Loss: 0.03395

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.66147
Value Function Update Magnitude: 0.77022

Collected Steps per Second: 20,736.23754
Overall Steps per Second: 9,874.71773

Timestep Collection Time: 2.41336
Timestep Consumption Time: 2.65453
PPO Batch Consumption Time: 0.31290
Total Iteration Time: 5.06789

Cumulative Model Updates: 162,716
Cumulative Timesteps: 1,356,810,352

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,442.80110
Policy Entropy: 3.85243
Value Function Loss: 0.03141

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.78380
Value Function Update Magnitude: 0.68446

Collected Steps per Second: 20,361.28247
Overall Steps per Second: 9,882.69263

Timestep Collection Time: 2.45603
Timestep Consumption Time: 2.60413
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 5.06016

Cumulative Model Updates: 162,722
Cumulative Timesteps: 1,356,860,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1356860360...
Checkpoint 1356860360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 230.52593
Policy Entropy: 3.83507
Value Function Loss: 0.02744

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10854
Policy Update Magnitude: 0.72277
Value Function Update Magnitude: 0.59871

Collected Steps per Second: 20,652.63568
Overall Steps per Second: 10,027.79203

Timestep Collection Time: 2.42100
Timestep Consumption Time: 2.56514
PPO Batch Consumption Time: 0.30564
Total Iteration Time: 4.98614

Cumulative Model Updates: 162,728
Cumulative Timesteps: 1,356,910,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.04966
Policy Entropy: 3.83897
Value Function Loss: 0.01994

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.52718
Value Function Update Magnitude: 0.51437

Collected Steps per Second: 20,302.38883
Overall Steps per Second: 9,823.45731

Timestep Collection Time: 2.46483
Timestep Consumption Time: 2.62930
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 5.09413

Cumulative Model Updates: 162,734
Cumulative Timesteps: 1,356,960,402

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1356960402...
Checkpoint 1356960402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24607
Policy Entropy: 3.82851
Value Function Loss: 0.01670

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.41858
Value Function Update Magnitude: 0.46812

Collected Steps per Second: 20,299.25494
Overall Steps per Second: 9,786.37305

Timestep Collection Time: 2.46433
Timestep Consumption Time: 2.64727
PPO Batch Consumption Time: 0.30074
Total Iteration Time: 5.11160

Cumulative Model Updates: 162,740
Cumulative Timesteps: 1,357,010,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.22403
Policy Entropy: 3.80876
Value Function Loss: 0.01749

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15566
Policy Update Magnitude: 0.37992
Value Function Update Magnitude: 0.45945

Collected Steps per Second: 20,357.95860
Overall Steps per Second: 9,880.39356

Timestep Collection Time: 2.45761
Timestep Consumption Time: 2.60615
PPO Batch Consumption Time: 0.30553
Total Iteration Time: 5.06377

Cumulative Model Updates: 162,746
Cumulative Timesteps: 1,357,060,458

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1357060458...
Checkpoint 1357060458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.22403
Policy Entropy: 3.78776
Value Function Loss: 0.01587

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15738
Policy Update Magnitude: 0.37199
Value Function Update Magnitude: 0.41109

Collected Steps per Second: 20,780.08986
Overall Steps per Second: 9,994.58760

Timestep Collection Time: 2.40769
Timestep Consumption Time: 2.59822
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 5.00591

Cumulative Model Updates: 162,752
Cumulative Timesteps: 1,357,110,490

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.22403
Policy Entropy: 3.77806
Value Function Loss: 0.01559

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07603
Policy Update Magnitude: 0.44280
Value Function Update Magnitude: 0.33296

Collected Steps per Second: 20,635.81245
Overall Steps per Second: 10,010.53959

Timestep Collection Time: 2.42346
Timestep Consumption Time: 2.57228
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.99573

Cumulative Model Updates: 162,758
Cumulative Timesteps: 1,357,160,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1357160500...
Checkpoint 1357160500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,740.38646
Policy Entropy: 3.78260
Value Function Loss: 0.01227

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.39038
Value Function Update Magnitude: 0.29011

Collected Steps per Second: 20,455.96342
Overall Steps per Second: 9,851.84713

Timestep Collection Time: 2.44427
Timestep Consumption Time: 2.63092
PPO Batch Consumption Time: 0.31064
Total Iteration Time: 5.07519

Cumulative Model Updates: 162,764
Cumulative Timesteps: 1,357,210,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,740.38646
Policy Entropy: 3.77544
Value Function Loss: 0.01168

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11692
Policy Update Magnitude: 0.30240
Value Function Update Magnitude: 0.28936

Collected Steps per Second: 20,386.69483
Overall Steps per Second: 9,978.79267

Timestep Collection Time: 2.45258
Timestep Consumption Time: 2.55805
PPO Batch Consumption Time: 0.30142
Total Iteration Time: 5.01063

Cumulative Model Updates: 162,770
Cumulative Timesteps: 1,357,260,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1357260500...
Checkpoint 1357260500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,023.95700
Policy Entropy: 3.77923
Value Function Loss: 0.01140

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12918
Policy Update Magnitude: 0.27489
Value Function Update Magnitude: 0.28138

Collected Steps per Second: 18,526.88002
Overall Steps per Second: 9,116.85212

Timestep Collection Time: 2.69932
Timestep Consumption Time: 2.78612
PPO Batch Consumption Time: 0.31992
Total Iteration Time: 5.48545

Cumulative Model Updates: 162,776
Cumulative Timesteps: 1,357,310,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,345.33347
Policy Entropy: 3.79103
Value Function Loss: 0.01123

Mean KL Divergence: 0.02691
SB3 Clip Fraction: 0.28847
Policy Update Magnitude: 0.26867
Value Function Update Magnitude: 0.34171

Collected Steps per Second: 19,036.09401
Overall Steps per Second: 9,699.63524

Timestep Collection Time: 2.62848
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 5.15854

Cumulative Model Updates: 162,782
Cumulative Timesteps: 1,357,360,546

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1357360546...
Checkpoint 1357360546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,508.64141
Policy Entropy: 3.79017
Value Function Loss: 0.02169

Mean KL Divergence: 0.01812
SB3 Clip Fraction: 0.20887
Policy Update Magnitude: 0.32850
Value Function Update Magnitude: 0.51807

Collected Steps per Second: 20,270.55916
Overall Steps per Second: 9,901.68042

Timestep Collection Time: 2.46752
Timestep Consumption Time: 2.58395
PPO Batch Consumption Time: 0.30930
Total Iteration Time: 5.05147

Cumulative Model Updates: 162,788
Cumulative Timesteps: 1,357,410,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,876.95633
Policy Entropy: 3.80908
Value Function Loss: 0.02425

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.16919
Policy Update Magnitude: 0.52621
Value Function Update Magnitude: 0.69409

Collected Steps per Second: 19,329.67474
Overall Steps per Second: 9,475.20216

Timestep Collection Time: 2.58701
Timestep Consumption Time: 2.69056
PPO Batch Consumption Time: 0.32064
Total Iteration Time: 5.27757

Cumulative Model Updates: 162,794
Cumulative Timesteps: 1,357,460,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1357460570...
Checkpoint 1357460570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,029.10566
Policy Entropy: 3.77471
Value Function Loss: 0.02651

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16505
Policy Update Magnitude: 0.58935
Value Function Update Magnitude: 0.69826

Collected Steps per Second: 18,195.72757
Overall Steps per Second: 9,470.86438

Timestep Collection Time: 2.74988
Timestep Consumption Time: 2.53327
PPO Batch Consumption Time: 0.29760
Total Iteration Time: 5.28315

Cumulative Model Updates: 162,800
Cumulative Timesteps: 1,357,510,606

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,074.59000
Policy Entropy: 3.79087
Value Function Loss: 0.02227

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.61461
Value Function Update Magnitude: 0.72344

Collected Steps per Second: 20,377.88173
Overall Steps per Second: 9,934.17121

Timestep Collection Time: 2.45364
Timestep Consumption Time: 2.57949
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 5.03313

Cumulative Model Updates: 162,806
Cumulative Timesteps: 1,357,560,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1357560606...
Checkpoint 1357560606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272.40673
Policy Entropy: 3.78698
Value Function Loss: 0.01889

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.66336
Value Function Update Magnitude: 0.71826

Collected Steps per Second: 18,338.18502
Overall Steps per Second: 9,436.34871

Timestep Collection Time: 2.72764
Timestep Consumption Time: 2.57314
PPO Batch Consumption Time: 0.30424
Total Iteration Time: 5.30078

Cumulative Model Updates: 162,812
Cumulative Timesteps: 1,357,610,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,569.28413
Policy Entropy: 3.80455
Value Function Loss: 0.01931

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.53048
Value Function Update Magnitude: 0.70295

Collected Steps per Second: 19,667.76815
Overall Steps per Second: 9,811.27353

Timestep Collection Time: 2.54315
Timestep Consumption Time: 2.55487
PPO Batch Consumption Time: 0.29717
Total Iteration Time: 5.09801

Cumulative Model Updates: 162,818
Cumulative Timesteps: 1,357,660,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1357660644...
Checkpoint 1357660644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.51906
Policy Entropy: 3.78937
Value Function Loss: 0.01984

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.43593
Value Function Update Magnitude: 0.51965

Collected Steps per Second: 20,186.83928
Overall Steps per Second: 9,784.98300

Timestep Collection Time: 2.47706
Timestep Consumption Time: 2.63322
PPO Batch Consumption Time: 0.31449
Total Iteration Time: 5.11028

Cumulative Model Updates: 162,824
Cumulative Timesteps: 1,357,710,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,542.64266
Policy Entropy: 3.76833
Value Function Loss: 0.02355

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14866
Policy Update Magnitude: 0.41631
Value Function Update Magnitude: 0.42430

Collected Steps per Second: 21,084.03068
Overall Steps per Second: 10,151.14106

Timestep Collection Time: 2.37298
Timestep Consumption Time: 2.55573
PPO Batch Consumption Time: 0.31111
Total Iteration Time: 4.92871

Cumulative Model Updates: 162,830
Cumulative Timesteps: 1,357,760,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1357760680...
Checkpoint 1357760680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,947.08368
Policy Entropy: 3.76839
Value Function Loss: 0.02308

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14357
Policy Update Magnitude: 0.46694
Value Function Update Magnitude: 0.39463

Collected Steps per Second: 19,588.02065
Overall Steps per Second: 9,507.35225

Timestep Collection Time: 2.55503
Timestep Consumption Time: 2.70911
PPO Batch Consumption Time: 0.30942
Total Iteration Time: 5.26414

Cumulative Model Updates: 162,836
Cumulative Timesteps: 1,357,810,728

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,984.87050
Policy Entropy: 3.78986
Value Function Loss: 0.02557

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.47353
Value Function Update Magnitude: 0.44987

Collected Steps per Second: 20,574.41804
Overall Steps per Second: 9,815.29466

Timestep Collection Time: 2.43147
Timestep Consumption Time: 2.66527
PPO Batch Consumption Time: 0.31749
Total Iteration Time: 5.09674

Cumulative Model Updates: 162,842
Cumulative Timesteps: 1,357,860,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1357860754...
Checkpoint 1357860754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,405.99610
Policy Entropy: 3.79220
Value Function Loss: 0.02504

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.48586
Value Function Update Magnitude: 0.53146

Collected Steps per Second: 20,518.19562
Overall Steps per Second: 9,818.47734

Timestep Collection Time: 2.43745
Timestep Consumption Time: 2.65622
PPO Batch Consumption Time: 0.31643
Total Iteration Time: 5.09366

Cumulative Model Updates: 162,848
Cumulative Timesteps: 1,357,910,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,232.64045
Policy Entropy: 3.79431
Value Function Loss: 0.02319

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.48944
Value Function Update Magnitude: 0.54867

Collected Steps per Second: 20,851.68296
Overall Steps per Second: 9,978.81845

Timestep Collection Time: 2.39923
Timestep Consumption Time: 2.61419
PPO Batch Consumption Time: 0.30846
Total Iteration Time: 5.01342

Cumulative Model Updates: 162,854
Cumulative Timesteps: 1,357,960,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1357960794...
Checkpoint 1357960794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,998.21037
Policy Entropy: 3.78594
Value Function Loss: 0.02370

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.11910
Policy Update Magnitude: 0.48732
Value Function Update Magnitude: 0.57453

Collected Steps per Second: 20,315.87971
Overall Steps per Second: 9,704.40381

Timestep Collection Time: 2.46142
Timestep Consumption Time: 2.69149
PPO Batch Consumption Time: 0.32112
Total Iteration Time: 5.15292

Cumulative Model Updates: 162,860
Cumulative Timesteps: 1,358,010,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,470.87457
Policy Entropy: 3.78363
Value Function Loss: 0.02512

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11809
Policy Update Magnitude: 0.51910
Value Function Update Magnitude: 0.72842

Collected Steps per Second: 19,884.31422
Overall Steps per Second: 9,435.26150

Timestep Collection Time: 2.51485
Timestep Consumption Time: 2.78506
PPO Batch Consumption Time: 0.33639
Total Iteration Time: 5.29991

Cumulative Model Updates: 162,866
Cumulative Timesteps: 1,358,060,806

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1358060806...
Checkpoint 1358060806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,300.41216
Policy Entropy: 3.77977
Value Function Loss: 0.02904

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.72732

Collected Steps per Second: 18,971.94692
Overall Steps per Second: 9,704.34486

Timestep Collection Time: 2.63737
Timestep Consumption Time: 2.51867
PPO Batch Consumption Time: 0.30774
Total Iteration Time: 5.15604

Cumulative Model Updates: 162,872
Cumulative Timesteps: 1,358,110,842

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,740.96618
Policy Entropy: 3.76301
Value Function Loss: 0.03130

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.60435
Value Function Update Magnitude: 0.69109

Collected Steps per Second: 20,647.68780
Overall Steps per Second: 9,791.56627

Timestep Collection Time: 2.42303
Timestep Consumption Time: 2.68647
PPO Batch Consumption Time: 0.32212
Total Iteration Time: 5.10950

Cumulative Model Updates: 162,878
Cumulative Timesteps: 1,358,160,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1358160872...
Checkpoint 1358160872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,187.22285
Policy Entropy: 3.74922
Value Function Loss: 0.03018

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.61884
Value Function Update Magnitude: 0.75197

Collected Steps per Second: 19,389.41828
Overall Steps per Second: 9,440.32054

Timestep Collection Time: 2.57904
Timestep Consumption Time: 2.71803
PPO Batch Consumption Time: 0.30754
Total Iteration Time: 5.29707

Cumulative Model Updates: 162,884
Cumulative Timesteps: 1,358,210,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,434.58256
Policy Entropy: 3.74114
Value Function Loss: 0.02962

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.70492

Collected Steps per Second: 20,915.63131
Overall Steps per Second: 10,110.52633

Timestep Collection Time: 2.39151
Timestep Consumption Time: 2.55581
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.94732

Cumulative Model Updates: 162,890
Cumulative Timesteps: 1,358,260,898

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1358260898...
Checkpoint 1358260898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,013.35024
Policy Entropy: 3.75494
Value Function Loss: 0.03028

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.51955

Collected Steps per Second: 20,653.71294
Overall Steps per Second: 9,957.73548

Timestep Collection Time: 2.42136
Timestep Consumption Time: 2.60087
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 5.02223

Cumulative Model Updates: 162,896
Cumulative Timesteps: 1,358,310,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,934.70855
Policy Entropy: 3.75927
Value Function Loss: 0.03200

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.57273
Value Function Update Magnitude: 0.42061

Collected Steps per Second: 17,719.16484
Overall Steps per Second: 9,254.44095

Timestep Collection Time: 2.82271
Timestep Consumption Time: 2.58183
PPO Batch Consumption Time: 0.30056
Total Iteration Time: 5.40454

Cumulative Model Updates: 162,902
Cumulative Timesteps: 1,358,360,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1358360924...
Checkpoint 1358360924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,564.01364
Policy Entropy: 3.77546
Value Function Loss: 0.02937

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.45070

Collected Steps per Second: 20,374.62917
Overall Steps per Second: 9,970.67533

Timestep Collection Time: 2.45452
Timestep Consumption Time: 2.56119
PPO Batch Consumption Time: 0.30198
Total Iteration Time: 5.01571

Cumulative Model Updates: 162,908
Cumulative Timesteps: 1,358,410,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,023.93147
Policy Entropy: 3.78955
Value Function Loss: 0.03148

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.49086

Collected Steps per Second: 20,491.04686
Overall Steps per Second: 10,076.28572

Timestep Collection Time: 2.44087
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.96373

Cumulative Model Updates: 162,914
Cumulative Timesteps: 1,358,460,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1358460950...
Checkpoint 1358460950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,620.60819
Policy Entropy: 3.82582
Value Function Loss: 0.03561

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.51751

Collected Steps per Second: 19,445.98580
Overall Steps per Second: 9,690.62108

Timestep Collection Time: 2.57133
Timestep Consumption Time: 2.58851
PPO Batch Consumption Time: 0.30413
Total Iteration Time: 5.15983

Cumulative Model Updates: 162,920
Cumulative Timesteps: 1,358,510,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401.49373
Policy Entropy: 3.83086
Value Function Loss: 0.03449

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.58497
Value Function Update Magnitude: 0.57964

Collected Steps per Second: 19,266.66502
Overall Steps per Second: 9,827.21125

Timestep Collection Time: 2.59630
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 5.09015

Cumulative Model Updates: 162,926
Cumulative Timesteps: 1,358,560,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1358560974...
Checkpoint 1358560974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,002.88373
Policy Entropy: 3.79753
Value Function Loss: 0.03093

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12179
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.55815

Collected Steps per Second: 19,552.64416
Overall Steps per Second: 9,851.67627

Timestep Collection Time: 2.55884
Timestep Consumption Time: 2.51969
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 5.07853

Cumulative Model Updates: 162,932
Cumulative Timesteps: 1,358,611,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,803.31428
Policy Entropy: 3.76839
Value Function Loss: 0.02724

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12340
Policy Update Magnitude: 0.54686
Value Function Update Magnitude: 0.50763

Collected Steps per Second: 19,874.86303
Overall Steps per Second: 9,538.75943

Timestep Collection Time: 2.51775
Timestep Consumption Time: 2.72821
PPO Batch Consumption Time: 0.32958
Total Iteration Time: 5.24597

Cumulative Model Updates: 162,938
Cumulative Timesteps: 1,358,661,046

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1358661046...
Checkpoint 1358661046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,787.58159
Policy Entropy: 3.77429
Value Function Loss: 0.02800

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.62173

Collected Steps per Second: 20,011.26584
Overall Steps per Second: 9,913.12932

Timestep Collection Time: 2.49959
Timestep Consumption Time: 2.54624
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 5.04583

Cumulative Model Updates: 162,944
Cumulative Timesteps: 1,358,711,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.55767
Policy Entropy: 3.79829
Value Function Loss: 0.02862

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.65444

Collected Steps per Second: 19,591.02358
Overall Steps per Second: 9,728.15820

Timestep Collection Time: 2.55352
Timestep Consumption Time: 2.58888
PPO Batch Consumption Time: 0.30107
Total Iteration Time: 5.14239

Cumulative Model Updates: 162,950
Cumulative Timesteps: 1,358,761,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1358761092...
Checkpoint 1358761092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,344.59163
Policy Entropy: 3.78581
Value Function Loss: 0.02857

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11727
Policy Update Magnitude: 0.56014
Value Function Update Magnitude: 0.75495

Collected Steps per Second: 19,972.58291
Overall Steps per Second: 9,514.51281

Timestep Collection Time: 2.50493
Timestep Consumption Time: 2.75335
PPO Batch Consumption Time: 0.32521
Total Iteration Time: 5.25828

Cumulative Model Updates: 162,956
Cumulative Timesteps: 1,358,811,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 191,411.27753
Policy Entropy: 3.77055
Value Function Loss: 0.02853

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.53759
Value Function Update Magnitude: 0.74567

Collected Steps per Second: 20,243.38593
Overall Steps per Second: 9,886.32993

Timestep Collection Time: 2.47152
Timestep Consumption Time: 2.58920
PPO Batch Consumption Time: 0.30459
Total Iteration Time: 5.06073

Cumulative Model Updates: 162,962
Cumulative Timesteps: 1,358,861,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1358861154...
Checkpoint 1358861154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,759.39059
Policy Entropy: 3.77062
Value Function Loss: 0.02650

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.50136
Value Function Update Magnitude: 0.60578

Collected Steps per Second: 17,219.41399
Overall Steps per Second: 9,132.24139

Timestep Collection Time: 2.90544
Timestep Consumption Time: 2.57295
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 5.47839

Cumulative Model Updates: 162,968
Cumulative Timesteps: 1,358,911,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,494.06997
Policy Entropy: 3.78894
Value Function Loss: 0.02609

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.47440
Value Function Update Magnitude: 0.50160

Collected Steps per Second: 18,662.75554
Overall Steps per Second: 9,356.01664

Timestep Collection Time: 2.67967
Timestep Consumption Time: 2.66555
PPO Batch Consumption Time: 0.31570
Total Iteration Time: 5.34522

Cumulative Model Updates: 162,974
Cumulative Timesteps: 1,358,961,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1358961194...
Checkpoint 1358961194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,114.45002
Policy Entropy: 3.77867
Value Function Loss: 0.02252

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12066
Policy Update Magnitude: 0.44830
Value Function Update Magnitude: 0.50734

Collected Steps per Second: 17,362.06824
Overall Steps per Second: 8,981.22713

Timestep Collection Time: 2.88042
Timestep Consumption Time: 2.68786
PPO Batch Consumption Time: 0.31468
Total Iteration Time: 5.56828

Cumulative Model Updates: 162,980
Cumulative Timesteps: 1,359,011,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,390.10271
Policy Entropy: 3.76404
Value Function Loss: 0.02059

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.42355
Value Function Update Magnitude: 0.53179

Collected Steps per Second: 21,099.33622
Overall Steps per Second: 10,050.53508

Timestep Collection Time: 2.37154
Timestep Consumption Time: 2.60710
PPO Batch Consumption Time: 0.30455
Total Iteration Time: 4.97864

Cumulative Model Updates: 162,986
Cumulative Timesteps: 1,359,061,242

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1359061242...
Checkpoint 1359061242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,975.71545
Policy Entropy: 3.74974
Value Function Loss: 0.01773

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.40721
Value Function Update Magnitude: 0.55358

Collected Steps per Second: 20,315.01967
Overall Steps per Second: 9,963.59291

Timestep Collection Time: 2.46232
Timestep Consumption Time: 2.55816
PPO Batch Consumption Time: 0.31268
Total Iteration Time: 5.02048

Cumulative Model Updates: 162,992
Cumulative Timesteps: 1,359,111,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,469.72448
Policy Entropy: 3.76266
Value Function Loss: 0.01739

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.39363
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 20,175.07626
Overall Steps per Second: 9,487.94192

Timestep Collection Time: 2.47930
Timestep Consumption Time: 2.79266
PPO Batch Consumption Time: 0.32518
Total Iteration Time: 5.27195

Cumulative Model Updates: 162,998
Cumulative Timesteps: 1,359,161,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1359161284...
Checkpoint 1359161284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,868.87223
Policy Entropy: 3.76815
Value Function Loss: 0.02014

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.39542
Value Function Update Magnitude: 0.62396

Collected Steps per Second: 21,032.66030
Overall Steps per Second: 9,972.78174

Timestep Collection Time: 2.37773
Timestep Consumption Time: 2.63692
PPO Batch Consumption Time: 0.31338
Total Iteration Time: 5.01465

Cumulative Model Updates: 163,004
Cumulative Timesteps: 1,359,211,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,763.24287
Policy Entropy: 3.76426
Value Function Loss: 0.02209

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.40880
Value Function Update Magnitude: 0.56271

Collected Steps per Second: 19,737.20505
Overall Steps per Second: 9,313.76061

Timestep Collection Time: 2.53410
Timestep Consumption Time: 2.83602
PPO Batch Consumption Time: 0.34616
Total Iteration Time: 5.37012

Cumulative Model Updates: 163,010
Cumulative Timesteps: 1,359,261,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1359261310...
Checkpoint 1359261310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,763.24287
Policy Entropy: 3.75664
Value Function Loss: 0.02417

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.43909
Value Function Update Magnitude: 0.42977

Collected Steps per Second: 19,856.51885
Overall Steps per Second: 9,787.97471

Timestep Collection Time: 2.51877
Timestep Consumption Time: 2.59097
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 5.10974

Cumulative Model Updates: 163,016
Cumulative Timesteps: 1,359,311,324

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,763.03924
Policy Entropy: 3.74163
Value Function Loss: 0.02301

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.43735
Value Function Update Magnitude: 0.42104

Collected Steps per Second: 20,566.47369
Overall Steps per Second: 10,123.64789

Timestep Collection Time: 2.43172
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29440
Total Iteration Time: 4.94012

Cumulative Model Updates: 163,022
Cumulative Timesteps: 1,359,361,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1359361336...
Checkpoint 1359361336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,242.19369
Policy Entropy: 3.73759
Value Function Loss: 0.02170

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.45731
Value Function Update Magnitude: 0.54217

Collected Steps per Second: 20,726.98223
Overall Steps per Second: 10,020.90971

Timestep Collection Time: 2.41376
Timestep Consumption Time: 2.57880
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.99256

Cumulative Model Updates: 163,028
Cumulative Timesteps: 1,359,411,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,616.26262
Policy Entropy: 3.73961
Value Function Loss: 0.01990

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.46455
Value Function Update Magnitude: 0.59768

Collected Steps per Second: 20,412.90902
Overall Steps per Second: 10,240.57971

Timestep Collection Time: 2.45031
Timestep Consumption Time: 2.43398
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.88429

Cumulative Model Updates: 163,034
Cumulative Timesteps: 1,359,461,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1359461384...
Checkpoint 1359461384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,042.72015
Policy Entropy: 3.72778
Value Function Loss: 0.02163

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.46141
Value Function Update Magnitude: 0.50796

Collected Steps per Second: 18,816.51279
Overall Steps per Second: 9,495.55761

Timestep Collection Time: 2.65937
Timestep Consumption Time: 2.61047
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 5.26983

Cumulative Model Updates: 163,040
Cumulative Timesteps: 1,359,511,424

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 231,850.88105
Policy Entropy: 3.74884
Value Function Loss: 0.02143

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.49941
Value Function Update Magnitude: 0.48127

Collected Steps per Second: 19,981.35925
Overall Steps per Second: 9,921.40503

Timestep Collection Time: 2.50483
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 5.04465

Cumulative Model Updates: 163,046
Cumulative Timesteps: 1,359,561,474

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1359561474...
Checkpoint 1359561474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,753.58599
Policy Entropy: 3.73879
Value Function Loss: 0.02283

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.48109
Value Function Update Magnitude: 0.44051

Collected Steps per Second: 19,762.58822
Overall Steps per Second: 9,868.39730

Timestep Collection Time: 2.53145
Timestep Consumption Time: 2.53807
PPO Batch Consumption Time: 0.30813
Total Iteration Time: 5.06952

Cumulative Model Updates: 163,052
Cumulative Timesteps: 1,359,611,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,391.01150
Policy Entropy: 3.75987
Value Function Loss: 0.02234

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.47283
Value Function Update Magnitude: 0.45775

Collected Steps per Second: 21,305.01319
Overall Steps per Second: 10,096.98450

Timestep Collection Time: 2.34790
Timestep Consumption Time: 2.60625
PPO Batch Consumption Time: 0.30447
Total Iteration Time: 4.95415

Cumulative Model Updates: 163,058
Cumulative Timesteps: 1,359,661,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1359661524...
Checkpoint 1359661524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,691.73557
Policy Entropy: 3.75985
Value Function Loss: 0.02588

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.50385
Value Function Update Magnitude: 0.55509

Collected Steps per Second: 20,733.21459
Overall Steps per Second: 10,174.58497

Timestep Collection Time: 2.41390
Timestep Consumption Time: 2.50502
PPO Batch Consumption Time: 0.29843
Total Iteration Time: 4.91892

Cumulative Model Updates: 163,064
Cumulative Timesteps: 1,359,711,572

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,908.07588
Policy Entropy: 3.76262
Value Function Loss: 0.02523

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.54359
Value Function Update Magnitude: 0.49377

Collected Steps per Second: 20,743.27843
Overall Steps per Second: 9,874.48355

Timestep Collection Time: 2.41235
Timestep Consumption Time: 2.65526
PPO Batch Consumption Time: 0.31124
Total Iteration Time: 5.06761

Cumulative Model Updates: 163,070
Cumulative Timesteps: 1,359,761,612

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1359761612...
Checkpoint 1359761612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,901.41645
Policy Entropy: 3.75361
Value Function Loss: 0.02333

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.53007
Value Function Update Magnitude: 0.52666

Collected Steps per Second: 19,107.98549
Overall Steps per Second: 9,781.90606

Timestep Collection Time: 2.61681
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29845
Total Iteration Time: 5.11168

Cumulative Model Updates: 163,076
Cumulative Timesteps: 1,359,811,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,779.08434
Policy Entropy: 3.74442
Value Function Loss: 0.02321

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.49882
Value Function Update Magnitude: 0.47411

Collected Steps per Second: 20,063.51682
Overall Steps per Second: 9,556.22922

Timestep Collection Time: 2.49348
Timestep Consumption Time: 2.74164
PPO Batch Consumption Time: 0.31363
Total Iteration Time: 5.23512

Cumulative Model Updates: 163,082
Cumulative Timesteps: 1,359,861,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1359861642...
Checkpoint 1359861642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,851.30429
Policy Entropy: 3.76181
Value Function Loss: 0.01977

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14560
Policy Update Magnitude: 0.47445
Value Function Update Magnitude: 0.41932

Collected Steps per Second: 18,732.68484
Overall Steps per Second: 9,386.41919

Timestep Collection Time: 2.66988
Timestep Consumption Time: 2.65846
PPO Batch Consumption Time: 0.31135
Total Iteration Time: 5.32834

Cumulative Model Updates: 163,088
Cumulative Timesteps: 1,359,911,656

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,851.30429
Policy Entropy: 3.74998
Value Function Loss: 0.01831

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.43924
Value Function Update Magnitude: 0.38965

Collected Steps per Second: 20,045.32052
Overall Steps per Second: 9,954.54679

Timestep Collection Time: 2.49604
Timestep Consumption Time: 2.53020
PPO Batch Consumption Time: 0.30800
Total Iteration Time: 5.02625

Cumulative Model Updates: 163,094
Cumulative Timesteps: 1,359,961,690

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1359961690...
Checkpoint 1359961690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,261.98304
Policy Entropy: 3.74296
Value Function Loss: 0.01878

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14533
Policy Update Magnitude: 0.42386
Value Function Update Magnitude: 0.40496

Collected Steps per Second: 20,129.23448
Overall Steps per Second: 10,209.75220

Timestep Collection Time: 2.48514
Timestep Consumption Time: 2.41449
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.89963

Cumulative Model Updates: 163,100
Cumulative Timesteps: 1,360,011,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,561.07749
Policy Entropy: 3.74371
Value Function Loss: 0.02315

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14487
Policy Update Magnitude: 0.45088
Value Function Update Magnitude: 0.49853

Collected Steps per Second: 20,358.76999
Overall Steps per Second: 9,844.68168

Timestep Collection Time: 2.45634
Timestep Consumption Time: 2.62336
PPO Batch Consumption Time: 0.30898
Total Iteration Time: 5.07970

Cumulative Model Updates: 163,106
Cumulative Timesteps: 1,360,061,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1360061722...
Checkpoint 1360061722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,887.53073
Policy Entropy: 3.76326
Value Function Loss: 0.02545

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.49903
Value Function Update Magnitude: 0.58988

Collected Steps per Second: 20,323.24040
Overall Steps per Second: 9,902.90060

Timestep Collection Time: 2.46034
Timestep Consumption Time: 2.58889
PPO Batch Consumption Time: 0.30425
Total Iteration Time: 5.04923

Cumulative Model Updates: 163,112
Cumulative Timesteps: 1,360,111,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,008.48368
Policy Entropy: 3.76770
Value Function Loss: 0.02641

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.52002
Value Function Update Magnitude: 0.58834

Collected Steps per Second: 20,306.46441
Overall Steps per Second: 9,982.63556

Timestep Collection Time: 2.46326
Timestep Consumption Time: 2.54745
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 5.01070

Cumulative Model Updates: 163,118
Cumulative Timesteps: 1,360,161,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1360161744...
Checkpoint 1360161744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,883.81166
Policy Entropy: 3.77596
Value Function Loss: 0.02342

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.51894
Value Function Update Magnitude: 0.61528

Collected Steps per Second: 20,013.39109
Overall Steps per Second: 10,110.71970

Timestep Collection Time: 2.49853
Timestep Consumption Time: 2.44711
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.94564

Cumulative Model Updates: 163,124
Cumulative Timesteps: 1,360,211,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,385.64496
Policy Entropy: 3.78204
Value Function Loss: 0.02142

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.49933
Value Function Update Magnitude: 0.68403

Collected Steps per Second: 21,191.18302
Overall Steps per Second: 10,306.37096

Timestep Collection Time: 2.36108
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.85467

Cumulative Model Updates: 163,130
Cumulative Timesteps: 1,360,261,782

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1360261782...
Checkpoint 1360261782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,288.55730
Policy Entropy: 3.77314
Value Function Loss: 0.01953

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.46741
Value Function Update Magnitude: 0.71138

Collected Steps per Second: 21,248.55398
Overall Steps per Second: 10,199.41301

Timestep Collection Time: 2.35310
Timestep Consumption Time: 2.54914
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.90224

Cumulative Model Updates: 163,136
Cumulative Timesteps: 1,360,311,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,122.09461
Policy Entropy: 3.75719
Value Function Loss: 0.01997

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.43236
Value Function Update Magnitude: 0.64923

Collected Steps per Second: 21,344.52599
Overall Steps per Second: 10,359.66269

Timestep Collection Time: 2.34440
Timestep Consumption Time: 2.48588
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.83027

Cumulative Model Updates: 163,142
Cumulative Timesteps: 1,360,361,822

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1360361822...
Checkpoint 1360361822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,190.99106
Policy Entropy: 3.74550
Value Function Loss: 0.01848

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.40479
Value Function Update Magnitude: 0.49387

Collected Steps per Second: 21,494.81864
Overall Steps per Second: 10,214.39528

Timestep Collection Time: 2.32679
Timestep Consumption Time: 2.56963
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 4.89642

Cumulative Model Updates: 163,148
Cumulative Timesteps: 1,360,411,836

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,536.49989
Policy Entropy: 3.75363
Value Function Loss: 0.01983

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.39929
Value Function Update Magnitude: 0.41733

Collected Steps per Second: 17,934.08876
Overall Steps per Second: 9,642.13412

Timestep Collection Time: 2.78944
Timestep Consumption Time: 2.39883
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 5.18827

Cumulative Model Updates: 163,154
Cumulative Timesteps: 1,360,461,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1360461862...
Checkpoint 1360461862 saved!
